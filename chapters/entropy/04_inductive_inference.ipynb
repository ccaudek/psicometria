{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239ed652-5e3e-4270-b5a3-f3437e6cae2b",
   "metadata": {},
   "source": [
    "# Limiti dell'inferenza induttiva {#sec-inductive-inference}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisiti**\n",
    "\n",
    "- Leggere *Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection* di @navarro2019between per un'introduzione ai limiti dell'inferenza induttiva.\n",
    "\n",
    "**Concetti e competenze chiave**\n",
    "\n",
    "- Selezione di ipotesi attraverso il teorema di Bayes.\n",
    "- Distinzione tra \"Grande Mondo\" e \"Piccolo Mondo\" secondo @McElreath_rethinking.\n",
    "- \"Validità poetica\" e disconnessione tra teoria e osservazione.\n",
    "- Concetti di Paul Meehl sulla teoria sostanziale, ipotesi statistica testabile e osservazioni.\n",
    "- Problemi epistemologici e operazionalizzazione dei concetti teorici in concetti empirici.\n",
    "- Selezione dei modelli e capacità di generalizzazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione {.unnumbered}\n",
    "\n",
    "È fondamentale comprendere che la selezione di ipotesi attraverso il teorema di Bayes, e i suoi sviluppi come il confronto tra modelli tramite il calcolo dell’Expected Log Predictive Density (ELPD), non risolve completamente il problema dell’inferenza statistica. Secondo @McElreath_rethinking, queste procedure affrontano problemi in un “piccolo mondo”, ma non è chiaro come queste soluzioni si estendano al “grande mondo” che ci interessa realmente. L’obiettivo di questo capitolo è approfondire questi temi, illustrando la disconnessione tra la teoria dei fenomeni empirici e i modelli statistici semplificati che possiamo testare in pratica.\n",
    "\n",
    "## Inferenza Statistica\n",
    "\n",
    "L’inferenza statistica è un processo di inferenza induttiva in cui i dati osservati non forniscono informazioni sufficienti per essere certi del processo che li ha generati, e la regola di Bayes offre una soluzione ottimale. @McElreath_rethinking introduce il concetto di “Grande Mondo”, che rappresenta l’infinità di processi possibili che potrebbero spiegare le nostre osservazioni. Poiché effettuare inferenze dirette su tutte le possibili proprietà del Grande Mondo è impraticabile, ci orientiamo verso il “Piccolo Mondo”, una rappresentazione semplificata che considera un insieme finito di modelli e parametri rilevanti per il nostro studio.\n",
    "\n",
    "Ad esempio, nell’analisi dell’altezza, potremmo proporre un modello probabilistico in cui l’altezza segue una distribuzione normale, caratterizzata da una media (µ) e una deviazione standard (σ), con l’intento di stimare questi parametri ignoti. La collezione di distribuzioni di probabilità derivante dalla variazione dei parametri del modello nel Piccolo Mondo costituisce la funzione di verosimiglianza. Tuttavia, questo insieme è spesso troppo ampio per essere gestito con facilità. La nostra conoscenza pregressa o le nostre convinzioni riguardo al fenomeno in esame ci assistono nel restringere le possibilità.\n",
    "\n",
    "Nell’inferenza bayesiana, queste convinzioni iniziali vengono espresse tramite una densità di probabilità a priori, che attribuisce un peso ai possibili parametri del modello in base alle nostre convinzioni iniziali. La regola di Bayes, cuore dell’inferenza bayesiana, permette di aggiornare queste convinzioni alla luce dei nuovi dati osservati. Attraverso questo processo, otteniamo la probabilità a posteriori dei parametri, che fornisce una stima più accurata del processo generativo dei dati, T.\n",
    "\n",
    "In sintesi, l’inferenza statistica ci avvicina alla comprensione di fenomeni complessi attraverso la modellazione delle osservazioni via processi semplificati nel “Piccolo Mondo”. Grazie all’inferenza bayesiana, che integra le conoscenze pregresse ai nuovi dati, perfezioniamo le nostre stime per una comprensione più profonda del vero processo sottostante. Non miriamo a un “modello perfetto” che rifletta ogni dettaglio del “Grande Mondo”, bensì a individuare modelli del “Piccolo Mondo” che siano efficaci nel fare previsioni sul fenomeno studiato. Attraverso la statistica, disponiamo degli strumenti per costruire, valutare e selezionare modelli basati sull’inferenza bayesiana, che ci consentono di aggiornare e rifinire i nostri modelli in risposta a nuove informazioni. Questo processo ci guida verso modelli “utili”, che, seppur non perfetti, ci permettono di fare previsioni accurate e di approfondire la nostra comprensione del fenomeno di interesse.\n",
    "\n",
    "## Validità Poetica {#sec-poetic-validity}\n",
    "\n",
    "In precedenza, abbiamo focalizzato la nostra attenzione sul teorema di Bayes come metodo per verificare la plausibilità di un’ipotesi, uno dei motivi chiave della sua importanza. Tuttavia, è essenziale comprendere che la quantificazione della plausibilità di un’ipotesi non risolve il problema scientifico dell’inferenza. Questo problema è stato ben caratterizzato da @navarro2019between, utilizzando una metafora di @box1976science:\n",
    "\n",
    "> Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.\n",
    "\n",
    "In questa metafora, i topi rappresentano i dettagli del nostro modello statistico, mentre la tigre è la disconnessione tra i dati osservati, modellizzati dal teorema di Bayes, e la teoria del fenomeno, che rappresenta il centro del nostro interesse.\n",
    "\n",
    "Paul Meehl ha articolato questo problema distinguendo tre piani: la teoria sostanziale (A), l’ipotesi statistica testabile (T) e le osservazioni (O). L’articolazione tra questi tre piani della riflessione scientifica solleva importanti difficoltà:\n",
    "\n",
    "> The map from substantive theory (A) to testable statistical hypothesis (T) goes through a derivation chain involving auxiliary theories, instruments, ceteris paribus assertions, and experimental conditions. The map from hypothesis to observation is through the statistical model manufactured by the derivation chain.\n",
    "\n",
    "La teoria statistica offre vari mezzi per inferire la veridicità di T da O, di solito attraverso la regola di Bayes. Tuttavia, anche se inferiamo che T ha un’alta probabilità date tutte le nostre evidenze, ciò non risolve il problema di calcolare la probabilità di A da T. Meehl sosteneva l’assenza di una procedura formale capace di tradurre rigorosamente tra le osservazioni empiriche (O) e la teoria scientifica (A).\n",
    "\n",
    "Il modello statistico, costruito attraverso una catena di derivazione, mappa l’ipotesi (T) sulle osservazioni (O). L’inferenza statistica, tipicamente basata sul teorema di Bayes, permette di valutare la probabilità di T dato O. Tuttavia, il passaggio cruciale da T a A rimane problematico. Questo coinvolge una catena di derivazione che include teorie ausiliarie, strumenti, assunzioni ceteris paribus e condizioni sperimentali [@hardt2022patterns]. Il passaggio inverso da O a A rimane dunque problematico e non caratterizzato da proprietà formali rigide.\n",
    "\n",
    "Questa disconnessione tra T e A è stata descritta come una forma di [\"validità poetica\"](https://kevinmunger.substack.com/p/do-echo-chambers-cause-echo-chambers). Questo concetto si riferisce alla capacità di un’idea di risuonare con l’intelletto e l’esperienza umana attraverso il linguaggio, anche quando non può essere rigorosamente validata in termini scientifici o statistici. La validità poetica sottolinea l’importanza dell’intuizione e della comprensione qualitativa nel processo di teorizzazione scientifica, complementando l’approccio puramente quantitativo e formale [@hardt2022patterns].\n",
    "\n",
    "La dicotomia tra concetti teorici e concetti empirici, manifestata nel processo di operazionalizzazione, chiarisce ulteriormente questa problematica [@hempel1970formazione]. L’operazionalizzazione dei concetti teorici in concetti empirici è un processo arbitrario e uno-a-molti, che comporta diverse implicazioni:\n",
    "\n",
    "- **Sottodeterminazione delle teorie:** Nessun test di ipotesi può essere considerato un test diretto di una teoria, dato che l’operazionalizzazione introduce un elemento di arbitrarietà.\n",
    "- **Flessibilità teorica:** La relazione uno-a-molti tra concetti teorici ed empirici permette un raffinamento progressivo delle teorie.\n",
    "- **Ambiguità empirica:** Operazionalizzazioni diverse possono portare a risultati contraddittori rispetto alla stessa teoria.\n",
    "- **Necessità di formalizzazione:** Le teorie psicologiche devono essere espresse in termini formali per consentire predizioni quantitative.\n",
    "\n",
    "In conclusione, il problema della demarcazione tra teoria e osservazione in psicologia rimane un tema aperto e fondamentale. La consapevolezza di queste limitazioni epistemologiche dovrebbe informare sia la pratica della ricerca empirica che l’interpretazione dei suoi risultati, promuovendo un approccio più critico alla costruzione, validazione e interpretazione delle teorie psicologiche.\n",
    "\n",
    "### Between the Devil and the Deep Blue Sea\n",
    "\n",
    "Poiché esistono diverse teorie concorrenti sul mondo, ciascuna rappresentata come modelli computazionali parametrizzati che forniscono interpretazioni diverse di un set di dati, come decidere quale modello sia meglio supportato dai dati? Questo può essere formulato come un problema di inferenza statistica, con la cross-validation come uno dei metodi per trovare una risposta.\n",
    "\n",
    "@navarro2019between osserva che, sebbene l’approccio della selezione di modelli sia encomiabile, una procedura di selezione applicata a problemi semplificati è un cattivo sostituto per i problemi inferenziali affrontati dagli scienziati. Gli scienziati sono consapevoli che tutti i modelli sono errati. Non comprendiamo pienamente i fenomeni che studiamo, e ogni descrizione formale basata su modelli del fenomeno è errata in modo sconosciuto e sistematico. Spesso ci troviamo di fronte al dilemma tra il diavolo della decisione statistica e il mare aperto delle questioni scientifiche. La letteratura sulla selezione di modelli tende a porre troppa enfasi sui problemi statistici di scelta del modello e troppo poca sulle questioni scientifiche a cui si riferiscono.\n",
    "\n",
    "Capire come i pattern qualitativi nei dati empirici emergano naturalmente da un modello computazionale di un processo psicologico è spesso più utile scientificamente rispetto alla presentazione di una misura quantificata delle sue performance. Dato quanto poco comprendiamo delle diverse modalità in cui funziona la cognizione umana e l’artificialità della maggior parte degli studi sperimentali, è lecito chiedersi quale sia lo scopo di quantificare la capacità di un modello di fare previsioni precise su ogni dettaglio nei dati. In pratica, molte esercitazioni in cui la scelta del modello si basa troppo su misure quantitative delle performance selezionano modelli basati su assunzioni ancillari, il che difficilmente risolve un problema scientifico di interesse.\n",
    "\n",
    "@navarro2019between, la caratteristica più utile di un modello non è la sua capacità di predire in maniera perfetta un determinato campione di dati, ma la sua capacità di generalizzazione. Per illustrare questo concetto, @navarro2019between descrive il motivo per cui riteniamo il modello di Rescorla-Wagner sul condizionamento pavloviano (Rescorla & Wagner, 1972) un punto di svolta fondamentale nello sviluppo delle teorie dell’apprendimento. Sebbene il modello fornisse una buona spiegazione di una serie di fenomeni di condizionamento già noti, come il blocco (Kamin, 1969), la sovrapposizione (Pavlov, 1927), l’inibizione condizionata (Rescorla, 1969) e gli effetti di contingenza (Rescorla, 1968), il contributo davvero impressionante non risiedeva nella capacità di predire nuovi dati da repliche di questi esperimenti, ma piuttosto nella capacità di anticipare nuovi fenomeni, come la sovraaspettativa (Lattal & Nakajima, 1998) e il super condizionamento (Rescorla, 1971). In altre parole, una delle funzioni più importanti di una teoria scientifica non è semplicemente quella di predire nuovi dati da esperimenti vecchi, ma di incoraggiare l’esplorazione diretta di nuovi territori, come illustrato dal ruolo significativo che il modello di Rescorla-Wagner ha avuto nell’aiutare i neuroscienziati a investigare i segnali di errore di previsione della ricompensa (ad esempio, Schultz, Dayan & Montague, 1997).\n",
    "\n",
    "@gronau2019limitations inquadrano la questione della selezione dei modelli come un dilemma pericoloso in cui si è intrappolati tra due mostri della mitologia classica: la Scilla dell’overfitting e la Cariddi dell’underfitting. Secondo @navarro2019between, è invece più comune per un ricercatore trovarsi a fronteggiare un dilemma di natura diversa, ovvero la tensione tra il diavolo della decisione statistica e il profondo mare blu delle questioni scientifiche. Gran parte della letteratura sulla selezione dei modelli pone troppa enfasi sugli aspetti statistici della scelta del modello e troppo poca sulle domande scientifiche a cui questi modelli si rivolgono. Nella vita reale molti esercizi in cui la scelta del modello si basa eccessivamente su misure quantitative di performance selezionano essenzialmente modelli in base alle loro assunzioni accessorie. Ma non è chiaro se e come questo risolva un problema scientifico di interesse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b318aa0d-78b8-4f73-80e0-117f3ccfb08f",
   "metadata": {},
   "source": [
    "## Riflessioni Conclusive \n",
    "\n",
    "In questo capitolo, abbiamo esaminato le complessità e le sfide dell'inferenza statistica e della selezione dei modelli attraverso una lente bayesiana. Sebbene il teorema di Bayes e i suoi strumenti derivati, come l'Expected Log Predictive Density (ELPD), siano potenti per aggiornare e confrontare modelli, essi operano principalmente in un \"Piccolo Mondo\" semplificato. Questo limita la nostra capacità di trarre conclusioni definitive sul \"Grande Mondo\" reale che ci interessa.\n",
    "\n",
    "La \"validità poetica\" sottolinea l'importanza di riconoscere le limitazioni intrinseche delle nostre rappresentazioni statistiche e di valorizzare l'intuizione e la comprensione qualitativa nel contesto scientifico. La distinzione tra concetti teorici e osservazioni empiriche ci ricorda che, nonostante i progressi metodologici, rimane una disconnessione fondamentale tra la teoria e le osservazioni empiriche.\n",
    "\n",
    "Infine, la capacità di un modello di generalizzare, piuttosto che di prevedere perfettamente i dati osservati, emerge come un criterio cruciale per la sua utilità scientifica. L'esempio del modello di Rescorla-Wagner illustra come un buon modello possa stimolare nuove esplorazioni e approfondimenti, dimostrando che il vero valore di una teoria scientifica risiede nella sua capacità di guidare l'indagine futura piuttosto che semplicemente adattarsi ai dati esistenti.\n",
    "\n",
    "In sintesi, questo capitolo ci invita a mantenere un equilibrio tra rigore quantitativo e intuizione qualitativa, riconoscendo i limiti delle nostre tecniche e cercando continuamente di migliorare le nostre rappresentazioni del complesso mondo reale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc5_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
