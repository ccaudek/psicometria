{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2cfc484-08e2-402a-8845-8e54d43dc40b",
   "metadata": {},
   "source": [
    "# Divergenza KL e ELPD {#sec-kl-elpd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisiti**\n",
    "\n",
    "**Concetti e competenze chiave**\n",
    "\n",
    "- Comprendere in modo dettagliato il concetto di Expected Log Predictive Density (ELPD), apprezzandone l'importanza e l'applicabilità nel contesto della valutazione predittiva dei modelli statistici.\n",
    "- Esplorare e analizzare la relazione tra il concetto di entropia e la ELPD, identificando come l'entropia possa influenzare o riflettere la capacità predittiva di un modello attraverso la densità logaritmica predittiva prevista.\n",
    "\n",
    "**Preparazione del Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6aa9ee-fd35-44ce-a0e5-69f1d084dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6520d11-c083-4b80-86b5-dcb07dab3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed: int = sum(map(ord, \"kl\"))\n",
    "rng: np.random.Generator = np.random.default_rng(seed=seed)\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione {.unnumbered}\n",
    "\n",
    "In questo capitolo, esamineremo in dettaglio tre concetti fondamentali per la valutazione e il confronto di modelli statistici nel contesto bayesiano: la distribuzione predittiva posteriori, \n",
    "la Divergenza di Kullback-Leibler ($\\mathbb{KL}$) e la Densità Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD). Questi strumenti ci permettono di quantificare l'adattamento dei modelli ai dati e la loro capacità predittiva.\n",
    "\n",
    "## Distribuzione Predittiva Posteriori\n",
    "\n",
    "La distribuzione predittiva posteriori $Q(\\tilde{y} \\mid y)$ rappresenta la distribuzione dei possibili nuovi dati $\\tilde{y},$ dati i dati osservati $y$. Essa si ottiene combinando:\n",
    "\n",
    "- la distribuzione del modello per i nuovi dati data una configurazione dei parametri $\\theta$: $Q(\\tilde{y} \\mid \\theta)$;\n",
    "- la distribuzione posteriore dei parametri data i dati osservati: $P(\\theta \\mid y)$.\n",
    "\n",
    "Matematicamente, la distribuzione predittiva posteriori può essere scritta come:\n",
    "\n",
    "$$\n",
    "Q(\\tilde{y} \\mid y) = \\int Q(\\tilde{y} \\mid \\theta) P(\\theta \\mid y) d\\theta.\n",
    "$$\n",
    "\n",
    "Questa espressione si legge come l'integrale della distribuzione predittiva $Q(\\tilde{y} \\mid \\theta)$ pesata dalla distribuzione posteriore dei parametri $P(\\theta \\mid y)$. In altre parole, stiamo \"mediando\" le previsioni del modello su tutte le possibili configurazioni dei parametri, tenendo conto della loro probabilità posteriore. La distribuzione predittiva posteriori è stata descritta nella @sec-posterior-predictive-distribution.\n",
    "\n",
    "## Divergenza di Kullback-Leibler (KL)\n",
    "\n",
    "La divergenza di Kullback-Leibler $\\mathbb{KL}(P \\parallel Q)$ misura la distanza tra due distribuzioni, $P$ e $Q$. È definita come:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(P \\parallel Q) = \\mathbb{E}_P[\\log P(X)] - \\mathbb{E}_P[\\log Q(X)].\n",
    "$$\n",
    "\n",
    "Il termine $\\mathbb{E}_P[\\log P(X)]$ è il valore atteso del logaritmo della distribuzione $P(X)$ sotto $P$ stessa, cioè:\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}_P[\\log P(X)] = \\sum_{i=1}^n p_i \\log p_i.\n",
    "  $$\n",
    "\n",
    "  Per distribuzioni continue, l'espressione diventa:\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}_P[\\log P(X)] = \\int p(x) \\log p(x) \\, dx.\n",
    "  $$\n",
    "\n",
    "  Questo termine rappresenta l'entropia negativa della distribuzione $P$.\n",
    "\n",
    "Il termine $\\mathbb{E}_P[\\log Q(X)]$ è il valore atteso del logaritmo della distribuzione $Q(X)$ sotto la distribuzione $P(X)$:\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}_P[\\log Q(X)] = \\sum_{i=1}^n p_i \\log q_i.\n",
    "  $$\n",
    "\n",
    "  Per variabili continue:\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}_P[\\log Q(X)] = \\int p(x) \\log q(x) \\, dx.\n",
    "  $$\n",
    "\n",
    "  Questo rappresenta l'entropia incrociata tra $P$ e $Q$.\n",
    "\n",
    "La divergenza KL è quindi:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(P \\parallel Q) = \\sum_{i=1}^n p_i (\\log p_i - \\log q_i)\n",
    "$$\n",
    "\n",
    "o, in forma continua:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(P \\parallel Q) = \\int p(x) (\\log p(x) - \\log q(x)) \\, dx\n",
    "$$\n",
    "\n",
    "Un punto importante è che la divergenza KL non è simmetrica, il che significa che $\\mathbb{KL}(P \\parallel Q) \\neq \\mathbb{KL}(Q \\parallel P)$. Questa divergenza misura quanta \"informazione\" si perde usando $Q$ al posto di $P$.\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Per rendere più chiaro il concetto di divergenza di Kullback-Leibler (KL) nel caso discreto, consideriamo un esempio semplice. Immaginiamo di avere due distribuzioni di probabilità discrete, $P$ e $Q$, su un insieme di eventi $\\{A, B, C\\}$. Supponiamo che le probabilità associate a ciascun evento sotto le distribuzioni $P$ e $Q$ siano le seguenti:\n",
    "\n",
    "- distribuzione $P$: $P(A) = 0.5$, $P(B) = 0.3$, $P(C) = 0.2$;\n",
    "- distribuzione $Q$: $Q(A) = 0.4$, $Q(B) = 0.4$, $Q(C) = 0.2$.\n",
    "\n",
    "La divergenza KL $\\mathbb{KL}(P \\parallel Q)$ è definita come:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(P \\parallel Q) = \\sum_{i} P(i) \\log \\frac{P(i)}{Q(i)},\n",
    "$$\n",
    "\n",
    "dove $i$ scorre su tutti gli eventi possibili $\\{A, B, C\\}$. Quindi, dobbiamo calcolare  $P(A) \\log \\frac{P(A)}{Q(A)}$,  $P(B) \\log \\frac{P(B)}{Q(B)}$ e  $P(C) \\log \\frac{P(C)}{Q(C)}$, ovvero,\n",
    "\n",
    "   $$\n",
    "   P(A) \\log \\frac{P(A)}{Q(A)} = 0.5 \\log \\frac{0.5}{0.4} 0.11155,\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   P(B) \\log \\frac{P(B)}{Q(B)} = 0.3 \\log \\frac{0.3}{0.4} = -0.08631,\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   P(C) \\log \\frac{P(C)}{Q(C)} = 0.2 \\log \\frac{0.2}{0.2} = 0.\n",
    "   $$\n",
    "\n",
    "Ora sommiamo tutti i termini:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(P \\parallel Q) = 0.11155 + (-0.08631) + 0 = 0.02524.\n",
    "$$\n",
    "\n",
    "La divergenza KL $\\mathbb{KL}(P \\parallel Q) \\approx 0.025$ indica che la distribuzione $Q$ non è troppo lontana dalla distribuzione $P$, ma c'è una piccola discrepanza tra le due. Se il valore fosse maggiore, significherebbe che la distribuzione $Q$ si discosta maggiormente da $P$, indicando una maggiore perdita di informazione se si usa $Q$ al posto di $P$.\n",
    "\n",
    ":::\n",
    "\n",
    "## Expected Log Predictive Density (ELPD)\n",
    "\n",
    "L'ELPD è una misura che valuta la capacità predittiva di un modello. Si definisce come:\n",
    "\n",
    "$$\n",
    "\\text{ELPD} = \\sum_{i=1}^n \\log p(y_i | \\mathbf{y}_{-i})\n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $y_i$ è l'i-esima osservazione,\n",
    "- $\\mathbf{y}_{-i}$ rappresenta tutte le osservazioni eccetto $y_i$.\n",
    "\n",
    "L'idea alla base dell'ELPD è di valutare quanto bene un modello prevede ciascun dato osservato utilizzando tutti gli altri dati. Questo approccio, noto come leave-one-out cross-validation, è particolarmente utile per evitare l'overfitting, perché valuta le previsioni del modello su dati che non ha \"visto\" durante il processo di addestramento.\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Per illustrare il calcolo dell'Expected Log Predictive Density (ELPD), vediamo un esempio semplice con un set di dati molto piccolo. Supponiamo di avere un dataset di tre osservazioni: $y_1, y_2, y_3$. Supponiamo che il nostro modello stimi le probabilità per ciascuna osservazione in base a tutte le altre osservazioni, cioè utilizziamo la leave-one-out cross-validation (LOO-CV) per calcolare $p(y_i \\mid \\mathbf{y}_{-i})$.\n",
    "\n",
    "Immaginiamo che il modello produca le seguenti probabilità condizionali per ogni osservazione $y_i$:\n",
    "\n",
    "- $p(y_1 \\mid y_2, y_3) = 0.6$,\n",
    "- $p(y_2 \\mid y_1, y_3) = 0.7$,\n",
    "- $p(y_3 \\mid y_1, y_2) = 0.5$.\n",
    "\n",
    "L'ELPD si calcola sommando i logaritmi di queste probabilità:\n",
    "\n",
    "$$\n",
    "\\text{ELPD} = \\log p(y_1 \\mid y_2, y_3) + \\log p(y_2 \\mid y_1, y_3) + \\log p(y_3 \\mid y_1, y_2).\n",
    "$$\n",
    "\n",
    "Calcoliamo i logaritmi naturali di ciascuna probabilità:\n",
    "\n",
    "- $\\log p(y_1 \\mid y_2, y_3) = \\log 0.6 \\approx -0.5108$,\n",
    "- $\\log p(y_2 \\mid y_1, y_3) = \\log 0.7 \\approx -0.3567$,\n",
    "- $\\log p(y_3 \\mid y_1, y_2) = \\log 0.5 \\approx -0.6931$.\n",
    "\n",
    "Sommiamo i logaritmi per ottenere l'ELPD:\n",
    "\n",
    "$$\n",
    "\\text{ELPD} = -0.5108 + (-0.3567) + (-0.6931) = -1.5606.\n",
    "$$\n",
    "\n",
    "L'ELPD ottenuto è $-1.5606$. In generale, valori più vicini a 0 o positivi indicano una migliore capacità predittiva del modello, poiché suggeriscono che le probabilità condizionali assegnate dal modello alle osservazioni lasciate fuori non sono troppo basse. Valori molto negativi indicherebbero che il modello ha assegnato probabilità molto basse alle osservazioni effettivamente osservate, suggerendo una scarsa capacità predittiva. L'ELPD è un modo efficace per valutare quanto bene un modello generalizza a nuovi dati, evitando l'overfitting.\n",
    "\n",
    ":::\n",
    "\n",
    "## Collegamento tra Divergenza KL e ELPD\n",
    "\n",
    "Entrambe le misure (Divergenza KL e ELPD) valutano la qualità del modello, ma da prospettive diverse:\n",
    "\n",
    "- la divergenza KL misura quanto la distribuzione predittiva del modello $Q$ si avvicina alla \"vera\" distribuzione $P$;\n",
    "- l'ELPD valuta direttamente la capacità del modello di prevedere nuovi dati, utilizzando la tecnica leave-one-out.\n",
    "\n",
    "Idealmente, vorremmo calcolare la divergenza KL per confrontare i modelli, poiché fornisce una misura diretta di quanto un modello si avvicina alla vera distribuzione dei dati. Tuttavia, poiché $P$ è sconosciuta nella pratica, la divergenza KL non può essere calcolata direttamente. Per questo motivo, nella pratica si utilizza l'ELPD, che, pur fornendo una misura leggermente diversa, ha il grande vantaggio di poter essere calcolata e offre una stima della capacità predittiva di un modello.\n",
    "\n",
    "L'ELPD tende a favorire modelli che non solo si adattano bene ai dati osservati, ma che sono anche robusti rispetto all'overfitting, grazie alla sua enfasi sulla capacità predittiva su dati non osservati.\n",
    "\n",
    "In sintesi, la distribuzione predittiva posteriori, la divergenza di Kullback-Leibler e l'ELPD sono strumenti matematici che ci permettono di valutare la bontà di un modello statistico. La divergenza KL fornisce una misura teoricamente ideale di quanto un modello approssima la vera distribuzione dei dati, mentre l'ELPD offre un'alternativa praticabile che valuta la capacità del modello di fare previsioni su nuovi dati. Questi concetti sono fondamentali nell'inferenza bayesiana, dove è importante non solo adattarsi ai dati esistenti, ma anche generalizzare bene su dati futuri.\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Consideriamo un secondo esempio per illustrare il concetto di ELPD utilizzando la distribuzione binomiale. Immaginiamo di condurre un esperimento in cui lanciamo una moneta 10 volte e contiamo il numero di volte in cui otteniamo testa. Supponiamo che la vera probabilità di ottenere testa sia 0.6.\n",
    "\n",
    "1) *Distribuzione reale dei dati:* Segue una distribuzione binomiale con 10 lanci e probabilità di successo pari a 0.6: $y \\sim \\text{Binomiale}(10, 0.6).$\n",
    "2) *Distribuzione stimata dal modello:* Il nostro modello ipotizza che la probabilità di ottenere testa sia 0.5, cioè considera la moneta come equa: $p(y \\mid \\theta) = \\text{Binomiale}(10, 0.5).$\n",
    "\n",
    "Ora procediamo al calcolo dell'ELPD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELPD del modello che stima p=0.5: -2.0549\n",
      "ELPD del modello vero (con p=0.6): -1.8536\n"
     ]
    }
   ],
   "source": [
    "# Parametri\n",
    "n = 10  # numero di lanci\n",
    "p = 0.6  # vera probabilità di testa\n",
    "q = 0.5  # probabilità stimata dal modello\n",
    "\n",
    "# Calcolo ELPD\n",
    "elpd = 0\n",
    "for y in range(n + 1):\n",
    "    # Probabilità di y secondo la vera distribuzione\n",
    "    p_y = binom.pmf(y, n, p)\n",
    "\n",
    "    # Log della densità predittiva del modello\n",
    "    log_q_y = binom.logpmf(y, n, q)\n",
    "\n",
    "    # Somma pesata\n",
    "    elpd += p_y * log_q_y\n",
    "\n",
    "print(f\"ELPD del modello che stima p=0.5: {elpd:.4f}\")\n",
    "\n",
    "# Per confronto, calcoliamo l'ELPD per il modello \"vero\"\n",
    "elpd_true = 0\n",
    "for y in range(n + 1):\n",
    "    p_y = binom.pmf(y, n, p)\n",
    "    log_p_y = binom.logpmf(y, n, p)\n",
    "    elpd_true += p_y * log_p_y\n",
    "\n",
    "print(f\"ELPD del modello vero (con p=0.6): {elpd_true:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3159c99-d64e-45a3-90a0-34ab26bdbab8",
   "metadata": {},
   "source": [
    "La conclusione è che l'ELPD del modello vero è maggiore (meno negativo) rispetto a quello del nostro modello stimato, il che riflette una capacità predittiva superiore del modello vero.\n",
    "\n",
    "Questo esempio dimostra come l'ELPD quantifica la capacità predittiva di un modello:\n",
    "\n",
    "1. Si considerano tutti i possibili risultati dell'esperimento (da 0 a 10 teste).\n",
    "2. Per ciascun risultato, si calcola:\n",
    "\n",
    "   - La probabilità di osservare quel risultato secondo la distribuzione reale.\n",
    "   - Il logaritmo della densità predittiva del modello stimato $q$ per lo stesso risultato.\n",
    "3. Si moltiplicano questi due valori e si sommano i risultati per tutti i possibili esiti.\n",
    "\n",
    "In sintesi, l'ELPD permette di confrontare l'efficacia predittiva di diversi modelli: un valore più alto (meno negativo) indica una migliore capacità del modello di prevedere i dati osservati. Nell'esempio presentato, il modello vero (con $p = 0.6$) ha un ELPD superiore rispetto al modello stimato (con $p = 0.5$), confermando che il primo ha una capacità predittiva migliore.\n",
    "\n",
    ":::\n",
    "\n",
    "## Metodi di Approssimazione per la Stima dell'ELPD\n",
    "\n",
    "Come la divergenza KL, anche il calcolo dell'ELPD richiede, in teoria, la conoscenza della vera distribuzione $P$, che è ignota. Tuttavia, a differenza della divergenza KL, disponiamo di metodi pratici per approssimare l'ELPD. Uno dei metodi più robusti e comunemente utilizzati per questa stima è la Leave-One-Out Cross-Validation (LOO-CV).\n",
    "\n",
    "### Leave-One-Out Cross-Validation (LOO-CV)\n",
    "\n",
    "Il LOO-CV è una tecnica che consente di stimare l'ELPD senza la necessità di conoscere la vera distribuzione dei dati. Questo metodo consiste nel rimuovere una singola osservazione dal dataset, adattare il modello sui dati rimanenti, e poi valutare la densità predittiva per l'osservazione esclusa. Questa procedura viene ripetuta per ogni osservazione nel dataset, e i risultati vengono sommati per ottenere una stima complessiva dell'ELPD.\n",
    "\n",
    "Procedura:\n",
    "\n",
    "1. rimuovere una singola osservazione $y_i$ dal dataset;\n",
    "2. adattare il modello ai dati rimanenti $y_{-i}$;\n",
    "3. calcolare la densità predittiva $p(y_i \\mid y_{-i})$ per l'osservazione esclusa;\n",
    "4. ripetere il processo per tutte le osservazioni e sommare i logaritmi delle densità predittive per ottenere l'ELPD.\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$ \\text{Stima dell'ELPD} = \\sum_{i=1}^{N} \\log p(y_i \\mid y_{-i}), $$\n",
    "\n",
    "dove $y_i$ è il dato escluso e $y_{-i}$ rappresenta tutti gli altri dati.\n",
    "\n",
    "Vantaggi e limitazioni:\n",
    "\n",
    "- LOO-CV fornisce una stima robusta dell'ELPD, particolarmente utile per modelli complessi e dataset di dimensioni ridotte;\n",
    "- questo metodo è computazionalmente intensivo, specialmente per dataset molto grandi o modelli complessi.\n",
    "\n",
    "### Criteri di Informazione come Approssimazioni alla Divergenza KL\n",
    "\n",
    "Oltre al LOO-CV, sono stati proposti altri metodi per approssimare l'ELPD, che derivano direttamente dal concetto di divergenza KL. Tra questi, i più noti sono i criteri di informazione, come l'errore quadratico medio (MSE), l'Akaike Information Criterion (AIC), il Bayesian Information Criterion (BIC) e il Widely Applicable Information Criterion (WAIC).\n",
    "\n",
    "Questi criteri forniscono approcci alternativi per valutare i modelli, bilanciando la bontà di adattamento del modello ai dati osservati con la sua complessità. \n",
    "\n",
    "#### Errore Quadratico Medio (MSE)\n",
    "\n",
    "L'Errore Quadratico Medio (Mean Squared Error o MSE) misura la discrepanza media tra le previsioni del modello e i valori reali.\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2, $$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $n$ è il numero totale di osservazioni,\n",
    "- $y_i$ sono i valori reali,\n",
    "- $\\hat{y}_i$ sono i valori previsti dal modello.\n",
    "\n",
    "Un MSE inferiore indica un migliore adattamento del modello ai dati.\n",
    "\n",
    "#### Criterio di Informazione di Akaike (AIC)\n",
    "\n",
    "Il Criterio di Informazione di Akaike (AIC) va oltre l'MSE, considerando sia l'adattamento del modello che la sua complessità.\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$ AIC = -2 \\sum \\log p(y_i \\mid \\hat{\\theta}_{\\text{mle}}) + 2k, $$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $\\hat{\\theta}_{\\text{mle}}$ sono i parametri stimati del modello,\n",
    "- $k$ è il numero di parametri del modello.\n",
    "\n",
    "L'AIC bilancia la bontà di adattamento (primo termine) con la complessità del modello (secondo termine). Un valore più basso di AIC indica una minor perdita di informazione, suggerendo un modello preferibile.\n",
    "\n",
    "Vantaggi e limitazioni:\n",
    "\n",
    "- facile e veloce da calcolare;\n",
    "- può essere meno accurato per campioni piccoli o modelli complessi;\n",
    "- fornisce un'approssimazione asintoticamente corretta dell'ELPD per modelli regolari e campioni grandi.\n",
    "\n",
    "#### Criterio di Informazione Bayesiano (BIC)\n",
    "\n",
    "Il Criterio di Informazione Bayesiano (BIC) è definito come:\n",
    "\n",
    "$$\n",
    "BIC = \\ln(n)k - 2\\ln(L),\n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $n$ è il numero di osservazioni,\n",
    "- $k$ è il numero di parametri del modello,\n",
    "- $L$ è il valore massimo della funzione di verosimiglianza del modello.\n",
    "\n",
    "Il termine $\\ln(L)$ rappresenta il logaritmo naturale della verosimiglianza massima, che indica quanto bene il modello si adatta ai dati osservati.\n",
    "  \n",
    "Il BIC impone una penalità maggiore per l'incremento dei parametri, rendendolo particolarmente adeguato per dataset di grandi dimensioni.\n",
    "\n",
    "#### Widely Applicable Information Criterion (WAIC)\n",
    "\n",
    "Il WAIC è una versione avanzata dell'AIC, particolarmente utile nel contesto bayesiano. Considera l'intera distribuzione a posteriori dei parametri anziché solo la stima puntuale.\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$ \n",
    "WAIC = -2\\left[ \\sum_{i=1}^{n} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta^{(s)}) \\right) - \\sum_{i=1}^{n} \\text{Var}_{\\theta^{(s)}} \\left( \\log p(y_i \\mid \\theta^{(s)}) \\right) \\right], \n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $S$ è il numero di campioni dalla distribuzione a posteriori,\n",
    "- $\\text{Var}_{\\theta^{(s)}}$ è la varianza della log-verosimiglianza.\n",
    "\n",
    "Caratteristiche del WAIC:\n",
    "\n",
    "1. calcola il logaritmo della densità predittiva per ogni punto dati;\n",
    "2. penalizza la complessità del modello basandosi sulla variabilità delle sue predizioni;\n",
    "3. la somma delle varianze a posteriori del logaritmo della densità predittiva converge al numero effettivo di parametri del modello.\n",
    "\n",
    "## Considerazioni Conclusive\n",
    "\n",
    "La valutazione dei modelli statistici è essenziale per garantire sia la loro affidabilità che la loro capacità di generalizzazione. Quando si sviluppano modelli, è fondamentale disporre di strumenti che permettano di confrontare diverse alternative e selezionare quella più adatta ai dati, garantendo al contempo previsioni accurate. In questo contesto, la divergenza di Kullback-Leibler (KL), l'Expected Log-Predictive Density (ELPD) e i criteri di informazione come AIC, BIC e WAIC offrono un quadro completo per la valutazione delle performance dei modelli.\n",
    "\n",
    "La divergenza KL rappresenta una misura ideale per quantificare la distanza tra la distribuzione di probabilità reale dei dati e quella stimata dal modello. Tuttavia, la sua applicazione pratica è limitata poiché richiede la conoscenza della distribuzione vera dei dati, che è generalmente sconosciuta. Questa limitazione rende impossibile calcolarla direttamente nella maggior parte dei casi pratici.\n",
    "\n",
    "Per superare questo ostacolo, si utilizza l'Expected Log-Predictive Density (ELPD). L'ELPD fornisce una stima della capacità predittiva del modello su nuovi dati, ovvero la sua abilità di generalizzare oltre i dati di training. Un'approssimazione particolarmente utile dell'ELPD si ottiene tramite la Leave-One-Out Cross-Validation (LOO-CV), che consiste nel rimuovere iterativamente un'osservazione dal dataset, addestrare il modello sui dati rimanenti e prevedere il valore dell'osservazione omessa. Questo processo permette di stimare accuratamente la capacità predittiva del modello su ogni singola osservazione, fornendo così un'approssimazione precisa dell'ELPD.\n",
    "\n",
    "L'ELPD e la divergenza KL sono strumenti complementari per la valutazione dei modelli statistici:\n",
    "\n",
    "1. l'ELPD misura la capacità predittiva su nuovi dati, con valori più alti che indicano previsioni migliori e una maggiore capacità di generalizzazione del modello.\n",
    "2. la divergenza KL quantifica la differenza tra la distribuzione vera dei dati e quella stimata dal modello, con valori più bassi che indicano una migliore approssimazione della distribuzione reale da parte del modello.\n",
    "\n",
    "Esiste una relazione diretta tra ELPD e divergenza KL: massimizzare l'ELPD equivale a minimizzare la divergenza KL. Entrambi gli approcci mirano a sviluppare modelli che catturino al meglio la realtà rappresentata dai dati.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "- la divergenza KL valuta l'adattamento del modello ai dati osservati, fornendo una misura di quanto il modello riesca a replicare la distribuzione reale;\n",
    "- l'ELPD e i suoi metodi di approssimazione (come LOO-CV, AIC, WAIC) misurano la capacità del modello di generalizzare su dati futuri, offrendo una valutazione più completa della qualità del modello.\n",
    "\n",
    "Anche i criteri di informazione come AIC, BIC e WAIC sono strumenti utili per approssimare la divergenza KL. Essi permettono di valutare i modelli in termini di adattamento ai dati e complessità, facilitando la selezione di un modello che bilancia precisione predittiva e parsimonia.\n",
    "\n",
    "Ciascun metodo fornisce prospettive diverse e complementari per sostituire la divergenza KL. Il LOO-CV è particolarmente utile per modelli complessi o quando si dispone di set di dati limitati, poiché offre una valutazione robusta, sebbene computazionalmente intensiva. D'altro canto, l'AIC e il WAIC sono più veloci e meno onerosi dal punto di vista computazionale, rendendoli adatti per valutazioni preliminari o quando si lavora con grandi dataset.\n",
    "\n",
    "In conclusione, la selezione del modello ottimale richiede un equilibrio tra adattamento ai dati e semplicità. L'uso combinato di tecniche di validazione incrociata e criteri di informazione permette di costruire modelli che:\n",
    "\n",
    "1. si adattano bene ai dati osservati,\n",
    "2. forniscono previsioni affidabili su nuovi dati,\n",
    "3. catturano le tendenze rilevanti senza essere eccessivamente influenzati dal rumore.\n",
    "\n",
    "L'obiettivo finale non è creare il modello più complesso o quello che si adatta perfettamente ai dati di addestramento, ma piuttosto trovare un equilibrio ottimale tra semplicità e accuratezza, garantendo che il modello sia robusto e generalizzabile a dati futuri."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c102a-4e3e-46ca-93ff-a82dd8c8361f",
   "metadata": {},
   "source": [
    "## Informazioni sull'Ambiente di Sviluppo {.unnumbered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db756413-085f-4b9c-8b14-c2b409f80046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Fri Jul 26 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.4\n",
      "IPython version      : 8.26.0\n",
      "\n",
      "arviz     : 0.18.0\n",
      "matplotlib: 3.9.1\n",
      "numpy     : 1.26.4\n",
      "scipy     : 1.14.0\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc5_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
