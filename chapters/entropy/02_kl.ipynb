{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2cfc484-08e2-402a-8845-8e54d43dc40b",
   "metadata": {},
   "source": [
    "# Divergenza KL, LPPD, ELPD e LOO-CV {#sec-kl-elpd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisiti**\n",
    "\n",
    "- Leggere il capitolo 7 *Ulysses’ Compass* di *Statistical Rethinking* (@McElreath_rethinking). \n",
    "\n",
    "**Concetti e competenze chiave**\n",
    "\n",
    "- Comprendere in modo dettagliato la distribuzione predittiva posteriore, la Divergenza di Kullback-Leibler ($\\mathbb{KL}$), il Log-Pointwise-Predictive-Density (LPPD) e la Densità Predittiva Logaritmica Attesa (ELPD).\n",
    "\n",
    "**Preparazione del Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6aa9ee-fd35-44ce-a0e5-69f1d084dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6520d11-c083-4b80-86b5-dcb07dab3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed: int = sum(map(ord, \"kl\"))\n",
    "rng: np.random.Generator = np.random.default_rng(seed=seed)\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione {.unnumbered}\n",
    "\n",
    "In questo capitolo, esamineremo in dettaglio quattro concetti fondamentali per la valutazione e il confronto di modelli statistici nel contesto bayesiano: la distribuzione predittiva posteriore, la Divergenza di Kullback-Leibler ($\\mathbb{KL}$), il Log-Pointwise-Predictive-Density (LPPD) e la Densità Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD). Questi strumenti ci permettono di quantificare l'adattamento dei modelli ai dati e la loro capacità predittiva.\n",
    "\n",
    "## Distribuzione Predittiva Posteriore\n",
    "\n",
    "La distribuzione predittiva posteriore $q(\\tilde{y} \\mid y)$ rappresenta la distribuzione dei possibili nuovi dati $\\tilde{y}$, alla luce dei dati osservati $y$. Essa si ottiene combinando:\n",
    "\n",
    "- la distribuzione del modello per i nuovi dati data una configurazione dei parametri $\\theta$: $q(\\tilde{y} \\mid \\theta)$;\n",
    "- la distribuzione posteriore dei parametri dati i dati osservati: $p(\\theta \\mid y)$.\n",
    "\n",
    "Matematicamente, la distribuzione predittiva posteriore può essere scritta come:\n",
    "\n",
    "$$\n",
    "q(\\tilde{y} \\mid y) = \\int q(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n",
    "$$\n",
    "\n",
    "Questa espressione si legge come l'integrale della distribuzione predittiva $q(\\tilde{y} \\mid \\theta)$ pesata dalla distribuzione posteriore dei parametri $p(\\theta \\mid y)$. In altre parole, stiamo \"mediando\" le previsioni del modello su tutte le possibili configurazioni dei parametri, tenendo conto della loro probabilità posteriore. La distribuzione predittiva posteriore è stata descritta nella @sec-posterior-predictive-distribution.\n",
    "\n",
    "## Divergenza di Kullback-Leibler (KL)\n",
    "\n",
    "La divergenza di Kullback-Leibler $\\mathbb{KL}(p \\parallel q)$ misura la distanza tra due distribuzioni, $p$ e $q$. È definita come:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(p \\parallel q) = \\mathbb{E}_p[\\log p(X)] - \\mathbb{E}_p[\\log q(X)].\n",
    "$$\n",
    "\n",
    "Il termine $\\mathbb{E}_p[\\log p(X)]$ è il valore atteso del logaritmo della distribuzione $p(X)$ sotto $p$ stessa, cioè:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_p[\\log p(X)] = \\sum_{i=1}^n p_i \\log p_i.\n",
    "$$\n",
    "\n",
    "Per distribuzioni continue, l'espressione diventa:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_p[\\log p(X)] = \\int p(x) \\log p(x) \\, dx.\n",
    "$$\n",
    "\n",
    "Questo termine rappresenta l'entropia negativa della distribuzione $p$.\n",
    "\n",
    "Il termine $\\mathbb{E}_p[\\log q(X)]$ è il valore atteso del logaritmo della distribuzione $q(X)$ sotto la distribuzione $p(X)$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_p[\\log q(X)] = \\sum_{i=1}^n p_i \\log q_i.\n",
    "$$\n",
    "\n",
    "Per variabili continue:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_p[\\log q(X)] = \\int p(x) \\log q(x) \\, dx.\n",
    "$$\n",
    "\n",
    "Questo rappresenta l'entropia incrociata tra $p$ e $q$.\n",
    "\n",
    "La divergenza KL è quindi:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(p \\parallel q) = \\sum_{i=1}^n p_i (\\log p_i - \\log q_i)\n",
    "$$\n",
    "\n",
    "o, in forma continua:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(p \\parallel q) = \\int p(x) (\\log p(x) - \\log q(x)) \\, dx\n",
    "$$\n",
    "\n",
    "Un punto importante è che la divergenza KL non è simmetrica, il che significa che $\\mathbb{KL}(q \\parallel q) \\neq \\mathbb{KL}(q \\parallel p)$. Questa divergenza misura quanta \"informazione\" si perde usando $q$ al posto di $p$.\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Per rendere più chiaro il concetto di divergenza KL nel caso discreto, consideriamo un esempio semplice. Immaginiamo di avere due distribuzioni di probabilità discrete, $p$ e $q$, su un insieme di eventi $\\{A, B, C\\}$. Supponiamo che le probabilità associate a ciascun evento sotto le distribuzioni $p$ e $q$ siano le seguenti:\n",
    "\n",
    "- distribuzione $p$: $p(A) = 0.5$, $p(B) = 0.3$, $p(C) = 0.2$;\n",
    "- distribuzione $q$: $q(A) = 0.4$, $q(B) = 0.4$, $q(C) = 0.2$.\n",
    "\n",
    "La divergenza KL $\\mathbb{KL}(p \\parallel q)$ è definita come:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(p \\parallel q) = \\sum_{i} p(i) \\log \\frac{p(i)}{q(i)},\n",
    "$$\n",
    "\n",
    "dove $i$ scorre su tutti gli eventi possibili $\\{A, B, C\\}$. Quindi, dobbiamo calcolare  $p(A) \\log \\frac{p(A)}{q(A)}$,  $p(B) \\log \\frac{p(B)}{q(B)}$ e  $p(C) \\log \\frac{p(C)}{q(C)}$, ovvero,\n",
    "\n",
    "   $$\n",
    "   p(A) \\log \\frac{p(A)}{q(A)} = 0.5 \\log \\frac{0.5}{0.4} 0.11155,\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   p(B) \\log \\frac{p(B)}{q(B)} = 0.3 \\log \\frac{0.3}{0.4} = -0.08631,\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   p(C) \\log \\frac{p(C)}{q(C)} = 0.2 \\log \\frac{0.2}{0.2} = 0.\n",
    "   $$\n",
    "\n",
    "Ora sommiamo tutti i termini:\n",
    "\n",
    "$$\n",
    "\\mathbb{KL}(p \\parallel q) = 0.11155 + (-0.08631) + 0 = 0.02524.\n",
    "$$\n",
    "\n",
    "La divergenza KL $\\mathbb{KL}(p \\parallel q) \\approx 0.025$ indica che la distribuzione $q$ non è troppo lontana dalla distribuzione $p$, ma c'è una piccola discrepanza tra le due. Se il valore fosse maggiore, significherebbe che la distribuzione $q$ si discosta maggiormente da $p$, indicando una maggiore perdita di informazione se si usa $q$ al posto di $p$.\n",
    "\n",
    ":::\n",
    "\n",
    "### Problema con $p$ sconosciuto\n",
    "\n",
    "Il problema è che in pratica non conosciamo $p$, la \"verità\" sottostante. Se conoscessimo $p$, non avremmo bisogno di fare inferenza statistica. Tuttavia, vogliamo comunque confrontare diversi modelli $q$ e $r$ per capire quale si avvicina di più a $p$.\n",
    "\n",
    "### L'idea della divergenza relativa\n",
    "\n",
    "Fortunatamente, per confrontare due modelli $q$ e $r$, non è necessario conoscere $p$ esattamente. Possiamo confrontare i modelli in termini di divergenza relativa da $p$. In pratica, molte delle componenti di $p$ si annullano quando confrontiamo $q$ e $r$, perché la differenza tra le divergenze $\\mathbb{KL}(p \\parallel q)$ e $\\mathbb{KL}(p \\parallel r)$ non dipende da $p$ in sé, ma solo dalla differenza tra $q$ e $r$.\n",
    "\n",
    "### Log-Probability Score (Log-Score)\n",
    "\n",
    "Il *log-probability score* (o *log-score*) è una misura pratica che possiamo usare per valutare modelli in assenza della conoscenza di $p$. Per ogni modello $q$, si calcola:\n",
    "\n",
    "$$\n",
    "S(q) = \\sum_{i} \\log(q_i).\n",
    "$$\n",
    "\n",
    "Questo score rappresenta una stima di $\\mathbb{E}[\\log(q_i)]$, ovvero dell'aspettativa del logaritmo delle probabilità predette dal modello $q$ rispetto ai dati osservati. Più alto è il log-score, migliore è il modello in termini di accuratezza predittiva.\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Consideriamo un semplice esempio numerico per illustrare il calcolo del *log-probability score* (o *log-score*) per un modello $q$. Immaginiamo di avere un piccolo dataset con 3 osservazioni, e che il modello $q$ predica le probabilità per ciascuna osservazione come segue:\n",
    "\n",
    "- Osservazione 1: $q_1 = 0.8$,\n",
    "- Osservazione 2: $q_2 = 0.6$,\n",
    "- Osservazione 3: $q_3 = 0.7$.\n",
    "\n",
    "Il *log-score* si calcola sommando i logaritmi delle probabilità predette:\n",
    "\n",
    "$$\n",
    "S(q) = \\log(0.8) + \\log(0.6) + \\log(0.7) \\approx -0.2231 + (-0.5108) + (-0.3567) = -1.0906.\n",
    "$$\n",
    "\n",
    "Il log-score totale per questo modello $q$ è $-1.0906$. Poiché un log-score più alto (meno negativo) indica una migliore accuratezza predittiva, questo risultato suggerisce che $q$ ha una discreta accuratezza per le osservazioni date. Un modello $r$ con un log-score più alto sarebbe preferibile in termini di accuratezza predittiva rispetto a $q$.\n",
    "\n",
    ":::\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Per chiarire ulteriormente il concetto di *log-probability score*, possiamo applicarlo al caso di un modello di regressione. In questo contesto, il calcolo del *log-probability score* implica la valutazione della probabilità che il modello assegna a ciascuna osservazione, considerando la distribuzione degli errori associata al modello.\n",
    "\n",
    "Consideriamo un modello di regressione lineare semplice:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i,\n",
    "$$\n",
    "\n",
    "dove $y_i$ è la variabile dipendente, $x_i$ è la variabile indipendente, $\\beta_0$ e $\\beta_1$ sono i coefficienti del modello, e $\\epsilon_i$ è l'errore, tipicamente assunto come distribuito secondo una normale $\\mathcal{N}(0, \\sigma^2)$.\n",
    "\n",
    "Per calcolare la probabilità di ciascuna osservazione $y_i$ data la predizione del modello, usiamo la distribuzione degli errori. Se $y_i$ è distribuito secondo una normale con media $\\hat{y}_i = \\beta_0 + \\beta_1 x_i$ e varianza $\\sigma^2$, allora la probabilità di osservare $y_i$ è:\n",
    "\n",
    "$$\n",
    "p(y_i \\mid x_i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\hat{y}_i)^2}{2\\sigma^2}\\right).\n",
    "$$\n",
    "\n",
    "Il *log-score* per ciascuna osservazione è il logaritmo della probabilità predetta:\n",
    "\n",
    "$$\n",
    "\\log p(y_i \\mid x_i) = -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\hat{y}_i)^2}{2\\sigma^2}.\n",
    "$$\n",
    "\n",
    "Il log-score totale del modello è la somma dei log-score su tutte le osservazioni:\n",
    "\n",
    "$$\n",
    "S(q) = \\sum_{i=1}^n \\log p(y_i \\mid x_i) = -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2.\n",
    "$$\n",
    "\n",
    "- *Primo termine*: $-\\frac{n}{2} \\log(2\\pi\\sigma^2)$ è una costante che dipende dal numero di osservazioni $n$ e dalla varianza degli errori $\\sigma^2$.\n",
    "- *Secondo termine*: $-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ è proporzionale alla somma dei quadrati degli errori (SSE), che misura quanto le predizioni si discostano dai valori osservati.\n",
    "\n",
    "Il log-score fornisce quindi una misura dell'accuratezza del modello di regressione, con valori più alti (meno negativi) che indicano un modello migliore. In pratica, poiché il primo termine è una costante, la differenza nei log-score tra modelli diversi sarà determinata principalmente dal secondo termine, legato alla SSE.\n",
    "\n",
    "In sintesi, nel contesto di un modello di regressione, la probabilità di ciascuna osservazione si basa sulla distribuzione normale degli errori, e il log-score riflette quanto bene il modello predice i dati osservati, penalizzando modelli con errori più grandi.\n",
    "\n",
    ":::\n",
    "\n",
    "### Log-Pointwise-Predictive-Density (LPPD)\n",
    "\n",
    "Il *Log-Pointwise-Predictive-Density* (LPPD) è una versione bayesiana del log-score, che tiene conto dell'incertezza sui parametri del modello. In un contesto bayesiano, non abbiamo un solo set di parametri $\\theta_s$, ma una distribuzione posteriore su di essi. Pertanto, il log-score viene calcolato come una media logaritmica su questa distribuzione. Il LPPD è una misura che deriva direttamente dalla distribuzione predittiva posteriore e rappresenta la somma delle densità predittive logaritmiche calcolate per ogni osservazione, mediate sulla distribuzione posteriore dei parametri. Formalmente, si definisce come:\n",
    "\n",
    "$$\n",
    "\\text{LPPD} = \\sum_{i=1}^n \\log \\left(\\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta_s)\\right),\n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $y_i$ è l'i-esima osservazione,\n",
    "- $S$ è il numero di campioni dalla distribuzione posteriore,\n",
    "- $\\theta_s$ è un campione di parametri dalla distribuzione posteriore.\n",
    "\n",
    "Il LPPD tiene conto dell'incertezza nei parametri, calcolando il logaritmo della densità predittiva media per ogni punto dati, mediata su tutte le possibili configurazioni dei parametri posteriore. Questo approccio è fondamentale per catturare la reale capacità predittiva di un modello, tenendo conto della variabilità nei parametri.\n",
    "\n",
    "In conclusione, il log-score e il LPPD sono metodi per stimare la bontà di un modello rispetto ai dati osservati, senza richiedere la conoscenza esatta di $p$. Anche se non possiamo calcolare direttamente la divergenza di KL perché $p$ è sconosciuto, possiamo comunque confrontare diversi modelli basandoci su queste misure. La differenza tra i log-score (o LPPD) di due modelli $q$ e $r$ ci dà un'informazione su quale modello è \"più vicino\" alla verità, analogamente a come useremmo la divergenza di KL se conoscessimo $p$.\n",
    "\n",
    "## Expected Log Predictive Density (ELPD)\n",
    "\n",
    "L'*Expected Log Predictive Density* (ELPD) è una misura che valuta la capacità predittiva di un modello utilizzando la tecnica della cross-validation. Si definisce come:\n",
    "\n",
    "$$\n",
    "\\text{ELPD} = \\sum_{i=1}^n \\log p(y_i \\mid \\mathbf{y}_{-i}),\n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $y_i$ è l'i-esima osservazione,\n",
    "- $\\mathbf{y}_{-i}$ rappresenta tutte le osservazioni eccetto $y_i$.\n",
    "\n",
    "L'ELPD utilizza la *Leave-One-Out Cross-Validation* (LOO-CV) per stimare la densità predittiva logaritmica di ogni osservazione, escludendo quella stessa osservazione dal training. Questo metodo permette di evitare l'overfitting, valutando la performance del modello su dati non visti.\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Per illustrare il calcolo dell'ELPD, vediamo un esempio semplice con un set di dati molto piccolo. Supponiamo di avere un dataset di tre osservazioni: $y_1, y_2, y_3$. Supponiamo che il nostro modello stimi le probabilità per ciascuna osservazione in base a tutte le altre osservazioni, cioè utilizziamo la leave-one-out cross-validation (LOO-CV) per calcolare $p(y_i \\mid \\mathbf{y}_{-i})$.\n",
    "\n",
    "Immaginiamo che il modello produca le seguenti probabilità condizionali per ogni osservazione $y_i$:\n",
    "\n",
    "- $p(y_1 \\mid y_2, y_3) = 0.6$,\n",
    "- $p(y_2 \\mid y_1, y_3) = 0.7$,\n",
    "- $p(y_3 \\mid y_1, y_2) = 0.5$.\n",
    "\n",
    "L'ELPD si calcola sommando i logaritmi di queste probabilità:\n",
    "\n",
    "$$\n",
    "\\text{ELPD} = \\log p(y_1 \\mid y_2, y_3) + \\log p(y_2 \\mid y_1, y_3) + \\log p(y_3 \\mid y_1, y_2).\n",
    "$$\n",
    "\n",
    "Calcoliamo i logaritmi naturali di ciascuna probabilità:\n",
    "\n",
    "- $\\log p(y_1 \\mid y_2, y_3) = \\log 0.6 \\approx -0.5108$,\n",
    "- $\\log p(y_2 \\mid y_1, y_3) = \\log 0.7 \\approx -0.3567$,\n",
    "- $\\log p(y_3 \\mid y_1, y_2) = \\log 0.5 \\approx -0.6931$.\n",
    "\n",
    "Sommiamo i logaritmi per ottenere l'ELPD:\n",
    "\n",
    "$$\n",
    "\\text{ELPD} = -0.5108 + (-0.3567) + (-0.6931) = -1.5606.\n",
    "$$\n",
    "\n",
    "L'ELPD ottenuto è $-1.5606$. In generale, valori più vicini a 0 o positivi indicano una migliore capacità predittiva del modello, poiché suggeriscono che le probabilità condizionali assegnate dal modello alle osservazioni lasciate fuori non sono troppo basse. Valori molto negativi indicherebbero che il modello ha assegnato probabilità molto basse alle osservazioni effettivamente osservate, suggerendo una scarsa capacità predittiva. L'ELPD è un modo efficace per valutare quanto bene un modello generalizza a nuovi dati, evitando l'overfitting.\n",
    "\n",
    ":::\n",
    "\n",
    "## Collegamento tra Divergenza KL e ELPD\n",
    "\n",
    "Entrambe le misure (Divergenza KL e ELPD) valutano la qualità del modello, ma da prospettive diverse:\n",
    "\n",
    "- la divergenza KL misura quanto la distribuzione predittiva del modello $Q$ si avvicina alla \"vera\" distribuzione $P$;\n",
    "- l'ELPD valuta direttamente la capacità del modello di prevedere nuovi dati, utilizzando la tecnica leave-one-out.\n",
    "\n",
    "L'ELPD tende a favorire modelli che non solo si adattano bene ai dati osservati, ma che sono anche robusti rispetto all'overfitting, grazie alla sua enfasi sulla capacità predittiva su dati non osservati.\n",
    "\n",
    "In sintesi, la distribuzione predittiva posteriori, la divergenza di Kullback-Leibler e l'ELPD sono strumenti matematici che ci permettono di valutare la bontà di un modello statistico. La divergenza KL fornisce una misura teoricamente ideale di quanto un modello approssima la vera distribuzione dei dati, mentre l'ELPD offre un'alternativa praticabile che valuta la capacità del modello di fare previsioni su nuovi dati. Questi concetti sono fondamentali nell'inferenza bayesiana, dove è importante non solo adattarsi ai dati esistenti, ma anche generalizzare bene su dati futuri.\n",
    "\n",
    "::: {#exm-}\n",
    "\n",
    "Consideriamo un secondo esempio per illustrare il concetto di ELPD utilizzando la distribuzione binomiale. Immaginiamo di condurre un esperimento in cui lanciamo una moneta 10 volte e contiamo il numero di volte in cui otteniamo testa. Supponiamo che la vera probabilità di ottenere testa sia 0.6.\n",
    "\n",
    "1) *Distribuzione reale dei dati:* Segue una distribuzione binomiale con 10 lanci e probabilità di successo pari a 0.6: $y \\sim \\text{Binomiale}(10, 0.6).$\n",
    "2) *Distribuzione stimata dal modello:* Il nostro modello ipotizza che la probabilità di ottenere testa sia 0.5, cioè considera la moneta come equa: $p(y \\mid \\theta) = \\text{Binomiale}(10, 0.5).$\n",
    "\n",
    "Ora procediamo al calcolo dell'ELPD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELPD del modello che stima p=0.5: -2.0549\n",
      "ELPD del modello vero (con p=0.6): -1.8536\n"
     ]
    }
   ],
   "source": [
    "# Parametri\n",
    "n = 10  # numero di lanci\n",
    "p = 0.6  # vera probabilità di testa\n",
    "q = 0.5  # probabilità stimata dal modello\n",
    "\n",
    "# Calcolo ELPD\n",
    "elpd = 0\n",
    "for y in range(n + 1):\n",
    "    # Probabilità di y secondo la vera distribuzione\n",
    "    p_y = binom.pmf(y, n, p)\n",
    "\n",
    "    # Log della densità predittiva del modello\n",
    "    log_q_y = binom.logpmf(y, n, q)\n",
    "\n",
    "    # Somma pesata\n",
    "    elpd += p_y * log_q_y\n",
    "\n",
    "print(f\"ELPD del modello che stima p=0.5: {elpd:.4f}\")\n",
    "\n",
    "# Per confronto, calcoliamo l'ELPD per il modello \"vero\"\n",
    "elpd_true = 0\n",
    "for y in range(n + 1):\n",
    "    p_y = binom.pmf(y, n, p)\n",
    "    log_p_y = binom.logpmf(y, n, p)\n",
    "    elpd_true += p_y * log_p_y\n",
    "\n",
    "print(f\"ELPD del modello vero (con p=0.6): {elpd_true:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3159c99-d64e-45a3-90a0-34ab26bdbab8",
   "metadata": {},
   "source": [
    "La conclusione è che l'ELPD del modello vero è maggiore (meno negativo) rispetto a quello del nostro modello stimato, il che riflette una capacità predittiva superiore del modello vero.\n",
    "\n",
    "Questo esempio dimostra come l'ELPD quantifica la capacità predittiva di un modello:\n",
    "\n",
    "1. Si considerano tutti i possibili risultati dell'esperimento (da 0 a 10 teste).\n",
    "2. Per ciascun risultato, si calcola:\n",
    "\n",
    "   - La probabilità di osservare quel risultato secondo la distribuzione reale.\n",
    "   - Il logaritmo della densità predittiva del modello stimato $q$ per lo stesso risultato.\n",
    "3. Si moltiplicano questi due valori e si sommano i risultati per tutti i possibili esiti.\n",
    "\n",
    "In sintesi, l'ELPD permette di confrontare l'efficacia predittiva di diversi modelli: un valore più alto (meno negativo) indica una migliore capacità del modello di prevedere i dati osservati. Nell'esempio presentato, il modello vero (con $p = 0.6$) ha un ELPD superiore rispetto al modello stimato (con $p = 0.5$), confermando che il primo ha una capacità predittiva migliore.\n",
    "\n",
    ":::\n",
    "\n",
    "### Collegamento tra LPPD e ELPD\n",
    "\n",
    "Il LPPD e l'ELPD sono strettamente collegati e forniscono una valutazione robusta della capacità predittiva di un modello statistico. Il LPPD fornisce una stima del log-score basata sull'intera distribuzione posteriore dei parametri, mentre l'ELPD utilizza la cross-validation per stimare la capacità predittiva del modello su nuovi dati.\n",
    "\n",
    "Sebbene il LPPD sia una buona misura, esso tende a migliorare con l'aumentare della complessità del modello, a causa del fenomeno dell'overfitting. Il modello, infatti, potrebbe adattarsi perfettamente ai dati di addestramento, ma non generalizzare bene ai nuovi dati, catturando il \"rumore\" presente nei dati piuttosto che il vero segnale sottostante.\n",
    "\n",
    "### Leave-One-Out Cross-Validation (LOO-CV)\n",
    "\n",
    "La *cross-validation*, in particolare la *Leave-One-Out Cross-Validation (LOO-CV)*, è una tecnica per affrontare questo problema. La LOO-CV valuta un modello lasciando fuori una sola osservazione dal dataset, addestrando il modello sul resto dei dati e poi testandolo sull'osservazione esclusa. Questo processo viene ripetuto per ogni osservazione nel dataset, e il risultato finale è una media delle prestazioni del modello su tutte le osservazioni lasciate fuori.\n",
    "\n",
    "Come la divergenza KL, anche il calcolo dell'ELPD richiede, in teoria, la conoscenza della vera distribuzione $p$, che è ignota. Tuttavia, a differenza della divergenza KL, disponiamo di metodi pratici per approssimare l'ELPD senza la necessità di conoscere la vera distribuzione dei dati. Uno dei metodi più robusti e comunemente utilizzati per questa stima è la Leave-One-Out Cross-Validation (LOO-CV). Questo metodo consiste nel rimuovere una singola osservazione dal dataset, adattare il modello sui dati rimanenti, e poi valutare la densità predittiva per l'osservazione esclusa. Questa procedura viene ripetuta per ogni osservazione, e i risultati vengono sommati per ottenere una stima complessiva dell'ELPD.\n",
    "\n",
    "La LOO-CV è considerata uno dei metodi migliori per la selezione del modello perché fornisce una stima dell'accuratezza predittiva del modello su dati che non sono stati utilizzati per addestrarlo. Questo approccio riduce il rischio di overfitting, poiché misura come il modello si comporta su dati effettivamente \"nuovi\".\n",
    "\n",
    "Quindi, sebbene il log-probability score sia una buona misura, il suo miglioramento con l'aumentare della complessità del modello può essere mitigato utilizzando tecniche di cross-validation, come la LOO-CV. Questo metodo fornisce una stima accurata della performance del modello su dati non visti, evitando così il problema dell'overfitting.\n",
    "\n",
    "### Criteri di Informazione come Approssimazioni alla Divergenza KL\n",
    "\n",
    "Oltre al LOO-CV, sono stati proposti altri metodi per approssimare l'ELPD, che derivano direttamente dal concetto di divergenza KL. Tra questi, i più noti sono i criteri di informazione, come l'errore quadratico medio (MSE), l'Akaike Information Criterion (AIC), il Bayesian Information Criterion (BIC) e il Widely Applicable Information Criterion (WAIC). Questi criteri forniscono approcci alternativi per valutare i modelli, bilanciando la bontà di adattamento del modello ai dati osservati con la sua complessità.\n",
    "\n",
    "#### Errore Quadratico Medio (MSE)\n",
    "\n",
    "L'Errore Quadratico Medio (Mean Squared Error o MSE) misura la discrepanza media tra le previsioni del modello e i valori reali:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2, $$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $n$ è il numero totale di osservazioni,\n",
    "- $y_i$ sono i valori reali,\n",
    "- $\\hat{y}_i$ sono i valori previsti dal modello.\n",
    "\n",
    "Un MSE inferiore indica un migliore adattamento del modello ai dati.\n",
    "\n",
    "#### Criterio di Informazione di Akaike (AIC)\n",
    "\n",
    "Il Criterio di Informazione di Akaike (AIC) va oltre l'MSE, considerando sia l'adattamento del modello che la sua complessità:\n",
    "\n",
    "$$ AIC = -2 \\sum \\log p(y_i \\mid \\hat{\\theta}_{\\text{mle}}) + 2k, $$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $\\hat{\\theta}_{\\text{mle}}$ sono i parametri stimati del modello,\n",
    "- $k$ è il numero di parametri del modello.\n",
    "\n",
    "L'AIC bilancia la bontà di adattamento (primo termine) con la complessità del modello (secondo termine). Un valore più basso di AIC indica una minor perdita di informazione, suggerendo un modello preferibile.\n",
    "\n",
    "Vantaggi e limitazioni:\n",
    "\n",
    "- facile e veloce da calcolare;\n",
    "- può essere meno accurato per campioni piccoli o modelli complessi;\n",
    "- fornisce un'approssimazione asintoticamente corretta dell'ELPD per modelli regolari e campioni grandi.\n",
    "\n",
    "#### Criterio di Informazione Bayesiano (BIC)\n",
    "\n",
    "Il Criterio di Informazione Bayesiano (BIC) è definito come:\n",
    "\n",
    "$$\n",
    "BIC = \\ln(n)k - 2\\ln(L),\n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $n$ è il numero di osservazioni,\n",
    "- $k$ è il numero di parametri del modello,\n",
    "- $L$ è il valore massimo della funzione di verosimiglianza del modello.\n",
    "\n",
    "Il termine $\\ln(L)$ rappresenta il logaritmo naturale della verosimiglianza massima, che indica quanto bene il modello si adatta ai dati osservati.\n",
    "  \n",
    "Il BIC impone una penalità maggiore per l'incremento dei parametri, rendendolo particolarmente adeguato per dataset di grandi dimensioni.\n",
    "\n",
    "#### Widely Applicable Information Criterion (WAIC)\n",
    "\n",
    "Il WAIC è una versione avanzata dell'AIC, particolarmente utile nel contesto bayesiano. Considera l'intera distribuzione a posteriori dei parametri anziché solo la stima puntuale:\n",
    "\n",
    "$$ \n",
    "WAIC = -2\\left[ \\sum_{i=1}^{n} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta^{(s)}) \\right) - \\sum_{i=1}^{n} \\text{Var}_{\\theta^{(s)}} \\left( \\log p(y_i \\mid \\theta^{(s)}) \\right) \\right], \n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "- $S$ è il numero di campioni dalla distribuzione a posteriori,\n",
    "- $\\text{Var}_{\\theta^{(s)}}$ è la varianza della log-verosimiglianza.\n",
    "\n",
    "Caratteristiche del WAIC:\n",
    "\n",
    "1. calcola il logaritmo della densità predittiva per ogni punto dati;\n",
    "2. penalizza la complessità del modello basandosi sulla variabilità delle sue predizioni;\n",
    "3. la somma delle varianze a posteriori del logaritmo della densità predittiva converge al numero effettivo di parametri del modello.\n",
    "\n",
    "## Considerazioni Conclusive\n",
    "\n",
    "La valutazione dei modelli statistici è fondamentale per garantirne l'affidabilità e la capacità di generalizzazione. Quando si sviluppano modelli, è essenziale disporre di strumenti che permettano di confrontare diverse alternative e selezionare quella più adatta ai dati, assicurando previsioni accurate.\n",
    "\n",
    "Il LPPD (Log Pointwise Predictive Density) e l'ELPD (Expected Log Pointwise Predictive Density) sono due importanti strumenti per la valutazione dei modelli statistici in ambito bayesiano. Sebbene la divergenza KL (Kullback-Leibler) rappresenti una misura ideale per quantificare la distanza tra la distribuzione di probabilità reale dei dati e quella stimata dal modello, la sua applicazione pratica è limitata in quanto richiede la conoscenza della distribuzione vera dei dati, che è generalmente sconosciuta.\n",
    "\n",
    "A differenza della divergenza KL, il LPPD offre un approccio praticabile per valutare la capacità predittiva dei modelli. Tuttavia, il LPPD soffre del problema dell'overfitting. Per superare questo ostacolo, si utilizza l'ELPD, che stima la capacità predittiva del modello su nuovi dati, ovvero la sua abilità di generalizzare oltre i dati di addestramento.\n",
    "\n",
    "L'ELPD e la divergenza KL sono pertanto strumenti complementari per la valutazione dei modelli statistici. L'ELPD misura la capacità predittiva su nuovi dati, con valori più alti che indicano previsioni migliori e una maggiore capacità di generalizzazione. La divergenza KL, invece, quantifica la differenza tra la distribuzione vera dei dati e quella stimata dal modello, con valori più bassi che indicano una migliore approssimazione della distribuzione reale da parte del modello.\n",
    "\n",
    "Esiste una relazione diretta tra ELPD e divergenza KL: massimizzare l'ELPD equivale a minimizzare la divergenza KL. Entrambi gli approcci mirano a sviluppare modelli in grado di catturare al meglio la realtà rappresentata dai dati.\n",
    "\n",
    "In pratica, la divergenza KL valuta l'adattamento del modello ai dati osservati, mentre l'ELPD e i suoi metodi di approssimazione (come LOO-CV) misurano la capacità del modello di generalizzare su dati futuri, offrendo una valutazione più completa della qualità del modello.\n",
    "\n",
    "La selezione del modello ottimale richiede quindi un equilibrio tra adattamento ai dati e semplicità. L'uso combinato di tecniche di validazione incrociata (come il LOO-CV) e criteri di informazione (come AIC, BIC e WAIC) permette di costruire modelli che si adattano bene ai dati osservati, forniscono previsioni affidabili su nuovi dati e catturano le tendenze rilevanti senza essere eccessivamente influenzati dal rumore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c102a-4e3e-46ca-93ff-a82dd8c8361f",
   "metadata": {},
   "source": [
    "## Informazioni sull'Ambiente di Sviluppo {.unnumbered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db756413-085f-4b9c-8b14-c2b409f80046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Fri Jul 26 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.4\n",
      "IPython version      : 8.26.0\n",
      "\n",
      "arviz     : 0.18.0\n",
      "matplotlib: 3.9.1\n",
      "numpy     : 1.26.4\n",
      "scipy     : 1.14.0\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc5_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
