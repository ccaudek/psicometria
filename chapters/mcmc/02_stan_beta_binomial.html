<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Corrado Caudek">

<title>Data Science per Psicologi - 44&nbsp; Linguaggio Stan</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/mcmc/03_stan_summary_posterior.html" rel="next">
<link href="../../chapters/mcmc/01_metropolis.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/mcmc/introduction_mcmc.html">MCMC</a></li><li class="breadcrumb-item"><a href="../../chapters/mcmc/02_stan_beta_binomial.html"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Data Science per Psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/introduction_python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/00_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/01_python_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Python (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/02_python_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/03_numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/04_pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Pandas (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/05_pandas_aggregate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Pandas (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/06_pandas_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pandas (3)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/07_matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/08_seaborn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Seaborn</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">L’analisi dei dati psicologici</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_data_cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Flusso di lavoro per la pulizia dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/03_freq_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/06_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Misura di Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_on_general_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_density_func.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">La funzione di densità di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Simulazioni</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modellazione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02a_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/06_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Modello Esponenziale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Monte Carlo a Catena di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_stan_beta_binomial.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/03_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/04_stan_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/05_stan_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/06_stan_odds_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Analisi bayesiana dell’odds-ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_stan_normal_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/08_stan_two_groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/09_stan_poisson_model_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Modello di Poisson (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/10_stan_poisson_model_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Modello di Poisson (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/11_stan_gaussian_mixture.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modelli Mistura Gaussiani</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/12_stan_nuisance_parameters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Modelli con più di un parametro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/13_stan_hier_beta_binom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Modello gerarchico beta-binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/14_stan_categorical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Modello categoriale</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_beauty_sex_power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Bellezza, sesso e potere</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Predizione e inferenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Disegno della ricerca e potere statistico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Disegno della ricerca e potere statistico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_linear_algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Elementi di algebra lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_stan_multreg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Il modello di regressione multipla</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_hier_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Il modello lineare gerarchico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_stan_mixed_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Modelli misti con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_specification_error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Errore di specificazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/12_causal_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">Inferenza causale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/13_interactions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Interazioni statistiche</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/14_ate_att_atu.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Concetti di ATE, ATT e ATU</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/15_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Dati mancanti</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false">
 <span class="menu-text">GLM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/introduction_glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/01_robust_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Regressione robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/02_stan_binomial_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Regressione binomiale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/03_stan_logistic_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/04_stan_poisson_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Regressione di Poisson con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/05_simchon_2023.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Tweets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/06_stan_rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Incorporare dati storici di controllo in una RCT</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/07_stan_mediation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Modello di mediazione con Stan</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="false">
 <span class="menu-text">Entropia</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/introduction_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/01_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/02_kl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Divergenza KL, LPPD, ELPD e LOO-CV</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/03_loo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Validazione Incrociata Leave-One-Out</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/04_cognitive_modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Dall’analisi descrittiva alla modellazione cognitiva</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/05_inductive_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza induttiva</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false">
 <span class="menu-text">Dinamiche</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/introduction_dynamic_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/01_canoeing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Dinamiche post-errore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/02_change_across_time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Modellare il cambiamento nel tempo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/03_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/04_affect.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Le emozioni influenzano le emozioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/05_sequential_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">Analisi dinamica delle sequenze di apprendimento</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false">
 <span class="menu-text">Modelli cognitivi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cognitive_models/introduction_cognitive_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cognitive_models/01_ddm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">Drift Diffusion Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">Introduzione all’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Intervallo di confidenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">La Crisi della Replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">96</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">97</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">98</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">99</span>&nbsp; <span class="chapter-title">Proposte di cambiamento</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">100</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../99-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" aria-expanded="false">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a00_installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Ambiente di lavoro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01_markdown.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a03_colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Colab: un breve tutorial</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a04_virtual_env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Ambienti virtuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a20_kde_plot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Kernel Density Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a30_prob_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">M</span>&nbsp; <span class="chapter-title">Esercizi di probabilità discreta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a40_rng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">N</span>&nbsp; <span class="chapter-title">Generazione di numeri casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a44_montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">O</span>&nbsp; <span class="chapter-title">Simulazione Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a46_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">P</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a47_first_order_markov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Q</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">R</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a51_r_squared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">S</span>&nbsp; <span class="chapter-title">Teorema della scomposizione della devianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a55_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">T</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a60_ttest_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">U</span>&nbsp; <span class="chapter-title">Esercizi sull’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a70_predict_counts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">V</span>&nbsp; <span class="chapter-title">La predizione delle frequenze</span></span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" aria-expanded="false">
 <span class="menu-text">Soluzioni degli esercizi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">W</span>&nbsp; <span class="chapter-title">Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">X</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Y</span>&nbsp; <span class="chapter-title">Causalità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_mult_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Z</span>&nbsp; <span class="chapter-title">Regressione multipla</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">\</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">]</span>&nbsp; <span class="chapter-title">Crisi della replicazione</span></span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">44.1</span> Introduzione</a></li>
  <li><a href="#stan-e-la-programmazione-probabilistica" id="toc-stan-e-la-programmazione-probabilistica" class="nav-link" data-scroll-target="#stan-e-la-programmazione-probabilistica"><span class="header-section-number">44.2</span> Stan e la Programmazione Probabilistica</a>
  <ul class="collapse">
  <li><a href="#struttura-di-un-programma-stan" id="toc-struttura-di-un-programma-stan" class="nav-link" data-scroll-target="#struttura-di-un-programma-stan"><span class="header-section-number">44.2.1</span> Struttura di un Programma Stan</a></li>
  <li><a href="#esecuzione-di-un-programma-stan" id="toc-esecuzione-di-un-programma-stan" class="nav-link" data-scroll-target="#esecuzione-di-un-programma-stan"><span class="header-section-number">44.2.2</span> Esecuzione di un Programma Stan</a></li>
  </ul></li>
  <li><a href="#simulazione-in-avanti" id="toc-simulazione-in-avanti" class="nav-link" data-scroll-target="#simulazione-in-avanti"><span class="header-section-number">44.3</span> Simulazione in Avanti</a>
  <ul class="collapse">
  <li><a href="#un-primo-programma-in-stan-generazione-di-dati-casuali" id="toc-un-primo-programma-in-stan-generazione-di-dati-casuali" class="nav-link" data-scroll-target="#un-primo-programma-in-stan-generazione-di-dati-casuali"><span class="header-section-number">44.3.1</span> Un Primo Programma in Stan: Generazione di Dati Casuali</a></li>
  <li><a href="#organizzazione-di-un-programma-stan" id="toc-organizzazione-di-un-programma-stan" class="nav-link" data-scroll-target="#organizzazione-di-un-programma-stan"><span class="header-section-number">44.3.2</span> Organizzazione di un Programma Stan</a></li>
  <li><a href="#tipi-di-variabili-in-stan" id="toc-tipi-di-variabili-in-stan" class="nav-link" data-scroll-target="#tipi-di-variabili-in-stan"><span class="header-section-number">44.3.3</span> Tipi di Variabili in Stan</a></li>
  <li><a href="#vincoli-sui-tipi" id="toc-vincoli-sui-tipi" class="nav-link" data-scroll-target="#vincoli-sui-tipi"><span class="header-section-number">44.3.4</span> Vincoli sui Tipi</a></li>
  <li><a href="#esecuzione-del-programma-stan" id="toc-esecuzione-del-programma-stan" class="nav-link" data-scroll-target="#esecuzione-del-programma-stan"><span class="header-section-number">44.3.5</span> Esecuzione del Programma Stan</a></li>
  <li><a href="#estrazione-dei-risultati" id="toc-estrazione-dei-risultati" class="nav-link" data-scroll-target="#estrazione-dei-risultati"><span class="header-section-number">44.3.6</span> Estrazione dei Risultati</a></li>
  </ul></li>
  <li><a href="#il-problema-inverso" id="toc-il-problema-inverso" class="nav-link" data-scroll-target="#il-problema-inverso"><span class="header-section-number">44.4</span> Il Problema Inverso</a>
  <ul class="collapse">
  <li><a href="#campionare-dalla-distribuzione-a-posteriori" id="toc-campionare-dalla-distribuzione-a-posteriori" class="nav-link" data-scroll-target="#campionare-dalla-distribuzione-a-posteriori"><span class="header-section-number">44.4.1</span> Campionare dalla Distribuzione a Posteriori</a></li>
  <li><a href="#compilazione-del-codice-stan" id="toc-compilazione-del-codice-stan" class="nav-link" data-scroll-target="#compilazione-del-codice-stan"><span class="header-section-number">44.4.2</span> Compilazione del Codice Stan</a></li>
  </ul></li>
  <li><a href="#stime-puntuali-bayesiane" id="toc-stime-puntuali-bayesiane" class="nav-link" data-scroll-target="#stime-puntuali-bayesiane"><span class="header-section-number">44.5</span> Stime Puntuali Bayesiane</a>
  <ul class="collapse">
  <li><a href="#stimatore-della-media-posteriori" id="toc-stimatore-della-media-posteriori" class="nav-link" data-scroll-target="#stimatore-della-media-posteriori"><span class="header-section-number">44.5.1</span> Stimatore della Media Posteriori</a></li>
  <li><a href="#stimatore-della-mediana-posteriori-quantili-e-intervalli" id="toc-stimatore-della-mediana-posteriori-quantili-e-intervalli" class="nav-link" data-scroll-target="#stimatore-della-mediana-posteriori-quantili-e-intervalli"><span class="header-section-number">44.5.2</span> Stimatore della Mediana Posteriori, Quantili e Intervalli</a></li>
  <li><a href="#quantili-e-intervalli-di-credibilità" id="toc-quantili-e-intervalli-di-credibilità" class="nav-link" data-scroll-target="#quantili-e-intervalli-di-credibilità"><span class="header-section-number">44.5.3</span> Quantili e Intervalli di Credibilità</a></li>
  <li><a href="#errore-di-stima-e-bias" id="toc-errore-di-stima-e-bias" class="nav-link" data-scroll-target="#errore-di-stima-e-bias"><span class="header-section-number">44.5.4</span> Errore di Stima e Bias</a></li>
  <li><a href="#stimatore-della-moda-posteriori" id="toc-stimatore-della-moda-posteriori" class="nav-link" data-scroll-target="#stimatore-della-moda-posteriori"><span class="header-section-number">44.5.5</span> Stimatore della Moda Posteriori</a></li>
  <li><a href="#caratteristiche-della-moda-posteriori" id="toc-caratteristiche-della-moda-posteriori" class="nav-link" data-scroll-target="#caratteristiche-della-moda-posteriori"><span class="header-section-number">44.5.6</span> Caratteristiche della Moda Posteriori</a></li>
  <li><a href="#funzioni-di-perdita-e-proprietà-degli-stimatori" id="toc-funzioni-di-perdita-e-proprietà-degli-stimatori" class="nav-link" data-scroll-target="#funzioni-di-perdita-e-proprietà-degli-stimatori"><span class="header-section-number">44.5.7</span> Funzioni di Perdita e Proprietà degli Stimatori</a></li>
  <li><a href="#proprietà-della-mediana-posteriori" id="toc-proprietà-della-mediana-posteriori" class="nav-link" data-scroll-target="#proprietà-della-mediana-posteriori"><span class="header-section-number">44.5.8</span> Proprietà della Mediana Posteriori</a></li>
  <li><a href="#concentrazione-sulle-medie-a-posteriori" id="toc-concentrazione-sulle-medie-a-posteriori" class="nav-link" data-scroll-target="#concentrazione-sulle-medie-a-posteriori"><span class="header-section-number">44.5.9</span> Concentrazione sulle Medie a Posteriori</a></li>
  <li><a href="#errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo" id="toc-errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo" class="nav-link" data-scroll-target="#errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo"><span class="header-section-number">44.5.10</span> Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo</a></li>
  </ul></li>
  <li><a href="#stima-delle-probabilità-di-evento" id="toc-stima-delle-probabilità-di-evento" class="nav-link" data-scroll-target="#stima-delle-probabilità-di-evento"><span class="header-section-number">44.6</span> Stima delle Probabilità di Evento</a>
  <ul class="collapse">
  <li><a href="#probabilità-di-evento-tramite-indicatori" id="toc-probabilità-di-evento-tramite-indicatori" class="nav-link" data-scroll-target="#probabilità-di-evento-tramite-indicatori"><span class="header-section-number">44.6.1</span> Probabilità di Evento tramite Indicatori</a></li>
  <li><a href="#diagnostiche-del-campionamento" id="toc-diagnostiche-del-campionamento" class="nav-link" data-scroll-target="#diagnostiche-del-campionamento"><span class="header-section-number">44.6.2</span> Diagnostiche del Campionamento</a></li>
  </ul></li>
  <li><a href="#riscaldamento-e-monitoraggio-della-convergenza" id="toc-riscaldamento-e-monitoraggio-della-convergenza" class="nav-link" data-scroll-target="#riscaldamento-e-monitoraggio-della-convergenza"><span class="header-section-number">44.7</span> Riscaldamento e monitoraggio della convergenza</a>
  <ul class="collapse">
  <li><a href="#riscaldamento" id="toc-riscaldamento" class="nav-link" data-scroll-target="#riscaldamento"><span class="header-section-number">44.7.1</span> Riscaldamento</a></li>
  <li><a href="#riduzione-potenziale-della-scala-e-widehatr" id="toc-riduzione-potenziale-della-scala-e-widehatr" class="nav-link" data-scroll-target="#riduzione-potenziale-della-scala-e-widehatr"><span class="header-section-number">44.7.2</span> Riduzione potenziale della scala e <span class="math inline">\(\widehat{R}\)</span></a></li>
  <li><a href="#quante-catene-per-quanto-tempo" id="toc-quante-catene-per-quanto-tempo" class="nav-link" data-scroll-target="#quante-catene-per-quanto-tempo"><span class="header-section-number">44.7.3</span> Quante catene per quanto tempo?</a></li>
  <li><a href="#esecuzione-delle-catene-contemporaneamente" id="toc-esecuzione-delle-catene-contemporaneamente" class="nav-link" data-scroll-target="#esecuzione-delle-catene-contemporaneamente"><span class="header-section-number">44.7.4</span> Esecuzione delle catene contemporaneamente</a></li>
  </ul></li>
  <li><a href="#considerazioni-conclusive" id="toc-considerazioni-conclusive" class="nav-link" data-scroll-target="#considerazioni-conclusive"><span class="header-section-number">44.8</span> Considerazioni Conclusive</a></li>
  <li><a href="#esercizi" id="toc-esercizi" class="nav-link" data-scroll-target="#esercizi"><span class="header-section-number">44.9</span> Esercizi</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo"><span class="header-section-number">44.10</span> Informazioni sull’Ambiente di Sviluppo</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/mcmc/02_stan_beta_binomial.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/mcmc/introduction_mcmc.html">MCMC</a></li><li class="breadcrumb-item"><a href="../../chapters/mcmc/02_stan_beta_binomial.html"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec_stan" class="quarto-section-identifier"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Prerequisiti</strong></p>
<p><strong>Concetti e competenze chiave</strong></p>
<p><strong>Preparazione del Notebook</strong></p>
<div id="cell-2" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:42:44.487021Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:42:44.472635Z&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statistics <span class="im">as</span> stat</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cmdstanpy</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cmdstanpy <span class="im">import</span> CmdStanModel</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>cmdstanpy.utils.get_logger().setLevel(logging.ERROR)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>seed: <span class="bu">int</span> <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">map</span>(<span class="bu">ord</span>, <span class="st">"beta_binomial_model"</span>))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>rng: np.random.Generator <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>seed)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>sns.set_theme(palette<span class="op">=</span><span class="st">"colorblind"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">"arviz-darkgrid"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">"retina"</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the home directory</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>home_directory <span class="op">=</span> os.path.expanduser(<span class="st">"~"</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct the path to the Quarto project directory </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>project_directory <span class="op">=</span> os.path.join(</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    home_directory, <span class="st">'_repositories'</span>, <span class="st">'psicometria'</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2" data-number="44.1">
<h2 data-number="44.1" class="anchored" data-anchor-id="introduzione"><span class="header-section-number">44.1</span> Introduzione</h2>
<p>Stan implementa una versione più efficiente dell’algoritmo di Metropolis (<a href="01_metropolis.html" class="quarto-xref"><span>Capitolo 43</span></a>) chiamata <em>Hamiltonian Monte Carlo</em> (HMC), che viene ulteriormente ottimizzata in Stan attraverso l’algoritmo NUTS (<em>No-U-Turn Sampler</em>). Sebbene l’algoritmo di Metropolis e NUTS producano la stessa soluzione finale, l’algoritmo di Metropolis richiede un numero molto maggiore di iterazioni per raggiungere una condizione di equilibrio, dove i valori prodotti possono essere considerati equivalenti a un campione casuale estratto dalla distribuzione a posteriori desiderata. Questo aspetto diventa particolarmente critico nei modelli complessi, dove la convergenza può richiedere un grande numero di iterazioni, comportando tempi di calcolo molto lunghi. Di conseguenza, l’efficienza del campionamento diventa essenziale.</p>
<p>Dal punto di vista concettuale, ciò che l’algoritmo di Metropolis e NUTS producono è sostanzialmente lo stesso: una catena di campioni che riflette la distribuzione a posteriori target. La differenza principale risiede nella velocità con cui NUTS raggiunge questo obiettivo, rendendolo una scelta preferibile per modelli complessi.</p>
<p>Nel presente capitolo, introdurremo un linguaggio di programmazione probabilistica (PPL) denominato <a href="http://mc-stan.org/">Stan</a>. Stan permette di estrarre campioni da distribuzioni di probabilità costruendo una catena di Markov, la cui distribuzione di equilibrio (o stazionaria) coincide con la distribuzione desiderata. Il nome del linguaggio onora Stanislaw Ulam, uno dei pionieri del metodo Monte Carlo. Una presentazione dettagliata del linguaggio Stan è fornita nella sezione <a href="../appendix/a46_stan.html" class="quarto-xref"><span>Appendice P</span></a>. In questo capitolo, utilizzeremo Stan per fare inferenza su una proporzione.</p>
<p>Il linguaggio Stan è compatibile con diverse piattaforme e offre varie interfacce, tra cui R, Python e Julia. In questo corso, utilizzeremo CmdStanPy, un’interfaccia pensata specificamente per gli utenti di Python. CmdStanPy è un pacchetto scritto in Python3 che funge da wrapper per CmdStan, l’interfaccia a riga di comando per Stan, scritta in C++. Di conseguenza, oltre a Python3, CmdStanPy richiede un toolchain C++ per compilare ed eseguire i modelli Stan.</p>
<p>Le istruzioni per <a href="https://mc-stan.org/cmdstanpy/installation.html">installare</a> CmdStanPy e i componenti necessari di CmdStan dal repository <code>conda-forge</code> sono descritte nell’<a href="../appendix/a04_virtual_env.html" class="quarto-xref"><span>Appendice E</span></a>.</p>
</section>
<section id="stan-e-la-programmazione-probabilistica" class="level2" data-number="44.2">
<h2 data-number="44.2" class="anchored" data-anchor-id="stan-e-la-programmazione-probabilistica"><span class="header-section-number">44.2</span> Stan e la Programmazione Probabilistica</h2>
<p>Stan si configura come un PPL concepito per definire modelli statistici complessi e effettuare inferenze su di essi. Un PPL consente di esprimere modelli probabilistici in modo conciso e di utilizzare algoritmi avanzati per l’inferenza. Ciò risulta particolarmente utile nell’inferenza bayesiana, dove si aggiornano le distribuzioni a priori con dati osservati per ottenere distribuzioni a posteriori.</p>
<section id="struttura-di-un-programma-stan" class="level3" data-number="44.2.1">
<h3 data-number="44.2.1" class="anchored" data-anchor-id="struttura-di-un-programma-stan"><span class="header-section-number">44.2.1</span> Struttura di un Programma Stan</h3>
<p>Un programma Stan richiede la specificazione di variabili e parametri, definendo le distribuzioni a priori dei parametri del modello statistico e la funzione di verosimiglianza. In sostanza, un programma Stan descrive l’interazione tra dati e parametri e le distribuzioni probabilistiche che li governano. Questo consente di effettuare inferenze sulle distribuzioni a posteriori dei parametri del modello, dedotte dai dati osservati e dalle distribuzioni a priori.</p>
</section>
<section id="esecuzione-di-un-programma-stan" class="level3" data-number="44.2.2">
<h3 data-number="44.2.2" class="anchored" data-anchor-id="esecuzione-di-un-programma-stan"><span class="header-section-number">44.2.2</span> Esecuzione di un Programma Stan</h3>
<p>Un programma Stan utilizza metodi Monte Carlo a catena di Markov (MCMC) per generare campioni dalle distribuzioni a posteriori. È inoltre possibile impiegare metodi approssimativi, noti come “inferenza variazionale”, che forniscono stime delle distribuzioni a posteriori.</p>
<p>Stan può generare dati attraverso procedure pseudo-casuali in due contesti principali: nel caso delle simulazioni in avanti, dove i dati vengono simulati a partire dai parametri del modello noti, e nel caso del problema inverso, in cui, partendo dai dati osservati e dalle distribuzioni a priori, si stima la distribuzione a posteriori dei parametri del modello.</p>
</section>
</section>
<section id="simulazione-in-avanti" class="level2" data-number="44.3">
<h2 data-number="44.3" class="anchored" data-anchor-id="simulazione-in-avanti"><span class="header-section-number">44.3</span> Simulazione in Avanti</h2>
<p>La simulazione in avanti consiste nella generazione di dati simulati a partire da un insieme di parametri noti di un modello probabilistico. In altri termini, date determinate assunzioni sui parametri di un modello, si utilizza la simulazione in avanti per prevedere i possibili risultati.</p>
<p>Ad esempio, consideriamo uno studio clinico con <span class="math inline">\(N\)</span> soggetti e una probabilità <span class="math inline">\(\theta\)</span> di esito positivo per ciascun soggetto. Conoscendo il valore di <span class="math inline">\(\theta\)</span> e il numero di soggetti <span class="math inline">\(N\)</span>, possiamo impiegare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci consente di generare dati che riflettono le nostre assunzioni sui parametri del modello.</p>
<p>In notazione statistica, questo si esprime come:</p>
<p><span class="math display">\[
Y \sim \text{Binomiale}(N, \theta)
\]</span></p>
<p>dove <span class="math inline">\(Y\)</span> rappresenta il numero di esiti positivi su <span class="math inline">\(N\)</span> pazienti, con probabilità <span class="math inline">\(\theta\)</span> di esito positivo per ciascun paziente.</p>
<p>Supponiamo di avere <span class="math inline">\(N = 100\)</span> soggetti in uno studio clinico e un tasso di successo <span class="math inline">\(\theta = 0.3\)</span>. Possiamo simulare un risultato <span class="math inline">\(Y\)</span> generando casualmente il numero di soggetti con esito positivo. Utilizzando una distribuzione binomiale, possiamo calcolare la probabilità di ottenere esattamente <span class="math inline">\(y\)</span> esiti positivi su <span class="math inline">\(N\)</span> tentativi:</p>
<p><span class="math display">\[
p(Y = y \mid N, \theta) = \binom{N}{y} \cdot \theta^y \cdot (1 - \theta)^{N - y}.
\]</span></p>
<p>Questa espressione ci permette di calcolare la probabilità di ottenere un certo numero di successi, dato il numero di soggetti e la probabilità di successo.</p>
<p>In altre parole, possiamo utilizzare Stan per generare valori casuali da una distribuzione binomiale, proprio come abbiamo fatto in precedenza utilizzando librerie Python come <code>numpy</code>. Ad esempio, in Python possiamo generare valori casuali da una distribuzione binomiale con <code>numpy</code> nel seguente modo:</p>
<div id="cell-6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Genera 20 valori casuali da una distribuzione binomiale con n=100 e p=0.3</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>random_values <span class="op">=</span> np.random.binomial(n<span class="op">=</span><span class="dv">100</span>, p<span class="op">=</span><span class="fl">0.3</span>, size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(random_values)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[38 18 23 33 23 35 34 23 27 30 27 29 29 27 29 27 34 29 34 27]</code></pre>
</div>
</div>
<p>Con Stan, possiamo ottenere un risultato simile ma all’interno di un contesto più ampio, ad esempio, durante l’esecuzione di un modello di inferenza bayesiana che utilizza la distribuzione binomiale come parte di un modello probabilistico. Questo ci permette di integrare la generazione di valori casuali con la stima dei parametri e altre analisi complesse in un’unica procedura.</p>
<section id="un-primo-programma-in-stan-generazione-di-dati-casuali" class="level3" data-number="44.3.1">
<h3 data-number="44.3.1" class="anchored" data-anchor-id="un-primo-programma-in-stan-generazione-di-dati-casuali"><span class="header-section-number">44.3.1</span> Un Primo Programma in Stan: Generazione di Dati Casuali</h3>
<p>Supponiamo di voler generare valori casuali <span class="math inline">\(Y\)</span> da una distribuzione binomiale con parametri <span class="math inline">\(N = 100\)</span> e <span class="math inline">\(\theta = 0.3\)</span>. Questo può essere realizzato utilizzando il seguente programma Stan:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; theta;</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=N&gt; y;</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  y = binomial_rng(N, theta);</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="organizzazione-di-un-programma-stan" class="level3" data-number="44.3.2">
<h3 data-number="44.3.2" class="anchored" data-anchor-id="organizzazione-di-un-programma-stan"><span class="header-section-number">44.3.2</span> Organizzazione di un Programma Stan</h3>
<p>La prima cosa da notare è che un programma Stan è strutturato in blocchi. In questo esempio, abbiamo due blocchi principali: il <em>blocco dei dati</em> (<code>data</code>), che contiene le dichiarazioni delle variabili da fornire come input, e il <em>blocco delle quantità generate</em> (<code>generated quantities</code>), che non solo dichiara le variabili, ma assegna anche dei valori. In questo programma Stan, la variabile <code>y</code> viene assegnata come risultato di una singola estrazione da una distribuzione <span class="math inline">\(\textrm{binomiale}(N, \theta)\)</span>, utilizzando la funzione <code>binomial_rng</code> fornita da Stan.</p>
</section>
<section id="tipi-di-variabili-in-stan" class="level3" data-number="44.3.3">
<h3 data-number="44.3.3" class="anchored" data-anchor-id="tipi-di-variabili-in-stan"><span class="header-section-number">44.3.3</span> Tipi di Variabili in Stan</h3>
<p>La seconda cosa da notare è che in un programma Stan tutte le variabili devono essere dichiarate con tipi specifici. Stan utilizza la <em>tipizzazione statica</em>, il che significa che, a differenza di linguaggi come Python o R, il tipo di una variabile deve essere dichiarato esplicitamente nel programma prima che venga utilizzata, e non viene determinato dinamicamente durante l’esecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile rimane invariato.</p>
<p>Nel programma in esame, vengono dichiarate tre variabili: <code>N</code> e <code>y</code>, entrambe di tipo <code>int</code> (intero), e <code>theta</code>, di tipo <code>real</code> (numero reale).</p>
</section>
<section id="vincoli-sui-tipi" class="level3" data-number="44.3.4">
<h3 data-number="44.3.4" class="anchored" data-anchor-id="vincoli-sui-tipi"><span class="header-section-number">44.3.4</span> Vincoli sui Tipi</h3>
<p>Le variabili in Stan possono avere dei vincoli specifici. Ad esempio, poiché <code>N</code> rappresenta un conteggio, deve essere maggiore o uguale a zero; questo è indicato con il vincolo <code>lower=0</code>. Allo stesso modo, la variabile <code>y</code>, che rappresenta il numero di successi su <code>N</code> tentativi, deve essere compresa tra 0 e <code>N</code> (inclusi), e questo è specificato con il vincolo <code>lower=0, upper=N</code>. Infine, la variabile <code>theta</code>, essendo una probabilità, deve essere compresa tra 0 e 1, il che viene espresso con il vincolo <code>lower=0, upper=1</code>. Sebbene tecnicamente i limiti per i numeri reali siano aperti, in pratica è possibile ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.</p>
</section>
<section id="esecuzione-del-programma-stan" class="level3" data-number="44.3.5">
<h3 data-number="44.3.5" class="anchored" data-anchor-id="esecuzione-del-programma-stan"><span class="header-section-number">44.3.5</span> Esecuzione del Programma Stan</h3>
<p>La funzione <code>cmdstan_model()</code> crea un nuovo oggetto <code>CmdStanModel</code> a partire da un file contenente un programma Stan. In background, CmdStan traduce un programma Stan in C++ e creare un eseguibile compilato.</p>
<div id="cell-9" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>stan_file <span class="op">=</span> os.path.join(project_directory, <span class="st">"stan"</span>, <span class="st">"binomial-rng.stan"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.code())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=0&gt; N;
  real&lt;lower=0, upper=1&gt; theta;
}
generated quantities {
  int&lt;lower=0, upper=N&gt; y = binomial_rng(N, theta);
}
</code></pre>
</div>
</div>
<p>Durante l’esecuzione, il programma Stan compilato richiede i valori di <code>N</code> e <code>theta</code>. Ad ogni iterazione, il programma campiona un valore di <code>y</code> utilizzando il suo generatore di numeri pseudocasuali integrato. I valori di <code>N</code> e <code>theta</code> devono essere forniti in un dizionario Python.</p>
<div id="cell-11" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:43:07.547928Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:43:07.545420Z&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'N'</span>: N, </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'theta'</span>: theta</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Infine campioniamo dal modello utilizzando il metodo <code>sample</code> di <code>CmdStanModel</code>.</p>
<div id="cell-13" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:43:11.651674Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:43:11.418991Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>trace <span class="op">=</span> model.sample(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>data, </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>, </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    chains<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">20</span>, </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nell’interfaccia Python, il metodo <code>sample()</code> accetta i seguenti argomenti:</p>
<ul>
<li><code>data</code>: i dati letti nel blocco dati del programma Stan,</li>
<li><code>seed</code>: generatore di numeri pseudocasuali per la riproducibilità,</li>
<li><code>chains</code>: il numero di simulazioni da eseguire (<code>parallel_chains</code> indica quante eseguire in parallelo),</li>
<li><code>iter_sampling</code>: numero di estrazioni (cioè, dimensione del campione) da restituire,</li>
<li><code>iter_warmup</code>: numero di iterazioni di riscaldamento per tarare i parametri dell’algoritmo di campionamento (non necessari qui, quindi impostato a 0),</li>
<li><code>show_progress</code>: se <code>True</code>, stampa aggiornamenti di progresso,</li>
<li><code>show_console</code>: apre un monitor di progresso GUI.</li>
</ul>
<p>Il risultato della chiamata a <code>sample()</code> sull’istanza del modello viene assegnato alla variabile <code>trace</code> e contiene le 20 estrazioni richieste con l’argomento <code>iter_sampling = 20</code>.</p>
<p>Quando si chiama <code>model.sample(...)</code>, CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell’argomento <code>data</code> di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poiché il nostro programma Stan ha solo un blocco di quantità generate, l’unico compito rimanente della classe C++ è generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da <code>iter_sampling</code>, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.</p>
<p>La generazione di numeri casuali è determinata dal valore <code>seed</code> specificato nella chiamata.</p>
</section>
<section id="estrazione-dei-risultati" class="level3" data-number="44.3.6">
<h3 data-number="44.3.6" class="anchored" data-anchor-id="estrazione-dei-risultati"><span class="header-section-number">44.3.6</span> Estrazione dei Risultati</h3>
<p>Una volta completato il campionamento, possiamo estrarre il campione di 20 valori per la variabile scalare <code>y</code> sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.</p>
<div id="cell-15" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:43:17.861234Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:43:17.853236Z&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> trace.stan_variable(<span class="st">'y'</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"N ="</span>, N, <span class="st">";  theta ="</span>, theta, <span class="st">";  y ="</span>, <span class="op">*</span>y.astype(<span class="bu">int</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>N = 100 ;  theta = 0.3 ;  y = 28 34 31 29 26 25 31 28 30 36 29 36 37 27 29 23 29 34 30 42</code></pre>
</div>
</div>
</section>
</section>
<section id="il-problema-inverso" class="level2" data-number="44.4">
<h2 data-number="44.4" class="anchored" data-anchor-id="il-problema-inverso"><span class="header-section-number">44.4</span> Il Problema Inverso</h2>
<p>Il problema inverso consiste nella stima dei parametri del modello, come la probabilità di successo <span class="math inline">\(\theta\)</span>, dato un insieme di dati osservati. Iniziamo con il caso più semplice, quello dei dati fittizi dell’esperimento con il compito Go-No Go in cui abbiamo osservato 6 successi in 9 prove. Inoltre, abbiamo imposto una distribuzione a priori uniforme sul parametro <span class="math inline">\(\theta\)</span> (probabilità di riuscire ad inibire la risposta in una prova No Go).</p>
<p>Abbiamo un campione di dati con <span class="math inline">\(N = 9\)</span> tentativi e <span class="math inline">\(y = 6\)</span> successi. L’obiettivo è stimare <span class="math inline">\(\theta\)</span>, la probabilità di successo.</p>
<p>Nell’approccio bayesiano, si specifica una distribuzione a priori per <span class="math inline">\(\theta\)</span>. Supponiamo di utilizzare una distribuzione Beta(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>) come prior per <span class="math inline">\(\theta\)</span>, dove <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> rappresentano la forza delle convinzioni precedenti sui successi e insuccessi rispettivamente.</p>
<p>La distribuzione a posteriori di <span class="math inline">\(\theta\)</span> dato il risultato osservato <span class="math inline">\(y\)</span> segue una distribuzione Beta con parametri aggiornati, che si ottiene sommando <span class="math inline">\(y\)</span> a <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(N-y\)</span> a <span class="math inline">\(\beta\)</span>. Questa è una proprietà ben nota delle distribuzioni Beta, che funge da distribuzione coniugata per la distribuzione binomiale.</p>
<p>Quindi, la distribuzione a posteriori è:</p>
<p><span class="math display">\[
\theta \mid y \sim \text{Beta}(\alpha + y, \beta + N - y).
\]</span></p>
<p>Se scegliamo una distribuzione a priori non informativa con <span class="math inline">\(\alpha = 1\)</span> e <span class="math inline">\(\beta = 1\)</span>, otteniamo:</p>
<p><span class="math display">\[
\theta \mid y \sim \text{Beta}(1 + 6, 1 + 9 - 6) = \text{Beta}(7, 4).
\]</span></p>
<p>La distribuzione a posteriori di <span class="math inline">\(\theta\)</span> è una Beta(7, 4), che riflette l’informazione aggiornata a partire dal campione di dati osservati.</p>
<p>Utilizzando Stan, è possibile ottenere campioni da questa distribuzione a posteriori per calcolare statistiche riassuntive e effettuare previsioni.</p>
<p>In sintesi, la simulazione in avanti e il problema inverso rappresentano due approcci complementari: la simulazione in avanti genera dati simulati da parametri noti, mentre il problema inverso stima i parametri del modello dai dati osservati.</p>
<p>Ecco come possiamo specificare il modello Stan:</p>
<div id="cell-18" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>stan_file <span class="op">=</span> os.path.join(project_directory, <span class="st">"stan"</span>, <span class="st">"go_nogo_model.stan"</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>model_go_nogo <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_go_nogo.code())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=1&gt; N;
  int&lt;lower=0&gt; y;
}
parameters {
  real&lt;lower=0, upper=1&gt; p;
}
model {
  y ~ binomial(N, p); // Likelihood
  p ~ beta(1, 1); // Prior
}
generated quantities {
  int&lt;lower=0, upper=1&gt; p_gt_chance = p &gt; 0.5;
}
</code></pre>
</div>
</div>
<p>In questo programma Stan, vediamo che il numero totale di prove (<code>n</code>) e il numero di successi (<code>y</code>) vengono forniti come dati. Successivamente, sono presenti due blocchi aggiuntivi: un <em>blocco dei parametri</em>, utilizzato per dichiarare i valori sconosciuti (in questo caso, la probabilità di rispondere correttamente, <code>p</code>), e un <em>blocco del modello</em>, dove vengono specificate la distribuzione a priori e la verosimiglianza. Stan calcola la distribuzione a posteriori combinando queste due componenti. Inoltre, è presente un <em>blocco delle quantità generate</em> in cui viene calcolata una variabile booleana che indica se la probabilità di risposta corretta è maggiore di 0.5.</p>
<p>Il modello bayesiano e la sua implementazione in Stan ci permettono di affrontare il problema inverso: inferire la probabilità di una risposta corretta (inibizione nelle prove No-Go) a partire dai dati osservati. Utilizzando Stan, possiamo stimare non solo la probabilità di rispondere correttamente nelle prove No-Go, ma anche la probabilità che tale probabilità sia superiore al valore atteso per caso (<code>p_gt_chance</code>).</p>
<section id="campionare-dalla-distribuzione-a-posteriori" class="level3" data-number="44.4.1">
<h3 data-number="44.4.1" class="anchored" data-anchor-id="campionare-dalla-distribuzione-a-posteriori"><span class="header-section-number">44.4.1</span> Campionare dalla Distribuzione a Posteriori</h3>
<p>Quando eseguiamo un programma Stan, vengono generati campioni casuali che approssimano la distribuzione a posteriori. Con l’aumentare del numero di campioni, questi si avvicinano sempre più a veri campioni della distribuzione a posteriori.</p>
<p>Stan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che può introdurre autocorrelazione tra i campioni, cioè i campioni successivi sono correlati tra loro. Sebbene l’autocorrelazione non crei bias, può aumentare la varianza delle stime, rendendo meno precise le stime nei modelli più complessi.</p>
<p>Per migliorare l’efficienza del campionamento, specialmente nei modelli ad alta dimensionalità, Stan utilizza un algoritmo chiamato No-U-Turn Sampler (NUTS), che è una versione avanzata dell’Hamiltonian Monte Carlo (HMC). NUTS può generare campioni anti-correlati, riducendo la varianza e migliorando la precisione delle stime rispetto ai campioni indipendenti.</p>
</section>
<section id="compilazione-del-codice-stan" class="level3" data-number="44.4.2">
<h3 data-number="44.4.2" class="anchored" data-anchor-id="compilazione-del-codice-stan"><span class="header-section-number">44.4.2</span> Compilazione del Codice Stan</h3>
<p>Per utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato <code>model_go_nogo</code>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>model_go_nogo <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Inseriamo i dati richiesti in un dizionario.</p>
<div id="cell-22" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>stan_data <span class="op">=</span> {<span class="st">"N"</span>: <span class="dv">9</span>, <span class="st">"y"</span>: <span class="dv">6</span>}</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stan_data)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'N': 9, 'y': 6}</code></pre>
</div>
</div>
<p>Eseguiamo il campionamento con la seguente chiamata:</p>
<div id="cell-24" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> model_go_nogo.sample(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>stan_data,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    chains<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    parallel_chains<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il metodo <code>.sample()</code> viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato <code>model_go_nogo</code>.</p>
<p>Assumendo una distribuzione a priori per il parametro <code>p</code>, l’algoritmo procede iterativamente, aggiornando la distribuzione a priori di <code>p</code> condizionandola ai valori già generati. Dopo un certo numero di iterazioni, l’algoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di <code>p</code>.</p>
<p>All’inizio del campionamento, la distribuzione dei campioni può essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale è chiamato “burn-in”. Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e vengono tipicamente scartati. Con l’aumentare del numero di iterazioni, la distribuzione dei campioni si avvicina sempre più alla distribuzione target.</p>
<p>Una volta eseguito il modello in Stan, otteniamo una serie di campioni di <code>p</code> dalla distribuzione a posteriori <span class="math inline">\(p(p \mid N, y)\)</span>. Ogni campione rappresenta un possibile valore di <code>p</code> compatibile con i dati osservati <code>y</code>. Procediamo quindi a estrarre i campioni a posteriori per le variabili <code>p</code> e <code>p_gt_chance</code>.</p>
<div id="cell-26" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>p_draws <span class="op">=</span> fit.stan_variable(<span class="st">"p"</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>p_gt_chance_draws <span class="op">=</span> fit.stan_variable(<span class="st">"p_gt_chance"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Tracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di <code>p</code> sono più probabili e comprendere meglio la forma della distribuzione a posteriori. L’istogramma ci fornisce diverse informazioni:</p>
<ul>
<li><strong>Valore più probabile di <code>p</code></strong>: Questo è il valore intorno al quale i campioni sono più concentrati, noto come la moda della distribuzione.</li>
<li><strong>Distribuzione dei possibili valori di <code>p</code></strong>: Questo ci dà un’idea dell’incertezza nella stima di <code>p</code>.</li>
</ul>
<p>Se l’istogramma è stretto e concentrato attorno a un valore specifico, significa che c’è poca incertezza nella stima di <code>p</code>. In altre parole, possiamo essere abbastanza sicuri che il valore vero di <code>p</code> sia vicino a questo valore. Se l’istogramma è largo e distribuito, significa che c’è maggiore incertezza nella stima di <code>p</code>. Questo indica che i dati osservati non forniscono una stima precisa e che il valore di <code>p</code> potrebbe variare notevolmente.</p>
<div id="cell-28" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>plt.hist(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    p_draws,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    bins<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    density<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Istogramma della distribizione a posteriori di p"</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Valori"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frequenza"</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_stan_beta_binomial_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Con un numero così piccolo di prove la nostra incertezza relativamente al valore vero di <span class="math inline">\(p\)</span> è enorme. Si noti la corrispondenza tra questo istogramma e quello calcolato “manualmente” nella <a href="01_metropolis.html#sec-metropolis-1" class="quarto-xref"><span>Sezione 43.5.3</span></a>.</p>
<p>Possiamo anche calcolare la probabilità posteriore che la probabilità di successo (<code>p</code>) sia superiore al livello di casualità (0.5). In altre parole, possiamo stimare la probabilità che il soggetto abbia una performance migliore di quella casuale nel compito go/no-go. Questa probabilità è data dalla proporzione di campioni nella distribuzione posteriore di <span class="math inline">\(p\)</span> per cui <span class="math inline">\(p\)</span> è maggiore di 0.5. Utilizziamo la funzione <code>np.mean()</code> per calcolare la media delle estrazioni di <code>p_gt_chance</code>, che fornisce una stima di questa probabilità.</p>
<div id="cell-31" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>np.mean(p_gt_chance_draws)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>0.821125</code></pre>
</div>
</div>
<div id="exm-moma-1" class="theorem example">
<p><span class="theorem-title"><strong>Esempio 44.1</strong></span> Ora consideriamo una seconda versione del modello Stan, questa volta utilizzando una distribuzione a priori informativa. Prendiamo in esame i dati relativi alla proporzione di artisti della Generazione X presenti al MoMA, dove 14 artisti su un campione di 100 appartenevano a questa generazione. Ci poniamo due obiettivi: (1) calcolare la distribuzione a posteriori per <span class="math inline">\(\theta\)</span>, la probabilità che un artista appartenga alla Generazione X, e (2) determinare se la Generazione X è rappresentata al MoMA con almeno un artista su quattro. Per fare ciò, imponiamo una distribuzione a priori Beta(4, 6) su <span class="math inline">\(\theta\)</span> e utilizziamo Stan per l’inferenza. Il codice Stan aggiornato è il seguente.</p>
<div id="cell-33" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>stan_file <span class="op">=</span> os.path.join(project_directory, <span class="st">"stan"</span>, <span class="st">"moma_model.stan"</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>model_moma <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_moma.code())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=0&gt; N;
  int&lt;lower=0, upper=N&gt; y;
  int&lt;lower=0&gt; alpha_prior;
  int&lt;lower=0&gt; beta_prior;
}
parameters {
  real&lt;lower=0, upper=1&gt; theta;
}
model {
  theta ~ beta(alpha_prior, beta_prior);
  y ~ binomial(N, theta);
}
generated quantities {
  int&lt;lower=0, upper=N&gt; y_rep;
  int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25;
  
  y_rep = binomial_rng(N, theta);
}
</code></pre>
</div>
</div>
<p>Creiamo un dizionario con i dati.</p>
<div id="cell-35" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>data_moma <span class="op">=</span> {</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"N"</span>: <span class="dv">100</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span>: <span class="dv">14</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"alpha_prior"</span>: <span class="dv">4</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"beta_prior"</span>: <span class="dv">6</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stan_data)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'N': 9, 'y': 6}</code></pre>
</div>
</div>
<p>Eseguiamo il campionamento.</p>
<div id="cell-37" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>fit_moma <span class="op">=</span> model_moma.sample(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>data_moma,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Un grafico con le tracce si ottiene nel modo seguente:</p>
<div id="cell-39" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> az.plot_trace(fit_moma, var_names<span class="op">=</span>(<span class="st">"theta"</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_stan_beta_binomial_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Con Stan, possiamo ottenere un riepilogo completo della variabile <span class="math inline">\(\theta\)</span> nella distribuzione a posteriori. Per fare ciò, basta chiamare la funzione <code>.summary()</code> sul campione. Questo riepilogo include tutte le statistiche rilevanti.</p>
<div id="cell-41" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>az.summary(fit_moma, var_names<span class="op">=</span>(<span class="st">"theta"</span>), hdi_prob<span class="op">=</span><span class="fl">0.94</span>, round_to<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">theta</td>
<td>0.164</td>
<td>0.0348</td>
<td>0.103</td>
<td>0.2309</td>
<td>0.0006</td>
<td>0.0005</td>
<td>2952.633</td>
<td>3837.07</td>
<td>1.001</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Si noti come la stima putuale a posteriori e l’intervallo di credibilità riproducono i valori ottenuti utilizzando l’algoritmo di Metropolis nella <a href="01_metropolis.html#sec-moma-post-estimates" class="quarto-xref"><span>Sezione 43.6.2</span></a>.</p>
<p>Il modello relativo agli artisti della Generazione X è abbastanza semplice da permettere una soluzione analitica della distribuzione a posteriori:</p>
<p><span class="math display">\[
\begin{aligned}
    p(\theta \mid y, N) &amp;\propto p(y \mid N, \theta) \cdot p(\theta) \\
    &amp;= \text{binomiale}(y \mid N, \theta) \cdot \text{beta}(\theta \mid 1, 1) \\
    &amp;\propto \theta^y \cdot (1 - \theta)^{N - y} \cdot \theta^{1 - 1} \cdot (1 - \theta)^{1 - 1} \\
    &amp;= \theta^{y} \cdot (1 - \theta)^{N - y} \\
    &amp;\propto \text{beta}(\theta \mid y + 1, N - y + 1).
\end{aligned}
\]</span></p>
<p>Quindi, possiamo concludere che</p>
<p><span class="math display">\[
p(\theta \mid y, N) = \text{beta}(\theta \mid y + 1, N - y + 1),
\]</span></p>
<p>ovvero <span class="math inline">\(p(\theta \mid y, N) = \text{beta}(\theta \mid 14 + 4, 100 - 14 + 6) = \text{beta}(18, 92)\)</span>.</p>
<p>Nella figura successiva, possiamo osservare la buona corrispondenza tra le stime a posteriori di <span class="math inline">\(\theta\)</span> ottenute con Stan e la distribuzione teorica <span class="math inline">\(\text{beta}(18, 92)\)</span>.</p>
<div id="cell-44" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>theta_draws <span class="op">=</span> fit_moma.stan_variable(<span class="st">"theta"</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the histogram of the posterior draws</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>plt.hist(</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    theta_draws, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">"blue"</span>, label<span class="op">=</span><span class="st">"Posterior draws"</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the x values for the theoretical Beta(18, 92) distribution</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> stats.beta.pdf(x, <span class="dv">18</span>, <span class="dv">92</span>)  <span class="co"># Calculate the PDF of the Beta distribution</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Overlay the theoretical distribution on the histogram</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y, <span class="st">"r-"</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"Beta(18, 92) theoretical distribution"</span>)</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels and legend</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Theta"</span>)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Posterior Distribution vs Theoretical Beta(18, 92)"</span>)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_stan_beta_binomial_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="stime-puntuali-bayesiane" class="level2" data-number="44.5">
<h2 data-number="44.5" class="anchored" data-anchor-id="stime-puntuali-bayesiane"><span class="header-section-number">44.5</span> Stime Puntuali Bayesiane</h2>
<p>In termini bayesiani, una <em>stima puntuale</em> per un parametro <span class="math inline">\(\Theta\)</span> condizionato sui dati osservati <span class="math inline">\(Y = y\)</span> è un singolo valore <span class="math inline">\(\hat{\theta} \in \mathbb{R}^D\)</span> che riassume la distribuzione a posteriori <span class="math inline">\(p(\theta \mid y)\)</span>. La notazione <span class="math inline">\(\hat{\theta}\)</span> è convenzionale nella statistica per indicare una stima di un parametro <span class="math inline">\(\theta\)</span>. In questa sezione definiamo tre stimatori e discutiamo come i due stimatori bayesiani minimizzino una <em>funzione di perdita</em> tra il valore vero e la stima. Torneremo alla funzione di perdita e alle proprietà degli stimatori dopo averli definiti.</p>
<section id="stimatore-della-media-posteriori" class="level3" data-number="44.5.1">
<h3 data-number="44.5.1" class="anchored" data-anchor-id="stimatore-della-media-posteriori"><span class="header-section-number">44.5.1</span> Stimatore della Media Posteriori</h3>
<p>La stima puntuale bayesiana più comune per un parametro è la media posteriori,</p>
<p><span class="math display">\[
\begin{align}
\widehat{\theta}
&amp;= \mathbb{E}[\Theta \mid Y = y] \\
&amp;= \int_{\Theta} \theta \cdot p(\theta \mid y) \, \textrm{d}\theta \\
&amp;= \lim_{M \rightarrow \infty} \, \frac{1}{M} \sum_{m=1}^M \theta^{(m)} \\
&amp;\approx \frac{1}{M} \sum_{m=1}^M \theta^{(m)},
\end{align}
\]</span></p>
<p>dove nelle ultime due righe, ogni estrazione è distribuita approssimativamente secondo la distribuzione a posteriori,</p>
<p><span class="math display">\[
\theta^{(m)} \sim p(\theta \mid y).
\]</span></p>
<p>Abbiamo introdotto la notazione di <em>aspettativa condizionale</em> nella prima riga di questa definizione. Le aspettative sono semplicemente medie ponderate, con i pesi dati da una densità di probabilità. L’inferenza bayesiana coinvolge aspettative sulla distribuzione a posteriori, la cui notazione concisa è quella dell’<em>aspettativa condizionale</em>,</p>
<p><span class="math display">\[
\mathbb{E}\!
\left[ f(\Theta) \mid Y = y \right]
= \int_{\mathbb{R^N}} f(\theta) \cdot p_{\Theta \mid Y}(\theta \mid y) \, \textrm{d}\theta,
\]</span></p>
<p>dove <span class="math inline">\(\Theta\)</span> e <span class="math inline">\(Y\)</span> sono variabili casuali, mentre <span class="math inline">\(\theta\)</span> e <span class="math inline">\(y\)</span> sono variabili vincolate ordinarie.</p>
<p>Per il modello dell’<a href="#exm-moma-1" class="quarto-xref">Esempio&nbsp;<span>44.1</span></a>, la stima per la proporzione <span class="math inline">\(\theta\)</span> di artisti della Generazione X condizionata sui dati <span class="math inline">\(y\)</span> osservati nel campione è calcolata come la media campionaria delle estrazioni per <code>theta</code>.</p>
<div id="cell-47" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:46:45.791282Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:46:45.766651Z&quot;}" data-execution_count="51">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="op">=</span> np.mean(theta_draws)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"estimated theta = </span><span class="sc">{</span>theta_hat<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>estimated theta = 0.164</code></pre>
</div>
</div>
</section>
<section id="stimatore-della-mediana-posteriori-quantili-e-intervalli" class="level3" data-number="44.5.2">
<h3 data-number="44.5.2" class="anchored" data-anchor-id="stimatore-della-mediana-posteriori-quantili-e-intervalli"><span class="header-section-number">44.5.2</span> Stimatore della Mediana Posteriori, Quantili e Intervalli</h3>
<p>Un’alternativa popolare alla stima puntuale bayesiana è la <em>mediana posteriori</em>, <span class="math inline">\(\theta^+\)</span>. La mediana è il valore tale che, per ogni dimensione <span class="math inline">\(d \in 1{:}D\)</span>,</p>
<p><span class="math display">\[
\Pr[\Theta_d \leq \theta^+_d] = \frac{1}{2}.
\]</span></p>
<p>In altre parole, la mediana è il valore che divide la distribuzione a posteriori in due parti uguali: il 50% dei campioni è al di sotto della mediana e il 50% è al di sopra. La mediana posteriori può essere calcolata prendendo la mediana dei campioni dalla distribuzione a posteriori.</p>
<p>Per il modello dell’<a href="#exm-moma-1" class="quarto-xref">Esempio&nbsp;<span>44.1</span></a>, ecco come calcolare la mediana posteriori utilizzando Python:</p>
<div id="cell-49" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:46:52.715592Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:46:52.709025Z&quot;}" data-execution_count="52">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>theta_plus <span class="op">=</span> np.median(theta_draws)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"estimated (median) theta = </span><span class="sc">{</span>theta_plus<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>estimated (median) theta = 0.162</code></pre>
</div>
</div>
<p>Poiché la distribuzione a posteriori per i dati degli artisti della Generazione X è quasi simmetrica, la media posteriori e la mediana posteriori sono molto simili.</p>
</section>
<section id="quantili-e-intervalli-di-credibilità" class="level3" data-number="44.5.3">
<h3 data-number="44.5.3" class="anchored" data-anchor-id="quantili-e-intervalli-di-credibilità"><span class="header-section-number">44.5.3</span> Quantili e Intervalli di Credibilità</h3>
<p>Oltre alla mediana, possiamo anche calcolare i quantili e gli intervalli di credibilità per fornire ulteriori informazioni sulla distribuzione a posteriori. I quantili sono valori che dividono la distribuzione in intervalli con una probabilità specificata. Gli intervalli di credibilità indicano l’intervallo entro il quale cade una certa percentuale della distribuzione a posteriori.</p>
<p>Ad esempio, se vogliamo calcolare il quantile al 95% della distribuzione a posteriori, possiamo semplicemente prendere il valore che si trova al 95° percentile nella sequenza ordinata dei campioni. Di seguito sono riportati i quantili al 5% e al 95% della distribuzione a posteriori del modello dell’<a href="#exm-moma-1" class="quarto-xref">Esempio&nbsp;<span>44.1</span></a>, calcolati utilizzando i quantili empirici.</p>
<div id="cell-53" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:46:57.238509Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:46:57.229690Z&quot;}" data-execution_count="53">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>quantile_05 <span class="op">=</span> np.quantile(theta_draws, <span class="fl">0.05</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>quantile_95 <span class="op">=</span> np.quantile(theta_draws, <span class="fl">0.95</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"""0.05 quantile = </span><span class="sc">{</span>quantile_05<span class="sc">:.3f}</span><span class="ss">;</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="ss">0.95 quantile = </span><span class="sc">{</span>quantile_95<span class="sc">:.3f}</span><span class="ss">"""</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.05 quantile = 0.111;
0.95 quantile = 0.224</code></pre>
</div>
</div>
<section id="intervalli-posteriori" class="level4" data-number="44.5.3.1">
<h4 data-number="44.5.3.1" class="anchored" data-anchor-id="intervalli-posteriori"><span class="header-section-number">44.5.3.1</span> Intervalli Posteriori</h4>
<p>Insieme, il quantile al 5% e al 95% ci forniscono i limiti del nostro <em>intervallo di probabilità centrale</em> al 90%. Questo intervallo è definito come l’intervallo che contiene il 90% della massa di probabilità a posteriori, con il 5% della massa rimanente al di sotto dell’intervallo e il 5% al di sopra.</p>
</section>
</section>
<section id="errore-di-stima-e-bias" class="level3" data-number="44.5.4">
<h3 data-number="44.5.4" class="anchored" data-anchor-id="errore-di-stima-e-bias"><span class="header-section-number">44.5.4</span> Errore di Stima e Bias</h3>
<p>L’<em>errore</em> di una stima è la differenza tra la stima stessa e il valore vero del parametro,</p>
<p><span class="math display">\[
\textrm{err} = \hat{\theta} - \theta.
\]</span></p>
<p>La nostra stima <span class="math inline">\(\hat{\theta}\)</span> è implicitamente una funzione dei dati <span class="math inline">\(y\)</span>, quindi anche l’errore dipende dai dati. Possiamo rendere esplicita questa dipendenza scrivendo</p>
<p><span class="math display">\[
\text{err}(y) = \hat{\theta}(y) - \theta.
\]</span></p>
<p>Il <em>bias</em> di uno stimatore è definito come l’errore atteso, cioè la media dell’errore rispetto alla distribuzione dei dati per la variabile casuale <span class="math inline">\(Y\)</span>,</p>
<p><span class="math display">\[
\begin{align}
\text{bias}
&amp;= \mathbb{E}[\text{err}(Y)] \\
&amp;= \mathbb{E}[\hat{\theta}(Y) - \theta] \\
&amp;= \int_Y (\hat{\theta}(y) - \theta) \, \text{d}y.
\end{align}
\]</span></p>
<p>In altre parole, il bias misura quanto, in media, la stima <span class="math inline">\(\hat{\theta}\)</span> si discosta dal valore vero <span class="math inline">\(\theta\)</span> considerando tutte le possibili realizzazioni dei dati <span class="math inline">\(Y\)</span>. Un bias nullo indica che lo stimatore è corretto in media, cioè non tende a sovrastimare o sottostimare il valore vero del parametro.</p>
</section>
<section id="stimatore-della-moda-posteriori" class="level3" data-number="44.5.5">
<h3 data-number="44.5.5" class="anchored" data-anchor-id="stimatore-della-moda-posteriori"><span class="header-section-number">44.5.5</span> Stimatore della Moda Posteriori</h3>
<p>Uno stimatore popolare, sebbene non strettamente bayesiano, è la moda a posteriori, che rappresenta il valore del parametro <span class="math inline">\(\theta\)</span> per cui la densità a posteriori è massima. Formalmente, è definita come:</p>
<p><span class="math display">\[
\theta^* = \text{arg max}_\theta \ p(\theta \mid y).
\]</span></p>
<p>La stima <span class="math inline">\(\theta^*\)</span> è spesso chiamata stima MAP (Maximum A Posteriori). La moda a posteriori non è considerata un vero stimatore bayesiano perché non tiene conto dell’incertezza nella stessa misura in cui lo fanno altri metodi bayesiani. In altre parole, non minimizza una funzione di perdita basata sui valori veri dei parametri, ma cerca semplicemente il valore più probabile dato i dati osservati.</p>
</section>
<section id="caratteristiche-della-moda-posteriori" class="level3" data-number="44.5.6">
<h3 data-number="44.5.6" class="anchored" data-anchor-id="caratteristiche-della-moda-posteriori"><span class="header-section-number">44.5.6</span> Caratteristiche della Moda Posteriori</h3>
<ul>
<li><strong>Non considera l’incertezza</strong>: La stima MAP si focalizza solo sul valore più probabile della distribuzione a posteriori, senza tenere conto della variabilità dei dati.</li>
<li><strong>Massimo della densità a posteriori</strong>: La moda a posteriori rappresenta il punto in cui la densità a posteriori raggiunge il suo massimo.</li>
<li><strong>Possibili limitazioni</strong>: La stima MAP potrebbe non esistere in alcuni casi, come nei modelli in cui la densità cresce senza limiti. Questo può accadere, ad esempio, nei modelli bayesiani gerarchici o in distribuzioni semplici come la distribuzione esponenziale con parametro 1 (<span class="math inline">\(\textrm{esponenziale}(1)\)</span>).</li>
</ul>
</section>
<section id="funzioni-di-perdita-e-proprietà-degli-stimatori" class="level3" data-number="44.5.7">
<h3 data-number="44.5.7" class="anchored" data-anchor-id="funzioni-di-perdita-e-proprietà-degli-stimatori"><span class="header-section-number">44.5.7</span> Funzioni di Perdita e Proprietà degli Stimatori</h3>
<p>La media a posteriori è uno stimatore bayesiano popolare per due ragioni principali. Primo, è uno stimatore non distorto, il che significa che ha un bias nullo. Secondo, ha l’errore quadratico medio atteso minimo tra tutti gli stimatori non distorti. L’errore quadratico di una stima è definito come:</p>
<p><span class="math display">\[
\text{err}^2(y) = \left(\hat{\theta}(y) - \theta\right)^2.
\]</span></p>
<p>Questa è una funzione di perdita, che misura la differenza tra una stima <span class="math inline">\(\hat{\theta}\)</span> e il valore vero <span class="math inline">\(\theta\)</span>. Tuttavia, la media a posteriori potrebbe non esistere se la distribuzione a posteriori ha code molto ampie, come accade nella distribuzione di Cauchy standard.</p>
</section>
<section id="proprietà-della-mediana-posteriori" class="level3" data-number="44.5.8">
<h3 data-number="44.5.8" class="anchored" data-anchor-id="proprietà-della-mediana-posteriori"><span class="header-section-number">44.5.8</span> Proprietà della Mediana Posteriori</h3>
<p>La mediana a posteriori <span class="math inline">\(\theta^+\)</span> ha tre proprietà interessanti:</p>
<ol type="1">
<li><strong>Sempre ben definita</strong>: La mediana a posteriori è sempre ben definita, anche per densità con poli o code molto ampie.</li>
<li><strong>Minimizzazione dell’errore assoluto atteso</strong>: La mediana minimizza l’errore assoluto atteso, il che la rende robusta.</li>
<li><strong>Robustezza ai valori anomali</strong>: La mediana è meno sensibile ai valori anomali rispetto alla media, perché minimizza l’errore assoluto anziché l’errore quadrato.</li>
</ol>
</section>
<section id="concentrazione-sulle-medie-a-posteriori" class="level3" data-number="44.5.9">
<h3 data-number="44.5.9" class="anchored" data-anchor-id="concentrazione-sulle-medie-a-posteriori"><span class="header-section-number">44.5.9</span> Concentrazione sulle Medie a Posteriori</h3>
<p>In questa introduzione a Stan, ci concentreremo principalmente sulle medie a posteriori. La media a posteriori non solo fornisce una stima non distorta, ma minimizza anche l’errore quadratico medio atteso, rendendola uno strumento potente per l’inferenza bayesiana. Tuttavia, è importante essere consapevoli delle sue limitazioni, specialmente in presenza di distribuzioni a posteriori con code molto ampie.</p>
</section>
<section id="errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo" class="level3" data-number="44.5.10">
<h3 data-number="44.5.10" class="anchored" data-anchor-id="errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo"><span class="header-section-number">44.5.10</span> Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo</h3>
<p>Quando utilizziamo un campionatore di catene di Markov per stimare parametri, otteniamo una sequenza di campioni casuali. Questa sequenza è essa stessa una variabile casuale, perché è composta da molte variabili casuali. A causa di questa natura casuale, ogni esecuzione del campionatore può produrre risultati leggermente diversi, introducendo quello che è noto come errore Monte Carlo.</p>
<p>L’errore Monte Carlo è l’errore introdotto dal fatto che utilizziamo solo un numero finito di campioni (<span class="math inline">\(M\)</span>) per stimare i parametri. Questo tipo di errore si verifica perché, con un numero limitato di campioni, non possiamo catturare perfettamente l’intera distribuzione a posteriori.</p>
<section id="errore-standard-di-monte-carlo-mcmc" class="level4" data-number="44.5.10.1">
<h4 data-number="44.5.10.1" class="anchored" data-anchor-id="errore-standard-di-monte-carlo-mcmc"><span class="header-section-number">44.5.10.1</span> Errore Standard di Monte Carlo (MCMC)</h4>
<p>Stan riporta l’errore standard di Monte Carlo (MCMC) insieme alle stime della media. L’errore standard MCMC per un parametro scalare $ _d $ è definito come:</p>
<p><span class="math display">\[
\text{mcmc-se} = \frac{\textrm{sd}[\Theta_d \mid Y = y]}{\sqrt{N^{\text{eff}}}},
\]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(\text{sd}[\Theta_d \mid Y = y]\)</span> è la deviazione standard del parametro <span class="math inline">\(\theta_d\)</span> nella distribuzione a posteriori.</li>
<li><span class="math inline">\(N^{\text{eff}}\)</span> è la dimensione del campione effettivo, che riflette il numero di campioni indipendenti equivalenti ottenuti dal campionatore.</li>
</ul>
</section>
<section id="dimensione-del-campione-effettivo" class="level4" data-number="44.5.10.2">
<h4 data-number="44.5.10.2" class="anchored" data-anchor-id="dimensione-del-campione-effettivo"><span class="header-section-number">44.5.10.2</span> Dimensione del Campione Effettivo</h4>
<p>Nel teorema del limite centrale, la dimensione del campione (numero di estrazioni indipendenti) appare al posto di <span class="math inline">\(N^{\text{eff}}\)</span>. Tuttavia, nel contesto delle catene di Markov, i campioni successivi sono correlati tra loro. La dimensione del campione effettivo (<span class="math inline">\(N^{\text{eff}}\)</span>) tiene conto di questa correlazione e rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle nostre estrazioni correlate.</p>
<p>La dimensione del campione effettivo per un campione di dimensione <span class="math inline">\(M\)</span> è definita come:</p>
<p><span class="math display">\[
N^{\text{eff}} = \frac{M}{\text{IAT}},
\]</span></p>
<p>dove <span class="math inline">\(\text{IAT}\)</span> è il tempo di autocorrelazione integrata. Sebbene non sia definito formalmente qui, può essere considerato come l’intervallo tra estrazioni effettivamente indipendenti nella nostra catena di Markov. Se l’autocorrelazione è bassa, <span class="math inline">\(\text{IAT}\)</span> sarà vicino a 1; se l’autocorrelazione è alta, <span class="math inline">\(\text{IAT}\)</span> sarà molto più alto.</p>
<p>In sintesi, <span class="math inline">\(N^{\text{eff}}\)</span> rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle estrazioni correlate della nostra catena di Markov.</p>
<p>In conclusione, l’errore standard di Monte Carlo (MCMC) fornisce una misura di quanto varierebbero le nostre stime se ripetessimo il processo di campionamento più volte. È un indicatore dell’affidabilità delle nostre stime, tenendo conto della casualità introdotta dall’utilizzo di un numero finito di campioni. Conoscere questo errore ci aiuta a valutare la precisione delle nostre stime e a comprendere meglio l’incertezza associata ai risultati ottenuti tramite il campionamento di catene di Markov.</p>
</section>
</section>
</section>
<section id="stima-delle-probabilità-di-evento" class="level2" data-number="44.6">
<h2 data-number="44.6" class="anchored" data-anchor-id="stima-delle-probabilità-di-evento"><span class="header-section-number">44.6</span> Stima delle Probabilità di Evento</h2>
<p>Nella seconda domanda dell’<a href="#exm-moma-1" class="quarto-xref">Esempio&nbsp;<span>44.1</span></a>, non stiamo cercando un valore specifico per <span class="math inline">\(\theta\)</span>, ma vogliamo sapere qual è la probabilità che <span class="math inline">\(\theta\)</span> sia maggiore di <span class="math inline">\(\frac{1}{4}\)</span> dopo aver osservato <span class="math inline">\(y\)</span> artisti della Generazione X su un totale di <span class="math inline">\(N\)</span> = 100 artisti. In termini probabilistici, stiamo cercando di stimare la probabilità di un evento.</p>
<p>Un sottoinsieme di valori di un parametro definisce un <em>evento</em>. Ad esempio, la condizione <span class="math inline">\(\theta &gt; \frac{1}{4}\)</span> può essere espressa come l’evento:</p>
<p><span class="math display">\[ A = \left\{ \theta \in \Theta : \theta &gt; \frac{1}{4} \right\}. \]</span></p>
<p>La probabilità dell’evento <span class="math inline">\(A\)</span>, cioè che la proporzione di artisti della Generazione X sia maggiore di 0.25, può essere calcolata come <span class="math inline">\(\Pr\!\left[\Theta &gt; \frac{1}{4} \, \big| \, N, y\right]\)</span>.</p>
<section id="probabilità-di-evento-tramite-indicatori" class="level3" data-number="44.6.1">
<h3 data-number="44.6.1" class="anchored" data-anchor-id="probabilità-di-evento-tramite-indicatori"><span class="header-section-number">44.6.1</span> Probabilità di Evento tramite Indicatori</h3>
<p>La <em>funzione indicatrice</em> <span class="math inline">\(\textrm{I}\)</span> assegna il valore 1 alle proposizioni vere e 0 a quelle false. Ad esempio, <span class="math inline">\(\textrm{I}(\theta &gt; \frac{1}{4}) = 1\)</span> se <span class="math inline">\(\theta &gt; 0.25\)</span> è vero.</p>
<p>Le probabilità di evento sono definite come aspettative condizionali posteriori delle funzioni indicatrici:</p>
<p><span class="math display">\[
\begin{align}
\Pr[\Theta &gt; 0.25 \mid N, y]
&amp;= \mathbb{E}\!\left[\textrm{I}[\Theta &gt; 0.25] \mid N, y\right] \\
&amp;= \int_{\Theta} \textrm{I}(\theta &gt; 0.25) \cdot p(\theta \mid N, y) \, \textrm{d}\theta \\
&amp;\approx \frac{1}{M} \sum_{m=1}^M \textrm{I}(\theta^{(m)} &gt; 0.25),
\end{align}
\]</span></p>
<p>dove <span class="math inline">\(\theta^{(m)}\)</span> rappresenta i campioni dalla distribuzione a posteriori <span class="math inline">\(p(\theta \mid N, y)\)</span>.</p>
<p>In Stan, possiamo codificare questa funzione indicatrice direttamente e assegnarla a una variabile nel blocco <code>generated quantities</code>.</p>
<p>Per rispondere alla seconda domanda dell’<a href="#exm-moma-1" class="quarto-xref">Esempio&nbsp;<span>44.1</span></a>, possiamo aggiungere la seguente linea di codice nel blocco <code>generated quantities</code>:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; theta_gt_025 = theta &gt; <span class="fl">0.25</span>;</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Questa espressione assume il valore 1 se <code>theta &gt; 0.25</code> è vero e 0 se è falso. In notazione matematica, questa funzione indicatrice sarebbe scritta come <span class="math inline">\(\textrm{I}(\theta &gt; 0.25)\)</span>. In Stan, l’operatore <code>&gt;</code> restituisce 0 o 1, quindi possiamo semplicemente scrivere <code>theta &gt; 0.25</code>.</p>
<p>La media a posteriori della variabile <code>theta_gt_025</code> rappresenta quindi la nostra stima per <span class="math inline">\(\Pr[\theta &gt; 0.25 \mid N, y]\)</span>.</p>
<div id="cell-55" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>theta_gt_025_draws <span class="op">=</span> fit_moma.stan_variable(<span class="st">"theta_gt_025"</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>Pr_theta_gt_025 <span class="op">=</span> np.mean(theta_gt_025_draws)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"estimated Pr[theta &gt; 0.25] = </span><span class="sc">{</span>Pr_theta_gt_025<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>estimated Pr[theta &gt; 0.25] = 0.0119</code></pre>
</div>
</div>
<p>Tale valore è approssimativamente uguale a 1.2%. Possiamo dunque rigettare l’idea che almeno un artista su quattro tra quelli rappresentati al MoMA appartenga alla Generazione X.</p>
</section>
<section id="diagnostiche-del-campionamento" class="level3" data-number="44.6.2">
<h3 data-number="44.6.2" class="anchored" data-anchor-id="diagnostiche-del-campionamento"><span class="header-section-number">44.6.2</span> Diagnostiche del Campionamento</h3>
<p>L’istruzione <code>print(fit_moma.diagnose())</code> in Stan viene utilizzata per eseguire una diagnosi completa del campionamento MCMC. Questa funzione fornisce una serie di statistiche diagnostiche che aiutano a valutare la qualità e la convergenza del campionamento.</p>
<p>Questi sono alcuni degli aspetti che possono essere diagnosticati:</p>
<ol type="1">
<li><p><strong>Convergenza</strong>: La diagnosi verifica se le catene di Markov sono convergenti, ad esempio controllando il valore di <span class="math inline">\(\hat{R}\)</span>. Un valore di <span class="math inline">\(\hat{R}\)</span> vicino a 1 indica che le catene sono ben mescolate e convergenti.</p></li>
<li><p><strong>Autocorrelazione</strong>: Fornisce informazioni sull’autocorrelazione delle catene, che può influire sull’efficienza del campionamento. Bassa autocorrelazione è desiderabile per ottenere campioni indipendenti.</p></li>
<li><p><strong>Efficienza del campionamento</strong>: Viene calcolata la dimensione del campione effettivo (<span class="math inline">\(N_{\text{eff}}\)</span>), che indica quanti campioni indipendenti equivarrebbero ai campioni correlati ottenuti.</p></li>
<li><p><strong>Varianza e Deviazione Standard</strong>: Viene riportata la varianza e la deviazione standard dei campioni, aiutando a comprendere la distribuzione a posteriori del parametro.</p></li>
</ol>
<p>Per il modello dell’<a href="#exm-moma-1" class="quarto-xref">Esempio&nbsp;<span>44.1</span></a> abbiamo:</p>
<div id="cell-58" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:47:49.768552Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:47:49.601366Z&quot;}" data-execution_count="66">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(fit_moma.diagnose())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_4.csv

Checking sampler transitions treedepth.
Treedepth satisfactory for all transitions.

Checking sampler transitions for divergences.
No divergent transitions found.

Checking E-BFMI - sampler transitions HMC potential energy.
E-BFMI satisfactory.

Effective sample size satisfactory.

Split R-hat values satisfactory all parameters.

Processing complete, no problems detected.
</code></pre>
</div>
</div>
</section>
</section>
<section id="riscaldamento-e-monitoraggio-della-convergenza" class="level2" data-number="44.7">
<h2 data-number="44.7" class="anchored" data-anchor-id="riscaldamento-e-monitoraggio-della-convergenza"><span class="header-section-number">44.7</span> Riscaldamento e monitoraggio della convergenza</h2>
<p>Quando si eseguono catene di Markov, è importante assicurarsi che i campioni siano approssimativamente estratti dalla distribuzione a posteriori. Un modo standard per monitorare la convergenza è avviare più catene di Markov con inizializzazioni diverse (idealmente scelte da una distribuzione iniziale diffusa) e misurare se stanno producendo campioni dalla stessa distribuzione.</p>
<section id="riscaldamento" class="level3" data-number="44.7.1">
<h3 data-number="44.7.1" class="anchored" data-anchor-id="riscaldamento"><span class="header-section-number">44.7.1</span> Riscaldamento</h3>
<p>Nelle fasi iniziali del riscaldamento, Stan cerca di individuare la regione di alta probabilità da cui estrarre campioni, ottimizzare la dimensione del passo e stimare la varianza a posteriori. La varianza stimata viene utilizzata per migliorare l’efficienza del campionatore attraverso un processo noto come “precondizionamento”. Il precondizionamento implica il ridimensionamento dei parametri per rendere il campionamento più efficiente.</p>
<p>Stan è anche in grado di stimare una matrice di covarianza completa, che cattura le relazioni tra tutti i parametri del modello. Con l’ausilio di questa matrice, Stan può eseguire rotazioni e ridimensionamenti dei parametri, operazioni che facilitano un campionamento più efficace. Nel contesto di Stan, “rotazione e scalatura” si riferiscono alla trasformazione dei parametri in una nuova base (rotazione) e alla regolazione delle loro scale (scalatura), ottimizzando così il processo di campionamento e rendendolo più veloce e affidabile. Per un approfondimento su questi processi, si può consultare Neal (2011).</p>
<p>Il riscaldamento si considera concluso quando la dimensione del passo e le stime della covarianza a posteriori si stabilizzano. Con più catene, è possibile verificare che tutte convergano verso una dimensione del passo e una stima della covarianza simili. Di solito, non si misura la convergenza dell’adattamento in sé, ma piuttosto si valuta se i campioni a posteriori ottenuti dopo il riscaldamento sono ragionevoli.</p>
<p>Durante la fase di riscaldamento, Stan non produce una catena di Markov coerente poiché si adatta dinamicamente alle condizioni del modello per trovare i parametri di campionamento ottimali. Tuttavia, una volta completato il riscaldamento e avviata la fase di campionamento, Stan inizia a generare una vera e propria catena di Markov.</p>
<p>Le nostre analisi a posteriori si basano esclusivamente sui campioni raccolti durante la fase di campionamento, escludendo quelli ottenuti durante il riscaldamento. Tuttavia, è possibile salvare ed esaminare i campioni del riscaldamento per comprendere meglio come è avvenuto il processo di adattamento e identificare eventuali problematiche.</p>
</section>
<section id="riduzione-potenziale-della-scala-e-widehatr" class="level3" data-number="44.7.2">
<h3 data-number="44.7.2" class="anchored" data-anchor-id="riduzione-potenziale-della-scala-e-widehatr"><span class="header-section-number">44.7.2</span> Riduzione potenziale della scala e <span class="math inline">\(\widehat{R}\)</span></h3>
<p>Stan utilizza la statistica <em>di riduzione potenziale della scala</em>, nota come <span class="math inline">\(\widehat{R}\)</span> (pronunciata “R hat”), per valutare la convergenza delle catene di Markov. Questa statistica serve a verificare se le catene indipendenti stanno campionando dalla stessa distribuzione a posteriori.</p>
<p>Per calcolare <span class="math inline">\(\widehat{R}\)</span>, Stan esegue i seguenti passaggi:</p>
<ol type="1">
<li>Ogni catena di Markov viene divisa a metà per controllare la coerenza tra la prima metà e la seconda metà della catena. Questo consente di rilevare se la catena si è stabilizzata o se ci sono ancora problemi di convergenza.</li>
<li>Vengono calcolate due varianze:
<ul>
<li>La <em>varianza all’interno delle catene</em> (intra-chain variance), che misura la variabilità dei campioni all’interno di ciascuna metà della catena.</li>
<li>La <em>varianza tra le catene</em> (inter-chain variance), che misura la variabilità tra le diverse catene.</li>
</ul></li>
<li>La statistica <span class="math inline">\(\widehat{R}\)</span> confronta la varianza tra le catene con la varianza all’interno delle catene. Se le catene sono convergenti, ci si aspetta che queste varianze siano simili.</li>
</ol>
<p>Quando <span class="math inline">\(\widehat{R}\)</span> si avvicina a 1, indica che le catene di Markov stanno campionando dalla stessa distribuzione, suggerendo che la convergenza è stata raggiunta. Un valore di <span class="math inline">\(\widehat{R}\)</span> significativamente maggiore di 1, invece, indica che le catene non hanno ancora raggiunto la convergenza, suggerendo la necessità di un’ulteriore fase di riscaldamento o di una revisione del modello.</p>
</section>
<section id="quante-catene-per-quanto-tempo" class="level3" data-number="44.7.3">
<h3 data-number="44.7.3" class="anchored" data-anchor-id="quante-catene-per-quanto-tempo"><span class="header-section-number">44.7.3</span> Quante catene per quanto tempo?</h3>
<p>Una regola pratica per valutare la convergenza di una catena di Markov è eseguire quattro catene fino a quando <span class="math inline">\(\widehat{R}\)</span> non scende sotto 1.01 e la dimensione campionaria effettiva (ESS) supera 100. L’obiettivo di avere un ESS di almeno 100 è legato al fatto che, con questo numero di campioni, l’errore standard delle stime è ridotto a circa un decimo della deviazione standard. Dato che la deviazione standard a posteriori rappresenta l’incertezza residua, ottenere stime ancora più precise raramente aggiunge valore significativo.</p>
<p>Per raggiungere questi obiettivi, un metodo semplice è iniziare con 100 iterazioni di riscaldamento e 100 iterazioni di campionamento. Se <span class="math inline">\(\widehat{R}\)</span> è ancora troppo alto o se l’ESS è troppo basso, si può raddoppiare il numero di iterazioni di riscaldamento e di campionamento e riprovare. È importante avere un riscaldamento sufficientemente lungo perché un campionamento efficiente richiede che il modello abbia raggiunto la convergenza durante questa fase. Usare lo stesso numero di iterazioni per il riscaldamento e il campionamento potrebbe risultare in un costo computazionale massimo doppio rispetto all’ottimo, ma questo ottimo non è prevedibile in anticipo.</p>
<p>Se si decide di utilizzare più di quattro catene, è essenziale che l’ESS per ogni catena sia almeno 25. Questo requisito non è tanto per la qualità dell’inferenza quanto per garantire la fiducia nell’accuratezza dello stimatore ESS, che diventa inaffidabile con valori troppo bassi. Un modo per verificare la correttezza dello stimatore ESS è raddoppiare il numero di campioni e controllare se anche l’ESS raddoppia di conseguenza. Se ciò non accade, la stima iniziale dell’ESS potrebbe non essere accurata.</p>
</section>
<section id="esecuzione-delle-catene-contemporaneamente" class="level3" data-number="44.7.4">
<h3 data-number="44.7.4" class="anchored" data-anchor-id="esecuzione-delle-catene-contemporaneamente"><span class="header-section-number">44.7.4</span> Esecuzione delle catene contemporaneamente</h3>
<p>È possibile impostare il numero di catene da eseguire utilizzando l’argomento <code>chains</code> del metodo <code>sample()</code>. Inoltre, è possibile controllare quante catene possono essere eseguite contemporaneamente con l’argomento <code>parallel_cores</code> (che per default è impostato su 1, ovvero esecuzione sequenziale).</p>
<p>Se il numero massimo di catene parallele è impostato troppo basso, le risorse della CPU potrebbero non essere sfruttate appieno. Al contrario, se è impostato troppo alto, la CPU o la memoria potrebbero diventare il collo di bottiglia, rallentando le prestazioni complessive rispetto all’esecuzione con un numero inferiore di catene parallele.</p>
<p>In progetti personali sul nostro hardware, l’obiettivo è solitamente ottenere la massima dimensione campionaria effettiva nel minor tempo possibile. Tuttavia, a volte è necessario lasciare abbastanza potenza di elaborazione per continuare a lavorare su altre attività come documenti, email, ecc.</p>
</section>
</section>
<section id="considerazioni-conclusive" class="level2" data-number="44.8">
<h2 data-number="44.8" class="anchored" data-anchor-id="considerazioni-conclusive"><span class="header-section-number">44.8</span> Considerazioni Conclusive</h2>
<p>In conclusione, l’utilizzo di Stan per generare campioni casuali dalla distribuzione a posteriori dei parametri in un modello bayesiano rappresenta un potente strumento per l’inferenza statistica, specialmente quando ci si confronta con modelli complessi. La capacità di eseguire estrazioni indipendenti ci ha permesso di calcolare stime delle aspettative, fornendo un mezzo robusto per gestire l’incertezza nella stima dei parametri.</p>
<p>Il calcolo bayesiano, che integra intrinsecamente l’incertezza, si basa spesso su aspettative che si traducono in integrali difficili da risolvere analiticamente. Tuttavia, l’applicazione dei metodi Monte Carlo a catena di Markov (MCMC) consente di superare questa difficoltà, trasformando integrali complessi in somme di campioni generati dalle distribuzioni a posteriori. Questo approccio non solo rende il problema computazionalmente trattabile, ma apre anche la strada all’analisi di modelli che altrimenti sarebbero inaccessibili.</p>
<p>Come abbiamo visto nella sezione <a href="../appendix/a44_montecarlo.html" class="quarto-xref"><span>Appendice O</span></a>, anche problemi concettualmente semplici, come l’aspettativa di una variabile indicatrice discreta, possono essere risolti efficacemente tramite simulazioni Monte Carlo, dimostrando l’ampia applicabilità di questi metodi.</p>
<p>In definitiva, i metodi MCMC, e in particolare l’Hamiltonian Monte Carlo implementato in Stan, rappresentano una rivoluzione nell’inferenza bayesiana, permettendoci di affrontare con successo modelli complessi che sfuggono alle soluzioni analitiche tradizionali. Questo rende i metodi MCMC uno strumento essenziale per l’analisi statistica moderna, ampliando notevolmente le frontiere della ricerca e dell’applicazione pratica nella statistica bayesiana.</p>
</section>
<section id="esercizi" class="level2" data-number="44.9">
<h2 data-number="44.9" class="anchored" data-anchor-id="esercizi"><span class="header-section-number">44.9</span> Esercizi</h2>
<div id="exr-stan-beta-binomial-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 44.1</strong></span> Circa un decennio dopo la pubblicazione della regola di Bayes, Laplace sfruttò la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori nel contesto del modello beta-binomiale. A tale scopo, egli analizzò i dati relativi al sesso dei nati vivi a Parigi tra il 1745 e il 1770:</p>
<table class="table">
<thead>
<tr class="header">
<th>Sesso</th>
<th>Nati vivi</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Femmina</td>
<td>105287</td>
</tr>
<tr class="even">
<td>Maschio</td>
<td>110312</td>
</tr>
</tbody>
</table>
<p>Laplace si interrogò sulla possibilità che, sulla base di questi dati, la probabilità di nascita di un maschio, denotata con <span class="math inline">\(\theta\)</span>, fosse superiore a quella di una femmina. Si propone di risolvere il problema di Laplace utilizzando Stan, assumendo una distribuzione uniforme a priori per <span class="math inline">\(\theta\)</span>.</p>
</div>
</section>
<section id="informazioni-sullambiente-di-sviluppo" class="level2" data-number="44.10">
<h2 data-number="44.10" class="anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo"><span class="header-section-number">44.10</span> Informazioni sull’Ambiente di Sviluppo</h2>
<div id="cell-63" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-06-15T06:48:08.464793Z&quot;,&quot;start_time&quot;:&quot;2024-06-15T06:48:08.410689Z&quot;}" data-execution_count="33">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext watermark</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>watermark <span class="op">-</span>n <span class="op">-</span>u <span class="op">-</span>v <span class="op">-</span>iv <span class="op">-</span>w <span class="op">-</span>m <span class="op">-</span>p cmdstanpy</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Last updated: Thu Jul 25 2024

Python implementation: CPython
Python version       : 3.12.4
IPython version      : 8.26.0

cmdstanpy: 1.2.4

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.5.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

logging   : 0.5.1.2
pandas    : 2.2.2
cmdstanpy : 1.2.4
matplotlib: 3.9.1
arviz     : 0.18.0
numpy     : 1.26.4

Watermark: 2.4.3
</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/mcmc/01_metropolis.html" class="pagination-link" aria-label="Monte Carlo a Catena di Markov">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Monte Carlo a Catena di Markov</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/mcmc/03_stan_summary_posterior.html" class="pagination-link" aria-label="Metodi di sintesi della distribuzione a posteriori">
        <span class="nav-page-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Data Science per Psicologi è stato scritto da Corrado Caudek.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/mcmc/02_stan_beta_binomial.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro è stato realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>