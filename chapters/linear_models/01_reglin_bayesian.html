<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Corrado Caudek">

<title>Data Science per Psicologi - 53&nbsp; Modello bayesiano di regressione lineare bivariata</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/linear_models/02_beauty_sex_power.html" rel="next">
<link href="../../chapters/linear_models/introduction_linear_models.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/linear_models/introduction_linear_models.html">Modelli lineari</a></li><li class="breadcrumb-item"><a href="../../chapters/linear_models/01_reglin_bayesian.html"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Data Science per Psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/introduction_python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/00_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/01_python_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Python (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/02_python_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/03_numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/04_pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Pandas (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/05_pandas_aggregate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Pandas (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/06_pandas_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pandas (3)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/07_matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/08_seaborn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Seaborn</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">L’analisi dei dati psicologici</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_freq_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/03_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Misura di Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_on_general_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Distribuzioni di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_density_func.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">La funzione di densità di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Simulazioni</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">Inferenza bayesiana</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Modellazione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02a_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/06_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Modello Esponenziale</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Monte Carlo a Catena di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_stan_beta_binomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/03_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/04_stan_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/05_stan_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/06_stan_odds_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Analisi bayesiana dell’odds-ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_stan_normal_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/08_stan_two_groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/09_stan_hier_beta_binom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Modello gerarchico beta-binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/10_stan_poisson_model_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Modello di Poisson (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/11_stan_poisson_model_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Modello di Poisson (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/12_stan_gaussian_mixture.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Modelli Mistura Gaussiani</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Modelli lineari</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_bayesian.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_beauty_sex_power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Bellezza, sesso e potere</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Predizione e inferenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Disegno della ricerca e potere statistico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_stan_multreg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Regressione multipla con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_hier_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Il modello lineare gerarchico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_stan_mixed_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Modelli misti con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_specification_error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Errore di specificazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_causal_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Inferenza causale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/12_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Dati mancanti</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false">
 <span class="menu-text">GLM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/introduction_glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/01_robust_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Regressione robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/02_stan_binomial_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Regressione binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/03_stan_logistic_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/04_stan_poisson_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Regressione di Poisson con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/05_stan_rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">Incorporare dati storici di controllo in una RCT</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/06_stan_mediation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Modello di mediazione con Stan</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="false">
 <span class="menu-text">Modelli cognitivi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cognitive_models/introduction_cognitive_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cognitive_models/01_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false">
 <span class="menu-text">Entropia</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/introduction_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/01_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/02_kl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Divergenza KL e ELPD</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/03_stan_loo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Validazione Incrociata Leave-One-Out</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/04_inductive_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza induttiva</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false">
 <span class="menu-text">Inferenza frequentista</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Introduzione all’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Intervallo di confidenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false">
 <span class="menu-text">Crisi della replicazione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">La Crisi della Replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">Proposte di cambiamento</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../99-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" aria-expanded="false">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a00_installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Ambiente di lavoro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01_markdown.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a03_colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Colab: un breve tutorial</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a04_virtual_env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Ambienti virtuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a20_kde_plot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Kernel Density Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a30_prob_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">M</span>&nbsp; <span class="chapter-title">Esercizi di probabilità discreta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a40_rng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">N</span>&nbsp; <span class="chapter-title">Generazione di numeri casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a44_montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">O</span>&nbsp; <span class="chapter-title">Simulazione Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a45_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">P</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a46_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Q</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">R</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a51_r_squared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">S</span>&nbsp; <span class="chapter-title">Teorema della scomposizione della devianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a55_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">T</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a60_ttest_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">U</span>&nbsp; <span class="chapter-title">Esercizi sull’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a70_predict_counts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">V</span>&nbsp; <span class="chapter-title">La predizione delle frequenze</span></span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" aria-expanded="false">
 <span class="menu-text">Soluzioni degli esercizi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">W</span>&nbsp; <span class="chapter-title">Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">X</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Y</span>&nbsp; <span class="chapter-title">Causalità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_mult_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Z</span>&nbsp; <span class="chapter-title">Regressione multipla</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">\</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">]</span>&nbsp; <span class="chapter-title">Crisi della replicazione</span></span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione">Introduzione</a></li>
  <li><a href="#modellare-lassociazione-statistica-tra-variabili" id="toc-modellare-lassociazione-statistica-tra-variabili" class="nav-link" data-scroll-target="#modellare-lassociazione-statistica-tra-variabili"><span class="header-section-number">53.1</span> Modellare l’associazione statistica tra variabili</a></li>
  <li><a href="#minimi-quadrati" id="toc-minimi-quadrati" class="nav-link" data-scroll-target="#minimi-quadrati"><span class="header-section-number">53.2</span> Minimi Quadrati</a>
  <ul class="collapse">
  <li><a href="#interpretazione" id="toc-interpretazione" class="nav-link" data-scroll-target="#interpretazione"><span class="header-section-number">53.2.1</span> Interpretazione</a></li>
  </ul></li>
  <li><a href="#residui" id="toc-residui" class="nav-link" data-scroll-target="#residui"><span class="header-section-number">53.3</span> Residui</a>
  <ul class="collapse">
  <li><a href="#errore-standard-della-regressione" id="toc-errore-standard-della-regressione" class="nav-link" data-scroll-target="#errore-standard-della-regressione"><span class="header-section-number">53.3.1</span> Errore Standard della Regressione</a></li>
  <li><a href="#parametrizzazione-alternativa" id="toc-parametrizzazione-alternativa" class="nav-link" data-scroll-target="#parametrizzazione-alternativa"><span class="header-section-number">53.3.2</span> Parametrizzazione Alternativa</a></li>
  <li><a href="#derivazione-delle-stime-dei-minimi-quadrati" id="toc-derivazione-delle-stime-dei-minimi-quadrati" class="nav-link" data-scroll-target="#derivazione-delle-stime-dei-minimi-quadrati"><span class="header-section-number">53.3.3</span> Derivazione delle stime dei minimi quadrati</a></li>
  </ul></li>
  <li><a href="#metodo-della-massima-verosimiglianza" id="toc-metodo-della-massima-verosimiglianza" class="nav-link" data-scroll-target="#metodo-della-massima-verosimiglianza"><span class="header-section-number">53.4</span> Metodo della Massima Verosimiglianza</a></li>
  <li><a href="#coefficiente-di-determinazione" id="toc-coefficiente-di-determinazione" class="nav-link" data-scroll-target="#coefficiente-di-determinazione"><span class="header-section-number">53.5</span> Coefficiente di Determinazione</a></li>
  <li><a href="#modello-di-regressione-bayesiano" id="toc-modello-di-regressione-bayesiano" class="nav-link" data-scroll-target="#modello-di-regressione-bayesiano"><span class="header-section-number">53.6</span> Modello di Regressione Bayesiano</a>
  <ul class="collapse">
  <li><a href="#verosimiglianza" id="toc-verosimiglianza" class="nav-link" data-scroll-target="#verosimiglianza"><span class="header-section-number">53.6.1</span> Verosimiglianza</a></li>
  <li><a href="#distribuzioni-a-priori" id="toc-distribuzioni-a-priori" class="nav-link" data-scroll-target="#distribuzioni-a-priori"><span class="header-section-number">53.6.2</span> Distribuzioni a Priori</a></li>
  <li><a href="#distribuzioni-a-posteriori" id="toc-distribuzioni-a-posteriori" class="nav-link" data-scroll-target="#distribuzioni-a-posteriori"><span class="header-section-number">53.6.3</span> Distribuzioni a Posteriori</a></li>
  <li><a href="#codice-stan" id="toc-codice-stan" class="nav-link" data-scroll-target="#codice-stan"><span class="header-section-number">53.6.4</span> Codice Stan</a></li>
  </ul></li>
  <li><a href="#interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti" id="toc-interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti" class="nav-link" data-scroll-target="#interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti"><span class="header-section-number">53.7</span> Interpretare i coefficienti di regressione come confronti, non come effetti</a></li>
  <li><a href="#ricodifica-dei-dati" id="toc-ricodifica-dei-dati" class="nav-link" data-scroll-target="#ricodifica-dei-dati"><span class="header-section-number">53.8</span> Ricodifica dei dati</a></li>
  <li><a href="#distribuzioni-a-priori-sui-parametri" id="toc-distribuzioni-a-priori-sui-parametri" class="nav-link" data-scroll-target="#distribuzioni-a-priori-sui-parametri"><span class="header-section-number">53.9</span> Distribuzioni a Priori sui Parametri</a></li>
  <li><a href="#verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi" id="toc-verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi" class="nav-link" data-scroll-target="#verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi"><span class="header-section-number">53.10</span> Verifica della procedura di fitting del modello utilizzando una simulazione con dati fittizi</a></li>
  <li><a href="#il-paradosso-della-regressione-verso-la-media" id="toc-il-paradosso-della-regressione-verso-la-media" class="nav-link" data-scroll-target="#il-paradosso-della-regressione-verso-la-media"><span class="header-section-number">53.11</span> Il Paradosso della Regressione verso la Media</a></li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali"><span class="header-section-number">53.12</span> Commenti e considerazioni finali</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/linear_models/01_reglin_bayesian.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/linear_models/introduction_linear_models.html">Modelli lineari</a></li><li class="breadcrumb-item"><a href="../../chapters/linear_models/01_reglin_bayesian.html"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-bivariate-bayesian-regression" class="quarto-section-identifier"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Prerequisiti</strong></p>
<ul>
<li>Leggere <em>Regression and Other Stories</em> <span class="citation" data-cites="gelman2020regression">(<a href="../../99-references.html#ref-gelman2020regression" role="doc-biblioref">Gelman, Hill, e Vehtari 2020</a>)</span>.
<ul>
<li>Prestare particolare attenzione ai capitoli 6, “Background on Regression Modeling,” 7, “Linear Regression with a Single Predictor” e 8, “Fitting regression models”, che offrono una guida dettagliata al modello di regressione bivariato.</li>
</ul></li>
</ul>
<p><strong>Concetti e Competenze Chiave</strong></p>
<ul>
<li>Comprendere il significato del modello di regressione lineare bayesiano e le differenze rispetto al modello frequentista.</li>
<li>Interpretare le stime dei parametri in un contesto bayesiano e confrontarle con l’interpretazione dei parametri nell’approccio frequentista.</li>
<li>Capire il metodo dei minimi quadrati.</li>
<li>Capire il concetto di verosimiglianza per il modello di regressione.</li>
<li>Capire il codice Stan per il modello di regressione.</li>
<li>Comprendere il significato delle previsioni del modello di regressione nell’ambito bayesiano.</li>
<li>Capire e sapere interpretare il Posterior Predictive Check nel modello bayesiano.</li>
<li>Capire il concetto di regressione verso la media.</li>
</ul>
<p><strong>Preparazione del Notebook</strong></p>
<div id="cell-2" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:00:47.833443Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:00:46.436472Z&quot;}" data-execution_count="36">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython <span class="im">import</span> get_ipython</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>warnings.simplefilter(action<span class="op">=</span><span class="st">"ignore"</span>, category<span class="op">=</span><span class="pp">FutureWarning</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cmdstanpy</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>cmdstanpy.utils.get_logger().setLevel(logging.ERROR)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cmdstanpy <span class="im">import</span> CmdStanModel</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin <span class="im">as</span> pg</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>seed: <span class="bu">int</span> <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">map</span>(<span class="bu">ord</span>, <span class="st">"bayesian_bivariate_regression"</span>))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>rng: np.random.Generator <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>seed)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>sns.set_theme(palette<span class="op">=</span><span class="st">"colorblind"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">"arviz-darkgrid"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">"retina"</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the home directory</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>home_directory <span class="op">=</span> os.path.expanduser(<span class="st">"~"</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct the path to the Quarto project directory</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>project_directory <span class="op">=</span> os.path.join(home_directory, <span class="st">"_repositories"</span>, <span class="st">"psicometria"</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standardize(series):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Standardize a pandas series with n degrees of freedom"""</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (series <span class="op">-</span> series.mean()) <span class="op">/</span> series.std(ddof<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>I modelli lineari sono stati impiegati in molteplici contesti per lungo tempo. Come descritto da <span class="citation" data-cites="stigler1986">Stigler (<a href="../../99-references.html#ref-stigler1986" role="doc-biblioref">1986</a>)</span>, il metodo dei minimi quadrati, una tecnica per adattare una semplice regressione lineare, veniva già utilizzato nel XVIII secolo per affrontare problemi di analisi dei dati in astronomia. Ad esempio, questo metodo era impiegato per determinare il moto della Luna e per riconciliare i movimenti non periodici di Giove e Saturno. All’epoca, gli astronomi erano tra i primi a sentirsi a proprio agio nell’uso di tali metodi, poiché raccoglievano personalmente le loro osservazioni e sapevano che le condizioni di raccolta dei dati erano omogenee, anche se i valori osservati potevano differire. Questo contrastava con l’approccio più cauto delle scienze sociali, dove la riluttanza a combinare dati eterogenei ritardava l’adozione dei modelli lineari <span class="citation" data-cites="stigler1986">(<a href="../../99-references.html#ref-stigler1986" role="doc-biblioref">Stigler 1986</a>)</span>.</p>
<p>In questa sezione della dispensa, esploreremo due modelli statistici fondamentali: la regressione lineare bivariata e la regressione lineare multipla. Il primo modello considera una sola variabile esplicativa, mentre il secondo ne include diverse.</p>
<p>È cruciale sottolineare che i modelli statistici sono principalmente utilizzati per due scopi: inferenza e previsione. La previsione si limita a descrivere l’associazione tra le variabili, mentre l’inferenza mira a stabilire relazioni di causa-effetto attraverso l’uso del modello lineare. Mentre la previsione non è una tecnica controversa e può essere facilmente verificata sulla base della sua effettiva capacità di predire la variabile dipendente, l’uso della regressione per l’inferenza causale è molto più problematico. Esso richiede una profonda comprensione del fenomeno in esame e una progettazione sperimentale o quasi-sperimentale adeguata per giustificare le assunzioni necessarie.</p>
<p>Indipendentemente dall’approccio scelto, è fondamentale tenere presente che l’analisi di regressione è essenzialmente una forma di media ponderata. Di conseguenza, i risultati ottenuti riflettono inevitabilmente i bias e le peculiarità del dataset utilizzato.</p>
<p>Per ciascun modello, esamineremo due approcci distinti:</p>
<ol type="1">
<li>L’utilizzo delle funzioni di <code>pingouin</code>, particolarmente utile per l’analisi esplorativa dei dati (EDA) quando si necessita di risultati rapidi.</li>
<li>L’approccio bayesiano, ideale quando l’obiettivo principale è l’inferenza statistica.</li>
</ol>
</section>
<section id="modellare-lassociazione-statistica-tra-variabili" class="level2" data-number="53.1">
<h2 data-number="53.1" class="anchored" data-anchor-id="modellare-lassociazione-statistica-tra-variabili"><span class="header-section-number">53.1</span> Modellare l’associazione statistica tra variabili</h2>
<p>Per introdurre l’approccio bayesiano al modello di regressione, esamineremo un set di <a href="../../data/affect.csv">dati</a> che riguarda la relazione tra i punteggi di affect e arousal. I dati provengono da due studi condotti nel Personality, Motivation and Cognition Laboratory della Northwestern University, in cui sono stati utilizzati film per indurre stati affettivi <span class="citation" data-cites="rafaeli2006premature">(<a href="../../99-references.html#ref-rafaeli2006premature" role="doc-biblioref">Rafaeli e Revelle 2006</a>)</span>.</p>
<p>Qui ci concentreremo sull’associazione tra l’ansia di stato, considerata come variabile indipendente, e la scala di Tense Arousal del <em>Motivational State Questionnaire</em> (MSQ), considerata come variabile dipendente.</p>
<p>In precedenza, abbiamo applicato il modello normale a una singola variabile. Tuttavia, di solito siamo interessati a modellare come una variabile di esito sia associata a una variabile predittiva. Se esiste un’associazione statistica tra la variabile predittiva e la variabile di esito, possiamo utilizzarla per predire il risultato. Quando la variabile predittiva è incorporata nel modello in un modo specifico, otteniamo una regressione lineare.</p>
<p>I dati dell’esempio sono forniti di seguito.</p>
<div id="cell-6" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Definire il percorso del file CSV</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>file_path <span class="op">=</span> os.path.join(project_directory, <span class="st">"data"</span>, <span class="st">"affect.csv"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Leggere il file CSV in un DataFrame pandas</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(file_path)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Selezionare le colonne state1 e TA1</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> data[[<span class="st">"state1"</span>, <span class="st">"TA1"</span>]]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">state1</th>
<th data-quarto-table-cell-role="th">TA1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>41</td>
<td>11.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>26</td>
<td>5.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>31</td>
<td>8.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>28</td>
<td>8.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>47</td>
<td>12.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>L’associazione tra le due variabili, ansia di stato e Tense Arousal, è rappresentata nel grafico sottostante. Il grafico suggerisce che l’associazione può essere approssimata da una semplice funzione matematica, come una retta. Tuttavia, è evidente che una funzione lineare sia troppo semplicistica per rappresentare accuratamente questi dati, poiché non è possibile trovare una singola retta che passi per tutti i punti del diagramma di dispersione.</p>
<div id="cell-8" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:00:57.143715Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:00:57.000582Z&quot;}" data-execution_count="33">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">"state1"</span>], df[<span class="st">"TA1"</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"State Anxiety"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Tense Arousal"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_reglin_bayesian_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="minimi-quadrati" class="level2" data-number="53.2">
<h2 data-number="53.2" class="anchored" data-anchor-id="minimi-quadrati"><span class="header-section-number">53.2</span> Minimi Quadrati</h2>
<p>Ci poniamo il duplice obiettivo di identificare la retta che meglio si adatta ai dati del diagramma e di valutare la qualità di tale adattamento. In altre parole, vogliamo misurare quanto, in media, i punti del diagramma si discostano dalla retta trovata.</p>
<p>Nel modello di regressione lineare classica, espresso come <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + e_i\)</span>, i coefficienti <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> vengono stimati minimizzando la somma dei quadrati degli errori <span class="math inline">\(\epsilon_i\)</span>.</p>
<p>Possiamo utilizzare la funzione <code>linear_regression()</code> del pacchetto <code>pingouin</code> per calcolare i coefficienti del modello seguendo questo approccio:</p>
<div id="cell-10" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> df[<span class="st">"state1"</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"TA1"</span>]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>lm <span class="op">=</span> pg.linear_regression(x, y)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>lm.<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">names</th>
<th data-quarto-table-cell-role="th">coef</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">T</th>
<th data-quarto-table-cell-role="th">pval</th>
<th data-quarto-table-cell-role="th">r2</th>
<th data-quarto-table-cell-role="th">adj_r2</th>
<th data-quarto-table-cell-role="th">CI[2.5%]</th>
<th data-quarto-table-cell-role="th">CI[97.5%]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Intercept</td>
<td>1.56</td>
<td>1.25</td>
<td>1.25</td>
<td>0.22</td>
<td>0.52</td>
<td>0.52</td>
<td>-0.93</td>
<td>4.04</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>state1</td>
<td>0.27</td>
<td>0.03</td>
<td>9.14</td>
<td>0.00</td>
<td>0.52</td>
<td>0.52</td>
<td>0.21</td>
<td>0.33</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Recuperiamo i coefficienti <code>b0</code> e <code>b1</code> dall’oggetto <code>lm</code> creato da <code>linear_regression()</code>.</p>
<div id="cell-12" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> lm[<span class="st">"coef"</span>]  <span class="co"># Coefficienti</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>beta</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>0    1.555463
1    0.267071
Name: coef, dtype: float64</code></pre>
</div>
</div>
<div id="cell-13" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>b0 <span class="op">=</span> beta[<span class="dv">0</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> beta[<span class="dv">1</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo i valori predetti dal modello di regressione:</p>
<div id="cell-15" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> b0 <span class="op">+</span> b1 <span class="op">*</span> x</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>yhat</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>0     12.505379
1      8.499312
2      9.834668
3      9.033455
4     14.107806
        ...    
73    12.238308
74    17.579731
75     7.965170
76    10.368810
77    10.368810
Name: state1, Length: 78, dtype: float64</code></pre>
</div>
</div>
<p>I valori predetti <span class="math inline">\(\hat{y}\)</span> corrispondono alla retta di regressione:</p>
<div id="cell-17" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x, yhat)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Ansia di stato"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Tense Arousal, $</span><span class="ch">\\</span><span class="st">hat</span><span class="sc">{y}</span><span class="st">$"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"Retta di regressione"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_reglin_bayesian_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Aggiungiamo i dati osservati al grafico.</p>
<div id="cell-19" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x, yhat)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y, <span class="st">"x"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Ansia di stato"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Tense Arousal, $</span><span class="ch">\\</span><span class="st">hat</span><span class="sc">{y}</span><span class="st">$"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"Retta di regressione"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_reglin_bayesian_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="interpretazione" class="level3" data-number="53.2.1">
<h3 data-number="53.2.1" class="anchored" data-anchor-id="interpretazione"><span class="header-section-number">53.2.1</span> Interpretazione</h3>
<p>Il coefficiente <span class="math inline">\(\beta_0\)</span> indica il valore atteso della distribuzione condizionata <span class="math inline">\(p(y_i \mid x_i = 0)\)</span>. Nel caso presente, indica la media di Tense Arousal quando l’ansia di stato è uguale a 0. Ovviamente questa non è un’informazione di una qualche importanza pratica. Vedremo come migliorare l’interpretabilità dell’intercetta usando una parametrizzazione alternativa dei dati.</p>
<p>Il coefficiente <span class="math inline">\(\beta_1\)</span> indica il cambiamento del valore atteso della variabile dipendente quando la variabile indipendente aumenta di un’unità. Nel caso presente abbiamo che il punteggio di Tense Arousal aumenta in media di 0.27 punti quando l’ansia di stato aumenta di un punto. In una parametrizzazione alternativa, standardizzando la variabile indipendente, <span class="math inline">\(\beta_1\)</span> indicherebbe di quanto varia in media Tense Arousal quando l’ansia di stato aumenta di una deviazione standard.</p>
</section>
</section>
<section id="residui" class="level2" data-number="53.3">
<h2 data-number="53.3" class="anchored" data-anchor-id="residui"><span class="header-section-number">53.3</span> Residui</h2>
<p>Calcoliamo i residui</p>
<p><span class="math display">\[
e_i = y_i - \hat{y}_i
\]</span></p>
<div id="cell-22" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> y <span class="op">-</span> yhat</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La retta di regressine calcolata con il metodo della massima verosimiglianza ha le seguenti proprietà:</p>
<ul>
<li>il valore atteso dei residui è zero,</li>
<li>i residui sono incorrelati con i valori predetti.</li>
</ul>
<p>Valutiamo la media dei residui:</p>
<div id="cell-24" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>np.mean(e)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>2.1065770210836304e-15</code></pre>
</div>
</div>
<p>Calcoliamo la correlazione tra i residui <span class="math inline">\(e\)</span> e i valori predetti <span class="math inline">\(\hat{y}\)</span>:</p>
<div id="cell-26" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>np.corrcoef(e, yhat)[<span class="dv">0</span>, <span class="dv">1</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>3.7592426344877714e-16</code></pre>
</div>
</div>
<p>Il modello di regressione bivariato</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_i + e_i
\]</span></p>
<p>scompone la variabile dipendente <span class="math inline">\(y_i\)</span> in due componenti tra loro incorrelate, una componente deterministica</p>
<p><span class="math display">\[
\hat{y}_i = \beta_0 + \beta_1 x_i
\]</span></p>
<p>e una componente aleatoria</p>
<p><span class="math display">\[
e_i = y_i - \hat{y}_i.
\]</span></p>
<div id="cell-28" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"x"</span>] <span class="op">=</span> x</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"y"</span>] <span class="op">=</span> y</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"yhat"</span>] <span class="op">=</span> yhat</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"e"</span>] <span class="op">=</span> e</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"sum"</span>] <span class="op">=</span> df[<span class="st">"yhat"</span>] <span class="op">+</span> df[<span class="st">"e"</span>]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">yhat</th>
<th data-quarto-table-cell-role="th">e</th>
<th data-quarto-table-cell-role="th">sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>41</td>
<td>11.0</td>
<td>12.505379</td>
<td>-1.505379</td>
<td>11.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>26</td>
<td>5.0</td>
<td>8.499312</td>
<td>-3.499312</td>
<td>5.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>31</td>
<td>8.0</td>
<td>9.834668</td>
<td>-1.834668</td>
<td>8.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>28</td>
<td>8.0</td>
<td>9.033455</td>
<td>-1.033455</td>
<td>8.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>47</td>
<td>12.0</td>
<td>14.107806</td>
<td>-2.107806</td>
<td>12.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">73</td>
<td>40</td>
<td>13.0</td>
<td>12.238308</td>
<td>0.761692</td>
<td>13.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">74</td>
<td>60</td>
<td>20.0</td>
<td>17.579731</td>
<td>2.420269</td>
<td>20.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75</td>
<td>24</td>
<td>10.0</td>
<td>7.965170</td>
<td>2.034830</td>
<td>10.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">76</td>
<td>33</td>
<td>10.0</td>
<td>10.368810</td>
<td>-0.368810</td>
<td>10.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">77</td>
<td>33</td>
<td>6.0</td>
<td>10.368810</td>
<td>-4.368810</td>
<td>6.0</td>
</tr>
</tbody>
</table>

<p>78 rows × 5 columns</p>
</div>
</div>
</div>
</div>
<section id="errore-standard-della-regressione" class="level3" data-number="53.3.1">
<h3 data-number="53.3.1" class="anchored" data-anchor-id="errore-standard-della-regressione"><span class="header-section-number">53.3.1</span> Errore Standard della Regressione</h3>
<p>L’errore standard della regressione rappresenta la stima della deviazione standard dei residui nell’intera popolazione. Questo parametro può essere calcolato attraverso la formula:</p>
<p><span class="math display">\[
\hat{\sigma}_e = \sqrt{\frac{\sum_i (e_i - \bar{e})^2}{n-2}},
\]</span></p>
<p>dove $ {e} $ indica la media dei residui, che teoricamente è zero dato che si assume che la media degli errori sia zero.</p>
<p>Il denominatore “n-2” deriva dalla perdita di due gradi di libertà, necessaria per la stima dei due coefficienti, $ _0 $ (intercetta) e $ _1 $ (pendenza), che sono utilizzati per calcolare le stime previste $ _i = _0 + _1 x_i $. Questi gradi di libertà vengono sottratti perché ciascun parametro stimato consuma un grado di libertà dal totale disponibile.</p>
<p>Nel caso dell’esempio, la numerosità campionaria è</p>
<div id="cell-30" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>n</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>78</code></pre>
</div>
</div>
<p>L’errore standard della regressione diventa</p>
<div id="cell-32" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>np.sqrt(np.<span class="bu">sum</span>(e<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> (n <span class="op">-</span> <span class="dv">2</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>2.671556929795855</code></pre>
</div>
</div>
<p>Questo valore indica che, in media, nella popolazione la distanza tra i valori osservati e la retta di regressione è di 2.67 punti.</p>
<p>Come discusso da {cite}<code>gelman2020regression</code>, la radice quadrata media dei residui, $ _{i=1}^n (y_i - ( + x_i))^2 $, tende a sottostimare la deviazione standard <span class="math inline">\(\sigma\)</span> dell’errore nel modello di regressione. Questa sottostima è spesso il risultato di un sovradimensionamento, dato che i parametri <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> sono stimati utilizzando gli stessi <span class="math inline">\(n\)</span> punti dati usati anche per calcolare i residui.</p>
<p>La validazione incrociata rappresenta un approccio alternativo per valutare l’errore predittivo che evita alcuni dei problemi legati al sovradimensionamento. La versione più semplice della validazione incrociata è l’approccio leave-one-out, in cui il modello è adattato <span class="math inline">\(n\)</span> volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti <span class="math inline">\(n-1\)</span> punti dati, e utilizzando questo modello adattato per predire l’osservazione esclusa: - Per <span class="math inline">\(i = 1, \ldots, n\)</span>: - Adatta il modello <span class="math inline">\(y = a + bx + \text{errore}\)</span> ai <span class="math inline">\(n-1\)</span> punti dati <span class="math inline">\((x,y)_j, j \neq i\)</span>. Denomina i coefficienti di regressione stimati come <span class="math inline">\(\hat{a}_{-i}, \hat{b}_{-i}\)</span>. - Calcola il residuo validato incrociato, $ r_{} = y_i - (<em>{-i} + </em>{-i} x_i) $. - Calcola la stima di <span class="math inline">\(\sigma_{\text{CV}} = \frac{1}{n} \sum_{i=1}^n r_{\text{CV}}^2\)</span>.</p>
<p>Per fare un esempio, eseguiamo i passaggi sopra descritti per il modello che predice Tense Arousal dall’ansia di stato.</p>
<div id="cell-34" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inizializzazione di un modello di regressione lineare</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Array per salvare i residui cross-validated</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>residuals_cv <span class="op">=</span> []</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop per la validazione incrociata leave-one-out</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df)):</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dati di training escludendo l'i-esimo punto</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> df.loc[df.index <span class="op">!=</span> i, [<span class="st">"x"</span>]]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> df.loc[df.index <span class="op">!=</span> i, <span class="st">"y"</span>]</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dati di test</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    X_test <span class="op">=</span> df.loc[[i], [<span class="st">"x"</span>]]</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    y_test <span class="op">=</span> df.loc[i, <span class="st">"y"</span>]</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Addestramento del modello</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predizione sull'i-esimo punto</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcolo del residuo validato incrociato</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    residual_cv <span class="op">=</span> y_test <span class="op">-</span> y_pred[<span class="dv">0</span>]</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    residuals_cv.append(residual_cv<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo di sigma_cv</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>sigma_cv <span class="op">=</span> np.sqrt(np.mean(residuals_cv))</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Stima di σ_CV:"</span>, sigma_cv)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stima di σ_CV: 2.7114997423207527</code></pre>
</div>
</div>
<p>Nel caso dei dati analizzati, si osserva che la stima ottenuta attraverso la validazione incrociata è leggermente superiore rispetto a quella calcolata usando la formula $ _e = $. Questo incremento, sebbene minimo, riflette le differenze metodologiche tra i due approcci di stima dell’errore standard.</p>
</section>
<section id="parametrizzazione-alternativa" class="level3" data-number="53.3.2">
<h3 data-number="53.3.2" class="anchored" data-anchor-id="parametrizzazione-alternativa"><span class="header-section-number">53.3.2</span> Parametrizzazione Alternativa</h3>
<p>Per consentire una migliore interpretazione dell’intercetta, centriamo i valori della variabile indipendente.</p>
<div id="cell-37" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> df[<span class="st">"state1"</span>]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"TA1"</span>]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>xc <span class="op">=</span> x <span class="op">-</span> np.mean(x)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>np.mean(xc)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>-1.8219044506669234e-15</code></pre>
</div>
</div>
<p>Eseguiamo l’analisi di regressione.</p>
<div id="cell-39" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>lm2 <span class="op">=</span> pg.linear_regression(xc, y)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>lm2.<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">names</th>
<th data-quarto-table-cell-role="th">coef</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">T</th>
<th data-quarto-table-cell-role="th">pval</th>
<th data-quarto-table-cell-role="th">r2</th>
<th data-quarto-table-cell-role="th">adj_r2</th>
<th data-quarto-table-cell-role="th">CI[2.5%]</th>
<th data-quarto-table-cell-role="th">CI[97.5%]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Intercept</td>
<td>12.62</td>
<td>0.30</td>
<td>41.73</td>
<td>0.0</td>
<td>0.52</td>
<td>0.52</td>
<td>12.02</td>
<td>13.22</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>state1</td>
<td>0.27</td>
<td>0.03</td>
<td>9.14</td>
<td>0.0</td>
<td>0.52</td>
<td>0.52</td>
<td>0.21</td>
<td>0.33</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Notiamo che la stima della pendenza della retta di regressione è rimasta immutata, mentre cambia il coefficiente <span class="math inline">\(\beta_0\)</span>. Nel caso in cui la variabile indipendente sia centrata, il coefficiente <span class="math inline">\(\beta_0\)</span> rappresenta il valore atteso della variabile dipendente quando la variabile indipendente assume il suo valore medio.</p>
<p>Nel caso presente, il valore 12.62 indica la media di Tense Arousal quando l’ansia di stato assume il valore medio nel campione.</p>
<p>Adesso standardizziamo sia la variabile dipendente che la variabile indipendente.</p>
<div id="cell-41" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardizzazione</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>zx <span class="op">=</span> standardize(x)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>zy <span class="op">=</span> standardize(y)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-42" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.mean(zx), np.std(zx))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-2.049642507000289e-16 1.0</code></pre>
</div>
</div>
<div id="cell-43" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.mean(zy), np.std(zy))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-1.25255930983351e-16 1.0</code></pre>
</div>
</div>
<div id="cell-44" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>lm3 <span class="op">=</span> pg.linear_regression(zx, zy)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>lm3.<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">names</th>
<th data-quarto-table-cell-role="th">coef</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">T</th>
<th data-quarto-table-cell-role="th">pval</th>
<th data-quarto-table-cell-role="th">r2</th>
<th data-quarto-table-cell-role="th">adj_r2</th>
<th data-quarto-table-cell-role="th">CI[2.5%]</th>
<th data-quarto-table-cell-role="th">CI[97.5%]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Intercept</td>
<td>-0.00</td>
<td>0.08</td>
<td>-0.00</td>
<td>1.0</td>
<td>0.52</td>
<td>0.52</td>
<td>-0.16</td>
<td>0.16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>state1</td>
<td>0.72</td>
<td>0.08</td>
<td>9.14</td>
<td>0.0</td>
<td>0.52</td>
<td>0.52</td>
<td>0.57</td>
<td>0.88</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Dopo aver standardizzato entrambe le variabili, i coefficienti di regressione possono essere interpretati nel seguente modo:</p>
<ul>
<li><strong><span class="math inline">\(\beta_0\)</span> = 0</strong>: Questo si verifica perché la retta di regressione, calcolata attraverso il metodo dei minimi quadrati (ML), interseca il punto delle medie delle variabili standardizzate, ovvero <span class="math inline">\((\bar{X}, \bar{Y})\)</span>.</li>
<li><strong><span class="math inline">\(\beta_1\)</span></strong>: Rappresenta la variazione media della variabile dipendente, espressa in termini di deviazioni standard, per ogni aumento di una deviazione standard nella variabile indipendente.</li>
</ul>
</section>
<section id="derivazione-delle-stime-dei-minimi-quadrati" class="level3" data-number="53.3.3">
<h3 data-number="53.3.3" class="anchored" data-anchor-id="derivazione-delle-stime-dei-minimi-quadrati"><span class="header-section-number">53.3.3</span> Derivazione delle stime dei minimi quadrati</h3>
<p>L’approccio classico al modello di regresione fa uso del metodo dei minimi quadrati per trovare la retta che meglio si adatta a un insieme di dati. L’obiettivo è minimizzare la somma dei quadrati delle differenze (residui) tra i valori osservati e quelli predetti dal modello lineare.</p>
<p>Supponiamo di avere un insieme di dati <span class="math inline">\((x_i, y_i)\)</span>, dove <span class="math inline">\(i = 1, 2, \dots, n\)</span>. Il modello lineare si esprime come:</p>
<p><span class="math display">\[
y_i = \alpha + \beta x_i + \epsilon_i,
\]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> è l’intercetta,</li>
<li><span class="math inline">\(\beta\)</span> è il coefficiente angolare (pendenza),</li>
<li><span class="math inline">\(\epsilon_i\)</span> è il residuo, ossia l’errore associato al punto <span class="math inline">\(i\)</span>.</li>
</ul>
<p>Il metodo dei minimi quadrati mira a minimizzare la somma dei quadrati dei residui <span class="math inline">\(\epsilon_i\)</span>:</p>
<p><span class="math display">\[
S(\alpha, \beta) = \sum_{i=1}^n \epsilon_i^2 = \sum_{i=1}^n (y_i - (\alpha + \beta x_i))^2
\]</span></p>
<p>Geometricamente, trovare i valori di <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> che minimizzano la funzione <span class="math inline">\(S(\alpha, \beta)\)</span> significa trovare il punto in cui la funzione è piatta, ossia dove la sua pendenza è zero. Questo si fa calcolando le derivate parziali di <span class="math inline">\(S(\alpha, \beta)\)</span> rispetto a <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>, e ponendole uguali a zero:</p>
<p><span class="math display">\[
\frac{\partial S}{\partial \alpha} = 0 \quad \text{e} \quad \frac{\partial S}{\partial \beta} = 0.
\]</span></p>
<p>Risolvendo questo sistema di equazioni, si trovano le espressioni per <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\beta = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2},
\]</span></p>
<p><span class="math display">\[
\alpha = \bar{y} - \beta \bar{x},
\]</span></p>
<p>dove <span class="math inline">\(\bar{x}\)</span> e <span class="math inline">\(\bar{y}\)</span> sono le medie dei valori <span class="math inline">\(x_i\)</span> e <span class="math inline">\(y_i\)</span> rispettivamente.</p>
<p>Per chiarire, ora consideriamo il caso in cui i dati sono standardizzati. Quando i dati sono standardizzati (cioè <span class="math inline">\(x_i\)</span> e <span class="math inline">\(y_i\)</span> hanno media 0 e deviazione standard 1), l’intercetta <span class="math inline">\(\alpha\)</span> è 0, quindi il modello diventa:</p>
<p><span class="math display">\[
y_i = \beta x_i + \epsilon_i
\]</span></p>
<p>Di conseguenza, dobbiamo solo stimare <span class="math inline">\(\beta\)</span>.</p>
<p>Ecco come eseguire una simulazione in Python per questo caso:</p>
<div id="cell-47" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Serie di valori di beta tra 0 e 1</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>beta_values <span class="op">=</span> np.linspace(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo della somma dei quadrati dei residui (SSE) per ciascun valore di beta</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>SSE <span class="op">=</span> []</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> beta <span class="kw">in</span> beta_values:</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    residuals <span class="op">=</span> zy <span class="op">-</span> beta <span class="op">*</span> zx</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    SSE.append(np.<span class="bu">sum</span>(residuals<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertiamo SSE in un array numpy per maggiore facilità nella visualizzazione</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>SSE <span class="op">=</span> np.array(SSE)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>beta_true <span class="op">=</span> <span class="fl">0.72</span> <span class="co"># trovato da pingouin</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizzazione della curva SSE in funzione di beta</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>plt.plot(beta_values, SSE, label<span class="op">=</span><span class="st">"SSE vs Beta"</span>, color<span class="op">=</span><span class="st">"blue"</span>)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>plt.axvline(beta_true, color<span class="op">=</span><span class="st">"red"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, label<span class="op">=</span><span class="ss">f"Beta True = </span><span class="sc">{</span>beta_true<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Beta"</span>)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"SSE (Somma dei quadrati dei residui)"</span>)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Curva SSE in funzione di Beta"</span>)</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Troviamo il valore di beta che minimizza SSE</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>beta_min_index <span class="op">=</span> np.argmin(SSE)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>beta_min <span class="op">=</span> beta_values[beta_min_index]</span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Valore di beta stimato con la formula dei minimi quadrati: </span><span class="sc">{</span>beta_true<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Valore stimato di beta (minimo SSE): </span><span class="sc">{</span>beta_min<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_reglin_bayesian_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Valore di beta stimato con la formula dei minimi quadrati: 0.72
Valore stimato di beta (minimo SSE): 0.7232232232232232</code></pre>
</div>
</div>
</section>
</section>
<section id="metodo-della-massima-verosimiglianza" class="level2" data-number="53.4">
<h2 data-number="53.4" class="anchored" data-anchor-id="metodo-della-massima-verosimiglianza"><span class="header-section-number">53.4</span> Metodo della Massima Verosimiglianza</h2>
<p>Dopo aver discusso il metodo dei minimi quadrati, possiamo affrontare il metodo della massima verosimiglianza, che in molti casi porta agli stessi risultati ma con un approccio leggermente diverso.</p>
<section id="connessione-con-il-metodo-dei-minimi-quadrati" class="level4" data-number="53.4.0.1">
<h4 data-number="53.4.0.1" class="anchored" data-anchor-id="connessione-con-il-metodo-dei-minimi-quadrati"><span class="header-section-number">53.4.0.1</span> Connessione con il Metodo dei Minimi Quadrati</h4>
<p>Nel contesto della regressione lineare, se gli errori del modello sono indipendenti e distribuiti normalmente, cioè se <span class="math inline">\(y_i \sim \text{Normale}(\alpha + \beta x_i, \sigma^2)\)</span> per ogni <span class="math inline">\(i\)</span>, allora la stima dei parametri ottenuta con il metodo dei minimi quadrati coincide con quella ottenuta usando il metodo della massima verosimiglianza. Questo significa che i valori di <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> che minimizzano la somma dei quadrati degli errori residui sono anche quelli che massimizzano la probabilità di osservare i dati dati quei parametri.</p>
</section>
<section id="la-funzione-di-verosimiglianza" class="level4" data-number="53.4.0.2">
<h4 data-number="53.4.0.2" class="anchored" data-anchor-id="la-funzione-di-verosimiglianza"><span class="header-section-number">53.4.0.2</span> La Funzione di Verosimiglianza</h4>
<p>In un modello di regressione, la funzione di verosimiglianza è definita come la probabilità (o densità di probabilità) di osservare i dati effettivi in funzione dei parametri e dei predittori del modello. In altre parole, dato un insieme di parametri <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> e <span class="math inline">\(\sigma\)</span>, la funzione di verosimiglianza ci dice quanto è probabile osservare i dati <span class="math inline">\(y\)</span> dati quei parametri.</p>
<p>Matematicamente, la funzione di verosimiglianza per un modello di regressione lineare è espressa come:</p>
<p><span class="math display">\[
p(y|\alpha, \beta, \sigma, X) = \prod_{i=1}^{n} N(y_i|\alpha + \beta x_i, \sigma^2).
\]</span></p>
<p>Qui, <span class="math inline">\(N(\cdot|\cdot, \cdot)\)</span> rappresenta la funzione di densità della distribuzione normale.</p>
<p>Questa formula indica che la verosimiglianza totale è il prodotto delle densità di probabilità per ciascun punto dati <span class="math inline">\(y_i\)</span>, considerando che ogni <span class="math inline">\(y_i\)</span> segue una distribuzione normale con media <span class="math inline">\(\alpha + \beta x_i\)</span> e varianza <span class="math inline">\(\sigma^2\)</span>.</p>
</section>
<section id="minimizzare-i-residui-quadratici" class="level4" data-number="53.4.0.3">
<h4 data-number="53.4.0.3" class="anchored" data-anchor-id="minimizzare-i-residui-quadratici"><span class="header-section-number">53.4.0.3</span> Minimizzare i Residui Quadratici</h4>
<p>Un’analisi della funzione di verosimiglianza mostra che massimizzare questa funzione equivale a minimizzare la somma dei quadrati dei residui, proprio come si fa nel metodo dei minimi quadrati. Questo perché la funzione di densità normale <span class="math inline">\(N(y_i|\alpha + \beta x_i, \sigma^2)\)</span> ha un massimo quando il valore di <span class="math inline">\(y_i\)</span> è vicino alla media prevista <span class="math inline">\(\alpha + \beta x_i\)</span>, e il prodotto delle densità è massimizzato quando i residui sono minimi.</p>
</section>
<section id="differenza-nella-stima-di-sigma" class="level4" data-number="53.4.0.4">
<h4 data-number="53.4.0.4" class="anchored" data-anchor-id="differenza-nella-stima-di-sigma"><span class="header-section-number">53.4.0.4</span> Differenza nella Stima di <span class="math inline">\(\sigma\)</span></h4>
<p>C’è una piccola differenza nella stima della deviazione standard <span class="math inline">\(\sigma\)</span> tra i due metodi. Nel metodo della massima verosimiglianza, la stima di <span class="math inline">\(\sigma\)</span> viene calcolata come:</p>
<p><span class="math display">\[
\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} \left(y_i - (\hat{\alpha} + \hat{\beta} x_i)\right)^2
\]</span></p>
<p>In questo caso, il denominatore è <span class="math inline">\(n\)</span>, mentre nel metodo dei minimi quadrati il denominatore è <span class="math inline">\(n-2\)</span>, che riflette l’aggiustamento per i gradi di libertà.</p>
<p>In sintesi, il metodo della massima verosimiglianza trova i parametri che rendono i dati osservati i più probabili, dato il modello. Quando gli errori sono normalmente distribuiti, questo approccio porta agli stessi risultati del metodo dei minimi quadrati, ma con un’interpretazione basata sulla probabilità.</p>
</section>
</section>
<section id="coefficiente-di-determinazione" class="level2" data-number="53.5">
<h2 data-number="53.5" class="anchored" data-anchor-id="coefficiente-di-determinazione"><span class="header-section-number">53.5</span> Coefficiente di Determinazione</h2>
<p>I modelli lineari, sia quelli stimati con il metodo dei minimi quadrati che quelli ottenuti tramite massima verosimiglianza, permettono una decomposizione della varianza totale della variabile dipendente <span class="math inline">\(y\)</span> in due componenti indipendenti: la devianza spiegata e la devianza residua. Questa decomposizione deriva dal teorema della decomposizione della devianza, come descritto nell’<a href="../appendix/a51_r_squared.html" class="quarto-xref"><span>Appendice S</span></a>.</p>
<p>La <em>devianza spiegata</em> (DS) rappresenta la parte della varianza totale che è attribuibile al modello, ed è definita come:</p>
<p><span class="math display">\[
DS = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2,
\]</span></p>
<p>dove <span class="math inline">\(\hat{y}_i\)</span> è il valore predetto dal modello per l’osservazione <span class="math inline">\(i\)</span>, e <span class="math inline">\(\bar{y}\)</span> è la media delle osservazioni di <span class="math inline">\(y\)</span>.</p>
<p>La <em>devianza residua</em> (DR), invece, rappresenta la parte della varianza totale che non è spiegata dal modello, ovvero l’errore, ed è calcolata come:</p>
<p><span class="math display">\[
DR = \sum_{i=1}^n (y_i - \hat{y}_i)^2.
\]</span></p>
<p>La somma delle due componenti, ovvero la devianza spiegata e la devianza residua, è pari alla <em>devianza totale</em> (DT):</p>
<p><span class="math display">\[
DT = \sum_{i=1}^n (y_i - \bar{y})^2.
\]</span></p>
<p>Il <em>coefficiente di determinazione</em> <span class="math inline">\(R^2\)</span> è definito come il rapporto tra la devianza spiegata e la devianza totale:</p>
<p><span class="math display">\[
R^2 = \frac{DS}{DT}.
\]</span></p>
<p>Il coefficiente di determinazione <span class="math inline">\(R^2\)</span> fornisce una misura della proporzione della varianza totale di <span class="math inline">\(y\)</span> che viene spiegata dal modello di regressione. Un valore di <span class="math inline">\(R^2\)</span> vicino a 1 indica che il modello spiega una grande parte della variabilità osservata nei dati, mentre un valore vicino a 0 suggerisce che il modello spiega poco della variabilità della variabile dipendente.</p>
<p>Questo coefficiente è particolarmente utile per valutare l’adeguatezza di un modello lineare, permettendo di comprendere quanto del fenomeno studiato viene catturato dalle variabili indipendenti incluse nel modello. Tuttavia, è importante ricordare che un alto valore di <span class="math inline">\(R^2\)</span> non implica necessariamente che il modello sia il migliore in senso assoluto; altri fattori come la complessità del modello e la presenza di potenziali errori di specificazione devono essere considerati nella valutazione complessiva del modello.</p>
</section>
<section id="modello-di-regressione-bayesiano" class="level2" data-number="53.6">
<h2 data-number="53.6" class="anchored" data-anchor-id="modello-di-regressione-bayesiano"><span class="header-section-number">53.6</span> Modello di Regressione Bayesiano</h2>
<p>L’approccio bayesiano, a differenza del metodo dei minimi quadrati (o massimo della verosimiglianza), non si limita a cercare i parametri che meglio si adattano ai dati osservati secondo un criterio predefinito. Invece, integra questa stima con informazioni a priori sui parametri stessi, combinando la verosimiglianza dei dati con una distribuzione a priori che riflette le conoscenze o le ipotesi preesistenti sui parametri. Questo rende l’inferenza bayesiana un processo di aggiornamento delle credenze, in cui la distribuzione a posteriori dei parametri riassume la nostra conoscenza aggiornata dopo aver osservato i dati. A differenza dei minimi quadrati e della massima verosimiglianza, che forniscono delle stime puntuali, l’inferenza bayesiana produce distribuzioni a posteriori che descrivono la probabilità di ciascun valore dei parametri, data l’incertezza complessiva nel modello.</p>
<p>Nel contesto della relazione tra ansia di stato (<span class="math inline">\(x\)</span>) e Tense Arousal (<span class="math inline">\(y\)</span>), l’approccio bayesiano ci consente di modellare questa relazione attraverso un modello statistico lineare simile a quello utilizzato nel metodo dei minimi quadrati. Anche qui si assume che gli errori siano indipendenti tra loro, distribuiti normalmente con media zero e varianza costante <span class="math inline">\(\sigma^2\)</span>. Tuttavia, l’approccio bayesiano va oltre, permettendo di specificare distribuzioni a priori per i parametri del modello (<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, e <span class="math inline">\(\sigma\)</span>). Queste distribuzioni a priori rappresentano la nostra conoscenza iniziale sui parametri prima di osservare i dati.</p>
<p>Dopo aver osservato i dati, l’inferenza bayesiana utilizza il teorema di Bayes per aggiornare queste distribuzioni a priori e ottenere le distribuzioni a posteriori dei parametri. Queste distribuzioni a posteriori combinano l’informazione contenuta nei dati con le credenze iniziali, offrendo una stima dei parametri che riflette sia l’evidenza empirica che le conoscenze preesistenti.</p>
<section id="verosimiglianza" class="level3" data-number="53.6.1">
<h3 data-number="53.6.1" class="anchored" data-anchor-id="verosimiglianza"><span class="header-section-number">53.6.1</span> Verosimiglianza</h3>
<p>Il modello di verosimiglianza per descrivere la relazione tra <span class="math inline">\(x\)</span> (ansia di stato) e <span class="math inline">\(y\)</span> (Tense Arousal) assume che:</p>
<p><span class="math display">\[ y \sim \text{Normale}(\alpha + \beta x, \sigma) \]</span></p>
<p>Questo implica che i valori osservati di <span class="math inline">\(y\)</span> sono distribuiti normalmente attorno alla retta di regressione <span class="math inline">\(\alpha + \beta x\)</span>, con una deviazione standard <span class="math inline">\(\sigma\)</span>. In altre parole, ogni osservazione di <span class="math inline">\(y\)</span> è una combinazione lineare dell’intercetta <span class="math inline">\(\alpha\)</span>, del coefficiente <span class="math inline">\(\beta\)</span> che moltiplica la variabile <span class="math inline">\(x\)</span>, e di un termine di errore normalmente distribuito.</p>
</section>
<section id="distribuzioni-a-priori" class="level3" data-number="53.6.2">
<h3 data-number="53.6.2" class="anchored" data-anchor-id="distribuzioni-a-priori"><span class="header-section-number">53.6.2</span> Distribuzioni a Priori</h3>
<p>Per implementare l’approccio bayesiano, definiamo delle distribuzioni a priori per i parametri <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, e <span class="math inline">\(\sigma\)</span>. In una prima versione del modello, possiamo utilizzare delle distribuzioni a priori uniformi, che esprimono una mancanza di conoscenza specifica o una neutralità nelle credenze iniziali sui valori di questi parametri.</p>
</section>
<section id="distribuzioni-a-posteriori" class="level3" data-number="53.6.3">
<h3 data-number="53.6.3" class="anchored" data-anchor-id="distribuzioni-a-posteriori"><span class="header-section-number">53.6.3</span> Distribuzioni a Posteriori</h3>
<p>Le distribuzioni a posteriori sono ottenute combinando la verosimiglianza con le distribuzioni a priori mediante il teorema di Bayes. Queste distribuzioni a posteriori riflettono il nostro stato di conoscenza sui parametri dopo aver osservato i dati, incorporando sia le informazioni contenute nei dati che le credenze iniziali espresse dalle distribuzioni a priori. L’approccio bayesiano, quindi, non solo fornisce stime dei parametri, ma anche una quantificazione dell’incertezza associata a queste stime, rendendolo particolarmente utile in situazioni con dati limitati o incertezza significativa.</p>
<p>Questa metodologia ci permette di modellare e comprendere in modo più completo e robusto la relazione tra ansia di stato e Tense Arousal, integrando informazioni preesistenti con nuove evidenze empiriche.</p>
<p>In sintesi, il modello di regressione bayesiano può essere riassunto come segue. La verosimiglianza è data da:</p>
<p><span class="math display">\[
y_i \sim \text{Normal}(\alpha + \beta \cdot x_i, \sigma).
\]</span></p>
<p>In una prima formulazione del modello, possiamo utilizzare prior uniformi per ciascuno dei parametri <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> e <span class="math inline">\(\sigma\)</span>:</p>
<p><span class="math display">\[
\alpha \sim \text{Uniform}(-\infty, \infty),
\]</span> <span class="math display">\[
\beta \sim \text{Uniform}(-\infty, \infty),
\]</span> <span class="math display">\[
\sigma \sim \text{Uniform}(0, \infty).
\]</span></p>
</section>
<section id="codice-stan" class="level3" data-number="53.6.4">
<h3 data-number="53.6.4" class="anchored" data-anchor-id="codice-stan"><span class="header-section-number">53.6.4</span> Codice Stan</h3>
<p>Il codice Stan che implementa il modello descritto in precedenza è contenuto nel file <code>arousal_model_1.stan</code>. Compiliamo e stampiamo il modello.</p>
<div id="cell-51" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:01:06.728618Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:01:05.671604Z&quot;}" data-execution_count="20">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>stan_file <span class="op">=</span> os.path.join(project_directory, <span class="st">'stan'</span>, <span class="st">'arousal_model1.stan'</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model1.code())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=1&gt; N; // numero totale di osservazioni 
  vector[N] y; // variabile di risposta
  vector[N] x; // variabile predittore
}
parameters {
  real alpha; // intercetta
  real beta; // coefficiente angolare
  real&lt;lower=0&gt; sigma; // deviazione standard residua
}
model {
  // verosimiglianza
  y ~ normal(alpha + beta * x, sigma);
}
</code></pre>
</div>
</div>
<p>Si osservi che, in questa prima istanziazione del modello bayesiano, non avendo specificato le distribuzioni a priori per i parametri <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> e <span class="math inline">\(\sigma\)</span>, Stan assume distribuzioni a priori uniformi per questi parametri.</p>
<p>Sistemiamo i dati in un dizionario come richiesto dal modello Stan.</p>
<div id="cell-53" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:01:10.217268Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:01:10.214117Z&quot;}" data-execution_count="21">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>stan_data <span class="op">=</span> {</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"N"</span>: <span class="bu">len</span>(df[<span class="st">"TA1"</span>]),</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span>: df[<span class="st">"state1"</span>],</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span>: df[<span class="st">"TA1"</span>]</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stan_data)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'N': 78, 'x': 0     41
1     26
2     31
3     28
4     47
      ..
73    40
74    60
75    24
76    33
77    33
Name: state1, Length: 78, dtype: int64, 'y': 0     11.0
1      5.0
2      8.0
3      8.0
4     12.0
      ... 
73    13.0
74    20.0
75    10.0
76    10.0
77     6.0
Name: TA1, Length: 78, dtype: float64}</code></pre>
</div>
</div>
<p>Eseguiamo il campionamento MCMC.</p>
<div id="cell-55" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:01:14.524548Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:01:13.793216Z&quot;}" data-execution_count="22">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>fit1 <span class="op">=</span> model1.sample(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>stan_data,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">1_000</span>,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo le distribuzioni a posteriori dei parametri.</p>
<div id="cell-57" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:01:19.008797Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:01:17.795902Z&quot;}" data-execution_count="23">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> az.plot_trace(fit1, var_names<span class="op">=</span>([<span class="st">"alpha"</span>, <span class="st">"beta"</span>, <span class="st">"sigma"</span>]))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_reglin_bayesian_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Le tracce delle quattro catene indicano che sono ben mescolate e convergono verso una distribuzione stazionaria, segnalando una buona esplorazione dello spazio dei parametri. Questo è evidenziato dal fatto che le tracce non mostrano trend evidenti e oscillano intorno a un valore centrale, suggerendo che le catene hanno raggiunto l’equilibrio.</p>
<p>La forma della distribuzione a posteriori, visibile nei grafici a densità, appare approssimativamente gaussiana per ciascun parametro (<code>alpha</code>, <code>beta</code>, e <code>sigma</code>). Questo suggerisce che, dato il modello e i dati, le stime a posteriori sono stabili e ben definite, con una concentrazione delle probabilità attorno ai valori medi e una simmetria che riflette una distribuzione normale.</p>
<p>In sintesi, i grafici di traccia indicano una buona convergenza e una distribuzione a posteriori stabile e ben definita, rafforzando la fiducia nelle stime bayesiane ottenute.</p>
<p>L’oggetto <code>fit</code> generato da <code>cmdstanpy</code> appartiene alla classe <code>cmdstanpy.stanfit.mcmc.CmdStanMCMC</code>. Questo oggetto è funzionalmente equivalente a un oggetto della classe <code>InferenceData</code>, consentendo la sua manipolazione tramite le funzioni offerte da ArviZ. Procediamo quindi con l’esame di un sommario delle distribuzioni a posteriori dei parametri del modello lineare.</p>
<div id="cell-59" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:01:23.493778Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:01:23.419555Z&quot;}" data-execution_count="24">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>az.summary(fit1, var_names<span class="op">=</span>([<span class="st">"alpha"</span>, <span class="st">"beta"</span>, <span class="st">"sigma"</span>]), hdi_prob<span class="op">=</span><span class="fl">0.94</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha</td>
<td>1.552</td>
<td>1.256</td>
<td>-0.859</td>
<td>3.816</td>
<td>0.026</td>
<td>0.019</td>
<td>2395.0</td>
<td>2748.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">beta</td>
<td>0.267</td>
<td>0.029</td>
<td>0.213</td>
<td>0.323</td>
<td>0.001</td>
<td>0.000</td>
<td>2436.0</td>
<td>2858.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sigma</td>
<td>2.716</td>
<td>0.227</td>
<td>2.314</td>
<td>3.149</td>
<td>0.004</td>
<td>0.003</td>
<td>3410.0</td>
<td>3273.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<ul>
<li><p><strong>Alpha (Intercetta):</strong> La stima media di <code>alpha</code> è 1.552, con un intervallo di credibilità (HDI - Highest Density Interval) al 3% e 97% che va da -0.859 a 3.816. Questo significa che, date le informazioni disponibili e il modello specificato, c’è una probabilità del 94% che l’intercetta reale si trovi all’interno di questo intervallo. L’intercetta corrisponde al valore atteso di Tense Arousal quando l’ansia di stato vale 0.</p></li>
<li><p><strong>Beta (Coefficiente angolare):</strong> La stima media di <code>beta</code> è 0.267. Anche qui, l’intervallo di credibilità al 94% va da 0.213 a 0.323, suggerendo che è molto probabile che l’effetto del predittore <code>x</code> sulla variabile di risposta <code>y</code> sia positivo e compreso in questo intervallo. La pendenza <span class="math inline">\(\beta\)</span> ci informa sull’incremento atteso di Tense Arousal quando l’ansia di stato aumenta di un’unità.</p></li>
<li><p><strong>Sigma (Deviazione standard residua):</strong> La stima media di <code>sigma</code> è 2.716, con un intervallo di credibilità da 2.314 a 3.149. Questa è una misura della variabilità residua, ovvero la deviazione standard degli errori rispetto alla linea di regressione.</p></li>
</ul>
<p>La colonna <code>mean</code> dell’output riporta la media della distribuzione a posteriori di ciasccun parametro, mentre nella colonna <code>sd</code> troviamo una misura di dispersione della distribuzione a posteriori del parametro, ovvero la quantificazione dell’intertezza della stima a posteriori. In pratica è la deviazione standard della distribuzione a posteriori, ovvero la radice quadrata della varianza dei campioni della distribuzione a posteriori del parametro.</p>
<p>Supponiamo di avere <span class="math inline">\(S\)</span> campioni per il parametro <span class="math inline">\(\theta\)</span>. Questi campioni possono essere denotati come <span class="math inline">\(\theta_1, \theta_2, \dots, \theta_S\)</span>. La media campionaria (o stima puntuale bayesiana) del parametro <span class="math inline">\(\theta\)</span> si calcola come:</p>
<p><span class="math display">\[
\bar{\theta} = \frac{1}{S} \sum_{i=1}^{S} \theta_i.
\]</span></p>
<p>La deviazione standard della distribuzione a posteriori, che è ciò che è indicato con <code>sd</code>, si calcola come la radice quadrata della varianza campionaria dei campioni posteriori:</p>
<p><span class="math display">\[
\text{Var}(\theta) = \frac{1}{S-1} \sum_{i=1}^{S} (\theta_i - \bar{\theta})^2,
\]</span></p>
<p><span class="math display">\[
\text{sd}(\theta) = \sqrt{\text{Var}(\theta)}.
\]</span></p>
<p>In sintesi, <code>sd</code> è calcolato come la deviazione standard dei campioni ottenuti dalla distribuzione a posteriori di un parametro.</p>
<p>Le altre colonne sono le seguenti.</p>
<ul>
<li><p><strong>HDI (Intervallo di Massima Densità):</strong> Questo intervallo rappresenta la regione più densa dell’intera distribuzione a posteriori, contenente il 94% delle probabilità. È l’equivalente bayesiano dell’intervallo di confidenza, ma con un’interpretazione probabilistica diretta.</p></li>
<li><p><strong>R_hat:</strong> È un indicatore di convergenza per le catene di Markov Monte Carlo (MCMC). Un valore di <code>R_hat</code> prossimo a 1 segnala che la catena è probabilmente convergente, suggerendo che le stime a posteriori sono affidabili.</p></li>
<li><p><strong>ESS (Dimensione Campionaria Effettiva):</strong> Indica l’equivalente di un campione indipendente in un’analisi MCMC, valutando quanto efficacemente i campioni generati dalla catena rappresentano la distribuzione a posteriori.</p></li>
</ul>
<p>Infine, <code>mcse_mean</code> che <code>mcse_sd</code> sono misure che valutano la precisione delle stime ottenute tramite MCMC, quantificando quanto queste stime possono variare a causa della natura stocastica del processo di campionamento.</p>
<ul>
<li><p><strong>mcse_mean (Monte Carlo Standard Error of the Mean):</strong> Questo valore rappresenta l’errore standard Monte Carlo associato alla stima della media del parametro. In altre parole, <code>mcse_mean</code> quantifica l’incertezza introdotta dal processo di campionamento MCMC stesso. Un valore basso indica che la catena di Markov Monte Carlo ha fornito una stima della media del parametro con un’alta precisione.</p></li>
<li><p><strong>mcse_sd (Monte Carlo Standard Error of the Standard Deviation):</strong> Analogamente, <code>mcse_sd</code> è l’errore standard Monte Carlo associato alla stima della deviazione standard della distribuzione a posteriori del parametro. Questo valore misura l’incertezza nella stima della dispersione del parametro, dovuta al processo di campionamento MCMC. Anche qui, un valore basso indica che la stima della deviazione standard è stabile e precisa.</p></li>
</ul>
<p>Possiamo confrontare i valori ottenuti con l’approccio bayesiano con quelli trovati usando la procedura di massima verosimiglianza.</p>
<div id="cell-62" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:01:27.411444Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:01:27.372191Z&quot;}" data-execution_count="75">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>lm <span class="op">=</span> pg.linear_regression(df[<span class="st">"state1"</span>], df[<span class="st">"TA1"</span>])</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>lm.<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">names</th>
<th data-quarto-table-cell-role="th">coef</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">T</th>
<th data-quarto-table-cell-role="th">pval</th>
<th data-quarto-table-cell-role="th">r2</th>
<th data-quarto-table-cell-role="th">adj_r2</th>
<th data-quarto-table-cell-role="th">CI[2.5%]</th>
<th data-quarto-table-cell-role="th">CI[97.5%]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Intercept</td>
<td>1.56</td>
<td>1.25</td>
<td>1.25</td>
<td>0.22</td>
<td>0.52</td>
<td>0.52</td>
<td>-0.93</td>
<td>4.04</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>state1</td>
<td>0.27</td>
<td>0.03</td>
<td>9.14</td>
<td>0.00</td>
<td>0.52</td>
<td>0.52</td>
<td>0.21</td>
<td>0.33</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>La somiglianza tra le due soluzioni indica che, quando usiamo dei prior uniformi per i parametri, i due approcci producono risultati sostanzialmente equivalenti.</p>
<p>L’interpretazione del significato dei parametri è la stessa anche per l’approccio frequentista:</p>
<ul>
<li>L’intercetta rappresenta il valore atteso della variabile di risposta <code>TA1</code> quando il predittore <code>state1</code> è pari a zero.</li>
<li>Il coefficiente <code>beta</code> rappresenta la variazione attesa nella variabile di risposta <code>TA1</code> per ogni unità di incremento in <code>state1</code>.</li>
</ul>
<p>Ci sono però delle differenze sostanziali nell’interpretazione dell’incertezza associata alle stime dei parametri.</p>
<ul>
<li><strong>Stima Puntuale vs Distribuzione a Posteriori:</strong>
<ul>
<li><strong>Frequentista:</strong> Le stime di <code>alpha</code> e <code>beta</code> sono considerate come valori puntuali, ottenuti attraverso il metodo dei minimi quadrati. Gli errori standard associati a queste stime forniscono un’indicazione della variabilità delle stime se ripetessimo il campionamento molte volte.</li>
<li><strong>Bayesiano:</strong> Le stime di <code>alpha</code> e <code>beta</code> sono presentate come distribuzioni a posteriori. La media di queste distribuzioni può essere considerata la stima puntuale, ma l’intera distribuzione riflette la nostra incertezza attorno a queste stime, basata sia sui dati osservati che sulle informazioni a priori.</li>
</ul></li>
<li><strong>Intervallo di Confidenza vs Intervallo Credibile:</strong>
<ul>
<li><strong>Frequentista:</strong> L’intervallo di confidenza al 95% indica che, se ripetessimo l’esperimento molte volte, il 95% di tali intervalli conterrà il vero valore del parametro. Questo intervallo si basa sulla stima puntuale e sull’assunzione di distribuzione normale degli errori.</li>
<li><strong>Bayesiano:</strong> L’intervallo credibile al 94% (ad esempio l’HDI - Highest Density Interval) rappresenta la probabilità che il parametro si trovi entro quell’intervallo dato il modello, i dati osservati e le informazioni a priori. È un’intervallo che ha una diretta interpretazione probabilistica.</li>
</ul></li>
<li><strong>p-value vs Significato Bayesiano:</strong>
<ul>
<li><strong>Frequentista:</strong> Il p-value è utilizzato per testare l’ipotesi nulla che il coefficiente sia uguale a zero. Un p-value molto basso (come in questo caso per <code>beta</code>) suggerisce che c’è una forte evidenza contro l’ipotesi nulla.</li>
<li><strong>Bayesiano:</strong> In un’analisi bayesiana, non si fa riferimento a p-value; l’accento è posto sulla distribuzione a posteriori e sull’intervallo credibile, che forniscono una comprensione diretta dell’incertezza attorno ai parametri senza bisogno di test di ipotesi tradizionali.</li>
</ul></li>
</ul>
<p>In sintesi,</p>
<ul>
<li><p><strong>Interpretazione delle stime:</strong> Nell’approccio frequentista, le stime dei parametri sono valori puntuali accompagnati da un intervallo di confidenza che riflette la variabilità campionaria. Nell’approccio bayesiano, ogni parametro è rappresentato come una distribuzione a posteriori che incorpora sia i dati osservati sia le informazioni a priori.</p></li>
<li><p><strong>Gestione dell’incertezza:</strong> L’approccio frequentista usa errori standard e intervalli di confidenza, mentre l’approccio bayesiano utilizza l’intera distribuzione a posteriori per descrivere l’incertezza.</p></li>
<li><p><strong>Probabilità e significatività:</strong> Nell’approccio frequentista, il p-value è cruciale per determinare la significatività statistica, mentre nell’approccio bayesiano si utilizza l’intervallo credibile e la probabilità a posteriori per descrivere quanto è probabile un parametro dato i dati e le informazioni a priori.</p></li>
</ul>
</section>
</section>
<section id="interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti" class="level2" data-number="53.7">
<h2 data-number="53.7" class="anchored" data-anchor-id="interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti"><span class="header-section-number">53.7</span> Interpretare i coefficienti di regressione come confronti, non come effetti</h2>
<p><span class="citation" data-cites="gelman2021regression">Gelman, Hill, e Vehtari (<a href="../../99-references.html#ref-gelman2021regression" role="doc-biblioref">2021</a>)</span> sottolineano che i coefficienti di regressione sono spesso chiamati “effetti”, ma questa terminologia può essere fuorviante. Gli effetti, infatti, sono conseguenze di una relazione causale. Tuttavia, ciò che il modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, quello che viene osservato è che la media della variabile <span class="math inline">\(y\)</span> nella sottopopolazione con <span class="math inline">\(X = x + 1\)</span> è <span class="math inline">\(b\)</span> volte maggiore o minore (a seconda del segno di <span class="math inline">\(\beta\)</span>) rispetto alla media della sottopopolazione con <span class="math inline">\(X = x\)</span>.</p>
<p>La regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono essere sempre interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere derivata unicamente dall’uso del modello statistico.</p>
</section>
<section id="ricodifica-dei-dati" class="level2" data-number="53.8">
<h2 data-number="53.8" class="anchored" data-anchor-id="ricodifica-dei-dati"><span class="header-section-number">53.8</span> Ricodifica dei dati</h2>
<p>L’intercetta (<span class="math inline">\(\alpha\)</span>) rappresenta il valore atteso di Tense Arousal quando l’ansia di stato è pari a 0. Tuttavia, poiché l’ansia di stato è misurata su una scala ad intervalli, l’origine è arbitraria e non rappresenta l’assenza della proprietà. Lo stesso vale per la variabile Tense Arousal. Per entrambe le variabili, inoltre, anche l’unità di misura è arbitraria.</p>
<p>In queste circostanze, una trasformazione utile è la standardizzazione. La standardizzazione fa sì che il valore 0 corrisponda alla media campionaria e che l’unità di misura sia una deviazione standard.</p>
<p>Quando standardizziamo l’ansia di stato, il valore 0 della variabile standardizzata corrisponde alla media della variabile originale. Dato che la retta di regressione passa per il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span>, utilizzando i valori standardizzati di <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, la nuova intercetta (<span class="math inline">\(\alpha\)</span>) sarà 0. La pendenza (<span class="math inline">\(\beta\)</span>) avrà un’interpretazione utile: nel caso di dati standardizzati, la pendenza stima l’incremento (o decremento) atteso di <span class="math inline">\(y\)</span> quando <span class="math inline">\(x\)</span> aumenta di una deviazione standard.</p>
<div id="cell-66" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo della media e della deviazione standard di state1</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>mean_state1 <span class="op">=</span> np.mean(df[<span class="st">"state1"</span>])</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>std_state1 <span class="op">=</span> np.std(df[<span class="st">"state1"</span>])</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardizzazione </span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"state1_z"</span>] <span class="op">=</span> (df[<span class="st">"state1"</span>] <span class="op">-</span> mean_state1) <span class="op">/</span> std_state1</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo della media e della deviazione standard di TA1</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>mean_ta1 <span class="op">=</span> np.mean(df[<span class="st">"TA1"</span>])</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>std_ta1 <span class="op">=</span> np.std(df[<span class="st">"TA1"</span>])</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardizzazione </span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"ta1_z"</span>] <span class="op">=</span> (df[<span class="st">"TA1"</span>] <span class="op">-</span> mean_ta1) <span class="op">/</span> std_ta1</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_79156/3940630615.py:5: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df["state1_z"] = (df["state1"] - mean_state1) / std_state1
/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_79156/3940630615.py:11: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df["ta1_z"] = (df["TA1"] - mean_ta1) / std_ta1</code></pre>
</div>
</div>
<p>Creiamo il dizionario dei dati con le nuove variabli standardizzate.</p>
<div id="cell-68" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:02:28.616378Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:02:28.608697Z&quot;}" data-execution_count="26">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>stan_data2 <span class="op">=</span> {</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"N"</span>: <span class="bu">len</span>(df[<span class="st">"state1_z"</span>]), </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span>: df[<span class="st">"state1_z"</span>], </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span>: df[<span class="st">"ta1_z"</span>]</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo il campionamento.</p>
<div id="cell-70" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:02:32.624353Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:02:32.337744Z&quot;}" data-execution_count="27">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>fit2 <span class="op">=</span> model1.sample(</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>stan_data2,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">1_000</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>,</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo le distribuzioni a posteriori dei parametri.</p>
<div id="cell-72" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:02:35.265226Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:02:35.213028Z&quot;}" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>az.summary(fit2, var_names<span class="op">=</span>([<span class="st">"alpha"</span>, <span class="st">"beta"</span>, <span class="st">"sigma"</span>]), hdi_prob<span class="op">=</span><span class="fl">0.94</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha</td>
<td>0.000</td>
<td>0.081</td>
<td>-0.152</td>
<td>0.155</td>
<td>0.001</td>
<td>0.001</td>
<td>6678.0</td>
<td>5110.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">beta</td>
<td>0.723</td>
<td>0.082</td>
<td>0.571</td>
<td>0.879</td>
<td>0.001</td>
<td>0.001</td>
<td>7508.0</td>
<td>5666.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sigma</td>
<td>0.712</td>
<td>0.059</td>
<td>0.603</td>
<td>0.822</td>
<td>0.001</td>
<td>0.000</td>
<td>7985.0</td>
<td>5955.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Ora possiamo assegnare al parametro <span class="math inline">\(\beta\)</span> la seguente interpretazione: quando l’ansia di stato aumenta di una deviazione standard Tense Arousal aumenta, in media, di 0.72 deviazioni standard.</p>
</section>
<section id="distribuzioni-a-priori-sui-parametri" class="level2" data-number="53.9">
<h2 data-number="53.9" class="anchored" data-anchor-id="distribuzioni-a-priori-sui-parametri"><span class="header-section-number">53.9</span> Distribuzioni a Priori sui Parametri</h2>
<p>Nei modelli precedenti, abbiamo adottato distribuzioni a priori uniformi per i parametri <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> e <span class="math inline">\(\sigma\)</span>. Tuttavia, in generale, quando non disponiamo di informazioni pregresse sul valore dei parametri, è preferibile specificare distribuzioni debolmente informative. Queste distribuzioni sono progettate per essere centrate su un valore neutro, come lo zero, in modo tale da non influenzare in modo significativo la distribuzione a posteriori nella direzione “desiderata” dal ricercatore. L’obiettivo delle distribuzioni a priori debolmente informative è, infatti, quello di regolarizzare il modello, penalizzando le osservazioni più estreme e contribuendo a una stima più robusta dei parametri.</p>
<p>Per il caso in esame, specificheremo le seguenti distribuzioni a priori debolmente informative sui parametri del modello.</p>
<ol type="1">
<li><p><strong>Intercetta (<span class="math inline">\(\alpha\)</span>)</strong>:</p>
<ul>
<li><span class="math inline">\(\alpha \sim \text{Normale}(0, 1)\)</span></li>
<li>La scelta di una deviazione standard ampia (2) riflette l’incertezza riguardo al valore iniziale dell’intercetta. Si crede che l’intercetta possa essere qualsiasi valore vicino a 0, ma con una variazione significativa.</li>
</ul></li>
<li><p><strong>Coefficiente Angolare (<span class="math inline">\(\beta\)</span>)</strong>:</p>
<ul>
<li><span class="math inline">\(\beta \sim \text{Normale}(0, 2)\)</span></li>
<li>Un’ampia deviazione standard (2) per <span class="math inline">\(\beta\)</span> permette di incorporare l’incertezza riguardo all’influenza della temperatura sui ricavi del gelato. Questo prior permette che <span class="math inline">\(\beta\)</span> possa essere sia positivo che negativo con una vasta gamma di valori.</li>
</ul></li>
<li><p><strong>Deviazione Standard Residua (<span class="math inline">\(\sigma\)</span>)</strong>:</p>
<ul>
<li><span class="math inline">\(\sigma \sim \text{Cauchy}^+(0, 2)\)</span></li>
<li>La distribuzione Half-Cauchy è scelta perché è debolmente informativa e adatta per i parametri di scala come la deviazione standard residua. La scala di 2 consente a <span class="math inline">\(\sigma\)</span> di assumere una vasta gamma di valori positivi, riflettendo l’incertezza riguardo alla variabilità residua.</li>
</ul></li>
</ol>
<p>Le distribuzioni normali per <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> con deviazioni standard ampie permettono una grande flessibilità, mentre la distribuzione Half-Cauchy per <span class="math inline">\(\sigma\)</span> è scelta per la sua capacità di gestire bene i parametri di scala. Queste scelte garantiscono che il modello sia debolmente informativo, permettendo ai dati osservati di avere un’influenza predominante sulle stime posteriori dei parametri.</p>
<p>Compiliamo e stampiamo il modello Stan che include le specificazioni delle distribuzioni a priori dei parametri su elencate.</p>
<div id="cell-75" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:02:39.597858Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:02:39.459995Z&quot;}" data-execution_count="29">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>stan_file <span class="op">=</span> os.path.join(project_directory, <span class="st">"stan"</span>, <span class="st">"arousal_model_prior_raw.stan"</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model3.code())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=1&gt; N; // numero totale di osservazioni 
  vector[N] y; // variabile di risposta
  vector[N] x; // variabile predittore
}
parameters {
  real alpha; // intercetta
  real beta; // coefficiente angolare
  real&lt;lower=0&gt; sigma; // deviazione standard residua
}
model {
  // distribuzioni a priori
  alpha ~ normal(0, 2.5);
  beta ~ normal(0, 2.5);
  sigma ~ cauchy(0, 2.5);
  // verosimiglianza
  y ~ normal(alpha + beta * x, sigma);
}
</code></pre>
</div>
</div>
<p>Adattiamo il modello ai dati.</p>
<div id="cell-77" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:02:42.838670Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:02:42.566294Z&quot;}" data-execution_count="30">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>fit3 <span class="op">=</span> model3.sample(</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>stan_data2,</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">1_000</span>,</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>,</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo le distribuzioni a posteriori dei parametri.</p>
<div id="cell-79" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:02:45.375219Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:02:45.327353Z&quot;}" data-execution_count="31">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>az.summary(fit3, var_names<span class="op">=</span>([<span class="st">"alpha"</span>, <span class="st">"beta"</span>, <span class="st">"sigma"</span>]), hdi_prob<span class="op">=</span><span class="fl">0.94</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha</td>
<td>0.000</td>
<td>0.081</td>
<td>-0.147</td>
<td>0.155</td>
<td>0.001</td>
<td>0.001</td>
<td>6463.0</td>
<td>5733.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">beta</td>
<td>0.724</td>
<td>0.080</td>
<td>0.569</td>
<td>0.869</td>
<td>0.001</td>
<td>0.001</td>
<td>8212.0</td>
<td>6155.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sigma</td>
<td>0.710</td>
<td>0.058</td>
<td>0.605</td>
<td>0.825</td>
<td>0.001</td>
<td>0.000</td>
<td>7705.0</td>
<td>5931.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Si noti che, utilizzando distribuzioni a priori debolmente informative, le distribuzioni a posteriori dei parametri risultano molto simili a quelle ottenute usando distribuzioni uniformi. Tuttavia, le distribuzioni a priori debolmente informative sono preferibili poiché forniscono una maggiore stabilità numerica e sono generalmente più affidabili e robuste, specialmente quando si lavora con dati reali. L’uso di distribuzioni uniformi è sconsigliato per via delle possibili instabilità numeriche che possono introdurre nei modelli.</p>
</section>
<section id="verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi" class="level2" data-number="53.10">
<h2 data-number="53.10" class="anchored" data-anchor-id="verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi"><span class="header-section-number">53.10</span> Verifica della procedura di fitting del modello utilizzando una simulazione con dati fittizi</h2>
<p>L’esempio precedente è abbastanza semplice da permetterci di tracciare un grafico e vedere se la linea di regressione attraversa i punti. Tuttavia, in generale, è una buona pratica verificare l’adattamento del modello eseguendo la procedura in condizioni controllate, dove conosciamo la verità. Mostriamo questo approccio utilizzando il modello precedente.</p>
<p><strong>Passo 1: Creazione di un mondo fittizio.</strong></p>
<p>Iniziamo assumendo dei valori reali per tutti i parametri del modello. In questo caso, abbiamo già adattato un modello ai dati, quindi procediamo assumendo che questi particolari valori dei parametri siano la verità. In altre parole, assumiamo che la relazione <span class="math inline">\(y = 1.126 + 2.2x + \text{errore}\)</span> sia vera, con gli errori estratti da una distribuzione normale con media 0 e deviazione standard 2.688. Successivamente, utilizzando i valori predittori <span class="math inline">\(x\)</span> già presenti nel nostro dataset, esaminiamo se questi predittori generano una distribuzione di <span class="math inline">\(y\)</span> coerente con i valori osservati di <span class="math inline">\(y\)</span>.</p>
<div id="cell-82" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">1.126</span>   </span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="fl">0.277</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="fl">2.688</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> df[<span class="st">"state1"</span>]</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(x)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Passo 2: Simulazione di dati fittizi.</strong></p>
<p>Successivamente, simuleremo un vettore <span class="math inline">\(y\)</span> di dati fittizi e inseriremo tutto questo in un data frame:</p>
<div id="cell-84" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> a <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> np.random.normal(<span class="dv">0</span>, sigma, size<span class="op">=</span>n)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>fake <span class="op">=</span> pd.DataFrame({<span class="st">"x"</span>: x, <span class="st">"y"</span>: y})</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>fake.head()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>41</td>
<td>14.560092</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>26</td>
<td>10.537546</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>31</td>
<td>11.326387</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>28</td>
<td>8.181064</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>47</td>
<td>13.802861</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p><strong>Passo 3: Adattamento del modello e confronto tra i valori stimati e quelli assunti.</strong></p>
<p>Il passo successivo è adattare un modello di regressione a questi dati. Durante l’adattamento, non si fa alcun uso dei valori veri assunti di α, β e σ.</p>
<div id="cell-86" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>lm <span class="op">=</span> pg.linear_regression(fake[<span class="st">"x"</span>], fake[<span class="st">"y"</span>])</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>lm.<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">names</th>
<th data-quarto-table-cell-role="th">coef</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">T</th>
<th data-quarto-table-cell-role="th">pval</th>
<th data-quarto-table-cell-role="th">r2</th>
<th data-quarto-table-cell-role="th">adj_r2</th>
<th data-quarto-table-cell-role="th">CI[2.5%]</th>
<th data-quarto-table-cell-role="th">CI[97.5%]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Intercept</td>
<td>1.44</td>
<td>1.30</td>
<td>1.11</td>
<td>0.27</td>
<td>0.53</td>
<td>0.52</td>
<td>-1.15</td>
<td>4.03</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>x</td>
<td>0.28</td>
<td>0.03</td>
<td>9.17</td>
<td>0.00</td>
<td>0.53</td>
<td>0.52</td>
<td>0.22</td>
<td>0.34</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Le stime ottenute dai dati fittizzi sono molto simili a quelle ottenute con i dati veri.</p>
<p><strong>Passo 4: Inserire la simulazione in un loop.</strong></p>
<p>Per ottenere una stima dell’incertezza delle nostre stime, ripetiamo la simulazione molte volte e calcoliamo il livello di copertura dei parametri.</p>
<p>Il livello di copertura rappresenta la proporzione delle volte in cui l’intervallo di confidenza calcolato contiene il vero valore del parametro <span class="math inline">\(b\)</span>. In altre parole, se l’intervallo di confidenza al 68% (o 95%) è calcolato correttamente, ci aspetteremmo che, rispettivamente, il 68% (o 95%) di questi intervalli contenga il vero valore di <span class="math inline">\(b\)</span>.</p>
<ul>
<li><p>Il codice seguente esegue <code>n_fake = 10_000</code> simulazioni, ciascuna delle quali genera un set di dati fittizio e adatta un modello di regressione a questi dati.</p></li>
<li><p>I valori critici <code>t_68</code> e <code>t_95</code> sono calcolati utilizzando la funzione <code>t.ppf</code> di <code>scipy.stats</code>, che fornisce i quantili della distribuzione t di Student per il livello di confidenza desiderato:</p>
<ul>
<li><code>t_68</code> corrisponde al quantile dell’84%, che definisce l’intervallo di confidenza al 68%.</li>
<li><code>t_95</code> corrisponde al quantile del 97,5%, che definisce l’intervallo di confidenza al 95%.</li>
</ul></li>
<li><p>Per ogni simulazione (<code>s</code> da 0 a <code>n_fake - 1</code>):</p>
<ul>
<li>Vengono generati dati fittizi per la variabile indipendente <code>x</code> e per la variabile dipendente <code>y</code> usando i valori di <code>a</code>, <code>b</code>, e <code>sigma</code>.</li>
<li>Viene adattato un modello di regressione lineare ai dati fittizi usando la libreria <code>pingouin</code>.</li>
<li>Il coefficiente stimato <code>b_hat</code> e il suo errore standard <code>b_se</code> sono estratti dai risultati della regressione.</li>
<li>Viene verificato se il vero valore di <span class="math inline">\(b\)</span> si trova all’interno dell’intervallo <span class="math inline">\(b_hat \pm t_68 \times b_se\)</span>.
<ul>
<li><code>cover_68[s] = np.abs(b - b_hat) &lt; t_68 * b_se</code> memorizza <code>True</code> (1) se il vero valore di <span class="math inline">\(b\)</span> è all’interno dell’intervallo di confidenza al 68%, altrimenti <code>False</code> (0).</li>
</ul></li>
<li>Viene verificato se il vero valore di <span class="math inline">\(b\)</span> si trova all’interno dell’intervallo <span class="math inline">\(b_hat \pm t_95 \times b_se\)</span>.</li>
<li><code>cover_95[s] = np.abs(b - b_hat) &lt; t_95 * b_se</code> memorizza <code>True</code> (1) se il vero valore di <span class="math inline">\(b\)</span> è all’interno dell’intervallo di confidenza al 95%, altrimenti <code>False</code> (0).</li>
</ul></li>
</ul>
<p>Dopo aver completato tutte le simulazioni, i livelli di copertura sono calcolati come la media dei valori in <code>cover_68</code> e <code>cover_95</code>:</p>
<ul>
<li><code>cover_68.mean()</code> fornisce la proporzione di simulazioni in cui l’intervallo di confidenza al 68% ha contenuto il vero valore di <span class="math inline">\(b\)</span>.</li>
<li><code>cover_95.mean()</code> fornisce la proporzione di simulazioni in cui l’intervallo di confidenza al 95% ha contenuto il vero valore di <span class="math inline">\(b\)</span>.</li>
</ul>
<p>Se il risultato è vicino a 0.68, significa che l’intervallo di confidenza al 68% calcolato per ogni simulazione ha contenuto il vero valore di <span class="math inline">\(b\)</span> nel 68% delle simulazioni, come previsto teoricamente. Se il risultato è vicino a 0.95, significa che l’intervallo di confidenza al 95% calcolato per ogni simulazione ha contenuto il vero valore di <span class="math inline">\(b\)</span> nel 95% delle simulazioni, in linea con le aspettative teoriche.</p>
<p>Se i livelli di copertura risultano sostanzialmente inferiori ai valori teorici (68% e 95%), potrebbe indicare problemi nella stima degli intervalli di confidenza o nelle assunzioni del modello.</p>
<div id="cell-89" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> t</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri della simulazione</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>n_fake <span class="op">=</span> <span class="dv">10_000</span>  <span class="co"># numero di simulazioni</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Inizializzazione delle liste di copertura</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>cover_68 <span class="op">=</span> np.zeros(n_fake)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>cover_95 <span class="op">=</span> np.zeros(n_fake)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcola i valori critici t per il 68% e il 95% utilizzando scipy.stats.t.ppf</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>t_68 <span class="op">=</span> t.ppf(<span class="fl">0.84</span>, df<span class="op">=</span>n <span class="op">-</span> <span class="dv">2</span>)</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>t_95 <span class="op">=</span> t.ppf(<span class="fl">0.975</span>, df<span class="op">=</span>n <span class="op">-</span> <span class="dv">2</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Ciclo per la simulazione</span></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(n_fake):</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.random.normal(size<span class="op">=</span>n)</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> a <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> np.random.normal(<span class="dv">0</span>, sigma, size<span class="op">=</span>n)</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>    fake <span class="op">=</span> pd.DataFrame({<span class="st">"x"</span>: x, <span class="st">"y"</span>: y})</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit del modello usando pingouin</span></span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a>    fit <span class="op">=</span> pg.linear_regression(fake[[<span class="st">"x"</span>]], fake[<span class="st">"y"</span>])</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>    b_hat <span class="op">=</span> fit[<span class="st">"coef"</span>][<span class="dv">1</span>]</span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>    b_se <span class="op">=</span> fit[<span class="st">"se"</span>][<span class="dv">1</span>]</span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcolo della copertura</span></span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a>    cover_68[s] <span class="op">=</span> np.<span class="bu">abs</span>(b <span class="op">-</span> b_hat) <span class="op">&lt;</span> t_68 <span class="op">*</span> b_se</span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a>    cover_95[s] <span class="op">=</span> np.<span class="bu">abs</span>(b <span class="op">-</span> b_hat) <span class="op">&lt;</span> t_95 <span class="op">*</span> b_se</span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Output dei risultati</span></span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"68% coverage: </span><span class="sc">{</span>cover_68<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% coverage: </span><span class="sc">{</span>cover_95<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>68% coverage: 0.6798
95% coverage: 0.9462</code></pre>
</div>
</div>
<p>Si noti come la simulazione produce una copertura molto prossima a quella teorica. Ciò significa che, nel caso di questa analisi, possiamo assegnare agli intervalli di confidenza o credibilità l’interpretazione usuale. Se il livello di copertura della simulazione fosse stato inferiore a quello teorico (per modelli più complessi), allora questo sarebbe un’indicazione che si dovrebbero interpetare gli intervalli di confidenza o credibilità con cautela.</p>
</section>
<section id="il-paradosso-della-regressione-verso-la-media" class="level2" data-number="53.11">
<h2 data-number="53.11" class="anchored" data-anchor-id="il-paradosso-della-regressione-verso-la-media"><span class="header-section-number">53.11</span> Il Paradosso della Regressione verso la Media</h2>
<p>Il fenomeno della regressione verso la media è un concetto statistico importante, spesso frainteso e talvolta interpretato erroneamente come un effetto causale. Questo fenomeno fu osservato inizialmente da Galton in uno studio classico sull’ereditarietà dell’altezza.</p>
<p><span class="citation" data-cites="gelman2021regression">Gelman, Hill, e Vehtari (<a href="../../99-references.html#ref-gelman2021regression" role="doc-biblioref">2021</a>)</span> discutono questo fenomeno analizzando i dati pubblicati nel 1903 da Karl Pearson e Alice Lee. Applicando un modello di regressione lineare a questi dati, si ottiene la seguente equazione:</p>
<p><span class="math display">\[
y = 63.9 + 0.54(x − 62.5) + \text{errore},
\]</span></p>
<p>dove <span class="math inline">\(y\)</span> rappresenta l’altezza delle figlie e <span class="math inline">\(x\)</span> l’altezza delle madri. La variabile indipendente è stata centrata per evitare interpretazioni prive di senso dell’intercetta.</p>
<p>Il paradosso emerge dal coefficiente di regressione, che è inferiore a 1. Questo implica che:</p>
<ol type="1">
<li>Se una madre ha un’altezza nella media, si prevede che sua figlia adulta avrà anch’essa un’altezza nella media.</li>
<li>Per ogni pollice in più (o in meno) rispetto alla media dell’altezza materna, ci si aspetta che la figlia sia circa mezzo pollice più alta (o più bassa) rispetto alla media della sua generazione.</li>
</ol>
<p>Questo porta a una domanda apparentemente paradossale: se le madri alte tendono ad avere figlie solo leggermente alte, e le madri basse figlie solo leggermente basse, non significa che le figlie saranno più vicine alla media rispetto alle loro madri? E se questo processo continua, non dovremmo aspettarci che dopo poche generazioni tutti abbiano un’altezza vicina alla media?</p>
<p>La risoluzione di questo apparente paradosso sta nel fatto che la previsione dell’altezza di una donna è più vicina alla media rispetto all’altezza di sua madre, ma l’altezza effettiva non è la stessa cosa della previsione, che ha un margine di errore. Le previsioni puntuali regrediscono verso la media - ecco perché il coefficiente è inferiore a 1 - e questo riduce la variazione. Allo stesso tempo, però, l’errore nel modello - l’imperfezione della previsione - aggiunge variazione, sufficiente a mantenere la variazione totale dell’altezza approssimativamente costante da una generazione all’altra.</p>
<p>La regressione verso la media si verifica sempre in qualche forma quando le previsioni sono imperfette in un ambiente stabile. L’imperfezione della previsione induce variazione, e la regressione nella previsione puntuale è necessaria per mantenere costante la variazione totale.</p>
<p>Questo fenomeno è controintuitivo e spesso porta a interpretazioni causali errate. Per chiarire come ciò possa accadere, possiamo considerare uno scenario matematicamente equivalente: studenti che affrontano due esami. Coloro che ottengono punteggi alti nel primo esame tendono a ottenere risultati solo leggermente superiori alla media nel secondo; d’altra parte, chi ottiene punteggi bassi nel primo esame tende a migliorare leggermente, ottenendo risultati nel secondo esame che, pur restando inferiori alla media, non sono così bassi come i primi.</p>
<p>Potrebbe sembrare naturale dare a questo fenomeno una spiegazione causale, suggerendo che gli studenti che eccellono nel primo esame possano avere alte capacità ma poi, diventando troppo sicuri di sé, tendano a rilassarsi, con il risultato di non ripetere la stessa performance nel secondo. Dall’altro lato, si potrebbe ipotizzare che gli studenti con punteggi bassi nel primo esame siano motivati a impegnarsi di più, migliorando così i loro risultati nel secondo.</p>
<p>In realtà, il fenomeno della regressione verso la media si verifica anche in assenza di fattori motivazionali, come dimostrano simulazioni in cui sia il primo che il secondo esame sono determinati dalla vera abilità dell’individuo, più un elemento di rumore casuale. La regressione verso la media è un fenomeno puramente statistico, privo di una spiegazione causale intrinseca. Comprendere correttamente questo concetto è essenziale per evitare di trarre conclusioni errate dai dati.</p>
</section>
<section id="commenti-e-considerazioni-finali" class="level2" data-number="53.12">
<h2 data-number="53.12" class="anchored" data-anchor-id="commenti-e-considerazioni-finali"><span class="header-section-number">53.12</span> Commenti e considerazioni finali</h2>
<p>In questo capitolo abbiamo esplorato la stima dei parametri di un modello di regressione bivariato utilizzando l’approccio bayesiano. Questo percorso ci ha portato a riflettere sulla natura e sul ruolo dei modelli statistici nella ricerca scientifica, in particolare nel campo della psicologia.</p>
<p>Come sottolineato da <span class="citation" data-cites="alexander2023telling">Alexander (<a href="../../99-references.html#ref-alexander2023telling" role="doc-biblioref">2023</a>)</span>, è fondamentale comprendere che i modelli statistici non sono strumenti per scoprire una verità assoluta, ma piuttosto mezzi per esplorare e interpretare i dati a nostra disposizione. Questa prospettiva ci invita a considerare i modelli non come rappresentazioni perfette della realtà, ma come lenti attraverso le quali osserviamo e cerchiamo di comprendere il mondo che ci circonda.</p>
<p>L’affermazione di McElreath che “la regressione è in effetti un oracolo, ma un oracolo crudele. Parla per enigmi e si diletta nel punirci per aver posto domande sbagliate” <span class="citation" data-cites="McElreath_rethinking">(<a href="../../99-references.html#ref-McElreath_rethinking" role="doc-biblioref">McElreath 2020</a>)</span> mette in luce la natura complessa e talvolta insidiosa dell’uso dei modelli statistici. Questa metafora ci ricorda che l’applicazione dei modelli richiede non solo competenza tecnica, ma anche una profonda comprensione del contesto e una costante riflessione critica.</p>
<p>Nel processo di modellizzazione statistica, è cruciale considerare due dimensioni interconnesse: il “mondo del modello”, con le sue assunzioni e semplificazioni, e il “mondo reale”, caratterizzato da una complessità spesso difficile da catturare pienamente. Questa distinzione ci invita a riflettere costantemente sulla relazione tra il modello e la realtà che cerchiamo di comprendere, ponendoci domande sulla misura in cui il modello ci insegna qualcosa sui dati a disposizione e su quanto accuratamente questi dati riflettano la realtà oggetto del nostro studio.</p>
<p>L’evoluzione dei metodi statistici, dalle loro origini in campi come l’astronomia e l’agricoltura fino alle applicazioni moderne in psicologia, evidenzia la necessità di adattare e riconsiderare costantemente questi strumenti. Il lavoro pioneristico di Ronald Fisher, sviluppato in gran parte in un contesto di ricerca agricola, pone interrogativi sulla validità delle sue assunzioni fondamentali quando applicate alla psicologia contemporanea. <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="../../99-references.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> sottolinea l’importanza di sviluppare modelli basati su ipotesi relative ai meccanismi psicologici sottostanti al comportamento, suggerendo che questi possano offrire intuizioni più profonde rispetto a un approccio puramente descrittivo come quello della regressione lineare.</p>
<p>Nonostante queste considerazioni, il modello di regressione rimane uno strumento di grande valore per la psicologia. Tuttavia, il suo utilizzo efficace richiede un equilibrio tra una solida conoscenza del fenomeno oggetto di studio e la flessibilità necessaria per adattarsi a contesti di ricerca in continua evoluzione. Gli psicologi sono chiamati a considerare una gamma più ampia di strumenti statistici, cercando quelli più appropriati per descrivere i complessi fenomeni psicologici, superando i limiti di un approccio puramente descrittivo.</p>
<p>In conclusione, questo capitolo ci ha permesso di esplorare l’approccio bayesiano alla regressione, offrendo una prospettiva critica sull’uso dei modelli statistici in psicologia. Per un confronto più ampio, l’appendice presenta un’introduzione all’approccio frequentista per il modello di regressione lineare bivariato, consentendo di apprezzare le differenze tra i due metodi nella stima dei parametri e nell’interpretazione dei risultati. Per approfondimenti ulteriori, si consiglia la lettura di <em>Applied Regression Analysis and Generalized Linear Models</em> <span class="citation" data-cites="fox2015applied">(<a href="../../99-references.html#ref-fox2015applied" role="doc-biblioref">Fox 2015</a>)</span>, in particolare il capitolo 2, e, in italiano, <em>Statistica per psicologi</em> <span class="citation" data-cites="caudek2001statistica">(<a href="../../99-references.html#ref-caudek2001statistica" role="doc-biblioref">Caudek e Luccio 2001</a>)</span>.</p>
</section>
<section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div id="cell-94" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-07-13T07:03:16.259171Z&quot;,&quot;start_time&quot;:&quot;2024-07-13T07:03:16.203222Z&quot;}" data-execution_count="69">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext watermark</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>watermark <span class="op">-</span>n <span class="op">-</span>u <span class="op">-</span>v <span class="op">-</span>iv <span class="op">-</span>m  </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Last updated: Tue Jul 30 2024

Python implementation: CPython
Python version       : 3.12.4
IPython version      : 8.26.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.6.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

matplotlib: 3.9.1
arviz     : 0.18.0
cmdstanpy : 1.2.4
pandas    : 2.2.2
logging   : 0.5.1.2
pingouin  : 0.5.4
seaborn   : 0.13.2
numpy     : 1.26.4
</code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-alexander2023telling" class="csl-entry" role="listitem">
Alexander, Rohan. 2023. <em>Telling Stories with Data: With Applications in R</em>. Chapman; Hall/CRC.
</div>
<div id="ref-caudek2001statistica" class="csl-entry" role="listitem">
Caudek, Corrado, e Riccardo Luccio. 2001. <span>«Statistica per psicologi»</span>.
</div>
<div id="ref-fox2015applied" class="csl-entry" role="listitem">
Fox, John. 2015. <em>Applied regression analysis and generalized linear models</em>. Sage publications.
</div>
<div id="ref-gelman2020regression" class="csl-entry" role="listitem">
Gelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. <em>Regression and Other Stories</em>. Cambridge University Press.
</div>
<div id="ref-gelman2021regression" class="csl-entry" role="listitem">
———. 2021. <em>Regression and other stories</em>. Cambridge University Press.
</div>
<div id="ref-McElreath_rethinking" class="csl-entry" role="listitem">
McElreath, Richard. 2020. <em>Statistical rethinking: <span>A</span> <span>Bayesian</span> course with examples in <span>R</span> and <span>Stan</span></em>. 2nd Edition. Boca Raton, Florida: CRC Press.
</div>
<div id="ref-rafaeli2006premature" class="csl-entry" role="listitem">
Rafaeli, Eshkol, e William Revelle. 2006. <span>«A premature consensus: are happiness and sadness truly opposite affects?»</span> <em>Motivation and Emotion</em> 30: 1–12.
</div>
<div id="ref-stigler1986" class="csl-entry" role="listitem">
Stigler, Stephen. 1986. <em>The History of Statistics</em>. Massachusetts: Belknap Harvard.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/linear_models/introduction_linear_models.html" class="pagination-link" aria-label="Introduzione">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Introduzione</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/linear_models/02_beauty_sex_power.html" class="pagination-link" aria-label="Bellezza, sesso e potere">
        <span class="nav-page-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Bellezza, sesso e potere</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Data Science per Psicologi è stato scritto da Corrado Caudek.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/linear_models/01_reglin_bayesian.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro è stato realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>