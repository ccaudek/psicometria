<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Corrado Caudek">

<title>104&nbsp; Apprendimento per rinforzo – Data Science per Psicologi</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/dynamic_models/04_affect.html" rel="next">
<link href="../../chapters/dynamic_models/02_change_across_time.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/dynamic_models/introduction_dynamic_models.html">Dinamiche</a></li><li class="breadcrumb-item"><a href="../../chapters/dynamic_models/03_rescorla_wagner.html"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Data Science per Psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalità oscura"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/introduction_python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/00_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/01_python_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Python (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/02_python_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/03_numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/04_pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Pandas (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/05_pandas_aggregate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Pandas (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/06_pandas_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pandas (3)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/07_matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/python/08_seaborn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Seaborn</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/00_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Abbracciare l’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">L’analisi dei dati psicologici</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_data_cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Flusso di lavoro per la pulizia dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/03_dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Data tidying</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_exploring_qualitative_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Esplorare i dati qualitativi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_exploring_numeric_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Esplorare i dati numerici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/06_data_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Principi della visualizzazione dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Indicatori di tendenza centrale e variabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/08_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Relazioni tra variabili: correlazione e covarianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/09_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/10_estimand.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Estimandi teorici e estimandi empirici</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Misura di Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_on_general_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_density_func.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">La funzione di densità di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_qq_plot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Diagramma quantile-quantile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Simulazioni</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">La quantificazione dell’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/06_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_gamma_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Modello coniugato Gamma-Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/10_gamma_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Modello gamma-esponenziale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/11_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Monte Carlo a Catena di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_ppl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/03_stan_language.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/04_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/05_stan_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/06_stan_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Flusso di lavoro bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/08_stan_odds_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Analisi bayesiana dell’odds-ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/09_stan_normal_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/10_stan_two_groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/11_stan_poisson_model_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Modello di Poisson (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/12_stan_poisson_model_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Modello di Poisson (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/13_stan_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Modello esponenziale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/14_stan_gaussian_mixture.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Modelli Mistura Gaussiani</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/15_stan_nuisance_parameters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Modelli con più di un parametro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/16_stan_hier_beta_binom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Modello gerarchico beta-binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/17_stan_categorical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Modello categoriale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/18_cmdstanr_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Introduzione a CmdStanR</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/19_approximations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Metodi approssimativi nell’inferenza Bayesiana</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_non_centered_param.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Non-Centered Parameterization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_beauty_sex_power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Bellezza, sesso e potere</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Predizione e inferenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Disegno della ricerca e potere statistico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_linear_algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Elementi di algebra lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_stan_multreg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Il modello di regressione multipla</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_hier_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Il modello lineare gerarchico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_stan_mixed_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Modelli misti con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/12_specification_error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Errore di specificazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/14_interactions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Interazioni statistiche</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/16_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Dati mancanti</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Causalità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/causal_inference/01_rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Trial controllati randomizzati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/causal_inference/02_ate_att_atu.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">Concetti di ATE, ATT e ATU</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/causal_inference/03_endogenous_treatments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Inferenza causale con trattamenti endogeni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/causal_inference/04_mult_reg_causal_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Inferenza causale nella regressione multipla</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/causal_inference/05_collider_bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Collider bias</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">GLM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/introduction_glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/01_robust_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Regressione robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/02_stan_binomial_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">Modelli lineari generalizzati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/03_stan_logistic_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/04_stan_poisson_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">Regressione di Poisson con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/05_simchon_2023.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Tweets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/06_stan_rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Incorporare dati storici di controllo in una RCT</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/07_stan_mediation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">Modello di mediazione con Stan</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Entropia</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/introduction_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/01_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/02_kl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">96</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/03_model_comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">97</span>&nbsp; <span class="chapter-title">Divergenza KL, LPPD, ELPD e LOO-CV</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/04_loo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">98</span>&nbsp; <span class="chapter-title">Validazione Incrociata Leave-One-Out</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/05_regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">99</span>&nbsp; <span class="chapter-title">Regolarizzazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/06_cognitive_modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">100</span>&nbsp; <span class="chapter-title">Dall’analisi descrittiva alla modellazione cognitiva</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/07_inductive_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">101</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza induttiva</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Dinamiche</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/introduction_dynamic_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/01_canoeing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">102</span>&nbsp; <span class="chapter-title">Dinamiche post-errore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/02_change_across_time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">103</span>&nbsp; <span class="chapter-title">Modellare il cambiamento nel tempo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/03_rescorla_wagner.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/04_affect.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">105</span>&nbsp; <span class="chapter-title">Le emozioni influenzano le emozioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/05_sequential_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">106</span>&nbsp; <span class="chapter-title">Analisi dinamica delle sequenze di apprendimento</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/07_bipolar_disorder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">107</span>&nbsp; <span class="chapter-title">Modello di Markov nascosto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/dynamic_models/08_haslbeck.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">108</span>&nbsp; <span class="chapter-title">Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Modelli cognitivi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cognitive_models/introduction_cognitive_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/cognitive_models/01_ddm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">109</span>&nbsp; <span class="chapter-title">Drift Diffusion Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">110</span>&nbsp; <span class="chapter-title">Introduzione all’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">111</span>&nbsp; <span class="chapter-title">Intervallo di confidenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">112</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">113</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">114</span>&nbsp; <span class="chapter-title">La Crisi della Replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">115</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">116</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">117</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_p_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">118</span>&nbsp; <span class="chapter-title">La fragilità del <em>p</em>-valore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">119</span>&nbsp; <span class="chapter-title">Proposte di cambiamento</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/07_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">120</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../99-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a00_installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Ambiente di lavoro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01_markdown.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a03_colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Colab: un breve tutorial</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a04_virtual_env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Ambienti virtuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a20_kde_plot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Kernel Density Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a30_prob_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">M</span>&nbsp; <span class="chapter-title">Esercizi di probabilità discreta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a40_rng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">N</span>&nbsp; <span class="chapter-title">Generazione di numeri casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a44_montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">O</span>&nbsp; <span class="chapter-title">Simulazione Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a46_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">P</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a47_first_order_markov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Q</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a48_hidden_markov_processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">R</span>&nbsp; <span class="chapter-title">Processi di Markov Nascosti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">S</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a51_r_squared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">T</span>&nbsp; <span class="chapter-title">Teorema della scomposizione della devianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a53_entropy_rv_cont.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">U</span>&nbsp; <span class="chapter-title">Entropia di una variabile casuale continua</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a55_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">V</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a60_ttest_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">W</span>&nbsp; <span class="chapter-title">Esercizi sull’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a70_predict_counts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">X</span>&nbsp; <span class="chapter-title">La predizione delle frequenze</span></span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Soluzioni degli esercizi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Y</span>&nbsp; <span class="chapter-title">Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Z</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_mult_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">\</span>&nbsp; <span class="chapter-title">Regressione multipla</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">]</span>&nbsp; <span class="chapter-title">Modello Rescorla-Wagner</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">^</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/solutions_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">_</span>&nbsp; <span class="chapter-title">Crisi della replicazione</span></span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione">Introduzione</a></li>
  <li><a href="#note-storiche" id="toc-note-storiche" class="nav-link" data-scroll-target="#note-storiche"><span class="header-section-number">104.1</span> Note Storiche</a></li>
  <li><a href="#concetti-fondamentali" id="toc-concetti-fondamentali" class="nav-link" data-scroll-target="#concetti-fondamentali"><span class="header-section-number">104.2</span> Concetti Fondamentali</a></li>
  <li><a href="#modello-di-rescorla-wagner" id="toc-modello-di-rescorla-wagner" class="nav-link" data-scroll-target="#modello-di-rescorla-wagner"><span class="header-section-number">104.3</span> Modello di Rescorla-Wagner</a>
  <ul>
  <li><a href="#bilanciare-sfruttamento-ed-esplorazione-con-la-regola-softmax" id="toc-bilanciare-sfruttamento-ed-esplorazione-con-la-regola-softmax" class="nav-link" data-scroll-target="#bilanciare-sfruttamento-ed-esplorazione-con-la-regola-softmax"><span class="header-section-number">104.3.1</span> Bilanciare Sfruttamento ed Esplorazione con la Regola Softmax</a></li>
  <li><a href="#limitazioni-del-modello-di-rescorla-wagner" id="toc-limitazioni-del-modello-di-rescorla-wagner" class="nav-link" data-scroll-target="#limitazioni-del-modello-di-rescorla-wagner"><span class="header-section-number">104.3.2</span> Limitazioni del Modello di Rescorla-Wagner</a></li>
  </ul></li>
  <li><a href="#algoritmi-upper-confidence-bound-ucb-e-thompson-sampling" id="toc-algoritmi-upper-confidence-bound-ucb-e-thompson-sampling" class="nav-link" data-scroll-target="#algoritmi-upper-confidence-bound-ucb-e-thompson-sampling"><span class="header-section-number">104.4</span> Algoritmi Upper Confidence Bound (UCB) e Thompson Sampling</a>
  <ul>
  <li><a href="#upper-confidence-bound-ucb" id="toc-upper-confidence-bound-ucb" class="nav-link" data-scroll-target="#upper-confidence-bound-ucb"><span class="header-section-number">104.4.1</span> Upper Confidence Bound (UCB)</a></li>
  <li><a href="#thompson-sampling" id="toc-thompson-sampling" class="nav-link" data-scroll-target="#thompson-sampling"><span class="header-section-number">104.4.2</span> Thompson Sampling</a></li>
  </ul></li>
  <li><a href="#contextual-bandits" id="toc-contextual-bandits" class="nav-link" data-scroll-target="#contextual-bandits"><span class="header-section-number">104.5</span> Contextual Bandits</a>
  <ul>
  <li><a href="#il-protocollo-dei-contextual-bandits" id="toc-il-protocollo-dei-contextual-bandits" class="nav-link" data-scroll-target="#il-protocollo-dei-contextual-bandits"><span class="header-section-number">104.5.1</span> Il Protocollo dei Contextual Bandits</a></li>
  <li><a href="#modello-matematico" id="toc-modello-matematico" class="nav-link" data-scroll-target="#modello-matematico"><span class="header-section-number">104.5.2</span> Modello Matematico</a></li>
  <li><a href="#esempio-anoressia-nervosa" id="toc-esempio-anoressia-nervosa" class="nav-link" data-scroll-target="#esempio-anoressia-nervosa"><span class="header-section-number">104.5.3</span> Esempio: Anoressia Nervosa</a></li>
  <li><a href="#rigidità-cognitiva-e-difficoltà-di-rl-nellanoressia-nervosa" id="toc-rigidità-cognitiva-e-difficoltà-di-rl-nellanoressia-nervosa" class="nav-link" data-scroll-target="#rigidità-cognitiva-e-difficoltà-di-rl-nellanoressia-nervosa"><span class="header-section-number">104.5.4</span> Rigidità Cognitiva e Difficoltà di RL nell’Anoressia Nervosa</a></li>
  <li><a href="#contextual-bandits-nel-contesto-dellanoressia-nervosa" id="toc-contextual-bandits-nel-contesto-dellanoressia-nervosa" class="nav-link" data-scroll-target="#contextual-bandits-nel-contesto-dellanoressia-nervosa"><span class="header-section-number">104.5.5</span> Contextual Bandits nel Contesto dell’Anoressia Nervosa</a></li>
  </ul></li>
  <li><a href="#simulare-lapprendimento" id="toc-simulare-lapprendimento" class="nav-link" data-scroll-target="#simulare-lapprendimento"><span class="header-section-number">104.6</span> Simulare l’Apprendimento</a></li>
  <li><a href="#esempio-di-calcolo-della-softmax" id="toc-esempio-di-calcolo-della-softmax" class="nav-link" data-scroll-target="#esempio-di-calcolo-della-softmax"><span class="header-section-number">104.7</span> Esempio di Calcolo della Softmax</a></li>
  <li><a href="#simulazione-del-modello-di-rescorla-wagner" id="toc-simulazione-del-modello-di-rescorla-wagner" class="nav-link" data-scroll-target="#simulazione-del-modello-di-rescorla-wagner"><span class="header-section-number">104.8</span> Simulazione del Modello di Rescorla-Wagner</a></li>
  <li><a href="#adattamento-del-modello" id="toc-adattamento-del-modello" class="nav-link" data-scroll-target="#adattamento-del-modello"><span class="header-section-number">104.9</span> Adattamento del Modello</a>
  <ul>
  <li><a href="#sezione-data" id="toc-sezione-data" class="nav-link" data-scroll-target="#sezione-data"><span class="header-section-number">104.9.1</span> Sezione <code>data</code></a></li>
  <li><a href="#sezione-transformed-data" id="toc-sezione-transformed-data" class="nav-link" data-scroll-target="#sezione-transformed-data"><span class="header-section-number">104.9.2</span> Sezione <code>transformed data</code></a></li>
  <li><a href="#sezione-parameters" id="toc-sezione-parameters" class="nav-link" data-scroll-target="#sezione-parameters"><span class="header-section-number">104.9.3</span> Sezione <code>parameters</code></a></li>
  <li><a href="#sezione-model" id="toc-sezione-model" class="nav-link" data-scroll-target="#sezione-model"><span class="header-section-number">104.9.4</span> Sezione <code>model</code></a></li>
  <li><a href="#inferenza" id="toc-inferenza" class="nav-link" data-scroll-target="#inferenza"><span class="header-section-number">104.9.5</span> Inferenza</a></li>
  <li><a href="#interpretazione-delle-stime-dei-parametri" id="toc-interpretazione-delle-stime-dei-parametri" class="nav-link" data-scroll-target="#interpretazione-delle-stime-dei-parametri"><span class="header-section-number">104.9.6</span> Interpretazione delle Stime dei Parametri</a></li>
  </ul></li>
  <li><a href="#apprendimento-probabilistico-e-reversal-learning" id="toc-apprendimento-probabilistico-e-reversal-learning" class="nav-link" data-scroll-target="#apprendimento-probabilistico-e-reversal-learning"><span class="header-section-number">104.10</span> Apprendimento Probabilistico e Reversal Learning</a></li>
  <li><a href="#incertezza-attesa-vs.-incertezza-non-attesa" id="toc-incertezza-attesa-vs.-incertezza-non-attesa" class="nav-link" data-scroll-target="#incertezza-attesa-vs.-incertezza-non-attesa"><span class="header-section-number">104.11</span> Incertezza Attesa vs.&nbsp;Incertezza Non Attesa</a></li>
  <li><a href="#anomalie-dellapprendimento" id="toc-anomalie-dellapprendimento" class="nav-link" data-scroll-target="#anomalie-dellapprendimento"><span class="header-section-number">104.12</span> Anomalie dell’apprendimento</a></li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali"><span class="header-section-number">104.13</span> Commenti e considerazioni finali</a></li>
  <li><a href="#esercizi" id="toc-esercizi" class="nav-link" data-scroll-target="#esercizi"><span class="header-section-number">104.14</span> Esercizi</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/dynamic_models/03_rescorla_wagner.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/dynamic_models/introduction_dynamic_models.html">Dinamiche</a></li><li class="breadcrumb-item"><a href="../../chapters/dynamic_models/03_rescorla_wagner.html"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-rescorla-wagner" class="quarto-section-identifier"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Prerequisiti</strong></p>
<p>Il presente tutorial trae ispirazione dall’articolo di <a href="https://elifesciences.org/articles/49547">Wilson &amp; Collins (2019)</a> e utilizza il codice fornito da <a href="https://shawnrhoads.github.io/gu-psyc-347/index.html">Rhoads, S. A. &amp; Gan, L. (2022)</a>.</p>
<p><strong>Concetti e competenze chiave</strong></p>
<ul>
<li>Concetti di apprendimento associativo, agente, ambiente, azioni, ricompense, politica e valore Q.</li>
<li>Concetti di esplorazione/sfruttamento.</li>
<li>Regola softmax.</li>
<li>Politica <em>greedy</em> e suoi limiti.</li>
<li>Modello Rescorla-Wagner e sua implementazione in Stan.</li>
<li>Limitazioni degli algoritmi RL.</li>
</ul>
<p><strong>Preparazione del Notebook</strong></p>
<div id="cell-2" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:24:07.510911Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:24:07.488037Z&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard library imports</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Third-party imports</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cmdstanpy <span class="im">import</span> CmdStanModel</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">map</span>(<span class="bu">ord</span>, <span class="st">"rescorla_wagner"</span>))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>seed)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>sns.set_theme(palette<span class="op">=</span><span class="st">"colorblind"</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">"arviz-darkgrid"</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">"retina"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Define directories</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>home_directory <span class="op">=</span> os.path.expanduser(<span class="st">"~"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>project_directory <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>home_directory<span class="sc">}</span><span class="ss">/_repositories/psicometria"</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>Nel <a href="02_change_across_time.html" class="quarto-xref"><span>Capitolo 103</span></a> abbiamo introdotto l’approccio bayesiano per descrivere i processi dinamici. In questo capitolo, presenteremo un altro esempio di questo approccio implementando uno dei modelli psicologici dinamici più influenti: il modello di apprendimento di Rescorla-Wagner. Dopo una breve introduzione storica, esamineremo la definizione del modello, il significato dei suoi parametri e i metodi per stimarli dai dati osservati, con un focus particolare sull’uso del linguaggio di programmazione probabilistica Stan.</p>
</section>
<section id="note-storiche" class="level2" data-number="104.1">
<h2 data-number="104.1" class="anchored" data-anchor-id="note-storiche"><span class="header-section-number">104.1</span> Note Storiche</h2>
<p>Negli anni ’50, uno dei concetti fondamentali nell’intelligenza artificiale (AI) era quello dell’apprendimento per rinforzo, che sosteneva l’importanza di incoraggiare le azioni che avevano avuto successo in passato. Questo approccio ha portato allo sviluppo di algoritmi avanzati per il gioco. Nei decenni successivi, l’apprendimento per rinforzo ha visto un’evoluzione significativa, applicandosi con successo a giochi complessi come il Go e al controllo di sistemi robotici altamente sofisticati.</p>
<p>Un aspetto centrale dell’apprendimento per rinforzo è la capacità di bilanciare l’acquisizione di conoscenza sull’ambiente con l’azione all’interno di esso. Questo equilibrio rappresenta una sfida complessa, anche in situazioni in cui le azioni non comportano un cambiamento nell’ambiente stesso. Nel contesto del machine learning, il processo di esplorazione, ovvero compiere un’azione e osservarne l’effetto, è fondamentale per apprendere. Tuttavia, l’esplorazione comporta il rischio di non sfruttare un’azione che già si conosce come vantaggiosa. Esiste quindi un inevitabile compromesso tra l’esplorazione di nuove opzioni e lo sfruttamento di quelle già note.</p>
<p>Questo concetto di apprendimento basato sul bilanciamento tra esplorazione e sfruttamento trova un’interessante applicazione anche nel campo della psicologia, in particolare attraverso il modello di Rescorla-Wagner. Sviluppato negli anni ’70 da Robert Rescorla e Allan Wagner, questo modello è ampiamente utilizzato per spiegare come animali e esseri umani apprendano le associazioni tra stimoli e conseguenze delle azioni <span class="citation" data-cites="rescorla1972theory">(<a href="../../99-references.html#ref-rescorla1972theory" role="doc-biblioref">Rescorla e Wagner 1972</a>)</span>. Questo modello è alla base di molti approcci più recenti nell’apprendimento per rinforzo e nelle neuroscienze computazionali <span class="citation" data-cites="soto2023rescorla">(<a href="../../99-references.html#ref-soto2023rescorla" role="doc-biblioref">Soto et al. 2023</a>)</span>.</p>
<p>Il modello di Rescorla-Wagner si basa sull’idea che l’apprendimento avvenga in funzione della discrepanza tra ciò che un individuo si aspetta e ciò che effettivamente accade. In altre parole, l’apprendimento è guidato dall’errore di previsione: quando l’esito di una situazione differisce da ciò che ci si aspettava, le associazioni mentali tra gli eventi coinvolti vengono aggiornate. Il modello suggerisce che la forza dell’apprendimento dipende dall’intensità della sorpresa generata dall’esito osservato.</p>
<p>Per esempio, immagina di partecipare a un esperimento in cui, ogni volta che compi una specifica azione, si verifica un evento che ti sorprende. All’inizio, non ti aspetti che quell’evento segua l’azione, quindi apprendi rapidamente l’associazione tra l’azione e l’evento. Con il tempo, man mano che ti abitui a questa sequenza, l’apprendimento rallenta, perché diventi più bravo a prevedere l’esito e la sorpresa diminuisce.</p>
<p>Questo modello ha avuto un impatto significativo nello studio dell’apprendimento e continua a essere un punto di riferimento per comprendere i meccanismi attraverso i quali formiamo associazioni basate sulle nostre esperienze.</p>
</section>
<section id="concetti-fondamentali" class="level2" data-number="104.2">
<h2 data-number="104.2" class="anchored" data-anchor-id="concetti-fondamentali"><span class="header-section-number">104.2</span> Concetti Fondamentali</h2>
<p>Per comprendere l’apprendimento associativo, è importante introdurre alcuni concetti chiave che sono comunemente utilizzati nella letteratura sull’apprendimento per rinforzo.</p>
<p>Nell’apprendimento per rinforzo, immaginiamo un “agente” che interagisce con un “ambiente”, in modo simile a un giocatore che esplora un nuovo videogioco. L’agente esegue una serie di azioni per scoprire quali siano le migliori per ottenere la massima ricompensa. Questo processo si svolge in vari turni, durante i quali l’agente fa delle scelte e riceve feedback sotto forma di ricompense o punizioni <span class="citation" data-cites="sutton2018reinforcement">(<a href="../../99-references.html#ref-sutton2018reinforcement" role="doc-biblioref">Sutton e Barto 2018</a>)</span>.</p>
<p>Ad ogni turno, l’agente seleziona un’azione tra quelle disponibili. In uno scenario semplice, potrebbe dover scegliere tra due opzioni, come decidere tra due porte in un gioco. Dopo aver fatto la sua scelta, l’agente riceve un feedback, che può essere positivo o negativo, in base al risultato dell’azione intrapresa.</p>
<p>È importante notare che i feedback sono stocastici, ovvero non sono deterministici ma probabilistici: una stessa azione può portare a una ricompensa o a una punizione, in momenti differenti. I feedback vengono generati in base a una distribuzione probabilistica rappresentata come <span class="math inline">\(r_t \sim M^\star(\cdot | \pi_t)\)</span>, dove <span class="math inline">\(M^\star(\cdot | \pi_t)\)</span> è il modello che descrive il comportamento dell’ambiente in risposta alla politica <span class="math inline">\(\pi_t\)</span>.</p>
<p>Definiamo <span class="math inline">\(f(\pi) := \mathbb{E}[r | \pi]\)</span> come la funzione di ricompensa media sotto la distribuzione <span class="math inline">\(r \sim M^\star(\cdot | \pi)\)</span>. Ad esempio, un’azione <span class="math inline">\(A\)</span> potrebbe avere una probabilità dell’80% di portare a una ricompensa positiva e del 20% di portare a una punizione. Queste probabilità possono restare costanti nel tempo o variare in base all’esperienza accumulata.</p>
<p>Nel contesto dell’apprendimento per rinforzo, la “storia” <span class="math inline">\(\mathcal{H}^t\)</span> rappresenta la sequenza di tutte le azioni intraprese e dai feedback ricevuti fino al tempo <span class="math inline">\(t\)</span>. Formalmente, può essere espressa come <span class="math inline">\(\mathcal{H}^t = (\pi^1, r^1), \ldots, (\pi^t, r^t)\)</span>. Questa storia è essenziale perché fornisce un quadro completo del percorso di apprendimento dell’agente, aiutandolo a migliorare le sue decisioni nel tempo.</p>
<p>L’obiettivo principale dell’agente è quello di identificare le azioni che, in media, forniscono la ricompensa più alta. Per misurare l’efficacia delle scelte dell’agente, si utilizza il concetto di “regret” (rimpianto). Il regret misura la differenza tra la ricompensa che l’agente avrebbe potuto ottenere scegliendo sempre l’azione ottimale e la ricompensa effettivamente ottenuta con le sue scelte attuali.</p>
<p>Matematicamente, il regret (<span class="math inline">\(\text{Reg}\)</span>) è definito come la differenza cumulativa tra la ricompensa massima possibile (ottenuta scegliendo sempre la politica ottimale <span class="math inline">\(\pi^\star\)</span>) e la ricompensa media delle scelte effettuate:</p>
<p><span class="math display">\[
\text{Reg} := \sum_{t=1}^{T} \left(f^\star(\pi^\star) - \mathbb{E}[f(\pi^t)]\right).
\]</span></p>
<p>In questa formula, <span class="math inline">\(f^\star(\pi^\star)\)</span> rappresenta la ricompensa media massima ottenibile con la politica ottimale <span class="math inline">\(\pi^\star\)</span>, che massimizza la ricompensa media attesa. Ad esempio, se <span class="math inline">\(f^\star(A) = 0.75\)</span> e <span class="math inline">\(f^\star(B) = 0.25\)</span>, allora la politica ottimale <span class="math inline">\(\pi^\star\)</span> è quella che seleziona sempre l’azione <span class="math inline">\(A\)</span>, la quale offre la maggiore probabilità di ricompensa positiva.</p>
<p>La “politica” (<span class="math inline">\(\pi\)</span>) è un concetto cruciale nell’apprendimento per rinforzo. Essa rappresenta una strategia o regola che guida l’agente nella scelta delle azioni. Una politica potrebbe essere molto semplice, come scegliere sempre la stessa azione, oppure più complessa, basata su un’analisi approfondita delle informazioni disponibili.</p>
<p>Un approccio comune ma talvolta limitato è la strategia “greedy”, che sceglie sempre l’azione che sembra avere il valore atteso più alto basato sulle esperienze passate. Tuttavia, questo può portare l’agente a “bloccarsi” su un’azione che appare buona ma non è la migliore in assoluto, limitando così la sua capacità di scoprire opzioni potenzialmente migliori attraverso l’esplorazione.</p>
<p>Per superare questa limitazione, gli algoritmi avanzati cercano di bilanciare due aspetti fondamentali: <em>esplorazione</em> e <em>sfruttamento</em>. L’esplorazione implica provare nuove azioni per acquisire più informazioni, mentre lo sfruttamento si concentra sul selezionare le azioni che hanno fornito i migliori risultati finora. Questo dilemma tra esplorazione e sfruttamento è centrale nell’apprendimento per rinforzo e può essere paragonato alla decisione tra ordinare sempre il nostro piatto preferito al ristorante (sfruttamento) o provare qualcosa di nuovo (esplorazione).</p>
<p>Diverse tecniche sono state sviluppate per trovare un equilibrio ottimale tra esplorazione e sfruttamento, migliorando così la capacità dell’agente di apprendere nel tempo e di adattarsi a nuovi contesti.</p>
</section>
<section id="modello-di-rescorla-wagner" class="level2" data-number="104.3">
<h2 data-number="104.3" class="anchored" data-anchor-id="modello-di-rescorla-wagner"><span class="header-section-number">104.3</span> Modello di Rescorla-Wagner</h2>
<p>Il modello di Rescorla-Wagner propone che le scelte siano basate su ‘Q-values’, che approssimano la ricompensa attesa associata a ciascuna azione. Questi valori sono tipicamente calcolati applicando ripetutamente una regola di apprendimento incrementale che confronta l’esito effettivo con la sua stima precedente.</p>
<p>Nel modello, l’aspettativa di valore (cioè la ricompensa attesa) per un’azione scelta viene aggiornata secondo la seguente formula: <span class="math display">\[
Q(t+1) = Q(t) + \alpha (R(t) - Q(t)),
\]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(Q(t)\)</span> rappresenta il valore atteso o ‘Q-value’ al tempo <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(R(t)\)</span> è la ricompensa effettivamente ottenuta al tempo <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(\alpha\)</span> è il tasso di apprendimento (un valore tra 0 e 1).</li>
</ul>
<p>In questa formula, l’aggiornamento del valore atteso dipende dalla differenza tra la ricompensa osservata <span class="math inline">\(R(t)\)</span> e il valore atteso corrente <span class="math inline">\(Q(t)\)</span>, moltiplicata per il tasso di apprendimento <span class="math inline">\(\alpha\)</span>.</p>
<p>Possiamo riarrangiare la formula precedente per rendere più chiaro il ruolo del tasso di apprendimento:</p>
<p><span class="math display">\[
Q(t+1) = (1 - \alpha)Q(t) + \alpha R(t).
\]</span></p>
<p>Questa forma dell’equazione mostra che il valore aggiornato <span class="math inline">\(Q(t+1)\)</span> è una media pesata tra l’informazione nuova derivata dall’osservazione recente <span class="math inline">\(R(t)\)</span> e l’informazione precedente sotto forma di valore atteso attuale <span class="math inline">\(Q(t)\)</span>. Il tasso di apprendimento <span class="math inline">\(\alpha\)</span> agisce come un peso che determina l’influenza delle nuove osservazioni rispetto alle credenze precedenti.</p>
<p>Possiamo descrivere il funzionamento del modello nel modo seguente.</p>
<ol type="1">
<li>L’agente ha un’aspettativa iniziale <span class="math inline">\(Q(t)\)</span> riguardo alla ricompensa associata a uno stimolo o a un’azione.</li>
<li>L’agente sperimenta lo stimolo o compie l’azione, ricevendo una ricompensa effettiva <span class="math inline">\(R(t)\)</span>.</li>
<li>La differenza tra la ricompensa attesa e quella ottenuta <span class="math inline">\((R(t) - Q(t))\)</span> costituisce l’errore di previsione.</li>
<li>Questo errore viene moltiplicato per il tasso di apprendimento <span class="math inline">\(\alpha\)</span> per determinare l’aggiornamento dell’aspettativa.</li>
<li>L’aspettativa di valore per il prossimo turno viene aggiornata secondo la formula <span class="math inline">\(Q(t+1) = (1 - \alpha)Q(t) + \alpha R(t)\)</span>.</li>
</ol>
<p>In sintesi, il modello di Rescorla-Wagner descrive come le aspettative di ricompensa vengono aggiornate sulla base dell’errore di previsione. Se la ricompensa ottenuta <span class="math inline">\(R(t)\)</span> è maggiore del valore previsto <span class="math inline">\(Q(t)\)</span>, il valore atteso <span class="math inline">\(Q(t)\)</span> aumenta. Se la ricompensa è minore del previsto, il valore atteso diminuisce. La velocità con cui questi aggiornamenti avvengono è regolata dal tasso di apprendimento <span class="math inline">\(\alpha\)</span>.</p>
<section id="bilanciare-sfruttamento-ed-esplorazione-con-la-regola-softmax" class="level3" data-number="104.3.1">
<h3 data-number="104.3.1" class="anchored" data-anchor-id="bilanciare-sfruttamento-ed-esplorazione-con-la-regola-softmax"><span class="header-section-number">104.3.1</span> Bilanciare Sfruttamento ed Esplorazione con la Regola Softmax</h3>
<p>Il modello di Rescorla-Wagner, da solo, non prevede un meccanismo per bilanciare direttamente lo sfruttamento (ossia scegliere l’azione con il valore atteso più alto) e l’esplorazione (ossia provare nuove azioni per ottenere maggiori informazioni). Per integrare questo equilibrio nel processo decisionale, si può utilizzare la <em>regola softmax</em>, che è una strategia di selezione delle azioni che bilancia sfruttamento ed esplorazione in base alle probabilità.</p>
<p>La formula della regola softmax è la seguente:</p>
<p><span class="math display">\[
P(\pi_k) = \frac{e^{Q_k(t) / \tau}}{\sum_{j} e^{Q_j(t) / \tau}},
\]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(P(\pi_k)\)</span> è la probabilità di selezionare l’azione <span class="math inline">\(k\)</span>,</li>
<li><span class="math inline">\(Q_k(t)\)</span> è il valore atteso dell’azione <span class="math inline">\(k\)</span> al tempo <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(\tau\)</span> è il parametro di temperatura che controlla il grado di esplorazione: un valore alto di <span class="math inline">\(\tau\)</span> aumenta l’esplorazione (le probabilità sono più uniformemente distribuite tra le azioni), mentre un valore basso di <span class="math inline">\(\tau\)</span> favorisce lo sfruttamento (una maggiore probabilità di scegliere l’azione con il valore atteso più alto).</li>
</ul>
<p>L’integrazione del modello di Rescorla-Wagner con la regola softmax può essere descritta nel modo seguente:</p>
<ol type="1">
<li><strong>Aggiornamento dei Valori Attesi:</strong> Dopo ogni turno, l’agente aggiorna i valori attesi <span class="math inline">\(Q_k(t)\)</span> per tutte le azioni <span class="math inline">\(k\)</span> utilizzando il modello di Rescorla-Wagner basato sull’errore di previsione.</li>
<li><strong>Calcolo delle Probabilità di Selezione:</strong> Le probabilità di selezione per ciascuna azione vengono calcolate utilizzando la regola softmax.</li>
<li><strong>Selezione dell’Azione:</strong> L’agente sceglie un’azione <span class="math inline">\(\pi_k\)</span> in modo probabilistico, in base alle probabilità <span class="math inline">\(P(\pi_k)\)</span> determinate dalla regola softmax.</li>
</ol>
<p>In sintesi, il modello di Rescorla-Wagner viene utilizzato per aggiornare continuamente le aspettative di valore basate sull’errore di previsione. La regola softmax, invece, viene utilizzata per determinare quale azione scegliere, bilanciando la necessità di sfruttare le azioni con il valore atteso più alto e di esplorare nuove possibilità per migliorare l’apprendimento futuro.</p>
<p>Questa combinazione consente all’agente di apprendere in modo adattivo e iterativo, migliorando la sua capacità di prendere decisioni ottimali nel tempo.</p>
</section>
<section id="limitazioni-del-modello-di-rescorla-wagner" class="level3" data-number="104.3.2">
<h3 data-number="104.3.2" class="anchored" data-anchor-id="limitazioni-del-modello-di-rescorla-wagner"><span class="header-section-number">104.3.2</span> Limitazioni del Modello di Rescorla-Wagner</h3>
<p>Nonostante la sua ampia applicabilità, il modello di Rescorla-Wagner presenta alcune limitazioni nel descrivere fenomeni complessi dell’apprendimento associativo, come il blocco retrospettivo e l’apprendimento latente.</p>
<ul>
<li><p><strong>Blocco retrospettivo:</strong> È un fenomeno in cui l’apprendimento di una nuova associazione tra uno stimolo e una conseguenza può essere inibito se uno stimolo già noto è associato alla stessa conseguenza. Ad esempio, se un agente ha imparato che uno stimolo A predice una ricompensa e successivamente gli viene presentato uno stimolo composto AB seguito dalla stessa ricompensa, l’agente potrebbe non apprendere l’associazione tra B e la ricompensa.</p></li>
<li><p><strong>Apprendimento latente:</strong> Riguarda l’acquisizione di conoscenze che non si manifestano immediatamente nel comportamento. Per esempio, un agente che esplora un labirinto senza ricompense apparenti può sembrare non imparare nulla. Tuttavia, quando viene introdotta una ricompensa, l’agente dimostra rapidamente di aver appreso la struttura del labirinto.</p></li>
</ul>
<p>Il modello di Rescorla-Wagner, che si basa esclusivamente sull’errore di previsione immediato, non è in grado di spiegare completamente questi fenomeni. Modelli più avanzati cercano di superare queste limitazioni mantenendo la semplicità e l’eleganza del modello originale.</p>
</section>
</section>
<section id="algoritmi-upper-confidence-bound-ucb-e-thompson-sampling" class="level2" data-number="104.4">
<h2 data-number="104.4" class="anchored" data-anchor-id="algoritmi-upper-confidence-bound-ucb-e-thompson-sampling"><span class="header-section-number">104.4</span> Algoritmi Upper Confidence Bound (UCB) e Thompson Sampling</h2>
<p>Gli algoritmi UCB e Thompson Sampling sono maggiormente utilizzati nel campo dell’intelligenza artificiale.</p>
<section id="upper-confidence-bound-ucb" class="level3" data-number="104.4.1">
<h3 data-number="104.4.1" class="anchored" data-anchor-id="upper-confidence-bound-ucb"><span class="header-section-number">104.4.1</span> Upper Confidence Bound (UCB)</h3>
<p>L’algoritmo UCB (Upper Confidence Bound) bilancia esplorazione e sfruttamento per scegliere le azioni migliori in un contesto di apprendimento per rinforzo. Per ogni azione <span class="math inline">\(\pi\)</span>, l’algoritmo UCB calcola un valore chiamato “limite superiore di confidenza” che tiene conto sia della ricompensa stimata sia dell’incertezza di tale stima. La formula è:</p>
<p><span class="math display">\[ \text{UCB}(\pi) = \hat{r}(\pi) + \sqrt{\frac{2 \log t}{n(\pi)}} \]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(\hat{r}(\pi)\)</span> è la ricompensa stimata per l’azione <span class="math inline">\(\pi\)</span>.</li>
<li><span class="math inline">\(t\)</span> è il turno corrente.</li>
<li><span class="math inline">\(n(\pi)\)</span> è il numero di volte che l’azione <span class="math inline">\(\pi\)</span> è stata scelta.</li>
</ul>
<p>Il termine <span class="math inline">\(\sqrt{\frac{2 \log t}{n(\pi)}}\)</span> rappresenta l’incertezza della stima. Più un’azione viene scelta, più diminuisce l’incertezza, e quindi il termine di esplorazione si riduce.</p>
<p>L’algoritmo seleziona l’azione con il valore UCB più alto. Questo approccio permette di esplorare nuove azioni ma anche di sfruttare quelle che sembrano offrire le migliori ricompense, garantendo un buon equilibrio tra esplorazione e sfruttamento.</p>
</section>
<section id="thompson-sampling" class="level3" data-number="104.4.2">
<h3 data-number="104.4.2" class="anchored" data-anchor-id="thompson-sampling"><span class="header-section-number">104.4.2</span> Thompson Sampling</h3>
<p>L’algoritmo Thompson Sampling bilancia esplorazione e sfruttamento scegliendo probabilisticamente le azioni in base alla loro probabilità di essere ottimali. Per ogni azione <span class="math inline">\(\pi\)</span>, una ricompensa viene campionata dalla distribuzione a posteriori della sua ricompensa attesa. L’azione con il valore campionato più alto viene scelta. Questo approccio bilancia efficacemente esplorazione (provando azioni meno certe) e sfruttamento (scegliendo l’azione che attualmente sembra la migliore).</p>
</section>
</section>
<section id="contextual-bandits" class="level2" data-number="104.5">
<h2 data-number="104.5" class="anchored" data-anchor-id="contextual-bandits"><span class="header-section-number">104.5</span> Contextual Bandits</h2>
<p>I contextual bandits rappresentano un’evoluzione rispetto ai tradizionali problemi multi-armed bandit, offrendo un framework più realistico per il processo decisionale interattivo in scenari complessi. Mentre i multi-armed bandits si concentrano sulla scelta ripetuta tra diverse opzioni fisse, i contextual bandits introducono un nuovo elemento: il contesto. In questo scenario, prima di prendere una decisione, l’agente osserva informazioni contestuali che possono influenzare la scelta ottimale.</p>
<section id="il-protocollo-dei-contextual-bandits" class="level3" data-number="104.5.1">
<h3 data-number="104.5.1" class="anchored" data-anchor-id="il-protocollo-dei-contextual-bandits"><span class="header-section-number">104.5.1</span> Il Protocollo dei Contextual Bandits</h3>
<p>Il processo decisionale nei contextual bandits si svolge come segue:</p>
<ol type="1">
<li>L’agente osserva un contesto <span class="math inline">\(x_t\)</span> (ad esempio, le caratteristiche di una situazione sociale per una persona con anoressia nervosa).</li>
<li>Basandosi su questo contesto, l’agente seleziona un’azione <span class="math inline">\(\pi_t\)</span> (ad esempio, la scelta di mangiare o meno in quella situazione).</li>
<li>L’agente riceve una ricompensa <span class="math inline">\(r_t\)</span> (ad esempio, il livello di ansia o controllo percepito dopo la scelta).</li>
</ol>
<p>Questo processo si ripete per <span class="math inline">\(T\)</span> turni.</p>
</section>
<section id="modello-matematico" class="level3" data-number="104.5.2">
<h3 data-number="104.5.2" class="anchored" data-anchor-id="modello-matematico"><span class="header-section-number">104.5.2</span> Modello Matematico</h3>
<ol type="1">
<li>Le ricompense sono generate secondo una distribuzione condizionale <span class="math inline">\(r_t \sim \mathcal{M}^*(\cdot | x_t, \pi_t)\)</span>, il che significa che la ricompensa <span class="math inline">\(r_t\)</span> è distribuita secondo una certa legge <span class="math inline">\(\mathcal{M}^*\)</span> che varia a seconda del contesto e dell’azione.</li>
<li>La funzione di ricompensa media <span class="math inline">\(f^*(x, \pi)\)</span> rappresenta il valore atteso della ricompensa data un certo contesto <span class="math inline">\(x\)</span> e una certa azione <span class="math inline">\(\pi\)</span>.</li>
<li>La politica ottimale <span class="math inline">\(\pi^*(x) = \arg\max_{\pi} f^*(x, \pi)\)</span> indica che, per ogni contesto <span class="math inline">\(x\)</span>, cerchiamo l’azione <span class="math inline">\(\pi\)</span> che dà la ricompensa media più alta.</li>
</ol>
<p>L’obiettivo di un agente che utilizza contextual bandits è minimizzare il “regret”. Il “regret” è la differenza tra la ricompensa che avremmo ottenuto se avessimo sempre scelto l’azione ottimale e la ricompensa che abbiamo effettivamente ottenuto.</p>
</section>
<section id="esempio-anoressia-nervosa" class="level3" data-number="104.5.3">
<h3 data-number="104.5.3" class="anchored" data-anchor-id="esempio-anoressia-nervosa"><span class="header-section-number">104.5.3</span> Esempio: Anoressia Nervosa</h3>
<p>Consideriamo un esempio legato all’anoressia nervosa (AN). L’approccio dei contextual bandits può spiegare perché le persone affette da AN mostrano un apprendimento per rinforzo (RL) compromesso in contesti legati al cibo e al corpo, mentre mostrano un RL adeguato in contesti non legati al cibo e al corpo.</p>
<p>Immaginiamo due scenari distinti:</p>
<p><strong>Scenario 1: Contesto legato al cibo</strong></p>
<ul>
<li><strong>Contesto (<span class="math inline">\(x_t\)</span>)</strong>: Una persona con AN si trova a una cena con amici dove è presente una varietà di cibi.</li>
<li><strong>Azione (<span class="math inline">\(\pi_t\)</span>)</strong>: La persona deve decidere se mangiare un certo cibo.</li>
<li><strong>Ricompensa (<span class="math inline">\(r_t\)</span>)</strong>: La ricompensa potrebbe essere misurata in termini di ansia percepita, con alti livelli di ansia che indicano una bassa ricompensa.</li>
</ul>
<p>In questo contesto, la persona con AN potrebbe avere una funzione di ricompensa media <span class="math inline">\(f^*(x, \pi)\)</span> che penalizza fortemente le azioni legate al consumo di cibo, a causa delle elevate preoccupazioni legate al peso e all’immagine corporea. Di conseguenza, l’apprendimento per rinforzo sarà compromesso perché la ricompensa attesa per le azioni legate al cibo è molto bassa.</p>
<p><strong>Scenario 2: Contesto non legato al cibo</strong></p>
<ul>
<li><strong>Contesto (<span class="math inline">\(x_t\)</span>)</strong>: La stessa persona con AN si trova in una situazione di lavoro dove deve decidere come completare un compito.</li>
<li><strong>Azione (<span class="math inline">\(\pi_t\)</span>)</strong>: La persona deve decidere quale strategia usare per completare il compito.</li>
<li><strong>Ricompensa (<span class="math inline">\(r_t\)</span>)</strong>: La ricompensa potrebbe essere misurata in termini di successo o soddisfazione per il compito completato, con alti livelli di successo che indicano una alta ricompensa.</li>
</ul>
<p>In questo contesto, la funzione di ricompensa media <span class="math inline">\(f^*(x, \pi)\)</span> non è influenzata dalle preoccupazioni legate al cibo o al corpo. Pertanto, la persona con AN può imparare efficacemente quale azione porta alla ricompensa massima, mostrando un apprendimento per rinforzo adeguato.</p>
<p>Questo esempio mostra come i contextual bandits possano spiegare le differenze nell’apprendimento per rinforzo in base al contesto, fornendo un quadro più completo e realistico delle dinamiche decisionali nelle persone con anoressia nervosa.</p>
<p>In sintesi, i contextual bandits sono un framework di RL che considera il contesto (o stato) quando si sceglie un’azione, ma non considera gli effetti a lungo termine delle azioni o come le azioni influenzano gli stati futuri.</p>
</section>
<section id="rigidità-cognitiva-e-difficoltà-di-rl-nellanoressia-nervosa" class="level3" data-number="104.5.4">
<h3 data-number="104.5.4" class="anchored" data-anchor-id="rigidità-cognitiva-e-difficoltà-di-rl-nellanoressia-nervosa"><span class="header-section-number">104.5.4</span> Rigidità Cognitiva e Difficoltà di RL nell’Anoressia Nervosa</h3>
<p>La rigidità cognitiva nelle decisioni legate a cibo e corpo può essere spiegata in termini di RL come segue:</p>
<ol type="1">
<li><strong>Sovrastima delle ricompense immediate:</strong> Le azioni che portano a sensazioni di controllo o riduzione dell’ansia a breve termine (es. restrizione calorica) ricevono un “peso” eccessivo nel processo decisionale.</li>
<li><strong>Sottostima delle ricompense a lungo termine:</strong> Le conseguenze positive di un’alimentazione sana o di un’immagine corporea più realistica vengono sottovalutate o ignorate.</li>
<li><strong>Esplorazione limitata:</strong> La persona potrebbe evitare di esplorare nuove azioni (es. mangiare cibi temuti) a causa dell’ansia associata, limitando così l’apprendimento.</li>
<li><strong>Aggiornamento selettivo del modello:</strong> Nel caso di apprendimento model-based, la persona potrebbe aggiornare selettivamente il suo modello interno, dando più peso alle informazioni che confermano le sue convinzioni sulla necessità di controllo sul cibo e sul corpo.</li>
</ol>
</section>
<section id="contextual-bandits-nel-contesto-dellanoressia-nervosa" class="level3" data-number="104.5.5">
<h3 data-number="104.5.5" class="anchored" data-anchor-id="contextual-bandits-nel-contesto-dellanoressia-nervosa"><span class="header-section-number">104.5.5</span> Contextual Bandits nel Contesto dell’Anoressia Nervosa</h3>
<p>Utilizzando il framework dei contextual bandits, possiamo vedere come una persona con anoressia possa mostrare un apprendimento per rinforzo adeguato in alcuni contesti, ma un apprendimento per rinforzo alterato e rigido in situazioni legate al cibo e al corpo. In contesti legati al cibo, l’ansia e la preoccupazione per il controllo del peso e dell’immagine corporea influenzano negativamente la percezione delle ricompense, portando a decisioni che evitano il cibo e rafforzano comportamenti dannosi.</p>
<p>Al contrario, in contesti non legati al cibo, dove queste preoccupazioni non sono presenti, la persona con anoressia può fare scelte basate su un’analisi più razionale delle ricompense, mostrando un apprendimento per rinforzo normale. Questo dualismo nell’apprendimento decisionale evidenzia come il contesto giochi un ruolo cruciale nelle scelte di una persona con anoressia, spiegando perché possa avere una rigida resistenza al cambiamento in situazioni legate al cibo e al corpo, ma decisioni più flessibili e adeguate in altri ambiti della vita.</p>
<p>Questa prospettiva aiuta a spiegare perché le persone con anoressia possono mostrare capacità decisionali normali in molti ambiti della vita, ma una marcata rigidità e resistenza al cambiamento quando si tratta di decisioni legate all’alimentazione e all’immagine corporea.</p>
</section>
</section>
<section id="simulare-lapprendimento" class="level2" data-number="104.6">
<h2 data-number="104.6" class="anchored" data-anchor-id="simulare-lapprendimento"><span class="header-section-number">104.6</span> Simulare l’Apprendimento</h2>
<p>I modelli precedenti sono spesso chiamati semplicemente ‘modelli RL’ e costituiscono la base di molti studi sulla psicologia e neuroscienza dell’apprendimento guidato dalla ricompensa. In questo tutorial, simuleremo il processo decisionale di un partecipante che sceglie tra due slot machine, utilizzando il modello di apprendimento di Rescorla-Wagner. Questa simulazione ci aiuterà a comprendere come le persone apprendono e prendono decisioni in situazioni di incertezza.</p>
<p>Configurazione della simulazione:</p>
<ol type="1">
<li>Numero di tentativi: <span class="math inline">\(T = 100\)</span>. Significa che il partecipante farà 100 scelte consecutive.</li>
<li>Numero di slot machine: <span class="math inline">\(K = 2\)</span>. Il partecipante sceglierà tra due slot machine ad ogni tentativo.</li>
<li>Probabilità di ricompensa: <span class="math inline">\(\mu = [0.2, 0.8]\)</span>. Ciò significa che la Slot machine 1 ha yna probabilità pari a 0.2 di offrire una ricompensa, mentre la Slot machine 2 ha una probabilità pari a 0.8 di offrire una ricompensa.</li>
</ol>
<p>Attraverso questa simulazione, osserveremo come il partecipante inizialmente esplora entrambe le opzioni, come gradualmente apprende quale slot machine offre ricompense più frequenti e come adatta le proprie scelte per massimizzare le vincite complessive.</p>
</section>
<section id="esempio-di-calcolo-della-softmax" class="level2" data-number="104.7">
<h2 data-number="104.7" class="anchored" data-anchor-id="esempio-di-calcolo-della-softmax"><span class="header-section-number">104.7</span> Esempio di Calcolo della Softmax</h2>
<p>Per capire come funziona la softmax, consideriamo due valori di <span class="math inline">\(Q\)</span> (aspettativa di ricompensa) e un valore fisso di <span class="math inline">\(\theta\)</span>.</p>
<p>La funzione softmax trasforma i valori <span class="math inline">\(Q\)</span> e <span class="math inline">\(\theta\)</span> in una distribuzione di probabilità, mostrando come la probabilità di scelta cambia al variare di <span class="math inline">\(\theta\)</span>.</p>
<div id="cell-9" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:38:39.406047Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:38:39.392564Z&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(Q, theta):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> np.exp(theta <span class="op">*</span> Q) <span class="op">/</span> np.<span class="bu">sum</span>(np.exp(theta <span class="op">*</span> Q))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> p</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Consideriamo una situazione in cui la seconda scelta ha un’aspettativa di valore tre volte maggiore la prima.</p>
<div id="cell-11" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:38:42.644984Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:38:42.637076Z&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.array([<span class="fl">0.25</span>, <span class="fl">0.75</span>])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo il caso di un valore <span class="math inline">\(\theta\)</span> alto.</p>
<div id="cell-13" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:38:45.652757Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:38:45.639959Z&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> <span class="fl">3.5</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-14" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:38:48.187309Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:38:48.179248Z&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(softmax(Q, theta))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.1480472 0.8519528]</code></pre>
</div>
</div>
<p>In tali circostanze, la probabilità di scegliere la seconda azione è quasi sei volte maggiore quella di scegliere la prima azione.</p>
<div id="cell-16" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fl">0.8519528</span> <span class="op">/</span> <span class="fl">0.1480472</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>5.754602586202238</code></pre>
</div>
</div>
<p>Consideriamo ora il caso in cui il valore <span class="math inline">\(\theta\)</span> è basso.</p>
<div id="cell-18" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:19:54.652419Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:19:54.646836Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(softmax(Q, theta))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.4378235 0.5621765]</code></pre>
</div>
</div>
<p>In tali circostanze, la probabilità di scegliere la seconda azione è appena maggiore di quella di scegliere la prima azione. Quando <span class="math inline">\(\theta\)</span> è zero, la probabilità di scegliere una delle due azioni è 0.5, indipendentemente dall’aspettativa di ricompensa delle due azioni.</p>
<div id="cell-20" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(softmax(Q, theta))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.5 0.5]</code></pre>
</div>
</div>
<p>Ora manteniamo fisso il valore di <span class="math inline">\(Q\)</span> e facciamo variare <span class="math inline">\(\theta\)</span>.</p>
<div id="cell-22" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:38:54.581477Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:38:54.410041Z&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.array([<span class="fl">0.25</span>, <span class="fl">0.75</span>])</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>theta_values <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>probabilities_list <span class="op">=</span> []</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> theta <span class="kw">in</span> theta_values:</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> softmax(Q, theta)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    probabilities_list.append(probabilities)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>probabilities_array <span class="op">=</span> np.array(probabilities_list).T</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>option_labels <span class="op">=</span> [<span class="st">'Opzione 1: Q = 0.25'</span>, <span class="st">'Opzione 2: Q = 0.75'</span>]</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(option_labels)):</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    plt.plot(theta_values, probabilities_array[i], label<span class="op">=</span>option_labels[i])</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Theta'</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probabilità'</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Funzione Softmax - Modello Rescorla-Wagner'</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="03_rescorla_wagner_files/figure-html/cell-10-output-1.png" width="731" height="491" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Il grafico risultante mostra come le probabilità di scelta cambiano al variare del parametro <span class="math inline">\(\theta\)</span>. Quando <span class="math inline">\(\theta\)</span> è vicino a zero, la scelta è quasi casuale. Quando <span class="math inline">\(\theta\)</span> è molto grande, la scelta è quasi sempre l’opzione con il valore più alto.</p>
</section>
<section id="simulazione-del-modello-di-rescorla-wagner" class="level2" data-number="104.8">
<h2 data-number="104.8" class="anchored" data-anchor-id="simulazione-del-modello-di-rescorla-wagner"><span class="header-section-number">104.8</span> Simulazione del Modello di Rescorla-Wagner</h2>
<p>Combiniamo la regola di apprendimento e la regola decisionale per simulare il comportamento del partecipante:</p>
<div id="cell-24" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:39:25.188311Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:39:25.168881Z&quot;}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_RescorlaWagner(params, T, mu, noisy_choice<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    alpha, theta <span class="op">=</span> params</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Un array di zeri di lunghezza T</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> np.zeros((T), dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> np.zeros((T), dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Un array multidimensionale di zeri di dimensione 2xT</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    Q_stored <span class="op">=</span> np.zeros((<span class="dv">2</span>, T), dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inizializza Q per t == 0</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    Q <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">0.5</span>]</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Salva i valori Q per Q_{t+1}</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        Q_stored[:, t] <span class="op">=</span> Q</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calcola le probabilità di scelta</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        p0 <span class="op">=</span> np.exp(theta<span class="op">*</span>Q[<span class="dv">0</span>]) <span class="op">/</span> (np.exp(theta<span class="op">*</span>Q[<span class="dv">0</span>]) <span class="op">+</span> np.exp(theta<span class="op">*</span>Q[<span class="dv">1</span>]))</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        p1 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> p0</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Se noisy_choice è vero, viene simulato un comportamento di scelta rumoroso in </span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># cui l'opzione 0 è scelta con probabilità p0, mentre l'opzione 1 è scelta con </span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># probabilità 1-p0.</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> noisy_choice:</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> np.random.random_sample(<span class="dv">1</span>) <span class="op">&lt;</span> p0:</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>                c[t] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>                c[t] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:  <span class="co"># la scelta viene effettuata senza rumore</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>            c[t] <span class="op">=</span> np.argmax([p0, p1])</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Genera la ricompensa sulla base delle probabilità di ricompensa</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        r[t] <span class="op">=</span> np.random.rand() <span class="op">&lt;</span> mu[c[t]]</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aggiorna le aspettative di valore</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>        delta <span class="op">=</span> r[t] <span class="op">-</span> Q[c[t]]</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>        Q[c[t]] <span class="op">=</span> Q[c[t]] <span class="op">+</span> alpha <span class="op">*</span> delta</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> c, r, Q_stored</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Simuliamo <code>T</code> = 100 prove utilizzando il modello generativo dei dati definito in precedenza.</p>
<div id="cell-26" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:39:30.403886Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:39:30.399500Z&quot;}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> [<span class="fl">0.2</span>, <span class="fl">0.8</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-27" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:39:35.297629Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:39:35.287615Z&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>c, r, Q <span class="op">=</span> simulate_RescorlaWagner([<span class="fl">.1</span>, <span class="fl">2.5</span>], T<span class="op">=</span>T, mu<span class="op">=</span>mu)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Rappresentiamo graficamente i risultati ottenuti dalla simulazione.</p>
<div id="cell-29" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:39:38.852623Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:39:38.703001Z&quot;}" data-execution_count="15">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(T), r, <span class="st">'r--'</span>, alpha<span class="op">=</span><span class="fl">.6</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(T), c, <span class="st">'+'</span>, label<span class="op">=</span><span class="st">'scelta'</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Prove'</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feedback (1=Ricompensa,</span><span class="ch">\n</span><span class="st"> 0=Nessuna ricompensa)'</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Apprendimento di Rescorla-Wagner'</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="03_rescorla_wagner_files/figure-html/cell-14-output-1.png" width="731" height="491" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Come possiamo osservare, le scelte per la slot machine che produce meno ricompense diventano meno frequenti nel corso delle prove.</p>
<p>Il diagramma seguente illustra l’aggiornamento del valore <span class="math inline">\(Q\)</span>, mostrando come l’aspettativa di ricompensa delle due slot machine venga aggiornata in base all’errore di predizione nel corso delle prove.</p>
<div id="cell-31" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:40:05.820595Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:40:05.658350Z&quot;}" data-execution_count="16">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(T), Q[<span class="dv">1</span>, :], <span class="st">"r--"</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">"80% machine"</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(T), Q[<span class="dv">0</span>, :], <span class="st">'m-'</span>, alpha<span class="op">=</span><span class="fl">.6</span>, label<span class="op">=</span><span class="st">'20% machine'</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(T), c, <span class="st">'b+'</span>, label<span class="op">=</span><span class="st">'choice'</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'trials'</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'value'</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Rescorla-Wagner Learning'</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="03_rescorla_wagner_files/figure-html/cell-15-output-1.png" width="731" height="491" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Si noti come nel corso delle prove i valori delle slot macchine convergano lentamente verso le probabilità di ricompensa (20% e 80%).</p>
<p>In sintesi, il modello di Rescorla-Wagner ci permette di simulare come le persone apprendono e prendono decisioni basate su ricompense. Utilizzando la regola di apprendimento (<span class="math inline">\(\delta\)</span>-rule) e la regola decisionale softmax, possiamo vedere come le aspettative di valore e le scelte cambiano nel tempo in risposta alle ricompense ottenute.</p>
</section>
<section id="adattamento-del-modello" class="level2" data-number="104.9">
<h2 data-number="104.9" class="anchored" data-anchor-id="adattamento-del-modello"><span class="header-section-number">104.9</span> Adattamento del Modello</h2>
<p>Dopo aver compreso il funzionamento del modello di Rescorla-Wagner, il passo successivo consiste nello stimare i parametri del modello a partire dai dati osservati. Questo processo è cruciale nella modellazione computazionale poiché ci permette di determinare quali valori dei parametri descrivono meglio il comportamento osservato. Esistono diversi metodi per stimare i parametri. La sezione <a href="../appendix/a55_rescorla_wagner.html" class="quarto-xref"><span>Appendice V</span></a> mostra come implementare l’approccio della <em>Massima Verosimiglianza</em>. Qui illustreremo la stima dei parametri del modello Rescorla-Wagner utilizzando un metodo bayesiano, attraverso l’uso di Stan. Procediamo quindi a compilare il modello e a stampare il codice Stan.</p>
<div id="cell-34" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:40:43.012082Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:40:42.192179Z&quot;}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>stan_file <span class="op">=</span> os.path.join(project_directory, <span class="st">"stan"</span>, <span class="st">"rescorla_wagner.stan"</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.code())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=1&gt; nTrials; // numero di tentativi
  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)
  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)
}
transformed data {
  vector[2] initV; // valori iniziali per V
  initV = rep_vector(0.5, 2); // inizializzati a 0.5
}
parameters {
  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento
  real&lt;lower=0&gt; theta; // temperatura
}
model {
  vector[2] v; // valori attesi
  real delta; // errore di previsione
  
  // Priori
  alpha ~ beta(1, 1); // prior uniforme su [0, 1]
  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10
  
  v = initV;
  
  for (t in 1 : nTrials) {
    // Calcolo delle probabilità di scelta usando la funzione softmax con limitazione
    vector[2] logits;
    logits = theta * v;
    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow
    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow
    
    choice[t] ~ categorical_logit(logits);
    
    // Errore di previsione
    delta = reward[t] - v[choice[t]];
    
    // Aggiornamento dei valori attesi (apprendimento)
    v[choice[t]] = v[choice[t]] + alpha * delta;
  }
}
</code></pre>
</div>
</div>
<section id="sezione-data" class="level3" data-number="104.9.1">
<h3 data-number="104.9.1" class="anchored" data-anchor-id="sezione-data"><span class="header-section-number">104.9.1</span> Sezione <code>data</code></h3>
<p>Questa sezione definisce i dati che vengono forniti al modello:</p>
<ul>
<li><code>nTrials</code>: Il numero totale di tentativi o scelte effettuate dal partecipante.</li>
<li><code>choice</code>: Un array che contiene le scelte effettuate dal partecipante in ciascun tentativo (1 o 2).</li>
<li><code>reward</code>: Un array che contiene le ricompense ricevute per ciascun tentativo (0 o 1).</li>
</ul>
</section>
<section id="sezione-transformed-data" class="level3" data-number="104.9.2">
<h3 data-number="104.9.2" class="anchored" data-anchor-id="sezione-transformed-data"><span class="header-section-number">104.9.2</span> Sezione <code>transformed data</code></h3>
<p>Questa sezione prepara alcuni dati iniziali trasformati per il modello. Qui <code>initV</code> è un vettore di lunghezza 2 che rappresenta i valori iniziali delle aspettative di ricompensa per le due opzioni, entrambi inizializzati a 0.5.</p>
</section>
<section id="sezione-parameters" class="level3" data-number="104.9.3">
<h3 data-number="104.9.3" class="anchored" data-anchor-id="sezione-parameters"><span class="header-section-number">104.9.3</span> Sezione <code>parameters</code></h3>
<p>Questa sezione definisce i parametri del modello che Stan cercherà di stimare:</p>
<ul>
<li><code>alpha</code>: Il tasso di apprendimento, che determina quanto rapidamente il partecipante aggiorna le proprie aspettative. Questo valore è compreso tra 0 e 1.</li>
<li><code>theta</code>: La temperatura, che controlla il livello di esplorazione (quanto spesso il partecipante sceglie l’opzione con il valore atteso più alto rispetto a esplorare altre opzioni). Questo valore è positivo.</li>
</ul>
</section>
<section id="sezione-model" class="level3" data-number="104.9.4">
<h3 data-number="104.9.4" class="anchored" data-anchor-id="sezione-model"><span class="header-section-number">104.9.4</span> Sezione <code>model</code></h3>
<p>La sezione <code>model</code> del codice Stan è il cuore del modello, dove avviene il processo di stima e aggiornamento dei valori attesi in base ai dati osservati. Vediamo passo passo come funziona.</p>
<ol type="1">
<li><p>Inizializzazione.</p>
<ul>
<li>Partiamo con valori attesi uguali per entrambe le opzioni (<code>v = [0.5, 0.5]</code>).</li>
<li>Scegliamo valori casuali iniziali per <code>alpha</code> e <code>theta</code>.</li>
</ul></li>
<li><p>Per ogni tentativo dell’esperimento:</p>
<ol type="a">
<li>Calcolo delle probabilità di scelta:</li>
</ol>
<div class="sourceCode" id="cb21"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>logits = theta * v;</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>logits = fmin(logits, <span class="dv">20</span>);</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>logits = fmax(logits, -<span class="dv">20</span>);</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Moltiplichiamo i valori attesi per la temperatura.</li>
<li>Limitiamo i risultati tra -20 e 20 per evitare problemi numerici.</li>
</ul>
<p><em>Esempio:</em></p>
<p>Se <code>v = [0.3, 0.7]</code> e <code>theta = 2</code>:</p>
<ol type="1">
<li><code>logits = 2 * [0.3, 0.7] = [0.6, 1.4]</code></li>
<li>Nessun cambiamento dopo <code>fmin</code> e <code>fmax</code> perché i valori sono già tra -20 e 20.</li>
</ol>
<ol start="2" type="a">
<li>Modellazione della scelta:</li>
</ol>
<div class="sourceCode" id="cb22"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>choice[t] ~ categorical_logit(logits);</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Usiamo i <code>logits</code> per calcolare le probabilità di scelta.</li>
<li>La funzione <code>softmax</code> converte i <code>logits</code> in probabilità.</li>
</ul>
<p><em>Esempio (continuazione):</em></p>
<ul>
<li><code>softmax([0.6, 1.4]) ≈ [0.38, 0.62]</code></li>
<li>C’è il 38% di probabilità di scegliere la prima opzione e il 62% per la seconda.</li>
</ul>
<ol start="3" type="a">
<li>Calcolo dell’errore di previsione:</li>
</ol>
<div class="sourceCode" id="cb23"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>delta = reward[t] - v[choice[t]];</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Confrontiamo la ricompensa ricevuta con quanto ci aspettavamo.</li>
<li>Se positivo, siamo stati piacevolmente sorpresi; se negativo, delusi.</li>
</ul>
<p><em>Esempio:</em></p>
<p>Se scegliamo la seconda opzione e riceviamo una ricompensa di 1:</p>
<ul>
<li><code>delta = 1 - 0.7 = 0.3</code></li>
</ul>
<p>Siamo stati leggermente sorpresi in positivo.</p>
<ol start="4" type="a">
<li>Aggiornamento dei valori attesi:</li>
</ol>
<div class="sourceCode" id="cb24"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>v[choice[t]] = v[choice[t]] + alpha * delta;</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Aggiorniamo la nostra aspettativa per l’opzione scelta.</li>
<li><code>alpha</code> determina quanto peso diamo alla nuova esperienza.</li>
</ul>
<p><em>Esempio (continuazione):</em></p>
<p>Se <code>alpha = 0.2</code>:</p>
<ul>
<li>Nuovo valore per la seconda opzione: <code>0.7 + 0.2 * 0.3 = 0.76</code></li>
</ul>
<p>La nostra aspettativa per la seconda opzione è leggermente aumentata.</p></li>
<li><p>Ripetizione.</p></li>
</ol>
<ul>
<li>Ripetiamo i passaggi 2a-2d per ogni tentativo dell’esperimento.</li>
<li>Ad ogni iterazione, affiniamo le nostre stime di <code>alpha</code> e <code>theta</code>.</li>
</ul>
</section>
<section id="inferenza" class="level3" data-number="104.9.5">
<h3 data-number="104.9.5" class="anchored" data-anchor-id="inferenza"><span class="header-section-number">104.9.5</span> Inferenza</h3>
<p>Considereremo qui i dati di un singolo partecipante che esegue 300 prove. Definiamo i parametri della simulazione:</p>
<div id="cell-38" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:21:49.754653Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:21:49.749685Z&quot;}" data-execution_count="19">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="fl">0.1</span>, <span class="fl">2.5</span>]  <span class="co"># alpha, theta</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">300</span>  <span class="co"># numero di tentativi</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> [<span class="fl">0.2</span>, <span class="fl">0.8</span>]  <span class="co"># probabilità di ricompensa per le due opzioni</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Simuliamo i dati:</p>
<div id="cell-40" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:21:52.753783Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:21:52.749274Z&quot;}" data-execution_count="20">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>choices, rewards, Q_stored <span class="op">=</span> simulate_RescorlaWagner(params, T, mu)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Prepariamo i dati per Stan. Si noti che abbiamo sommato 1 a <code>choices</code> per adattarsi agli indici di Stan che partono da 1.</p>
<div id="cell-42" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:21:56.234398Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:21:56.228710Z&quot;}" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> choices <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>stan_data <span class="op">=</span> {</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nTrials'</span>: T,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'choice'</span>: c.tolist(),</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reward'</span>: rewards.tolist()</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stan_data)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'nTrials': 300, 'choice': [1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2], 'reward': [0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>Eseguiamo il campionamento:</p>
<div id="cell-44" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:41:05.014484Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:41:03.052034Z&quot;}" data-execution_count="23">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>trace <span class="op">=</span> model.sample(</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>stan_data,</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>16:00:53 - cmdstanpy - INFO - CmdStan start processing
16:00:53 - cmdstanpy - INFO - Chain [1] start processing
16:00:53 - cmdstanpy - INFO - Chain [2] start processing
16:00:53 - cmdstanpy - INFO - Chain [3] start processing
16:00:53 - cmdstanpy - INFO - Chain [4] start processing
16:00:56 - cmdstanpy - INFO - Chain [3] done processing
16:00:56 - cmdstanpy - INFO - Chain [2] done processing
16:00:56 - cmdstanpy - INFO - Chain [1] done processing
16:00:56 - cmdstanpy - INFO - Chain [4] done processing</code></pre>
</div>
</div>
<p>Esaminiamo le distribuzioni a posteriori dei due parametri oggetto dell’inferenza insieme alle loro tracce (cioè i vettori dei campioni dei parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\theta\)</span> prodotti dalla procedura di campionamento MCMC) mediante un <em>trace plot</em> .</p>
<div id="cell-46" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:46:30.862393Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:46:29.835530Z&quot;}" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> az.plot_trace(trace)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="03_rescorla_wagner_files/figure-html/cell-21-output-1.png" width="1211" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="interpretazione-delle-stime-dei-parametri" class="level3" data-number="104.9.6">
<h3 data-number="104.9.6" class="anchored" data-anchor-id="interpretazione-delle-stime-dei-parametri"><span class="header-section-number">104.9.6</span> Interpretazione delle Stime dei Parametri</h3>
<p>Utilizzando <code>az.summary(trace, hdi_prob=0.94, round_to=2)</code>, otteniamo un riassunto delle stime dei parametri del modello, che include la media, la deviazione standard, gli intervalli di credibilità (HDI) e altre statistiche diagnostiche:</p>
<div id="cell-48" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:41:24.954979Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:41:24.901567Z&quot;}" data-execution_count="25">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>az.summary(trace, hdi_prob<span class="op">=</span><span class="fl">0.94</span>, round_to<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha</td>
<td>0.13</td>
<td>0.08</td>
<td>0.02</td>
<td>0.27</td>
<td>0.00</td>
<td>0.00</td>
<td>1973.89</td>
<td>1757.85</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">theta</td>
<td>2.70</td>
<td>0.41</td>
<td>2.01</td>
<td>3.46</td>
<td>0.01</td>
<td>0.01</td>
<td>2095.86</td>
<td>1581.69</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Con 300 prove, le stime dei parametri fornite dal modello sono adeguate:</p>
<ul>
<li>L’intervallo di credibilità al 94% (hdi_3% - hdi_97%) include il valore simulato del parametro. Questo significa che le stime del modello sono coerenti con i parametri originali usati nella simulazione.</li>
<li>La deviazione standard della stima a posteriori è relativamente piccola, indicando che le stime sono precise.</li>
<li>I valori di <code>r_hat</code> sono vicini a 1, indicando che le catene di campionamento sono ben mescolate e hanno ottenuto la convergenza.</li>
</ul>
<p>Questi risultati suggeriscono che il modello di apprendimento di Rescorla-Wagner ha stimato correttamente i parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\theta\)</span> dai dati simulati.</p>
</section>
</section>
<section id="apprendimento-probabilistico-e-reversal-learning" class="level2" data-number="104.10">
<h2 data-number="104.10" class="anchored" data-anchor-id="apprendimento-probabilistico-e-reversal-learning"><span class="header-section-number">104.10</span> Apprendimento Probabilistico e Reversal Learning</h2>
<p>Un paradigma sperimentale particolarmente interessante per indagare i meccanismi dell’apprendimento umano è il <em>Probabilistic Reversal Learning</em> <span class="citation" data-cites="caudek2020cognitive caudek2021susceptibility">(<a href="../../99-references.html#ref-caudek2020cognitive" role="doc-biblioref">Caudek et al. 2020</a>, <a href="../../99-references.html#ref-caudek2021susceptibility" role="doc-biblioref">2021</a>)</span>. In questo compito, le associazioni tra stimoli e outcomes vengono invertite a metà della procedura sperimentale. Ad esempio, se inizialmente lo stimolo A era associato a una ricompensa, in seguito questa associazione può essere invertita, rendendo lo stimolo A svantaggioso.</p>
<p>L’apprendimento per rinforzo offre un solido quadro teorico per comprendere come gli individui si adattano a tali cambiamenti. Modelli computazionali come quello di Rescorla-Wagner possono essere impiegati per simulare questo tipo di apprendimento e per studiare i processi cognitivi sottostanti.</p>
</section>
<section id="incertezza-attesa-vs.-incertezza-non-attesa" class="level2" data-number="104.11">
<h2 data-number="104.11" class="anchored" data-anchor-id="incertezza-attesa-vs.-incertezza-non-attesa"><span class="header-section-number">104.11</span> Incertezza Attesa vs.&nbsp;Incertezza Non Attesa</h2>
<p>Nel contesto dell’apprendimento per rinforzo e dei modelli come quello di Rescorla-Wagner, è fondamentale distinguere tra <strong>incertezza attesa</strong> e <strong>incertezza non attesa</strong>, poiché influenzano in modo diverso il processo di apprendimento.</p>
<ol type="1">
<li><p><strong>Incertezza Attesa</strong>: L’incertezza attesa si riferisce alla variabilità che esiste a causa della natura probabilistica delle ricompense, anche quando le condizioni dell’ambiente rimangono invariate. Ad esempio, se un agente sa che un’azione A ha una probabilità dell’80% di fornire una ricompensa positiva e del 20% di fornire una ricompensa negativa, l’incertezza attesa deriva dal fatto che, nonostante la conoscenza delle probabilità, l’esito di ogni singola azione rimane imprevedibile. In altre parole, anche se l’agente sa che un’azione è generalmente buona, non può prevedere con certezza il risultato di ogni tentativo. Questo tipo di incertezza è considerato “irreducibile” perché non può essere eliminato semplicemente con l’accumulo di esperienze.</p></li>
<li><p><strong>Incertezza Non Attesa</strong>: L’incertezza non attesa, invece, si riferisce alla variabilità che emerge quando le condizioni o le regole dell’ambiente cambiano in modo imprevisto. Ad esempio, se un’azione A che di solito porta a una ricompensa positiva improvvisamente inizia a portare a una ricompensa negativa, l’incertezza non attesa deriva da questo cambiamento inatteso. Questo tipo di incertezza richiede che l’agente aggiorni rapidamente le sue aspettative e strategie, poiché le informazioni precedenti non sono più valide. L’incertezza non attesa è quindi legata alla “volatilità” dell’ambiente e alla necessità di adattarsi ai cambiamenti.</p></li>
</ol>
<p>In sintesi, l’incertezza attesa riguarda la variabilità nelle ricompense che è già nota e considerata nel processo decisionale dell’agente, mentre l’incertezza non attesa implica un cambiamento nelle regole dell’ambiente che richiede un adattamento rapido. Comprendere la differenza tra questi due tipi di incertezza è cruciale per modellare accuratamente il comportamento di apprendimento e prendere decisioni ottimali in ambienti dinamici.</p>
</section>
<section id="anomalie-dellapprendimento" class="level2" data-number="104.12">
<h2 data-number="104.12" class="anchored" data-anchor-id="anomalie-dellapprendimento"><span class="header-section-number">104.12</span> Anomalie dell’apprendimento</h2>
<p>L’uso dei modelli di apprendimento per rinforzo, come il modello di Rescorla-Wagner, ha importanti implicazioni per comprendere le anomalie dell’apprendimento nelle patologie psicologiche, come l’ansia e la depressione <span class="citation" data-cites="pulcu2019misestimation">(<a href="../../99-references.html#ref-pulcu2019misestimation" role="doc-biblioref">Pulcu e Browning 2019</a>)</span>. Questi modelli aiutano a spiegare come le persone con disturbi affettivi possano avere difficoltà a stimare correttamente l’incertezza, sia attesa che non attesa, riguardo agli esiti delle loro azioni.</p>
<p>Ad esempio, una sovrastima dell’incertezza attesa o una sottostima dell’incertezza non attesa può rendere un individuo meno reattivo agli eventi recenti e più lento nell’adattarsi a cambiamenti importanti, specialmente in ambienti dinamici e poco rumorosi. Al contrario, una sottostima dell’incertezza attesa o una sovrastima dell’incertezza non attesa può portare a una maggiore influenza degli eventi recenti e a credenze instabili, specialmente in ambienti stabili ma rumorosi. Questa errata stima dell’incertezza può ridurre la capacità di un individuo di tracciare accuratamente lo stato degli ambienti dinamici e, di conseguenza, scegliere le azioni più adatte per ottenere risultati positivi o evitare quelli negativi.</p>
<p>Inoltre, la tendenza a sopravvalutare l’incertezza non attesa degli esiti negativi rispetto a quelli positivi può portare a un’influenza maggiore degli eventi negativi, un profilo cognitivo tipico dell’ansia e della depressione. Studi recenti suggeriscono che i bias nella stima dell’incertezza potrebbero fornire un collegamento meccanicistico tra gli aspetti cognitivi interni della depressione e dell’ansia e i fattori di rischio esterni, come l’esposizione a esperienze avverse. Pertanto, l’integrazione di modelli di apprendimento per rinforzo come il Rescorla-Wagner nelle ricerche cliniche può offrire nuove prospettive per comprendere e trattare questi disturbi <span class="citation" data-cites="browning2015anxious">(<a href="../../99-references.html#ref-browning2015anxious" role="doc-biblioref">Browning et al. 2015</a>)</span>.</p>
</section>
<section id="commenti-e-considerazioni-finali" class="level2" data-number="104.13">
<h2 data-number="104.13" class="anchored" data-anchor-id="commenti-e-considerazioni-finali"><span class="header-section-number">104.13</span> Commenti e considerazioni finali</h2>
<p>In precedenza abbiamo esaminato il modello di regressione. Sebbene il modello di regressione sia estremamente popolare in psicologia e nelle scienze sociali, presenta dei limiti sostanziali. È utile per descrivere le associazioni tra variabili, ma non è adatto per scoprire nessi causali, che rappresentano l’obiettivo principale delle teorie scientifiche. Come afferma Richard McElreath:</p>
<blockquote class="blockquote">
<p>Le persone una volta facevano teoria. Ora fanno solo regressioni.</p>
</blockquote>
<p>Trovare associazioni nei dati osservazionali non è un buon metodo per costruire teorie. Abbiamo bisogno di una motivazione per esaminare determinate variabili, poiché le associazioni tra variabili non sono rare, ma raramente ci informano sulle relazioni causali.</p>
<p>Un approccio preferibile è utilizzare una teoria formale per sviluppare aspettative sui dati osservati, misurare le variabili rilevanti e utilizzare modelli statistici specifici per testare la teoria.</p>
<p>L’apprendimento per rinforzo offre un potente framework per studiare come gli organismi apprendono dall’interazione con l’ambiente. Modelli come quello di Rescorla-Wagner e algoritmi come UCB e Thompson Sampling forniscono strumenti utili per comprendere i processi cognitivi sottostanti l’apprendimento associativo e per sviluppare agenti intelligenti. Questi modelli hanno raggiunto un notevole successo, fornendo spiegazioni computazionali sia per fenomeni di apprendimento di base che complessi <span class="citation" data-cites="eckstein2020computational frank2012mechanisms">(<a href="../../99-references.html#ref-eckstein2020computational" role="doc-biblioref">M. K. Eckstein e Collins 2020</a>; <a href="../../99-references.html#ref-frank2012mechanisms" role="doc-biblioref">Frank e Badre 2012</a>)</span>.</p>
<p>Tuttavia, è importante riconoscere alcune limitazioni di questi modelli di apprendimento per rinforzo. La letteratura scientifica ha infatti accumulato una serie di osservazioni che questi modelli faticano a spiegare adeguatamente <span class="citation" data-cites="ecksteinhybrid">(<a href="../../99-references.html#ref-ecksteinhybrid" role="doc-biblioref">M. Eckstein et al., s.d.</a>)</span>. In primo luogo, eventi singoli del passato possono influenzare il comportamento in modo sproporzionato <span class="citation" data-cites="duncan2016memory schulz2019algorithmic bornstein2017reinstated">(<a href="../../99-references.html#ref-duncan2016memory" role="doc-biblioref">Duncan e Shohamy 2016</a>; <a href="../../99-references.html#ref-schulz2019algorithmic" role="doc-biblioref">Schulz e Gershman 2019</a>; <a href="../../99-references.html#ref-bornstein2017reinstated" role="doc-biblioref">Bornstein e Norman 2017</a>)</span>. Questo suggerisce che la memoria rilevante per il compito contiene più che semplici statistiche riassuntive come i Q-values. In altre parole, le esperienze passate possono avere un impatto duraturo e significativo sulle decisioni future, anche se non riflesse nei valori medi appresi. In secondo luogo, il comportamento è spesso sensibile a statistiche globali del passato, come l’intervallo di ricompense ricevute o il raggruppamento delle opzioni di scelta <span class="citation" data-cites="palminteri2015contextual khaw2017normalized">(<a href="../../99-references.html#ref-palminteri2015contextual" role="doc-biblioref">Palminteri et al. 2015</a>; <a href="../../99-references.html#ref-khaw2017normalized" role="doc-biblioref">Khaw, Glimcher, e Louie 2017</a>)</span>. Questi aspetti non sono facilmente catturati dai modelli standard di apprendimento per rinforzo, che tendono a concentrarsi su valori specifici per ogni azione piuttosto che su pattern più ampi. Infine, i segnali neurali precedentemente ritenuti direttamente correlati ai Q-values hanno mostrato una marcata diversità che è in contrasto con le previsioni dei modelli standard di apprendimento per rinforzo <span class="citation" data-cites="yaple2019fractionating">(<a href="../../99-references.html#ref-yaple2019fractionating" role="doc-biblioref">Yaple e Yu 2019</a>)</span>. Questa variabilità suggerisce che i processi neurali sottostanti alle decisioni basate su ricompense sono più complessi di quanto inizialmente si pensasse.</p>
<p>Nell’insieme, questi risultati indicano che le rappresentazioni mnemoniche utilizzate da esseri umani e animali per prendere decisioni basate su ricompense vanno oltre le semplici statistiche riassuntive apprese in modo incrementale e associate a singole azioni. È probabile che queste decisioni si basino su una varietà di meccanismi di memoria interni aggiuntivi, che permettono una rappresentazione più ricca e sfumata delle esperienze passate e del contesto decisionale. Questa complessità sottolinea la necessità di sviluppare modelli più sofisticati che possano catturare la ricchezza dei processi decisionali osservati negli organismi biologici, integrando aspetti di memoria episodica, sensibilità al contesto e variabilità nei segnali neurali.</p>
</section>
<section id="esercizi" class="level2" data-number="104.14">
<h2 data-number="104.14" class="anchored" data-anchor-id="esercizi"><span class="header-section-number">104.14</span> Esercizi</h2>
<div id="exr-rescorla-wagner-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 104.1</strong></span> Implementa una funzione Python <code>softmax</code> che prende in input un array di valori attesi <code>Q</code> per ciascuna azione e un parametro di temperatura <code>theta</code>. La funzione deve restituire un array di probabilità che rappresenta la probabilità di selezione di ciascuna azione.</p>
<p>La formula della regola softmax è la seguente:</p>
<p><span class="math display">\[ p_i = \frac{e^{\theta Q_i}}{\sum_{j} e^{\theta Q_j}}, \]</span></p>
<p>dove <span class="math inline">\(p_i\)</span> è la probabilità di selezionare l’azione <span class="math inline">\(i\)</span>, <span class="math inline">\(Q_i\)</span> è il valore atteso dell’azione <span class="math inline">\(i\)</span>, <span class="math inline">\(\theta\)</span> è il parametro di temperatura che controlla il livello di esplorazione.</p>
<p>Utilizza:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.array([<span class="fl">0.25</span>, <span class="fl">0.75</span>])</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>theta_values <span class="op">=</span> [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Questo esercizio fornisce una comprensione pratica di come la regola softmax bilancia esplorazione e sfruttamento nei modelli di apprendimento per rinforzo.</p>
</div>
<div id="exr-rescorla-wagner-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 104.2</strong></span> L’obiettivo di questo esercizio è implementare il calcolo dell’errore di previsione nel modello di Rescorla-Wagner. Implementa una funzione Python <code>update_value(Q, R, alpha)</code> che prende in input il valore atteso attuale <code>Q</code>, la ricompensa ricevuta <code>R</code>, il tasso di apprendimento <code>alpha</code>, e restituisce il nuovo valore atteso aggiornato. La funzione deve anche restituire l’errore di previsione.</p>
<p>Il valore atteso <span class="math inline">\(Q\)</span> viene aggiornato secondo la seguente formula:</p>
<p><span class="math display">\[ \Delta Q = \alpha (R - Q), \]</span></p>
<p>dove <span class="math inline">\(\Delta Q\)</span> è la variazione del valore atteso, <span class="math inline">\(\alpha\)</span> è il tasso di apprendimento, <span class="math inline">\(R\)</span> è la ricompensa ricevuta, <span class="math inline">\(Q\)</span> è il valore atteso attuale.</p>
<p>Il nuovo valore atteso <span class="math inline">\(Q'\)</span> è dato da <span class="math inline">\(Q' = Q + \Delta Q\)</span>.</p>
<p>Usa:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># Valore atteso iniziale</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>R_values <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>]  <span class="co"># Sequenza di ricompense ricevute</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># Tasso di apprendimento</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Questo esercizio fornisce una comprensione pratica di come il modello di Rescorla-Wagner utilizza l’errore di previsione per aggiornare le aspettative di ricompensa.</p>
</div>
<div id="exr-rescorla-wagner-3" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 104.3</strong></span> L’obiettivo di questo esercizio è comprendere e interpretare i parametri del modello di apprendimento di Rescorla-Wagner. Considera i seguenti scenari in cui un agente sta apprendendo a fare delle scelte basate sulle ricompense ricevute. Per ciascuno scenario, descrivi come il tasso di apprendimento (<code>alpha</code>) e il valore iniziale atteso (<code>Q_0</code>) potrebbero influenzare il comportamento dell’agente.</p>
<ol type="1">
<li><strong>Scenario 1: Apprendimento Rapido in un Ambiente Stabile</strong> Un cane sta imparando a eseguire un nuovo trucco e riceve sempre una ricompensa (un bocconcino) ogni volta che esegue il trucco correttamente.</li>
<li><strong>Scenario 2: Apprendimento Lento in un Ambiente Stabile</strong> Un bambino sta imparando a risolvere puzzle semplici. Ogni volta che completa un puzzle, riceve una stella adesiva come ricompensa.</li>
<li><strong>Scenario 3: Apprendimento in un Ambiente Variabile</strong> Un giocatore di un videogioco sta cercando di capire quale arma è la migliore contro diversi nemici. Le ricompense (punteggi) per l’uso delle armi variano in modo imprevedibile.</li>
<li><strong>Scenario 4: Apprendimento con Informazioni Iniziali Parziali</strong> Un ricercatore che ha una conoscenza preliminare su quale farmaco potrebbe funzionare meglio sta conducendo un esperimento per confermare la sua ipotesi.</li>
</ol>
</div>
<div id="exr-rescorla-wagner-4" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 104.4</strong></span> L’obiettivo di questo esercizio è analizzare come il modello di Rescorla-Wagner può essere applicato in diversi contesti di apprendimento e come le variazioni nelle condizioni ambientali e nelle caratteristiche dell’agente possono influenzare l’efficacia dell’apprendimento.</p>
<p>Per ciascuno dei seguenti contesti di apprendimento, descrivi come l’errore di previsione e l’aggiornamento del valore atteso influenzerebbero il comportamento dell’agente. Discuti anche eventuali limitazioni del modello di Rescorla-Wagner nel catturare tutti gli aspetti del processo di apprendimento in quel contesto.</p>
<ol type="1">
<li><strong>Contesto 1: Addestramento di un Animale Domestico</strong> Un cane viene addestrato a eseguire un comando specifico, come “seduto”. Ogni volta che il cane esegue correttamente il comando, riceve una ricompensa.</li>
<li><strong>Contesto 2: Apprendimento Scolastico</strong> Uno studente sta imparando una nuova materia a scuola. Riceve un feedback positivo o negativo (es. voti) in base alle sue prestazioni nei compiti e nelle verifiche.</li>
<li><strong>Contesto 3: Terapia Comportamentale</strong> Un terapeuta utilizza tecniche di rinforzo per aiutare un paziente a superare una fobia. Il paziente riceve rinforzi positivi ogni volta che riesce ad affrontare la situazione temuta senza evitare.</li>
<li><strong>Contesto 4: Apprendimento nelle Organizzazioni</strong> Un’azienda implementa un sistema di premi per i dipendenti che raggiungono determinati obiettivi di performance. I dipendenti ricevono bonus e riconoscimenti in base ai risultati raggiunti.</li>
</ol>
</div>
</section>
<section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div id="cell-55" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-08-07T17:45:58.150570Z&quot;,&quot;start_time&quot;:&quot;2024-08-07T17:45:58.090781Z&quot;}" data-execution_count="26">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext watermark</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>watermark <span class="op">-</span>n <span class="op">-</span>u <span class="op">-</span>v <span class="op">-</span>iv <span class="op">-</span>w <span class="op">-</span>m</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Last updated: Sun Aug 18 2024

Python implementation: CPython
Python version       : 3.12.4
IPython version      : 8.26.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.6.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

numpy     : 1.26.4
seaborn   : 0.13.2
matplotlib: 3.9.1
arviz     : 0.18.0

Watermark: 2.4.3
</code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bornstein2017reinstated" class="csl-entry" role="listitem">
Bornstein, Aaron M, e Kenneth A Norman. 2017. <span>«Reinstated episodic context guides sampling-based decisions for reward»</span>. <em>Nature Neuroscience</em> 20 (7): 997–1003.
</div>
<div id="ref-browning2015anxious" class="csl-entry" role="listitem">
Browning, Michael, Timothy E Behrens, Gerhard Jocham, Jill X O’reilly, e Sonia J Bishop. 2015. <span>«Anxious individuals have difficulty learning the causal statistics of aversive environments»</span>. <em>Nature Neuroscience</em> 18 (4): 590–96.
</div>
<div id="ref-caudek2021susceptibility" class="csl-entry" role="listitem">
Caudek, Corrado, Claudio Sica, Silvia Cerea, Ilaria Colpizzi, e Debora Stendardi. 2021. <span>«Susceptibility to eating disorders is associated with cognitive inflexibility in female university students»</span>. <em>Journal of Behavioral and Cognitive Therapy</em> 31 (4): 317–28.
</div>
<div id="ref-caudek2020cognitive" class="csl-entry" role="listitem">
Caudek, Corrado, Claudio Sica, Igor Marchetti, Ilaria Colpizzi, e Debora Stendardi. 2020. <span>«Cognitive inflexibility specificity for individuals with high levels of obsessive-compulsive symptoms»</span>. <em>Journal of Behavioral and Cognitive Therapy</em> 30 (2): 103–13.
</div>
<div id="ref-duncan2016memory" class="csl-entry" role="listitem">
Duncan, Katherine D, e Daphna Shohamy. 2016. <span>«Memory states influence value-based decisions.»</span> <em>Journal of Experimental Psychology: General</em> 145 (11): 1420.
</div>
<div id="ref-eckstein2020computational" class="csl-entry" role="listitem">
Eckstein, Maria K, e Anne GE Collins. 2020. <span>«Computational evidence for hierarchically structured reinforcement learning in humans»</span>. <em>Proceedings of the National Academy of Sciences</em> 117 (47): 29381–89.
</div>
<div id="ref-ecksteinhybrid" class="csl-entry" role="listitem">
Eckstein, Maria, Christopher Summerfield, Nathaniel Daw, e Kevin J Miller. s.d. <span>«Hybrid Neural-Cognitive Models Reveal How Memory Shapes Human Reward Learning»</span>.
</div>
<div id="ref-frank2012mechanisms" class="csl-entry" role="listitem">
Frank, Michael J, e David Badre. 2012. <span>«Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis»</span>. <em>Cerebral Cortex</em> 22 (3): 509–26.
</div>
<div id="ref-khaw2017normalized" class="csl-entry" role="listitem">
Khaw, Mel W, Paul W Glimcher, e Kenway Louie. 2017. <span>«Normalized value coding explains dynamic adaptation in the human valuation process»</span>. <em>Proceedings of the National Academy of Sciences</em> 114 (48): 12696–701.
</div>
<div id="ref-palminteri2015contextual" class="csl-entry" role="listitem">
Palminteri, Stefano, Mehdi Khamassi, Mateus Joffily, e Giorgio Coricelli. 2015. <span>«Contextual modulation of value signals in reward and punishment learning»</span>. <em>Nature Communications</em> 6 (1): 8096.
</div>
<div id="ref-pulcu2019misestimation" class="csl-entry" role="listitem">
Pulcu, Erdem, e Michael Browning. 2019. <span>«The misestimation of uncertainty in affective disorders»</span>. <em>Trends in Cognitive Sciences</em> 23 (10): 865–75.
</div>
<div id="ref-rescorla1972theory" class="csl-entry" role="listitem">
Rescorla, Robert A, e A. R. Wagner. 1972. <span>«A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and non-reinforcement»</span>. <em>Classical conditioning II, Current research and theory</em> 2: 64–69.
</div>
<div id="ref-schulz2019algorithmic" class="csl-entry" role="listitem">
Schulz, Eric, e Samuel J Gershman. 2019. <span>«The algorithmic architecture of exploration in the human brain»</span>. <em>Current Opinion in Neurobiology</em> 55: 7–14.
</div>
<div id="ref-soto2023rescorla" class="csl-entry" role="listitem">
Soto, Fabian A, Edgar H Vogel, Yerco E Uribe-Bahamonde, e Omar D Perez. 2023. <span>«Why is the Rescorla-Wagner model so influential?»</span> <em>Neurobiology of Learning and Memory</em> 204: 107794.
</div>
<div id="ref-sutton2018reinforcement" class="csl-entry" role="listitem">
Sutton, Richard S, e Andrew G Barto. 2018. <span>«Reinforcement Learning: an introduction, second edi»</span>. The MIT Press.
</div>
<div id="ref-yaple2019fractionating" class="csl-entry" role="listitem">
Yaple, Zachary A, e Rongjun Yu. 2019. <span>«Fractionating adaptive learning: A meta-analysis of the reversal learning paradigm»</span>. <em>Neuroscience &amp; Biobehavioral Reviews</em> 102: 85–94.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/dynamic_models/02_change_across_time.html" class="pagination-link" aria-label="Modellare il cambiamento nel tempo">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">103</span>&nbsp; <span class="chapter-title">Modellare il cambiamento nel tempo</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/dynamic_models/04_affect.html" class="pagination-link" aria-label="Le emozioni influenzano le emozioni">
        <span class="nav-page-text"><span class="chapter-number">105</span>&nbsp; <span class="chapter-title">Le emozioni influenzano le emozioni</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Data Science per Psicologi è stato scritto da Corrado Caudek.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/dynamic_models/03_rescorla_wagner.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro è stato realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>