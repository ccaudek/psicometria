<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Analisi dei dati per psicologi - 55&nbsp; Divergenza KL e ELPD</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter_5/05_32_stan_loo.html" rel="next">
<link href="../../chapters/chapter_5/05_30_entropy.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter_5/05_03_reglin_bayesian.html">Modelli lineari</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter_5/05_31_kl.html"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Divergenza KL e ELPD</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Analisi dei dati per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/00_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/01_python_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Python (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/02_python_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/03_numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/04_pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Pandas (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/05_pandas_aggregate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Pandas (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/06_pandas_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pandas (3)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/07_matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/08_seaborn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Seaborn</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/00_scientific_method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">La scienza dei dati e il metodo scientifico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/01_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/02_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/03_freq_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di Frequenze</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/04_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/05_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/06_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduzione al calcolo delle probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/02_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/03_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04a_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04b_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04c_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/05_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/06_density_func.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La funzione di densità di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/07_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/08_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/09_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/10_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Inferenza Bayesiana</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Modellazione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/02_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/03_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/04_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/05_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/06_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/10_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Monte Carlo a Catena di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/15_stan_beta_binomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/16_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/17_stan_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/18_stan_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/19_stan_odds_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Analisi bayesiana dell’odds-ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/22_stan_normal_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Modelli lineari</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_03_reglin_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Modello di regressione lineare bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_04_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_05_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_05a_stan_multreg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Regressione multipla con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_06_hier_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Il modello lineare gerarchico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_07_robust_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Regressione robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_08_specification_error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Errore di specificazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_09_causal_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Inferenza causale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_21_stan_binomial_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Regressione binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_22_stan_logistic_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_23_stan_poisson_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Regressione di Poisson con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_24_stan_mixed_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modelli misti con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_30_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_31_kl.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Divergenza KL e ELPD</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_32_stan_loo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Validazione Incrociata Leave-One-Out</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_35_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Dati mancanti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_40_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a00_installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Ambiente di lavoro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a01_markdown.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a03_colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Colab: un breve tutorial</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a04_virtual_env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Ambienti virtuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a13a_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Sigma algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a44_montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Simulazione Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a46_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">M</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../99-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione">Introduzione</a></li>
  <li><a href="#confronto-di-modelli-utilizzando-la-divergenza-mathbbkl" id="toc-confronto-di-modelli-utilizzando-la-divergenza-mathbbkl" class="nav-link" data-scroll-target="#confronto-di-modelli-utilizzando-la-divergenza-mathbbkl"><span class="header-section-number">55.1</span> Confronto di Modelli Utilizzando la Divergenza <span class="math inline">\(\mathbb{KL}\)</span></a>
  <ul class="collapse">
  <li><a href="#la-distribuzione-predittiva-posteriori" id="toc-la-distribuzione-predittiva-posteriori" class="nav-link" data-scroll-target="#la-distribuzione-predittiva-posteriori"><span class="header-section-number">55.1.1</span> La Distribuzione Predittiva Posteriori</a></li>
  <li><a href="#misurazione-della-divergenza-mathbbkl" id="toc-misurazione-della-divergenza-mathbbkl" class="nav-link" data-scroll-target="#misurazione-della-divergenza-mathbbkl"><span class="header-section-number">55.1.2</span> Misurazione della Divergenza <span class="math inline">\(\mathbb{KL}\)</span></a></li>
  <li><a href="#confronto-pratico-tra-modelli" id="toc-confronto-pratico-tra-modelli" class="nav-link" data-scroll-target="#confronto-pratico-tra-modelli"><span class="header-section-number">55.1.3</span> Confronto Pratico tra Modelli</a></li>
  </ul></li>
  <li><a href="#expected-log-predictive-density-elpd" id="toc-expected-log-predictive-density-elpd" class="nav-link" data-scroll-target="#expected-log-predictive-density-elpd"><span class="header-section-number">55.2</span> Expected Log Predictive Density (ELPD)</a>
  <ul class="collapse">
  <li><a href="#collegamento-con-la-divergenza-mathbbkl" id="toc-collegamento-con-la-divergenza-mathbbkl" class="nav-link" data-scroll-target="#collegamento-con-la-divergenza-mathbbkl"><span class="header-section-number">55.2.1</span> Collegamento con la Divergenza <span class="math inline">\(\mathbb{KL}\)</span></a></li>
  </ul></li>
  <li><a href="#metodi-di-approssimazione-per-la-stima-dellelpd" id="toc-metodi-di-approssimazione-per-la-stima-dellelpd" class="nav-link" data-scroll-target="#metodi-di-approssimazione-per-la-stima-dellelpd"><span class="header-section-number">55.3</span> Metodi di Approssimazione per la Stima dell’ELPD</a>
  <ul class="collapse">
  <li><a href="#obiettivo-dei-criteri-di-informazione" id="toc-obiettivo-dei-criteri-di-informazione" class="nav-link" data-scroll-target="#obiettivo-dei-criteri-di-informazione"><span class="header-section-number">55.3.1</span> Obiettivo dei Criteri di Informazione</a></li>
  <li><a href="#errore-quadratico-medio-mse" id="toc-errore-quadratico-medio-mse" class="nav-link" data-scroll-target="#errore-quadratico-medio-mse"><span class="header-section-number">55.3.2</span> Errore Quadratico Medio (MSE)</a></li>
  <li><a href="#criterio-di-informazione-di-akaike-aic" id="toc-criterio-di-informazione-di-akaike-aic" class="nav-link" data-scroll-target="#criterio-di-informazione-di-akaike-aic"><span class="header-section-number">55.3.3</span> Criterio di Informazione di Akaike (AIC)</a></li>
  <li><a href="#criterio-di-informazione-bayesiano-bic" id="toc-criterio-di-informazione-bayesiano-bic" class="nav-link" data-scroll-target="#criterio-di-informazione-bayesiano-bic"><span class="header-section-number">55.3.4</span> Criterio di Informazione Bayesiano (BIC)</a></li>
  <li><a href="#widely-applicable-information-criterion-waic" id="toc-widely-applicable-information-criterion-waic" class="nav-link" data-scroll-target="#widely-applicable-information-criterion-waic"><span class="header-section-number">55.3.5</span> Widely Applicable Information Criterion (WAIC)</a></li>
  <li><a href="#leave-one-out-cross-validation-loo-cv" id="toc-leave-one-out-cross-validation-loo-cv" class="nav-link" data-scroll-target="#leave-one-out-cross-validation-loo-cv"><span class="header-section-number">55.3.6</span> Leave-One-Out Cross-Validation (LOO-CV)</a></li>
  <li><a href="#valutazione-comparativa-e-applicazioni-pratiche" id="toc-valutazione-comparativa-e-applicazioni-pratiche" class="nav-link" data-scroll-target="#valutazione-comparativa-e-applicazioni-pratiche"><span class="header-section-number">55.3.7</span> Valutazione Comparativa e Applicazioni Pratiche</a></li>
  </ul></li>
  <li><a href="#considerazioni-conclusive" id="toc-considerazioni-conclusive" class="nav-link" data-scroll-target="#considerazioni-conclusive"><span class="header-section-number">55.4</span> Considerazioni Conclusive</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/chapter_5/05_31_kl.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter_5/05_03_reglin_bayesian.html">Modelli lineari</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter_5/05_31_kl.html"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Divergenza KL e ELPD</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="saec-kl" class="quarto-section-identifier"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Divergenza KL e ELPD</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Prerequisiti</strong></p>
<p><strong>Concetti e competenze chiave</strong></p>
<ul>
<li>Comprendere in modo dettagliato il concetto di Expected Log Predictive Density (ELPD), apprezzandone l’importanza e l’applicabilità nel contesto della valutazione predittiva dei modelli statistici.</li>
<li>Esplorare e analizzare la relazione tra il concetto di entropia e la ELPD, identificando come l’entropia possa influenzare o riflettere la capacità predittiva di un modello attraverso la densità logaritmica predittiva prevista.</li>
</ul>
<p><strong>Preparazione del Notebook</strong></p>
<div id="1a6aa9ee-fd35-44ce-a0e5-69f1d084dfcb" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> binom</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c6520d11-c083-4b80-86b5-dcb07dab3975" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>seed: <span class="bu">int</span> <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">map</span>(<span class="bu">ord</span>, <span class="st">"kl"</span>))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>rng: np.random.Generator <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>seed)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">"arviz-darkgrid"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">"retina"</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>In questo capitolo, esamineremo in dettaglio due concetti fondamentali per la valutazione e il confronto di modelli statistici nel contesto bayesiano: la Divergenza di Kullback-Leibler (<span class="math inline">\(\mathbb{KL}\)</span>) e la Densità Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD). Questi strumenti ci permettono di quantificare l’adattamento dei modelli ai dati e la loro capacità predittiva.</p>
</section>
<section id="confronto-di-modelli-utilizzando-la-divergenza-mathbbkl" class="level2" data-number="55.1">
<h2 data-number="55.1" class="anchored" data-anchor-id="confronto-di-modelli-utilizzando-la-divergenza-mathbbkl"><span class="header-section-number">55.1</span> Confronto di Modelli Utilizzando la Divergenza <span class="math inline">\(\mathbb{KL}\)</span></h2>
<section id="la-distribuzione-predittiva-posteriori" class="level3" data-number="55.1.1">
<h3 data-number="55.1.1" class="anchored" data-anchor-id="la-distribuzione-predittiva-posteriori"><span class="header-section-number">55.1.1</span> La Distribuzione Predittiva Posteriori</h3>
<p>La distribuzione predittiva posteriori, indicata come <span class="math inline">\(Q(\tilde{y} \mid y)\)</span>, rappresenta le previsioni su nuovi dati <span class="math inline">\(\tilde{y}\)</span> basate su un modello statistico <span class="math inline">\(Q\)</span> e i dati osservati <span class="math inline">\(y\)</span>. Questa distribuzione combina:</p>
<ol type="1">
<li>Le previsioni del modello per un dato set di parametri <span class="math inline">\(\theta\)</span>, ovvero <span class="math inline">\(Q(\tilde{y} \mid \theta)\)</span>.</li>
<li>La distribuzione posteriore di questi parametri dati i dati osservati, cioè <span class="math inline">\(P(\theta \mid y)\)</span>.</li>
</ol>
<p>Questa combinazione permette di fare previsioni che tengono conto sia dell’incertezza nei parametri che della struttura del modello.</p>
</section>
<section id="misurazione-della-divergenza-mathbbkl" class="level3" data-number="55.1.2">
<h3 data-number="55.1.2" class="anchored" data-anchor-id="misurazione-della-divergenza-mathbbkl"><span class="header-section-number">55.1.2</span> Misurazione della Divergenza <span class="math inline">\(\mathbb{KL}\)</span></h3>
<p>La divergenza <span class="math inline">\(\mathbb{KL}\)</span> quantifica quanto bene la distribuzione predittiva del modello <span class="math inline">\(Q\)</span> si avvicina alla distribuzione vera <span class="math inline">\(P\)</span> che ha generato i dati. Matematicamente, questo è espresso come <span class="math inline">\(\mathbb{KL}(P \parallel Q)\)</span>.</p>
<p>Interpretazione:</p>
<ul>
<li>Un valore basso di <span class="math inline">\(\mathbb{KL}\)</span> indica che <span class="math inline">\(Q\)</span> è una buona approssimazione di <span class="math inline">\(P\)</span>.</li>
<li>Un valore alto indica una maggiore discrepanza tra le due distribuzioni.</li>
</ul>
</section>
<section id="confronto-pratico-tra-modelli" class="level3" data-number="55.1.3">
<h3 data-number="55.1.3" class="anchored" data-anchor-id="confronto-pratico-tra-modelli"><span class="header-section-number">55.1.3</span> Confronto Pratico tra Modelli</h3>
<p>Poiché non conosciamo direttamente <span class="math inline">\(P\)</span>, la vera distribuzione che ha generato i dati, utilizziamo la divergenza <span class="math inline">\(\mathbb{KL}\)</span> per confrontare diversi modelli. La formula generale per la divergenza <span class="math inline">\(\mathbb{KL}\)</span> tra due distribuzioni <span class="math inline">\(P\)</span> e <span class="math inline">\(Q\)</span> è:</p>
<p><span class="math display">\[
\mathbb{KL}(P \parallel Q) = \mathbb{E}_P[\log P] - \mathbb{E}_P[\log Q],
\]</span></p>
<p>dove <span class="math inline">\(\mathbb{E}_P\)</span> indica il valore atteso calcolato sotto la distribuzione <span class="math inline">\(P\)</span>.</p>
<p>Per distribuzioni discrete, questa si esprime come:</p>
<p><span class="math display">\[
\mathbb{KL}(P \parallel Q) = \sum_{i=1}^n p_i (\log p_i - \log q_i),
\]</span></p>
<p>dove <span class="math inline">\(p_i\)</span> e <span class="math inline">\(q_i\)</span> rappresentano le probabilità degli eventi <span class="math inline">\(i\)</span> per le distribuzioni <span class="math inline">\(P\)</span> e <span class="math inline">\(Q\)</span> rispettivamente.</p>
<p>La divergenza <span class="math inline">\(\mathbb{KL}\)</span> può essere riformulata in termini di valore atteso come segue:</p>
<ul>
<li><p>Termine <span class="math inline">\(\log P\)</span>: <span class="math display">\[
\mathbb{E}_P[\log P(X)] = \sum_{i=1}^n p_i \log p_i
\]</span> Questo termine rappresenta l’entropia negativa di <span class="math inline">\(P\)</span>.</p></li>
<li><p>Termine <span class="math inline">\(\log Q\)</span>: <span class="math display">\[
\mathbb{E}_P[\log Q(X)] = \sum_{i=1}^n p_i \log q_i
\]</span> Questo termine rappresenta l’entropia incrociata tra <span class="math inline">\(P\)</span> e <span class="math inline">\(Q\)</span>.</p></li>
</ul>
<p>Quindi, la divergenza <span class="math inline">\(\mathbb{KL}\)</span> si riduce a:</p>
<p><span class="math display">\[
\mathbb{KL}(P \parallel Q) = \mathbb{E}_P[\log P(X)] - \mathbb{E}_P[\log Q(X)]
\]</span></p>
<p>Per variabili continue, la formula diventa:</p>
<p><span class="math display">\[
\mathbb{KL}(P \parallel Q) = \int p(x) (\log p(x) - \log q(x)) \, dx.
\]</span></p>
<p>Nella pratica del confronto tra modelli, il termine <span class="math inline">\(\mathbb{E}_P[\log P]\)</span> rimane costante per tutti i modelli confrontati e può quindi essere omesso. Ci concentriamo dunque sul termine:</p>
<p><span class="math display">\[
-\mathbb{E}_P[\log Q(y)]
\]</span></p>
<p>che misura l’adattabilità del modello ai dati osservati. Questo si calcola come:</p>
<p><span class="math display">\[
-\int p(y) \log Q(y) \, dy,
\]</span></p>
<p>indicando quale modello <span class="math inline">\(Q\)</span> rappresenti meglio la distribuzione <span class="math inline">\(P\)</span> secondo la quantità di informazione che si perderebbe utilizzandolo per descrivere i dati osservati.</p>
</section>
</section>
<section id="expected-log-predictive-density-elpd" class="level2" data-number="55.2">
<h2 data-number="55.2" class="anchored" data-anchor-id="expected-log-predictive-density-elpd"><span class="header-section-number">55.2</span> Expected Log Predictive Density (ELPD)</h2>
<p>L’ELPD è una misura avanzata usata nei metodi bayesiani per valutare quanto bene un modello può prevedere nuovi dati. È come se stessimo chiedendo al modello: “Quanto sei sicuro delle tue previsioni per dati che non hai mai visto?”</p>
<p>La formula dell’ELPD è:</p>
<p><span class="math display">\[ \text{ELPD} = \sum_{i=1}^n \log p(y_i | \mathbf{y}_{-i}), \]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(y_i\)</span> è l’i-esima osservazione,</li>
<li><span class="math inline">\(\mathbf{y}_{-i}\)</span> rappresenta tutte le osservazioni eccetto <span class="math inline">\(y_i\)</span>.</li>
</ul>
<p>Interpretazione:</p>
<ul>
<li>L’ELPD misura quanto bene il modello può prevedere ogni singola osservazione basandosi su tutte le altre.</li>
<li>Un ELPD più alto indica un modello con migliori capacità predittive.</li>
</ul>
<section id="collegamento-con-la-divergenza-mathbbkl" class="level3" data-number="55.2.1">
<h3 data-number="55.2.1" class="anchored" data-anchor-id="collegamento-con-la-divergenza-mathbbkl"><span class="header-section-number">55.2.1</span> Collegamento con la Divergenza <span class="math inline">\(\mathbb{KL}\)</span></h3>
<p>Il collegamento tra <span class="math inline">\(-\mathbb{E}_P[\log Q(y)]\)</span> e l’ELPD è che entrambi misurano la capacità predittiva di un modello, ma in modi leggermente diversi:</p>
<ol type="1">
<li><span class="math inline">\(-\mathbb{E}_P[\log Q(y)]\)</span> misura la divergenza tra la vera distribuzione <span class="math inline">\(P\)</span> e la distribuzione del modello <span class="math inline">\(Q\)</span>, indicando quanto bene <span class="math inline">\(Q\)</span> approssima <span class="math inline">\(P\)</span>.</li>
<li>L’ELPD, d’altra parte, misura direttamente la capacità del modello di prevedere nuove osservazioni, utilizzando un approccio di convalida incrociata leave-one-out.</li>
</ol>
<p>L’ELPD si focalizza sulla capacità di un modello di predire nuovi dati, offrendo una misura della sua capacità di generalizzazione. Matematicamente, l’ELPD è definito come il valore atteso del logaritmo della densità predittiva di un modello, calcolato sotto la vera distribuzione dei dati futuri:</p>
<p><span class="math display">\[
\text{ELPD} = \mathbb{E}_{y \sim p(y)} [\log p(y \mid \theta)]
\]</span></p>
<p>Mentre <span class="math inline">\(-\int p(y) \log Q(y) \, dy\)</span> quantifica quanto bene un modello descrive la distribuzione attuale dei dati, l’ELPD stima quanto efficacemente il modello può essere utilizzato per prevedere nuovi dati. Questo rende l’ELPD una misura complementare alla <span class="math inline">\(\mathbb{KL}\)</span>, enfatizzando non solo l’adattabilità ma anche la predittività di un modello.</p>
<p>In conclusione, utilizzare l’ELPD come criterio di valutazione tende a favorire modelli che non solo si adattano bene ai dati esistenti ma sono anche robusti contro l’overfitting. La combinazione di Divergenza <span class="math inline">\(\mathbb{KL}\)</span> ed ELPD fornisce una valutazione completa dei modelli, considerando sia la loro capacità di adattarsi ai dati osservati che la loro abilità nel fare previsioni accurate su nuovi dati.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Esempio 55.1</strong></span> Consideriamo un esempio utilizzando la distribuzione binomiale per illustrare il concetto di ELPD. Immaginiamo un esperimento in cui lanciamo una moneta 10 volte e contiamo il numero di teste. Supponiamo che la vera probabilità di ottenere testa sia 0.6 (anche se nella realtà non la conosceremmo).</p>
<ol type="1">
<li>La vera distribuzione dei dati segue una Binomiale(n=10, p=0.6): <span class="math inline">\(y \sim \text{Binomiale}(10, 0.6)\)</span></li>
<li>Il nostro modello stima <span class="math inline">\(p=0.5\)</span> (ipotizziamo una moneta equa): <span class="math inline">\(p(y|\theta) = \text{Binomiale}(10, 0.5)\)</span></li>
</ol>
<p>Calcoliamo l’ELPD:</p>
<div id="cell-5" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">10</span>  <span class="co"># numero di lanci</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>p_true <span class="op">=</span> <span class="fl">0.6</span>  <span class="co"># vera probabilità di testa</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>p_model <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># probabilità stimata dal modello</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo ELPD</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>elpd <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> y <span class="kw">in</span> <span class="bu">range</span>(n <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Probabilità di y secondo la vera distribuzione</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    p_true_y <span class="op">=</span> binom.pmf(y, n, p_true)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log della densità predittiva del modello</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    log_p_model_y <span class="op">=</span> binom.logpmf(y, n, p_model)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Somma pesata</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    elpd <span class="op">+=</span> p_true_y <span class="op">*</span> log_p_model_y</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ELPD del modello che stima p=0.5: </span><span class="sc">{</span>elpd<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Per confronto, calcoliamo l'ELPD per il modello "vero"</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>elpd_true <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> y <span class="kw">in</span> <span class="bu">range</span>(n <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    p_true_y <span class="op">=</span> binom.pmf(y, n, p_true)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    log_p_true_y <span class="op">=</span> binom.logpmf(y, n, p_true)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    elpd_true <span class="op">+=</span> p_true_y <span class="op">*</span> log_p_true_y</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ELPD del modello vero (con p=0.6): </span><span class="sc">{</span>elpd_true<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ELPD del modello che stima p=0.5: -2.0549
ELPD del modello vero (con p=0.6): -1.8536</code></pre>
</div>
</div>
<p>L’ELPD del modello vero è maggiore (meno negativo) di quello del nostro modello stimato, indicando una migliore capacità predittiva.</p>
<p>Questo esempio illustra come l’ELPD quantifica la capacità predittiva di un modello:</p>
<ol type="1">
<li>Considera tutti i possibili risultati (da 0 a 10 teste).</li>
<li>Per ogni risultato, calcola:
<ul>
<li>La probabilità di quel risultato secondo la vera distribuzione.</li>
<li>Il logaritmo della densità predittiva del nostro modello per quel risultato.</li>
</ul></li>
<li>Moltiplica questi due valori e somma su tutti i possibili risultati.</li>
</ol>
<p>In conclusione, l’ELPD ci permette di confrontare modelli diversi: un valore più alto (meno negativo) indica una migliore capacità predittiva. Nel nostro caso, il vero modello (p=0.6) ha un ELPD maggiore del modello stimato (p=0.5).</p>
</div>
</section>
</section>
<section id="metodi-di-approssimazione-per-la-stima-dellelpd" class="level2" data-number="55.3">
<h2 data-number="55.3" class="anchored" data-anchor-id="metodi-di-approssimazione-per-la-stima-dellelpd"><span class="header-section-number">55.3</span> Metodi di Approssimazione per la Stima dell’ELPD</h2>
<p>L’ELPD è un importante indicatore della qualità di un modello statistico. Tuttavia, poiché la vera distribuzione dei dati è sconosciuta, non possiamo calcolare direttamente l’ELPD. Per superare questa limitazione, utilizziamo metodi di approssimazione noti come “criteri di informazione”.</p>
<section id="obiettivo-dei-criteri-di-informazione" class="level3" data-number="55.3.1">
<h3 data-number="55.3.1" class="anchored" data-anchor-id="obiettivo-dei-criteri-di-informazione"><span class="header-section-number">55.3.1</span> Obiettivo dei Criteri di Informazione</h3>
<p>I criteri di informazione ci aiutano a bilanciare due aspetti cruciali nella valutazione di un modello:</p>
<ol type="1">
<li>L’adattamento del modello ai dati osservati</li>
<li>La complessità del modello</li>
</ol>
<p>Esaminiamo alcuni dei criteri più comuni utilizzati per approssimare l’ELPD.</p>
</section>
<section id="errore-quadratico-medio-mse" class="level3" data-number="55.3.2">
<h3 data-number="55.3.2" class="anchored" data-anchor-id="errore-quadratico-medio-mse"><span class="header-section-number">55.3.2</span> Errore Quadratico Medio (MSE)</h3>
<p>L’Errore Quadratico Medio (Mean Squared Error o MSE) misura la discrepanza media tra le previsioni del modello e i valori reali.</p>
<p><strong>Formula:</strong></p>
<p><span class="math display">\[ MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2, \]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(n\)</span> è il numero totale di osservazioni,</li>
<li><span class="math inline">\(y_i\)</span> sono i valori reali,</li>
<li><span class="math inline">\(\hat{y}_i\)</span> sono i valori previsti dal modello.</li>
</ul>
<p>Un MSE inferiore indica un migliore adattamento del modello ai dati.</p>
</section>
<section id="criterio-di-informazione-di-akaike-aic" class="level3" data-number="55.3.3">
<h3 data-number="55.3.3" class="anchored" data-anchor-id="criterio-di-informazione-di-akaike-aic"><span class="header-section-number">55.3.3</span> Criterio di Informazione di Akaike (AIC)</h3>
<p>Il Criterio di Informazione di Akaike (AIC) va oltre l’MSE, considerando sia l’adattamento del modello che la sua complessità.</p>
<p><strong>Formula:</strong></p>
<p><span class="math display">\[ AIC = -2 \sum \log p(y_i \mid \hat{\theta}_{\text{mle}}) + 2k, \]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(\hat{\theta}_{\text{mle}}\)</span> sono i parametri stimati del modello,</li>
<li><span class="math inline">\(k\)</span> è il numero di parametri del modello.</li>
</ul>
<p>L’AIC bilancia la bontà di adattamento (primo termine) con la complessità del modello (secondo termine). Un valore più basso di AIC indica una minor perdita di informazione, suggerendo un modello preferibile.</p>
<p><strong>Vantaggi e Limitazioni:</strong></p>
<ul>
<li>Facile e veloce da calcolare.</li>
<li>Può essere meno accurato per campioni piccoli o modelli complessi.</li>
<li>Fornisce un’approssimazione asintoticamente corretta dell’ELPD per modelli regolari e campioni grandi.</li>
</ul>
</section>
<section id="criterio-di-informazione-bayesiano-bic" class="level3" data-number="55.3.4">
<h3 data-number="55.3.4" class="anchored" data-anchor-id="criterio-di-informazione-bayesiano-bic"><span class="header-section-number">55.3.4</span> Criterio di Informazione Bayesiano (BIC)</h3>
<p>Il Criterio di Informazione Bayesiano (BIC) è definito come:</p>
<p><span class="math display">\[
BIC = \ln(n)k - 2\ln(L),
\]</span></p>
<p>dove <span class="math inline">\(n\)</span> è il numero di osservazioni.</p>
<p>Il BIC impone una penalità maggiore per l’incremento dei parametri, rendendolo particolarmente adeguato per dataset di grandi dimensioni.</p>
</section>
<section id="widely-applicable-information-criterion-waic" class="level3" data-number="55.3.5">
<h3 data-number="55.3.5" class="anchored" data-anchor-id="widely-applicable-information-criterion-waic"><span class="header-section-number">55.3.5</span> Widely Applicable Information Criterion (WAIC)</h3>
<p>Il WAIC è una versione avanzata dell’AIC, particolarmente utile nel contesto bayesiano. Considera l’intera distribuzione a posteriori dei parametri anziché solo la stima puntuale.</p>
<p><strong>Formula:</strong></p>
<p><span class="math display">\[ WAIC = -2\left[ \sum_{i=1}^{n} \log \left( \frac{1}{S} \sum_{s=1}^{S} p(y_i|\theta^{(s)}) \right) - \sum_{i=1}^{n} \text{Var}_{\theta^{(s)}} \left( \log p(y_i|\theta^{(s)}) \right) \right], \]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(S\)</span> è il numero di campioni dalla distribuzione a posteriori,</li>
<li><span class="math inline">\(\text{Var}_{\theta^{(s)}}\)</span> è la varianza della log-verosimiglianza.</li>
</ul>
<p><strong>Caratteristiche del WAIC:</strong></p>
<ol type="1">
<li>Calcola il logaritmo della densità predittiva per ogni punto dati.</li>
<li>Penalizza la complessità del modello basandosi sulla variabilità delle sue predizioni.</li>
<li>La somma delle varianze a posteriori del logaritmo della densità predittiva converge al numero effettivo di parametri del modello.</li>
</ol>
</section>
<section id="leave-one-out-cross-validation-loo-cv" class="level3" data-number="55.3.6">
<h3 data-number="55.3.6" class="anchored" data-anchor-id="leave-one-out-cross-validation-loo-cv"><span class="header-section-number">55.3.6</span> Leave-One-Out Cross-Validation (LOO-CV)</h3>
<p>Il LOO-CV è un metodo robusto che massimizza l’utilizzo dei dati disponibili, rendendolo ideale per modelli complessi e campioni di dimensioni ridotte.</p>
<p><strong>Procedura:</strong></p>
<ol type="1">
<li>Rimuove un’osservazione alla volta.</li>
<li>Adatta il modello sui dati rimanenti.</li>
<li>Valuta la densità predittiva per l’osservazione esclusa.</li>
</ol>
<p><strong>Formula:</strong></p>
<p><span class="math display">\[ \text{Stima dell'ELPD} = \sum_{i=1}^N \log p(y_i \mid y_{-i}), \]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(y_i\)</span> è il dato escluso,</li>
<li><span class="math inline">\(y_{-i}\)</span> rappresenta tutti gli altri dati.</li>
</ul>
<p><strong>Vantaggi e Limitazioni:</strong></p>
<ul>
<li>Fornisce una stima robusta dell’ELPD.</li>
<li>Particolarmente utile per set di dati non molto ampi.</li>
<li>Computazionalmente intensivo.</li>
</ul>
</section>
<section id="valutazione-comparativa-e-applicazioni-pratiche" class="level3" data-number="55.3.7">
<h3 data-number="55.3.7" class="anchored" data-anchor-id="valutazione-comparativa-e-applicazioni-pratiche"><span class="header-section-number">55.3.7</span> Valutazione Comparativa e Applicazioni Pratiche</h3>
<p>Questi metodi forniscono diverse prospettive sulla stima dell’ELPD. Il LOO-CV è particolarmente prezioso per modelli complessi o set di dati limitati, mentre AIC e WAIC offrono approcci più rapidi e meno computazionalmente intensivi, adatti per valutazioni preliminari o quando si dispone di grandi set di dati.</p>
<p>In conclusione, la selezione del modello ottimale richiede un equilibrio tra adattamento ai dati e semplicità. L’utilizzo combinato di tecniche di validazione incrociata e criteri di informazione permette di costruire modelli che:</p>
<ol type="1">
<li>si adattano bene ai dati attuali,</li>
<li>sono in grado di fare previsioni affidabili su nuovi dati,</li>
<li>catturano le tendenze importanti senza perdersi nel rumore.</li>
</ol>
<p>L’obiettivo finale non è creare il modello più complesso o quello che si adatta perfettamente ai dati di addestramento, ma trovare un equilibrio ottimale tra semplicità e accuratezza.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Esempio 55.2</strong></span> Il seguente script Python dimostra come calcolare l’AIC per un modello binomiale. Ecco una breve spiegazione del codice:</p>
<ul>
<li>Definiamo una funzione per la log-verosimiglianza negativa del modello binomiale.</li>
<li>Implementiamo una funzione per calcolare l’AIC dato il valore di log-verosimiglianza e il numero di parametri.</li>
<li>Utilizziamo scipy.optimize.minimize per trovare il parametro che massimizza la verosimiglianza.</li>
<li>Calcoliamo l’AIC per il modello binomiale.</li>
</ul>
<div id="cell-8" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dati di esempio </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>n_trials <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>true_p <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.binomial(n_trials, true_p, size<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Funzione di log-verosimiglianza negativa</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> neg_log_likelihood(p, data, n):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.<span class="bu">sum</span>(binom.logpmf(data, n, p))</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Funzione per calcolare l'AIC</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_aic(log_likelihood, k):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> k <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> log_likelihood</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Ottimizzazione per trovare la massima verosimiglianza</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    neg_log_likelihood,</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    x0<span class="op">=</span>[<span class="fl">0.5</span>],</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>(data, n_trials),</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">"L-BFGS-B"</span>,</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    bounds<span class="op">=</span>[(<span class="dv">0</span>, <span class="dv">1</span>)],</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Estrai il parametro ottimale e la log-verosimiglianza</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>p_mle <span class="op">=</span> result.x[<span class="dv">0</span>]</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>max_log_likelihood <span class="op">=</span> <span class="op">-</span>result.fun</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcola l'AIC</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">1</span>  <span class="co"># numero di parametri (solo p in questo caso)</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>aic <span class="op">=</span> calculate_aic(max_log_likelihood, k)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Parametro stimato (p): </span><span class="sc">{</span>p_mle<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-verosimiglianza massimizzata: </span><span class="sc">{</span>max_log_likelihood<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AIC: </span><span class="sc">{</span>aic<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parametro stimato (p): 0.5000
Log-verosimiglianza massimizzata: -567.8227
AIC: 1137.6453</code></pre>
</div>
</div>
<p>Questo esempio mostra come calcolare l’AIC. Questo indice può essere utilizzato per confrontare modelli con diversi livelli di complessità. Il modello con l’AIC più basso è generalmente considerato il migliore in termini di compromesso tra adattamento ai dati e complessità del modello.</p>
</div>
</section>
</section>
<section id="considerazioni-conclusive" class="level2" data-number="55.4">
<h2 data-number="55.4" class="anchored" data-anchor-id="considerazioni-conclusive"><span class="header-section-number">55.4</span> Considerazioni Conclusive</h2>
<p>L’ELPD e la divergenza <span class="math inline">\(\mathbb{KL}\)</span> sono strumenti complementari per la valutazione dei modelli statistici:</p>
<ol type="1">
<li>ELPD: Misura la capacità predittiva su nuovi dati. Più alto è l’ELPD, migliori sono le previsioni.</li>
<li>Divergenza <span class="math inline">\(\mathbb{KL}\)</span>: Quantifica la differenza tra la distribuzione vera dei dati e quella del modello. Una divergenza KL minore indica una migliore approssimazione.</li>
</ol>
<p>Relazione tra ELPD e divergenza <span class="math inline">\(\mathbb{KL}\)</span>:</p>
<ul>
<li>Un alto ELPD generalmente corrisponde a una bassa divergenza <span class="math inline">\(\mathbb{KL}\)</span>.</li>
<li>Massimizzare l’ELPD equivale a minimizzare la divergenza <span class="math inline">\(\mathbb{KL}\)</span>.</li>
<li>Entrambi guidano verso modelli che catturano meglio la realtà dei dati.</li>
</ul>
<p>Nella pratica:</p>
<ul>
<li>La divergenza <span class="math inline">\(\mathbb{KL}\)</span> valuta l’adattamento ai dati osservati.</li>
<li>L’ELPD e i suoi metodi di approssimazione (LOO-CV, AIC, WAIC) misurano la capacità di generalizzazione a dati futuri.</li>
</ul>
<p>In conclusione, l’ELPD, la divergenza <span class="math inline">\(\mathbb{KL}\)</span> e i relativi metodi di approssimazione forniscono un framework essenziale per la valutazione e la selezione di modelli statistici, bilanciando efficacemente l’adattamento ai dati con la capacità predittiva su nuove osservazioni.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Esempio 55.3</strong></span> Consideriamo un esempio numerico per confrontare AIC con la divergenza <span class="math inline">\(\mathbb{KL}\)</span>. Supponiamo di avere un set di dati e due modelli statistici: il primo modello si adatta bene ai dati (modello vero), mentre il secondo è un po’ più distante dalla realtà (modello alternativo, ne considereremo 5). Calcoleremo la divergenza <span class="math inline">\(\mathbb{KL}\)</span> tra le distribuzioni previste da questi modelli e il Criterio di Informazione di Akaike per valutare la qualità di adattamento dei modelli.</p>
<p>Per questo esempio, supponiamo di avere un set di dati e due modelli statistici: il primo modello si adatta bene ai dati (modello vero), mentre il secondo è un po’ più distante dalla realtà (modello alternativo). Calcoleremo la divergenza <span class="math inline">\(\mathbb{KL}\)</span> tra le distribuzioni previste da questi modelli e il Criterio di Informazione di Akaike per valutare la qualità di adattamento dei modelli.</p>
<ul>
<li>Supponiamo che i dati siano generati da una distribuzione normale con media vera <span class="math inline">\(\mu = 0\)</span> e deviazione standard <span class="math inline">\(\sigma = 1\)</span>.</li>
<li>Assumiamo che il modello vero conosca i parametri della distribuzione.</li>
<li>Assumiamo che questo modello abbia una deviazione standard leggermente diversa (considereremo 5 modelli diversi: <span class="math inline">\(\sigma\)</span> = 1.5 fino a 5.0).</li>
</ul>
<div id="cell-12" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generazione dei dati simulati</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri del modello vero</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>mu_true, sigma_true <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Variazione di sigma_alt</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>sigma_alts <span class="op">=</span> np.linspace(<span class="fl">1.5</span>, <span class="fl">5.0</span>, <span class="dv">5</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>KL_divergences <span class="op">=</span> []</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>AIC_values <span class="op">=</span> []</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo della divergenza KL e AIC per ogni sigma_alt</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sigma_alt <span class="kw">in</span> sigma_alts:</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    p_true <span class="op">=</span> stats.norm.pdf(data, mu_true, sigma_true)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    p_alt <span class="op">=</span> stats.norm.pdf(data, mu_true, sigma_alt)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    KL_divergence <span class="op">=</span> np.<span class="bu">sum</span>(p_true <span class="op">*</span> np.log(p_true <span class="op">/</span> p_alt))</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    KL_divergences.append(KL_divergence)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    log_likelihood_alt <span class="op">=</span> np.<span class="bu">sum</span>(np.log(stats.norm.pdf(data, mu_true, sigma_alt)))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    AIC_alt <span class="op">=</span> (</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="dv">2</span> <span class="op">*</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> log_likelihood_alt</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    )  <span class="co"># 2 parametri (mu e sigma), nessuna esponenziale</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    AIC_values.append(AIC_alt)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Creazione del grafico</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma_alts, KL_divergences, label<span class="op">=</span><span class="st">"Divergenza KL"</span>, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>plt.plot(sigma_alts, AIC_values, label<span class="op">=</span><span class="st">"AIC"</span>, marker<span class="op">=</span><span class="st">"x"</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Sigma Alternativo"</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Valore"</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Divergenza KL e AIC al variare di Sigma Alternativo"</span>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_31_kl_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Si vede che, anche se la scala di misura è diversa tra la divergenza <span class="math inline">\(\mathbb{KL}\)</span> e il criterio AIC, all’aumentare della differenza tra la distribuzione vera <span class="math inline">\(P\)</span> e la distribuzione alternativa <span class="math inline">\(Q\)</span>, entrambi aumentano.</p>
</div>
</section>
<section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div id="db756413-085f-4b9c-8b14-c2b409f80046" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext watermark</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>watermark <span class="op">-</span>n <span class="op">-</span>u <span class="op">-</span>v <span class="op">-</span>iv <span class="op">-</span>w</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Last updated: Fri Jul 26 2024

Python implementation: CPython
Python version       : 3.12.4
IPython version      : 8.26.0

arviz     : 0.18.0
matplotlib: 3.9.1
numpy     : 1.26.4
scipy     : 1.14.0

Watermark: 2.4.3
</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter_5/05_30_entropy.html" class="pagination-link" aria-label="Entropia">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Entropia</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter_5/05_32_stan_loo.html" class="pagination-link" aria-label="Validazione Incrociata Leave-One-Out">
        <span class="nav-page-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Validazione Incrociata Leave-One-Out</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/chapter_5/05_31_kl.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></div></div></footer></body></html>