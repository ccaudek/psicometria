<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Analisi dei dati per psicologi - 61&nbsp; Regressione logistica con Stan</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter_5/05_23_stan_poisson_regr.html" rel="next">
<link href="../../chapters/chapter_5/05_21_stan_binomial_regr.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter_5/introduction_chapter_5.html">Modelli lineari</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter_5/05_22_stan_logistic_regr.html"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Analisi dei dati per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/introduction_chapter_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/00_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/01_python_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/02_python_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Python (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/03_numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/04_pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Pandas (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/05_pandas_aggregate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pandas (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/06_pandas_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pandas (3)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/07_matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/08_seaborn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Seaborn</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/introduction_chapter_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/00_scientific_method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Il Ruolo della Data Science nella Psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/01_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/02_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/03_freq_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/04_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/05_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/06_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/introduction_chapter_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/01a_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/01b_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Misura di Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/01c_prob_on_general_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Misure e distribuzioni di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/02_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/03_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04a_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04b_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04c_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/05_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/06_density_func.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">La funzione di densità di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/07_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/08_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/09_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/10_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Inferenza Bayesiana</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/introduction_chapter_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Modellazione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/02_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/03_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/04_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/05_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/06_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/10_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Monte Carlo a Catena di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/15_stan_beta_binomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/16_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/17_stan_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/18_stan_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/19_stan_odds_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Analisi bayesiana dell’odds-ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/22_stan_normal_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/23_stan_two_groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/24_stan_hier_beta_binom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Modello gerarchico beta-binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/25_stan_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Modelli lineari</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/introduction_chapter_5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_03_reglin_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Modello di regressione lineare bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_04_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_05_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_05a_stan_multreg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Regressione multipla con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_06_hier_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Il modello lineare gerarchico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_07_robust_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Regressione robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_08_specification_error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Errore di specificazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_09_causal_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Inferenza causale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_21_stan_binomial_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Regressione binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_22_stan_logistic_regr.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_23_stan_poisson_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Regressione di Poisson con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_24_stan_mixed_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Modelli misti con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_25_stan_rct.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Incorporare dati storici di controllo in una RCT</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_30_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_31_kl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Divergenza KL e ELPD</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_32_stan_loo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Validazione Incrociata Leave-One-Out</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_35_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Dati mancanti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_40_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Inferenza frequentista</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/introduction_chapter_6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Introduzione all’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Intervallo di confidenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/03_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/04_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/05_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">La Crisi della Replicabilità dei Risultati della Ricerca</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/06_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/07_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/09_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Crisi della replicabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_6/10_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../99-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a00_installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Ambiente di lavoro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a01_markdown.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a03_colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Colab: un breve tutorial</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a04_virtual_env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Ambienti virtuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a20_kde_plot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Kernel Density Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a30_prob_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">M</span>&nbsp; <span class="chapter-title">Esercizi di probabilità discreta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a40_rng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">N</span>&nbsp; <span class="chapter-title">Generazione di numeri casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a45_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">O</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a46_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">P</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Q</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a51_reglin_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">R</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a60_ttest_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">S</span>&nbsp; <span class="chapter-title">Esercizi sull’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a70_predict_counts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">T</span>&nbsp; <span class="chapter-title">La predizione delle frequenze</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a100_solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">U</span>&nbsp; <span class="chapter-title">Soluzioni degli Esercizi</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione">Introduzione</a></li>
  <li><a href="#modello-di-regressione-logistica-per-variabili-binarie" id="toc-modello-di-regressione-logistica-per-variabili-binarie" class="nav-link" data-scroll-target="#modello-di-regressione-logistica-per-variabili-binarie"><span class="header-section-number">61.1</span> Modello di Regressione Logistica per Variabili Binarie</a></li>
  <li><a href="#modello-lineare-nelle-probabilità" id="toc-modello-lineare-nelle-probabilità" class="nav-link" data-scroll-target="#modello-lineare-nelle-probabilità"><span class="header-section-number">61.2</span> Modello Lineare nelle Probabilità</a>
  <ul class="collapse">
  <li><a href="#problemi-di-normalità" id="toc-problemi-di-normalità" class="nav-link" data-scroll-target="#problemi-di-normalità"><span class="header-section-number">61.2.1</span> Problemi di Normalità</a></li>
  <li><a href="#problematiche-di-eteroschedasticità" id="toc-problematiche-di-eteroschedasticità" class="nav-link" data-scroll-target="#problematiche-di-eteroschedasticità"><span class="header-section-number">61.2.2</span> Problematiche di Eteroschedasticità</a></li>
  <li><a href="#linearità" id="toc-linearità" class="nav-link" data-scroll-target="#linearità"><span class="header-section-number">61.2.3</span> Linearità</a></li>
  </ul></li>
  <li><a href="#modello-lineare-nelle-probabilità-vincolato" id="toc-modello-lineare-nelle-probabilità-vincolato" class="nav-link" data-scroll-target="#modello-lineare-nelle-probabilità-vincolato"><span class="header-section-number">61.3</span> Modello Lineare nelle Probabilità Vincolato</a></li>
  <li><a href="#regressione-logistica" id="toc-regressione-logistica" class="nav-link" data-scroll-target="#regressione-logistica"><span class="header-section-number">61.4</span> Regressione Logistica</a>
  <ul class="collapse">
  <li><a href="#vantaggi-della-regressione-logistica" id="toc-vantaggi-della-regressione-logistica" class="nav-link" data-scroll-target="#vantaggi-della-regressione-logistica"><span class="header-section-number">61.4.1</span> Vantaggi della Regressione Logistica</a></li>
  <li><a href="#esempio-pratico" id="toc-esempio-pratico" class="nav-link" data-scroll-target="#esempio-pratico"><span class="header-section-number">61.4.2</span> Esempio Pratico</a></li>
  </ul></li>
  <li><a href="#probabilità-odds-e-logit" id="toc-probabilità-odds-e-logit" class="nav-link" data-scroll-target="#probabilità-odds-e-logit"><span class="header-section-number">61.5</span> Probabilità, Odds e Logit</a>
  <ul class="collapse">
  <li><a href="#trasformazione-inversa-del-logit" id="toc-trasformazione-inversa-del-logit" class="nav-link" data-scroll-target="#trasformazione-inversa-del-logit"><span class="header-section-number">61.5.1</span> Trasformazione Inversa del Logit</a></li>
  </ul></li>
  <li><a href="#modelli-lineari-generalizzati" id="toc-modelli-lineari-generalizzati" class="nav-link" data-scroll-target="#modelli-lineari-generalizzati"><span class="header-section-number">61.6</span> Modelli Lineari Generalizzati</a></li>
  <li><a href="#componente-sistematica" id="toc-componente-sistematica" class="nav-link" data-scroll-target="#componente-sistematica"><span class="header-section-number">61.7</span> Componente Sistematica</a></li>
  <li><a href="#componente-aleatoria" id="toc-componente-aleatoria" class="nav-link" data-scroll-target="#componente-aleatoria"><span class="header-section-number">61.8</span> Componente Aleatoria</a></li>
  <li><a href="#funzione-legame" id="toc-funzione-legame" class="nav-link" data-scroll-target="#funzione-legame"><span class="header-section-number">61.9</span> Funzione Legame</a></li>
  <li><a href="#modelli-lineari-generalizzati-1" id="toc-modelli-lineari-generalizzati-1" class="nav-link" data-scroll-target="#modelli-lineari-generalizzati-1"><span class="header-section-number">61.10</span> Modelli Lineari Generalizzati</a>
  <ul class="collapse">
  <li><a href="#combinazioni-di-componenti-nei-glm" id="toc-combinazioni-di-componenti-nei-glm" class="nav-link" data-scroll-target="#combinazioni-di-componenti-nei-glm"><span class="header-section-number">61.10.1</span> Combinazioni di Componenti nei GLM</a></li>
  </ul></li>
  <li><a href="#componente-sistematica-1" id="toc-componente-sistematica-1" class="nav-link" data-scroll-target="#componente-sistematica-1"><span class="header-section-number">61.11</span> Componente Sistematica</a></li>
  <li><a href="#componente-aleatoria-1" id="toc-componente-aleatoria-1" class="nav-link" data-scroll-target="#componente-aleatoria-1"><span class="header-section-number">61.12</span> Componente Aleatoria</a></li>
  <li><a href="#funzione-legame-1" id="toc-funzione-legame-1" class="nav-link" data-scroll-target="#funzione-legame-1"><span class="header-section-number">61.13</span> Funzione Legame</a>
  <ul class="collapse">
  <li><a href="#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione" id="toc-coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione" class="nav-link" data-scroll-target="#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione"><span class="header-section-number">61.13.1</span> Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione</a></li>
  </ul></li>
  <li><a href="#un-esempio-concreto" id="toc-un-esempio-concreto" class="nav-link" data-scroll-target="#un-esempio-concreto"><span class="header-section-number">61.14</span> Un esempio concreto</a>
  <ul class="collapse">
  <li><a href="#interpretazione-dei-coefficienti-nella-regressione-logistica" id="toc-interpretazione-dei-coefficienti-nella-regressione-logistica" class="nav-link" data-scroll-target="#interpretazione-dei-coefficienti-nella-regressione-logistica"><span class="header-section-number">61.14.1</span> Interpretazione dei Coefficienti nella Regressione Logistica</a></li>
  <li><a href="#riassunto" id="toc-riassunto" class="nav-link" data-scroll-target="#riassunto"><span class="header-section-number">61.14.2</span> Riassunto</a></li>
  </ul></li>
  <li><a href="#regressione-logistica-con-solo-lintercetta" id="toc-regressione-logistica-con-solo-lintercetta" class="nav-link" data-scroll-target="#regressione-logistica-con-solo-lintercetta"><span class="header-section-number">61.15</span> Regressione logistica con solo l’intercetta</a></li>
  <li><a href="#regressione-logistica-con-un-singolo-predittore-binario" id="toc-regressione-logistica-con-un-singolo-predittore-binario" class="nav-link" data-scroll-target="#regressione-logistica-con-un-singolo-predittore-binario"><span class="header-section-number">61.16</span> Regressione logistica con un singolo predittore binario</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/chapter_5/05_22_stan_logistic_regr.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter_5/introduction_chapter_5.html">Modelli lineari</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter_5/05_22_stan_logistic_regr.html"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-stan-logistic-regr" class="quarto-section-identifier"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Prerequisiti</strong></p>
<p><strong>Concetti e competenze chiave</strong></p>
<p><strong>Preparazione del Notebook</strong></p>
<div id="cell-2" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard library imports</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Third-party imports</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> expit  <span class="co"># Funzione logistica</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cmdstanpy <span class="im">import</span> cmdstan_path, CmdStanModel</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">map</span>(<span class="bu">ord</span>, <span class="st">"stan_poisson_regression"</span>))</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>seed)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">"arviz-darkgrid"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">"retina"</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Define directories</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>home_directory <span class="op">=</span> os.path.expanduser(<span class="st">"~"</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>project_directory <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>home_directory<span class="sc">}</span><span class="ss">/_repositories/psicometria"</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Print project directory to verify</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Project directory: </span><span class="sc">{</span>project_directory<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Project directory: /Users/corradocaudek/_repositories/psicometria</code></pre>
</div>
</div>
<div id="cell-3" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scale_columns(dataframe, columns_to_scale):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Work on a copy to avoid modifying the original DataFrame</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    df_scaled <span class="op">=</span> dataframe.copy()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> column <span class="kw">in</span> columns_to_scale:</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Scale each specified column individually</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        df_scaled[column] <span class="op">=</span> stats.zscore(df_scaled[column])</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_scaled</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>La regressione logistica è un modello additivo utilizzato per dati binari, ossia dati <span class="math inline">\(y\)</span> che assumono valori 0 o 1. Per modellare i dati binari, dobbiamo aggiungere due caratteristiche al modello base <span class="math inline">\(y = a + bx\)</span>: una trasformazione non lineare che vincola l’output tra 0 e 1 (a differenza di <span class="math inline">\(a + bx\)</span>, che è illimitato), e un metodo per interpretare i numeri risultanti come probabilità che un evento si verifichi.</p>
<p>In questo capitolo, approfondiremo la regressione logistica bivariata, un modello statistico che ci consente di analizzare le relazioni tra una variabile di esito binaria e una singola variabile indipendente. Esploreremo il processo di stima dei coefficienti del modello attraverso un approccio bayesiano e forniremo un’interpretazione dei risultati ottenuti. Mostreremo come i coefficienti influenzano la probabilità di successo della variabile binaria di esito, nonché come interpretare il loro segno e ampiezza.</p>
</section>
<section id="modello-di-regressione-logistica-per-variabili-binarie" class="level2" data-number="61.1">
<h2 data-number="61.1" class="anchored" data-anchor-id="modello-di-regressione-logistica-per-variabili-binarie"><span class="header-section-number">61.1</span> Modello di Regressione Logistica per Variabili Binarie</h2>
<p>Il modello di regressione logistica è utilizzato per analizzare la relazione tra una variabile dipendente dicotomica, che assume i valori di “successo” e “fallimento”, e una o più variabili indipendenti, che possono essere sia quantitative che qualitative. Qui ci concentreremo sul caso di una sola variabile indipendente.</p>
<p>Consideriamo <span class="math inline">\(n\)</span> osservazioni i.i.d., dove <span class="math inline">\(Y_i\)</span> indica l’osservazione <span class="math inline">\(i\)</span>-esima della variabile risposta, per <span class="math inline">\(i=1, \dots, n\)</span>. Ogni osservazione è associata a un vettore di variabili esplicative <span class="math inline">\((x_1, \dots, x_p)\)</span>. La relazione che vogliamo esaminare è tra la probabilità di successo <span class="math inline">\(\pi_i\)</span> e la variabile esplicativa, espressa dalla formula:</p>
<p><span class="math display">\[
P(Y=1 \mid X=x_i) = \pi_i.
\]</span></p>
<p>In questo contesto, la variabile dipendente <span class="math inline">\(Y\)</span> segue una distribuzione di Bernoulli, con i seguenti possibili valori:</p>
<p><span class="math display">\[
y_i =
\begin{cases}
    1 &amp; \text{per un successo (per l'osservazione $i$-esima)},\\
    0 &amp; \text{per un fallimento}.
\end{cases}
\]</span></p>
<p>Le probabilità associate a questi valori sono rispettivamente <span class="math inline">\(\pi\)</span> per il successo e <span class="math inline">\(1-\pi\)</span> per il fallimento:</p>
<p><span class="math display">\[
\begin{aligned}
    P(Y_i = 1) &amp;= \pi,\\
    P(Y_i = 0) &amp;= 1-\pi.
\end{aligned}
\]</span></p>
<p>Questo modello permette di studiare come le variabili esplicative influenzino la probabilità di un evento binario, come il successo o il fallimento.</p>
<p>La media condizionata <span class="math inline">\(\mathbb{E}(Y \mid X=x)\)</span> in una popolazione può essere vista come la proporzione di valori 1 per un dato punteggio <span class="math inline">\(x\)</span> sulla variabile esplicativa, ovvero la probabilità condizionata <span class="math inline">\(\pi_i\)</span> di osservare l’esito <span class="math inline">\(Y = 1\)</span> in corrispondenza di un certo livello <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
\pi_i \equiv P(Y = 1 \mid X = x).
\]</span></p>
<p>Il valore atteso diventa:</p>
<p><span class="math display">\[
\mathbb{E}(Y \mid x) = \pi_i.
\]</span></p>
<p>Se <span class="math inline">\(X\)</span> è una variabile discreta, possiamo calcolare la proporzione di <span class="math inline">\(Y=1\)</span> per ogni valore di <span class="math inline">\(X=x\)</span> nel campione. Queste proporzioni rappresentano una stima non parametrica della funzione di regressione di <span class="math inline">\(Y\)</span> su <span class="math inline">\(X\)</span>, e possono essere stimate tramite tecniche di smoothing.</p>
<p>Per valori bassi della variabile <span class="math inline">\(X\)</span>, la proporzione condizionata di valori <span class="math inline">\(Y=1\)</span> sarà prossima allo 0. Per valori alti di <span class="math inline">\(X\)</span>, la proporzione di valori <span class="math inline">\(Y=1\)</span> sarà prossima a 1. A livelli intermedi di <span class="math inline">\(X\)</span>, la curva di regressione non parametrica gradualmente approssima i valori 0 e 1 seguendo un andamento sigmoidale.</p>
<p>Per illustrare, generiamo dei dati simulati con una variabile dicotomica <span class="math inline">\(Y\)</span> e una variabile discreta <span class="math inline">\(X\)</span> nei quali la probabilità che <span class="math inline">\(Y=1\)</span> aumenta con il valore di <span class="math inline">\(X\)</span>.</p>
<div id="cell-6" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span>  <span class="co"># Number of samples</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">10</span>, size<span class="op">=</span>n)  <span class="co"># Discrete independent variable with levels from 0 to 9</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the logistic model</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> logistic(x, beta0, beta1):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> expit(beta0 <span class="op">+</span> beta1 <span class="op">*</span> x)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>beta0 <span class="op">=</span> <span class="op">-</span><span class="dv">2</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>beta1 <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Increase the steepness of the curve</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> logistic(X, beta0, beta1)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate dichotomous outcome variable Y</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.random.binomial(<span class="dv">1</span>, p, size<span class="op">=</span>n)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute mean success rate and standard error for each level of X</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">'X'</span>: X, <span class="st">'Y'</span>: Y})</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>mean_success_rate <span class="op">=</span> df.groupby(<span class="st">'X'</span>)[<span class="st">'Y'</span>].mean()</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>standard_error <span class="op">=</span> df.groupby(<span class="st">'X'</span>)[<span class="st">'Y'</span>].sem()</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot mean success rates with standard errors</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>sns.pointplot(x<span class="op">=</span>mean_success_rate.index, y<span class="op">=</span>mean_success_rate.values, capsize<span class="op">=</span><span class="fl">0.1</span>, linestyle<span class="op">=</span><span class="st">'none'</span>)  <span class="co"># Use linestyle='none' to avoid connecting lines</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>plt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr<span class="op">=</span>standard_error.values, fmt<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a non-parametric smoother (LOESS) and plot the curve</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>lowess_smoothed <span class="op">=</span> lowess(mean_success_rate.values, mean_success_rate.index, frac<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>plt.plot(lowess_smoothed[:, <span class="dv">0</span>], lowess_smoothed[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Non-parametric Smoother'</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Customizing the plot</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'X'</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Mean Success Rate'</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_22_stan_logistic_regr_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="modello-lineare-nelle-probabilità" class="level2" data-number="61.2">
<h2 data-number="61.2" class="anchored" data-anchor-id="modello-lineare-nelle-probabilità"><span class="header-section-number">61.2</span> Modello Lineare nelle Probabilità</h2>
<p>Potremmo pensare di usare una funzione lineare per rappresentare la dipendenza di <span class="math inline">\(Y\)</span> da <span class="math inline">\(X\)</span>. Introduciamo un modello lineare con le seguenti assunzioni standard:</p>
<p><span class="math display">\[
Y_i = \alpha + \beta X_i + \varepsilon_i,
\]</span></p>
<p>dove <span class="math inline">\(\varepsilon_i\)</span> segue una distribuzione normale con media 0 e varianza 1 (<span class="math inline">\(\varepsilon_i \sim \mathcal{N}(0, 1)\)</span>) e gli errori <span class="math inline">\(\varepsilon_i\)</span> e <span class="math inline">\(\varepsilon_j\)</span> sono indipendenti per ogni <span class="math inline">\(i \neq j\)</span>. Il valore atteso di <span class="math inline">\(Y_i\)</span> è quindi <span class="math inline">\(\mathbb{E}(Y_i) = \alpha + \beta X_i\)</span>, portando a:</p>
<p><span class="math display">\[
\pi_i = \alpha + \beta X_i.
\]</span></p>
<p>Questo è noto come <em>modello lineare nelle probabilità</em> (<em>linear probability model</em>). Tuttavia, questo approccio presenta una limitazione significativa: non garantisce che i valori predetti di <span class="math inline">\(\pi_i\)</span> siano confinati nell’intervallo [0,1], come richiesto per le probabilità.</p>
<section id="problemi-di-normalità" class="level3" data-number="61.2.1">
<h3 data-number="61.2.1" class="anchored" data-anchor-id="problemi-di-normalità"><span class="header-section-number">61.2.1</span> Problemi di Normalità</h3>
<p>Considerando che <span class="math inline">\(Y_i\)</span> può assumere solo i valori 0 o 1, i residui <span class="math inline">\(\varepsilon_i\)</span> risultano anch’essi dicotomici e quindi non possono seguire una distribuzione normale. Ad esempio, se <span class="math inline">\(Y_i=1\)</span> con probabilità <span class="math inline">\(\pi_i\)</span>, il residuo sarà:</p>
<p><span class="math display">\[
\varepsilon_i = 1 - \mathbb{E}(Y_i) = 1 - (\alpha + \beta X_i) = 1 - \pi_i.
\]</span></p>
<p>Se, invece, <span class="math inline">\(Y_i=0\)</span> con probabilità <span class="math inline">\(1-\pi_i\)</span>, il residuo sarà:</p>
<p><span class="math display">\[
\varepsilon_i = 0 - \mathbb{E}(Y_i) = 0 - (\alpha + \beta X_i) = - \pi_i.
\]</span></p>
<p>Tuttavia, se la dimensione del campione è grande, il teorema del limite centrale può mitigare l’importanza dell’assunzione di normalità per le stime dei minimi quadrati.</p>
</section>
<section id="problematiche-di-eteroschedasticità" class="level3" data-number="61.2.2">
<h3 data-number="61.2.2" class="anchored" data-anchor-id="problematiche-di-eteroschedasticità"><span class="header-section-number">61.2.2</span> Problematiche di Eteroschedasticità</h3>
<p>Utilizzare il metodo dei minimi quadrati può essere inappropriato in questo contesto poiché la varianza dei residui non è costante ma dipende dalla media, e quindi dalla variabile <span class="math inline">\(X\)</span>. Assumendo che il modello sia lineare, abbiamo che <span class="math inline">\(\mathbb{E}(\varepsilon_i)=0\)</span>. Sfruttando le relazioni discusse in precedenza, la varianza dei residui si calcola come:</p>
<p><span class="math display">\[
\mathbb{V}(\varepsilon_i) = (1-\pi_i)\pi_i.
\]</span></p>
<p>Consideriamo che la varianza dei residui <span class="math inline">\(\varepsilon_i\)</span> può essere espressa come:</p>
<p><span class="math display">\[
\text{Var}(\varepsilon_i) = \mathbb{E}(\varepsilon_i^2) - \mathbb{E}(\varepsilon_i)^2,
\]</span></p>
<p>dove <span class="math inline">\(\mathbb{E}(\varepsilon_i^2)\)</span> è il valore atteso del quadrato dei residui e <span class="math inline">\(\mathbb{E}(\varepsilon_i)^2\)</span> è il quadrato del valore atteso dei residui.</p>
<p>Ora calcoliamo <span class="math inline">\(\mathbb{E}(\varepsilon_i^2)\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\mathbb{E}(\varepsilon_i^2) &amp;= \mathbb{E}[(Y_i - \mathbb{E}(Y_i))^2] \\
&amp;= \mathbb{E}[(Y_i - \pi_i)^2] \\
&amp;= \mathbb{E}[(Y_i^2 - 2Y_i\pi_i + \pi_i^2)] \\
&amp;= \mathbb{E}(Y_i^2) - 2\mathbb{E}(Y_i\pi_i) + \mathbb{E}(\pi_i^2) \\
&amp;= \mathbb{E}(Y_i) - 2\mathbb{E}(Y_i\pi_i) + \pi_i^2 \\
&amp;= \pi_i - 2\pi_i^2 + \pi_i^2 \\
&amp;= \pi_i - \pi_i^2 \\
&amp;= \pi_i(1 - \pi_i)
\end{align*}
\]</span></p>
<p>Ora calcoliamo <span class="math inline">\(\mathbb{E}(\varepsilon_i)^2\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\mathbb{E}(\varepsilon_i)^2 &amp;= (\mathbb{E}(Y_i - \mathbb{E}(Y_i)))^2 \\
&amp;= (\mathbb{E}(Y_i - \pi_i))^2 \\
&amp;= (0)^2 \\
&amp;= 0
\end{align*}
\]</span></p>
<p>Quindi, sostituendo questi risultati nella formula della varianza dei residui, otteniamo:</p>
<p><span class="math display">\[
\text{Var}(\varepsilon_i) = \mathbb{E}(\varepsilon_i^2) - \mathbb{E}(\varepsilon_i)^2 = \pi_i(1 - \pi_i)
\]</span></p>
<p>Quindi, abbiamo dimostrato che la varianza dei residui nel modello lineare nelle probabilità può essere espressa come <span class="math inline">\((1-\pi_i)\pi_i\)</span>.</p>
<p>Dato che <span class="math inline">\(\pi_i\)</span> dipende da <span class="math inline">\(x\)</span>, ciò significa che la varianza non è costante in funzione di <span class="math inline">\(x\)</span>. Questa eteroschedasticità dei residui rappresenta un problema per le stime dei minimi quadrati nel modello lineare, specialmente quando le probabilità <span class="math inline">\(\pi_i\)</span> sono vicine a 0 o 1.</p>
</section>
<section id="linearità" class="level3" data-number="61.2.3">
<h3 data-number="61.2.3" class="anchored" data-anchor-id="linearità"><span class="header-section-number">61.2.3</span> Linearità</h3>
<p>Il maggiore inconveniente connesso all’adozione del modello lineare nelle probabilità deriva dal fatto che la stima della probabilità di successo, <span class="math inline">\(P(\hat{Y}_i=1)=\hat{\pi}_i\)</span>, non è necessariamente compresa nell’intervallo <span class="math inline">\((0,1)\)</span>, ma può essere sia negativa sia maggiore di 1. Nel caso dell’esempio in discussione, ciò significa che la retta dei minimi quadrati produce valori attesi <span class="math inline">\(\hat{\pi}\)</span> inferiori a 0 per bassi valori della variabile <span class="math inline">\(X\)</span> e valori <span class="math inline">\(\hat{\pi}\)</span> superiori a 1 per valori di <span class="math inline">\(X\)</span> alti.</p>
</section>
</section>
<section id="modello-lineare-nelle-probabilità-vincolato" class="level2" data-number="61.3">
<h2 data-number="61.3" class="anchored" data-anchor-id="modello-lineare-nelle-probabilità-vincolato"><span class="header-section-number">61.3</span> Modello Lineare nelle Probabilità Vincolato</h2>
<p>Una soluzione per mantenere <span class="math inline">\(\pi\)</span> all’interno dell’intervallo (0, 1) è la seguente specificazione del modello:</p>
<p><span class="math display">\[
\pi=
\begin{cases}
  0                           &amp;\text{se $\alpha + \beta X &lt; 0$},\\
  \alpha + \beta X           &amp;\text{se $0 \leq \alpha + \beta X \leq 1$},\\
  1 &amp;\text{se $\alpha + \beta X &gt; 1$}.
\end{cases}
\]</span></p>
<p>Questo <em>modello lineare nelle probabilità vincolato</em> mostra alcune instabilità, soprattutto a causa della sua dipendenza critica dai valori estremi di <span class="math inline">\(\pi\)</span>, dove assume i valori 0 o 1. La linearità di <span class="math inline">\(\pi = \alpha + \beta X\)</span> si basa fortemente sui punti in cui si verificano questi estremi. In particolare, la stima di <span class="math inline">\(\pi = 0\)</span> può essere influenzata dal valore minimo di <span class="math inline">\(X\)</span> associato a <span class="math inline">\(Y=1\)</span>, mentre la stima di <span class="math inline">\(\pi = 1\)</span> può dipendere dal valore massimo di <span class="math inline">\(X\)</span> per cui <span class="math inline">\(Y=0\)</span>. Questi valori estremi tendono a variare significativamente tra diversi campioni e possono diventare più estremi all’aumentare della dimensione del campione.</p>
<p>La presenza di più variabili esplicative (<span class="math inline">\(k \geq 2\)</span>) complica ulteriormente la stima dei parametri del modello. Inoltre, il modello mostra un cambiamento brusco nella pendenza della curva di regressione ai punti estremi (0 e 1 di <span class="math inline">\(\pi\)</span>), risultando poco realistico in molte situazioni pratiche. Questo rende il modello meno adatto a descrivere relazioni complesse e gradualmente variabili tra <span class="math inline">\(\pi\)</span> e <span class="math inline">\(X\)</span>.</p>
<p>Una funzione che modella una relazione più fluida e continua tra <span class="math inline">\(\pi\)</span> e <span class="math inline">\(X\)</span> sarebbe più realistica e rappresentativa delle dinamiche osservate. Questo motiva la preferenza per modelli alternativi, come il modello di regressione logistica, che tende a fornire una rappresentazione più accurata e realistica delle interazioni tra variabili dicotomiche e esplicative.</p>
</section>
<section id="regressione-logistica" class="level2" data-number="61.4">
<h2 data-number="61.4" class="anchored" data-anchor-id="regressione-logistica"><span class="header-section-number">61.4</span> Regressione Logistica</h2>
<p>Un metodo efficace per gestire il problema del vincolo sulle probabilità è specificare modelli non direttamente per le probabilità stesse, ma per una loro trasformazione che elimina tale vincolo. Invece di definire un modello lineare per la probabilità condizionata <span class="math inline">\(\pi_i\)</span>, si può specificare un modello lineare per il logaritmo degli odds (logit):</p>
<p><span class="math display">\[
\eta_i = \log_e \frac{\pi_i}{1-\pi_i} = \alpha + \beta x_i,
\]</span></p>
<p>Questo approccio non presenta problemi poiché il logit <span class="math inline">\(\eta_i\)</span> è sempre un numero reale, permettendo di modellare una trasformazione lineare di <span class="math inline">\(\pi_i\)</span>. La trasformazione inversa, che ci permette di ottenere <span class="math inline">\(\pi_i\)</span> da <span class="math inline">\(\eta_i\)</span>, è data dalla funzione logistica:</p>
<p><span class="math display">\[
\pi_i = \frac{e^{\eta_i}}{1 + e^{\eta_i}} = \frac{e^{\alpha + \beta x_i}}{1 + e^{\alpha + \beta x_i}}.
\]</span></p>
<section id="vantaggi-della-regressione-logistica" class="level3" data-number="61.4.1">
<h3 data-number="61.4.1" class="anchored" data-anchor-id="vantaggi-della-regressione-logistica"><span class="header-section-number">61.4.1</span> Vantaggi della Regressione Logistica</h3>
<p>La regressione logistica presenta diversi vantaggi rispetto al modello lineare delle probabilità:</p>
<ol type="1">
<li><strong>Vincolo delle Probabilità:</strong> La trasformazione logistica assicura che i valori predetti di <span class="math inline">\(\pi_i\)</span> siano sempre compresi nell’intervallo [0,1].</li>
<li><strong>Interpretabilità degli Odds Ratio:</strong> Il coefficiente <span class="math inline">\(\beta\)</span> può essere interpretato come il cambiamento logaritmico negli odds di successo associato a un incremento unitario di <span class="math inline">\(X\)</span>. In altre parole, <span class="math inline">\(e^\beta\)</span> rappresenta il fattore di aumento (o diminuzione) degli odds per un incremento unitario della variabile indipendente.</li>
<li><strong>Gestione dell’Eteroschedasticità:</strong> La forma funzionale della varianza del modello di regressione logistica <span class="math inline">\(\pi_i (1 - \pi_i)\)</span> è intrinsecamente considerata nel processo di stima tramite il metodo della massima verosimiglianza.</li>
</ol>
</section>
<section id="esempio-pratico" class="level3" data-number="61.4.2">
<h3 data-number="61.4.2" class="anchored" data-anchor-id="esempio-pratico"><span class="header-section-number">61.4.2</span> Esempio Pratico</h3>
<p>Per illustrare l’applicazione della regressione logistica, consideriamo nuovamente i dati simulati precedentemente. Applichiamo il modello di regressione logistica ai dati e tracciamo la curva logistica risultante:</p>
<div id="cell-10" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot mean success rates with standard errors</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>sns.pointplot(x<span class="op">=</span>mean_success_rate.index, y<span class="op">=</span>mean_success_rate.values, capsize<span class="op">=</span><span class="fl">0.1</span>, linestyle<span class="op">=</span><span class="st">'none'</span>)  <span class="co"># Use linestyle='none' to avoid connecting lines</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr<span class="op">=</span>standard_error.values, fmt<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic regression model and plot logistic curve</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>X_design <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> sm.Logit(Y, X_design).fit()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(X.<span class="bu">min</span>(), X.<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>y_vals <span class="op">=</span> logit_model.predict(sm.add_constant(x_vals))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, y_vals, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Logistic Regression Curve'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Customizing the plot</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'X'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Mean Success Rate'</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.289256
         Iterations 8</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_22_stan_logistic_regr_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Questo esempio dimostra come la regressione logistica possa essere utilizzata per modellare una variabile dicotomica in funzione di una variabile indipendente. La curva logistica risultante rappresenta adeguatamente la relazione tra <span class="math inline">\(X\)</span> e la probabilità di successo <span class="math inline">\(Y\)</span>, garantendo che i valori predetti di <span class="math inline">\(\pi_i\)</span> siano sempre compresi nell’intervallo [0,1].</p>
<p>Nelle sezioni seguenti, descriveremo in dettaglio il modello di regressione logistica utilizzato per generare la curva logistica mostrata nella figura precedente. Inizieremo chiarendo i concetti di odds e logit e la loro relazione con le probabilità.</p>
</section>
</section>
<section id="probabilità-odds-e-logit" class="level2" data-number="61.5">
<h2 data-number="61.5" class="anchored" data-anchor-id="probabilità-odds-e-logit"><span class="header-section-number">61.5</span> Probabilità, Odds e Logit</h2>
<p>La relazione tra probabilità, odds e logit è fondamentale per comprendere la regressione logistica. Questa relazione trasforma l’intervallo di probabilità (0, 1) in uno spettro più ampio, rendendo possibile modellare le probabilità con un modello lineare.</p>
<p>Gli odds rappresentano il rapporto tra la probabilità di un evento e la probabilità del suo complemento. Il logit, invece, è il logaritmo naturale degli odds, trasformando così l’intervallo di probabilità in tutta la linea dei numeri reali. Quando la probabilità è 0.5, gli odds sono 1 e il logit è 0. Logit negativi indicano probabilità inferiori a 0.5, mentre logit positivi indicano probabilità superiori a 0.5.</p>
<table class="table">
<colgroup>
<col style="width: 30%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Probabilità (P)</th>
<th>Odds (O)</th>
<th>logit (L)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.01</td>
<td>0.01 / 0.99 = 0.0101</td>
<td><span class="math inline">\(\ln(\frac{0.01}{0.99}) = -4.60\)</span></td>
</tr>
<tr class="even">
<td>0.05</td>
<td>0.05 / 0.95 = 0.0526</td>
<td><span class="math inline">\(\ln(\frac{0.05}{0.95}) = -2.94\)</span></td>
</tr>
<tr class="odd">
<td>0.10</td>
<td>0.10 / 90 = 0.1111</td>
<td><span class="math inline">\(\ln(\frac{0.10}{0.90}) = -2.20\)</span></td>
</tr>
<tr class="even">
<td>0.30</td>
<td>0.30 / 0.70 = 0.4286</td>
<td><span class="math inline">\(\ln(\frac{0.30}{0.70}) = -0.85\)</span></td>
</tr>
<tr class="odd">
<td>0.50</td>
<td>0.50 / 0.50 = 1</td>
<td><span class="math inline">\(\ln(\frac{0.50}{0.50}) = 0.00\)</span></td>
</tr>
<tr class="even">
<td>0.70</td>
<td>0.70 / 0.30 = 2.3333</td>
<td><span class="math inline">\(\ln(\frac{0.70}{0.30}) = 0.85\)</span></td>
</tr>
<tr class="odd">
<td>0.90</td>
<td>0.90 / 0.10 = 9</td>
<td><span class="math inline">\(\ln(\frac{0.90}{0.10}) = 2.20\)</span></td>
</tr>
<tr class="even">
<td>0.95</td>
<td>0.95 / 0.05 = 19</td>
<td><span class="math inline">\(\ln(\frac{0.95}{0.05}) = 2.94\)</span></td>
</tr>
<tr class="odd">
<td>0.99</td>
<td>0.99 / 0.01 = 99</td>
<td><span class="math inline">\(\ln(\frac{0.99}{0.01}) = 4.60\)</span></td>
</tr>
</tbody>
</table>
<section id="trasformazione-inversa-del-logit" class="level3" data-number="61.5.1">
<h3 data-number="61.5.1" class="anchored" data-anchor-id="trasformazione-inversa-del-logit"><span class="header-section-number">61.5.1</span> Trasformazione Inversa del Logit</h3>
<p>La trasformazione inversa del logit, detta <em>antilogit</em>, consente di trasformare i logit in probabilità:</p>
<p><span class="math display">\[
  \pi_i = \frac{e^{\eta_i}}{1 + e^{\eta_i}}.
\]</span></p>
<p>Grazie a questa trasformazione, possiamo passare dai logit alle probabilità. La trasformazione inversa del logit permette di specificare un modello non lineare per le probabilità <span class="math inline">\(\pi_i\)</span>. Tale modello non lineare è detto <em>logit</em> o modello di regressione logistica:</p>
<p><span class="math display">\[
  \pi_i = \frac{e^{\eta_i}}{1 + e^{\eta_i}} = \frac{e^{\alpha + \beta x_i}}{1 + e^{\alpha + \beta x_i}}.
\]</span></p>
<p>Questo modello garantisce che le probabilità <span class="math inline">\(\pi_i\)</span> siano sempre comprese nell’intervallo [0,1], risolvendo i problemi del modello lineare nelle probabilità e fornendo una rappresentazione accurata della relazione tra la variabile indipendente <span class="math inline">\(X\)</span> e la probabilità di successo <span class="math inline">\(Y\)</span>.</p>
<p>La funzione logistica ben rappresenta l’andamento sigmoidale delle proporzioni di casi <span class="math inline">\(Y=1\)</span>, ovvero <span class="math inline">\(\hat{\pi}_i = E(Y \mid x_i)\)</span> in funzione di livelli crescenti della variabile <span class="math inline">\(X\)</span>.</p>
</section>
</section>
<section id="modelli-lineari-generalizzati" class="level2" data-number="61.6">
<h2 data-number="61.6" class="anchored" data-anchor-id="modelli-lineari-generalizzati"><span class="header-section-number">61.6</span> Modelli Lineari Generalizzati</h2>
<p>Nel caso di una variabile risposta binaria, il modello classico di regressione lineare si scontra con sfide specifiche:</p>
<ol type="1">
<li><strong>Distribuzione Binomiale</strong>: <span class="math inline">\(Y_i\)</span> segue una distribuzione binomiale (con indice <span class="math inline">\(n_i\)</span>, potenzialmente uguale a uno nel caso individuale), rendendo non applicabile l’ipotesi di normalità.</li>
<li><strong>Limiti delle Probabilità</strong>: Utilizzando una specificazione lineare come <span class="math inline">\(\pi_i= \beta_0 + \beta_1 x_i\)</span>, si possono ottenere stime di probabilità esterne all’intervallo 0-1.</li>
<li><strong>Varianze Non Costanti</strong>: La varianza di <span class="math inline">\(\varepsilon\)</span> varia in base alla specificazione del modello di probabilità, seguendo la formula <span class="math inline">\(V(\varepsilon_i)=\pi_i(1-\pi_i)\)</span>.</li>
</ol>
<p>Per superare queste sfide, si utilizzano i Modelli Lineari Generalizzati (GLM). Questi modelli consentono l’uso di variabili risposta di diversa natura e includono:</p>
<ul>
<li><strong>Regressione Lineare</strong>: Per variabili dipendenti continue e variabili esplicative continue o qualitative.</li>
<li><strong>Regressione Logistica</strong>: Per variabili risposta binarie.</li>
<li><strong>Modello Loglineare di Poisson</strong>: Per modellare frequenze in tabelle di contingenza.</li>
</ul>
<p>I GLM allentano alcune ipotesi fondamentali del modello lineare classico, come linearità, normalità della componente erratica, e omoschedasticità delle osservazioni. Sono strutturati in tre componenti principali:</p>
<ol type="1">
<li><strong>Componente Aleatoria</strong>: Definisce la distribuzione di probabilità della variabile risposta <span class="math inline">\(Y\)</span>.</li>
<li><strong>Componente Sistematica</strong>: Specifica la relazione lineare tra le variabili esplicative e una trasformazione della variabile risposta.</li>
<li><strong>Funzione Legame</strong>: Trasforma la media attesa <span class="math inline">\(\mathbb{E}(Y)\)</span> in un formato che possa essere modellato linearmente rispetto alle variabili esplicative. Non è la variabile risposta stessa ad essere modellizzata direttamente, ma una sua trasformazione, come il logit nel caso della regressione logistica.</li>
</ol>
<p>Esempi di combinazioni di componenti aleatorie, funzioni di legame e sistematiche nei GLM includono:</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 19%">
<col style="width: 27%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Componente Aleatoria</th>
<th>Funzione Legame</th>
<th>Componente Sistematica</th>
<th>Modello</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gaussiana</td>
<td>Identità</td>
<td>Continua</td>
<td>Regressione</td>
</tr>
<tr class="even">
<td>Gaussiana</td>
<td>Identità</td>
<td>Categoriale</td>
<td>Analisi della varianza</td>
</tr>
<tr class="odd">
<td>Gaussiana</td>
<td>Identità</td>
<td>Mista</td>
<td>Analisi della covarianza</td>
</tr>
<tr class="even">
<td>Binomiale</td>
<td>Logit</td>
<td>Mista</td>
<td>Regressione logistica</td>
</tr>
<tr class="odd">
<td>Poisson</td>
<td>Logaritmo</td>
<td>Mista</td>
<td>Modello Loglineare</td>
</tr>
</tbody>
</table>
<p>Questa struttura rende i GLM particolarmente flessibili e adatti a una vasta gamma di situazioni statistiche, superando i limiti del modello lineare classico.</p>
</section>
<section id="componente-sistematica" class="level2" data-number="61.7">
<h2 data-number="61.7" class="anchored" data-anchor-id="componente-sistematica"><span class="header-section-number">61.7</span> Componente Sistematica</h2>
<p>La componente sistematica mette in relazione un vettore (<span class="math inline">\(\eta_1, \eta_2, \dots, \eta_k\)</span>) con le variabili esplicative mediante un modello lineare. Sia <span class="math inline">\(X_{ij}\)</span> il valore della <span class="math inline">\(j\)</span>-esima variabile esplicativa (<span class="math inline">\(j=1, 2, \dots, p\)</span>) per l’<span class="math inline">\(i\)</span>-esima osservazione (<span class="math inline">\(i=1, \dots, k\)</span>). Allora</p>
<p><span class="math display">\[
\eta_i = \sum_j \beta_j X_{ij}.
\]</span></p>
<p>Questa combinazione lineare di variabili esplicative è chiamata il <em>predittore lineare</em>. Un <span class="math inline">\(X_{ij}=1, \forall i\)</span> viene utilizzato per il coefficiente dell’intercetta del modello (talvolta denotata da <span class="math inline">\(\alpha\)</span>).</p>
</section>
<section id="componente-aleatoria" class="level2" data-number="61.8">
<h2 data-number="61.8" class="anchored" data-anchor-id="componente-aleatoria"><span class="header-section-number">61.8</span> Componente Aleatoria</h2>
<p>La componente aleatoria del modello suppone l’esistenza di <span class="math inline">\(k\)</span> osservazioni indipendenti <span class="math inline">\(y_1, y_2, \dots, y_k\)</span>, ciascuna delle quali viene trattata come la realizzazione di una variabile casuale <span class="math inline">\(Y_i\)</span>. Si assume che <span class="math inline">\(Y_i\)</span> abbia una distribuzione binomiale:</p>
<p><span class="math display">\[
Y_i \sim Bin(n_i, \pi_i)
\]</span></p>
<p>con parametri <span class="math inline">\(n_i\)</span> e <span class="math inline">\(\pi_i\)</span>. Per dati individuali (uno per ciascun valore <span class="math inline">\(x_i\)</span>), <span class="math inline">\(n_i=1,
    \forall i\)</span>.</p>
</section>
<section id="funzione-legame" class="level2" data-number="61.9">
<h2 data-number="61.9" class="anchored" data-anchor-id="funzione-legame"><span class="header-section-number">61.9</span> Funzione Legame</h2>
<p>La funzione legame <span class="math inline">\(g(\cdot)\)</span> mette in relazione il valore atteso della variabile risposta <span class="math inline">\(Y_i\)</span> con la componente sistematica <span class="math inline">\(\eta_i\)</span> del modello. Abbiamo visto che <span class="math inline">\(\mathbb{E}(Y_i)=\pi_i\)</span>. Che relazione c’è tra <span class="math inline">\(\pi_i\)</span> e il predittore lineare <span class="math inline">\(\eta_i= \alpha + \sum_j  \beta_j X_{ij}\)</span>? La risposta a questa domanda è data dalla funzione legame:</p>
<p><span class="math display">\[
\eta_i = g(\pi_i) = \ln{\frac{\pi_i}{1-\pi_i}}
\]</span></p>
<p>Si noti che la funzione legame non trasforma la variabile risposta <span class="math inline">\(Y_i\)</span> ma bensì il suo valore atteso <span class="math inline">\(\pi_i\)</span>.</p>
<p>La funzione legame è invertibile: anziché trasformare il valore atteso nel predittore lineare si può trasformare il predittore lineare nel valore atteso <span class="math inline">\(\pi_i\)</span>:</p>
<p><span class="math display">\[
\pi_i = \frac{e^{\eta_i}}{1+e^{\eta_i}} =  \frac{e^{\alpha + \sum_j  \beta_j X_{ij}}}{1+e^{\alpha + \sum_j  \beta_j X_{ij}}}.
\]</span></p>
<p>Si ottiene così un modello non lineare per le probabilità <span class="math inline">\(\pi_i\)</span>.</p>
<p>In conclusione, la regressione logistica estende il concetto di regressione lineare per modellare le probabilità condizionate di esiti Bernoulliani $ Y <span class="math inline">\(, adoperando la funzione logistica come collegamento per trasformare relazioni lineari tra predittori (\)</span> _i = _0 + <em>1 X</em>{i} $) in probabilità nell’intervallo [0,1]. Questo metodo permette di passare dalla modellazione diretta della probabilità $ p $ alla modellazione di una funzione di tale probabilità attraverso una relazione lineare, impiegando la funzione logit come funzione di collegamento.</p>
</section>
<section id="modelli-lineari-generalizzati-1" class="level2" data-number="61.10">
<h2 data-number="61.10" class="anchored" data-anchor-id="modelli-lineari-generalizzati-1"><span class="header-section-number">61.10</span> Modelli Lineari Generalizzati</h2>
<p>Nel caso di una variabile risposta binaria, il modello classico di regressione lineare incontra alcune difficoltà specifiche:</p>
<ol type="1">
<li><strong>Distribuzione Binomiale</strong>: <span class="math inline">\(Y_i\)</span> segue una distribuzione binomiale, rendendo inapplicabile l’ipotesi di normalità.</li>
<li><strong>Limiti delle Probabilità</strong>: Utilizzando una specificazione lineare come <span class="math inline">\(\pi_i = \beta_0 + \beta_1 x_i\)</span>, si possono ottenere stime di probabilità al di fuori dell’intervallo 0-1.</li>
<li><strong>Varianze Non Costanti</strong>: La varianza dei residui <span class="math inline">\(\varepsilon_i\)</span> varia in base alla specificazione del modello di probabilità, seguendo la formula <span class="math inline">\(V(\varepsilon_i) = \pi_i(1 - \pi_i)\)</span>.</li>
</ol>
<p>Per superare queste sfide, si utilizzano i Modelli Lineari Generalizzati (GLM). Questi modelli consentono l’uso di variabili risposta di diversa natura e includono:</p>
<ul>
<li><strong>Regressione Lineare</strong>: Per variabili dipendenti continue.</li>
<li><strong>Regressione Logistica</strong>: Per variabili risposta binarie.</li>
<li><strong>Modello Loglineare di Poisson</strong>: Per modellare frequenze in tabelle di contingenza.</li>
</ul>
<p>I GLM allentano alcune ipotesi fondamentali del modello lineare classico, come linearità, normalità della componente erratica e omoschedasticità delle osservazioni. Sono strutturati in tre componenti principali:</p>
<ol type="1">
<li><strong>Componente Aleatoria</strong>: Definisce la distribuzione di probabilità della variabile risposta <span class="math inline">\(Y\)</span>.</li>
<li><strong>Componente Sistematica</strong>: Specifica la relazione lineare tra le variabili esplicative e una trasformazione della variabile risposta.</li>
<li><strong>Funzione Legame</strong>: Trasforma la media attesa <span class="math inline">\(\mathbb{E}(Y)\)</span> in un formato che possa essere modellato linearmente rispetto alle variabili esplicative. Non è la variabile risposta stessa ad essere modellata direttamente, ma una sua trasformazione, come il logit nel caso della regressione logistica.</li>
</ol>
<section id="combinazioni-di-componenti-nei-glm" class="level3" data-number="61.10.1">
<h3 data-number="61.10.1" class="anchored" data-anchor-id="combinazioni-di-componenti-nei-glm"><span class="header-section-number">61.10.1</span> Combinazioni di Componenti nei GLM</h3>
<p>Esempi di combinazioni di componenti aleatorie, funzioni di legame e sistematiche nei GLM includono:</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 19%">
<col style="width: 27%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Componente Aleatoria</th>
<th>Funzione Legame</th>
<th>Componente Sistematica</th>
<th>Modello</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gaussiana</td>
<td>Identità</td>
<td>Continua</td>
<td>Regressione</td>
</tr>
<tr class="even">
<td>Binomiale</td>
<td>Logit</td>
<td>Continua</td>
<td>Regressione logistica</td>
</tr>
<tr class="odd">
<td>Poisson</td>
<td>Logaritmo</td>
<td>Continua</td>
<td>Modello Loglineare</td>
</tr>
</tbody>
</table>
<p>Questa struttura rende i GLM particolarmente flessibili e adatti a una vasta gamma di situazioni statistiche, superando i limiti del modello lineare classico.</p>
</section>
</section>
<section id="componente-sistematica-1" class="level2" data-number="61.11">
<h2 data-number="61.11" class="anchored" data-anchor-id="componente-sistematica-1"><span class="header-section-number">61.11</span> Componente Sistematica</h2>
<p>La componente sistematica mette in relazione un vettore <span class="math inline">\((\eta_1, \eta_2, \dots, \eta_k)\)</span> con le variabili esplicative mediante un modello lineare. Sia <span class="math inline">\(X_{i}\)</span> il valore della variabile esplicativa continua per l’<span class="math inline">\(i\)</span>-esima osservazione (<span class="math inline">\(i=1, \dots, k\)</span>). Allora:</p>
<p><span class="math display">\[
\eta_i = \beta_0 + \beta_1 X_i.
\]</span></p>
<p>Questa combinazione lineare di variabili esplicative è chiamata il <em>predittore lineare</em>.</p>
</section>
<section id="componente-aleatoria-1" class="level2" data-number="61.12">
<h2 data-number="61.12" class="anchored" data-anchor-id="componente-aleatoria-1"><span class="header-section-number">61.12</span> Componente Aleatoria</h2>
<p>La componente aleatoria del modello suppone l’esistenza di <span class="math inline">\(k\)</span> osservazioni indipendenti <span class="math inline">\(y_1, y_2, \dots, y_k\)</span>, ciascuna delle quali viene trattata come la realizzazione di una variabile casuale <span class="math inline">\(Y_i\)</span>. Si assume che <span class="math inline">\(Y_i\)</span> abbia una distribuzione binomiale:</p>
<p><span class="math display">\[
Y_i \sim \text{Bin}(1, \pi_i),
\]</span></p>
<p>con parametro <span class="math inline">\(\pi_i\)</span>. Per dati individuali, <span class="math inline">\(n_i=1\)</span> per tutti <span class="math inline">\(i\)</span>.</p>
</section>
<section id="funzione-legame-1" class="level2" data-number="61.13">
<h2 data-number="61.13" class="anchored" data-anchor-id="funzione-legame-1"><span class="header-section-number">61.13</span> Funzione Legame</h2>
<p>La funzione legame <span class="math inline">\(g(\cdot)\)</span> mette in relazione il valore atteso della variabile risposta <span class="math inline">\(Y_i\)</span> con la componente sistematica <span class="math inline">\(\eta_i\)</span> del modello. Abbiamo visto che <span class="math inline">\(\mathbb{E}(Y_i) = \pi_i\)</span>. La relazione tra <span class="math inline">\(\pi_i\)</span> e il predittore lineare <span class="math inline">\(\eta_i = \beta_0 + \beta_1 X_i\)</span> è data dalla funzione legame:</p>
<p><span class="math display">\[
\eta_i = g(\pi_i) = \ln{\frac{\pi_i}{1 - \pi_i}}.
\]</span></p>
<p>Si noti che la funzione legame non trasforma la variabile risposta <span class="math inline">\(Y_i\)</span> ma il suo valore atteso <span class="math inline">\(\pi_i\)</span>.</p>
<p>La funzione legame è invertibile: anziché trasformare il valore atteso nel predittore lineare, si può trasformare il predittore lineare nel valore atteso <span class="math inline">\(\pi_i\)</span>:</p>
<p><span class="math display">\[
\pi_i = \frac{e^{\eta_i}}{1 + e^{\eta_i}} = \frac{e^{\beta_0 + \beta_1 X_i}}{1 + e^{\beta_0 + \beta_1 X_i}}.
\]</span></p>
<p>Si ottiene così un modello non lineare per le probabilità <span class="math inline">\(\pi_i\)</span>.</p>
<section id="coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione" class="level3" data-number="61.13.1">
<h3 data-number="61.13.1" class="anchored" data-anchor-id="coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione"><span class="header-section-number">61.13.1</span> Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione</h3>
<p>Un aspetto cruciale per comprendere la relazione tra le variabili predittive e una variabile di risposta binaria è l’interpretazione dei coefficienti del modello.</p>
<section id="interpretazione-sui-logit" class="level4" data-number="61.13.1.1">
<h4 data-number="61.13.1.1" class="anchored" data-anchor-id="interpretazione-sui-logit"><span class="header-section-number">61.13.1.1</span> Interpretazione sui Logit</h4>
<p>Nella regressione logistica, ogni coefficiente <span class="math inline">\(\beta_j\)</span> del modello può essere interpretato direttamente in termini di log-odds, che sono i logaritmi delle probabilità di ottenere un evento con esito positivo (<span class="math inline">\(y=1\)</span>). Quando interpretiamo i coefficienti:</p>
<ul>
<li><p><strong>Coefficienti Positivi (<span class="math inline">\(\beta_j &gt; 0\)</span>)</strong>: Un coefficiente positivo indica che c’è una relazione diretta tra il predittore e l’aumento dei log-odds di osservare l’evento di interesse. Questo significa che all’aumentare del valore del predittore, la probabilità dell’evento di interesse aumenta.</p></li>
<li><p><strong>Coefficienti Negativi (<span class="math inline">\(\beta_j &lt; 0\)</span>)</strong>: Al contrario, un coefficiente negativo indica una relazione inversa tra il predittore e la probabilità logistica dell’evento. Con l’aumentare del predittore, i log-odds e quindi la probabilità dell’evento diminuiscono.</p></li>
</ul>
</section>
<section id="interpretazione-sugli-odds-ratio-or" class="level4" data-number="61.13.1.2">
<h4 data-number="61.13.1.2" class="anchored" data-anchor-id="interpretazione-sugli-odds-ratio-or"><span class="header-section-number">61.13.1.2</span> Interpretazione sugli Odds Ratio (OR)</h4>
<p>L’interpretazione dei coefficienti nella regressione logistica può estendersi agli odds ratio (OR), che forniscono informazioni sulla relazione tra i predittori e la probabilità dell’evento di interesse. Per esempio, consideriamo un modello con un predittore continuo <span class="math inline">\(X\)</span> e un coefficiente <span class="math inline">\(\beta_1 = 0.50\)</span>. Il logaritmo naturale dell’odds ratio, <span class="math inline">\(\log(OR) = 0.50\)</span>, viene esponenziato per ottenere:</p>
<p><span class="math display">\[
OR = e^{0.50} \approx 1.65.
\]</span></p>
<p>Questo risultato indica che per un’unità di incremento in <span class="math inline">\(X\)</span>, l’odds di sperimentare l’evento di interesse è circa 1.65 volte maggiore. In altre parole, l’incremento di una unità nel predittore <span class="math inline">\(X\)</span> aumenta l’odds di sperimentare l’evento di interesse di circa il 65%. Viceversa, un coefficiente negativo indicherebbe una diminuzione dell’odds per un incremento di una unità in <span class="math inline">\(X\)</span>.</p>
</section>
<section id="interpretazione-sulla-scala-delle-probabilità" class="level4" data-number="61.13.1.3">
<h4 data-number="61.13.1.3" class="anchored" data-anchor-id="interpretazione-sulla-scala-delle-probabilità"><span class="header-section-number">61.13.1.3</span> Interpretazione sulla Scala delle Probabilità</h4>
<p>La regressione logistica consente di interpretare i coefficienti non solo in termini di log-odds, ma anche relativamente alle variazioni di probabilità. Consideriamo un modello che predice la probabilità di superare un esame basandosi sul numero di ore di studio (<span class="math inline">\(X\)</span>).</p>
<p>Supponiamo che il coefficiente associato alle ore di studio sia <span class="math inline">\(\beta_1 = 0.5\)</span>. Questo valore indica che ogni ora aggiuntiva di studio incrementa i log-odds di successo nell’esame. Per comprendere l’impatto di un’ora in più di studio sulla probabilità di successo, possiamo utilizzare la seguente formula:</p>
<p><span class="math display">\[
\Delta p = \frac{1}{1 + e^{-(\beta_0 + 0.5 \cdot (X_1 + 1))}} - \frac{1}{1 + e^{-(\beta_0 + 0.5 \cdot X_1)}}.
\]</span></p>
<p>Questa formula calcola la differenza tra la probabilità di successo dopo aver aggiunto un’ora di studio e la probabilità di successo prima di tale aggiunta. In termini pratici, <span class="math inline">\(\Delta p\)</span> rappresenta l’incremento della probabilità di superare l’esame attribuibile a un’ora supplementare di studio. Questa interpretazione è cruciale per valutare quantitativamente l’effetto delle ore di studio sulla probabilità di superare l’esame.</p>
</section>
</section>
</section>
<section id="un-esempio-concreto" class="level2" data-number="61.14">
<h2 data-number="61.14" class="anchored" data-anchor-id="un-esempio-concreto"><span class="header-section-number">61.14</span> Un esempio concreto</h2>
<p>Consideriamo nuovamente i dati simulati in precedenza</p>
<div id="cell-17" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">X</th>
<th data-quarto-table-cell-role="th">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>6</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>7</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>6</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Stimeremo ora i coefficienti del modello di regressione logistica usando Stan. Definiamo i dati nel formato atteso da Stan:</p>
<div id="cell-19" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>stan_data <span class="op">=</span> {</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"N"</span> : df.shape[<span class="dv">0</span>],</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span> : df[<span class="st">"Y"</span>],</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span> : df[<span class="st">"X"</span>] </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compiliamo il modello di regressione logistica e stampiamo lo script Stan:</p>
<div id="cell-21" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>stan_file <span class="op">=</span> os.path.join(project_directory, <span class="st">"stan"</span>, <span class="st">"logistic_regression.stan"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span>stan_file)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.code())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>12:47:02 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression
12:47:13 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] x;
  array[N] int&lt;lower=0, upper=1&gt; y;
}
parameters {
  real alpha;
  real beta;
}
model {
  y ~ bernoulli_logit(alpha + beta * x);
}
</code></pre>
</div>
</div>
<p>Eseguiamo il campionamento MCMC:</p>
<div id="cell-23" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> model.sample(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>stan_data,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    iter_warmup<span class="op">=</span><span class="dv">1_000</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    iter_sampling<span class="op">=</span><span class="dv">2_000</span>,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    show_progress<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    show_console<span class="op">=</span><span class="va">False</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>12:47:36 - cmdstanpy - INFO - CmdStan start processing
12:47:36 - cmdstanpy - INFO - Chain [1] start processing
12:47:36 - cmdstanpy - INFO - Chain [2] start processing
12:47:36 - cmdstanpy - INFO - Chain [3] start processing
12:47:36 - cmdstanpy - INFO - Chain [4] start processing
12:47:37 - cmdstanpy - INFO - Chain [3] done processing
12:47:37 - cmdstanpy - INFO - Chain [2] done processing
12:47:37 - cmdstanpy - INFO - Chain [4] done processing
12:47:37 - cmdstanpy - INFO - Chain [1] done processing</code></pre>
</div>
</div>
<p>Esaminiamo le tracce:</p>
<div id="cell-25" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> az.plot_trace(fit)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_22_stan_logistic_regr_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Otteniamo le stime a posteriori dei parametri:</p>
<div id="cell-27" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>az.summary(fit, var_names<span class="op">=</span>([<span class="st">"alpha"</span>, <span class="st">"beta"</span>]), hdi_prob<span class="op">=</span><span class="fl">0.95</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_2.5%</th>
<th data-quarto-table-cell-role="th">hdi_97.5%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">alpha</td>
<td>-1.778</td>
<td>0.18</td>
<td>-2.132</td>
<td>-1.436</td>
<td>0.004</td>
<td>0.003</td>
<td>2261.0</td>
<td>2634.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">beta</td>
<td>1.004</td>
<td>0.07</td>
<td>0.869</td>
<td>1.144</td>
<td>0.001</td>
<td>0.001</td>
<td>2305.0</td>
<td>2682.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Creiamo un nuovo DataFrame con 100 valori <span class="math inline">\(x\)</span> nell’intervallo [0, 9]:</p>
<div id="cell-29" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>new_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span>: np.linspace(<span class="dv">0</span>, <span class="dv">9</span>, <span class="dv">100</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>new_data</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.090909</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.181818</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.272727</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.363636</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">95</td>
<td>8.636364</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">96</td>
<td>8.727273</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">97</td>
<td>8.818182</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">98</td>
<td>8.909091</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">99</td>
<td>9.000000</td>
</tr>
</tbody>
</table>

<p>100 rows × 1 columns</p>
</div>
</div>
</div>
</div>
<p>Otteniamo le medie a posteriori dei parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>:</p>
<div id="cell-31" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> fit.stan_variable(<span class="st">'alpha'</span>).mean()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> fit.stan_variable(<span class="st">'beta'</span>).mean() </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(alpha, beta)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-1.7784477 1.003503126</code></pre>
</div>
</div>
<p>Calcoliamo i logit per ogni valore $ x $ nel dataset <code>new_data</code> utilizzando le stime a posteriori dei parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilità è una funzione lineare di $ x $:</p>
<p><span class="math display">\[
\log \left( \frac{p}{1-p} \right) = \alpha + \beta x
\]</span></p>
<div id="cell-33" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>logit_p <span class="op">=</span> alpha <span class="op">+</span> new_data[<span class="st">'x'</span>] <span class="op">*</span> beta</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>logit_p</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>0    -1.778448
1    -1.687220
2    -1.595993
3    -1.504765
4    -1.413537
        ...   
95    6.888170
96    6.979398
97    7.070625
98    7.161853
99    7.253080
Name: x, Length: 100, dtype: float64</code></pre>
</div>
</div>
<p>Esaminiamo graficamente la relazione tra il logit <span class="math inline">\(\log \left( \frac{p}{1-p} \right)\)</span> e <span class="math inline">\(x\)</span>:</p>
<div id="cell-35" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>new_data[<span class="st">'logit_p'</span>] <span class="op">=</span> logit_p</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>plt.plot(new_data[<span class="st">'x'</span>], new_data[<span class="st">'logit_p'</span>], linestyle<span class="op">=</span><span class="st">'-'</span>, color<span class="op">=</span><span class="st">'blue'</span>)  <span class="co"># Plot con marcatori e linea</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Logit Predetti in Funzione di X'</span>)  <span class="co"># Titolo del grafico</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'X'</span>)  <span class="co"># Etichetta asse x</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Logit'</span>)  <span class="co"># Etichetta asse y</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>plt.show() </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_22_stan_logistic_regr_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Calcoliamo i logit per ogni valore $ x $ nel dataset <code>new_data</code> utilizzando le stime a posteriori dei parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilità è una funzione lineare di $ x $. Per ottenere la probabilità $ p $ dalla trasformazione del logit, possiamo utilizzare la funzione logistica inversa. Svolgiamo la conversione:</p>
<ol type="1">
<li><p>Calcoliamo il logit per ogni valore di $ x $:</p>
<p><span class="math display">\[
\text{logit}_p = \alpha + \beta x
\]</span></p></li>
<li><p>Applichiamo la funzione logistica inversa (antilogit) per ottenere la probabilità $ p $:</p>
<p><span class="math display">\[
p = \frac{e^{\text{logit}_p}}{1 + e^{\text{logit}_p}} = \frac{e^{\alpha + \beta x}}{1 + e^{\alpha + \beta x}}
\]</span></p></li>
</ol>
<p>Questa formula ci permette di trasformare il logit in una probabilità compresa tra 0 e 1 per ogni valore di $ x $ nel dataset <code>new_data</code>.</p>
<div id="cell-37" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> np.exp(logit_p) <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(logit_p))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggiungi le probabilità calcolate a `new_data`</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>new_data[<span class="st">'prob'</span>] <span class="op">=</span> prob</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>new_data.head()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">logit_p</th>
<th data-quarto-table-cell-role="th">prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.000000</td>
<td>-1.778448</td>
<td>0.144495</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.090909</td>
<td>-1.687220</td>
<td>0.156142</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.181818</td>
<td>-1.595993</td>
<td>0.168542</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.272727</td>
<td>-1.504765</td>
<td>0.181716</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.363636</td>
<td>-1.413537</td>
<td>0.195677</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="cell-38" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>plt.plot(new_data[<span class="st">'x'</span>], new_data[<span class="st">'prob'</span>], linestyle<span class="op">=</span><span class="st">'-'</span>, color<span class="op">=</span><span class="st">'blue'</span>)  <span class="co"># Plot con marcatori e linea</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probabilità Predetta in Funzione di X'</span>)  <span class="co"># Titolo del grafico</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'X'</span>)  <span class="co"># Etichetta asse x</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probabilità Predetta'</span>)  <span class="co"># Etichetta asse y</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.show() </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_22_stan_logistic_regr_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="interpretazione-dei-coefficienti-nella-regressione-logistica" class="level3" data-number="61.14.1">
<h3 data-number="61.14.1" class="anchored" data-anchor-id="interpretazione-dei-coefficienti-nella-regressione-logistica"><span class="header-section-number">61.14.1</span> Interpretazione dei Coefficienti nella Regressione Logistica</h3>
<p>Abbiamo stimato i coefficienti <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> dal modello di regressione logistica con i seguenti valori: - <span class="math inline">\(\alpha = -1.7784477\)</span> - <span class="math inline">\(\beta = 1.003503126\)</span></p>
<p>Esamineremo ora l’interpretazione di questi coefficienti sulla scala dei logit, dell’odds ratio e delle probabilità.</p>
<section id="la-regola-del-dividere-per-4" class="level4" data-number="61.14.1.1">
<h4 data-number="61.14.1.1" class="anchored" data-anchor-id="la-regola-del-dividere-per-4"><span class="header-section-number">61.14.1.1</span> La regola del dividere per 4</h4>
<p>La regola del dividere per 4 è un metodo utile per interpretare i coefficienti della regressione logistica. Dividendo il coefficiente <span class="math inline">\(\beta\)</span> per 4, si ottiene un’approssimazione della massima variazione nella probabilità <span class="math inline">\(\Pr(y = 1)\)</span> per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.</p>
<p>La curva logistica è più ripida al centro, dove $ + x = 0 $ e quindi $ ^{-1}(+ x) = 0.5 $. In questo punto, la pendenza della curva, ovvero la derivata della funzione logistica, è massima e raggiunge il valore $ / 4 $.</p>
<p>Per esempio, nel modello con $ = -1.778 $ e $ = 1.003 $, dividendo <span class="math inline">\(\beta\)</span> per 4 otteniamo circa 0.25. Questo valore rappresenta l’aumento massimo, in termini di probabilità, che possiamo aspettarci per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.</p>
<p>In sintesi, la regola del dividere per 4 semplifica l’interpretazione dei coefficienti della regressione logistica, fornendo un’indicazione intuitiva di come la variabile indipendente influisce sulla probabilità dell’evento di interesse.</p>
</section>
<section id="scala-dei-logit" class="level4" data-number="61.14.1.2">
<h4 data-number="61.14.1.2" class="anchored" data-anchor-id="scala-dei-logit"><span class="header-section-number">61.14.1.2</span> Scala dei Logit</h4>
<p>Nella regressione logistica, la funzione logit rappresenta una relazione lineare tra il logit della probabilità di successo e la variabile indipendente <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
\log \left( \frac{p}{1-p} \right) = \alpha + \beta x
\]</span></p>
<p>Con i coefficienti stimati, la funzione logit diventa:</p>
<p><span class="math display">\[
\log \left( \frac{p}{1-p} \right) = -1.7784477 + 1.003503126 \cdot x
\]</span></p>
<ul>
<li><strong><span class="math inline">\(\alpha = -1.7784477\)</span></strong>: Questo è l’intercetta del modello, il valore del logit quando <span class="math inline">\(x = 0\)</span>. Indica che, quando <span class="math inline">\(x\)</span> è 0, il logit della probabilità di successo è <span class="math inline">\(-1.7784477\)</span>.</li>
<li><strong><span class="math inline">\(\beta = 1.003503126\)</span></strong>: Questo è il coefficiente di <span class="math inline">\(x\)</span> e rappresenta il cambiamento nel logit per ogni incremento unitario in <span class="math inline">\(x\)</span>. In altre parole, per ogni incremento di 1 unità in <span class="math inline">\(x\)</span>, il logit della probabilità di successo aumenta di circa <span class="math inline">\(1.003503126\)</span>.</li>
</ul>
</section>
<section id="odds-ratio" class="level4" data-number="61.14.1.3">
<h4 data-number="61.14.1.3" class="anchored" data-anchor-id="odds-ratio"><span class="header-section-number">61.14.1.3</span> Odds Ratio</h4>
<p>L’odds ratio (OR) misura il cambiamento relativo nelle odds di successo per un incremento unitario in <span class="math inline">\(x\)</span>. È ottenuto esponenziando il coefficiente <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\text{OR} = e^{\beta} = e^{1.003503126} \approx 2.728
\]</span></p>
<p>Un odds ratio di circa <span class="math inline">\(2.728\)</span> indica che, per ogni incremento unitario in <span class="math inline">\(x\)</span>, le odds di successo aumentano di circa <span class="math inline">\(172.8\%\)</span>. In altre parole, l’odds di successo è circa <span class="math inline">\(2.728\)</span> volte maggiore per ogni unità aggiuntiva di <span class="math inline">\(x\)</span>.</p>
</section>
<section id="scala-delle-probabilità" class="level4" data-number="61.14.1.4">
<h4 data-number="61.14.1.4" class="anchored" data-anchor-id="scala-delle-probabilità"><span class="header-section-number">61.14.1.4</span> Scala delle Probabilità</h4>
<p>Per interpretare l’effetto di <span class="math inline">\(\beta\)</span> sulla scala delle probabilità, possiamo considerare come la probabilità <span class="math inline">\(p\)</span> cambia in corrispondenza di specifici valori di <span class="math inline">\(x\)</span>.</p>
<ol type="1">
<li>Quando <span class="math inline">\(x = 0\)</span>:</li>
</ol>
<p><span class="math display">\[
\log \left( \frac{p}{1-p} \right) = -1.7784477
\]</span></p>
<p>Invertendo il logit per ottenere <span class="math inline">\(p\)</span>:</p>
<p><span class="math display">\[
p = \frac{e^{-1.7784477}}{1 + e^{-1.7784477}} \approx \frac{0.169} {1 + 0.169} \approx 0.144
\]</span></p>
<p>Quindi, la probabilità di successo quando <span class="math inline">\(x = 0\)</span> è circa <span class="math inline">\(14.4\%\)</span>.</p>
<ol start="2" type="1">
<li>Per un incremento unitario in <span class="math inline">\(x\)</span>, diciamo <span class="math inline">\(x = 1\)</span>:</li>
</ol>
<p><span class="math display">\[
\log \left( \frac{p}{1-p} \right) = -1.7784477 + 1.003503126 \cdot 1 \approx -0.774944574
\]</span></p>
<p>Invertendo il logit per ottenere <span class="math inline">\(p\)</span>:</p>
<p><span class="math display">\[
p = \frac{e^{-0.774944574}}{1 + e^{-0.774944574}} \approx \frac{0.461} {1 + 0.461} \approx 0.316
\]</span></p>
<p>Quindi, la probabilità di successo quando <span class="math inline">\(x = 1\)</span> è circa <span class="math inline">\(31.6\%\)</span>. Tuttavia questo incremento non è costante per i diversi livelli <span class="math inline">\(x\)</span> e il modo più semplice per mostrare la relazione tra probabilità di successo e la variabile <span class="math inline">\(X\)</span> è quella di generare un grafico come quello che abbimo prodotto in precedenza.</p>
</section>
</section>
<section id="riassunto" class="level3" data-number="61.14.2">
<h3 data-number="61.14.2" class="anchored" data-anchor-id="riassunto"><span class="header-section-number">61.14.2</span> Riassunto</h3>
<ul>
<li><strong>Scala dei Logit</strong>: Un incremento unitario in <span class="math inline">\(x\)</span> aumenta il logit della probabilità di successo di <span class="math inline">\(1.003503126\)</span>.</li>
<li><strong>Odds Ratio</strong>: Le odds di successo aumentano di circa <span class="math inline">\(2.728\)</span> volte per ogni incremento unitario in <span class="math inline">\(x\)</span>.</li>
<li><strong>Scala delle Probabilità</strong>: Quando <span class="math inline">\(x\)</span> passa da 0 a 1, la probabilità di successo aumenta da circa <span class="math inline">\(14.4\%\)</span> a <span class="math inline">\(31.6\%\)</span>. Per la relazione tra ciascun livello <span class="math inline">\(x\)</span> e la probabilità di successo è necessario generare un grafico.</li>
</ul>
<p>Questa analisi dimostra come i coefficienti del modello di regressione logistica possono essere interpretati su diverse scale, fornendo un quadro completo della relazione tra la variabile indipendente e la probabilità di successo.</p>
</section>
</section>
<section id="regressione-logistica-con-solo-lintercetta" class="level2" data-number="61.15">
<h2 data-number="61.15" class="anchored" data-anchor-id="regressione-logistica-con-solo-lintercetta"><span class="header-section-number">61.15</span> Regressione logistica con solo l’intercetta</h2>
<p>La regressione lineare con solo l’intercetta è equivalente a stimare una media e la regressione lineare con un singolo predittore binario è equivalente a stimare una differenza tra medie. Allo stesso modo, la regressione logistica con solo l’intercetta è equivalente alla stima di una proporzione.</p>
<p>Ecco un esempio. Un campione casuale di 50 persone viene testato e 10 di loro manifestano una certa caratteristica psicologica. La proporzione è 0.20 con errore standard $ = 0.06 $. In alternativa, possiamo impostare questo come regressione logistica usando Bambi in Python:</p>
<div id="cell-41" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dati</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="dv">40</span> <span class="op">+</span> [<span class="dv">1</span>]<span class="op">*</span><span class="dv">10</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">'y'</span>: y})</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Modello</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> bmb.Model(<span class="st">'y ~ 1'</span>, data<span class="op">=</span>df, family<span class="op">=</span><span class="st">'bernoulli'</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> model.fit(nuts_sampler<span class="op">=</span><span class="st">"numpyro"</span>, random_seed<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Modeling the probability that y==1</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3e88b9f07c274ffe9894c4e95dfde298","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"66935c4595bb4d98a5fe302309e44c92","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ed0020f473104c4c99adace3d4597a26","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"efb61c3bbab1473aae5522acd448fd28","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="cell-42" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>az.summary(fit, round_to<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Intercept</td>
<td>-1.39</td>
<td>0.35</td>
<td>-2.05</td>
<td>-0.73</td>
<td>0.01</td>
<td>0.01</td>
<td>1524.26</td>
<td>1636.18</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Possiamo trasformare la previsione nella scala delle probabilità e ottenere un risultato che è essenzialmente lo stesso della stima classica con incertezza di 0.20 ± 0.06.</p>
<div id="cell-44" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Given values</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> <span class="op">-</span><span class="fl">1.4</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate logit^-1(-1.41)</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> expit(intercept)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate logit^-1(-1.41 ± 0.36)</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>lower_bound <span class="op">=</span> expit(intercept <span class="op">-</span> error)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>upper_bound <span class="op">=</span> expit(intercept <span class="op">+</span> error)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'p_hat: </span><span class="sc">{</span>p_hat<span class="sc">:.3f}</span><span class="ss">, Lower bound: </span><span class="sc">{</span>lower_bound<span class="sc">:.3f}</span><span class="ss">, Upper bound: </span><span class="sc">{</span>upper_bound<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>p_hat: 0.198, Lower bound: 0.148, Upper bound: 0.259</code></pre>
</div>
</div>
<p>Le stime classiche e quelle della regressione logistica differiscono leggermente, in parte perché Bambi usa una distribuzione a priori e in parte perché l’errore standard classico è solo un’approssimazione all’incertezza inferenziale derivante dai dati discreti.</p>
</section>
<section id="regressione-logistica-con-un-singolo-predittore-binario" class="level2" data-number="61.16">
<h2 data-number="61.16" class="anchored" data-anchor-id="regressione-logistica-con-un-singolo-predittore-binario"><span class="header-section-number">61.16</span> Regressione logistica con un singolo predittore binario</h2>
<p>La regressione logistica su una variabile indicatrice è equivalente a un confronto di proporzioni. Per un esempio semplice, consideriamo i test per una malattia su campioni provenienti da due popolazioni diverse, dove 10 su 50 individui della popolazione A risultano positivi, rispetto a 20 su 60 della popolazione B. La stima classica è 0.13 con errore standard di 0.08. Ecco come impostare questo caso come regressione logistica utilizzando Bambi in Python:</p>
<div id="cell-47" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dati</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> <span class="dv">50</span> <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">60</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> <span class="dv">40</span> <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">10</span> <span class="op">+</span> [<span class="dv">0</span>] <span class="op">*</span> <span class="dv">40</span> <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">20</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: x, <span class="st">'y'</span>: y})</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Definire il modello</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> bmb.Model(<span class="st">'y ~ x'</span>, data<span class="op">=</span>df, family<span class="op">=</span><span class="st">'bernoulli'</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Adattare il modello con un seed</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> model.fit(nuts_sampler<span class="op">=</span><span class="st">"numpyro"</span>, random_seed<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Modeling the probability that y==1</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"281efe8997334896ad6232de743d24b0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"27b2c54192524cf8a07ee81ffeea3e98","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e4241ea9d2a54ec98123fa0ab1673516","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"99102561224f47dea2c541575d69e14c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="cell-48" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizzare i risultati del fit</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>az.summary(fit, round_to<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Intercept</td>
<td>-1.41</td>
<td>0.36</td>
<td>-2.07</td>
<td>-0.74</td>
<td>0.01</td>
<td>0.01</td>
<td>2661.46</td>
<td>2476.84</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">x</td>
<td>0.71</td>
<td>0.45</td>
<td>-0.09</td>
<td>1.60</td>
<td>0.01</td>
<td>0.01</td>
<td>3115.18</td>
<td>2554.46</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Per ottenere l’inferenza per la differenza di probabilità, confrontiamo le previsioni sulla scala delle probabilità per $ x = 0 $ e $ x = 1 $:</p>
<div id="cell-50" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Given values</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> <span class="op">-</span><span class="fl">1.41</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>slope <span class="op">=</span> <span class="fl">0.71</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probabilities for x = 0 and x = 1</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>logit_0 <span class="op">=</span> intercept</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>logit_1 <span class="op">=</span> intercept <span class="op">+</span> slope</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>prob_0 <span class="op">=</span> expit(logit_0)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>prob_1 <span class="op">=</span> expit(logit_1)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the difference in probabilities</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> prob_1 <span class="op">-</span> prob_0</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>prob_0, prob_1, diff</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'prob_0: </span><span class="sc">{</span>prob_0<span class="sc">:.3f}</span><span class="ss">, prob_1: </span><span class="sc">{</span>prob_1<span class="sc">:.3f}</span><span class="ss">, difference: </span><span class="sc">{</span>diff<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>prob_0: 0.196, prob_1: 0.332, difference: 0.136</code></pre>
</div>
</div>
<p>Per l’errore standard possiamo eseguire la seguente simulazione:</p>
<div id="cell-52" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Given values</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>intercept_mean <span class="op">=</span> <span class="op">-</span><span class="fl">1.41</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>slope_mean <span class="op">=</span> <span class="fl">0.71</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>intercept_sd <span class="op">=</span> <span class="fl">0.36</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>slope_sd <span class="op">=</span> <span class="fl">0.45</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of simulations</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>num_simulations <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate samples of the coefficients</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>intercept_samples <span class="op">=</span> np.random.normal(intercept_mean, intercept_sd, num_simulations)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>slope_samples <span class="op">=</span> np.random.normal(slope_mean, slope_sd, num_simulations)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the corresponding probabilities</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>prob_0_samples <span class="op">=</span> expit(intercept_samples)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>prob_1_samples <span class="op">=</span> expit(intercept_samples <span class="op">+</span> slope_samples)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the difference in probabilities for each sample</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>diff_samples <span class="op">=</span> prob_1_samples <span class="op">-</span> prob_0_samples</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean and standard deviation of the differences</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>mean_diff <span class="op">=</span> np.mean(diff_samples)</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>std_diff <span class="op">=</span> np.std(diff_samples)</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>mean_diff, std_diff</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'difference: </span><span class="sc">{</span>mean_diff<span class="sc">:.3f}</span><span class="ss">, standard error: </span><span class="sc">{</span>std_diff<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>difference: 0.140, standard error: 0.096</code></pre>
</div>
</div>
<p>Sebbene abbiamo ottenuto un errore standard di circa 0.095, che è leggermente diverso dall’errore standard di 0.08 menzionato inizialmente, questo valore riflette l’incertezza nelle stime dei coefficienti fornite. Potrebbero esserci delle variazioni dovute al metodo di campionamento utilizzato. Tuttavia, questi calcoli dimostrano l’approccio corretto per stimare l’errore standard utilizzando la simulazione Monte Carlo con le deviazioni standard dei coefficienti stimati. ​</p>
</section>
<section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div id="844248b2-1dfe-4384-bc46-7510b2758172" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext watermark</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>watermark <span class="op">-</span>n <span class="op">-</span>u <span class="op">-</span>v <span class="op">-</span>iv <span class="op">-</span>w <span class="op">-</span>m <span class="op">-</span>p cmdstanp</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The watermark extension is already loaded. To reload it, use:
  %reload_ext watermark
Last updated: Fri Jul 26 2024

Python implementation: CPython
Python version       : 3.12.4
IPython version      : 8.26.0

cmdstanp: not installed

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.5.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

arviz      : 0.18.0
seaborn    : 0.13.2
matplotlib : 3.9.1
scipy      : 1.14.0
statsmodels: 0.14.2
pandas     : 2.2.2
numpy      : 1.26.4
bambi      : 0.14.0

Watermark: 2.4.3
</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter_5/05_21_stan_binomial_regr.html" class="pagination-link" aria-label="Regressione binomiale con Stan">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Regressione binomiale con Stan</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter_5/05_23_stan_poisson_regr.html" class="pagination-link" aria-label="Regressione di Poisson con Stan">
        <span class="nav-page-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Regressione di Poisson con Stan</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/chapter_5/05_22_stan_logistic_regr.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></div></div></footer></body></html>