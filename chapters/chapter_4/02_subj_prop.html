<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Analisi dei dati per psicologi - 30&nbsp; Pensare ad una proporzione in termini soggettivi</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter_4/03_conjugate_families_1.html" rel="next">
<link href="../../chapters/chapter_4/01_intro_bayes.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter_4/01_intro_bayes.html">Inferenza Bayesiana</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter_4/02_subj_prop.html"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Analisi dei dati per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/00_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/01_python_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Python (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/02_python_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/03_numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/04_pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Pandas (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/05_pandas_aggregate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Pandas (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/06_pandas_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pandas (3)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/07_matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Matplotlib</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_1/08_seaborn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Seaborn</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/00_scientific_method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Il Ruolo della Data Science nella Psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/01_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/02_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/03_freq_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/04_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/05_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_2/06_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduzione al calcolo delle probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/02_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/03_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04a_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04b_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/04c_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/05_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/06_density_func.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La funzione di densità di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/07_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/08_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/09_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_3/10_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Inferenza Bayesiana</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Modellazione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/02_subj_prop.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/03_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/04_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/05_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/06_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/10_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Monte Carlo a Catena di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/15_stan_beta_binomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/16_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/17_stan_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/18_stan_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/19_stan_odds_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Analisi bayesiana dell’odds-ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/22_stan_normal_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/23_stan_two_groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/24_stan_hier_beta_binom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Modello gerarchico beta-binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_4/25_stan_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Modelli lineari</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_03_reglin_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Modello di regressione lineare bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_04_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_05_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_05a_stan_multreg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Regressione multipla con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_06_hier_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Il modello lineare gerarchico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_07_robust_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Regressione robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_08_specification_error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Errore di specificazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_09_causal_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Inferenza causale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_21_stan_binomial_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Regressione binomiale con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_22_stan_logistic_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_23_stan_poisson_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Regressione di Poisson con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_24_stan_mixed_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Modelli misti con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_30_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_31_kl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Divergenza KL e ELPD</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_32_stan_loo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Validazione Incrociata Leave-One-Out</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_35_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Dati mancanti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_5/05_40_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Apprendimento per rinforzo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a00_installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Ambiente di lavoro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a01_markdown.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a03_colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Colab: un breve tutorial</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a04_virtual_env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Ambienti virtuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a13a_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Sigma algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a20_kde_plot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">M</span>&nbsp; <span class="chapter-title">Kernel Density Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a30_prob_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">N</span>&nbsp; <span class="chapter-title">Esercizi di probabilità discreta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a40_rng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">O</span>&nbsp; <span class="chapter-title">Generazione di numeri casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a44_montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">P</span>&nbsp; <span class="chapter-title">Simulazione Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a45_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">Q</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a46_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">R</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">S</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a50_reglin_ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">T</span>&nbsp; <span class="chapter-title">Modello di Regressione Bivariato e ML</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a51_reglin_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">U</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a60_ttest_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">V</span>&nbsp; <span class="chapter-title">Esercizi sull’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a70_predict_counts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">W</span>&nbsp; <span class="chapter-title">La predizione delle frequenze</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter_7/a100_solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">X</span>&nbsp; <span class="chapter-title">Soluzioni degli Esercizi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../99-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione">Introduzione</a></li>
  <li><a href="#verosimiglianza-binomiale" id="toc-verosimiglianza-binomiale" class="nav-link" data-scroll-target="#verosimiglianza-binomiale"><span class="header-section-number">30.1</span> Verosimiglianza Binomiale</a></li>
  <li><a href="#applicazione-specifica-del-modello-binomiale" id="toc-applicazione-specifica-del-modello-binomiale" class="nav-link" data-scroll-target="#applicazione-specifica-del-modello-binomiale"><span class="header-section-number">30.2</span> Applicazione Specifica del Modello Binomiale</a>
  <ul class="collapse">
  <li><a href="#processo-di-lavoro" id="toc-processo-di-lavoro" class="nav-link" data-scroll-target="#processo-di-lavoro"><span class="header-section-number">30.2.1</span> Processo di Lavoro</a></li>
  </ul></li>
  <li><a href="#metodo-basato-su-griglia-nellaggiornamento-bayesiano" id="toc-metodo-basato-su-griglia-nellaggiornamento-bayesiano" class="nav-link" data-scroll-target="#metodo-basato-su-griglia-nellaggiornamento-bayesiano"><span class="header-section-number">30.3</span> Metodo Basato su Griglia nell’Aggiornamento Bayesiano</a></li>
  <li><a href="#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta" id="toc-aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta" class="nav-link" data-scroll-target="#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta"><span class="header-section-number">30.4</span> Aggiornamento Bayesiano con una Distribuzione a Priori Discreta</a></li>
  <li><a href="#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua" id="toc-aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua" class="nav-link" data-scroll-target="#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua"><span class="header-section-number">30.5</span> Aggiornamento bayesiano con una distribuzione a priori continua</a></li>
  <li><a href="#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori" id="toc-sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori" class="nav-link" data-scroll-target="#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori"><span class="header-section-number">30.6</span> Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori</a></li>
  <li><a href="#qual-è-il-modo-migliore-per-stimare-il-parametro-theta" id="toc-qual-è-il-modo-migliore-per-stimare-il-parametro-theta" class="nav-link" data-scroll-target="#qual-è-il-modo-migliore-per-stimare-il-parametro-theta"><span class="header-section-number">30.7</span> Qual è il modo migliore per stimare il parametro <span class="math inline">\(\theta\)</span>?</a></li>
  <li><a href="#metodo-basato-su-griglia" id="toc-metodo-basato-su-griglia" class="nav-link" data-scroll-target="#metodo-basato-su-griglia"><span class="header-section-number">30.8</span> Metodo basato su griglia</a></li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali"><span class="header-section-number">30.9</span> Commenti e Considerazioni Finali</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/chapter_4/02_subj_prop.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter_4/01_intro_bayes.html">Inferenza Bayesiana</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter_4/02_subj_prop.html"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-subj-prop" class="quarto-section-identifier"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>Prerequisiti</strong></p>
<p>Leggere il settimo capitolo del libro di <span class="citation" data-cites="albert_2019prob">Albert e Hu (<a href="../../99-references.html#ref-albert_2019prob" role="doc-biblioref">2019</a>)</span>.</p>
<p><strong>Concetti e Competenze Chiave</strong></p>
<ul>
<li>Comprendere e applicare l’aggiornamento bayesiano per affinare le credenze preesistenti alla luce di nuovi dati.</li>
<li>Rappresentare le convinzioni iniziali su un parametro tramite una distribuzione a priori, sia discreta che continua.</li>
<li>Calcolare la verosimiglianza per dati binomiali e utilizzarla per aggiornare la distribuzione a priori.</li>
<li>Derivare e interpretare la distribuzione a posteriori combinando la distribuzione a priori e la verosimiglianza dei dati osservati.</li>
<li>Utilizzare il metodo basato su griglia per approssimare la distribuzione a posteriori di un parametro.</li>
<li>Applicare il modello binomiale a un esempio concreto per stimare la probabilità di un evento specifico e quantificare l’incertezza associata.</li>
<li>Calcolare quantità di interesse (media, moda, intervalli di credibilità) dalla distribuzione a posteriori e interpretare i risultati.</li>
<li>Utilizzare una distribuzione a priori continua, come la Beta, per rappresentare un’ampia gamma di possibili valori del parametro.</li>
</ul>
<p><strong>Preparazione del Notebook</strong></p>
<div id="84332bbc-7cfa-43ce-8beb-666388a1b123" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c82a16ac-ca79-40c2-99a3-e0b28ce0eb07" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>seed: <span class="bu">int</span> <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">map</span>(<span class="bu">ord</span>, <span class="st">"subj_prop"</span>))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>rng: np.random.Generator <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>seed)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>sns.set_theme(palette<span class="op">=</span><span class="st">"colorblind"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">"arviz-darkgrid"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">"retina"</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>Questo capitolo mira a esplorare in profondità il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L’obiettivo è dimostrare come le nostre credenze preesistenti sulla probabilità <span class="math inline">\(\theta\)</span> di un evento specifico possano essere affinate mediante l’osservazione di nuovi dati.</p>
<p>Inizieremo descrivendo come rappresentare le nostre convinzioni iniziali, ovvero quelle formulate prima di raccogliere qualsiasi dato, tramite una distribuzione a priori. Successivamente, delineeremo i passaggi calcolativi necessari per derivare la distribuzione a posteriori di <span class="math inline">\(\theta\)</span>. Questa distribuzione rappresenta le nostre credenze aggiornate su <span class="math inline">\(\theta\)</span> una volta considerati i dati osservati. L’ottenimento della distribuzione a posteriori avviene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, seguita da una normalizzazione per garantire che il risultato sia una distribuzione di probabilità valida.</p>
<p>Il capitolo si focalizza principalmente sul modello binomiale, un contesto elementare ma cruciale per l’inferenza bayesiana. Questo modello è utilizzato per stimare una proporzione di popolazione sconosciuta a partire da una serie di “prove di Bernoulli”, ovvero dati <span class="math inline">\(y_1, \ldots, y_n\)</span>, ciascuno dei quali assume valore 0 o 1. Questo problema rappresenta un punto di partenza relativamente semplice ma fondamentale per la discussione dell’inferenza bayesiana. Inizieremo esplorando il caso in cui la distribuzione a priori è discreta, per poi passare all’analisi di scenari in cui essa è continua.</p>
</section>
<section id="verosimiglianza-binomiale" class="level2" data-number="30.1">
<h2 data-number="30.1" class="anchored" data-anchor-id="verosimiglianza-binomiale"><span class="header-section-number">30.1</span> Verosimiglianza Binomiale</h2>
<p>La distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di <span class="math inline">\(n\)</span> prove indipendenti e identicamente distribuite, dove ciascuna prova dà origine a uno dei due possibili esiti, convenzionalmente etichettati come ‘successo’ e ‘fallimento’. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle <span class="math inline">\(n\)</span> prove, che denotiamo con <span class="math inline">\(y\)</span>. Il parametro <span class="math inline">\(\theta\)</span> rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilità di successo in ciascuna prova. Il modello di campionamento binomiale è:</p>
<p><span class="math display">\[ p(y|\theta) = \text{Bin}(y|n, \theta) = \binom{n}{y} \theta^y (1 - \theta)^{n-y}, \]</span></p>
<p>dove nella parte sinistra dell’equazione non si indica la dipendenza da <span class="math inline">\(n\)</span> perché viene considerato parte del disegno sperimentale e fissato; tutte le probabilità discusse per questo problema sono considerate condizionate su <span class="math inline">\(n\)</span>, cioè assumono che il numero totale di prove sia fissato e noto.</p>
</section>
<section id="applicazione-specifica-del-modello-binomiale" class="level2" data-number="30.2">
<h2 data-number="30.2" class="anchored" data-anchor-id="applicazione-specifica-del-modello-binomiale"><span class="header-section-number">30.2</span> Applicazione Specifica del Modello Binomiale</h2>
<p>In questo capitolo, consideriamo un’applicazione specifica del modello binomiale per stimare la proporzione di presenza di ideazione suicidaria all’interno di una popolazione specifica. Prenderemo in esame lo studio di <span class="citation" data-cites="comtois2023reducing">Comtois et al. (<a href="../../99-references.html#ref-comtois2023reducing" role="doc-biblioref">2023</a>)</span>, in cui viene valutata l’efficacia di un intervento volto a prevenire l’ideazione suicidaria nella comunità universitaria. I partecipanti allo studio erano pazienti reclutati secondo i seguenti criteri: 1. Ricovero ospedaliero o accesso al pronto soccorso per rischio suicidario. 2. Tentativo di suicidio nel mese precedente (compresi tentativi interrotti o auto-interrotti).</p>
<p>Nel gruppo di controllo dello studio, composto da 75 pazienti, è stato somministrato il trattamento standard (TAU), che seguiva le politiche e procedure standard per i servizi brevi e orientati alla crisi. Questo trattamento comprendeva una valutazione iniziale seguita da 1-11 visite con un clinico (con una media di 4,5 visite) e gestione dei farmaci, se necessario, terminando con un rinvio a un altro servizio per il follow-up delle cure primarie o per un ulteriore trattamento per la salute mentale o l’abuso di sostanze.</p>
<p>Dopo 12 mesi, l’ideazione suicidaria è stata misurata utilizzando la Beck Scale for Suicide Ideation (BSS; Beck &amp; Steer, 1993), la versione self-report della Scale for Suicide Ideation (Beck, Brown, &amp; Steer, 1997), una misura valida e affidabile dell’ideazione suicidaria. I dati mostrano che, dopo 12 mesi, 35 pazienti del gruppo TAU hanno riportato almeno un episodio di ideazione suicidaria. L’obiettivo dell’analisi è quantificare l’incertezza di questa stima di <span class="math inline">\(\theta\)</span>, la proporzione di presenza di ideazione suicidaria in questa popolazione dopo un anno.</p>
<p>Consideriamo ogni paziente come una prova bernoulliana in cui emerge (1) o non emerge (0) almeno un episodio di ideazione suicidaria nel corso dell’anno considerato. Utilizzando il modello binomiale, stimiamo quindi la probabilità <span class="math inline">\(\theta\)</span> di ideazione suicidaria nella popolazione e quantifichiamo l’incertezza associata a questa stima.</p>
<section id="processo-di-lavoro" class="level3" data-number="30.2.1">
<h3 data-number="30.2.1" class="anchored" data-anchor-id="processo-di-lavoro"><span class="header-section-number">30.2.1</span> Processo di Lavoro</h3>
<p><span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="../../99-references.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> descrive il flusso lavoro bayesiano nel modo seguente.</p>
<ol type="1">
<li><p><strong>Definire un Modello Generativo per i Dati</strong>: Un modello generativo spiega come i dati sono stati prodotti. Nel nostro caso, consideriamo ogni paziente come un esperimento di Bernoulli con due possibili esiti: presenza (1) o assenza (0) di ideazione suicidaria. Definiamo <span class="math inline">\(\theta\)</span> come la probabilità di osservare ideazione suicidaria in un singolo paziente. Il modello generativo dei dati si esprime quindi come:</p>
<p><span class="math display">\[
X_i \sim \text{Bernoulli}(\theta),
\]</span></p>
<p>dove <span class="math inline">\(i = 1, 2, ..., 75\)</span> e <span class="math inline">\(X_i\)</span> assume valore 1 in caso di presenza e 0 in caso di assenza di ideazione suicidaria.</p></li>
<li><p><strong>Definire uno Stimatore per il Parametro di Interesse</strong>: Uno stimatore è una regola o una formula che utilizza i dati del campione per calcolare una stima del parametro di interesse. Nel nostro caso, lo stimatore che cerchiamo è la probabilità <span class="math inline">\(\theta\)</span> di osservare un episodio di ideazione suicidaria dopo 12 mesi dall’episodio di crisi. L’obiettivo è stimare l’incertezza di questa probabilità basandoci sui dati raccolti.</p></li>
<li><p><strong>Sviluppare un Metodo Statistico per la Stima del Parametro di Interesse</strong>: Per stimare <span class="math inline">\(\theta\)</span>, applichiamo l’approccio bayesiano. Nella statistica bayesiana, partiamo da una distribuzione a priori che esprime le nostre convinzioni iniziali su <span class="math inline">\(\theta\)</span>, per poi aggiornarla con i dati osservati e ottenere una distribuzione a posteriori. Una scelta comune per la priori in un contesto Bernoulli/Binomiale è la distribuzione Beta. Partiamo da una priori non informativa, <span class="math inline">\(\text{Beta}(1, 1)\)</span>, che corrisponde a una distribuzione uniforme.</p>
<p>La verosimiglianza dei nostri dati (35 “successi”, 40 “insuccessi”) è data dalla distribuzione binomiale:</p>
<p><span class="math display">\[
L(p) = {75 \choose 35} \theta^{35} (1-\theta)^{40}.
\]</span></p>
<p>Utilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:</p>
<p><span class="math display">\[
\text{Posteriore} \propto \text{Verosimiglianza} \times \text{Priori}
\]</span></p></li>
<li><p><strong>Validazione del Modello attraverso Simulazioni</strong>: Prima di esaminare i dati concreti, effettuiamo una simulazione predittiva a priori per verificare se il modello può generare dati plausibili. Dopo l’adattamento del modello ai dati veri, conduciamo una simulazione predittiva a posteriori per testare la capacità del modello di produrre dati comparabili a quelli osservati.</p></li>
<li><p><strong>Analisi e Sintesi dei Risultati</strong>: Infine, procediamo con l’analisi dei dati veri, calcolando la distribuzione a posteriori, solitamente attraverso metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per inferire su <span class="math inline">\(\theta\)</span>, utilizzando statistiche descrittive quali media, mediana e intervalli di credibilità.</p></li>
</ol>
<p>Nel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="../../99-references.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span>.</p>
</section>
</section>
<section id="metodo-basato-su-griglia-nellaggiornamento-bayesiano" class="level2" data-number="30.3">
<h2 data-number="30.3" class="anchored" data-anchor-id="metodo-basato-su-griglia-nellaggiornamento-bayesiano"><span class="header-section-number">30.3</span> Metodo Basato su Griglia nell’Aggiornamento Bayesiano</h2>
<p>Dopo aver discusso l’aggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.</p>
<p>Il metodo basato su griglia è un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l’uso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:</p>
<ol type="1">
<li><strong>Selezione di un intervallo per il parametro</strong>: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.</li>
<li><strong>Creazione di una griglia di punti</strong>: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.</li>
<li><strong>Calcolo della posteriori per ogni punto</strong>: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.</li>
<li><strong>Normalizzazione dei risultati</strong>: Per garantire che la somma delle probabilità sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l’area totale sottesa dalla curva della distribuzione a posteriori.</li>
</ol>
<p>Attraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.</p>
</section>
<section id="aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta" class="level2" data-number="30.4">
<h2 data-number="30.4" class="anchored" data-anchor-id="aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta"><span class="header-section-number">30.4</span> Aggiornamento Bayesiano con una Distribuzione a Priori Discreta</h2>
<p>Quando non disponiamo di informazioni specifiche preliminari su <span class="math inline">\(\theta\)</span>, potremmo inizialmente considerare un valore di 0.5, suggerendo una probabilità ugualmente bilanciata tra la presenza e l’assenza di ideazione suicidaria. Tuttavia, questo valore non rappresenta adeguatamente l’intero spettro della nostra incertezza iniziale.</p>
<p>Per riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilità distinta a ciascun valore plausibile di <span class="math inline">\(\theta\)</span>. Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.</p>
<p>Supponiamo di considerare undici possibili valori per <span class="math inline">\(\theta\)</span>, che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilità a priori uguale, creando così una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di <span class="math inline">\(\theta\)</span> più probabili.</p>
<p>Dopo aver osservato i dati — ad esempio, 35 casi di ideazione suicidaria su 75 — applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilità a priori di <span class="math inline">\(\theta\)</span> con la verosimiglianza dei dati per produrre una probabilità a posteriori aggiornata per <span class="math inline">\(\theta\)</span>.</p>
<p>La distribuzione a posteriori integra quindi le nostre conoscenze pregresse con le nuove informazioni ottenute dalle osservazioni, offrendoci una visione aggiornata e quantitativamente informata del parametro <span class="math inline">\(\theta\)</span>. Attraverso questo esempio, possiamo osservare un approccio sistematico ed efficace per affinare le nostre credenze alla luce di nuove prove.</p>
<div id="0335e655-28d9-4305-b335-168e9055d3a4" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">11</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(theta)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]</code></pre>
</div>
</div>
<p>Nel caso in cui non vi siano motivi fondati per assegnare probabilità diverse ai vari valori di <span class="math inline">\(\theta\)</span>, è possibile attribuire la stessa probabilità a ciascun valore, creando così una distribuzione uniforme. È importante prestare attenzione alla seconda riga di codice, che esegue una standardizzazione. Poiché <code>unif_discr_pdf</code> è un vettore composto da un numero finito di elementi, questi elementi devono essere considerati come probabilità, e tali probabilità devono obbligatoriamente sommarsi a uno.</p>
<div id="f86cfde8-567a-4f92-b702-b0f0d405ede1" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>unif_distr_pdf <span class="op">=</span> stats.uniform.pdf(theta) </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>unif_distr_pdf <span class="op">=</span> unif_distr_pdf <span class="op">/</span> np.<span class="bu">sum</span>(unif_distr_pdf)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>unif_distr_pdf</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>array([0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,
       0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,
       0.09090909])</code></pre>
</div>
</div>
<p>Una rappresentazione visiva di questa distribuzione di massa di probabilità si ottiene nel modo seguente.</p>
<div id="f64bf8c4-e7c7-42ca-b282-bb5b645bf24d" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plt.stem(theta, unif_distr_pdf, markerfmt<span class="op">=</span><span class="st">" "</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribuzione a priori"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Probabilità"</span>)<span class="op">;</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Se, al contrario, riteniamo che i valori centrali nella distribuzione di <span class="math inline">\(\theta\)</span> siano più credibili rispetto a quelli situati agli estremi, potremmo esprimere questa opinione soggettiva mediante la seguente distribuzione di massa di probabilità.</p>
<div id="ac190fa9-cde1-4475-92d1-4b4ff1a43226" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>not_unif_distr_pdf <span class="op">=</span> [<span class="dv">0</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.175</span>, <span class="fl">0.175</span>, <span class="fl">0.175</span>, <span class="fl">0.175</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plt.stem(theta, not_unif_distr_pdf, markerfmt<span class="op">=</span><span class="st">" "</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribuzione a priori"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Probabilità"</span>)<span class="op">;</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>La prima distribuzione di probabilità è una distribuzione discreta uniforme, in quanto assegna la stessa probabilità a ciascun elemento dell’insieme discreto su cui è definita, ossia i valori <span class="math inline">\(\{0, 0.1, 0.2, \dots, 1.0\}\)</span>. La seconda distribuzione di probabilità, pur essendo discreta, segue un andamento non uniforme: si presume che <span class="math inline">\(\theta\)</span> abbia una probabilità maggiore di assumere un valore nell’insieme <span class="math inline">\(\{0.4, 0.5, 0.6, 0.7\}\)</span> rispetto all’insieme <span class="math inline">\(\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\}\)</span>.</p>
<p>Le credenze iniziali riguardo ai possibili valori di <span class="math inline">\(\theta\)</span> costituiscono la “distribuzione a priori”. L’inferenza bayesiana aggiorna queste credenze iniziali utilizzando le informazioni ottenute dai dati. Queste informazioni vengono combinate con le credenze iniziali su <span class="math inline">\(\theta\)</span> attraverso l’applicazione del teorema di Bayes, allo scopo di ottenere la “distribuzione a posteriori”. Quest’ultima rappresenta le nostre credenze aggiornate sui possibili valori di <span class="math inline">\(\theta\)</span> dopo l’osservazione dei dati.</p>
<p>Supponiamo di aver osservato 35 “successi” in 75 prove. Per calcolare la distribuzione a posteriori, utilizzeremo la seconda delle due distribuzioni a priori precedentemente descritte. In base al teorema di Bayes, la distribuzione a posteriori si ottiene moltiplicando la verosimiglianza per la distribuzione a priori e quindi dividendo per una costante di normalizzazione (la verosimiglianza marginale):</p>
<p><span class="math display">\[ p(\theta \mid y) = \frac{p(y \mid \theta)p(\theta)}{p(y)}. \]</span></p>
<p>Per calcolare la funzione di verosimiglianza, <span class="math inline">\(p(y \mid \theta)\)</span>, dobbiamo comprendere il processo mediante il quale i dati sono stati generati. Nel nostro contesto, i dati rappresentano i risultati di 75 ripetizioni di un esperimento casuale che può produrre solo due risultati possibili: “presenza” e “assenza” di ideazione suicidaria. Inoltre, i 75 casi esaminati sono tra loro indipendenti (i pazienti non si influenzano reciprocamente). In tali circostanze, possiamo assumere che il modello generativo dei dati sia il modello binomiale con probabilità sconosciuta <span class="math inline">\(\theta\)</span>.</p>
<p>Utilizzando Python, è possibile calcolare la funzione di verosimiglianza tramite la funzione <code>binom.pmf()</code>.</p>
<div id="67e4acf9-aa28-4ddf-b670-2eb080b8e566" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>lk <span class="op">=</span> stats.binom.pmf(<span class="dv">35</span>, <span class="dv">70</span>, theta)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>lk <span class="op">=</span> lk <span class="op">/</span> np.<span class="bu">sum</span>(lk)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>lk</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>array([0.00000000e+00, 1.99180385e-16, 1.10906788e-07, 1.50811359e-03,
       1.61492440e-01, 6.73998671e-01, 1.61492440e-01, 1.50811359e-03,
       1.10906788e-07, 1.99180385e-16, 0.00000000e+00])</code></pre>
</div>
</div>
<p>Per i 10 valori <span class="math inline">\(\theta\)</span> considerati, la funzione di verosimiglianza assume la forma indicata dalla figura seguente.</p>
<div id="7ec8350c-510a-4d13-9d9d-9c4126f96847" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>plt.stem(theta, lk, markerfmt<span class="op">=</span><span class="st">" "</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Funzione di verosimiglianza"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"$L(</span><span class="ch">\\</span><span class="st">theta)$"</span>)<span class="op">;</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Per calcolare la distribuzione a posteriori, eseguiamo una moltiplicazione elemento per elemento tra il vettore contenente i valori della distribuzione a priori e il vettore contenente i valori della funzione di verosimiglianza. Usando Python, il risultato si trova nel modo seguente.</p>
<div id="25927bc4-c882-4ea3-b90c-d7394ea9124f" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>not_unif_distr_pdf <span class="op">*</span> lk</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>array([0.00000000e+00, 9.95901924e-18, 5.54533942e-09, 7.54056793e-05,
       2.82611770e-02, 1.17949767e-01, 2.82611770e-02, 2.63919878e-04,
       5.54533942e-09, 9.95901924e-18, 0.00000000e+00])</code></pre>
</div>
</div>
<p>Per illustrare con un esempio, il valore dell’ottavo elemento della distribuzione a posteriori si calcola come segue (tenendo presente che in Python gli indici partono da 0):</p>
<div id="319a71bf-a4c9-4d02-a9b3-32284f3c9831" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>not_unif_distr_pdf[<span class="dv">7</span>] <span class="op">*</span> lk[<span class="dv">7</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>0.0002639198775144677</code></pre>
</div>
</div>
<p>Dopo questa moltiplicazione, otteniamo una distribuzione che rappresenta le probabilità condizionate dei possibili valori di <span class="math inline">\(\theta\)</span> alla luce dei dati osservati. Tuttavia, questa distribuzione potrebbe non è normalizzata, il che significa che la somma di tutte le probabilità condizionate non è uguale a 1.</p>
<p>Per ottenere una distribuzione di probabilità correttamente normalizzata, dobbiamo dividere ciascun valore ottenuto precedentemente per la probabilità marginale dei dati <span class="math inline">\(y\)</span>. La probabilità marginale dei dati <span class="math inline">\(y\)</span> è una costante di normalizzazione e può essere calcolata utilizzando la legge della probabilità totale (si veda l’eq. {eq}<code>eq-prob-tot</code>).</p>
<p>Per chiarire, ricordiamo che, nel capitolo {ref}<code>cond-prob-notebook</code> abbiamo considerato il caso di una partizione dello spazio campione in due eventi mutualmente esclusivi ed esaustivi, <span class="math inline">\(H_1\)</span> e <span class="math inline">\(H_2\)</span>. All’interno dello spazio campione abbiamo definito un evento <span class="math inline">\(E\)</span> non nullo e abbiamo visto che <span class="math inline">\(P(E) = P(E \cap H_1) + P(E \cap H_2)\)</span>, ovvero <span class="math inline">\(P(E) = P(E \mid H_1) P(H_1) + P(E \mid H_2) P(H_2)\)</span>. Usando la terminologia che stiamo usando qui, <span class="math inline">\(P(E \mid H_i)\)</span> corrisponde alla funzione di verosimiglianza e <span class="math inline">\(P(H_i)\)</span> corrisponde alla funzione a priori. Nel caso discreto, come quello che stiamo considerando ora, il teorema della probabilità totale ci dice dunque che dobbiamo fare la somma dei prodotti tra i valori della funzione di verosimiglianza e i corrispondenti valori della distribuzione a priori.</p>
<div id="07a1f5c4-fec3-4e73-acad-815743e6f779" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>(not_unif_distr_pdf <span class="op">*</span> lk)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>0.17481145807507814</code></pre>
</div>
</div>
<p>Otteniamo dunque il seguente risultato.</p>
<div id="a479a53a-a3c3-4156-8cd5-a8f036963b7a" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>post <span class="op">=</span> (not_unif_distr_pdf <span class="op">*</span> lk) <span class="op">/</span> np.<span class="bu">sum</span>(not_unif_distr_pdf <span class="op">*</span> lk)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(post)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.00000000e+00 5.69700599e-17 3.17218304e-08 4.31354330e-04
 1.61666617e-01 6.74725608e-01 1.61666617e-01 1.50974015e-03
 3.17218304e-08 5.69700599e-17 0.00000000e+00]</code></pre>
</div>
</div>
<p>Verifichiamo di avere ottenuto una distribuzione di massa di probabilità:</p>
<div id="1d26b695-f1f0-4db3-8a77-62dcbb27fa77" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>(post)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>1.0000000000000002</code></pre>
</div>
</div>
<p>Esaminiamo la distribuzione a posteriori di <span class="math inline">\(\theta\)</span> con un grafico.</p>
<div id="8f9a2376-5c08-4167-9de7-72e7d67f98d0" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>plt.stem(theta, post, markerfmt<span class="op">=</span><span class="st">" "</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribuzione a posteriori"</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$f(\theta)$"</span>)<span class="op">;</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Una volta trovata la distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, possiamo calcolare altre quantità di interesse. Ad esempio, la moda a posteriori di <span class="math inline">\(\theta\)</span> può essere individuata direttamente dal grafico precedente e risulta pari a 0.5. Per calcolare invece la media a posteriori, ci avvaliamo della formula del valore atteso delle variabili casuali.</p>
<div id="8aba7f8e-7fb9-4591-91e2-08ba3eda7286" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>(theta <span class="op">*</span> post)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>0.5002156771647586</code></pre>
</div>
</div>
<p>La varianza della distribuzione a posteriori è</p>
<div id="c9cbbb4a-a79e-448e-9615-e11aa35db220" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>(theta<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> post) <span class="op">-</span> (np.<span class="bu">sum</span>(theta <span class="op">*</span> post)) <span class="op">**</span> <span class="dv">2</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>0.0033109353091205773</code></pre>
</div>
</div>
<p>Con questo metodo, possiamo calcolare la distribuzione a posteriori di <span class="math inline">\(\theta\)</span> per qualsiasi distribuzione a priori discreta.</p>
</section>
<section id="aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua" class="level2" data-number="30.5">
<h2 data-number="30.5" class="anchored" data-anchor-id="aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua"><span class="header-section-number">30.5</span> Aggiornamento bayesiano con una distribuzione a priori continua</h2>
<p>A fini didattici, abbiamo esaminato il caso di una distribuzione a priori discreta. Tuttavia, è importante notare che l’impiego di una distribuzione a priori continua, come la distribuzione Beta, risulta più appropriato in quanto permette di rappresentare un’ampia gamma di possibili valori per il parametro non noto <span class="math inline">\(\theta\)</span>, senza essere vincolati a un insieme discreto di valori. Inoltre, la distribuzione Beta presenta l’ulteriore vantaggio di avere un dominio definito nell’intervallo [0, 1], che corrisponde alla gamma dei possibili valori per la proporzione <span class="math inline">\(\theta\)</span>.</p>
<p>Per esempio, consideriamo la distribuzione Beta(2, 2), caratterizzata da una simmetria nella sua forma. Per valutare la distribuzione Beta in corrispondenza di punti specifici, come ad esempio 0.5, 0.8 e 1.2, possiamo fare affidamento sulla funzione <code>beta.pdf</code>. A titolo illustrativo, la densità di probabilità della distribuzione Beta(2, 2) nel caso del valore 0.5 risulta essere 1.5, suggerendo che i valori di <span class="math inline">\(\theta\)</span> vicini a 0.5 appaiono più plausibili rispetto a quelli intorno a 0.8, dove la funzione assume un valore di 0.96. È importante sottolineare che la densità di probabilità della distribuzione Beta(2, 2) relativa al valore 1.2 è pari a 0, poiché tale valore esula dall’intervallo di definizione della distribuzione (0 e 1). La distribuzione Beta(2, 2) è illustrata nella figura qui di seguito.</p>
<div id="fe0cc46e-37c1-44b7-b8a3-bcc8f6fceb7e" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> stats.beta.pdf(x, alpha, beta)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">'Probability Density Function of Beta Distribution'</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Supponiamo – solo allo scopo di illustrare la procedura – che le nostre credenze a priori siano rappresentate da una Beta(2, 5).</p>
<div id="b0e78aa0-e2a1-458c-a218-5523a2812c4a" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> stats.beta.pdf(x, alpha, beta)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">'Probability Density Function of Beta Distribution'</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Nel seguente esempio, useremo la funzione <code>beta.pdf()</code> per generare una distribuzione a priori discretizzata.</p>
<div id="72a2ffa2-2cb1-4412-9ff5-317c8f1a4173" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats.beta.pdf(theta, <span class="dv">2</span>, <span class="dv">5</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.     1.9683 2.4576 2.1609 1.5552 0.9375 0.4608 0.1701 0.0384 0.0027
 0.    ]</code></pre>
</div>
</div>
<div id="8ff061d5-730d-4616-b4fe-d60121144d05" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.plot(theta, stats.beta.pdf(theta, <span class="dv">2</span>, <span class="dv">5</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Ora però usiamo un numero maggiore di valori <span class="math inline">\(\theta\)</span>.</p>
<div id="51674518-1506-4a79-b704-f7c033bf38ab" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1001</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(theta)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.    0.001 0.002 ... 0.998 0.999 1.   ]</code></pre>
</div>
</div>
<p>Calcoliamo la distribuzione a priori normalizzata.</p>
<div id="9814802f-ce24-4cbd-af85-7bc78d235182" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> stats.beta.pdf(theta, <span class="dv">2</span>, <span class="dv">5</span>) </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> prior <span class="op">/</span> np.<span class="bu">sum</span>(prior)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(prior)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.00000000e+00 2.98802546e-05 5.95215869e-05 ... 4.79041198e-13
 2.99700749e-14 0.00000000e+00]</code></pre>
</div>
</div>
<div id="5ef1fbe7-37eb-4f32-92db-ab28703abfff" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>(prior)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>1.0000000000000002</code></pre>
</div>
</div>
<p>Per calcolare la verosimiglianza, seguiamo la medesima procedura illustrata nel capitolo {ref}<code>cap-likelihood</code>. In aggiunta, effettuiamo la normalizzazione dei valori discretizzati della verosimiglianza, come precedentemente descritto.</p>
<div id="61c86afa-5c17-4486-8925-f02aaeded2ba" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>lk <span class="op">=</span> stats.binom.pmf(<span class="dv">6</span>, <span class="dv">9</span>, theta)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>lk <span class="op">=</span> lk <span class="op">/</span> np.<span class="bu">sum</span>(lk)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lk)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.00000000e+00 8.37482519e-19 5.34380847e-17 ... 6.63976213e-09
 8.34972583e-10 0.00000000e+00]</code></pre>
</div>
</div>
<p>Infine, otteniamo la distribuzione a posteriori moltiplicando la distribuzione a priori per la verosimiglianza e dividendo per la costante di normalizzazione.</p>
<div id="67ba7bf8-9711-4421-a2ac-3148d3a4c4dd" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>post <span class="op">=</span> (prior <span class="op">*</span> lk) <span class="op">/</span> np.<span class="bu">sum</span>(prior <span class="op">*</span> lk)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="34cbdb45-18c7-42d8-a70b-720d4862022b" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>(post)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>1.0</code></pre>
</div>
</div>
<div id="d663b17d-705b-43fb-9074-cb009e217db6" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>plt.plot(theta, prior, linestyle<span class="op">=</span><span class="st">"solid"</span>, color<span class="op">=</span><span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"Prior"</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>plt.plot(theta, lk, linestyle<span class="op">=</span><span class="st">"solid"</span>, color<span class="op">=</span><span class="st">"C2"</span>, label<span class="op">=</span><span class="st">"Likelihood"</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>plt.plot(theta, post, linestyle<span class="op">=</span><span class="st">"solid"</span>, color<span class="op">=</span><span class="st">"C3"</span>, label<span class="op">=</span><span class="st">"Posterior"</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"$\theta$"</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$f(\theta)$"</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.legend()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Possiamo calcolare la media e la deviazione standard della distribuzione a posteriori come abbiamo fatto in precedenza.</p>
<div id="694e09d3-7f8a-49c7-beb3-cea591574ca2" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># media</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>(theta <span class="op">*</span> post)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>0.5000000000000001</code></pre>
</div>
</div>
<div id="bd9e09a4-ab29-4c1e-b73b-aae5acb590f8" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># deviazione standard</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>np.sqrt(np.<span class="bu">sum</span>(theta<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> post) <span class="op">-</span> (np.<span class="bu">sum</span>(theta <span class="op">*</span> post)) <span class="op">**</span> <span class="dv">2</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>0.12126781251816628</code></pre>
</div>
</div>
</section>
<section id="sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori" class="level2" data-number="30.6">
<h2 data-number="30.6" class="anchored" data-anchor-id="sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori"><span class="header-section-number">30.6</span> Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori</h2>
<p>Una volta ottenuta la distribuzione a posteriori, è possibile generare un campione casuale da questa distribuzione. A titolo di esempio, possiamo estrarre un campione di 10000 punti dalla distribuzione a posteriori di <span class="math inline">\(\theta\)</span> che abbiamo calcolato.</p>
<div id="48575740-494b-463e-b624-7d3895fa3f05" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> np.random.choice(theta, p<span class="op">=</span>post, size<span class="op">=</span><span class="bu">int</span>(<span class="fl">1e4</span>), replace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>L’istruzione precedente genera un array denominato <code>samples</code> contenente 10000 punti campionati dalla distribuzione a posteriori calcolata. La funzione <code>np.random.choice</code> viene impiegata per selezionare casualmente i valori <code>theta</code> basandosi sulle probabilità definite da <code>post</code>.</p>
<div id="83567aba-8b57-4479-8012-cb6b7c931d37" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First subplot: Scatter plot</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)  <span class="co"># 1 row, 2 columns, first subplot</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>plt.plot(samples, <span class="st">'o'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"sample number"</span>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$\theta$"</span>)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Second subplot: KDE plot</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)  <span class="co"># 1 row, 2 columns, second subplot</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>az.plot_kde(samples)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"$\theta$"</span>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.ylabel(<span class="st">"density"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_subj_prop_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Sfruttando il campione estratto dalla distribuzione a posteriori, è possibile calcolare diverse quantità di interesse. Ad esempio, la stima della media a posteriori di <span class="math inline">\(\theta\)</span> si ottiene semplicemente calcolando la media dei valori così ottenuti.</p>
<div id="c8bd0ad9-7ff9-42fc-8dd8-5a4eebcd7f50" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>np.mean(samples)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>0.499356</code></pre>
</div>
</div>
<p>In maniera analoga possiamo calcolare la deviazione standard della distribuzione a posteriori di <span class="math inline">\(\theta\)</span>.</p>
<div id="61b419d9-61b2-406c-bfad-14636e6595f0" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>np.std(samples)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>0.1199298022344738</code></pre>
</div>
</div>
<p>La moda a posteriori si può calcolare nel modo seguente.</p>
<div id="1d4b27e8-86b8-4700-a326-35ca3d2328c3" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(theta[post <span class="op">==</span> <span class="bu">max</span>(post)])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.5]</code></pre>
</div>
</div>
<p>Oppure, usando il campione estratto dalla distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, otteniamo</p>
<div id="aa0e5c12-63be-49aa-bd51-4653b609c8cf" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>stats.mode(samples)[<span class="dv">0</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>0.507</code></pre>
</div>
</div>
<p>Usando il campione estratto dalla distribuzione a posteriori, è immediato trovare la mediana a posteriori di <span class="math inline">\(\theta\)</span>.</p>
<div id="1128d5b8-eb13-4607-8307-8bc328985e4a" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>np.median(samples)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>0.5</code></pre>
</div>
</div>
<p>Possiamo calcolare la probabilità di varie ipotesi relative a <span class="math inline">\(\theta\)</span> nella distribuzione a posteriori. Per esempio, calcoliamo la probabilità <span class="math inline">\(P(\theta &lt; 0.5)\)</span>.</p>
<div id="5502d7e0-cad1-46f5-9101-0329bfc05d07" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>(post[theta <span class="op">&lt;</span> <span class="fl">0.5</span>])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>0.49842895507812507</code></pre>
</div>
</div>
<p>Alternativamente, utilizzando il campione estratto dalla distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, otteniamo un risultato analogo, sebbene soggetto a variazioni dovute all’approssimazione numerica.</p>
<div id="5ee2af9f-47eb-44a2-a611-e54552622cf6" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>(samples <span class="op">&lt;</span> <span class="fl">0.5</span>) <span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>0.4996</code></pre>
</div>
</div>
<p>Possiamo trovare la probabilità a posteriori che <span class="math inline">\(\theta\)</span> sia compresa in un dato intervallo. Per esempio, troviamo <span class="math inline">\(P(0.5 &lt; \theta &lt; 0.75)\)</span>.</p>
<div id="dade5aee-bbc2-4dfd-b445-7469807f2113" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>((samples <span class="op">&gt;</span> <span class="fl">0.6</span>) <span class="op">&amp;</span> (samples <span class="op">&lt;</span> <span class="fl">0.8</span>)) <span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>0.2073</code></pre>
</div>
</div>
<p>Utilizzando il campionamento effettuato dalla distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, è possibile risolvere il problema inverso, ovvero determinare l’intervallo che contiene <span class="math inline">\(\theta\)</span> con una specifica probabilità. Ad esempio, si può calcolare l’intervallo che ha una probabilità pari a 0.94 di contenere <span class="math inline">\(\theta\)</span>, basandosi sulla distribuzione a posteriori campionata.</p>
<div id="67e8b099-9dda-457b-9099-6d000c93734f" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>np.percentile(samples, [<span class="dv">2</span>, <span class="dv">98</span>])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>array([0.261, 0.741])</code></pre>
</div>
</div>
<p>L’intervallo specificato è noto come <em>intervallo di credibilità</em> e rappresenta una quantificazione statistica dell’incertezza associata alla stima del parametro <span class="math inline">\(\theta\)</span>. In termini probabilistici, si può affermare con il 94% di credibilità che il valore “vero” di <span class="math inline">\(\theta\)</span> è contenuto nell’intervallo [0.26, 0.74].</p>
<p>Se vogliamo trovare l’intervallo di credibilità a più alta densità a posteriori (HPD), usiamo la funzione ArviZ <code>hdi()</code> (si veda il capitolo {ref}<code>sintesi-distr-post-notebook</code>).</p>
<div id="45e0d0d8-b2d8-4dde-a5c0-7c1207c161e3" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>az.hdi(samples, hdi_prob<span class="op">=</span><span class="fl">0.94</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>array([0.278, 0.721])</code></pre>
</div>
</div>
<p>Nel contesto attuale, la distribuzione a posteriori è simmetrica. Di conseguenza, l’intervallo di credibilità calcolato attraverso i quantili e l’intervallo di credibilità a più alta densità a posteriori (HPDI) sono molto simili.</p>
</section>
<section id="qual-è-il-modo-migliore-per-stimare-il-parametro-theta" class="level2" data-number="30.7">
<h2 data-number="30.7" class="anchored" data-anchor-id="qual-è-il-modo-migliore-per-stimare-il-parametro-theta"><span class="header-section-number">30.7</span> Qual è il modo migliore per stimare il parametro <span class="math inline">\(\theta\)</span>?</h2>
<p>Nonostante abbiamo discusso in precedenza dei diversi metodi di stima puntuale e intervallare per riassumere la distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, la migliore stima del parametro che stiamo cercando di inferire è rappresentata dall’intera distribuzione a posteriori. Per citare le parole di <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="../../99-references.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span>:</p>
<blockquote class="blockquote">
<p>That an arbitrary interval contains an arbitrary value is not meaningful. Use the whole distribution.</p>
</blockquote>
</section>
<section id="metodo-basato-su-griglia" class="level2" data-number="30.8">
<h2 data-number="30.8" class="anchored" data-anchor-id="metodo-basato-su-griglia"><span class="header-section-number">30.8</span> Metodo basato su griglia</h2>
<p>Il metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l’approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:</p>
<ol type="1">
<li>Fissare una griglia discreta di possibili valori dei parametri.</li>
<li>Valutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.</li>
<li>Calcolare l’approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.</li>
<li>Selezionare <span class="math inline">\(n\)</span> valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.</li>
</ol>
<p>Questo metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all’aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.</p>
<p>In sintesi, l’approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l’implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della <em>maledizione della dimensionalità</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.</p>
</section>
<section id="commenti-e-considerazioni-finali" class="level2" data-number="30.9">
<h2 data-number="30.9" class="anchored" data-anchor-id="commenti-e-considerazioni-finali"><span class="header-section-number">30.9</span> Commenti e Considerazioni Finali</h2>
<p>In questo capitolo, abbiamo esplorato l’aggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l’elaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell’inferenza relativa alle proporzioni, dove la distribuzione a priori è modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, è possibile derivare analiticamente la distribuzione a posteriori. L’analisi dettagliata di questo caso sarà trattata nel capitolo successivo.</p>
<p>L’aspetto fondamentale della discussione presente risiede nell’approccio adottato per affrontare una specifica questione di ricerca, ossia la quantificazione dell’incertezza relativa alla proporzione di presenza di ideazione suicidaria nella popolazione considerata. Abbiamo illustrato come sia possibile mettere in pratica alcuni dei passaggi del flusso di lavoro bayesiano proposto da <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="../../99-references.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span>.</p>
</section>
<section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div id="589acf1f-6daa-4cf3-9806-b163cda1dac3" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext watermark</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>watermark <span class="op">-</span>n <span class="op">-</span>u <span class="op">-</span>v <span class="op">-</span>iv <span class="op">-</span>w <span class="op">-</span>m</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Last updated: Wed Jul 17 2024

Python implementation: CPython
Python version       : 3.12.4
IPython version      : 8.26.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.5.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

pandas    : 2.2.2
scipy     : 1.14.0
seaborn   : 0.13.2
arviz     : 0.18.0
matplotlib: 3.9.1
numpy     : 1.26.4

Watermark: 2.4.3
</code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-albert_2019prob" class="csl-entry" role="listitem">
Albert, Jim, e Jingchen Hu. 2019. <em>Probability and Bayesian Modeling</em>. Boca Raton, Florida: CRC Press.
</div>
<div id="ref-comtois2023reducing" class="csl-entry" role="listitem">
Comtois, Katherine Anne, Karin E Hendricks, Christopher R DeCou, Samantha A Chalker, Amanda H Kerbrat, Jennifer Crumlish, Tierney K Huppert, e David Jobes. 2023. <span>«Reducing short term suicide risk after hospitalization: A randomized controlled trial of the Collaborative Assessment and Management of Suicidality»</span>. <em>Journal of affective disorders</em> 320: 656–66.
</div>
<div id="ref-McElreath_rethinking" class="csl-entry" role="listitem">
McElreath, Richard. 2020. <em>Statistical rethinking: <span>A</span> <span>Bayesian</span> course with examples in <span>R</span> and <span>Stan</span></em>. 2nd Edition. Boca Raton, Florida: CRC Press.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Per comprendere la maledizione della dimensionalità, possiamo considerare l’esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa <span class="math inline">\(100^2\)</span>. Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di <span class="math inline">\(10^{10}\)</span>. È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter_4/01_intro_bayes.html" class="pagination-link" aria-label="Modellazione bayesiana">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Modellazione bayesiana</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter_4/03_conjugate_families_1.html" class="pagination-link" aria-label="Distribuzioni coniugate (1)">
        <span class="nav-page-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/ccaudek/psicometria/blob/main/chapters/chapter_4/02_subj_prop.ipynb" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li></ul></div></div></div></footer></body></html>