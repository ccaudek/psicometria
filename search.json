[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analisi dei dati per psicologi",
    "section": "",
    "text": "Benvenuti\nQuesto sito web √® dedicato al materiale didattico dell‚Äôinsegnamento di Psicometria (A.A. 2024/2025), rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell‚ÄôUniversit√† degli Studi di Firenze.\nIl corso √® strutturato per fornire agli studenti una formazione teorica e pratica approfondita nell‚Äôinferenza statistica, enfatizzando particolarmente le applicazioni pratiche attraverso la programmazione. Attraverso esercitazioni guidate, gli studenti impareranno a manipolare e analizzare dati psicologici utilizzando Python, acquisendo cos√¨ le competenze necessarie per prendere decisioni informate e realizzare interpretazioni precise nei loro progetti di modellazione.\nIl programma copre un ampio spettro di tecniche, partendo dall‚Äôanalisi descrittiva per arrivare fino ai modelli gerarchici avanzati. Si pone un forte accento sull‚Äôinferenza causale, approcciata da una prospettiva bayesiana, includendo l‚Äôuso di Grafi Aciclici Diretti (DAG) per esplorare in modo approfondito le relazioni causali. L‚Äôintento √® di andare oltre i limiti della modellazione lineare tradizionale, mostrando come integrare efficacemente i modelli psicologici avanzati nell‚Äôanalisi statistica.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#informazioni-sullinsegnamento",
    "href": "index.html#informazioni-sullinsegnamento",
    "title": "Analisi dei dati per psicologi",
    "section": "Informazioni sull‚Äôinsegnamento",
    "text": "Informazioni sull‚Äôinsegnamento\nCodice: B000286 - PSICOMETRIA  Modulo: B000286 - PSICOMETRIA (Cognomi L-Z)  Corso di laurea: Scienze e Tecniche Psicologiche  Anno Accademico: 2024-2025  Materiali didattici: √à sufficiente disporre di un laptop/computer funzionante. Tutti i materiali didattici e il software necessario sono forniti gratuitamente a tutti gli studenti, senza richiedere alcun acquisto. Calendario: Il corso si terr√† dal 3 marzo al 31 maggio 2025. Orario delle lezioni: Le lezioni si svolgeranno il luned√¨ e il marted√¨ dalle 8:30 alle 10:30 e il gioved√¨ dalle 11:30 alle 13:30. Luogo: Le lezioni si terranno presso il Plesso didattico La Torretta. Modalit√† di svolgimento della didattica: Le lezioni ed esercitazioni saranno svolte in modalit√† frontale.\n\n\n\n\n\n\nIl presente sito web costituisce l‚Äôunica fonte ufficiale da consultare per ottenere informazioni sul programma dell‚Äôinsegnamento B000286 - PSICOMETRIA (Cognomi L-Z) A.A. 2024-2025 e sulle modalit√† d‚Äôesame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Analisi dei dati per psicologi",
    "section": "Syllabus",
    "text": "Syllabus\nIl Syllabus pu√≤ essere scaricato utilizzando questo link.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "chapters/chapter_1/introduction_chapter_1.html",
    "href": "chapters/chapter_1/introduction_chapter_1.html",
    "title": "1¬† Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa verranno presentati alcuni concetti fondamentali per l‚Äôanalisi dei dati utilizzando Python come linguaggio di programmazione e Jupyter come ambiente di sviluppo. Tuttavia, saranno trattati solo in modo conciso, poich√© esistono numerose risorse online che approfondiscono questo argomento. Per coloro che preferiscono una trattazione pi√π completa, si consiglia il libro A Beginners Guide to Python 3 Programming di John Hunt (disponibile gratuitamente alla comunit√† UniFi). Il tutorial ufficiale della documentazione Python, in italiano, √® fornito qui.\nPrima di procedere con il presente capitolo, √® indispensabile leggere l‚ÄôAppendice A, l‚ÄôAppendice C e l‚ÄôAppendice I.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html",
    "href": "chapters/chapter_1/00_prelims.html",
    "title": "2¬† Preliminari",
    "section": "",
    "text": "2.1 Iniziare ad Usare Python üêç\nIn questo corso, utilizzeremo Python all‚Äôinterno di un ambiente Jupyter Notebook. L‚Äôappendice Appendice A fornisce le istruzioni per installare Jupyter Notebook sul vostro computer.\nIn alternativa, √® possibile scrivere uno script Python in un file con estensione .py, il quale pu√≤ essere eseguito tramite il comando python nome_file.py dalla linea di comando.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#jupyter-notebook",
    "href": "chapters/chapter_1/00_prelims.html#jupyter-notebook",
    "title": "2¬† Preliminari",
    "section": "2.2 Jupyter Notebook",
    "text": "2.2 Jupyter Notebook\nI Jupyter Notebook offrono un ambiente interattivo in cui √® possibile eseguire il codice suddiviso in celle. Sebbene sia possibile eseguire il codice nelle celle in qualsiasi ordine, √® considerata una pratica consigliata eseguirle in sequenza al fine di prevenire errori e garantire una corretta esecuzione del codice.\nI Jupyter Notebook supportano due tipi di celle:\n\nCelle di Testo: Queste celle consentono di scrivere testo formattato utilizzando la sintassi Markdown. Questo permette agli autori di inserire del testo descrittivo, comprese immagini, formule in formato \\(\\LaTeX\\), tabelle e altro ancora. Le celle di testo facilitano la documentazione del processo di analisi dei dati in modo chiaro e comprensibile.\nCelle di Codice: Le celle di codice consentono di scrivere e eseguire codice Python. Il codice pu√≤ essere eseguito facendo clic sul triangolo situato a sinistra di ogni cella. Diverse celle possono contenere istruzioni diverse e possono essere eseguite in sequenza. √à importante notare che una funzione definita in una cella precedente pu√≤ essere utilizzata solo se la cella precedente √® stata eseguita.\n\nQui sotto abbiamo una cella di codice.\n\n# Make plot\n%matplotlib inline\nimport math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntheta = np.arange(0, 4 * math.pi, 0.1)\neight = plt.figure()\naxes = eight.add_axes([0, 0, 1, 1])\naxes.plot(0.5 * np.sin(theta), np.cos(theta / 2))\n\n\n\n\n\n\n\n\nQuando lavori con il notebook, puoi essere all‚Äôinterno di una cella, digitando i suoi contenuti, oppure al di fuori delle celle, muovendoti nel notebook.\nQuando sei all‚Äôinterno di una cella, premi Esc per uscirne. Quando ti muovi al di fuori delle celle, premi Invio per entrare.\n\nFuori da una cella:\n\nUsa i tasti freccia per muoverti.\nPremi Shift+Invio per eseguire il codice nel blocco.\n\nAll‚Äôinterno di una cella:\n\nPremi Tab per suggerire completamenti delle variabili.\n\n\nIl nome \"Jupyter\" deriva dalle tre principali lingue di programmazione supportate: Julia, Python e R. Tuttavia, √® possibile utilizzare i Jupyter Notebook con molte altre lingue di programmazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#esecuzione-locale-o-su-colab",
    "href": "chapters/chapter_1/00_prelims.html#esecuzione-locale-o-su-colab",
    "title": "2¬† Preliminari",
    "section": "2.3 Esecuzione Locale o su Colab",
    "text": "2.3 Esecuzione Locale o su Colab\nI Jupyter Notebook possono essere eseguiti sia in locale, sul vostro computer, che su un server remoto, come Google Colab. Questa flessibilit√† permette agli utenti di accedere ai propri notebook da qualsiasi dispositivo connesso a Internet e di condividere agevolmente il proprio lavoro con altri.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#kernel-nei-jupyter-notebook",
    "href": "chapters/chapter_1/00_prelims.html#kernel-nei-jupyter-notebook",
    "title": "2¬† Preliminari",
    "section": "2.4 Kernel nei Jupyter Notebook",
    "text": "2.4 Kernel nei Jupyter Notebook\nI Jupyter Notebook sono strumenti che agevolano la programmazione in Python grazie a un componente essenziale: il kernel. Quest‚Äôultimo funge da motore di esecuzione per il codice Python presente nelle celle dei notebook. Ogni volta che eseguite una cella, il suo contenuto viene processato dal kernel. La caratteristica pi√π significativa del kernel √® la sua capacit√† di preservare lo stato delle variabili e delle funzioni tra le diverse celle. In pratica, ci√≤ significa che potete definire variabili o funzioni in una cella e poi riutilizzarle in celle successive. Questa interattivit√† facilita l‚Äôesecuzione iterativa del codice e offre un modo dinamico per esplorare i dati.\nDurante l‚Äôinstallazione di Jupyter Notebook, di norma ricevete anche IPython, un kernel ottimizzato per Python.\nSi noti che il kernel Python deve essere installato all‚Äôinterno di un ambiente di sviluppo dedicato noto come ‚Äúambiente virtuale‚Äù (per ulteriori dettagli, si veda {ref}sec-virtual-environment). Questo ambiente svolge un ruolo fondamentale nel separare e isolare le librerie e le dipendenze necessarie per il kernel. Ci√≤ aiuta a evitare conflitti tra diverse configurazioni e garantisce il corretto funzionamento del codice nel contesto desiderato. L‚Äôutilizzo di ambienti specifici risulta particolarmente vantaggioso nei progetti che richiedono versioni particolari di librerie.\nIn questo insegnamento, faremo ampio uso della funzionalit√† conda, inclusa nell‚Äôinstallazione di Anaconda, per la gestione di questi ambienti. conda mette a disposizione funzioni utili per la creazione, la gestione e l‚Äôattivazione di ambienti separati, ciascuno con le sue configurazioni e dipendenze uniche. Questa capacit√† semplifica notevolmente la transizione tra diversi ambienti, garantendo che ogni progetto o kernel disponga delle risorse necessarie per operare in modo efficiente e senza interferenze.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#visual-studio-code",
    "href": "chapters/chapter_1/00_prelims.html#visual-studio-code",
    "title": "2¬† Preliminari",
    "section": "2.5 Visual Studio Code",
    "text": "2.5 Visual Studio Code\nIl modo pi√π semplice di usare un Jupyter Notebook √® all‚Äôinterno di Visual Studio Code. Dopo aver installato Visual Studio Code, √® necessario installare l‚Äôestensione Python per sfruttare le funzionalit√† specifiche per Python, inclusa la capacit√† di lavorare con Jupyter Notebook.\n\nIn Visual Studio Code, si clicca sull‚Äôicona delle estensioni (quadrati che si intersecano) nella barra laterale a sinistra.\nSi cerca ‚ÄúPython‚Äù nella barra di ricerca e si seleziona l‚Äôestensione ufficiale offerta da Microsoft.\nSi clicca su ‚ÄúInstall‚Äù.\n\nUna volta completate le installazioni, siete pronti per creare il vostro primo Jupyter Notebook in VS Code.\n\nSi apre Visual Studio Code.\nSi clicca su File &gt; New File.\nSi preme Ctrl+Shift+P per aprire la Palette dei Comandi.\nSi digita ‚ÄúJupyter‚Äù e si seleziona Jupyter: Create New Blank Notebook.\nSi aprir√† un nuovo notebook dove si pu√≤ iniziare a scrivere il codice Python nelle celle.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html",
    "href": "chapters/chapter_1/01_python_1.html",
    "title": "3¬† Python (1)",
    "section": "",
    "text": "3.1 Scrivere Codice con il Supporto dei LLM\nI Large Language Models (LLM), come GPT-4, stanno rivoluzionando non solo molte applicazioni legate alla creazione di testi in linguaggio naturale, ma stanno anche aprendo nuove e interessanti potenzialit√† nel campo della programmazione e dell‚Äôanalisi dei dati. La programmazione, con le sue regole esplicite e la sintassi strutturata, si adatta particolarmente bene alle capacit√† di riconoscimento dei pattern degli LLM. A differenza dei linguaggi umani, ricchi di significati ambigui ed espressioni idiomatiche, i linguaggi di programmazione sono rigorosi e precisi.\nNel contesto dell‚Äôanalisi dei dati, √® naturale unire le capacit√† degli LLM con la potenza computazionale dei linguaggi statistici come R o di programmazione come Python. Sono gi√† stati pubblicati libri su come integrare le capacit√† degli LLM con l‚Äôanalisi dei dati Matter (2025), e sta emergendo una nuova branca dell‚Äôingegneria dedicata allo sviluppo dei prompt pi√π efficaci per l‚Äôuso con gli LLM. Pertanto, il problema non √® se utilizzare gli LLM a supporto della programmazione, ma come farlo nel modo pi√π efficace.\nUn principio fondamentale √® che, maggiore √® la conoscenza delle regole sintattiche di un linguaggio di programmazione, maggiore sar√† l‚Äôefficacia dell‚Äôuso degli LLM per scopi di analisi dei dati. Quindi, anche se i problemi di programmazione richiesti in questo corso di analisi dei dati sono relativamente semplici rispetto alle capacit√† degli LLM, gli utenti che utilizzeranno gli LLM a supporto delle proprie attivit√† di programmazione trarranno certamente beneficio dalla conoscenza delle regole sintattiche del linguaggio di programmazione utilizzato, che nel nostro caso sar√† principalmente Python (esamineremo anche degli esempi in R).\nGli LLM si basano sul concetto di ‚Äúpredizione del prossimo token‚Äù. Questo significa che sono addestrati per prevedere la parola o il carattere successivo in una sequenza, basandosi su quelli precedenti. Questo principio √® fondamentale per la capacit√† degli LLM di generare codice e per il loro utilizzo nel migliorare i flussi di lavoro di analisi dei dati in Python o R. Oltre a miliardi di parole provenienti da testi comuni (siti web, libri, articoli di riviste), gli LLM di OpenAI, come GPT-4, sono stati addestrati su un vasto corpus di codice open-source e discussioni sul codice presenti su piattaforme come Stack Overflow. Questo consente loro di generare codice sintatticamente e semanticamente corretto in molte situazioni.\nGli LLM possono assistere in diversi compiti di programmazione in Python e R, tra cui l‚Äôidentificazione degli errori negli script, la scrittura di codice a partire da descrizioni in linguaggio naturale, l‚Äôottimizzazione del codice, la generazione di documentazione e la creazione di casi di test.\nAcquisire conoscenze sull‚Äôuso pratico dell‚ÄôAI/LLM nelle attivit√† di programmazione e analisi √® pi√π di una tendenza: √® una necessit√† nel mercato del lavoro attuale. I professionisti che possono utilizzare efficacemente l‚ÄôAI/LLM per migliorare le loro competenze di programmazione e integrare questi strumenti in Python e R avranno un vantaggio competitivo. Man mano che l‚ÄôAI e gli LLM diventano sempre pi√π diffusi nell‚Äôindustria e nel mondo accademico, la domanda per queste competenze continuer√† a crescere.\nL‚Äôobiettivo di questo capitolo √® fornire una panoramica della sintassi di Python e delle principali funzioni di pacchetti come Pandas, Numpy e Matplotlib, utili per la data science. Python √® un linguaggio di programmazione versatile e di facile lettura, adatto a numerosi usi. Anche se il suo nome √® un omaggio al gruppo comico Monty Python, apprendere Python richiede tempo, pratica e impegno.\nQuesta guida si concentra sull‚Äôinsegnamento dei principi di base della programmazione, piuttosto che sui dettagli tecnici. Con questa conoscenza, gli studenti saranno pi√π capaci di risolvere problemi specifici e di cercare autonomamente la sintassi appropriata per il problema da risolvere.\nNel mondo attuale, in cui l‚Äôintelligenza artificiale riveste un ruolo sempre pi√π centrale, √® fondamentale sviluppare la capacit√† di pensare in modo algoritmico. Questa competenza va oltre la mera programmazione e offre un approccio strutturato per risolvere problemi complessi. Sebbene gli LLM siano in grado di risolvere molti dei problemi di programmazione che affronteremo in questo corso, una comprensione approfondita dei principi della programmazione rimane essenziale per interpretare, modificare o migliorare le soluzioni proposte da tali sistemi.\nIn conclusione, anche nell‚Äôera dell‚ÄôIA, una solida comprensione dei fondamenti della programmazione √® indispensabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#espressioni-e-operatori",
    "href": "chapters/chapter_1/01_python_1.html#espressioni-e-operatori",
    "title": "3¬† Python (1)",
    "section": "3.2 Espressioni e Operatori",
    "text": "3.2 Espressioni e Operatori\nI programmi sono insiemi di espressioni che elaborano dati per fornire istruzioni specifiche al computer. Ad esempio, in Python, l‚Äôoperazione di moltiplicazione si esegue utilizzando l‚Äôasterisco (*) tra due numeri. Quando si incontra un‚Äôespressione come 3 * 4, il computer la valuta e produce il risultato, che pu√≤ essere visualizzato in una cella successiva di un notebook Jupyter.\nLe regole sintattiche in un linguaggio di programmazione come Python sono stringenti. Ad esempio, non √® consentito inserire due simboli asterisco in sequenza senza un operando intermedio. Qualora un‚Äôespressione violi queste norme sintattiche, il sistema ritorner√† un ‚ÄúSyntaxError‚Äù, un errore che indica la non conformit√† alle regole del linguaggio. Per esempio\n3 * * 4\nrestituisce:\n Cell In[3], line 1\n    3 * * 4\n        ^\nSyntaxError: invalid syntax\nAnche piccole modifiche in un‚Äôespressione possono cambiarne completamente il significato. Nell‚Äôesempio successivo, lo spazio tra i due asterischi * √® stato rimosso. Tuttavia, poich√© gli asterischi compaiono tra due espressioni numeriche, l‚Äôespressione √® corretta e indica l‚Äôelevamento a potenza del primo numero al secondo: 3 elevato alla quarta potenza (\\(3 \\times 3 \\times 3 \\times 3\\)). In programmazione, simboli come * e ** sono noti come ‚Äúoperatori‚Äù, mentre i valori su cui agiscono sono denominati ‚Äúoperandi‚Äù.\n\n3 ** 4\n\n81\n\n\nLa tabella seguente elenca i principali operatori binari utilizzati in Python, chiamati cos√¨ perch√© agiscono su due operandi.\n\n\n\nOperazione\nOperatore\n\n\n\n\naddizione\n+\n\n\nsottrazione\n-\n\n\nmoltiplicazione\n*\n\n\ndivisione (reale)\n/\n\n\ndivisione (intera; rimuove il resto)\n//\n\n\nresto (modulo)\n%\n\n\nelevamento a potenza\n**\n\n\n\nLe due operazioni che potrebbero essere meno familiari sono % (trova il resto di una divisione) e // (esegui una divisione scartando il resto).\nPer esempio, la divisione intera (scartando il resto) di 11/2 produce 5.\n\n11 // 2\n\n5\n\n\nIl resto di 11/2 √® 1.\n\n11 % 2\n\n1\n\n\nUsando gli operatori che abbiamo elencato in precedenza possiamo usare Python come un calcolatore.\n\nprint(\"4 + 2 √®\", 4 + 2)\nprint(\"4 - 2 √®\", 4 - 2)\nprint(\"4 * 2 √®\", 4 * 2)\nprint(\"4 / 2 √®\", 4 / 2)\nprint(\"4 ** 2 √®\", 4**2)\nprint(\"9 % 4 √®\", 9 % 4)\nprint(\"9 // 4 √®\", 9 // 4)\n\n4 + 2 √® 6\n4 - 2 √® 2\n4 * 2 √® 8\n4 / 2 √® 2.0\n4 ** 2 √® 16\n9 % 4 √® 1\n9 // 4 √® 2\n\n\nL‚Äôapplicazione degli operatori aritmetici in Python dipende dalle seguenti regole di precedenza degli operatori, che sono analoghe a quelle usate in algebra.\n\nLe espressioni tra parentesi vengono valutate per prime.\nSuccessivamente si valutano gli elevamenti a potenza.\nIn seguito, si valutano moltiplicazioni, divisioni e moduli.\nPer ultime vengono valutate somme e sottrazioni.\n\n\n1 + 2 * 3 * 4 * 5 / 6 ** 3 + 7 + 8 - 9 + 10\n\n17.555555555555557\n\n\n\n1 + 2 * (3 * 4 * 5 / 6) ** 3 + 7 + 8 - 9 + 10\n\n2017.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#variabili",
    "href": "chapters/chapter_1/01_python_1.html#variabili",
    "title": "3¬† Python (1)",
    "section": "3.3 Variabili",
    "text": "3.3 Variabili\nQuando generiamo un risultato, la risposta viene visualizzata ma non viene memorizzata da nessuna parte, come abbiamo visto negli esempi precedenti. Se vogliamo recuperare quel risultato, dobbiamo memorizzarlo. Lo mettiamo in un oggetto, e diamo un nome a quell‚Äôoggetto. Questa √® una variabile.\nPer creare una variabile facciamo uso di un‚Äôistruzione di assegnazione. In un‚Äôistruzione di assegnazione, si specifica un nome seguito dal simbolo di uguale (=) e dall‚Äôespressione che si desidera assegnare a tale nome. L‚Äôoperazione di assegnazione consiste nell‚Äôassociare il valore dell‚Äôespressione a destra del simbolo di uguale al nome a sinistra. Da quel momento in poi, ogni volta che il nome viene utilizzato in un‚Äôespressione, il valore associato durante l‚Äôassegnazione viene utilizzato al suo posto.\n\na = 10\nb = 20\na + b\n\n30\n\n\n\na = 1/4\nb = 2 * a\nb\n\n0.5\n\n\n\nmy_var = 100\nconst = 3\n\nmy_var * const\n\n300\n\n\nIn Python, ogni ‚Äúoggetto‚Äù √® un‚Äôarea di memoria nel computer. Una ‚Äúvariabile‚Äù funge da etichetta che fa riferimento a quest‚Äôarea. Se un oggetto non ha pi√π etichette (ovvero, non ci sono pi√π variabili che lo referenziano), i dati contenuti nell‚Äôoggetto diventano inaccessibili. Il Garbage Collector del linguaggio si occuper√† di rilevare questi oggetti non referenziati e liberare la memoria, permettendo che venga riutilizzata per nuovi dati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#nomi-delle-variabili",
    "href": "chapters/chapter_1/01_python_1.html#nomi-delle-variabili",
    "title": "3¬† Python (1)",
    "section": "3.4 Nomi delle Variabili",
    "text": "3.4 Nomi delle Variabili\nI nomi delle variabili in Python possono contenere caratteri alfanumerici da a-z, A-Z, 0-9 e alcuni caratteri speciali come _. I nomi delle variabili normali devono iniziare con una lettera. I nomi delle variabili non possono contenere uno spazio; invece, √® comune utilizzare il carattere _ per sostituire ogni spazio. Sta al programmatore scegliere nomi facili da interpretare.\nPer convenzione, i nomi delle variabili iniziano con una lettera minuscola, mentre i nomi delle classi iniziano con una lettera maiuscola.\nInoltre, ci sono una serie di parole chiave (keyword) in Python che non possono essere utilizzate come nomi di variabili. Queste parole chiave sono:\n\nimport keyword\nprint(*keyword.kwlist, sep=\"\\n\")\n\nFalse\nNone\nTrue\nand\nas\nassert\nasync\nawait\nbreak\nclass\ncontinue\ndef\ndel\nelif\nelse\nexcept\nfinally\nfor\nfrom\nglobal\nif\nimport\nin\nis\nlambda\nnonlocal\nnot\nor\npass\nraise\nreturn\ntry\nwhile\nwith\nyield\n\n\nSi presti attenzione alla parola chiave ‚Äúlambda‚Äù, che potrebbe facilmente essere un nome di variabile naturale in un programma scientifico. Tuttavia, essendo una parola chiave, non pu√≤ essere utilizzata come nome di variabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#tipologie-di-dati-in-python",
    "href": "chapters/chapter_1/01_python_1.html#tipologie-di-dati-in-python",
    "title": "3¬† Python (1)",
    "section": "3.5 Tipologie di Dati in Python",
    "text": "3.5 Tipologie di Dati in Python\nIn Python, le variabili possono appartenere a diverse tipologie di dati, ciascuna con caratteristiche e utilizzi specifici.\n\n3.5.1 Stringhe (String)\nLe stringhe sono sequenze di caratteri, utilizzate per rappresentare testo. In Python, le stringhe possono essere create utilizzando apici singoli (' '), doppi (\" \") o tripli (''' ''' oppure \"\"\" \"\"\") per delimitare il testo. Esempi di stringhe sono:\n\"Hello, world!\"\n'Beyonce-Lemonade.txt'\n\"lemonade\"\nSi noti il risultato ottenuto quando si applica l‚Äôoperatore + a due stringhe.\n\n\"data\" + \"science\"\n\n'datascience'\n\n\n\n\"data\" + \" \" + \"science\"\n\n'data science'\n\n\nSia le virgolette singole che doppie possono essere utilizzate per creare le stringhe: ‚Äúciao‚Äù e ‚Äòciao‚Äô sono espressioni equivalenti. Tuttavia, le virgolette doppie sono spesso preferite poich√© consentono di includere virgolette singole all‚Äôinterno delle stringhe.\n\n\"Che cos'√® una parola?\"\n\n\"Che cos'√® una parola?\"\n\n\nL‚Äôespressione precedente avrebbe prodotto un SyntaxError se fosse stata racchiusa da virgolette singole.\n\n3.5.1.1 Parsing strings\nIn Python, una stringa √® concepita come una sequenza ordinata di caratteri. Grazie all‚Äôoperatore di indicizzazione, rappresentato dalle parentesi quadre [], √® possibile accedere a singoli elementi della stringa.\n√à importante ricordare che l‚Äôindicizzazione in Python parte da zero.\nL‚Äôindice del primo carattere √® [0], quello del secondo √® [1], del terzo [2], e cos√¨ via. Questa funzionalit√† consente di manipolare o consultare specifici segmenti della stringa, piuttosto che gestirla come un blocco unico.\nConsideriamo questo verso di Eugenio Montale:\n\nmy_string = \"Tendono alla chiarit√† le cose oscure\"\nprint(my_string)\n\nTendono alla chiarit√† le cose oscure\n\n\n\nmy_string[0]\n\n'T'\n\n\n\nmy_string[3]\n\n'd'\n\n\n\nlen(my_string)\n\n36\n\n\nLa stringa ‚Äúmy_string‚Äù conta 36 caratteri. Pertanto, gli indici validi per questa stringa vanno da 0 a 35. Per accedere all‚Äôultimo carattere, √® necessario utilizzare l‚Äôindice 35, che corrisponde a 36 meno 1.\n\nmy_string[35]\n\n'e'\n\n\nUn modo efficiente per ottenere l‚Äôultimo carattere √® ricorrere alla funzione len, sottraendo 1 al risultato:\n\nmy_string[len(my_string) - 1]\n\n'e'\n\n\nSi noti che len() √® una funzione. Una funzione √® un blocco di codice che esegue un‚Äôoperazione specifica. I programmatori chiamano anche gli input delle funzioni ‚Äúparametri‚Äù o ‚Äúargomenti‚Äù.\nLa funzione len prende un input e restituisce un output. L‚Äôoutput √® la lunghezza di ci√≤ che √® stato passato come input.\n\n\n3.5.1.2 Slicing strings\nOltre a estrarre caratteri individuali da una stringa, Python offre la possibilit√† di selezionare segmenti di testo attraverso la tecnica dello ‚Äúslicing‚Äù. Questo meccanismo √® simile all‚Äôindicizzazione, ma utilizza due indici separati da un carattere a due punti (:). Il primo indice indica la posizione di partenza dello ‚Äúslicing‚Äù nella stringa, mentre il secondo indice segnala il punto in cui terminare l‚Äôestrazione del segmento.\n\nmy_string[2:4]\n\n'nd'\n\n\nSe si omette il primo indice, Python utilizzer√† l‚Äôinizio della stringa; se si omette il secondo, utilizzer√† la fine della stringa.\n\nmy_string[:4]\n\n'Tend'\n\n\n\nmy_string[4:]\n\n'ono alla chiarit√† le cose oscure'\n\n\n\n\n3.5.1.3 Metodi\nA partire da una stringa esistente, si possono generare nuove stringhe mediante l‚Äôutilizzo di metodi specifici per le stringhe. Questi metodi sono essenzialmente funzioni che agiscono direttamente sull‚Äôoggetto stringa. Per invocare un metodo, basta posizionare un punto subito dopo la stringa e seguire con il nome del metodo desiderato. Ad esempio, il metodo successivo converte tutti i caratteri della stringa in maiuscole.\n\nmy_string.upper()\n\n'TENDONO ALLA CHIARIT√Ä LE COSE OSCURE'\n\n\nIl metodo my_string.title() √® utilizzato per convertire la prima lettera di ogni parola nella stringa my_string in maiuscolo, mentre rende tutte le altre lettere minuscole. In pratica, trasforma la stringa in una forma ‚Äúa titolo‚Äù, in cui ogni parola inizia con una lettera maiuscola.\n\nmy_string.title()\n\n'Tendono Alla Chiarit√† Le Cose Oscure'\n\n\n\n\n\n3.5.2 Numeri Interi (Integer)\nI numeri interi rappresentano numeri senza una componente decimale. In Python, possono essere creati assegnando un valore senza parte decimale a una variabile. Esempio di un numero intero √®:\n\nage = 20\n\n\n\n3.5.3 Numeri in Virgola Mobile (Float)\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, rappresentano numeri che hanno una componente decimale. Sono creati assegnando un valore con una parte decimale a una variabile. Esempio di un numero float √®:\n\ntemperature = 36.4\n\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, hanno una precisione limitata a circa 15-16 cifre decimali; oltre questo limite, la precisione viene persa. Nonostante questa limitazione, sono sufficienti per la maggior parte delle applicazioni.\nInoltre, √® possibile utilizzare la notazione scientifica per rappresentare numeri molto grandi o molto piccoli. In questa notazione, m * 10^n viene comunemente abbreviato come mEn, dove ‚ÄúE‚Äù rappresenta l‚Äôesponente dieci. Ad esempio, 1E9 equivale a un miliardo (\\(1 \\times 10^9\\)) e 1E-9 rappresenta un miliardesimo (\\(1 \\times 10^{-9}\\)).\n\n\n3.5.4 Valori Booleani (Boolean)\nI valori booleani possono assumere solo due stati: vero (True) o falso (False). Sono utilizzati per rappresentare le condizioni logiche e sono ottenuti attraverso espressioni di confronto. Esempio di un valore booleano √®:\n\nis_raining = False\n\nNel contesto delle operazioni aritmetiche, True √® equivalente al numero intero 1, mentre False corrisponde a 0. Questo permette di includere valori booleani in calcoli matematici. Per esempio:\n\nTrue + True + False\n\n2\n\n\nUn valore booleano viene ritornato quando si valuta un confronto. Per esempio:\n\n3 &gt; 1 + 1\n\nIl valore True indica che il confronto √® valido; Python ha confermato questo semplice fatto sulla relazione tra 3 e 1+1.\nSi noti la regola di precedenza: gli operatori &gt;, &lt;, &gt;=, &lt;=, ==, != hanno la precedenza pi√π bassa (vengono valutati per ultimi), il che significa che nell‚Äôespressione precedente viene prima valutato (1 + 1) e poi (3 &gt; 2).\n\n\n3.5.5 Operatori di confronto\nUn operatore di confronto √® un operatore che esegue un qualche tipo di confronto e restituisce un valore booleano (True oppure False). Per esempio, l‚Äôoperatore == confronta le espressioni su entrambi i lati e restituisce True se hanno gli stessi valori e False altrimenti. L‚Äôopposto di == √® !=, che si pu√≤ leggere come ‚Äònon uguale al valore di‚Äô. Gli operatori di confronto sono elencati qui sotto:\n\n\n\nConfronto\nOperatore\n\n\n\n\nMinore\n&lt;\n\n\nMaggiore\n&gt;\n\n\nMinore o uguale\n&lt;=\n\n\nMaggiore o uguale\n&gt;=\n\n\nUguale\n==\n\n\nNon uguale\n!=\n\n\n\nAd esempio:\n\na = 4\nb = 2\n\nprint(\"a &gt; b\", \"is\", a &gt; b)\nprint(\"a &lt; b\", \"is\", a &lt; b)\nprint(\"a == b\", \"is\", a == b)\nprint(\"a &gt;= b\", \"is\", a &gt;= b)\nprint(\"a &lt;= b\", \"is\", a &lt;= b)\n\nNella cella seguente si presti attenzione all‚Äôuso di = e di ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nL‚Äôoperatore = √® un‚Äôistruzione di assegnazione. Ovvero, crea un nuovo oggetto. L‚Äôoperatore == valuta invece una condizione logica e ritorna un valore booleano.\nUn‚Äôespressione pu√≤ contenere pi√π confronti e tutti devono essere veri affinch√© l‚Äôintera espressione sia vera. Ad esempio:\n\n1 &lt; 1 + 1 &lt; 3\n\n\n\n3.5.6 Tipizzazione Dinamica in Python\nPython √® un linguaggio con tipizzazione dinamica, il che significa che il tipo di una variabile √® determinato dal valore che le viene assegnato durante l‚Äôesecuzione del programma e non necessita di essere dichiarato esplicitamente.\nPer identificare il tipo di una variabile o del risultato di un‚Äôespressione, Python mette a disposizione la funzione type(). Questa funzione, quando chiamata con una variabile o un‚Äôespressione come argomento, restituisce il tipo di dati corrispondente.\nNell‚Äôesempio seguente il programma stamper√† &lt;class 'str'&gt;, indicando che x √® una variabile di tipo ‚Äústringa‚Äù.\n\nx = \"hello\"\nprint(type(x))\n\n&lt;class 'str'&gt;\n\n\nApplichiamo la funzione type() alle altre variabili che abbiamo definito in precedenza.\n\nage = 20\nprint(type(age))\n\n&lt;class 'int'&gt;\n\n\n\ntemperature = 36.4\nprint(type(temperature))\n\n&lt;class 'float'&gt;\n\n\n\nis_raining = False\nprint(type(is_raining))\n\n&lt;class 'bool'&gt;\n\n\n\n\n3.5.7 Operatori Booleani\nGli operatori booleani (o operatori logici) confrontano espressioni (non valori) e ritornano un valore booleano. Python ha tre operatori logici:\n\nand ‚Äì Ritorna True solo se entrambi le espressioni sono vere, altrimenti ritorna False\nor ‚Äì Ritorna True se almeno una delle due espressioni √® vera, altrimenti ritorna False.\nnot ‚Äì Ritorna True se l‚Äôespressione √® falsa, altrimenti ritorna False.\n\nAd esempio:\n\na = 2\nb = 3\n\n(a + b &gt; a) and (a + b &gt; b)\n\nTrue\n\n\nNella cella sopra le parentesi tonde sono opzionali ma facilitano la lettura.\nL‚Äôoperatore and restituisce True solo se entrambe le condizioni booleane sono vere. Ad esempio, True and False restituir√† False perch√© una delle condizioni √® falsa:\n\nTrue and False\n\nFalse\n\n\nL‚Äôoperatore or restituisce True se almeno una delle due condizioni booleane √® vera. Ad esempio, True or False restituir√† True perch√© almeno una delle condizioni √® vera.\n\nTrue or False\n\nTrue\n\n\nL‚Äôoperatore not viene utilizzato per invertire il valore di verit√† di una condizione booleana. Ad esempio, not True restituir√† False e not False restituir√† True.\n\nnot True\n\nFalse\n\n\nAlcuni esempi sono i seguenti (si noti l‚Äôuso della funzione len()):\n\nprint(3 &gt; 2)  # True, because 3 is greater than 2\nprint(3 &gt;= 2)  # True, because 3 is greater than 2\nprint(3 &lt; 2)  # False,  because 3 is greater than 2\nprint(2 &lt; 3)  # True, because 2 is less than 3\nprint(2 &lt;= 3)  # True, because 2 is less than 3\nprint(3 == 2)  # False, because 3 is not equal to 2\nprint(3 != 2)  # True, because 3 is not equal to 2\nprint(len(\"mango\") == len(\"avocado\"))  # False\nprint(len(\"mango\") != len(\"avocado\"))  # True\nprint(len(\"mango\") &lt; len(\"avocado\"))  # True\nprint(len(\"milk\") != len(\"meat\"))  # False\nprint(len(\"milk\") == len(\"meat\"))  # True\nprint(len(\"tomato\") == len(\"potato\"))  # True\nprint(len(\"python\") &gt; len(\"dragon\"))  # False\n\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\nAltri esempi di come questi operatori possono essere utilizzati sono i seguenti:\n\nprint(3 &gt; 2 and 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 and 4 &lt; 3)  # False - because the second statement is false\nprint(3 &lt; 2 and 4 &lt; 3)  # False - because both statements are false\nprint(\"True and True: \", True and True)\nprint(3 &gt; 2 or 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 or 4 &lt; 3)  # True - because one of the statements is true\nprint(3 &lt; 2 or 4 &lt; 3)  # False - because both statements are false\nprint(\"True or False:\", True or False)\nprint(not 3 &gt; 2)  # False - because 3 &gt; 2 is true, then not True gives False\nprint(not True)  # False - Negation, the not operator turns true to false\nprint(not False)  # True\nprint(not not True)  # True\nprint(not not False)  # False\n\nTrue\nFalse\nFalse\nTrue and True:  True\nTrue\nTrue\nFalse\nTrue or False: True\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\nAbbiamo tralasciato alcuni operatori in Python. Due di quelli che abbiamo omesso sono gli operatori di appartenenza, in e not in. Gli altri operatori che abbiamo tralasciato sono gli operatori bitwise e gli operatori sugli insiemi, che verranno trattati in seguito.\n\n\n3.5.8 Valori Numerici di True e False\n√à fondamentale comprendere i valori numerici associati alle parole chiave True e False. Queste due parole chiave hanno i valori numerici di 1 e 0, rispettivamente.\n\nTrue == 1\n\nTrue\n\n\n\nFalse == 0\n\nTrue\n\n\n\nTrue + False\n\n1\n\n\n\ntype(True + False)\n\nint",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#sequenze",
    "href": "chapters/chapter_1/01_python_1.html#sequenze",
    "title": "3¬† Python (1)",
    "section": "3.6 Sequenze",
    "text": "3.6 Sequenze\nOltre ai numeri e ai valori booleani, Python supporta anche un insieme di ‚Äúcontenitori‚Äù, ovvero i seguenti tipi strutturati:\n\nle liste,\nle tuple,\ngli insiemi,\ni dizionari.\n\n\n3.6.1 Le tuple\nUna tupla √® una collezione di diversi tipi di dati che √® ordinata e immutabile (non modificabile). Le tuple sono scritte tra parentesi tonde, (). Una volta creata una tupla, non √® possibile modificarne i contenuti.\n\ncolors = (\"Rosso\", \"Nero\", \"Bianco\")\ncolors\n\n('Rosso', 'Nero', 'Bianco')\n\n\n\ntype(colors)\n\ntuple\n\n\nLe stringhe sono tuple di caratteri. Pertanto non sono modificabili.\n\n\n3.6.2 Le liste\nGli oggetti di tipo lista sono simili alle tuple, ma con alcune differenze. La lista √® un oggetto mutabile, il che significa che possiamo aggiungere o rimuovere elementi dalla lista anche dopo la sua creazione. Una lista viene creata separando i suoi elementi tramite virgola e racchiudendo il tutto tra parentesi quadre.\nSi noti che una lista √® una struttura dati eterogenea contentente una sequenza di elementi che possono essere di tipo diverso.\n\nmy_list = [\"Pippo\", 3, -2.953, [1, 2, 3]]\nmy_list\n\n['Pippo', 3, -2.953, [1, 2, 3]]\n\n\n\ntype(my_list)\n\nlist\n\n\nLa lista my_list √® composta da diversi elementi: una stringa (‚ÄúPippo‚Äù), un numero intero (3), un numero decimale (-2.953) e un‚Äôaltra lista ([1, 2, 3]).\nGli elementi nella lista sono ordinati in base all‚Äôindice, il quale rappresenta la loro posizione all‚Äôinterno della lista. Gli indici delle liste partono da 0 e aumentano di uno. Per accedere a un elemento della lista tramite il suo indice, si utilizza la notazione delle parentesi quadre: nome_lista[indice]. Ad esempio:\n\nmy_list[1]\n\n3\n\n\n\nmy_list[0]\n\n'Pippo'\n\n\nPython prevede alcune funzioni che elaborano liste, come per esempio len che restituisce il numero di elementi contenuti in una lista:\n\nlen(my_list)\n\n4\n\n\nBench√© questa lista contenga come elemento un‚Äôaltra lista, tale lista nidificata conta comunque come un singolo elemento. La lunghezza di di my_list √® quattro.\nUna lista vuota si crea nel modo seguente:\n\nempty_list = []\nlen(empty_list)\n\n0\n\n\nEcco alcuni esempi.\n\nfruits = [\"banana\", \"orange\", \"mango\", \"lemon\"]  # list of fruits\nvegetables = [\"Tomato\", \"Potato\", \"Cabbage\", \"Onion\", \"Carrot\"]  # list of vegetables\n\nprint(\"Fruits:\", fruits)\nprint(\"Number of fruits:\", len(fruits))\nprint(\"Vegetables:\", vegetables)\nprint(\"Number of vegetables:\", len(vegetables))\n\nFruits: ['banana', 'orange', 'mango', 'lemon']\nNumber of fruits: 4\nVegetables: ['Tomato', 'Potato', 'Cabbage', 'Onion', 'Carrot']\nNumber of vegetables: 5\n\n\nSupponiamo di voler ordinare in ordine alfabetico i nomi presenti nella lista. Per fare ci√≤, √® necessario utilizzare il metodo sort sulla lista utilizzando la notazione con il punto (dot notation):\n\nnames = [\"Carlo\", \"Giovanni\", \"Giacomo\"]\nnames.sort()\n\nTale metodo per√≤ non restituisce alcun valore, in quanto l‚Äôordinamento √® eseguito in place: dopo l‚Äôinvocazione, gli elementi della lista saranno stati riposizionati nell‚Äôordine richiesto. Visualizziamo la listra trasformata:\n\nnames\n\n['Carlo', 'Giacomo', 'Giovanni']\n\n\nL‚Äôinvocazione di metodi (e di funzioni) prevede anche la possibilit√† di specificare degli argomenti opzionali. Per esempio:\n\nnames.sort(reverse=True)\nnames\n\n['Giovanni', 'Giacomo', 'Carlo']\n\n\nIl metodo remove() pu√≤ essere usato per rimuovere elementi da una lista.\n\nprint(fruits)\nfruits.remove(\"banana\")\nprint(fruits)\n\n['banana', 'orange', 'mango', 'lemon']\n['orange', 'mango', 'lemon']\n\n\nIl metodo insert() pu√≤ essere usato per aggiungere elementi ad una lista.\n\nprint(fruits)\nfruits.insert(2, \"watermelon\")\nprint(fruits)\n\n['orange', 'mango', 'lemon']\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n√à possibile copiare una lista in una nuova variabile:\n\nprint(fruits)\nnew_fruits = fruits.copy()\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\nprint(new_fruits)\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\n\n3.6.3 Operazioni su liste\nL‚Äôoperatore + concatena liste:\n\na = [1, 2, 3]\nb = [4, 5, 6]\nc = a + b\nprint(c)\n\n[1, 2, 3, 4, 5, 6]\n\n\nIn maniera simile, l‚Äôoperatore * ripete una lista un certo numero di volte:\n\n[0] * 4\n\n[0, 0, 0, 0]\n\n\n\n[1, 2, 3] * 3\n\n[1, 2, 3, 1, 2, 3, 1, 2, 3]\n\n\nL‚Äôaspetto importante da considerare √® che, essendo una sequenza di elementi eterogenei, √® difficile eseguire operazioni algebriche sulle liste in Python puro. Ad esempio, consideriamo la seguente lista:\n\nx = [1, 2, 3]\nx\n\n[1, 2, 3]\n\n\nSe desideriamo calcolare una semplice operazione, come la media di x, √® necessario seguire una procedura abbastanza articolata. Ad esempio:\n\ntotal = 0\ncounter = 0\n\nfor num in x:\n    counter += 1\n    total += num\n\navg = total / counter\n\nprint(avg)\n\n2.0\n\n\nIndubbiamente, sarebbe preferibile ottenere questo risultato con un approccio pi√π semplice. In seguito, vedremo che se utilizziamo una sequenza di elementi omogenei, il problema pu√≤ essere risolto in modo molto pi√π agevole. Ad esempio,\n\nimport numpy as np\n\nx = np.array([1, 2, 3])\nnp.mean(x)\n\n2.0\n\n\nPossiamo contare il numero degli elementi specificati che sono contenuti in una lista usando count().\n\nages = [22, 19, 24, 25, 26, 24, 25, 24]\nprint(ages.count(24))         \n\n3\n\n\nPossiamo trovare l‚Äôindice di un elemento in una lista con index().\n\nages.index(24)  # index of the first occurrence\n\n2\n\n\n\n\n3.6.4 Operatore slice\nL‚Äôoperatore di slice (:) applicato alle liste in Python consente di estrarre una porzione specifica di elementi dalla lista. L‚Äôoperatore di slice ha la seguente sintassi: lista[inizio:fine:passo].\n\ninizio rappresenta l‚Äôindice di partenza dell‚Äôintervallo (inclusivo).\nfine rappresenta l‚Äôindice di fine dell‚Äôintervallo (esclusivo).\npasso rappresenta il passo o l‚Äôincremento tra gli indici degli elementi selezionati (facoltativo).\n\nEcco alcuni esempi per illustrare l‚Äôutilizzo dell‚Äôoperatore di slice:\n\nlista = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# Estrarre una porzione della lista\nporzione = lista[2:6]  # [3, 4, 5, 6]\n\n# Estrarre una porzione con un passo specifico\nporzione_passo = lista[1:9:2]  # [2, 4, 6, 8]\n\n# Estrarre una porzione dalla fine della lista\nporzione_fine = lista[6:]  # [7, 8, 9, 10]\n\n# Estrarre una porzione dall'inizio della lista\nporzione_inizio = lista[:5]  # [1, 2, 3, 4, 5]\n\n\n\n3.6.5 Gli insiemi\nGli insiemi sono collezioni finite di elementi distinti e non memorizzati in un ordine specifico. Un insieme non pu√≤ contenere pi√π di un‚Äôistanza dello stesso elemento. Per creare un insieme si utilizzano le parentesi graffe {}. Ad esempio:\n\nmy_set = {\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"}\nmy_set\n\n{'A', 'B', 'C', 'D', 'E', 'F'}\n\n\n\ntype(my_set)\n\nset\n\n\nGli oggetti di tipo ‚Äúset‚Äù sono utili per eseguire operazioni matematiche sugli insiemi.\nPer verificare se un elemento esiste in un insieme usiamo l‚Äôoperatore in.\n\nprint(\"Does set my_set contain D? \", \"D\" in my_set)\n\nDoes set my_set contain D?  True\n\n\nL‚Äôunione di due insieme si ottiene con union().\n\nfruits = {\"banana\", \"orange\", \"mango\", \"lemon\"}\nvegetables = {\"tomato\", \"potato\", \"cabbage\", \"onion\", \"carrot\"}\nprint(fruits.union(vegetables))\n\n{'carrot', 'onion', 'lemon', 'mango', 'tomato', 'potato', 'banana', 'cabbage', 'orange'}\n\n\nL‚Äôintersezione di due insieme si trova con intersection().\n\npython = {\"p\", \"y\", \"t\", \"h\", \"o\", \"n\"}\ndragon = {\"d\", \"r\", \"a\", \"g\", \"o\", \"n\"}\npython.intersection(dragon)\n\n{'n', 'o'}\n\n\nUn insieme pu√≤ essere un sottoinsieme o un sovrainsieme di altri insiemi.\nPer verificare se un insieme √® un sottoinsieme di un altro, si utilizza il metodo issubset(). Per verificare se un insieme √® un sovrainsieme di un altro, si utilizza il metodo issuperset().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.issubset(st1)\n\nTrue\n\n\n\nst1.issuperset(st2) \n\nTrue\n\n\nLa differenza tra due insiemi si ottiene con difference().\n\nwhole_numbers = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\neven_numbers = {0, 2, 4, 6, 8, 10}\nwhole_numbers.difference(even_numbers)\n\n{1, 3, 5, 7, 9}\n\n\nPossiamo verificare se due insiemi sono disgiunti, ovvero non hanno elementi in comune, utilizzando il metodo isdisjoint().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.isdisjoint(st1)\n\nFalse\n\n\n\n\n3.6.6 I dizionari\nGli oggetti di tipo ‚Äúdizionario‚Äù vengono utilizzati per creare coppie chiave-valore, dove ogni chiave √® unica. Un dizionario viene creato specificando ogni coppia come chiave : valore, separando le diverse coppie con una virgola e racchiudendo il tutto tra parentesi graffe. Ad esempio:\n\nmusic = {\n    \"blues\": \"Betty Smith\",\n    \"classical\": \"Gustav Mahler\",\n    \"pop\": \"David Bowie\",\n    \"jazz\": \"John Coltrane\",\n}\n\nL‚Äôaccesso agli elementi di un dizionario viene fatto specificando all‚Äôinterno di parentesi quadre la chiave per ottenere o modificare il valore corrispondente:\n\nmusic[\"pop\"]\n\n'David Bowie'\n\n\nPer trovare il numero di coppie key: value nel dizionario usiamo len().\n\nprint(len(music))\n\n4\n\n\n\nmusic[\"new music\"] = \"Missy Mazzoli\"\nprint(music)\n\n{'blues': 'Betty Smith', 'classical': 'Gustav Mahler', 'pop': 'David Bowie', 'jazz': 'John Coltrane', 'new music': 'Missy Mazzoli'}\n\n\n\n\n3.6.7 Contenitori vuoti\nA volte √® utile creare dei contenitori vuoti. I comandi per creare liste vuote, tuple vuote, dizionari vuoti e insiemi vuoti sono rispettivamente lst = [], tup=(), dic={} e st = set().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "3¬† Python (1)",
    "section": "3.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "3.7 Informazioni sull‚ÄôAmbiente di Sviluppo\nAlla fine di ogni capitolo e, in effetti, alla fine (o all‚Äôinizio) di qualsiasi notebook che creiamo, √® utile includere informazioni sull‚Äôambiente di calcolo, compresi i numeri di versione di tutti i pacchetti che utilizziamo. Il pacchetto watermark pu√≤ essere usato per questo scopo. Il pacchetto watermark contiene comandi speciali ed √® un‚Äôestensione di IPython. In generale, per utilizzare tali comandi speciali, li precediamo con il segno % o %% in una cella. Utilizziamo la funzione speciale built-in %load_ext per caricare watermark, e quindi utilizziamo %watermark per invocarlo.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 24 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\nEcco una spiegazione dettagliata delle opzioni che sono state utilizzate nell‚Äôistruzione precedente.\n\n-n o --datename: Aggiunge la data e l‚Äôora correnti al watermark. Questo pu√≤ essere utile per mantenere una cronologia delle modifiche o delle esecuzioni del notebook.\n-u o --updated: Mostra l‚Äôultima volta in cui il notebook √® stato salvato. √à utile per tenere traccia delle modifiche recenti apportate al notebook.\n-v o --python: Mostra la versione di Python utilizzata nel kernel del notebook. Questo √® importante per garantire la compatibilit√† del codice e replicare gli ambienti di lavoro.\n-iv o --iversions: Visualizza le versioni delle librerie importate nel notebook. √à fondamentale per la replicabilit√† degli esperimenti e degli analisi, dato che diverse versioni delle librerie possono comportare risultati diversi.\n-w o --watermark: Aggiunge il watermark stesso, che √® semplicemente il logo ‚Äúwatermark‚Äù. √à pi√π una questione estetica che funzionale.\n-m o --machine: Fornisce informazioni sulla macchina su cui viene eseguito il Jupyter Notebook, come il tipo di sistema operativo e l‚Äôarchitettura della macchina (ad esempio, x86_64). Questo pu√≤ essere utile per documentare l‚Äôambiente hardware in cui vengono eseguiti gli esperimenti.\n\nQueste opzioni forniscono un modo semplice e immediato per documentare e tracciare importanti metadati nei notebook Jupyter.\n\n\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and R. 1st Edition. New York, NY: Manning Publications.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html",
    "href": "chapters/chapter_1/02_python_2.html",
    "title": "4¬† Python (2)",
    "section": "",
    "text": "4.1 Funzioni\nLo scopo delle funzioni √® raggruppare il codice in un formato organizzato, leggibile e riutilizzabile, contribuendo cos√¨ a ridurre la ridondanza del codice.\nUna regola generale per le funzioni √® che dovrebbero essere di piccole dimensioni e svolgere un‚Äôunica operazione.\nNella programmazione, una funzione accetta un input, esegue operazioni su di esso e pu√≤ restituire un output. Python mette a disposizione un‚Äôampia gamma di funzioni integrate, e si pu√≤ anche importare funzioni da pacchetti aggiuntivi o definirne di nuove.\nPer definire una nuova funzione in Python, si utilizza la parola chiave def, seguita dal nome della funzione e dai nomi simbolici dei suoi argomenti, separati da virgole e racchiusi tra parentesi. La definizione continua con i due punti (:) e il corpo della funzione, le cui istruzioni devono essere indentate. Il valore restituito dalla funzione viene specificato tramite la parola chiave return, generalmente nella riga finale del corpo della funzione.\ndef add_numbers(a, b):\n    \"\"\"\n    returns the sum of the two numeric arguments\n    \"\"\"\n    the_sum = a + b\n    return the_sum\nUna volta definita una funzione, √® possibile eseguirla chiamandola e passando gli argomenti appropriati. Ad esempio, possiamo chiamare la funzione add_numbers per sommare due numeri, come ad esempio 20 e 10:\nadd_numbers(20, 10)\n\n30\nConsideriamo la funzione roll_die():\nimport random\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return random.choice([1, 2, 3, 4, 5, 6])\nIl corpo della funzione √® composto da una singola riga di codice che utilizza la funzione choice() della libreria random, a cui viene passata una lista. Questo significa che una funzione pu√≤ utilizzare altre funzioni che sono gi√† state definite. In questo caso, la funzione si limita a specificare l‚Äôargomento da passare a choice(). La funzione choice() restituir√† un numero casuale tra quelli specificati in input. Pertanto, la funzione roll_die() simula il lancio di un dado:\nroll_die()\n\n6\nroll_die()\n\n5\nSi noti inoltre la docstring, cio√® una stringa (in genere racchiusa tra ‚Äú‚Äú‚Äú‚Ä¶‚Äù‚Äú‚Äú) che si trova come prima istruzione all‚Äôinterno di una funzione. La docstring contiene informazioni sullo scopo e sulle modalit√† d‚Äôuso della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#funzioni",
    "href": "chapters/chapter_1/02_python_2.html#funzioni",
    "title": "4¬† Python (2)",
    "section": "",
    "text": "4.1.1 Introspection\nUsando un punto interrogativo (?) prima o dopo una variabile √® possibile visualizzare alcune informazioni generale su quell‚Äôoggetto. Nel caso di una funzione viene stampata la doc string.\n\nroll_die?\n\nSignature: roll_die()\nDocstring: returns a random int between 1 and 6\nFile:      /var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_13125/63164766.py\nType:      function\n\n\n\n\n4.1.2 Metodi\nLe funzioni definite all‚Äôinterno di una classe, chiamate ‚Äúmetodi‚Äù, rappresentano operazioni specifiche che possono essere eseguite sugli oggetti di quella classe. Una classe √® una struttura concettuale che rappresenta un concetto o un oggetto nel contesto del problema che stiamo affrontando. Ad esempio, nel capitolo sull‚Äôintroduzione a Pandas, lavorando con dati organizzati in una tabella, utilizziamo un oggetto chiamato DataFrame, appartenente alla classe ‚Äúpandas.DataFrame‚Äù. Un DataFrame √® una struttura tabellare che contiene dati disposti in righe e colonne.\nI metodi specifici della classe DataFrame offrono funzionalit√† per manipolare e analizzare i dati in questa struttura. Per esempio, il metodo ‚Äúhist()‚Äù genera istogrammi dei valori presenti in una colonna specifica del DataFrame. Per invocare un metodo su un oggetto DataFrame, come ‚Äúdf‚Äù, utilizziamo la sintassi ‚Äúnome_oggetto.nome_metodo()‚Äù e possiamo passare eventuali parametri richiesti tra parentesi.\nD‚Äôaltra parte, gli attributi rappresentano le caratteristiche o le propriet√† degli oggetti di una classe. Gli attributi possono essere richiamati utilizzando la sintassi ‚Äúnome_oggetto.nome_attributo‚Äù e restituiscono un valore specifico associato a quell‚Äôoggetto. Per esempio, l‚Äôattributo ‚Äú.shape‚Äù applicato a un DataFrame come ‚Äúdf.shape‚Äù restituisce il numero di righe e colonne presenti nel DataFrame.\nIn sintesi, una classe definisce un tipo di oggetto che ha attributi che ne descrivono le caratteristiche e metodi che rappresentano le azioni eseguibili su di esso. Gli attributi forniscono informazioni specifiche sull‚Äôoggetto, mentre i metodi consentono di effettuare operazioni e manipolazioni sui dati contenuti nell‚Äôoggetto stesso.\n\n\n4.1.3 La funzione lambda\nPython offre una sintassi alternativa che consente di definire funzioni ‚Äúinline‚Äù, cio√® in una singola linea di codice. Queste funzioni, chiamate funzioni anonime, non richiedono una definizione esplicita poich√© vengono utilizzate solo nel punto in cui sono dichiarate. Per creare una funzione anonima, utilizziamo la parola chiave lambda, seguita da un elenco di argomenti separati da virgole, due punti ‚Äú:‚Äù e l‚Äôespressione che definisce il comportamento della funzione basandosi sugli argomenti forniti.\nlambda argomento1, argomento2, ... : espressione\nQuesta sintassi permette di creare funzioni semplici ed espressive in modo conciso.\nNell‚Äôesempio seguente, la funzione somma 1 al valore passato come input:\n\n(lambda x : x + 1)(2)\n\n3\n\n\nQuando eseguiamo (lambda x : x + 1)(2), avviene quanto segue:\n\nL‚Äôinterprete Python definisce la funzione lambda lambda x : x + 1.\nLa funzione lambda viene immediatamente chiamata con l‚Äôargomento 2.\nAll‚Äôinterno della funzione lambda, x viene sostituito da 2, quindi l‚Äôespressione x + 1 diventa 2 + 1.\nLa funzione lambda restituisce 3.\n\nQuindi, il risultato dell‚Äôespressione (lambda x : x + 1)(2) √® 3.\nIn sintesi, la funzione lambda (lambda x : x + 1) definisce una funzione che aggiunge 1 al suo argomento. Quando la chiamiamo con l‚Äôargomento 2, otteniamo 3 come risultato.\nIn questo secondo esempio sommiamo i due numeri in entrata:\n\n(lambda x, y: x + y)(2, 3)\n\n5\n\n\nLa sintassi seguente √® valida in quanto, per l‚Äôinterprete, il carattere _ corrisponde all‚Äôultima funzione che √® stata valutata:\n\nlambda x, y: x + y\n\n&lt;function __main__.&lt;lambda&gt;(x, y)&gt;\n\n\n\n_(20, 10)\n\n30\n\n\nSi noti che abbiamo valutato la funzione lambda x, y: x + y in una cella precedente a quella che contiene _(20, 10); inserendo le due espressioni in una singola cella si ottiene un SyntaxError.\n\n\n4.1.4 Le funzioni map() e filter()\nPer gli esercizi che svolgeremo in seguito, risultano utili le funzioni map() e filter().\nLa funzione map() prende come input una funzione e una lista, e restituisce il risultato dell‚Äôapplicazione della funzione a ciascun elemento della lista (√® anche possibile usare qualsiasi oggetto iterabile al posto della lista). La lista stessa rimane invariata. Ad esempio, la seguente linea di codice eleva al quadrato ciascuno degli elementi della lista a e salva il risultato nella lista b:\n\na = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nb = list(map(lambda x: x * x, a))\nb\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n\n\nUn‚Äôaltra funzione molto utile per manipolare gli oggetti iterabili √® la funzione filter(). Questa funzione filtra un oggetto iterabile selezionando solo gli elementi che rispondono ad un determinato predicato. (Il predicato √® una funzione che restituisce un booleano). Per esempio\n\nc = list(filter(lambda x: x &gt; 50, b))\nc\n\n[64, 81, 100]\n\n\nSia map() che filter() restituiscono risultati che non sono ancora stati calcolati.\n\nfilter(lambda x: x &gt; 50, b)\n\n&lt;filter at 0x171da9720&gt;\n\n\nPossiamo visualizzare il risultato convertendolo in una lista:\n\nlist(filter(lambda x: x &gt; 50, b))\n\n[64, 81, 100]\n\n\n\n\n4.1.5 La funzione zip()\nLa funzione zip() crea una lista di tuple dagli elementi di due contenitori. Come nel caso delle operazioni precedenti, gli elementi vengono calcolati solo quando viene richiesto. Per esempio:\n\na = list(range(4))\na\n\n[0, 1, 2, 3]\n\n\n\nb = list(range(4, 8))\nb\n\n[4, 5, 6, 7]\n\n\n\nb = zip(a, b)\nb\n\n&lt;zip at 0x172034f80&gt;\n\n\n\nlist(b)\n\n[(0, 4), (1, 5), (2, 6), (3, 7)]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#il-flusso-di-esecuzione",
    "href": "chapters/chapter_1/02_python_2.html#il-flusso-di-esecuzione",
    "title": "4¬† Python (2)",
    "section": "4.2 Il flusso di esecuzione",
    "text": "4.2 Il flusso di esecuzione\nIn Python il codice viene eseguito sequenzialmente, partendo dalla prima riga fino a quando non c‚Äô√® pi√π nulla da eseguire. L‚Äôordine di esecuzione delle varie istruzioni √® detto flusso di esecuzione.\nPer esempio la cella seguente prima memorizza la lista names, poi la lista born e infine la lista dead.\n\nnames = [\"Sigmund Freud\", \"Jean Piaget\", \"Burrhus Frederic Skinner\", \"Albert Bandura\"]\nborn = [1856, 1896, 1904, 1925]\ndead = [1939, 1980, 1990, None]\n\nHo usato il valore speciale None in quanto non risulta disponibile l‚Äôanno. In queste situazioni si parla di valori mancanti (missing values) che, di norma, vengono indicati con la sigla NA (not available).\nLa cella seguente include le istruzioni condizionali che specificano se e quando devono essere eseguiti determinati blocchi di codice. La pi√π semplice istruzione di controllo √® l‚Äôistruzione if. Per esempio:\n\nname = \"Maria\"\ngrade = 29\n\nif name == \"Maria\" and grade &gt; 28:\n    print(\"Maria, hai ottenuto un ottimo voto all'esame!\")\n\nif name == \"Giovanna\" or grade &gt; 28:\n    print(\n        \"Tu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\"\n    )\n\nif name != \"Giovanna\" and grade &gt; 28:\n    print(\"Tu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\")\n\nMaria, hai ottenuto un ottimo voto all'esame!\nTu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\nTu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\n\n\nTutte e tre le condizioni precedenti ritornano True, quindi vengono stampati tutti e tre i messaggi.\nSi noti che == e != confrontano valori, mentre is e not confrontano oggetti. Per esempio,\n\nname_list = [\"Maria\", \"Giovanna\"]\nname_list_two = [\"Marco\", \"Francesco\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nFalse\nFalse\n\n\nUna delle parole chiave condizionali pi√π utili √® in. Un esempio √® il seguente:\n\nname_list = [\"Maria\", \"Giovanna\", \"Marco\", \"Francesco\"]\n\nprint(\"Giovanna\" in name_list)\nprint(\"Luca\" in name_list)\n\nTrue\nFalse\n\n\nLa condizione opposta √® not in.\n\nprint(\"Luca\" not in name_list)\n\nTrue\n\n\nFacciamo un altro esempio.\n\nage = 26\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\n\nSei maggiorenne\n\n\nPython dispone di un‚Äôespressione ternaria che introduce la potenza dell‚Äôistruzione ‚Äòelse‚Äô in una sintassi concisa:\n\nage = 26\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei maggiorenne\n\n\n\nage = 16\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei minorenne\n\n\nUna struttura di selezione leggermente pi√π complessa √® ‚Äúif-else‚Äù. La sintassi di questa struttura √® la seguente:\nif &lt;condizione&gt;:\n    &lt;istruzione_se_condizione_vera&gt;\nelse:\n    &lt;istruzione_se_condizione_falsa&gt;\nLa semantica di ‚Äúif-else‚Äù √® quella che ci si aspetta: la condizione tra la parola chiave if e il carattere di due punti viene valutata: se risulta vera viene eseguita l‚Äôistruzione alla linea seguente, altrimenti viene eseguita l‚Äôistruzione dopo la parola chiave else. Anche in questo caso l‚Äôindentazione permette di identificare quali istruzioni devono essere eseguite nei due rami della selezione. Per esempio:\n\nage = 16\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\nelse:\n    print(\"Sei minorenne\")\n\nSei minorenne\n\n\nIn presenza di pi√π di due possibilit√† mutuamente esclusive ed esaustive possiamo usare l‚Äôistruzione elif. Per esempio:\n\ncfu = 36\nthesis_defense = False\n\nif cfu &gt;= 180 and thesis_defense == True:\n    print(\"Puoi andare a festeggiare!\")\nelif cfu &gt;= 180 and thesis_defense == False:\n    print(\"Devi ancora superare la prova finale!\")\nelse:\n    print(\"Ripassa tra qualche anno!\")\n\nRipassa tra qualche anno!\n\n\n\n4.2.1 Commenti\nIn Python √® possibile usare il carattere # per aggiungere commenti al codice. Ogni riga di commento deve essere preceduta da un #. I commenti non devono spiegare il metodo (cosa fa il codice: quello si vede), ma bens√¨ lo scopo: quello che noi intendiamo ottenere. I primi destinatari dei commenti siamo noi stessi tra un po‚Äô di tempo, ovvero quando ci saremo dimenticati cosa avevamo in mente quando abbiamo scritto il codice.\n\n# This is a comment and will not be executed.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#cicli",
    "href": "chapters/chapter_1/02_python_2.html#cicli",
    "title": "4¬† Python (2)",
    "section": "4.3 Cicli",
    "text": "4.3 Cicli\nUn ciclo √® un modo per eseguire una porzione di codice pi√π di una volta. I cicli sono fondamentali nei linguaggi di programmazione. Come molti altri linguaggi di programmazione, Python ha due tipi di cicli per gestire tutte le proprie necessit√† di iterazione: il ciclo ‚Äúwhile‚Äù e il ciclo ‚Äúfor‚Äù.\n\n4.3.1 Il ciclo while\nil ciclo while permette l‚Äôesecuzione di un blocco di codice finch√© una determinata condizione √® True. Per esempio:\n\ncounter = 0\n\nwhile counter &lt;= 10:\n    print(counter)\n    counter += 1\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nIl codice counter += 1 √® equivalente a counter = counter + 1 e, ogni qualvolta viene eseguito il ciclo, riassegna alla variabile counter il valore che aveva in precedenza + 1.\nL‚Äôistruzione while controlla se alla variabile counter √® associato un valore minore o uguale a 10. Nel primo passo del ciclo la condizione √® soddisfatta, avendo noi definito counter = 0, pertanto il programma entra nel loop, stampa il valore della variabile counter e incrementa counter di un‚Äôunit√†.\nQuesto comportamento si ripete finch√© la condizione counter &lt;= 10 risulta True. Quando il contatore counter assume il valore 11 il ciclo while si interrompe e il blocco di codice del ciclo non viene pi√π eseguito.\n\n\n4.3.2 Il ciclo for\nIl ciclo for √® un costrutto di controllo di flusso che viene utilizzato per iterare su una sequenza di valori, come ad esempio una lista, una tupla, una stringa o un dizionario.\nLa sintassi generale di un ciclo for in Python √® la seguente:\nfor element in sequence:\n    # codice da eseguire\nDove element √® una variabile temporanea che assume il valore di ciascun elemento della sequenza ad ogni iterazione del ciclo, e sequence √® la sequenza di valori su cui iterare.\nDurante l‚Äôesecuzione del ciclo, il blocco di codice indentato sotto la linea for viene eseguito una volta per ogni elemento della sequenza. Ad ogni iterazione, la variabile elemento assume il valore dell‚Äôelemento corrente della sequenza e il codice all‚Äôinterno del blocco viene eseguito con questo valore.\nIl ciclo for √® spesso utilizzato per eseguire operazioni su ciascun elemento di una sequenza, come ad esempio la somma degli elementi di una lista o la stampa di ciascun carattere di una stringa. Per esempio\n\nnumbers = [0, 1, 2, 3, 4, 5]\nfor number in numbers: # number is temporary name to refer to the list's items, valid only inside this loop\n    print(number)\n\n0\n1\n2\n3\n4\n5\n\n\n\nlanguage = \"Python\"\nfor letter in language:\n    print(letter)\n\nP\ny\nt\nh\no\nn\n\n\nLa funzione range() √® spesso usata nei cicli for e permette di impostare un intervallo di esecuzione tanto ampio quanto il numero che le passiamo come parametro meno uno.\nLa funzione range() prende tre parametri: start (default 0), stop e step (default 1), ovvero un punto di inizio dell‚Äôintervallo, un punto di fine e un passo di avanzamento. L‚Äôindicizzazione Python parte da 0; quindi range(0, 11, 1) una lista di 11 elementi, da 0 a 10 inclusi.\n\nprint(list(range(0, 11, 1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nAd esempio, impostiamo un punto di inizio a 3, il punto di fine a 11 e un passo di 2:\n\nprint(list(range(3, 12, 2)))\n\n[3, 5, 7, 9, 11]\n\n\nIn un ciclo for, l‚Äôintervallo di range() corrisponde al numero di iterazioni che verranno eseguite, ovvero al numero di volte che il ciclo verr√† processato. Nel caso seguente, l‚Äôindice del ciclo (qui chiamato number) assume il valore 0 la prima volta che il ciclo viene eseguito e il valore 10 nell‚Äôultima esecuzione del ciclo.\n\nfor number in range(11):\n    print(number)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nfor number in range(3, 12, 2):\n    print(number)\n\n3\n5\n7\n9\n11\n\n\n\n4.3.2.1 Cicli for annidati\nSono possibili i cicli for annidati, vale a dire un ciclo posto all‚Äôinterno del corpo di un altro (chiamato ciclo esterno). Al suo primo passo, il ciclo esterno mette in esecuzione quello interno che esegue il proprio blocco di codice fino alla conclusione. Quindi, al secondo passo, il ciclo esterno rimette in esecuzione quello interno. Questo si ripete finch√© il ciclo esterno non termina. Per esempio:\n\nfor i in range(4):\n    for j in range(4):\n        print((i, j))\n\n(0, 0)\n(0, 1)\n(0, 2)\n(0, 3)\n(1, 0)\n(1, 1)\n(1, 2)\n(1, 3)\n(2, 0)\n(2, 1)\n(2, 2)\n(2, 3)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)\n\n\n\n\n4.3.2.2 Modificare gli elementi di una lista\nIl ciclo for √® il modo pi√π comune per scorrere gli elementi di una lista, come abbiamo visto in precedenza.\n\nfor name in name_list:\n    print(name)\n\nMaria\nGiovanna\nMarco\nFrancesco\n\n\nQuesto approccio pu√≤ essere usato se abbiamo solo bisogno di leggere gli elementi della lista. Nel ciclo seguente, ad esempio, leggiamo gli elementi d una lista per incrementare una variabile cos√¨ da calcolare una somma.\n\nnumbers = [2, -4, 1, 6, 3]\n\ntotal = 0\nfor num in numbers:\n    total += num\n\nprint(total)\n\n8\n\n\nMa se vogliamo cambiare gli elementi di una lista l‚Äôapproccio precedente non funziona e dobbiamo usare gli indici. Nell‚Äôesempio seguente, questo risultato viene ottenuto utilizzando le funzioni range e len:\n\nnumbers = [2, -4, 1, 6, 3]\n\nfor i in range(len(numbers)):\n    numbers[i] = numbers[i] * 2\n\nprint(numbers)\n\n[4, -8, 2, 12, 6]\n\n\nNel codice seguente, la funzione len() ritorna 5.\n\nnumbers = [2, -4, 1, 6, 3]\nlen(numbers)\n\n5\n\n\nQuindi, range(5) produce la seguente sequenza iterabile:\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]\n\n\nQuesti sono gli indici che verranno usati nelle iterazioni del ciclo for.\n\nLa prima volta che il ciclo viene eseguito, l‚Äôindice i vale 0 e numbers[i] si riferisce al primo elemento della lista;\nla seconda volta che il ciclo viene eseguito, i vale 1 e numbers[i] si riferisce al secondo elemento della lista;\ne cos√¨ via.\n\nL‚Äôistruzione di assegnazione nel corpo del ciclo for usa i per leggere il valore i-esimo della lista originale (a destra dell‚Äôuguale) e per assegnargli un nuovo valore (a sinistra dell‚Äôuguale).\n\n\n\n4.3.3 List comprehension\nUna list comprehension √® un modo conciso di creare una lista. √à un modo compatto per creare una nuova lista. Accade speso di dover creare una lista dove ciascun elemento √® il risultato di un‚Äôoperazione condotta sugli elementi di un‚Äôaltra lista o di un iterabile; oppure, di dover estrarre gli elementi che soddisfano una certa condizione. Per esempio, supponiamo di volere sommare una costante ad una lista di numeri. Usando un ciclo for possiamo procedere nel modo seguente (si noti l‚Äôuso della funzione append):\n\nnew_list = []\nk = 10\nfor x in range(10):\n    new_list.append(x + k)\n\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nOppure, in maniera pi√π semplice, possiamo usare una list comprehension:\n\nnew_list = [x + k for x in range(10)]\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nUna list comprehension √® racchiusa tra parentesi quadre; contiene un‚Äôespressione, seguita da una clausola for, seguita da zero o pi√π clausole for o if. La sintassi √® la seguente:\n[ &lt;expression&gt; for item in iterable &lt;if optional_condition&gt; ]\nIl risultato √® una nuova lista costruita valutando l‚Äôespressione nel contesto delle clausole for e if che la seguono. Una list comprehension combina dunque un ciclo for e (se necessario) una o pi√π condizioni logiche in una singola riga di codice. Esaminiamo una variante dell‚Äôesempio precedente.\n\nlist1 = [1, 2, 3, 4, 5, 6]\nprint(\"list1:\", list1)\n\nlist1: [1, 2, 3, 4, 5, 6]\n\n\n\nlist2 = [item + 1 for item in list1]\nprint(\"list2:\", list2)\n\nlist2: [2, 3, 4, 5, 6, 7]\n\n\nSi noti che la parola item avrebbe potuto essere quasi qualsiasi stringa (in precedenza abbiamo usato x). La possiamo immaginare con la seguente definizione: ...per ogni elemento in .... Nel seguente esempio, sommiamo 1 agli elementi di list1 solo se sono pari:\n\nlist3 = [item + 1 for item in list1 if item % 2 == 0] \nprint('list3:', list3)\n\nlist3: [3, 5, 7]\n\n\nFacciamo un altro esempio usando range():\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nQui selezioniamo solo i numeri pari (oltre allo zero):\n\n[i for i in range(11) if i % 2 == 0]\n\n[0, 2, 4, 6, 8, 10]\n\n\nSpecificando una condizione, possiamo cambiare il segno solo dei numeri dispari nella lista:\n\n[-i if i % 2 else i for i in range(11)]\n\n[0, -1, 2, -3, 4, -5, 6, -7, 8, -9, 10]\n\n\nPossiamo anche eseguire pi√π iterazioni simultaneamente:\n\n[(i, j) for i in range(3) for j in range(4)]\n\n[(0, 0),\n (0, 1),\n (0, 2),\n (0, 3),\n (1, 0),\n (1, 1),\n (1, 2),\n (1, 3),\n (2, 0),\n (2, 1),\n (2, 2),\n (2, 3)]\n\n\nIn questo esempio vengono selezionati solo i nomi inclusi nella lista female_names:\n\nfirst_names = [\"Maria\", \"Marco\", \"Francesco\", \"Giovanna\"]\nfemale_names = [\"Alice\", \"Maria\", \"Giovanna\", \"Lisa\"]\nfemale_list = [name for name in first_names if name in female_names]\nprint(female_list)\n\n['Maria', 'Giovanna']\n\n\nNel seguente esempio vengono estratte le prime tre lettere di ciascuno dei nomi che compongono una lista:\n\nletters = [name[0:3] for name in first_names] \nletters\n\n['Mar', 'Mar', 'Fra', 'Gio']\n\n\nPer estrarre l‚Äôultimo carattere di una stringa usiamo [-1]:\n\nmy_string = \"barbabl√π\"\nmy_string[-1]\n\n'√π'\n\n\nPossiamo dunque usare seguente list comprehension estrae gli ultimi tre caratteri di ciascun elemento della lista first_names.\n\nletters = [name[-3:] for name in first_names] \nletters\n\n['ria', 'rco', 'sco', 'nna']\n\n\n√à possibile impiegare un‚Äôespressione ternaria all‚Äôinterno di una list comprehension per sfruttare la versatilit√† dell‚Äôistruzione ‚Äòelse‚Äô in modo sintatticamente efficace. Ad esempio, possiamo sostituire tutti i numeri dispari di una lista (un un NumPy array) con il valore 99.\n\nnum = np.array([4, 7, 2, 6, 3, 9])  # pu√≤ anche essere una lista Python\n[e if e % 2 == 0 else 99 for e in num]\n\n[4, 99, 2, 6, 99, 99]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#librerie-e-moduli",
    "href": "chapters/chapter_1/02_python_2.html#librerie-e-moduli",
    "title": "4¬† Python (2)",
    "section": "4.4 Librerie e moduli",
    "text": "4.4 Librerie e moduli\n\n4.4.1 Importare moduli\nI moduli (anche conosciuti come librerie in altri linguaggi) sono dei file usati per raggruppare funzioni e altri oggetti. Python include una lista estensiva di moduli standard (anche conosciuti come Standard Library), ma √® anche possibile scaricarne o definirne di nuovi. Prima di potere utilizzare le funzioni non presenti nella Standard Library all‚Äôinterno dei nostri programmi dobbiamo importare dei moduli aggiuntivi, e per fare ci√≤ usiamo il comando import.\nL‚Äôimportazione pu√≤ riguardare un intero modulo oppure solo uno (o pi√π) dei suoi elementi. Consideriamo per esempio la funzione mean. Essa √® disponibile nel modulo numpy. L‚Äôistruzione import numpy importa tutto il modulo numpy. Dopo che un modulo √® stato importato, √® possibile accedere a un suo generico elemento usando il nome del modulo, seguito da un punto e dal nome dell‚Äôelemento in questione. Ad esempio, numpy.mean().\nIndicare il nome di un modulo per poter accedere ai suoi elementi ha spesso l‚Äôeffetto di allungare il codice, diminuendone al contempo la leggibilit√†. √à per questo motivo che √® possibile importare un modulo specificando un nome alternativo, pi√π corto. √à quello che succede quando scriviamo l‚Äôistruzione import numpy as np. In questo caso, l‚Äôistruzione precedente diventa np.mean().\nI moduli pi√π complessi sono organizzati in strutture gerarchiche chiamate package. La seguente cella importa il modulo pyplot che √® contenuto nel package matplotlib (matplotlib √® la libreria di riferimento in Python per la creazione di grafici).\n\nimport matplotlib.pyplot as plt\n\nQui di seguito sono descritte tutte le possibilit√†:\n\n# import everything from library\nimport random\n# call function by\nrandom.random()\n\n0.16777284588756924\n\n\n\n#import everything, but change name\nimport random as rnd\n# call function by\nrnd.random()\n\n0.05690270000491682\n\n\n\n# select what to import from library\nfrom random import random\n#call function by\nrandom()\n\n0.037974565142151695\n\n\n\n# import everything from library\nfrom random import *\n# call function by\nrandom()\n\n0.20988431417194764\n\n\nNella cella seguente importiamo seaborn con il nome sns e usiamo le sue funzionalit√† per impostare uno stile e una palette di colori per la visualizzazione dei grafici.\n\nimport seaborn as sns\nsns.set_theme()\nsns.set_palette(\"colorblind\")\n\nNell‚Äôesempio seguente calcoliamo la somma degli elementi della lista numerica primes usando funzione sum() contenuta nella libreria NumPy che abbiamo importato con il nome di np:\n\nimport numpy as np\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nnp.sum(primes)\n\n42\n\n\nCalcolo la media di primes:\n\nnp.mean(primes)\n\n6.0\n\n\nScriviamo una nuova funzione per la media, \\(\\bar{x} = n^{-1}\\sum_{i=1}^n x_i\\):\n\ndef my_mean(x):\n    res = np.sum(x) / len(x)\n    return res\n\n\nmy_mean(primes)\n\n6.0\n\n\nSi noti che, nel corpo di una funzione, √® possibile usare altre funzioni: qui, np.sum() e len().\n√à sempre possibile usare la funzione di help su una funzione:\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n    \n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nIn Visual Studio Code √® sufficiente posizionare il cursore sul nome della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#formattazione-del-codice",
    "href": "chapters/chapter_1/02_python_2.html#formattazione-del-codice",
    "title": "4¬† Python (2)",
    "section": "4.5 Formattazione del codice",
    "text": "4.5 Formattazione del codice\n\noolbkvm ../images/code_quality_2x.png :align: center",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "4¬† Python (2)",
    "section": "4.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "4.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.1.4\nnumpy     : 1.26.2\nseaborn   : 0.13.0\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html",
    "href": "chapters/chapter_1/03_numpy.html",
    "title": "5¬† NumPy",
    "section": "",
    "text": "5.1 Preparazione del Notebook\nimport numpy as np",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "href": "chapters/chapter_1/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "title": "5¬† NumPy",
    "section": "5.2 Utilizzo degli Array nel Modulo NumPy",
    "text": "5.2 Utilizzo degli Array nel Modulo NumPy\nIn Python standard, abbiamo a disposizione tipi di dati numerici (come numeri interi e decimali) e strutture come liste, dizionari e insiemi. NumPy, d‚Äôaltro canto, introduce un nuovo tipo di struttura dati: l‚Äôarray N-dimensionale, noto come ndarray. Questi array hanno alcune caratteristiche distintive:\n\nDimensioni: Gli ndarray possono variare nel numero di dimensioni, definite come ‚Äúassi‚Äù. Ad esempio, un array pu√≤ essere unidimensionale (simile a un vettore lineare), bidimensionale (come una matrice o una tabella), tridimensionale (simile a un cubo), e cos√¨ via.\nTipo di Dato: A differenza delle liste in Python standard che possono contenere diversi tipi di dati, ogni elemento all‚Äôinterno di un ndarray deve essere dello stesso tipo, come numeri interi, decimali, booleani o stringhe.\nForma: La ‚Äúforma‚Äù di un ndarray si riferisce alle sue dimensioni, ovvero quante righe, colonne o altri livelli di profondit√† ha. Per esempio, la forma (3, 4) indica un array con 3 righe e 4 colonne.\nIndicizzazione: Gli ndarray possono essere indicizzati in modo simile agli array standard di Python, ma offrono anche opzioni pi√π avanzate per l‚Äôindicizzazione.\n\nGli ndarray sono potenti per manipolare e analizzare i dati, grazie alle loro funzioni e metodi che includono operazioni matematiche e statistiche, trasformazioni e altre manipolazioni dei dati.\nTerminologia Importante: - Size: Indica il numero totale di elementi in un array. - Rank: Si riferisce al numero di dimensioni, o assi, di un array. - Shape: Denota le dimensioni specifiche dell‚Äôarray, ovvero una sequenza di numeri che rappresentano il conteggio degli elementi in ogni dimensione.\nCome Creare un ndarray: Il modo pi√π diretto per creare un ndarray √® attraverso la conversione di una lista Python. Ad esempio, √® possibile creare un array unidimensionale (1-D) a partire da una lista standard di Python.\n\nx = np.array([1, 2, 3, 4, 5, 6])\n\nL‚Äôistruzione precedente crea un array in NumPy, assegnandolo alla variabile x. Questo array √® un vettore unidimensionale contenente sei elementi, che sono i numeri interi specificati all‚Äôinterno delle parentesi quadre.\n\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nIndicizzazione\nSe vogliamo estrarre un singolo elemento del vettore lo indicizziamo con la sua posizione (si ricordi che l‚Äôindice inizia da 0):\n\nx[0]\n\n1\n\n\n\nx[2]\n\n3\n\n\nUn array 2-D si crea nel modo seguente:\n\ny = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nEstraiamo un singolo elemento dall‚Äôarray:\n\ny[0, 2]\n\n3\n\n\nEstraiamo la seconda riga dall‚Äôarray:\n\ny[1]\n\narray([5, 6, 7, 8])\n\n\nEstraiamo la seconda colonna dall‚Äôarray:\n\ny[:, 1] \n\narray([ 2,  6, 10])\n\n\nLa sintassi con i due punti √® chiamata ‚Äúslicing‚Äù dell‚Äôarray.\n\n# Display the first row of the array\nprint(\"Displaying the first row:\")\nprint(y[0, :])\n\nDisplaying the first row:\n[1 2 3 4]\n\n\n\n# Show the last two elements in the first row\nprint(\"Showing the last two elements in the first row:\")\nprint(y[0, -2:])\n\nShowing the last two elements in the first row:\n[3 4]\n\n\n\n# Retrieve every second element in the first row\nprint(\"Retrieving every second element in the first row:\")\nprint(y[0, ::2])\n\nRetrieving every second element in the first row:\n[1 3]\n\n\n\n# Extract a submatrix from the original array\nprint(\"Extracting a submatrix:\")\nprint(y[:2, 1:3])\n\nExtracting a submatrix:\n[[2 3]\n [6 7]]\n\n\n\n5.2.1 Funzioni per ndarray\nNumpy offre varie funzioni per creare ndarray. Per esempio, √® possibile creare un array 1-D con la funzione .arange(start, stop, incr, dtype=..) che fornisce l‚Äôintervallo di numeri compreso fra start, stop, al passo incr:\n\nz = np.arange(2, 9, 2)\nprint(z)\n\n[2 4 6 8]\n\n\nSi usa spesso .arange per creare sequenze a incrementi unitari:\n\nw = np.arange(11)\nprint(w)\n\n[ 0  1  2  3  4  5  6  7  8  9 10]\n\n\nUn‚Äôaltra funzione molto utile √® .linspace:\n\nx = np.linspace(0, 10, num=20)\nprint(x)\n\n[ 0.          0.52631579  1.05263158  1.57894737  2.10526316  2.63157895\n  3.15789474  3.68421053  4.21052632  4.73684211  5.26315789  5.78947368\n  6.31578947  6.84210526  7.36842105  7.89473684  8.42105263  8.94736842\n  9.47368421 10.        ]\n\n\nFissati gli estremi (qui 0, 10) e il numero di elementi desiderati, .linspace determina in maniera automatica l‚Äôincremento.\nUna propriet√† molto utile dei ndarray √® la possibilit√† di filtrare gli elementi di un array che rispondono come True ad un criterio. Per esempio:\n\nprint(x[x &gt; 7])\n\n[ 7.36842105  7.89473684  8.42105263  8.94736842  9.47368421 10.        ]\n\n\nperch√© solo gli ultimi sei elementi di x rispondono True al criterio \\(x &gt; 7\\).\nLe dimensioni (‚Äúassi‚Äù) di un ndarray vengono ritornate dal metodo .dim. Per esempio:\n\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\ny.ndim\n\n2\n\n\n\nprint(y.max(axis=1))\n\n[ 4  8 12]\n\n\n\nprint(y.max(axis=0))\n\n[ 9 10 11 12]\n\n\nIl numero di elementi per ciascun asse viene ritornato dal metodo .shape:\n\ny.shape\n\n(3, 4)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#manipolazione-di-array-con-numpy",
    "href": "chapters/chapter_1/03_numpy.html#manipolazione-di-array-con-numpy",
    "title": "5¬† NumPy",
    "section": "5.3 Manipolazione di Array con NumPy",
    "text": "5.3 Manipolazione di Array con NumPy\nNumPy rende pi√π agevole lavorare con grandi quantit√† di dati. Un concetto fondamentale in NumPy sono gli array monodimensionali, spesso utilizzati per rappresentare vettori, ovvero sequenze di numeri che possono rappresentare, ad esempio, le misurazioni di una variabile specifica. Grazie a NumPy, possiamo eseguire operazioni aritmetiche su questi vettori in modo semplice, applicando la stessa operazione a tutti gli elementi dell‚Äôarray contemporaneamente.\n\n5.3.1 Cosa Significa Vettorizzare un‚ÄôOperazione\nLa vettorizzazione √® una delle funzionalit√† pi√π efficaci di NumPy. Quando diciamo che un‚Äôoperazione √® vettorizzata, significa che questa operazione viene applicata in un colpo solo a tutti gli elementi dell‚Äôarray, invece di dover agire su ciascun elemento individualmente. Questo approccio rende la manipolazione di grandi insiemi di dati non solo pi√π veloce ma anche pi√π intuitiva, poich√© consente di trattare l‚Äôintero insieme di dati come un‚Äôunica entit√† anzich√© come una serie di punti dati individuali.\nSupponiamo di avere raccolto i dati di 4 individui\n\nm = np.array([1.62, 1.75, 1.55, 1.74])\nkg = np.array([55.4, 73.6, 57.1, 59.5])\n\nprint(m)\nprint(kg)\n\n[1.62 1.75 1.55 1.74]\n[55.4 73.6 57.1 59.5]\n\n\ndove m √® l‚Äôarray che contiene i dati relativi all‚Äôaltezza in metri dei quattro individui e kg √® l‚Äôarray che contiene i dati relativi al peso in kg. I dati sono organizzati in modo tale che il primo elemento di entrambi i vettori si riferisce alle misure del primo individuo, il secondo elemento dei due vettori si riferisce alle misure del secondo individuo, ecc.\nSupponiamo di volere calcolare l‚Äôindice BMI:\n\\[\nBMI = \\frac{kg}{m^2}.\n\\]\nPer il primo individuo del campione, l‚Äôindice di massa corporea √®\n\n55.4 / 1.62**2\n\n21.109586953208346\n\n\nSi noti che non abbiamo bisogno di scrivere 55.4 / (1.62**2) in quanto, in Python, l‚Äôelevazione a potenza viene eseguita prima della somma e della divisione (come in tutti i linguaggi). Usando i dati immagazzinati nei due vettori, lo stesso risultato si ottiene nel modo seguente:\n\nkg[0] / m[0]**2\n\n21.109586953208346\n\n\nSe ora non specifichiamo l‚Äôindice (per esempio, [0]), le operazioni aritmetiche indicate verranno eseguite per ciascuna coppia di elementi corrispondenti nei due vettori:\n\nbmi = kg / m**2\n\nOtteniamo cos√¨, con una sola istruzione, l‚Äôindice BMI dei quattro individui:\n\nbmi.round(1)\n\narray([21.1, 24. , 23.8, 19.7])\n\n\nQuesto esempio illustra come le operazioni aritmetiche standard vengano eseguite elemento per elemento negli array, grazie al processo di vettorizzazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#broadcasting",
    "href": "chapters/chapter_1/03_numpy.html#broadcasting",
    "title": "5¬† NumPy",
    "section": "5.4 Broadcasting",
    "text": "5.4 Broadcasting\nIl broadcasting √® una caratteristica distintiva di NumPy che facilita l‚Äôesecuzione di operazioni tra array di dimensioni diverse o tra un array e uno scalare, anche se le loro dimensioni non sono direttamente compatibili. Grazie al broadcasting, NumPy √® in grado di ‚Äúespandere‚Äù automaticamente le dimensioni di uno degli operandi per rendere possibile l‚Äôoperazione.\nQuesto significa che possiamo, per esempio, eseguire un‚Äôoperazione tra un array e un numero singolo (un vettore e uno scalare) o tra due array di dimensioni differenti, senza la necessit√† di modificare manualmente le dimensioni di questi array. Il broadcasting si occupa di adattare le dimensioni in modo coerente per consentire l‚Äôoperazione desiderata. Ci√≤ rende il codice pi√π snello e leggibile, eliminando la necessit√† di espandere gli array manualmente.\nIn breve, il broadcasting in NumPy √® un potente strumento che semplifica l‚Äôesecuzione di operazioni su array di dimensioni diverse o tra array e scalari, automatizzando l‚Äôallineamento delle dimensioni.\n\n5.4.1 Esempio di Broadcasting\nImmaginiamo di avere un array A con dimensioni 3x3 e un numero scalare B. Senza broadcasting, dovremmo espandere B in un array 3x3 riempiendo ogni cella con il valore di B per eseguire un‚Äôoperazione come l‚Äôaddizione su ciascun elemento di A. Grazie al broadcasting, possiamo semplicemente scrivere A + B, e NumPy si occuper√† automaticamente di ‚Äúespandere‚Äù B durante l‚Äôoperazione, applicando il valore scalare a ogni elemento di A.\n\n# Creiamo un array 3x3\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Definiamo uno scalare\nB = 5\n\n# Applichiamo il broadcasting per aggiungere lo scalare a ogni elemento dell'array\nC = A + B\n\nprint(C)\n\n[[ 6  7  8]\n [ 9 10 11]\n [12 13 14]]\n\n\nIn questo esempio, C conterr√† l‚Äôarray originale A con ogni elemento incrementato di 5, dimostrando come il broadcasting semplifichi operazioni che altrimenti richiederebbero passaggi aggiuntivi.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#altre-operazioni-sugli-array",
    "href": "chapters/chapter_1/03_numpy.html#altre-operazioni-sugli-array",
    "title": "5¬† NumPy",
    "section": "5.5 Altre operazioni sugli array",
    "text": "5.5 Altre operazioni sugli array\nC‚Äô√® un numero enorme di funzioni predefinite in NumPy che calcolano automaticamente diverse quantit√† sugli ndarray. Ad esempio:\n\nmean(): calcola la media di un vettore o matrice;\nsum(): calcola la somma di un vettore o matrice;\nstd(): calcola la deviazione standard;\nmin(): trova il minimo nel vettore o matrice;\nmax(): trova il massimo;\nndim: dimensione del vettore o matrice;\nshape: restituisce una tupla con la ‚Äúforma‚Äù del vettore o matrice;\nsize: restituisce la dimensione totale del vettore (=ndim) o della matrice;\ndtype: scrive il tipo numpy del dato;\nzeros(num): scrive un vettore di num elementi inizializzati a zero;\narange(start,stop,step): genera un intervallo di valori (interi o reali, a seconda dei valori di start, ecc.) intervallati di step. Nota che i dati vengono generati nell‚Äôintervallo aperto [start,stop)!\nlinstep(start,stop,num): genera un intervallo di num valori interi o reali a partire da start fino a stop (incluso!);\nastype(tipo): converte l‚Äôndarray nel tipo specificato\n\nPer esempio:\n\nx = np.array([1, 2, 3])\nprint(x)\n\n[1 2 3]\n\n\n\n[x.min(), x.max(), x.sum(), x.mean(), x.std()]\n\n[1, 3, 6, 2.0, 0.816496580927726]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#lavorare-con-formule-matematiche",
    "href": "chapters/chapter_1/03_numpy.html#lavorare-con-formule-matematiche",
    "title": "5¬† NumPy",
    "section": "5.6 Lavorare con formule matematiche",
    "text": "5.6 Lavorare con formule matematiche\nL‚Äôimplementazione delle formule matematiche sugli array √® un processo molto semplice con Numpy. Possiamo prendere ad esempio la formula della deviazione standard che discuteremo nel capitolo {ref}loc-scale-notebook:\n\\[\ns = \\sqrt{\\sum_{i=1}^n\\frac{(x_i - \\bar{x})^2}{n}}\n\\]\nL‚Äôimplementazione su un array NumPy √® la seguente:\n\nprint(x)\n\n[1 2 3]\n\n\n\nnp.sqrt(np.sum((x - np.mean(x)) ** 2) / np.size(x))\n\n0.816496580927726\n\n\nQuesta implementazione funziona nello stesso modo sia che x contenga 3 elementi (come nel caso presente) sia che x contenga migliaia di elementi. √à importante notare l‚Äôutilizzo delle parentesi tonde per specificare l‚Äôordine di esecuzione delle operazioni. In particolare, nel codice fornito, si inizia calcolando la media degli elementi del vettore x per mezzo della funzione np.mean(x). Questa operazione produce uno scalare, ovvero un singolo valore numerico che rappresenta la media degli elementi del vettore. L‚Äôutilizzo delle parentesi tonde √® fondamentale per garantire l‚Äôordine corretto delle operazioni. In questo caso, la funzione np.mean() viene applicata al vettore x prima di qualsiasi altra operazione matematica. Senza le parentesi tonde, le operazioni verrebbero eseguite in un ordine diverso e il risultato potrebbe essere errato.\n\nnp.mean(x)\n\n2.0\n\n\nSuccessivamente, eseguiamo la sottrazione dei singoli elementi del vettore x per la media del vettore stesso, ovvero \\(x_i - \\bar{x}\\), utilizzando il meccanismo del broadcasting.\n\nx - np.mean(x)\n\narray([-1.,  0.,  1.])\n\n\nEleviamo poi al quadrato gli elementi del vettore che abbiamo ottenuto:\n\n(x - np.mean(x)) ** 2\n\narray([1., 0., 1.])\n\n\nSommiamo gli elementi del vettore:\n\nnp.sum((x - np.mean(x)) ** 2)\n\n2.0\n\n\nDividiamo il numero ottenuto per \\(n\\). Questa √® la varianza di \\(x\\):\n\nres = np.sum((x - np.mean(x)) ** 2) / np.size(x)\nres\n\n0.6666666666666666\n\n\nInfine, per ottenere la deviazione standard, prendiamo la radice quadrata:\n\nnp.sqrt(res)\n\n0.816496580927726\n\n\nIl risultato ottenuto coincide con quello che si trova applicando la funzione np.std():\n\nnp.std(x)\n\n0.816496580927726",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#slicing",
    "href": "chapters/chapter_1/03_numpy.html#slicing",
    "title": "5¬† NumPy",
    "section": "5.7 Slicing",
    "text": "5.7 Slicing\nPer concludere, spendiamo ancora alcune parole sull‚Äôindicizzazione degli ndarray.\nSlicing in Numpy √® un meccanismo che consente di selezionare una porzione di un array multidimensionale, ovvero una sotto-matrice o un sotto-vettore. Per selezionare una porzione di un array, si utilizza la sintassi [start:stop:step], dove start indica l‚Äôindice di partenza della porzione, stop indica l‚Äôindice di fine e step indica il passo da utilizzare per la selezione. Se uno o pi√π di questi valori vengono omessi, vengono utilizzati dei valori di default.\nAd esempio, se abbiamo un array arr di dimensione (3, 4) e vogliamo selezionare la seconda colonna, possiamo usare la sintassi arr[:, 1]. In questo caso, il simbolo : indica che vogliamo selezionare tutte le righe, mentre il numero 1 indica che vogliamo selezionare la seconda colonna.\nInoltre, possiamo utilizzare il meccanismo di slicing anche per selezionare porzioni di array multidimensionali. Ad esempio, se abbiamo un array arr di dimensione (3, 4, 5) e vogliamo selezionare la prima riga di ciascuna matrice 4x5, possiamo usare la sintassi arr[:, 0, :].\nPer esempio, creiamo l‚Äôarray x di rango 2 con shape (3, 4):\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nUtilizziamo il meccanismo di slicing per estrarre la sottomatrice composta dalle prime 2 righe e dalle colonne 1 e 2. y √® l‚Äôarray risultante di dimensione (2, 2):\n\ny = x[:2, 1:3]\nprint(y)\n\n[[2 3]\n [6 7]]\n\n\n√à importante sapere che uno slice di un array in Numpy √® una vista degli stessi dati, il che significa che modificarlo implica la modifica dell‚Äôarray originale. In pratica, quando si modifica uno slice di un array, si sta modificando direttamente l‚Äôarray originale e tutte le altre visualizzazioni dell‚Äôarray vedranno la stessa modifica. Questo avviene perch√© Numpy √® progettato per gestire enormi quantit√† di dati, pertanto cerca di evitare il pi√π possibile di effettuare copie dei dati.\nQuesto comportamento deve essere preso in considerazione durante la modifica degli array in Numpy, al fine di evitare modifiche accidentali o indesiderate. In alcuni casi, √® possibile utilizzare il metodo copy() per creare una copia indipendente di un array e lavorare sulla copia senza modificare l‚Äôoriginale. Vediamo un esempio.\n\nprint(x[0, 1])   \n\n2\n\n\n\ny[0, 0] = 77     \n\n\nprint(x)\n\n[[ 1 77  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nz = x.copy()\nprint(z)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nz[0, 1] = 33\nprint(z)\n\n[[ 1 33  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#copia-e-copia-profonda-in-python",
    "href": "chapters/chapter_1/03_numpy.html#copia-e-copia-profonda-in-python",
    "title": "5¬† NumPy",
    "section": "5.8 Copia e ‚ÄúCopia Profonda‚Äù in Python",
    "text": "5.8 Copia e ‚ÄúCopia Profonda‚Äù in Python\nIn Python, per ottimizzare le prestazioni, le assegnazioni di solito non copiano gli oggetti sottostanti. Questo √® particolarmente importante, ad esempio, quando gli oggetti vengono passati tra funzioni, per evitare una quantit√† eccessiva di copie in memoria quando non sono necessarie (questo approccio √® noto tecnicamente come ‚Äúpassaggio per riferimento‚Äù).\nConsideriamo il seguente esempio con un array A:\n\nA = np.array([[1, 2], [3, 4]])\n\nSe creiamo un nuovo riferimento B a A:\n\nB = A\n\nOra B si riferisce allo stesso insieme di dati di A. Se modifichiamo B, anche A viene modificato di conseguenza:\n\nB[0,0] = 10\n\nDopo questa modifica, sia B che A saranno:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nSe desideriamo evitare questo comportamento, in modo tale che B diventi un oggetto completamente indipendente da A, dobbiamo effettuare una cosiddetta ‚Äúcopia profonda‚Äù utilizzando la funzione copy:\n\nB = np.copy(A)\n\nOra, se modificassimo B, A non subirebbe alcuna modifica. Ad esempio:\n\nB[0,0] = -5\n\nA questo punto, B sar√†:\n\nprint(B)\n\n[[-5  2]\n [ 3  4]]\n\n\nMa A rimarr√† invariato:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nQuesto esempio mostra chiaramente la differenza tra una semplice assegnazione, che crea un riferimento all‚Äôoggetto originale, e una ‚Äúcopia profonda‚Äù, che crea un nuovo oggetto indipendente.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "title": "5¬† NumPy",
    "section": "5.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "5.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy: 1.26.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html",
    "href": "chapters/chapter_1/04_pandas.html",
    "title": "6¬† Pandas (1)",
    "section": "",
    "text": "6.1 Preparazione del NoteBook\nimport pandas as pd\nimport numpy as np\n\n# Di default, Pandas mostrer√† 60 righe e 20 colonne. \n# Modifichiamo qui le impostazioni di visualizzazione predefinite di Pandas per mostrare pi√π righe.\npd.options.display.max_rows = 100",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#series",
    "href": "chapters/chapter_1/04_pandas.html#series",
    "title": "6¬† Pandas (1)",
    "section": "6.2 Series",
    "text": "6.2 Series\nIn Pandas, una Series √® un array unidimensionale composto da una sequenza di valori omogenei, simile ad un ndarray, accompagnato da un array di etichette chiamato ‚Äúindex‚Äù. A differenza degli indici degli array Numpy, che sono sempre interi e partono da zero, gli oggetti Series supportano etichette personalizzate che possono essere, ad esempio, delle stringhe. Inoltre, gli oggetti Series possono contenere dati mancanti che vengono ignorati da molte delle operazioni della classe.\nIl modo pi√π semplice di creare un oggetto Series √® di convertire una lista. Per esempio:\n\ngrades = pd.Series([27, 30, 24, 18, 22, 20, 29])\n\n√à possibile ottenere la rappresentazione dell‚Äôarray dell‚Äôoggetto e dell‚Äôindice dell‚Äôoggetto Series tramite i suoi attributi array e index, rispettivamente.\n\ngrades.array\n\n&lt;NumpyExtensionArray&gt;\n[27, 30, 24, 18, 22, 20, 29]\nLength: 7, dtype: int64\n\n\n\ngrades.index\n\nRangeIndex(start=0, stop=7, step=1)\n\n\nOppure, possiamo semplicemente stampare i contenuti dell‚Äôoggetto Series direttamente:\n\nprint(grades)\n\n0    27\n1    30\n2    24\n3    18\n4    22\n5    20\n6    29\ndtype: int64\n\n\nPer accedere agli elementi di un oggetto Series si usano le parentesi quadre contenenti un indice:\n\ngrades[0]\n\n27\n\n\n\ngrades[0:3]\n\n0    27\n1    30\n2    24\ndtype: int64\n\n\n√à possibile filtrare gli elementi di un oggetto Series con un array booleano:\n\ngrades &gt; 24\n\n0     True\n1     True\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: bool\n\n\n\ngrades[grades &gt; 24]\n\n0    27\n1    30\n6    29\ndtype: int64\n\n\n√à possibile manipolare gli elementi di un oggetto Series con le normali operazioni aritmetiche mediante la vettorializzazione:\n\ngrades / 10\n\n0    2.7\n1    3.0\n2    2.4\n3    1.8\n4    2.2\n5    2.0\n6    2.9\ndtype: float64\n\n\n\nnp.sqrt(grades)\n\n0    5.196152\n1    5.477226\n2    4.898979\n3    4.242641\n4    4.690416\n5    4.472136\n6    5.385165\ndtype: float64\n\n\nGli oggetti Series hanno diversi metodi per svolgere varie operazioni, per esempio per ricavare alcune statistiche descrittive:\n\n[grades.count(), grades.mean(), grades.min(), grades.max(), grades.std(), grades.sum()]\n\n[7, 24.285714285714285, 18, 30, 4.572172558506722, 170]\n\n\nMolto utile √® il metodo .describe():\n\ngrades.describe()\n\ncount     7.000000\nmean     24.285714\nstd       4.572173\nmin      18.000000\n25%      21.000000\n50%      24.000000\n75%      28.000000\nmax      30.000000\ndtype: float64",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#dataframe",
    "href": "chapters/chapter_1/04_pandas.html#dataframe",
    "title": "6¬† Pandas (1)",
    "section": "6.3 DataFrame",
    "text": "6.3 DataFrame\nUn pandas.DataFrame √® composto da righe e colonne. Ogni colonna di un dataframe √® un oggetto pandas.Series: quindi, un dataframe √® una collezione di serie. A differenza di un array NumPy, un dataframe pu√≤ combinare pi√π tipi di dati, come numeri e testo, ma i dati in ogni colonna sono dello stesso tipo.\nEsistono molti modi per costruire un DataFrame. Un primo metodo √® quello di utilizzare un dizionario che include una o pi√π liste o array Numpy di uguale lunghezza. Per esempio:\n\ndata = {\n    \"name\": [\n        \"Maria\",\n        \"Anna\",\n        \"Francesco\",\n        \"Cristina\",\n        \"Gianni\",\n        \"Gabriella\",\n        \"Stefano\",\n    ],\n    \"sex\": [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"],\n    \"group\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"],\n    \"x\": [1, 2, 3, 4, 5, 6, 7],\n    \"y\": [8, 9, 10, 11, 12, 13, 14],\n    \"z\": [15, 16, 17, 18, 19, 20, 21],\n}\nframe = pd.DataFrame(data)\nframe\n\n\n\n\n\n\n\n\n\nname\nsex\ngroup\nx\ny\nz\n\n\n\n\n0\nMaria\nf\na\n1\n8\n15\n\n\n1\nAnna\nf\nb\n2\n9\n16\n\n\n2\nFrancesco\nm\na\n3\n10\n17\n\n\n3\nCristina\nf\nb\n4\n11\n18\n\n\n4\nGianni\nm\nb\n5\n12\n19\n\n\n5\nGabriella\nf\nc\n6\n13\n20\n\n\n6\nStefano\nm\na\n7\n14\n21\n\n\n\n\n\n\n\n\nOppure possiamo procedere nel modo seguente:\n\ndf = pd.DataFrame()\n\ndf[\"x\"] = [1, 2, 3, 4, 5, 6, 7]\ndf[\"y\"] = [8, 9, 10, 11, 12, 13, 14]\ndf[\"z\"] = [14.4, 15.1, 16.7, 17.3, 18.9, 19.3, 20.2]\ndf[\"group\"] = [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"]\ndf[\"sex\"] = [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"]\ndf[\"name\"] = [\n    \"Maria\",\n    \"Anna\",\n    \"Francesco\",\n    \"Cristina\",\n    \"Gianni\",\n    \"Gabriella\",\n    \"Stefano\",\n]\n\nprint(df)\n\n   x   y     z group sex       name\n0  1   8  14.4     a   f      Maria\n1  2   9  15.1     b   f       Anna\n2  3  10  16.7     a   m  Francesco\n3  4  11  17.3     b   f   Cristina\n4  5  12  18.9     b   m     Gianni\n5  6  13  19.3     c   f  Gabriella\n6  7  14  20.2     a   m    Stefano\n\n\nMolto spesso un DataFrame viene creato dal caricamento di dati da file.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#lettura-di-dati-da-file",
    "href": "chapters/chapter_1/04_pandas.html#lettura-di-dati-da-file",
    "title": "6¬† Pandas (1)",
    "section": "6.4 Lettura di dati da file",
    "text": "6.4 Lettura di dati da file\nDi solito la quantit√† di dati da analizzare √® tale che non √® pensabile di poterli immettere manualmente in una o pi√π liste. Normalmente i dati sono memorizzati su un file ed √® necessario importarli. La lettura (importazione) dei file √® il primo fondamentale passo nel processo pi√π generale di analisi dei dati.\nIn un primo esempio, importiamo i dati da un repository remoto.\n\nurl = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\ntitanic = pd.read_csv(url, index_col=\"Name\")\n\n√à possibile usare il metodo .head() per visualizzare le prime cinque righe.\n\ntitanic.head()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBraund, Mr. Owen Harris\n1\n0\n3\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\n2\n1\n1\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\nHeikkinen, Miss. Laina\n3\n1\n3\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n4\n1\n1\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\nAllen, Mr. William Henry\n5\n0\n3\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\nLe statistiche descrittive per ciascuna colonna si ottengono con il metodo describe.\n\ntitanic.describe()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.000000\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.486592\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n0.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n0.000000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n0.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n1.000000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n1.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n\n\n\nIn questo modo possiamo ottenere informazioni sui nomi dei passeggeri, la sopravvivenza (0 o 1), l‚Äôet√†, il prezzo del biglietto, ecc. Con le statistiche riassuntive vediamo che l‚Äôet√† media √® di 29,7 anni, il prezzo massimo del biglietto √® di 512 USD, il 38% dei passeggeri √® sopravvissuto, ecc.\nPer fare un secondo esempio, importo i dati dal file penguins.csv situato nella directory ‚Äúdata‚Äù del mio computer. I dati relativi ai pinguini di Palmer sono resi disponibili da Kristen Gorman e dalla Palmer station, Antarctica LTER. La seguente cella legge il contenuto del file penguins.csv e lo inserisce nell‚Äôoggetto df utilizzando la funzione read_csv() di Pandas.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nPer il DataFrame df il significato delle colonne √® il seguente:\n\nspecies: a factor denoting penguin type (Ad√©lie, Chinstrap and Gentoo)\nisland: a factor denoting island in Palmer Archipelago, Antarctica (Biscoe, Dream or Torgersen)\nbill_length_mm: a number denoting bill length (millimeters)\nbill_depth_mm: a number denoting bill depth (millimeters)\nflipper_length_mm: an integer denoting flipper length (millimeters)\nbody_mass_g: an integer denoting body mass (grams)\nsex: a factor denoting sexuality (female, male)\nyear: the year of the study\n\nUsiamo il metodo .head() per visualizzare le prime cinque righe.\n\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nA volte potrebbero esserci dati estranei alla fine del file, quindi √® importante anche controllare le ultime righe:\n\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n\n\n\n\nUn breve tutorial in formato video √® disponibile tramite il seguente [collegamento](https://drive.google.com/file/d/12y7jZ0McvZBXThg6yjFgWx2ljQKrhoYR/view?usp=share_link), il quale illustra come effettuare la lettura dei dati da un file esterno in Visual Studio Code. \nL‚Äôattributo .dtypes restituisce il tipo dei dati:\n\ndf.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\nGli attributi pi√π comunemente usati sono elencati di seguito:\n\n\n\n\n\n\n\nAttributo\nRitorna\n\n\n\n\ndtypes\nIl tipo di dati in ogni colonna\n\n\nshape\nUna tupla con le dimensioni del DataFrame object (numero di righe, numero di colonne)\n\n\nindex\nL‚Äôoggetto Index lungo le righe del DataFrame\n\n\ncolumns\nIl nome delle colonne\n\n\nvalues\nI dati contenuti nel DataFrame\n\n\nempty\nCheck if the DataFrame object is empty\n\n\n\nPer esempio, l‚Äôistruzione della cella seguente restituisce l‚Äôelenco con i nomi delle colonne del DataFrame df:\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')\n\n\nLe dimensioni del Data Frame si ottengono con l‚Äôattributo .shape, che ritorna il numero di righe e di colonne. Nel caso presente, ci sono 344 righe e 8 colonne.\n\ndf.shape\n\n(344, 8)\n\n\nCome abbiamo gi√† visto in precedenza, un sommario dei dati si ottiene con il metodo .describe():\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\n\nUna descrizione del DataFrame si ottiene con il metodo .info().\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nSi noti che, alle volte, abbiamo utilizzato la sintassi `df.word` e talvolta la sintassi `df.word()`. Tecnicamente, la classe Pandas Dataframe ha sia attributi che metodi. Gli attributi sono `.word`, mentre i metodi sono `.word()` o `.word(arg1, arg2, ecc.)`. Per sapere se qualcosa √® un metodo o un attributo √® necessario leggere la documentazione.\nAbbiamo visto in precedenza come possiamo leggere i dati in un dataframe utilizzando la funzione read_csv(). Pandas comprende anche molti altri formati, ad esempio utilizzando le funzioni read_excel(), read_hdf(), read_json(), ecc. (e i corrispondenti metodi per scrivere su file: to_csv(), to_excel(), to_hdf(), to_json(), ecc.).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#gestione-dei-dati-mancanti",
    "href": "chapters/chapter_1/04_pandas.html#gestione-dei-dati-mancanti",
    "title": "6¬† Pandas (1)",
    "section": "6.5 Gestione dei dati mancanti",
    "text": "6.5 Gestione dei dati mancanti\nNell‚Äôoutput di .info() troviamo la colonna ‚ÄúNon-Null Count‚Äù, ovvero il numero di dati non mancanti per ciascuna colonna del DataFrame. Da questo si nota che le colonne del DataFrame df contengono alcuni dati mancanti. La gestione dei dati mancanti √® un argomento complesso. Per ora ci limitiamo ad escludere tutte le righe che, in qualche colonna, contengono dei dati mancanti.\nOttengo il numero di dati per ciascuna colonna del DataFrame:\n\ndf.isnull().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\nRimuovo i dati mancanti con il metodo .dropna(). L‚Äôargomento inplace=True specifica il DataFrame viene trasformato in maniera permanente.\n\ndf.dropna(inplace=True)\n\nVerifico che i dati mancanti siano stati rimossi.\n\ndf.shape\n\n(333, 8)\n\n\nIn alternativa, possiamo rimuovere solo le righe del DataFrame per le quali ci sono dei dati mancanti rispetto a specifiche colonne. Per esempio\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf0 = df.copy()\n\nmissing_data = df0.isnull()[[\"bill_length_mm\", \"body_mass_g\"]].any(axis=1)\n# Drop rows with any missing data\ndf0_cleaned = df0.loc[~missing_data]\ndf0_cleaned.shape\n\n(342, 8)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#rinominare-le-colonne",
    "href": "chapters/chapter_1/04_pandas.html#rinominare-le-colonne",
    "title": "6¬† Pandas (1)",
    "section": "6.6 Rinominare le colonne",
    "text": "6.6 Rinominare le colonne\n√à possibile rinominare tutte le colonne passando al metodo .rename() un dizionario che specifica quali colonne devono essere mappate a cosa. Nella cella seguente facciamo prima una copia del DataFrame con il metodo copy() e poi rinominiamo sex che diventa gender e year che diventa year_of_the_study:\n\ndf1 = df.copy()\n\n# rename(columns={\"OLD_NAME\": \"NEW_NAME\"})\ndf1.rename(columns={\n    \"sex\": \"gender\", \n    \"year\": \"year_of_the_study\"\n    }, \n           inplace=True)\ndf1.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\ngender\nyear_of_the_study\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python valgono le seguenti regole.\n\n- Il nome di una variabile deve iniziare con una lettera o con il trattino basso (*underscore*) `_`.\n- Il nome di una variabile non pu√≤ iniziare con un numero.\n- Un nome di variabile pu√≤ contenere solo caratteri alfanumerici e il trattino basso (A-z, 0-9 e _).\n- I nomi delle variabili fanno distinzione tra maiuscole e minuscole (`age`, `Age` e `AGE` sono tre variabili diverse).\n\nGli spazi non sono consentiti nel nome delle variabili: come separatore usate il trattino basso.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "href": "chapters/chapter_1/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "title": "6¬† Pandas (1)",
    "section": "6.7 Estrarre i dati dal DataFrame",
    "text": "6.7 Estrarre i dati dal DataFrame\nUna parte cruciale del lavoro con i DataFrame √® l‚Äôestrazione di sottoinsiemi di dati: vogliamo trovare le righe che soddisfano un determinato insieme di criteri, vogliamo isolare le colonne/righe di interesse, ecc. Per rispondere alle domande di interesse dell‚Äôanalisi dei dati, molto spesso √® necessario selezionare un sottoinsieme del DataFrame.\n\n6.7.1 Colonne\n√à possibile estrarre una colonna da un DataFrame usando una notazione simile a quella che si usa per il dizionario (DataFrame['word']) o utilizzando la notazione DataFrame.word. Per esempio:\n\ndf[\"bill_length_mm\"]\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\n\ndf.bill_length_mm\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\nSe tra parentesi quadre indichiamo una lista di colonne, come nel caso di df[['bill_length_mm','species']], otteniamo un nuovo DataFrame costituito unicamente dalle colonne selezionate:\n\ndf[[\"bill_length_mm\", \"species\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nspecies\n\n\n\n\n0\n39.1\nAdelie\n\n\n1\n39.5\nAdelie\n\n\n2\n40.3\nAdelie\n\n\n4\n36.7\nAdelie\n\n\n5\n39.3\nAdelie\n\n\n...\n...\n...\n\n\n339\n55.8\nChinstrap\n\n\n340\n43.5\nChinstrap\n\n\n341\n49.6\nChinstrap\n\n\n342\n50.8\nChinstrap\n\n\n343\n50.2\nChinstrap\n\n\n\n\n333 rows √ó 2 columns\n\n\n\n\n\n\n6.7.2 Righe\nIn un pandas.DataFrame, anche le righe hanno un nome. I nomi delle righe sono chiamati index:\n\ndf.index\n\nInt64Index([  0,   1,   2,   4,   5,   6,   7,  12,  13,  14,\n            ...\n            334, 335, 336, 337, 338, 339, 340, 341, 342, 343],\n           dtype='int64', length=333)\n\n\nCi sono vari metodi per estrarre sottoinsimi di righe da un DataFrame. √à possibile fare riferimento ad un intervallo di righe mediante un indice di slice. Per esempio, possiamo ottenere le prime 3 righe del DataFrame df nel modo seguente:\n\ndf[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python una sequenza √® determinata dal valore iniziale e quello finale ma si interrompe ad n-1. Pertanto, per selezionare una singola riga (per esempio, la prima) dobbiamo procedere nel modo seguente:\n\ndf[0:1]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n\n\n\n\n\n\n\n\n6.7.3 Indicizzazione, selezione e filtraggio\nPoich√© l‚Äôoggetto DataFrame √® bidimensionale, √® possibile selezionare un sottoinsieme di righe e colonne utilizzando le etichette degli assi (loc) o gli indici delle righe (iloc).\nPer esempio, usando l‚Äôattributo iloc posso selezionare la prima riga del DataFrame:\n\ndf.iloc[0]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            39.1\nbill_depth_mm             18.7\nflipper_length_mm        181.0\nbody_mass_g             3750.0\nsex                       male\nyear                      2007\nName: 0, dtype: object\n\n\nLa cella seguene seleziona le prime tre righe del DataFrame:\n\ndf.iloc[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nL‚Äôattributo loc consente di selezionare simultaneamente righe e colonne per ‚Äúnome‚Äù. Il ‚Äúnome‚Äù delle righe √® l‚Äôindice di riga. Per esempio, visualizzo il quinto valore della colonna body_mass_g:\n\ndf.loc[4, \"body_mass_g\"]\n\n3450.0\n\n\noppure, il quinto valore delle colonne bill_length_mm, bill_depth_mm, flipper_length_mm:\n\ndf.loc[4, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\nbill_length_mm        36.7\nbill_depth_mm         19.3\nflipper_length_mm    193.0\nName: 4, dtype: object\n\n\nVisualizzo ora le prime tre righe sulle tre colonne precedenti. Si noti l‚Äôuso di : per definire un intervallo di valori sull‚Äôindice di riga.\n\ndf.loc[0:2, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n39.1\n18.7\n181.0\n\n\n1\n39.5\n17.4\n186.0\n\n\n2\n40.3\n18.0\n195.0\n\n\n\n\n\n\n\n\nUna piccola variante della sintassi precedente si rivela molto utile. Qui, il segno di due punti (:) signfica ‚Äútutte le righe‚Äù:\n\nkeep_cols = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\nprint(df.loc[:, keep_cols])\n\n     bill_length_mm  bill_depth_mm  flipper_length_mm\n0              39.1           18.7              181.0\n1              39.5           17.4              186.0\n2              40.3           18.0              195.0\n4              36.7           19.3              193.0\n5              39.3           20.6              190.0\n..              ...            ...                ...\n339            55.8           19.8              207.0\n340            43.5           18.1              202.0\n341            49.6           18.2              193.0\n342            50.8           19.0              210.0\n343            50.2           18.7              198.0\n\n[333 rows x 3 columns]\n\n\n\n\n6.7.4 Filtrare righe in maniera condizionale\nIn precedenza abbiamo utilizzato la selezione delle righe in un DataFrame in base alla loro posizione. Tuttavia, √® pi√π comune selezionare le righe del DataFrame utilizzando una condizione logica, cio√® tramite l‚Äôindicizzazione booleana.\nIniziamo con un esempio relativo ad una condizione specificata sui valori di una sola colonna. Quando applichiamo un operatore logico come &gt;, &lt;, ==, != ai valori di una colonna del DataFrame, il risultato √® una sequenza di valori booleani (True, False), uno per ogni riga nel DataFrame, i quali indicano se, per quella riga, la condizione √® vera o falsa. Ad esempio:\n\ndf[\"island\"] == \"Torgersen\"\n\n0       True\n1       True\n2       True\n4       True\n5       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: island, Length: 333, dtype: bool\n\n\nUtilizzando i valori booleani che sono stati ottenuti in questo modo √® possibile filtrare le righe del DataFrame, ovvero, ottenere un nuovo DataFrame nel quale la condizione logica specificata √® vera su tutte le righe. Per esempio, nella cella seguente selezioniamo solo le osservazioni relative all‚Äôisola Torgersen, ovvero tutte le righe del DataFrame nelle quali la colonna island assume il valore Torgersen.\n\nonly_torgersen = df[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo scrivere:\n\nonly_torgersen = df.loc[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\n√à possibile combinare pi√π condizioni logiche usando gli operatori & (e), | (oppure). Si presti attenzione all‚Äôuso delle parentesi.\n\ndf.loc[(df[\"island\"] == \"Torgersen\") & (df[\"sex\"] == \"female\")].head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n12\nAdelie\nTorgersen\n41.1\n17.6\n182.0\n3200.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n\n6.7.5 Metodo .query\n√à anche possibile filtrare le righe del DataFrame usando il metodo query(). Ci sono diversi modi per generare sottoinsiemi con Pandas. I metodi loc e iloc consentono di recuperare sottoinsiemi in base alle etichette di riga e colonna o all‚Äôindice intero delle righe e delle colonne. E Pandas ha una notazione a parentesi quadre che consente di utilizzare condizioni logiche per recuperare righe di dati specifiche. Ma la sintassi di questi metodi non √® la pi√π trasparente. Inoltre, tali metodi sono difficili da usare insieme ad altri metodi di manipolazione dei dati in modo organico.\nIl metodo .query di Pandas cerca di risolve questi problemi. Il metodo .query consente di ‚Äúinterrogare‚Äù un DataFrame e recuperare sottoinsiemi basati su condizioni logiche. La sintassi √® un po‚Äô pi√π snella rispetto alla notazione a parentesi quadre di Pandas. Inoltre, il metodo .query pu√≤ essere utilizzato con altri metodi di Pandas in modo snello e semplice, rendendo la manipolazione dei dati maggiormente fluida e diretta.\nLa sintassi √® la seguente:\nyour_data_frame.query(expression, inplace = False)\nL‚Äôespressione utilizzata nella query √® una sorta di espressione logica che descrive quali righe restituire in output. Se l‚Äôespressione √® vera per una particolare riga, la riga verr√† inclusa nell‚Äôoutput. Se l‚Äôespressione √® falsa per una particolare riga, quella riga verr√† esclusa dall‚Äôoutput.\nIl parametro inplace consente di specificare se si desidera modificare direttamente il DataFrame con cui si sta lavorando.\nPer esempio:\n\neval_string = \"island == 'Torgersen' & sex == 'female' & year != 2009\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n6\n17.8\n181.0\n\n\n12\n17.6\n182.0\n\n\n15\n17.8\n185.0\n\n\n16\n19.0\n195.0\n\n\n18\n18.4\n184.0\n\n\n68\n16.6\n190.0\n\n\n70\n19.0\n190.0\n\n\n72\n17.2\n196.0\n\n\n74\n17.5\n190.0\n\n\n76\n16.8\n191.0\n\n\n78\n16.1\n187.0\n\n\n80\n17.2\n189.0\n\n\n82\n18.8\n187.0\n\n\n\n\n\n\n\n\nUn altro esempio usa la keyword in per selezionare solo le righe relative alle due isole specificate.\n\neval_string = \"island in ['Torgersen', 'Dream']\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n18.7\n181.0\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n5\n20.6\n190.0\n\n\n...\n...\n...\n\n\n339\n19.8\n207.0\n\n\n340\n18.1\n202.0\n\n\n341\n18.2\n193.0\n\n\n342\n19.0\n210.0\n\n\n343\n18.7\n198.0\n\n\n\n\n170 rows √ó 2 columns\n\n\n\n\nIl metodo query() pu√≤ anche essere utilizzato per selezionare le righe di un DataFrame in base alle relazioni tra le colonne. Ad esempio,\n\ndf.query(\"bill_length_mm &gt; 3*bill_depth_mm\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n152\n13.2\n211.0\n\n\n153\n16.3\n230.0\n\n\n154\n14.1\n210.0\n\n\n155\n15.2\n218.0\n\n\n156\n14.5\n215.0\n\n\n...\n...\n...\n\n\n272\n14.3\n215.0\n\n\n273\n15.7\n222.0\n\n\n274\n14.8\n212.0\n\n\n275\n16.1\n213.0\n\n\n293\n17.8\n181.0\n\n\n\n\n106 rows √ó 2 columns\n\n\n\n\n√à anche possibile fare riferimento a variabili non contenute nel DataFrame usando il carattere @.\n\noutside_var = 21\ndf.query(\"bill_depth_mm &gt; @outside_var\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n13\n21.2\n191.0\n\n\n14\n21.1\n198.0\n\n\n19\n21.5\n194.0\n\n\n35\n21.1\n196.0\n\n\n49\n21.2\n191.0\n\n\n61\n21.1\n195.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "href": "chapters/chapter_1/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "title": "6¬† Pandas (1)",
    "section": "6.8 Selezione casuale di un sottoinsieme di righe",
    "text": "6.8 Selezione casuale di un sottoinsieme di righe\nIl metodo sample() viene usato per ottenere un sottoinsieme casuale di righe del DataFrame. L‚Äôargomento replace=False indica l‚Äôestrazione senza rimessa (default); se specifichiamo replace=True otteniamo un‚Äôestrazione con rimessa. L‚Äôargomento n specifica il numero di righe che vogliamo ottenere. Ad esempio\n\ndf_sample = df.sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n204\nGentoo\nBiscoe\n45.1\n14.4\n210.0\n4400.0\nfemale\n2008\n\n\n69\nAdelie\nTorgersen\n41.8\n19.4\n198.0\n4450.0\nmale\n2008\n\n\n296\nChinstrap\nDream\n42.4\n17.3\n181.0\n3600.0\nfemale\n2007\n\n\n208\nGentoo\nBiscoe\n43.8\n13.9\n208.0\n4300.0\nfemale\n2008\n\n\n\n\n\n\n\n\n\ndf_sample = df[[\"bill_length_mm\", \"bill_depth_mm\"]].sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\n\n\n175\n46.3\n15.8\n\n\n133\n37.5\n18.5\n\n\n182\n47.3\n15.3\n\n\n251\n51.1\n16.5",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#selezione-di-colonne",
    "href": "chapters/chapter_1/04_pandas.html#selezione-di-colonne",
    "title": "6¬† Pandas (1)",
    "section": "6.9 Selezione di colonne",
    "text": "6.9 Selezione di colonne\nIl metodo drop() prende in input una lista con i nomi di colonne che vogliamo escludere dal DataFrame e pu√≤ essere usato per creare un nuovo DataFrame o per sovrascrivere quello di partenza. √à possibile usare le espressioni regolari (regex) per semplificare la ricerca dei nomi delle colonne.\nIn *regex* il simbolo `$` significa \"la stringa finisce con\"; il simbolo `^` significa \"la stringa inizia con\". L'espressione `regex` pu√≤ contenere (senza spazi) il simbolo `|` che significa \"oppure\". \nNel codice della cella seguente, alla funzione .columns.str.contains() viene passata l‚Äôespressione regolare mm$|year che significa: tutte le stringhe (in questo caso, nomi di colonne) che finiscono con mm oppure la stringa (nome di colonna) year.\n\nmask = df.columns.str.contains(\"mm$|year\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'year'], dtype='object')\n\n\n\ndf_new = df.drop(columns=columns_to_drop)\ndf_new.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n3750.0\nmale\n\n\n1\nAdelie\nTorgersen\n3800.0\nfemale\n\n\n2\nAdelie\nTorgersen\n3250.0\nfemale\n\n\n4\nAdelie\nTorgersen\n3450.0\nfemale\n\n\n5\nAdelie\nTorgersen\n3650.0\nmale\n\n\n\n\n\n\n\n\nIn un altro esempio, creaiamo l‚Äôelenco delle colonne che iniziano con la lettera ‚Äúb‚Äù, insieme a year e sex.\n\nmask = df.columns.str.contains(\"^b|year|sex\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'body_mass_g', 'sex', 'year'], dtype='object')\n\n\nOppure l‚Äôelenco delle colonne che contengono il patten ‚Äúlength‚Äù.\n\nmask = df.columns.str.contains(\"length\")\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'flipper_length_mm'], dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#creare-nuove-colonne",
    "href": "chapters/chapter_1/04_pandas.html#creare-nuove-colonne",
    "title": "6¬† Pandas (1)",
    "section": "6.10 Creare nuove colonne",
    "text": "6.10 Creare nuove colonne\nPer ciascuna riga, calcoliamo\n\nbill_length_mm - bill_depth_mm\nbill_length_mm / (body_mass_g / 1000)\n\nPer ottenere questo risultato possiamo usare una lambda function.\n\ndf = df.assign(\n    bill_difference=lambda x: x.bill_length_mm - x.bill_depth_mm,\n    bill_ratio=lambda x: x.bill_length_mm / (x.body_mass_g / 1000),\n)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n\n\n\n\n\n\n\n\nIn maniera pi√π semplice possiamo procedere nel modo seguente:\n\ndf[\"bill_ratio2\"] = df[\"bill_length_mm\"] / (df[\"body_mass_g\"] / 1000)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\nbill_ratio2\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n10.767123\n\n\n\n\n\n\n\n\nUn‚Äôutile funzionalit√† √® quella che consente di aggiungere una colonna ad un DataFrame (o di mofificare una colonna gi√† esistente) sulla base di una condizione True/False. Questo risultato pu√≤ essere raggiunto usando np.where(), con la seguente sintassi:\nnp.where(condition, value if condition is true, value if condition is false)\nSupponiamo di avere un DataFrame df con due colonne, A e B, e vogliamo creare una nuova colonna C che contenga il valore di A quando questo √® maggiore di 0, e il valore di B altrimenti. Possiamo utilizzare la funzione where() per ottenere ci√≤ come segue:\n\n# Creiamo un DataFrame di esempio\ndf = pd.DataFrame({\"A\": [-1, 2, 3, -4], \"B\": [5, 6, 0, 8]})\n\n# Creiamo una nuova colonna 'C' usando la funzione where()\ndf[\"C\"] = df[\"A\"].where(df[\"A\"] &gt; 0, df[\"B\"])\n\nprint(df)\n\n   A  B  C\n0 -1  5  5\n1  2  6  2\n2  3  0  3\n3 -4  8  8",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#formato-long-e-wide",
    "href": "chapters/chapter_1/04_pandas.html#formato-long-e-wide",
    "title": "6¬† Pandas (1)",
    "section": "6.11 Formato long e wide",
    "text": "6.11 Formato long e wide\nNella data analysis, i termini ‚Äúformato long‚Äù e ‚Äúformato wide‚Äù sono usati per descrivere la struttura di un set di dati. l formato wide (in inglese ‚Äúwide format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni variabile √® rappresentata da pi√π colonne. Un esempio √® il seguente, nel quale per ciascun partecipante, identificato da Name e ID abbiamo i punteggi di un ipotetico test per 6 anni consecutivi.\n\nscores = {\n    \"Name\": [\"Maria\", \"Carlo\", \"Giovanna\", \"Irene\"],\n    \"ID\": [1, 2, 3, 4],\n    \"2017\": [85, 87, 89, 91],\n    \"2018\": [96, 98, 100, 102],\n    \"2019\": [100, 102, 106, 106],\n    \"2020\": [89, 95, 98, 100],\n    \"2021\": [94, 96, 98, 100],\n    \"2022\": [100, 104, 104, 107],\n}\n\nwide_data = pd.DataFrame(scores)\nwide_data\n\n\n\n\n\n\n\n\n\nName\nID\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\n0\nMaria\n1\n85\n96\n100\n89\n94\n100\n\n\n1\nCarlo\n2\n87\n98\n102\n95\n96\n104\n\n\n2\nGiovanna\n3\n89\n100\n106\n98\n98\n104\n\n\n3\nIrene\n4\n91\n102\n106\n100\n100\n107\n\n\n\n\n\n\n\n\nIl formato long (in inglese ‚Äúlong format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni colonna rappresenta una singola variabile. Questo formato √® quello che viene richiesto per molte analisi statistiche. In Pandas √® possibile usare la funzione melt per trasformare i dati dal formato wide al formato long. Un esempio √® riportato qui sotto. Sono state mantenute le due colonne che identificano ciascun partecipante, ma i dati del test, che prima erano distribuiti su sei colonne, ora sono presenti in una singola colonna. Al DataFrame, inoltre, √® stata aggiunta una colonna che riporta l‚Äôanno.\n\nlong_data = wide_data.melt(id_vars=[\"Name\", \"ID\"], var_name=\"Year\", value_name=\"Score\")\nlong_data\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n1\nCarlo\n2\n2017\n87\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n3\nIrene\n4\n2017\n91\n\n\n4\nMaria\n1\n2018\n96\n\n\n5\nCarlo\n2\n2018\n98\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n7\nIrene\n4\n2018\n102\n\n\n8\nMaria\n1\n2019\n100\n\n\n9\nCarlo\n2\n2019\n102\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n11\nIrene\n4\n2019\n106\n\n\n12\nMaria\n1\n2020\n89\n\n\n13\nCarlo\n2\n2020\n95\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n15\nIrene\n4\n2020\n100\n\n\n16\nMaria\n1\n2021\n94\n\n\n17\nCarlo\n2\n2021\n96\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n19\nIrene\n4\n2021\n100\n\n\n20\nMaria\n1\n2022\n100\n\n\n21\nCarlo\n2\n2022\n104\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n23\nIrene\n4\n2022\n107\n\n\n\n\n\n\n\n\nPer migliorare la leggibilit√† dei dati, √® possibile riordinare le righe del set di dati utilizzando la funzione sort_values. In questo modo, le informazioni saranno presentate in un ordine specifico, che pu√≤ rendere pi√π facile la lettura dei dati.\n\nlong_data.sort_values(by=[\"ID\", \"Year\"])\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n4\nMaria\n1\n2018\n96\n\n\n8\nMaria\n1\n2019\n100\n\n\n12\nMaria\n1\n2020\n89\n\n\n16\nMaria\n1\n2021\n94\n\n\n20\nMaria\n1\n2022\n100\n\n\n1\nCarlo\n2\n2017\n87\n\n\n5\nCarlo\n2\n2018\n98\n\n\n9\nCarlo\n2\n2019\n102\n\n\n13\nCarlo\n2\n2020\n95\n\n\n17\nCarlo\n2\n2021\n96\n\n\n21\nCarlo\n2\n2022\n104\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n3\nIrene\n4\n2017\n91\n\n\n7\nIrene\n4\n2018\n102\n\n\n11\nIrene\n4\n2019\n106\n\n\n15\nIrene\n4\n2020\n100\n\n\n19\nIrene\n4\n2021\n100\n\n\n23\nIrene\n4\n2022\n107",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#copia-di-un-data-frame",
    "href": "chapters/chapter_1/04_pandas.html#copia-di-un-data-frame",
    "title": "6¬† Pandas (1)",
    "section": "6.12 Copia di un data frame",
    "text": "6.12 Copia di un data frame\nQuando in Python definiamo un nuovo data frame basandoci su un data frame esistente con l‚Äôistruzione new_df = old_df, √® importante essere consapevoli del fatto che non stiamo creando un nuovo data frame indipendente. In realt√†, new_df diventa solamente un riferimento all‚Äôoggetto originale old_df nell‚Äôambiente corrente. Questo significa che qualsiasi modifica apportata a new_df si rifletter√† automaticamente anche in old_df. In pratica, abbiamo un unico oggetto data frame accessibile attraverso due nomi diversi.\nPer creare effettivamente una copia indipendente di old_df, in modo che le modifiche apportate a questa copia non influiscano sull‚Äôoriginale, dobbiamo utilizzare il metodo .copy(). Questo metodo crea un nuovo oggetto data frame che √® una copia del data frame originale. L‚Äôistruzione corretta per fare ci√≤ in Python √® la seguente:\nnew_df = old_df.copy()\nUtilizzando old_df.copy(), otteniamo due data frame completamente indipendenti. Modifiche apportate a new_df non avranno alcun impatto su old_df, permettendoci di lavorare con i dati in modo sicuro e senza rischi di sovrascrittura o alterazione involontaria dei dati originali. Questa pratica √® fondamentale per mantenere l‚Äôintegrit√† dei dati e per gestire correttamente le variabili all‚Äôinterno di un programma Python.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "title": "6¬† Pandas (1)",
    "section": "6.13 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "6.13 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.2\npandas: 2.1.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/05_pandas_aggregate.html",
    "href": "chapters/chapter_1/05_pandas_aggregate.html",
    "title": "7¬† Pandas (2)",
    "section": "",
    "text": "7.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport arviz as az\nimport seaborn as sns\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nsns.set_theme(palette=\"colorblind\")\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = 'retina'",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "href": "chapters/chapter_1/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "title": "7¬† Pandas (2)",
    "section": "7.2 Calcolo delle statistiche descrittive",
    "text": "7.2 Calcolo delle statistiche descrittive\nAgli oggetti Pandas possono essere applicati vari metodi matematici e statistici. La maggior parte di questi rientra nella categoria della riduzione di dati o delle statistiche descrittive. Rispetto ai metodi degli array NumPy, i metodi Pandas consentono la gestione dei dati mancanti. Alcuni dei metodi disponibili per gli oggetti Pandas sono elencati di seguito.\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncount\nNumber of non-NA values\n\n\ndescribe\nCompute set of summary statistics\n\n\nmin, max\nCompute minimum and maximum values\n\n\nargmin, argmax\nCompute index locations (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects\n\n\nidxmin, idxmax\nCompute index labels at which minimum or maximum value is obtained, respectively\n\n\nquantile\nCompute sample quantile ranging from 0 to 1 (default: 0.5)\n\n\nsum\nSum of values\n\n\nmean\nMean of values\n\n\nmedian\nArithmetic median (50% quantile) of values\n\n\nmad\nMean absolute deviation from mean value\n\n\nprod\nProduct of all values\n\n\nvar\nSample variance of values\n\n\nstd\nSample standard deviation of values\n\n\nskew\nSample skewness (third moment) of values\n\n\nkurt\nSample kurtosis (fourth moment) of values\n\n\ncumsum\nCumulative sum of values\n\n\ncummin, cummax\nCumulative minimum or maximum of values, respectively\n\n\ncumprod\nCumulative product of values\n\n\ndiff\nCompute first arithmetic difference (useful for time series)\n\n\npct_change\nCompute percent changes\n\n\n\nTali metodi possono essere applicati a tutto il DataFrame, oppure soltanto ad una o pi√π colonne.\nPer fare un esempio, esamineremo nuovamente i dati penguins.csv. Come in precedenza, dopo avere caricato i dati, rimuoviamo i dati mancanti.\n\ndf = pd.read_csv(\"../../data/penguins.csv\")\ndf.dropna(inplace=True)\n\nUsiamo il metodo describe() su tutto il DataFrame:\n\ndf.describe(include=\"all\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\ncount\n333\n333\n333.000000\n333.000000\n333.000000\n333.000000\n333\n333.000000\n\n\nunique\n3\n3\nNaN\nNaN\nNaN\nNaN\n2\nNaN\n\n\ntop\nAdelie\nBiscoe\nNaN\nNaN\nNaN\nNaN\nmale\nNaN\n\n\nfreq\n146\n163\nNaN\nNaN\nNaN\nNaN\n168\nNaN\n\n\nmean\nNaN\nNaN\n43.992793\n17.164865\n200.966967\n4207.057057\nNaN\n2008.042042\n\n\nstd\nNaN\nNaN\n5.468668\n1.969235\n14.015765\n805.215802\nNaN\n0.812944\n\n\nmin\nNaN\nNaN\n32.100000\n13.100000\n172.000000\n2700.000000\nNaN\n2007.000000\n\n\n25%\nNaN\nNaN\n39.500000\n15.600000\n190.000000\n3550.000000\nNaN\n2007.000000\n\n\n50%\nNaN\nNaN\n44.500000\n17.300000\n197.000000\n4050.000000\nNaN\n2008.000000\n\n\n75%\nNaN\nNaN\n48.600000\n18.700000\n213.000000\n4775.000000\nNaN\n2009.000000\n\n\nmax\nNaN\nNaN\n59.600000\n21.500000\n231.000000\n6300.000000\nNaN\n2009.000000\n\n\n\n\n\n\n\n\nSe desideriamo solo le informazioni relative alle variabili qualitative, usiamo l‚Äôargomento include='object'.\n\ndf.describe(include=\"object\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nsex\n\n\n\n\ncount\n333\n333\n333\n\n\nunique\n3\n3\n2\n\n\ntop\nAdelie\nBiscoe\nmale\n\n\nfreq\n146\n163\n168\n\n\n\n\n\n\n\n\nI valori NaN indicano dati mancanti. Ad esempio, la colonna species contiene stringhe, quindi non esiste alcun valore per mean; allo stesso modo, bill_length_mm √® una variabile numerica, quindi non vengono calcolate le statistiche riassuntive per le variabili categoriali (unique, top, freq).\nEsaminimiamo le colonne singolarmente. Ad esempio, troviamo la media della colonna bill_depth_mm.\n\ndf[\"bill_depth_mm\"].mean()\n\n17.164864864864867\n\n\nPer la deviazione standard usiamo il metodo std(). Si noti l‚Äôargomento opzionale ddof:\n\ndf[\"bill_length_mm\"].std(ddof=1)\n\n5.46866834264756\n\n\nLa cella seguente fornisce l‚Äôindice della riga nella quale la colonna bill_length_mm assume il suo valore massimo:\n\ndf[\"bill_length_mm\"].idxmax()\n\n185\n\n\nLa colonna species nel DataFrame df √® una variabile a livello nominale. Elenchiamo le modalit√† di tale variabile.\n\ndf[\"species\"].unique()\n\narray(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n\nIl metodo value_counts ritorna la distribuzione di frequenza assoluta:\n\ndf[\"species\"].value_counts()\n\nspecies\nAdelie       146\nGentoo       119\nChinstrap     68\nName: count, dtype: int64\n\n\nPer le frequenze relative si imposta l‚Äôargomento normalize=True:\n\nprint(df[\"species\"].value_counts(normalize=True))\n\nspecies\nAdelie       0.438438\nGentoo       0.357357\nChinstrap    0.204204\nName: proportion, dtype: float64\n\n\nConsideriamo la lunghezza del becco dei pinguini suddivisa per ciascuna specie. Con l‚Äôistruzione seguente, possiamo generare gli istogrammi corrispondenti che rappresentano la distribuzione della lunghezza del becco in ciascun gruppo.\n\ncolor_fill = \"#b97c7c\"\n_ = df.hist(\n    column=\"bill_length_mm\",\n    by=[\"species\"],\n    bins=20,\n    figsize=(12, 4),\n    layout=(1, 3),\n    rwidth=0.9,\n    color=color_fill\n)\n\n\n\n\n\n\n\n\n\ndf\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n333 rows √ó 8 columns\n\n\n\n\n\n7.2.1 Aggregazione dei dati\nIl riepilogo di pi√π valori in un unico indice va sotto il nome di ‚Äúaggregazione‚Äù dei dati. Il metodo aggregate() pu√≤ essere applicato ai DataFrame e restituisce un nuovo DataFrame pi√π breve contenente solo i valori aggregati. Il primo argomento di aggregate() specifica quale funzione o quali funzioni devono essere utilizzate per aggregare i dati. Molte comuni funzioni di aggregazione sono disponibili nel modulo statistics. Ad esempio:\n\nmedian(): la mediana;\nmean(): la media;\nstdev(): la deviazione standard;\n\nSe vogliamo applicare pi√π funzioni di aggregazione, allora possiamo raccogliere prima le funzioni in una lista e poi passare la lista ad aggregate().\n\n# Lista delle funzioni statistiche di riepilogo come stringhe\nsummary_stats = [\"min\", \"median\", \"mean\", \"std\", \"max\"]\n\n# Calcola le statistiche di riepilogo per le colonne numeriche usando aggregate\nresult = df[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n].aggregate(summary_stats)\n\nprint(result)\n\n        bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\nmin          32.100000      13.100000         172.000000  2700.000000\nmedian       44.500000      17.300000         197.000000  4050.000000\nmean         43.992793      17.164865         200.966967  4207.057057\nstd           5.468668       1.969235          14.015765   805.215802\nmax          59.600000      21.500000         231.000000  6300.000000\n\n\nSi noti che Pandas ha applicato le funzioni di riepilogo a ogni colonna, ma, per alcune colonne, le statistiche riassuntive non si possono calcolare, ovvero tutte le colonne che contengono stringhe anzich√© numeri. Di conseguenza, vediamo che alcuni dei risultati per tali colonne sono contrassegnati con ‚ÄúNaN‚Äù. Questa √® un‚Äôabbreviazione di ‚ÄúNot a Number‚Äù, talvolta utilizzata nell‚Äôanalisi dei dati per rappresentare valori mancanti o non definiti.\nMolto spesso vogliamo calcolare le statistiche descrittive separatamente per ciascun gruppo di osservazioni ‚Äì per esempio, nel caso presente, potremmo volere distinguere le statistiche descrittive in base alla specie dei pinguini. Questo risultato si ottiene con il metodo .groupby().\nIl nome ‚Äúgroup by‚Äù deriva da un comando nel linguaggio del database SQL, ma forse √® pi√π semplice pensarlo nei termini coniati da Hadley Wickham: split, apply, combine. Un esempio canonico di questa operazione di split-apply-combine, in cui ‚Äúapply‚Äù √® un‚Äôaggregazione di sommatoria, √® illustrato nella figura seguente:\n\n\n\n\n\n\nFigura¬†7.1: Split, apply, combine.\n\n\n\nLa figura rende chiaro ci√≤ che si ottiene con groupby:\n\nla fase ‚Äúsplit‚Äù prevede la suddivisione e il raggruppamento di un DataFrame in base al valore della chiave specificata;\nla fase ‚Äúapply‚Äù implica il calcolo di alcune funzioni, solitamente un‚Äôaggregazione, una trasformazione o un filtro, all‚Äôinterno dei singoli gruppi;\nla fase ‚Äúcombine‚Äù unisce i risultati di queste operazioni in una matrice di output.\n\nPer esempio, ragruppiamo le osservazioni body_mass_g in funzione delle modalit√† della variabile species.\n\ngrouped = df[\"body_mass_g\"].groupby(df[\"species\"])\n\nCalcoliamo ora la media della variabile body_mass_g separatamente per ciascun gruppo di osservazioni.\n\ngrouped.mean()\n\nspecies\nAdelie       3706.164384\nChinstrap    3733.088235\nGentoo       5092.436975\nName: body_mass_g, dtype: float64\n\n\n√à possibile applicare criteri di classificazione multipli. Per fare un altro esempio, contiamo il numero di pinguini presenti sulle tre isole, distinguendoli per specie e genere.\n\ndf.groupby([\"island\", \"species\", \"sex\"]).size()\n\nisland     species    sex   \nBiscoe     Adelie     female    22\n                      male      22\n           Gentoo     female    58\n                      male      61\nDream      Adelie     female    27\n                      male      28\n           Chinstrap  female    34\n                      male      34\nTorgersen  Adelie     female    24\n                      male      23\ndtype: int64\n\n\nCon il metodo aggregate() possiamo applicare diverse funzioni di aggregazione alle osservazioni ragruppate. Ad esempio\n\nsummary_stats = [np.mean, np.std]\n# Group by \"species\" and calculate summary statistics for numeric columns\nresult = df.groupby(\"species\").agg(\n    {col: summary_stats for col in df.columns if pd.api.types.is_numeric_dtype(df[col])}\n)\n\nprint(result)\n\n          bill_length_mm           bill_depth_mm           flipper_length_mm  \\\n                    mean       std          mean       std              mean   \nspecies                                                                        \nAdelie         38.823973  2.662597     18.347260  1.219338        190.102740   \nChinstrap      48.833824  3.339256     18.420588  1.135395        195.823529   \nGentoo         47.568067  3.106116     14.996639  0.985998        217.235294   \n\n                     body_mass_g                     year            \n                std         mean         std         mean       std  \nspecies                                                              \nAdelie     6.521825  3706.164384  458.620135  2008.054795  0.811816  \nChinstrap  7.131894  3733.088235  384.335081  2007.970588  0.863360  \nGentoo     6.585431  5092.436975  501.476154  2008.067227  0.789025  \n\n\nNella cella seguente troviamo la media di body_mass_g e flipper_length_mm separatamente per ciascuna isola e ciascuna specie:\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].mean()\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n188.795455\n\n\nGentoo\n5092.436975\n217.235294\n\n\nDream\nAdelie\n3701.363636\n189.927273\n\n\nChinstrap\n3733.088235\n195.823529\n\n\nTorgersen\nAdelie\n3708.510638\n191.531915\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per la deviazione standard.\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].std(ddof=1)\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n487.733722\n6.729247\n\n\nGentoo\n501.476154\n6.585431\n\n\nDream\nAdelie\n448.774519\n6.480325\n\n\nChinstrap\n384.335081\n7.131894\n\n\nTorgersen\nAdelie\n451.846351\n6.220062\n\n\n\n\n\n\n\n\nPrestiamo attenzione alla seguente sintassi:\n\nsummary_stats = (\n    df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]\n    .groupby([\"island\", \"species\"])\n    .aggregate([\"mean\", \"std\", \"count\"])\n)\nsummary_stats\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\n\n\nmean\nstd\ncount\nmean\nstd\ncount\n\n\nisland\nspecies\n\n\n\n\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n487.733722\n44\n188.795455\n6.729247\n44\n\n\nGentoo\n5092.436975\n501.476154\n119\n217.235294\n6.585431\n119\n\n\nDream\nAdelie\n3701.363636\n448.774519\n55\n189.927273\n6.480325\n55\n\n\nChinstrap\n3733.088235\n384.335081\n68\n195.823529\n7.131894\n68\n\n\nTorgersen\nAdelie\n3708.510638\n451.846351\n47\n191.531915\n6.220062\n47\n\n\n\n\n\n\n\n\nNell‚Äôistruzione precedente selezioniamo tutte le righe (:) di tre colonne di interesse: df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]. L‚Äôistruzione .groupby([\"island\", \"species\"]) ragruppa le osservazioni (righe) secondo le modalit√† delle variabili island e species. Infine .aggregate([\"mean\", \"std\", \"count\"]) applica i metodi statistici specificati a ciascun gruppo di osservazioni. Con questa sintassi la sequenza delle operazioni da eseguire diventa molto intuitiva.\n√à possibile approfondire questo argomento consultanto il capitolo 10 del testo Python for Data Analysis di McKinney (2022).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "title": "7¬† Pandas (2)",
    "section": "7.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "7.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.11.4\nseaborn   : 0.13.0\nnumpy     : 1.26.2\npandas    : 2.1.4\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html",
    "href": "chapters/chapter_1/06_pandas_functions.html",
    "title": "8¬† Pandas (3)",
    "section": "",
    "text": "8.1 pd.read_csv, pd.read_excel\nLa prima funzione da menzionare √® read_csv o read_excel. Le funzioni vengono utilizzate per leggere un file CSV o un file Excel in formato DataFrame di Pandas. Qui stiamo utilizzando la funzione read_csv per leggere il dataset penguins. In precedenza abbiamo anche visto come la funzione dropna viene utilizzata per rimuovere tutte le righe del DataFrame che includono dati mancanti.\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#columns",
    "href": "chapters/chapter_1/06_pandas_functions.html#columns",
    "title": "8¬† Pandas (3)",
    "section": "8.2 .columns",
    "text": "8.2 .columns\nQuando si dispone di un grande dataset, pu√≤ essere difficile visualizzare tutte le colonne. Utilizzando la funzione columns, √® possibile stampare tutte le colonne del dataset.\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#drop",
    "href": "chapters/chapter_1/06_pandas_functions.html#drop",
    "title": "8¬† Pandas (3)",
    "section": "8.3 .drop()",
    "text": "8.3 .drop()\n√à possibile eliminare alcune colonne non necessarie utilizzando drop.\n\ndf = df.drop(columns=[\"year\"])\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#len",
    "href": "chapters/chapter_1/06_pandas_functions.html#len",
    "title": "8¬† Pandas (3)",
    "section": "8.4 len()",
    "text": "8.4 len()\nFornisce il numero di righe di un DataFrame.\n\nlen(df)\n\n333",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#query",
    "href": "chapters/chapter_1/06_pandas_functions.html#query",
    "title": "8¬† Pandas (3)",
    "section": "8.5 .query()",
    "text": "8.5 .query()\n√à possibile filtrare un DataFrame utilizzando un‚Äôespressione booleana.\n\ndf1 = df.query(\"species == 'Chinstrap' & island == 'Dream'\")\nlen(df1)\n\n68",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#iloc",
    "href": "chapters/chapter_1/06_pandas_functions.html#iloc",
    "title": "8¬† Pandas (3)",
    "section": "8.6 .iloc[]",
    "text": "8.6 .iloc[]\nQuesta funzione accetta come parametri gli indici delle righe e delle colonne, fornendo una selezione del DataFrame in base a questi. In questo caso, stiamo selezionando le prime 3 righe di dati e le colonne con indice 2, 3 e 5.\n\ndf2 = df.iloc[:3, [2, 3, 5]]\ndf2\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nbody_mass_g\n\n\n\n\n0\n39.1\n18.7\n3750.0\n\n\n1\n39.5\n17.4\n3800.0\n\n\n2\n40.3\n18.0\n3250.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#loc",
    "href": "chapters/chapter_1/06_pandas_functions.html#loc",
    "title": "8¬† Pandas (3)",
    "section": "8.7 .loc[]",
    "text": "8.7 .loc[]\nQuesta funzione compie un‚Äôoperazione molto simile a quella della funzione .iloc. Tuttavia, in questo caso, abbiamo la possibilit√† di specificare gli indici delle righe che desideriamo, insieme ai nomi delle colonne che vogliamo includere nella nostra selezione.\n\ndf3 = df.loc[[2, 4, 6], [\"island\", \"flipper_length_mm\", \"sex\"]]\ndf3\n\n\n\n\n\n\n\n\n\nisland\nflipper_length_mm\nsex\n\n\n\n\n2\nTorgersen\n195.0\nfemale\n\n\n4\nTorgersen\n193.0\nfemale\n\n\n6\nTorgersen\n181.0\nfemale",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "title": "8¬† Pandas (3)",
    "section": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.0\nnumpy     : 1.26.2\narviz     : 0.17.0\npandas    : 2.1.4\nmatplotlib: 3.8.2\nscipy     : 1.11.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html",
    "href": "chapters/chapter_1/07_matplotlib.html",
    "title": "9¬† Matplotlib",
    "section": "",
    "text": "9.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\n# Questa istruzione consente di visualizzare i grafici generati dai comandi di \n# plot direttamente all'interno del notebook.\n%config InlineBackend.figure_format = 'retina'\n\n# Questo valore viene usato come seed per il random number generator.\nRANDOM_SEED = 42\n\n# In questa riga, stai utilizzando il generatore di numeri casuali di NumPy per \n# creare una nuova istanza denominata rng. La funzione np.random.default_rng() viene \n# utilizzata per inizializzare un generatore di numeri casuali con un seme specifico, \n# che in questo caso √® RANDOM_SEED.\nrng = np.random.default_rng(RANDOM_SEED)\n\n# Queste due righe di codice sono spesso utilizzate per personalizzare l'aspetto dei \n# grafici in Python utilizzando le librerie ArviZ e Seaborn.\n# Questa riga di codice utilizza il metodo use() della libreria ArviZ per impostare uno \n# stile specifico per i tuoi grafici. In particolare, sta impostando lo stile chiamato \n# \"arviz-darkgrid\". Gli stili in ArviZ determinano come saranno visualizzati i grafici, inclusi colori, linee di griglia e altri dettagli estetici.\naz.style.use(\"arviz-darkgrid\")\n\n# Questa riga di codice utilizza la libreria Seaborn per impostare il tema dei grafici. \n# In questo caso, il tema viene impostato utilizzando set_theme() con il parametro palette \n# impostato su \"colorblind\". Questo significa che i colori utilizzati nei grafici saranno \n# scelti in modo da essere adatti alle persone con deficit visivi dei colori, rendendo i \n# grafici pi√π accessibili.\nsns.set_theme(palette=\"colorblind\")",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "href": "chapters/chapter_1/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "title": "9¬† Matplotlib",
    "section": "9.2 L‚ÄôInterfaccia pyplot per Creare Grafici",
    "text": "9.2 L‚ÄôInterfaccia pyplot per Creare Grafici\nMatplotlib √® una libreria in Python famosa per la creazione di grafici, e la sua interfaccia pyplot √® particolarmente apprezzata per la sua semplicit√†. Vediamo in dettaglio come funzionano le sue funzioni principali. Per comprendere meglio come funzionano le sue funzioni principali, possiamo fare un parallelo con il disegno su un supporto fisico.\n\nPrepariamo la Tela: Iniziamo con plt.figure(), che √® analogo a ottenere una tela bianca pronta per essere dipinta. √à il punto di partenza, una superficie vuota su cui creeremo il nostro grafico.\nDefiniamo le Aree di Disegno: Successivamente, utilizzando plt.subplot() o plt.axes(), creiamo delle aree specifiche o ‚Äúassi‚Äù sulla nostra tela. Questi assi corrispondono a diverse sezioni in cui posizioneremo vari elementi del nostro grafico, come se suddividessimo la tela fisica in diverse parti.\nAggiungiamo Elementi al Grafico: Una volta definiti gli assi, entriamo nel processo di creazione. Usandando funzioni come plt.plot() per tracciare linee o plt.scatter() per punti, aggiungiamo elementi grafici alla nostra area di disegno. √à simile a disegnare direttamente sulla tela fisica.\nRendiamo il Grafico Comprensibile: Per garantire che il grafico sia chiaro e informativo, aggiungiamo etichette e titoli con plt.xlabel(), plt.ylabel() e plt.title().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "href": "chapters/chapter_1/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "title": "9¬† Matplotlib",
    "section": "9.3 Principi Fondamentali di Pyplot",
    "text": "9.3 Principi Fondamentali di Pyplot\nEsploriamo le funzionalit√† essenziali di pyplot di Matplotlib:\n\nCreazione di Grafici Lineari: Utilizzando plt.plot(x, y), √® possibile generare grafici lineari. Questa funzione necessita delle coordinate x e y per disegnare il grafico, semplificando cos√¨ la rappresentazione visiva dei dati.\nDenominazione degli Assi: √à fondamentale assegnare un‚Äôetichetta appropriata agli assi per migliorare la comprensione del grafico. Si possono denominare gli assi tramite plt.xlabel('Nome') per l‚Äôasse X e plt.ylabel('Nome') per l‚Äôasse Y, facilitando l‚Äôinterpretazione dei dati visualizzati.\nInserimento del Titolo: Un titolo descrittivo clarifica lo scopo o il contesto del grafico. Aggiungere un titolo √® semplice con plt.title('Titolo'), che aiuta a comunicare il messaggio principale del grafico in modo efficace.\nInserimento di Legende: Per grafici che includono pi√π serie di dati o elementi distinti, l‚Äôaggiunta di una legenda √® cruciale per la distinzione tra questi. La funzione plt.legend() permette di integrare una legenda, migliorando la leggibilit√† del grafico.\nEsposizione del Grafico: Una volta completata la composizione del grafico, il passo finale √® la sua visualizzazione. Attraverso plt.show(), √® possibile mostrare il grafico elaborato, offrendo una visione complessiva dei dati analizzati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "title": "9¬† Matplotlib",
    "section": "9.4 Esempio 1: Grafico lineare semplice",
    "text": "9.4 Esempio 1: Grafico lineare semplice\n\nx = [1, 2, 3, 4]\ny = [10, 20, 30, 40]\n\nplt.plot(x, y)\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico Lineare Semplice\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "title": "9¬† Matplotlib",
    "section": "9.5 Esempio 2: Grafico con legenda e stile",
    "text": "9.5 Esempio 2: Grafico con legenda e stile\n\nx = [1, 2, 3, 4]\ny1 = [10, 20, 30, 40]\ny2 = [5, 15, 25, 35]\n\nplt.plot(x, y1, label=\"Linea 1\", color=\"C0\", linestyle=\"--\")\nplt.plot(x, y2, label=\"Linea 2\", color=\"C3\", linestyle=\"-\")\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico con Legenda\")\nplt.legend();",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-3-istogramma",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-3-istogramma",
    "title": "9¬† Matplotlib",
    "section": "9.6 Esempio 3: Istogramma",
    "text": "9.6 Esempio 3: Istogramma\n\ndata = rng.normal(100, 15, 1000)\n\nplt.hist(data, bins=20)\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Istogramma\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-4-pannelli-multipli",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-4-pannelli-multipli",
    "title": "9¬† Matplotlib",
    "section": "9.7 Esempio 4: pannelli multipli",
    "text": "9.7 Esempio 4: pannelli multipli\nFacciamo un altro esempio usando i dati penguins.csv.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\n\n\nplt.figure(figsize=(9, 8))\n\nplt.subplot(2, 2, 1)\nplt.hist(df[\"bill_depth_mm\"], 10, density=True, color=\"C3\")\nplt.title(\"Bill depth (mm)\");\n\nplt.subplot(2, 2, 2)\nsns.kdeplot(df[\"bill_length_mm\"], fill=True)\nplt.title(\"KDE of Bill length (mm)\");\n\nplt.subplot(2, 2, 3)\nplt.scatter(x=df[\"bill_length_mm\"], y=df[\"bill_depth_mm\"], alpha=0.4)\nplt.title(\"Bill depth as a function of bill length\");\n\nplt.subplot(2, 2, 4)\nplt.boxplot(df[\"bill_length_mm\"])\nplt.title(\"Boxplot of Bill Length (mm)\")\n\nplt.tight_layout()\n\n/var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_55046/1324325854.py:19: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nGli indici in plt.subplot() sono utilizzati per specificare come dividere una figura in diverse aree di tracciamento, chiamate ‚Äúsubplots‚Äù. La funzione plt.subplot(nrows, ncols, index) prende tre argomenti principali:\n\nnrows: Numero di righe in cui la figura sar√† suddivisa.\nncols: Numero di colonne in cui la figura sar√† suddivisa.\nindex: Indice del subplot su cui operare, partendo dall‚Äôangolo in alto a sinistra e proseguendo da sinistra a destra e dall‚Äôalto in basso.\n\nNel codice precedente, plt.subplot(2, 2, 1) indica che la figura sar√† divisa in una griglia 2x2 (2 righe e 2 colonne) e che la funzione plt.hist() agir√† sul primo subplot, che si trover√† nell‚Äôangolo in alto a sinistra.\nGli altri indici (2, 3, 4) selezionano rispettivamente il secondo subplot (in alto a destra), il terzo subplot (in basso a sinistra) e il quarto subplot (in basso a destra) della griglia 2x2.\nEcco come i subplot sono organizzati sulla figura:\n+---------------------+----------------------+\n|  plt.subplot(2,2,1) |  plt.subplot(2,2,2)  |\n+---------------------+----------------------+\n|  plt.subplot(2,2,3) |  plt.subplot(2,2,4)  |\n+---------------------+----------------------+\nOgni volta che si chiama plt.subplot() con un nuovo indice, il ‚Äúcurrent axes‚Äù cambia per puntare al subplot specificato. Quindi, le funzioni di tracciamento come plt.hist(), sns.kdeplot(), plt.scatter() e plt.boxplot() saranno applicate al subplot attualmente selezionato.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "title": "9¬† Matplotlib",
    "section": "9.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "9.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\narviz     : 0.17.0\nmatplotlib: 3.8.2\npandas    : 2.1.4\nseaborn   : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html",
    "href": "chapters/chapter_1/08_seaborn.html",
    "title": "10¬† Seaborn",
    "section": "",
    "text": "10.1 Elevare la Visualizzazione dei Dati con Seaborn\nNel capitolo precedente, abbiamo esaminato Matplotlib, una libreria estremamente versatile per la visualizzazione dei dati in Python. Ora esamineremo le funzionalit√† di Seabonrn. Seaborn, che si basa su Matplotlib, arricchisce l‚Äôesperienza di visualizzazione dei dati offrendo una gamma pi√π ampia e specializzata di opzioni grafiche, particolarmente utili nel campo della data science.\nIl vero punto di forza di Seaborn √® la sua capacit√† di migliorare non solo l‚Äôaspetto estetico dei grafici ma anche di facilitare la creazione di visualizzazioni pi√π complesse. Questo rende il processo pi√π diretto e intuitivo. La libreria √® dotata di un‚Äôampia variet√† di strumenti, dalle mappe di calore ai grafici a violino, permettendo agli utenti di esplorare e rappresentare i dati in modi innovativi e informativi.\nPer chi vuole approfondire ulteriormente, i tutorial presenti sul sito ufficiale di Seaborn sono una risorsa preziosa e facilmente accessibile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#preparazione-del-notebook",
    "href": "chapters/chapter_1/08_seaborn.html#preparazione-del-notebook",
    "title": "10¬† Seaborn",
    "section": "10.2 Preparazione del Notebook",
    "text": "10.2 Preparazione del Notebook\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport arviz as az\n\n\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"seaborn\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "href": "chapters/chapter_1/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "title": "10¬† Seaborn",
    "section": "10.3 Visualizzare la distribuzione dei dati",
    "text": "10.3 Visualizzare la distribuzione dei dati\nVediamo alcuni esempi pratici per scoprire come Seaborn possa trasformare il modo in cui visualizziamo i dati.\nConsideriamo nuovamente i dati Palmer penguin.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nUna delle forme di visualizzazione pi√π comuni e informative nel campo dell‚Äôanalisi dei dati √® l‚Äôistogramma, e la sua variante pi√π sofisticata, l‚Äôistogramma lisciato. Vediamo dunque come generare istogrammi che, per il DataFrame df, sono stratificati sia in base alla specie che al genere dei pinguini.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n);\n\nGeneriamo la stessa figura usando questa volta gli istogrammi lisciati.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    height=3, kind=\"kde\", facet_kws=dict(margin_titles=True),\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "href": "chapters/chapter_1/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "title": "10¬† Seaborn",
    "section": "10.4 Visualizzazione di dati categoriali",
    "text": "10.4 Visualizzazione di dati categoriali\nConsideriamo ora il caso in cui si vuole rappresentare la relazione tra una variabile numerica e una o pi√π variabili categoriali.\nConsideriamo, ad esempio, la massa corporea in relazione alla specie, differenziando le osservazioni per genere. Creiamo il grafico utilizzando i boxplot.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"box\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\n\n\n\nDai diagrammi risulta evidente che i pinguini maschi hanno un peso maggiore rispetto alle femmine in tutte le specie, e che i pinguini Gentoo hanno un peso superiore rispetto ad Adelie e Chinstrap.\nCome alternativa, possiamo utilizzare il violinplot per la rappresentazione grafica dei dati.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"violin\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#relazioni-tra-variabili",
    "href": "chapters/chapter_1/08_seaborn.html#relazioni-tra-variabili",
    "title": "10¬† Seaborn",
    "section": "10.5 Relazioni tra variabili",
    "text": "10.5 Relazioni tra variabili\nCalcoliamo la correlazione tra le variabili.\n\nvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\ncorr_matrix = df[vars].corr().round(2)\ncorr_matrix\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.00\n-0.24\n0.66\n0.60\n\n\nbill_depth_mm\n-0.24\n1.00\n-0.58\n-0.47\n\n\nflipper_length_mm\n0.66\n-0.58\n1.00\n0.87\n\n\nbody_mass_g\n0.60\n-0.47\n0.87\n1.00\n\n\n\n\n\n\n\n\nQueste informazioni possono essere comunicate in forma pi√π diretta se usiamo una rappresentazione grafica.\n\nsns.heatmap(corr_matrix, annot=True, linecolor=\"white\", linewidths=5);\n\n\n\n\n\n\n\n\nLa lunghezza della pinna e la massa corporea mostrano un forte legame, con una correlazione di 0.87. Ci√≤ indica che i pinguini con pinne pi√π lunghe tendono a pesare di pi√π.\nDi seguito √® riportato un esempio di diagramma a dispersione che illustra questa relazione.\n\nsns.scatterplot(df, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\");\n\n\n\n\n\n\n\n\nEvidentemente, le osservazioni delle tre specie formano cluster distinti. Per ciascuna specie, la lunghezza e la larghezza del becco presentano un intervallo specifico.\nSpesso √® vantaggioso creare grafici separati in base a diverse dimensioni dei dati; nell‚Äôesempio seguente, suddividiamo i dati in base all‚Äôisola di appartenenza.\n\ng = sns.relplot(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    row=\"sex\",\n    col=\"island\",\n    height=3,\n    facet_kws=dict(margin_titles=True),\n)\ng.set_axis_labels(\n    \"Bill length (mm)\",\n    \"Bill depth (mm)\",\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "title": "10¬† Seaborn",
    "section": "10.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "10.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\narviz     : 0.18.0\npandas    : 2.2.2\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/introduction_chapter_2.html",
    "href": "chapters/chapter_2/introduction_chapter_2.html",
    "title": "11¬† Introduzione",
    "section": "",
    "text": "La data science √® un campo che si sviluppa all‚Äôintersezione tra la statistica e l‚Äôinformatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l‚Äôinformatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica descrittiva. Oltre alle definizioni teoriche, verranno fornite istruzioni in Python necessarie per svolgere analisi statistiche su dati reali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html",
    "href": "chapters/chapter_2/00_scientific_method.html",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "",
    "text": "Introduzione\nLa psicologia, come molte altre discipline scientifiche, ha affrontato sfide significative negli ultimi anni, in particolare per quanto riguarda la cosiddetta crisi della replicabilit√† (Baker 2016; Collaboration 2015; Ioannidis 2005). Questa crisi ha messo in luce la necessit√† di pratiche di ricerca pi√π robuste, trasparenti e riproducibili. In risposta a queste sfide, molti psicologi hanno adottato nuove metodologie e strumenti, e la data science √® emersa come una componente cruciale per affrontare questi problemi e far progredire il campo.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#la-crisi-della-replicabilit√†-in-psicologia",
    "href": "chapters/chapter_2/00_scientific_method.html#la-crisi-della-replicabilit√†-in-psicologia",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "12.1 La Crisi della Replicabilit√† in Psicologia",
    "text": "12.1 La Crisi della Replicabilit√† in Psicologia\nLa crisi della replicabilit√† si riferisce alla difficolt√† di riprodurre o replicare i risultati di molti studi psicologici. Questo problema ha sollevato preoccupazioni sulla affidabilit√† e validit√† della ricerca psicologica, portando a una rivalutazione delle pratiche e delle metodologie di ricerca.\nDiversi fattori hanno contribuito a questa crisi. Tra questi, possiamo annoverare la tendenza a pubblicare prevalentemente risultati positivi, l‚Äôuso di campioni troppo piccoli che portano a studi con potenza statistica insufficiente, la mancanza di trasparenza nei metodi di ricerca e nella condivisione dei dati, e l‚Äôuso di pratiche di ricerca discutibili come il p-hacking. Inoltre, molti studi empirici si basavano su fondamenti teorici insufficienti, rendendo difficile l‚Äôinterpretazione e la generalizzazione dei risultati (Nuzzo 2014).\nPer affrontare questi problemi, gli psicologi hanno implementato varie misure. Tra queste, la pre-registrazione degli studi √® diventata una pratica sempre pi√π comune. Questo approccio richiede ai ricercatori di specificare in anticipo i loro metodi e ipotesi, riducendo il rischio di bias nella segnalazione dei risultati. Inoltre, la condivisione aperta dei dati e del codice utilizzato nelle analisi √® diventata una pratica incoraggiata, se non richiesta, da molte riviste scientifiche. Questa trasparenza permette ad altri ricercatori di verificare e replicare i risultati, aumentando la fiducia nelle scoperte pubblicate.\nUn‚Äôaltra iniziativa importante √® stata l‚Äôavvio di sforzi di replicazione su larga scala. Questi progetti coinvolgono numerosi laboratori che lavorano insieme per replicare studi importanti, fornendo una valutazione pi√π robusta della validit√† dei risultati originali (McShane et al. 2019). Parallelamente, c‚Äô√® stata una maggiore enfasi sull‚Äôuso di pratiche statistiche migliorate, come l‚Äôattenzione alle dimensioni dell‚Äôeffetto e agli intervalli di credibilit√†, piuttosto che concentrarsi esclusivamente sulla significativit√† statistica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#la-necessit√†-della-data-science-in-psicologia",
    "href": "chapters/chapter_2/00_scientific_method.html#la-necessit√†-della-data-science-in-psicologia",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "12.2 La Necessit√† della Data Science in Psicologia",
    "text": "12.2 La Necessit√† della Data Science in Psicologia\nIn questo contesto di crisi e rinnovamento, la data science √® emersa come uno strumento critico per affrontare la crisi della replicabilit√† e far progredire la ricerca psicologica. L‚Äôintegrazione della data science nella ricerca psicologica offre numerosi vantaggi che vanno oltre le pratiche statistiche tradizionali.\nIn primo luogo, le tecniche di data science forniscono metodi pi√π sofisticati per l‚Äôanalisi di dataset complessi. Questo permette ai ricercatori di estrarre insight significativi e pattern che potrebbero essere sfuggiti agli approcci statistici tradizionali. Ad esempio, l‚Äôuso di tecniche di machine learning pu√≤ rivelare relazioni non lineari tra variabili o identificare sottogruppi all‚Äôinterno di campioni pi√π ampi, portando a una comprensione pi√π sfumata dei fenomeni psicologici.\nUn altro vantaggio significativo dell‚Äôadozione delle pratiche di data science √® il miglioramento della riproducibilit√† della ricerca. L‚Äôuso di strumenti come il controllo di versione, l‚Äôelaborazione automatizzata dei dati e pipeline di analisi riproducibili permette ai ricercatori di garantire che il loro lavoro sia pi√π facilmente verificabile e replicabile da altri. Questo non solo aumenta la fiducia nei risultati pubblicati, ma facilita anche la collaborazione e l‚Äôaccumulo di conoscenze nel campo.\nLa capacit√† della data science di gestire e analizzare dataset su larga scala apre anche nuove strade per la ricerca psicologica. Con l‚Äôaumento della disponibilit√† di dati provenienti da fonti diverse come social media, dispositivi indossabili e registrazioni comportamentali in tempo reale, i ricercatori possono studiare pattern comportamentali complessi e integrare fonti di dati diverse in modi precedentemente impossibili. Questo permette di affrontare questioni di ricerca su scala pi√π ampia e con maggiore granularit√†.\nInfine, le tecniche di data science permettono lo sviluppo di modelli predittivi, che possono aiutare a validare teorie e generare nuove ipotesi nella ricerca psicologica. Questi modelli non solo forniscono insight sui meccanismi sottostanti i fenomeni psicologici, ma possono anche avere applicazioni pratiche in settori come la psicologia clinica e delle organizzazioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#teorie-e-modelli-formali-in-psicologia",
    "href": "chapters/chapter_2/00_scientific_method.html#teorie-e-modelli-formali-in-psicologia",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "12.3 Teorie e Modelli Formali in Psicologia",
    "text": "12.3 Teorie e Modelli Formali in Psicologia\nMentre l‚Äôaffrontare le questioni empiriche √® cruciale, c‚Äô√® anche la necessit√† di basi teoriche pi√π solide in psicologia. Le teorie e i modelli formali giocano un ruolo vitale in questo contesto. Le teorie formali forniscono un quadro preciso per descrivere le relazioni tra variabili, riducendo l‚Äôambiguit√† e l‚Äôarbitrariet√† nell‚Äôinterpretazione dei risultati. Permettono di formulare previsioni chiare e verificabili, e consentono una valutazione rigorosa delle spiegazioni teoriche.\nLa valutazione delle spiegazioni teoriche in psicologia pu√≤ basarsi su criteri chiave come la precisione, la robustezza e la rilevanza empirica (Van Dongen et al. 2024). La precisione si riferisce alla specificit√† con cui una teoria √® formulata. Una teoria precisa specifica chiaramente i suoi componenti e le relazioni tra di essi, riducendo le decisioni arbitrarie nella costruzione di modelli formali coerenti.\nLa robustezza misura la capacit√† dei modelli formali, coerenti con una teoria, di produrre il fenomeno di interesse in diverse condizioni. Una spiegazione robusta rimane valida sotto diverse condizioni e parametri, dimostrando la sua generalizzabilit√†.\nLa rilevanza empirica valuta quanto i componenti specifici di una teoria siano necessari per produrre il modello statistico del fenomeno osservato. Una teoria con alta rilevanza empirica richiede elementi teorici specifici per spiegare il fenomeno, non solo assunzioni di base.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#i-modelli-come-strumenti-per-comprendere-la-realt√†",
    "href": "chapters/chapter_2/00_scientific_method.html#i-modelli-come-strumenti-per-comprendere-la-realt√†",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "12.4 I Modelli come Strumenti per Comprendere la Realt√†",
    "text": "12.4 I Modelli come Strumenti per Comprendere la Realt√†\n√à importante riconoscere che i modelli scientifici, inclusi quelli in psicologia, sono strumenti essenziali per comprendere il mondo che ci circonda, ma non sono descrizioni ‚Äúvere‚Äù della realt√†. Sono piuttosto rappresentazioni che ci permettono di esplorare, testare e approfondire la nostra conoscenza dei fenomeni naturali.\nIl processo di costruzione, test e revisione dei modelli √® spesso pi√π prezioso del risultato finale. Questo processo iterativo ci permette di affinare progressivamente la nostra comprensione, mettendo alla prova le nostre ipotesi e scoprendo i limiti delle nostre teorie. √à attraverso questo ciclo di ipotesi, test e revisione che la scienza progredisce.\n√à anche fondamentale riconoscere la dualit√† tra il ‚Äúmondo del modello‚Äù - il contesto specifico in cui il modello opera - e il mondo reale pi√π ampio di cui vogliamo parlare (McElreath 2020). I dataset su cui addestriamo i modelli spesso non sono completamente rappresentativi delle popolazioni reali in certi aspetti. Questo non significa che i modelli addestrati su tali dati siano privi di valore, ma richiede una consapevolezza critica dei loro limiti e delle loro applicazioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#il-ruolo-della-statistica-nel-processo-scientifico",
    "href": "chapters/chapter_2/00_scientific_method.html#il-ruolo-della-statistica-nel-processo-scientifico",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "12.5 Il Ruolo della Statistica nel Processo Scientifico",
    "text": "12.5 Il Ruolo della Statistica nel Processo Scientifico\nLa statistica e la data science giocano un ruolo fondamentale nel processo scientifico moderno, particolarmente in psicologia. Tuttavia, √® importante considerare alcune sfumature. La validit√† statistica si basa su determinate assunzioni che potrebbero non essere sempre soddisfatte nei contesti di ricerca specifici. Mentre ci√≤ che viene insegnato nella teoria statistica √® corretto, le circostanze specifiche della ricerca potrebbero non soddisfare i criteri di partenza.\nInoltre, il processo scientifico reale √® spesso pi√π complesso del percorso lineare presentato in teoria. Gli scienziati reagiscono agli incentivi, fanno tentativi, formulano ipotesi e seguono la loro intuizione, spesso superando le metodologie convenzionali per giungere a scoperte innovative. Mentre √® fondamentale una comprensione approfondita dei concetti statistici e metodologici, √® altrettanto importante sviluppare la capacit√† di riconoscere quando √® necessario andare oltre le metodologie convenzionali per perseguire nuove intuizioni o approcci.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#implicazioni-epistemologiche",
    "href": "chapters/chapter_2/00_scientific_method.html#implicazioni-epistemologiche",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "12.6 Implicazioni Epistemologiche",
    "text": "12.6 Implicazioni Epistemologiche\nL‚Äôuso della data science e dei modelli in psicologia ha diverse implicazioni epistemologiche. In primo luogo, √® importante riconoscere che i modelli sono strumenti di apprendimento piuttosto che rappresentazioni definitive della realt√†. Il loro valore risiede nella loro capacit√† di generare intuizioni, testare ipotesi e guidare ulteriori indagini.\nIn secondo luogo, il processo scientifico, attraverso l‚Äôuso di modelli e tecniche di data science, √® caratterizzato da un ciclo continuo di ipotesi, test e revisione. Questo approccio iterativo permette un raffinamento progressivo della nostra comprensione, ma richiede anche una costante vigilanza contro la tendenza a reificare i nostri modelli o a confonderli con la realt√† che cercano di rappresentare.\nInfine, una comprensione critica dei modelli richiede una costante consapevolezza dei loro limiti, delle assunzioni sottostanti e del contesto in cui sono stati sviluppati. Questa consapevolezza non diminuisce il valore dei modelli, ma ci permette di utilizzarli in modo pi√π efficace e responsabile.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#conclusione",
    "href": "chapters/chapter_2/00_scientific_method.html#conclusione",
    "title": "12¬† Il Ruolo della Data Science nella Psicologia",
    "section": "12.7 Conclusione",
    "text": "12.7 Conclusione\nLa data science gioca un ruolo cruciale nell‚Äôaffrontare la crisi della replicabilit√† in psicologia e nel far progredire il rigore scientifico del campo. Fornendo strumenti per un‚Äôanalisi dei dati migliorata, una maggiore riproducibilit√† e lo sviluppo di teorie formali, la data science contribuisce a una scienza psicologica pi√π robusta e affidabile.\nTuttavia, √® essenziale mantenere una prospettiva critica sui limiti e le assunzioni sottostanti ai nostri modelli e alle nostre analisi. Mentre la psicologia continua a evolversi, l‚Äôintegrazione delle metodologie di data science sar√† vitale per garantire la validit√† scientifica e la rilevanza del campo. Allo stesso tempo, questa integrazione deve essere guidata da una solida base teorica e da una comprensione profonda dei fenomeni psicologici che cerchiamo di studiare.\nIn definitiva, la combinazione di robusti metodi di data science con una solida teoria psicologica offre la promessa di una comprensione pi√π profonda e affidabile del comportamento umano e dei processi mentali.\n\n\n\n\nBaker, Monya. 2016. ¬´1,500 scientists lift the lid on reproducibility¬ª. Nature 533 (7604).\n\n\nCollaboration, Open Science. 2015. ¬´Estimating the reproducibility of psychological science¬ª. Science 349 (6251): aac4716.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nLabatut, Benjamƒ±ÃÅn. 2021. Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nMcShane, Blakeley B, Jennifer L Tackett, Ulf B√∂ckenholt, e Andrew Gelman. 2019. ¬´Large-scale replication projects in contemporary psychological research¬ª. The American Statistician 73 (sup1): 99‚Äì105.\n\n\nNuzzo, Regina. 2014. ¬´Scientific method: statistical errors.¬ª Nature 506 (7487).\n\n\nVan Dongen, Noah, Riet van Bork, Adam Finnemann, Jonas Haslbeck, Han LJ van der Maas, Donald J Robinaugh, Jill de Ron, Jan Sprenger, e Denny Borsboom. 2024. ¬´Productive explanation: A framework for evaluating explanations in psychological science.¬ª Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Il Ruolo della Data Science nella Psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html",
    "href": "chapters/chapter_2/01_key_notions.html",
    "title": "13¬† Concetti chiave",
    "section": "",
    "text": "Introduzione\nL‚Äôanalisi dei dati si colloca all‚Äôintersezione tra statistica, teoria della probabilit√† e informatica. Questa disciplina multidisciplinare richiede una solida comprensione dei concetti fondamentali provenienti da ciascuna di queste tre aree.\nLa statistica fornisce gli strumenti e le tecniche per raccogliere, analizzare e interpretare i dati. Attraverso metodi descrittivi e inferenziali, la statistica permette di trarre conclusioni dai dati e di prendere decisioni informate.\nLa teoria della probabilit√† costituisce la base matematica della statistica. Essa consente di modellare l‚Äôincertezza e di comprendere i fenomeni aleatori, fornendo i fondamenti per sviluppare metodi statistici rigorosi.\nL‚Äôinformatica gioca un ruolo cruciale nell‚Äôanalisi dei dati, offrendo gli strumenti necessari per la gestione, l‚Äôelaborazione e la visualizzazione dei dati su larga scala. Conoscere i principi dell‚Äôinformatica √® essenziale per sfruttare appieno le tecnologie moderne, come il machine learning e l‚Äôintelligenza artificiale, nell‚Äôanalisi dei dati. Ad esempio, l‚Äôuso di linguaggi di programmazione come Python e R, insieme a librerie specializzate, permette di eseguire analisi complesse e di visualizzare i dati in modo efficace.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#introduzione",
    "href": "chapters/chapter_2/01_key_notions.html#introduzione",
    "title": "13¬† Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine ‚Äústatistica‚Äù pu√≤ assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica √® una scienza e una disciplina che si occupa dello studio e dell‚Äôapplicazione di metodi e tecniche per la raccolta, l‚Äôorganizzazione, l‚Äôanalisi, l‚Äôinterpretazione e la presentazione di dati.\nNel secondo senso, il termine ‚Äústatistica‚Äù si riferisce a una singola misura o un valore numerico che √® stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#popolazioni-e-campioni",
    "href": "chapters/chapter_2/01_key_notions.html#popolazioni-e-campioni",
    "title": "13¬† Concetti chiave",
    "section": "13.1 Popolazioni e Campioni",
    "text": "13.1 Popolazioni e Campioni\nPer iniziare l‚Äôanalisi dei dati, √® fondamentale individuare le unit√† che contengono le informazioni rilevanti per il fenomeno di interesse. Questo insieme di unit√† costituisce la popolazione o universo, che rappresenta l‚Äôinsieme completo di entit√† capaci di fornire informazioni per l‚Äôindagine statistica in questione. Possiamo rappresentare la popolazione come \\(N\\) o \\(\\infty\\) nel caso di popolazioni finite o infinite, rispettivamente. Le singole unit√† dell‚Äôinsieme sono chiamate unit√† statistiche.\nNella ricerca psicologica, sia nelle ricerche sperimentali che in quelle osservazionali, l‚Äôobiettivo principale √® studiare i fenomeni psicologici all‚Äôinterno di una specifica popolazione. Pertanto, √® essenziale definire con chiarezza la popolazione di interesse, ovvero l‚Äôinsieme di individui ai quali verranno applicati i risultati della ricerca. Tale popolazione pu√≤ essere reale, come ad esempio tutte le persone sopravvissute per un anno dopo il bombardamento atomico di Hiroshima, o ipotetica, come ad esempio tutte le persone depresse che potrebbero beneficiare di un intervento psicologico. Il ricercatore deve sempre essere in grado di identificare se un individuo specifico appartiene o meno alla popolazione in questione.\n\n13.1.1 Sotto-popolazioni e Campioni\nUna sotto-popolazione √® un sottoinsieme di individui che possiedono propriet√† specifiche ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione degli uomini di et√† inferiore ai 30 anni o alla sotto-popolazione dei pazienti depressi che hanno ricevuto uno specifico intervento psicologico. Molte questioni scientifiche cercano di descrivere le differenze tra sotto-popolazioni, come ad esempio il confronto tra un gruppo di pazienti sottoposti a psicoterapia e un gruppo di controllo per valutare l‚Äôefficacia di un trattamento.\nIl campione √® un sottoinsieme della popolazione composto da un insieme di elementi, ognuno dei quali rappresenta un‚Äôunit√† statistica (abbreviata con u.s.) portatrice delle informazioni che verranno rilevate tramite un‚Äôoperazione di misurazione. Il campione viene utilizzato per ottenere informazioni sulla popolazione di riferimento.\n\n\n13.1.2 Metodi di Campionamento\nIl campionamento pu√≤ avvenire in diversi modi. Il campionamento casuale consente al ricercatore di trarre conclusioni sulla popolazione e di quantificare l‚Äôincertezza dei risultati. Un esempio di campione casuale √® quello utilizzato in un sondaggio. Tuttavia, esistono anche altre forme di campionamento, come il campione di convenienza, in cui si seleziona una coorte di studenti da un unico istituto, o il campionamento stratificato, dove la popolazione viene divisa in gruppi o strati, e vengono selezionati campioni proporzionali da ciascuno strato.\nIl ricercatore, indipendentemente dal metodo di acquisizione dei dati, deve sempre considerare la questione della rappresentativit√† statistica del campione, ovvero se il campione scelto √® in grado di riflettere in modo accurato e privo di distorsioni le caratteristiche di interesse della popolazione. Selezionare le unit√† statistiche in modo casuale rappresenta il metodo pi√π semplice per garantire la rappresentativit√† del campione. Tuttavia, in molti casi, soprattutto in psicologia, i ricercatori possono non avere a disposizione le risorse necessarie, inclusi i fondi, per utilizzare la tecnica del campionamento casuale nelle loro ricerche. In tali situazioni, possono ricorrere ad altri metodi di campionamento, come il campionamento di convenienza, a seconda delle esigenze e delle risorse disponibili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#variabili-e-costanti",
    "href": "chapters/chapter_2/01_key_notions.html#variabili-e-costanti",
    "title": "13¬† Concetti chiave",
    "section": "13.2 Variabili e Costanti",
    "text": "13.2 Variabili e Costanti\nNell‚Äôambito dell‚Äôanalisi statistica, le variabili rappresentano concetti centrali, denotando le caratteristiche o gli attributi che possono assumere una variet√† di valori, numerici o categoriali. Essi incarnano gli elementi quantificabili o osservabili ai quali le unit√† statistiche danno riscontro. Ad esempio, ponendo la domanda ‚ÄúQual √® l‚Äôet√† di questo partecipante?‚Äù e ottenendo come risposta ‚Äú19 anni‚Äù, si identifica ‚Äúet√†‚Äù come la variabile, e ‚Äú19‚Äù come il valore corrispondente.\n\n13.2.1 Tipi di Variabili\nIn pratica, nel contesto della ricerca empirica, una variabile rappresenta un insieme di osservazioni relative alla stessa misurazione, come ad esempio il punteggio di ‚Äúnevrosismo‚Äù ottenuto da interviste condotte su 744 bambini. Descrivere una variabile significa essere in grado di prendere tali osservazioni e comunicare chiaramente il loro significato, senza obbligare chi legge a dover esaminare ciascuno dei 744 punteggi di nevrosismo separatamente. Questo compito non √® affatto semplice.\nPossiamo distinguere varie classi di variabili:\n\nVariabili continue: Possono assumere valori in un intervallo potenzialmente infinito.\nVariabili di conteggio: Rappresentano la frequenza con cui si verificano eventi o la quantit√† di oggetti in una categoria specifica.\nVariabili ordinali: Caratterizzate da un ordine intrinseco tra i loro valori, ma non esiste una scala standard per quantificare la differenza tra essi.\nVariabili categoriche: Utilizzate per assegnare categorie o classi a un‚Äôosservazione, indicando a quale categoria appartiene.\nVariabili binarie: Una sottocategoria di variabili categoriche che possono assumere solo due valori distinti.\n\nLe modalit√† descrivono le diverse forme che una variabile statistica pu√≤ assumere. L‚Äôinsieme delle modalit√† di una variabile √® rappresentato dall‚Äôinsieme \\(\\mathcal{X}\\), che include tutte le possibili manifestazioni della variabile. Le modalit√† presenti nel campione vengono etichettate come dati.\nIn statistica, la nozione di ‚Äúvariabile‚Äù si distingue da quella di ‚Äúcostante‚Äù, che rimane immutabile attraverso tutte le unit√† statistiche.\n\nEsempio 1: In uno studio relativo all‚Äôintelligenza degli adulti italiani, la variabile di interesse √® il punteggio nel test WAIS-IV, con modalit√† quali 112, 92, 121 ecc. Questa variabile √® classificata come quantitativa discreta.\nEsempio 2: Nell‚Äôanalisi del compito Stroop, focalizzata su bambini di et√† 6-8 anni, la variabile in esame √® l‚Äôinverso dei tempi di reazione, misurati in secondi, con modalit√† come 1.93, 2.35, 1.32 ecc. Questa variabile √® classificata come quantitativa continua.\nEsempio 3: In uno studio del disturbo di personalit√† condotto tra i detenuti nelle carceri italiane, la variabile scrutinata √® l‚Äôassessment del disturbo di personalit√†, valutato attraverso interviste cliniche strutturate. Le modalit√† sono i Cluster A, Cluster B, Cluster C, secondo la classificazione del DSM-V, e questa variabile √® classificata come qualitativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#la-distribuzione-delle-variabili",
    "href": "chapters/chapter_2/01_key_notions.html#la-distribuzione-delle-variabili",
    "title": "13¬† Concetti chiave",
    "section": "13.3 La Distribuzione delle Variabili",
    "text": "13.3 La Distribuzione delle Variabili\nUna volta compreso il tipo di variabile con cui lavoriamo, √® fondamentale esaminare la distribuzione di tale variabile. La distribuzione di una variabile rappresenta la frequenza con cui si verificano i diversi valori. Nel caso delle variabili discrete, la distribuzione √® semplicemente un elenco delle modalit√† (valori distinti) e delle relative frequenze. Ad esempio, se consideriamo la variabile ‚Äúgenere‚Äù all‚Äôinterno di un campione di studenti, possiamo affermare che l‚Äô82% sono donne e il 18% sono uomini.\nLe distribuzioni delle variabili sono descritte in termini di probabilit√†. Le frequenze relative possono essere interpretate come ‚Äúprobabilit√† empiriche‚Äù. Nell‚Äôesempio precedente, la probabilit√† di ‚Äúessere una donna‚Äù nel campione specifico √® 0.82, mentre la probabilit√† di ‚Äúessere un uomo‚Äù √® 0.18. La probabilit√† che una variabile \\(X\\) (come il genere) assuma un valore specifico \\(x\\) (ad esempio, ‚Äúdonna‚Äù) viene indicata come \\(P(X = x)\\), o pi√π semplicemente \\(P(x)\\).\nLe distribuzioni delle variabili continue sono pi√π complesse da descrivere. Per le variabili continue, non descriviamo la probabilit√† che la variabile assuma un valore specifico, ma la probabilit√† che essa cada in un intervallo vicino a quel valore specifico. In futuro, esploreremo come rappresentare graficamente la distribuzione di una variabile continua utilizzando un istogramma o un grafico della densit√† di probabilit√† chiamato ‚ÄúKernel Density Plot‚Äù.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#la-matrice-dei-dati",
    "href": "chapters/chapter_2/01_key_notions.html#la-matrice-dei-dati",
    "title": "13¬† Concetti chiave",
    "section": "13.4 La Matrice dei Dati",
    "text": "13.4 La Matrice dei Dati\nNell‚Äôambito dell‚Äôanalisi statistica, la matrice dei dati svolge un ruolo fondamentale nell‚Äôorganizzazione delle informazioni relative alle variabili. Si tratta di una tabella strutturata con righe e colonne, dove ogni riga individua un‚Äôunit√† statistica specifica e ogni colonna rappresenta una diversa variabile statistica in esame.\nVa enfatizzato che, all‚Äôinterno della matrice dei dati, le unit√† statistiche non seguono generalmente un ordine progressivo o gerarchico. L‚Äôindice attribuito a ciascuna unit√† statistica indica semplicemente la posizione che essa occupa all‚Äôinterno della tabella, senza implicare un valore intrinseco o una relazione ordinale. Tale strutturazione metodica offre un mezzo efficace per raccogliere, visualizzare e analizzare le informazioni ottenute durante lo studio statistico, permettendo una gestione chiara e sistematica dei dati raccolti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#capire-i-dati",
    "href": "chapters/chapter_2/01_key_notions.html#capire-i-dati",
    "title": "13¬† Concetti chiave",
    "section": "13.5 Capire i dati",
    "text": "13.5 Capire i dati\nA scopo illustrativo, prendiamo in considerazione il dataset contenuto nel file STAR.csv. Questi dati sono parte integrante del progetto STAR (Student-Teacher Achievement Ratio), un esperimento pedagogico sviluppato negli Stati Uniti nel periodo tra il 1985 e il 1990. La finalit√† centrale di questo studio era indagare l‚Äôimpatto delle dimensioni delle classi sulle performance accademiche degli studenti. In questo contesto, gli studenti venivano distribuiti casualmente in classi di dimensioni ridotte (13-17 studenti) o pi√π ampie (22-25 studenti).\nDopo aver preparato l‚Äôambiente di lavoro caricando i pacchetti necessari, √® possibile procedere all‚Äôimportazione dei dati in Python. Si pu√≤ fare ci√≤ utilizzando il seguente codice, prestando attenzione al fatto che l‚Äôargomento di read_csv() deve specificare il percorso relativo del file rispetto alla directory in cui √® situato lo script .ipynb:\n\ndf_star = pd.read_csv(\"../data/STAR.csv\")\n\nQuesto codice importa i dati dal file STAR.csv e li memorizza in un DataFrame di pandas. Questo passo √® fondamentale per consentire un‚Äôanalisi e una manipolazione efficiente delle informazioni relative all‚Äôesperimento STAR. In Python, il DataFrame rappresenta la struttura dati principale per la gestione e l‚Äôelaborazione dei dati. Il DataFrame attualizza il concetto di ‚Äúmatrice di dati‚Äù che abbiamo introdotto in precedenza.\n\ndf_star.shape\n\n(1274, 4)\n\n\nDato che il DataFrame √® troppo grande (1274 righe e 4 colonne), stampiamo sullo schermo le prime 5 righe.\n\ndf_star.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nNella terminologia statistica, l‚Äôosservazione √® l‚Äôinformazione raccolta da un individuo o un‚Äôentit√† specifica che partecipa allo studio. Considerando il dataset STAR, l‚Äôunit√† di osservazione √® costituita dagli studenti. Pertanto, nel DataFrame denominato df_star, ogni riga simboleggia uno studente distinto coinvolto nell‚Äôindagine.\nLe variabili, d‚Äôaltro canto, sono espressioni delle diverse caratteristiche degli individui o delle entit√† analizzate. Nel contesto del progetto STAR, questo concetto si traduce in:\n\nOgni colonna di df_star rappresenta una variabile che incarna una particolare propriet√† condivisa da tutti gli studenti partecipanti.\nLe variabili sono identificate attraverso etichette collegate alle colonne, come classtype (il tipo di classe assegnata, con modalit√† small e regular), reading (il punteggio nel test di lettura standardizzato), math (il punteggio nel test di matematica standardizzato) e graduated (indicazione se lo studente ha conseguito o meno il diploma di scuola superiore, con ‚Äú1‚Äù o ‚Äú0‚Äù rispettivamente).\n\nPer rappresentare un‚Äôosservazione singola della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l‚Äôindice dell‚Äôosservazione. Questo indice significa che abbiamo un valore differente di \\(X\\) per ogni valore distinto di \\(i\\). Ad esempio, nel caso di 1274 osservazioni, \\(i\\) pu√≤ variare da 1 a 1274. Pertanto, per simboleggiare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\). √à fondamentale tener presente che, mentre in Python gli indici iniziano da 0, nella notazione matematica tradizionale, come quella rappresentata da \\(X_i\\), l‚Äôindice ha inizio da 1. Questa differenza tra le convenzioni di indicizzazione pu√≤ essere un aspetto cruciale da considerare durante l‚Äôanalisi dei dati.\n\ndf_star[\"reading\"][1]\n\n612\n\n\nUna delle prime cose da fare, quando esaminiamo un dataset, √® capire che tipo di variabili sono incluse.\n\ndf_star.dtypes\n\nclasstype    object\nreading       int64\nmath          int64\ngraduated     int64\ndtype: object\n\n\nNel caso specifico, notiamo che la variabile classtype √® di tipo object, quindi √® una variabile qualitativa, mentre le altre variabili sono numeriche, rappresentate come numeri interi (int64). Se elenchiamo le modalit√† presenti in classtype utilizzando il metodo unique(), scopriamo che corrispondono a ‚Äúsmall‚Äù e ‚Äúregular‚Äù.\n\ndf_star[\"classtype\"].unique()\n\narray(['small', 'regular'], dtype=object)\n\n\nCon l‚Äôistruzione seguente verifichiamo che la variabile graduated sia una variabile binaria.\n\ndf_star[\"graduated\"].unique()\n\narray([1, 0])",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#i-bias-nella-raccolta-dati",
    "href": "chapters/chapter_2/01_key_notions.html#i-bias-nella-raccolta-dati",
    "title": "13¬† Concetti chiave",
    "section": "13.6 I Bias nella Raccolta Dati",
    "text": "13.6 I Bias nella Raccolta Dati\nSi tengano sempre presenti i bias di partenza che governano la raccolta di dati. I dati non sono mai ‚Äúneutri‚Äù. Il contenuto dei dati raccolti - cosa viene chiesto e registrato - e le intenzioni iniziali che guidano la raccolta dei dati spesso dettano i parametri della nostra comprensione (Nobles 2000).\nQuesto punto √® stato sviluppato, per esempio, nello studio di Johnson (2021). L‚Äôarticolo confronta due modalit√† di raccolta dati riguardanti le persone incarcerate negli Stati Uniti: quella statale e quella comunitaria. La raccolta dati statale, iniziata con il censimento del 1850, si concentra su informazioni demografiche e statistiche di base (numero di incarcerati, et√†, razza, ecc.), mantenendo una visione distante e basata su pregiudizi storici. Questo approccio tende a perpetuare una comprensione limitata e spesso distorta del sistema carcerario, influenzata da preconcetti razziali e da un‚Äôottica di controllo sociale.\nAl contrario, la raccolta dati comunitaria, eseguita da persone direttamente coinvolte o colpite dal sistema carcerario, include dettagli pi√π specifici e rilevanti sulle condizioni di vita, la qualit√† della rappresentanza legale e gli effetti della detenzione sulle relazioni sociali e familiari. Questo metodo offre una visione pi√π completa e umana della realt√† carceraria, mettendo in luce problemi strutturali e fallimenti istituzionali che spesso sfuggono alle indagini statali.\nIn sintesi, le conclusioni a cui si arriva con i due metodi di raccolta dati sono diverse: mentre i dati statali tendono a mantenere una narrazione limitata e spesso fuorviante, i dati comunitari forniscono una comprensione pi√π approfondita e critica delle dinamiche carcerarie, evidenziando le esperienze vissute e le disuguaglianze sistemiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#variabili-indipendenti-e-variabili-dipendenti",
    "href": "chapters/chapter_2/01_key_notions.html#variabili-indipendenti-e-variabili-dipendenti",
    "title": "13¬† Concetti chiave",
    "section": "13.7 Variabili Indipendenti e Variabili Dipendenti",
    "text": "13.7 Variabili Indipendenti e Variabili Dipendenti\nNell‚Äôambito della ricerca statistica, √® fondamentale distinguere tra variabili indipendenti e dipendenti. Questa distinzione si basa sulla domanda di ricerca e sulla comprensione del fenomeno che si sta studiando.\n\n13.7.1 Variabili Indipendenti\nLe variabili indipendenti, a volte chiamate variabili predittive, rappresentano i fattori che si ipotizza influenzino l‚Äôesito di interesse. Esse sono spesso manipolate o controllate dal ricercatore.\n\n\n13.7.2 Variabili Dipendenti\nLe variabili dipendenti, d‚Äôaltra parte, rappresentano l‚Äôesito o il risultato che si sta cercando di spiegare o prevedere. Esse sono ci√≤ che il ricercatore sta cercando di capire e sono influenzate dalle variabili indipendenti.\nIn molti studi, √® abbastanza chiaro quali sono le variabili indipendenti e dipendenti. Tuttavia, in alcuni casi, la relazione pu√≤ essere pi√π sfumata o complessa. Ad esempio, nell‚Äôanalizzare la correlazione tra l‚Äôesercizio fisico e l‚Äôinsonnia, pu√≤ non essere immediatamente evidente quale sia la causa e quale l‚Äôeffetto. In tali circostanze, una comprensione delle relazioni causali inerenti il fenomeno considerato √® necessaria per una corretta distinzione tra variabili indipendenti (cause) e dipendenti (effetti).\nEsempio 5 Prendiamo in considerazione un esperimento in cui uno psicologo ha chiamato 120 studenti universitari per un test di memoria. Prima di iniziare, met√† dei partecipanti √® stata informata che il compito era particolarmente difficile, mentre all‚Äôaltra met√† non √® stata fornita alcuna indicazione sulla difficolt√†. Successivamente, √® stato misurato il punteggio ottenuto nella prova di memoria da ciascun partecipante.\nIn questo esperimento:\n\nLa variabile indipendente √® l‚Äôinformazione sulla difficolt√† del compito, che √® stata manipolata dallo sperimentatore attraverso l‚Äôassegnazione casuale dei soggetti alle due diverse condizioni (‚Äúinformazione fornita‚Äù e ‚Äúinformazione non fornita‚Äù).\nLa variabile dipendente √® il punteggio ottenuto nella prova di memoria, ovvero l‚Äôoutcome che lo sperimentatore sta cercando di capire e che potrebbe essere influenzato dalla variabile indipendente.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#effetto",
    "href": "chapters/chapter_2/01_key_notions.html#effetto",
    "title": "13¬† Concetti chiave",
    "section": "13.8 Effetto",
    "text": "13.8 Effetto\nIl concetto di ‚Äúeffetto‚Äù √® fondamentale nell‚Äôanalisi dei dati e nella statistica, poich√© rappresenta una misura del cambiamento o dell‚Äôinfluenza tra le variabili (Huntington-Klein 2021). Ad esempio, consideriamo uno studio sulla memoria che indaga l‚Äôeffetto delle mnemotecniche sul miglioramento della memoria. In questo studio, un gruppo riceve un intervento relativo al rilassamento, mentre un altro partecipa a un workshop di riorganizzazione mnemonica. Alla fine, i partecipanti vengono sottoposti a test di memoria e l‚Äôeffetto delle mnemotecniche √® determinato dalla differenza tra i punteggi medi dei due gruppi. Se il gruppo che ha seguito il workshop mostra un punteggio medio superiore, si pu√≤ affermare che le mnemotecniche hanno un effetto positivo sulla memoria.\nL‚Äôeffetto viene misurato attraverso diverse statistiche, come la differenza di medie, il rapporto di probabilit√†, ecc. Quando si analizzano i dati con metodi statistici, l‚Äôobiettivo √® determinare se l‚Äôeffetto osservato √® credibile, ovvero se ci sono evidenze che l‚Äôeffetto sia generalizzabile alla popolazione nel suo insieme. Questo aiuta a valutare l‚Äôimportanza dell‚Äôeffetto e a trarre conclusioni sulle relazioni tra le variabili nello studio.\nNel suo lavoro, Huntington-Klein (2021) affronta un punto cruciale: gli effetti dei trattamenti nelle scienze sociali non sono uniformi per tutti gli individui. Questo √® particolarmente evidente quando si considera un trattamento psicologico, ad esempio una terapia cognitivo-comportamentale (CBT) per la gestione dell‚Äôansia. L‚Äôefficacia della CBT pu√≤ variare significativamente da persona a persona, portando al concetto di effetti eterogenei del trattamento. Questo significa che ogni individuo pu√≤ avere una risposta diversa al trattamento, influenzata da fattori come la storia personale, il livello di ansia iniziale, le strategie di coping esistenti e altre variabili psicologiche.\nQuando parliamo di medie degli effetti del trattamento, ci riferiamo a diverse modalit√† di aggregazione degli effetti individuali. La media degli effetti del trattamento (ATE) rappresenta l‚Äôeffetto medio che il trattamento avrebbe se fosse applicato a tutti. Tuttavia, esistono altre medie che possono essere pi√π rilevanti in specifici contesti.\nL‚Äôeffetto medio del trattamento sui trattati (ATT) si riferisce all‚Äôeffetto medio per coloro che hanno effettivamente ricevuto il trattamento. Ad esempio, se valutiamo l‚Äôefficacia della CBT solo su individui che hanno completato la terapia, otteniamo l‚ÄôATT. D‚Äôaltra parte, l‚Äôeffetto medio del trattamento sui non trattati (ATUT) considera l‚Äôeffetto medio che il trattamento avrebbe su coloro che non hanno ricevuto il trattamento. Questo potrebbe essere utile per valutare come la CBT potrebbe aiutare coloro che ancora non l‚Äôhanno provata.\nIl tipo di effetto del trattamento che otteniamo dipende dal disegno della ricerca. Se conduciamo un esperimento con randomizzazione vera in un campione rappresentativo, otteniamo l‚ÄôATE. Se, invece, la randomizzazione √® limitata a un certo gruppo, otteniamo un effetto medio condizionale su quel gruppo. Chiudendo le ‚Äúback doors‚Äù - ossia eliminando le influenze confondenti - possiamo ottenere un effetto medio ponderato dalla varianza. Quando utilizziamo una variabile esogena per predire il trattamento, otteniamo l‚Äôeffetto medio locale del trattamento (LATE).\nCapire quale tipo di effetto del trattamento stiamo misurando √® cruciale per applicare i risultati a interventi reali. Supponiamo di voler valutare un nuovo programma di supporto psicologico per studenti universitari. Se non prestiamo attenzione al tipo di effetto che stiamo misurando, potremmo trarre conclusioni errate su come il programma influenzer√† una popolazione pi√π ampia di studenti. Ad esempio, potremmo trovare che il programma √® molto efficace tra gli studenti che gi√† cercano attivamente aiuto, ma non tra quelli che evitano il supporto psicologico.\n√à importante tenere a mente i diversi tipi di effetti del trattamento, come l‚ÄôATE, l‚ÄôATT, l‚ÄôATUT, e il LATE, perch√© ci aiutano a comprendere meglio come un trattamento influenzer√† diverse popolazioni e a pianificare interventi pi√π efficaci. Se vogliamo applicare un trattamento a tutta la popolazione, l‚ÄôATE √® ci√≤ che ci interessa. Se, invece, vogliamo estendere un trattamento gi√† popolare a pi√π persone, potremmo essere pi√π interessati all‚ÄôATUT o all‚Äôeffetto marginale del trattamento. Se il nostro obiettivo √® capire l‚Äôefficacia di un trattamento tra quelli che gi√† lo ricevono, allora l‚ÄôATT √® pi√π rilevante. Conoscere e capire questi concetti ci permette di utilizzare i risultati della ricerca per prendere decisioni informate e progettare interventi psicologici che siano veramente efficaci.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#variabili-casuali",
    "href": "chapters/chapter_2/01_key_notions.html#variabili-casuali",
    "title": "13¬† Concetti chiave",
    "section": "13.9 Variabili Casuali",
    "text": "13.9 Variabili Casuali\nIl concetto di variabile nella statistica trova un corrispondente nella teoria delle probabilit√†, dove √® chiamato variabile casuale. Quando ci occupiamo di studi come quelli sugli interventi psicologici, le variabili casuali vengono utilizzate per rappresentare e misurare i risultati di tali interventi. In sostanza, una variabile casuale descrive una caratteristica specifica degli individui all‚Äôinterno di una popolazione, e i suoi valori possono variare tra gli individui. Teoricamente, una variabile casuale pu√≤ assumere una gamma di valori possibili, ma in pratica si osserva un valore specifico per ogni individuo.\nUtilizziamo notazioni particolari per riferirci alle variabili casuali e ai loro valori specifici. Ad esempio, le lettere maiuscole come \\(X\\) e \\(Y\\) denotano le variabili casuali, mentre le lettere minuscole come \\(x\\) e \\(y\\) si riferiscono ai valori che queste variabili possono assumere in circostanze specifiche.\n\n13.9.1 Differenza tra Variabili Casuali e Variabili Statistiche\nLa chiave per comprendere la differenza tra questi due concetti risiede nell‚Äôincertezza epistemica che il ricercatore affronta. Immaginiamo un esperimento casuale, come il lancio di un dado. Supponiamo che la variabile di interesse \\(X\\) rappresenti l‚Äôesito del lancio. Prima del lancio, \\(X\\) √® una variabile casuale, poich√© conosciamo i possibili valori che pu√≤ assumere (da 1 a 6), ma non sappiamo quale valore specifico si manifester√†. In questo stadio, \\(X\\) rappresenta una quantit√† incognita, suscettibile di variazione casuale.\nDopo il lancio, supponiamo che l‚Äôesito sia 5. A questo punto, la variabile \\(X\\) diventa una variabile statistica, poich√© rappresenta un dato osservato e concreto all‚Äôinterno del campione di osservazioni. L‚Äôincertezza √® risolta, e il valore di \\(X\\) √® ora noto e fisso.\nIn sintesi, una variabile casuale rappresenta una quantit√† che pu√≤ assumere diversi valori con una certa probabilit√†, mentre una variabile statistica √® una realizzazione specifica di quella quantit√† incognita. La transizione da una variabile casuale a una variabile statistica avviene attraverso l‚Äôosservazione e la misurazione, che trasformano un‚Äôincertezza teorica in una certezza empirica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#stima-e-inferenza",
    "href": "chapters/chapter_2/01_key_notions.html#stima-e-inferenza",
    "title": "13¬† Concetti chiave",
    "section": "13.10 Stima e Inferenza",
    "text": "13.10 Stima e Inferenza\n\n13.10.1 Stima\nLa stima √® un concetto centrale in statistica che si riferisce al processo attraverso il quale si ottengono informazioni sulle caratteristiche di una popolazione intera basandosi sui dati di un campione estratto da essa. Ad esempio, calcolando la media o la mediana dei dati all‚Äôinterno del campione, possiamo derivare stime per la media o la mediana della popolazione complessiva. Le caratteristiche che vogliamo conoscere della popolazione sono spesso chiamate ‚Äúparametri‚Äù, e la stima pu√≤ riguardare sia questi parametri sia la distribuzione di una variabile casuale nella popolazione.\n\n\n13.10.2 Inferenza Statistica\nDopo aver ottenuto queste stime, si passa al passaggio successivo: l‚Äôinferenza statistica. Questo processo va oltre la semplice stima e ci permette di trarre conclusioni pi√π ampie sulla popolazione. L‚Äôinferenza statistica riguarda la valutazione di specifiche ipotesi o risposte a domande di ricerca relative alla popolazione, utilizzando le stime ottenute dal campione.\nAd esempio, se abbiamo stimato la media dei redditi in un campione di famiglie, possiamo utilizzare l‚Äôinferenza statistica per testare se c‚Äô√® una differenza significativa nei redditi tra diverse regioni o gruppi demografici all‚Äôinterno della popolazione. In questo modo, l‚Äôinferenza statistica ci fornisce gli strumenti per fare previsioni e trarre conclusioni riguardanti la popolazione intera.\n\n\n13.10.3 Approcci all‚ÄôInferenza Statistica\nEsistono vari approcci e metodologie per condurre l‚Äôinferenza statistica, tra cui due dei pi√π comuni sono l‚Äôinferenza bayesiana e l‚Äôapproccio frequentista. L‚Äôinferenza bayesiana si basa sull‚Äôuso di probabilit√† a priori e a posteriori, mentre l‚Äôapproccio frequentista si basa su tecniche come i test d‚Äôipotesi e gli intervalli di confidenza.\nIn sintesi, la stima e l‚Äôinferenza statistica sono due fasi cruciali nell‚Äôanalisi statistica. La stima ci permette di utilizzare i dati del campione per ottenere informazioni su specifiche caratteristiche della popolazione, mentre l‚Äôinferenza statistica ci consente di utilizzare quelle stime per fare affermazioni pi√π generali e valutare ipotesi sulla popolazione nel suo insieme. Entrambi questi processi sono fondamentali per comprendere e interpretare i fenomeni che stiamo studiando.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#modelli-psicologici",
    "href": "chapters/chapter_2/01_key_notions.html#modelli-psicologici",
    "title": "13¬† Concetti chiave",
    "section": "13.11 Modelli Psicologici",
    "text": "13.11 Modelli Psicologici\n\n13.11.1 Concetto di Modello\nIn ambito statistico e nel campo della data science, un ‚Äúmodello‚Äù rappresenta una formulazione matematica semplificata di un fenomeno reale che si desidera studiare. Si tratta di un insieme di equazioni e ipotesi che delineano la struttura probabilistica e le relazioni tra le variabili, cercando di catturare gli aspetti essenziali del fenomeno senza rappresentarlo in ogni dettaglio. La scelta del modello specifico pu√≤ dipendere dai dati disponibili, dalla domanda di ricerca e dall‚Äôobiettivo dell‚Äôanalisi. Poich√© spesso esistono diversi modelli che possono essere applicati allo stesso problema, la data science si pone il problema dell‚Äôidentificazione del modello che meglio si adatta ai dati e che soddisfa certi criteri di validit√† e bont√†.\n\n\n13.11.2 Modelli in Psicologia\nNel contesto della psicologia, la modellazione assume un ruolo fondamentale e particolarmente delicato. I modelli psicologici sono strumenti concettuali utilizzati per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Data la complessit√† e la variabilit√† dei fenomeni psicologici, la costruzione di modelli efficaci richiede un approccio rigoroso e multidimensionale. Un modello psicologico robusto e valido deve soddisfare diverse caratteristiche essenziali:\n\nCoerenza descrittiva: Il modello deve fornire una rappresentazione logica e internamente coerente del fenomeno studiato. Deve catturare gli elementi essenziali del processo psicologico in esame, offrendo una struttura concettuale che organizzi le osservazioni in modo significativo e comprensibile.\nCapacit√† predittiva: Un aspetto cruciale di un modello psicologico efficace √® la sua abilit√† di formulare predizioni accurate sulle manifestazioni future del fenomeno. Questa caratteristica non solo aumenta l‚Äôutilit√† pratica del modello, ma fornisce anche un mezzo per testarne la validit√†.\nSupporto empirico: Il modello deve essere ancorato a solide prove empiriche. Ci√≤ implica che le sue assunzioni e previsioni devono essere confermate da dati osservabili raccolti attraverso ricerche sistematiche e metodologicamente rigorose.\nFalsificabilit√†: Forse la caratteristica pi√π critica, la falsificabilit√†, richiede che il modello sia costruito in modo da poter essere sottoposto a verifica o confutazione attraverso l‚Äôosservazione e l‚Äôesperimento. Questo principio, fondamentale per il metodo scientifico, assicura che il modello rimanga aperto al scrutinio critico e alla revisione basata su nuove evidenze.\nParsimonia: Un buon modello psicologico dovrebbe essere parsimonioso. Dovrebbe spiegare il fenomeno nel modo pi√π semplice possibile, evitando complessit√† non necessarie.\nGeneralizzabilit√†: Il modello dovrebbe essere applicabile a una vasta gamma di situazioni e contesti, non solo a specifici casi o condizioni sperimentali.\nUtilit√† pratica: Infine, un modello psicologico efficace dovrebbe avere implicazioni pratiche, fornendo insights utili per interventi, terapie o applicazioni nel mondo reale.\n\nLa modellazione in psicologia si trova spesso di fronte a sfide uniche dovute alla natura soggettiva e variabile dell‚Äôesperienza umana. I ricercatori devono bilanciare la necessit√† di precisione scientifica con la flessibilit√† richiesta per catturare la ricchezza e la complessit√† dei fenomeni psicologici. Inoltre, devono essere consapevoli dei limiti etici nella sperimentazione e delle potenziali implicazioni sociali dei loro modelli.\nLa creazione e l‚Äôutilizzo di modelli in psicologia √® un processo dinamico e iterativo. I modelli sono costantemente raffinati, testati e, se necessario, rivisti o sostituiti man mano che emergono nuove evidenze. Questo approccio assicura che la comprensione dei processi psicologici continui a evolvere e migliorare nel tempo.\nL‚Äôanalisi dei dati, attraverso l‚Äôapplicazione di tecniche statistiche, √® il mezzo attraverso il quale un modello psicologico viene valutato. Oltre a determinare se il modello √® in grado di spiegare i dati osservati, l‚Äôanalisi pu√≤ anche verificare la capacit√† del modello di fare previsioni accurate su dati non ancora osservati. In questo modo, la modellazione diventa uno strumento potente non solo per comprendere i fenomeni psicologici ma anche per prevedere e, in alcuni casi, influenzare il comportamento e le dinamiche mentali.\nIn sintesi, un modello, sia in statistica che in psicologia, √® uno strumento teorico che cerca di rappresentare un fenomeno complesso in una forma semplificata ma informativa, guidando la comprensione, la previsione e, in ultima analisi, l‚Äôintervento efficace su quel fenomeno. La scelta e la valutazione del modello giusto sono fondamentali per garantire che le conclusioni derivanti dall‚Äôanalisi siano valide e utili nel contesto specifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "title": "13¬† Concetti chiave",
    "section": "13.12 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "13.12 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHuntington-Klein, Nick. 2021. The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, Kaneesha R. 2021. ¬´Two regimes of prison data collection¬ª. Harvard Data Science Review 3 (3): 10‚Äì1162.\n\n\nNobles, Melissa. 2000. Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html",
    "href": "chapters/chapter_2/02_measurement.html",
    "title": "14¬† La misurazione in psicologia",
    "section": "",
    "text": "14.1 Introduzione\nIn questo capitolo verranno introdotte alcune nozioni di base relative ai temi della misurazione quantitativa delle caratteristiche psicologiche. Verr√† presentata la teoria delle scale di misura di Stevens (1946), ma prima di procedere, √® indispensabile leggere l‚ÄôAppendice G.\nIl problema dello scaling psicologico riguarda la trasformazione dei dati osservati in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche misurate. Quando conduciamo ricerche in psicologia, spesso vogliamo assegnare numeri ai comportamenti o alle risposte degli individui per analizzarli in modo oggettivo. Tuttavia, questa trasformazione √® complessa e richiede attenzione a diverse considerazioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#introduzione",
    "href": "chapters/chapter_2/02_measurement.html#introduzione",
    "title": "14¬† La misurazione in psicologia",
    "section": "",
    "text": "14.1.1 Scaling di Guttman\nUno dei metodi di scaling pi√π noti √® il ¬´Scaling di Guttman¬ª, utilizzato per rappresentare relazioni ordinate tra elementi di una scala. Per esempio, in un questionario sui sintomi di ansia, le domande sono ordinate per intensit√† crescente. Se un partecipante risponde ‚Äús√¨‚Äù a una domanda pi√π intensa, dovrebbe aver risposto ‚Äús√¨‚Äù anche a tutte le domande meno intense precedenti, creando una scala ordinata di gravit√† dei sintomi.\n\n\n14.1.2 Scaling Thurstoniano\nLo ¬´Scaling Thurstoniano¬ª misura le preferenze o i giudizi soggettivi. Ad esempio, per valutare la preferenza per diversi tipi di cibi, i partecipanti confrontano due cibi alla volta e esprimono una preferenza. Queste risposte vengono usate per assegnare punteggi basati sulla preferenza media.\n\n\n14.1.3 Questionari Likert\nI questionari Likert richiedono ai partecipanti di esprimere il grado di accordo con affermazioni su una scala a pi√π livelli (da ¬´fortemente in disaccordo¬ª a ¬´fortemente d‚Äôaccordo¬ª). I punteggi ottenuti vengono sommati per rappresentare la posizione dell‚Äôindividuo rispetto all‚Äôoggetto di studio.\n\n\n14.1.4 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le propriet√† delle scale psicologiche, si utilizzano vari metodi. Ad esempio, l‚Äôaffidabilit√† delle misure pu√≤ essere analizzata con il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, che misurano la coerenza interna delle risposte ai vari item del questionario. Inoltre, la validit√† delle scale pu√≤ essere esaminata confrontando i risultati con misure simili o utilizzando analisi statistiche per verificare se la scala cattura accuratamente il costrutto che si intende misurare. La validit√† di costrutto √® cruciale, poich√© riguarda la capacit√† della scala di misurare effettivamente il concetto psicologico che si intende esaminare.\n\n\n14.1.5 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si √® arricchito di nuove prospettive, grazie all‚Äôavvento di tecnologie avanzate e all‚Äôintegrazione di approcci interdisciplinari. Ecco alcune delle tendenze pi√π rilevanti:\n\n14.1.5.1 Teoria della Risposta agli Item (IRT)\nLa Teoria della Risposta agli Item (IRT) ha guadagnato popolarit√† per la sua capacit√† di fornire stime pi√π precise delle abilit√† latenti rispetto ai modelli classici. La IRT considera la probabilit√† che un individuo risponda correttamente a un item in funzione della sua abilit√† e delle caratteristiche dell‚Äôitem stesso, offrendo una visione pi√π dettagliata delle propriet√† psicometriche degli strumenti di misurazione.\n\n\n14.1.5.2 Approcci Bayesiani\nGli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessit√† e l‚Äôincertezza inerenti alla misurazione psicologica.\n\n\n14.1.5.3 Analisi di Rete\nL‚Äôanalisi di rete √® un‚Äôaltra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio pu√≤ offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#le-scale-di-misurazione",
    "href": "chapters/chapter_2/02_measurement.html#le-scale-di-misurazione",
    "title": "14¬† La misurazione in psicologia",
    "section": "14.2 Le scale di misurazione",
    "text": "14.2 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le propriet√† psicologiche. La teoria delle scale di Stevens {cite:p}stevens_46 identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poich√© ciascuna di esse √® in grado di ‚Äúcatturare‚Äù solo alcune delle propriet√† dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n14.2.1 Scala nominale\nILa scala nominale √® il livello di misurazione pi√π semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica √® uguale o diversa da un‚Äôaltra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unit√† di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL‚Äôunica operazione algebrica consentita dalla scala nominale √® quella di contare le unit√† di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale √® possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unit√† di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n14.2.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unit√† di misura all‚Äôinterno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) √® uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale √® quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed √® scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto √® considerato pi√π duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearit√† della scala di Mohs (Burchard, 2004).\n\n\n\n\n14.2.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le propriet√† della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unit√† statistiche in termini di un intervallo costante, chiamato ‚Äúunit√† di misura‚Äù, a cui viene attribuito il valore ‚Äú1‚Äù. L‚Äôorigine della scala, ovvero il punto zero, √® scelta arbitrariamente e non indica l‚Äôassenza della propriet√† che si sta misurando. Ci√≤ significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all‚Äôunit√† statistica in cui la propriet√† risulta assente.\nLa scala ad intervalli equivalenti consente l‚Äôesecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli √® che non consente di calcolare il rapporto tra coppie di misure. √à possibile affermare la differenza tra \\(a\\) e \\(b\\) come la met√† della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non √® possibile affermare che \\(a\\) abbia una propriet√† misurata in quantit√† doppia rispetto a \\(b\\). In altre parole, non √® possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalit√† permettono tutte le operazioni aritmetiche, come la somma, l‚Äôelevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l‚Äôunit√† di misura √® arbitraria e pu√≤ essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l‚Äôaggiunta di una costante a tutti i valori della scala, √® ammessa poich√© non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l‚Äôuguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli √® la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, √® possibile stabilire se due modalit√† sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale √® possibile mettere due modalit√† in una relazione d‚Äôordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, per√≤, √® possibile definire una unit√† di misura per cui √® possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c‚Äô√® una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l‚Äôintensit√† del fenomeno, godono della propriet√† che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli √® quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non √® il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione ‚Äúil doppio di‚Äù che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla propriet√† misurata (cio√® la temperatura). La decisione di che scala usare (Centigrada vs.¬†Fahrenheit) √® arbitraria. Ma questa arbitrariet√† non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realt√† empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l‚Äôaspetto invariante di una trasformazione lineare, ovvero l‚Äôuguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\n√à facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall‚Äôunit√† di misura che √® stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n14.2.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non √® arbitrario e rappresenta l‚Äôelemento che ha intensit√† nulla rispetto alla propriet√† misurata. Per costruire questa scala, si associa il numero 0 all‚Äôelemento con intensit√† nulla e si sceglie un‚Äôunit√† di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall‚Äôorigine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensit√† della propriet√† misurata.\nIn questa scala, √® possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L‚Äôunica scelta arbitraria √® l‚Äôunit√† di misura, ma lo zero deve sempre rappresentare l‚Äôintensit√† nulla della propriet√† considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarit√† e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/chapter_2/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "14¬† La misurazione in psicologia",
    "section": "14.3 Gerarchia dei livelli delle scale di misurazione",
    "text": "14.3 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati ‚Äúlivelli di scala‚Äù. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello pi√π basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello pi√π alto. - La scala nominale √® il livello pi√π elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine. - Al livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualit√† o caratteristica. Qui, √® possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non √® possibile quantificare la differenza tra di esse in modo preciso. - La scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse √® quantificabile in modo preciso. In questa scala, √® possibile effettuare operazioni matematiche come l‚Äôaddizione e la sottrazione tra i valori, ma non √® possibile stabilire un vero e proprio punto zero significativo. - Infine, la scala a rapporti equivalenti rappresenta il livello pi√π alto. In questa scala, le categorie sono ordinate, la differenza tra di esse √® quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l‚Äôassenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\nPassando da un livello di misurazione ad uno pi√π alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ci√≤ che riguarda le trasformazioni ammissibili, pi√π il livello di scala √® basso, pi√π le funzioni sono generali (sono minori cio√® i vincoli per passare da una rappresentazione numerica ad un‚Äôaltra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa pi√π restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/chapter_2/02_measurement.html#variabili-discrete-o-continue",
    "title": "14¬† La misurazione in psicologia",
    "section": "14.4 Variabili discrete o continue",
    "text": "14.4 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue. - Le variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l‚Äôelenco dei valori accettabili √® stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti. - D‚Äôaltra parte, le variabili continue possono assumere qualsiasi valore all‚Äôinterno di un intervallo specificato. Teoricamente, ci√≤ significa che √® possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/chapter_2/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "14¬† La misurazione in psicologia",
    "section": "14.5 Comprendere gli errori nella misurazione",
    "text": "14.5 Comprendere gli errori nella misurazione\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\n\n14.5.1 Precisione e Accuratezza\nLa precisione indica la coerenza tra misurazioni ripetute, mentre l‚Äôaccuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l‚Äôassessment psicometrico.\nUtilizzando l‚Äôanalogia del tiro al bersaglio, si pu√≤ avere una serie di colpi vicini tra loro ma lontani dal centro (precisione senza accuratezza) oppure colpi distribuiti in modo sparso ma in media vicini al centro (accuratezza senza precisione).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#assessment-psicometrico",
    "href": "chapters/chapter_2/02_measurement.html#assessment-psicometrico",
    "title": "14¬† La misurazione in psicologia",
    "section": "14.6 Assessment psicometrico",
    "text": "14.6 Assessment psicometrico\nL‚Äôassessment psicometrico valuta la qualit√† delle misurazioni psicologiche, considerando la validit√† e l‚Äôaffidabilit√†.\n\n14.6.1 Validit√† nella Misurazione Psicologica\nLa validit√† √® una propriet√† psicometrica fondamentale dei test psicologici. Secondo gli Standards for Educational and Psychological Testing (2014), la validit√† si riferisce al grado in cui evidenza e teoria supportano le interpretazioni dei punteggi dei test per gli usi proposti. Questo concetto evidenzia che la validit√† riguarda sia il significato dei punteggi sia il loro utilizzo, rendendola ‚Äúla considerazione pi√π fondamentale nello sviluppo e nella valutazione dei test‚Äù.\n\n\n14.6.2 Evoluzione del Concetto di Validit√†\nTradizionalmente, la validit√† era suddivisa in tre categorie:\n\nValidit√† di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell‚Äôattributo psicologico che il test intende misurare. √à importante che gli item siano pertinenti e rappresentativi dell‚Äôattributo misurato.\nValidit√† di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validit√† concorrente e predittiva.\nValidit√† di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validit√† convergente (accordo con strumenti che misurano lo stesso costrutto) e validit√† divergente (capacit√† di discriminare tra costrutti diversi).\n\nLa moderna teoria della validit√† non adotta pi√π questa visione tripartita. Gli Standards del 2014 descrivono la validit√† come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l‚Äôinterpretazione dei punteggi del test per il loro utilizzo previsto.\n\n\n14.6.3 Tipologie di Prove di Validit√†\nGli Standards del 2014 identificano cinque categorie principali di prove di validit√†:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L‚Äôanalisi fattoriale √® uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validit√† convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell‚Äôuso del test, sia intenzionali che non intenzionali.\n\n\n\n14.6.4 Minacce alla Validit√†\nLa validit√† pu√≤ essere compromessa quando un test non misura integralmente il costrutto di interesse (sotto-rappresentazione del costrutto) o quando include varianza estranea al costrutto. Inoltre, fattori esterni come l‚Äôansia o la bassa motivazione degli esaminandi, e deviazioni nelle procedure di amministrazione e valutazione, possono influenzare negativamente la validit√† delle interpretazioni dei risultati.\n\n\n14.6.5 Integrazione delle Prove di Validit√†\nLa validit√† di un test si costruisce attraverso l‚Äôintegrazione di diverse linee di evidenza. Ogni interpretazione o uso di un test deve essere validato specificamente, richiedendo una valutazione continua e accurata delle prove disponibili. Questo processo implica la costruzione di un argomento di validit√† che consideri attentamente la qualit√† tecnica del test e l‚Äôadeguatezza delle sue interpretazioni per gli scopi previsti.\nIn conclusione, la validit√† √® un concetto complesso e integrato che richiede un‚Äôanalisi continua e multidimensionale delle evidenze. La moderna teoria della validit√† enfatizza l‚Äôimportanza di considerare diverse forme di evidenza per supportare le interpretazioni dei punteggi dei test, garantendo che siano utilizzati in modo appropriato e significativo. Gli sviluppatori e gli utilizzatori di test devono impegnarsi a valutare costantemente la validit√† per assicurare misurazioni psicologiche accurate e affidabili.\n\n\n14.6.6 Affidabilit√†\nL‚Äôaffidabilit√† concerne la consistenza e stabilit√† delle misurazioni, verificata attraverso metodi come l‚Äôaffidabilit√† test-retest, inter-rater, intra-rater e l‚Äôaffidabilit√† interna.\n\nAffidabilit√† Test-Retest: Questa forma di affidabilit√† verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilit√† Inter-rater: In questo caso, l‚Äôaffidabilit√† √® determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se pi√π psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilit√† Intra-rater: Questa misura dell‚Äôaffidabilit√† si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilit√† Interna: Si riferisce alla coerenza delle risposte all‚Äôinterno dello stesso test. Ad esempio, se un test misura un costrutto come l‚Äôansia, gli item che misurano l‚Äôansia dovrebbero correlare positivamente l‚Äôuno con l‚Äôaltro. Un modo comune per valutare l‚Äôaffidabilit√† interna √® utilizzare il coefficiente \\(\\omega\\) di McDonald.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_2/02_measurement.html#commenti-e-considerazioni-finali",
    "title": "14¬† La misurazione in psicologia",
    "section": "14.7 Commenti e considerazioni finali",
    "text": "14.7 Commenti e considerazioni finali\nLa teoria della misurazione √® fondamentale nella ricerca empirica per valutare l‚Äôattendibilit√† e la validit√† delle misurazioni. √à cruciale valutare l‚Äôerrore nella misurazione per garantire la precisione e l‚Äôaccuratezza delle misure. L‚Äôassessment psicometrico si occupa di valutare la qualit√† delle misurazioni psicologiche, considerando l‚Äôaffidabilit√† e la validit√† per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre pi√π raffinati per la comprensione delle caratteristiche psicologiche.\n\n\n\n\nLilienfeld, Scott O, e Adele N Strother. 2020. ¬´Psychological measurement and the replication crisis: Four sacred cows.¬ª Canadian Psychology/Psychologie Canadienne 61 (4): 281‚Äì288.\n\n\nMaul, Andrew, David Torres Irribarra, e Mark Wilson. 2016. ¬´On the philosophical foundations of psychological measurement¬ª. Measurement 79: 311‚Äì20.\n\n\nStevens, Stanley Smith. 1946. ¬´On the theory of scales of measurement¬ª. Science 103 (2684): 677‚Äì80.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html",
    "href": "chapters/chapter_2/03_freq_distr.html",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "",
    "text": "15.1 Introduzione\nIn questo capitolo, esploreremo le strategie per sintetizzare grandi quantit√† di dati, soffermandoci su concetti fondamentali come le distribuzioni di frequenza, i quantili e le tecniche di visualizzazione. Discuteremo sia il calcolo che l‚Äôinterpretazione di queste misure, fornendo strumenti utili per rappresentare graficamente le sintesi di dati. Prima di procedere, √® indispensabile leggere l‚Äôappendice Appendice H per comprendere appieno le operazioni descritte.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#i-dati-grezzi",
    "href": "chapters/chapter_2/03_freq_distr.html#i-dati-grezzi",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.2 I dati grezzi",
    "text": "15.2 I dati grezzi\nPer illustrare i principali strumenti della statistica descrittiva, analizzeremo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento della depressione. I ricercatori hanno confrontato 30 soggetti con episodi depressivi con un gruppo di controllo di 37 individui sani, utilizzando il Beck Depression Inventory (BDI-II) per misurare la depressione.\nCarichiamo quindi i dati dal file data.mood.csv.\n\ndf = pd.read_csv(\"../../data/data.mood.csv\")\n\nPer conoscere le dimensioni del DataFrame utilizzo il metodo shape().\n\ndf.shape\n\n(1188, 44)\n\n\nIl DataFrame ha 1188 righe e 44 colonne. Visualizzo il nome delle colonne con il metodo .columns.\n\ndf.columns\n\nIndex(['Unnamed: 0', 'vpn_nr', 'esm_id', 'group', 'bildung', 'bdi',\n       'nr_of_episodes', 'nobs_mood', 'trigger_counter', 'form', 'traurig_re',\n       'niedergeschlagen_re', 'unsicher_re', 'nervos_re', 'glucklich_re',\n       'frohlich_re', 'mood_sad.5', 'mood_fearful.5', 'mood_neg.5',\n       'mood_happy.5', 'cesd_sum', 'rrs_sum', 'rrs_brood', 'rrs_reflect',\n       'forecast_sad', 'forecast_fear', 'forecast_neg', 'forecast_happy',\n       'recall_sad', 'recall_fear', 'recall_neg', 'recall_happy',\n       'diff_neg.fore.5', 'diff_sad.fore.5', 'diff_fear.fore.5',\n       'diff_happy.fore.5', 'diff_neg.retro.5', 'diff_sad.retro.5',\n       'diff_fear.retro.5', 'diff_happy.retro.5', 'mood_sad5_tm1',\n       'mood_neg5_tm1', 'mood_fearful5_tm1', 'mood_happy5_tm1'],\n      dtype='object')\n\n\nPer questo esercizio, ci concentriamo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf = df[[\"esm_id\", \"group\", \"bdi\"]]\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n1\n10\nmdd\n25.0\n\n\n2\n10\nmdd\n25.0\n\n\n3\n10\nmdd\n25.0\n\n\n4\n10\nmdd\n25.0\n\n\n\n\n\n\n\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf = df.drop_duplicates(keep=\"first\")\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndf.shape\n\n(67, 3)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n14\n9\nmdd\n30.0\n\n\n29\n6\nmdd\n26.0\n\n\n45\n7\nmdd\n35.0\n\n\n64\n12\nmdd\n44.0\n\n\n\n\n\n\n\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il ‚Äúnome‚Äù delle righe (ovvero, l‚Äôindice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga √® 15. Questo non ha nessuna conseguenza perch√© non useremo l‚Äôindice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf = df[pd.notnull(df[\"bdi\"])]\n\nOtteniamo cos√¨ il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndf.shape\n\n(66, 3)\n\n\nStampiamo i valori BDI-II presentandoli ordinati dal pi√π piccolo al pi√π grande:\n\nprint(df[\"bdi\"].sort_values())\n\n682     0.0\n455     0.0\n465     0.0\n485     0.0\n540     0.0\n       ... \n190    39.0\n810    41.0\n150    43.0\n135    43.0\n64     44.0\nName: bdi, Length: 66, dtype: float64\n\n\n√à chiaro dall‚Äôelenco precedente che i dati grezzi non sono molto informativi. Nella sezione successiva vedremo come creare una rappresentazione sintetica e comprensibile di questi dati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#distribuzioni-di-frequenze",
    "href": "chapters/chapter_2/03_freq_distr.html#distribuzioni-di-frequenze",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.3 Distribuzioni di frequenze",
    "text": "15.3 Distribuzioni di frequenze\nUna distribuzione di frequenze rappresenta il conteggio delle volte in cui i valori di una variabile si verificano all‚Äôinterno di un intervallo. Per i nostri dati BDI-II, categorizziamo i punteggi in quattro classi:\n\n0‚Äì13: depressione minima\n14‚Äì19: depressione lieve-moderata\n20‚Äì28: depressione moderata-severa\n29‚Äì63: depressione severa\n\nOgni classe \\(\\Delta_i\\) rappresenta un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\), con limiti inferiori e superiori \\(a_i\\) e \\(b_i\\), vengono associati un‚Äôampiezza \\(b_i - a_i\\) (che non √® necessariamente uguale per ogni classe) e un valore centrale \\(\\bar{x}_i\\). Poich√© ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), √® possibile calcolare le seguenti quantit√†.\n\nLa frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\n\nPropriet√†: \\(n_1 + n_2 + \\dots + n_m = n\\).\n\nLa frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.\n\nPropriet√†: \\(f_1+f_2+\\dots+f_m =1\\).\n\nLa frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\)\nLa frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\)\n\n\n15.3.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, √® necessario prima aggiungere al DataFrame df una colonna che contenga una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravit√† della depressione. Questo risultato si ottiene con il metodo pandas.cut().\nIn pandas.cut(), il primo argomento x √® un array unidimensionale (lista python, numpy.ndarray o pandas.Series) che contiene i dati e il secondo argomento bins specifica gli intervalli delle classi. La funzione restituisce un array che specifica la classe di appartenenza di ogni elemento dell‚Äôarray x. L‚Äôargomento include_lowest=True specifica classi chiuse a destra (nel nostro caso √® irrilevante dato che nessuna osservazione coincide con il limite di una classe).\n\n15.3.1.1 Frequenze assolute\n\ndf[\"bdi_class\"] = pd.cut(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], include_lowest=True)\ndf[\"bdi_class\"].value_counts()\n\nbdi_class\n(-0.001, 13.5]    36\n(28.5, 63.0]      17\n(19.5, 28.5]      12\n(13.5, 19.5]       1\nName: count, dtype: int64\n\n\n\n\n15.3.1.2 Frequenze relative\n\nabs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=[\"Abs. freq.\"])\nrel_freq = abs_freq / abs_freq.sum()\nrel_freq = rel_freq.round(2)\nrel_freq\n\n\n\n\n\n\n\n\ncol_0\nAbs. freq.\n\n\nbdi_class\n\n\n\n\n\n(-0.001, 13.5]\n0.55\n\n\n(13.5, 19.5]\n0.02\n\n\n(19.5, 28.5]\n0.18\n\n\n(28.5, 63.0]\n0.26\n\n\n\n\n\n\n\n\nControlliamo\n\nrel_freq.sum()\n\ncol_0\nAbs. freq.    1.01\ndtype: float64\n\n\n\ngrp_freq = pd.crosstab(index=df[\"group\"], columns=[\"Abs. freq.\"], colnames=[\"\"])\ngrp_freq\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nctl\n36\n\n\nmdd\n30\n\n\n\n\n\n\n\n\nVolendo modificare tale ordine √® possibile accedere al DataFrame tramite loc e specificando come secondo argomento una lista dei valori nell‚Äôordine desiderato:\n\ngrp_freq.loc[[\"mdd\", \"ctl\"], :]\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nmdd\n30\n\n\nctl\n36\n\n\n\n\n\n\n\n\nIn Python, il simbolo : utilizzato all‚Äôinterno delle parentesi quadre permette di ottenere uno slicing corrispondente all‚Äôintera lista.\n\n\n\n15.3.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l‚Äôinsieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l‚Äôinsieme di variabili \\(V\\) √® composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali pu√≤ assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell‚Äôesempio precedente, la funzione pd.crosstab pu√≤ essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti index e columns.\n\nbdi_group_abs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"])\nbdi_group_abs_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n36\n0\n\n\n(13.5, 19.5]\n0\n1\n\n\n(19.5, 28.5]\n0\n12\n\n\n(28.5, 63.0]\n0\n17\n\n\n\n\n\n\n\n\nOppure:\n\nbdi_group_rel_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"], normalize=True)\nbdi_group_rel_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n0.545455\n0.000000\n\n\n(13.5, 19.5]\n0.000000\n0.015152\n\n\n(19.5, 28.5]\n0.000000\n0.181818\n\n\n(28.5, 63.0]\n0.000000\n0.257576\n\n\n\n\n\n\n\n\nInvocando il metodo plot.bar sulla tabella, otteniamo un grafico a barre nel quale le barre relative a uno stesso valore bdi_class risultino affiancate. Nel caso presente, le due distribuzioni sono completamente separate, quindi non abbiamo mai due barre affiancate:\n\nbdi_group_rel_freq.plot.bar();",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#istogramma",
    "href": "chapters/chapter_2/03_freq_distr.html#istogramma",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.4 Istogramma",
    "text": "15.4 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densit√† della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densit√† della frequenza relativa √® misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) √® la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l‚Äôampiezza della classe. In questo modo, l‚Äôarea del rettangolo associato alla classe \\(\\Delta_i\\) sull‚Äôistogramma sar√† proporzionale alla frequenza relativa \\(f_i\\). √à importante notare che l‚Äôarea totale dell‚Äôistogramma delle frequenze relative √® uguale a 1.0, poich√© rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche, Buerkner, e Renneberg (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell‚Äôistogramma ‚Äì si notino le frequenze assolute sull‚Äôasse delle ordinate.\n\ncolor_fill = \"#b97c7c\"\nplt.hist(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], density=True, color=color_fill)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()\n\n\n\n\n\n\n\n\nAnche se nel caso presente √® sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un‚Äôampiezza uguale.\n\nplt.hist(df[\"bdi\"], density=True, color=color_fill)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#kernel-density-plot",
    "href": "chapters/chapter_2/03_freq_distr.html#kernel-density-plot",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.5 Kernel density plot",
    "text": "15.5 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell‚Äôistogramma: la sua forma dipende dall‚Äôarbitrariet√† con cui vengono scelti il numero e l‚Äôampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficolt√†, possiamo utilizzare una tecnica alternativa chiamata stima della densit√† kernel (KDE) ‚Äì si veda l‚ÄôAppendice M. Mentre l‚Äôistogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione pi√π continua e meno dipendente dall‚Äôarbitrariet√† delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo √® ci√≤ che fa la KDE: smussa il profilo dell‚Äôistogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un‚Äôaltezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densit√† dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L‚Äôarea sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell‚Äôintervallo. Per esempio, se un intervallo ha un‚Äôarea maggiore sotto la curva rispetto ad altri, significa che in quell‚Äôintervallo c‚Äô√® una maggiore concentrazione di dati.\nLa curva di densit√† ottenuta tramite KDE fornisce dunque un‚Äôidea chiara di come i dati sono distribuiti senza dipendere dall‚Äôarbitrariet√† della scelta delle classi dell‚Äôistogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da {cite:t}zetsche_2019future.\n\nsns.kdeplot(data=df, x=\"bdi\", hue=\"group\", common_norm=False)\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI-II Scores\")\nplt.show()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#forma-di-una-distribuzione",
    "href": "chapters/chapter_2/03_freq_distr.html#forma-di-una-distribuzione",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.6 Forma di una distribuzione",
    "text": "15.6 Forma di una distribuzione\nIn generale, la forma di una distribuzione descrive come i dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un‚Äôillustrazione grafica √® fornita nella figura seguente. Nel pannello 1 la distribuzione √® unimodale con asimmetria negativa; nel pannello 2 la distribuzione √® unimodale con asimmetria positiva; nel pannello 3 la distribuzione √® simmetrica e unimodale; nel pannello 4 la distribuzione √® bimodale.\n\nIl kernel density plot dei valori BDI-II nel campione di Zetsche, Buerkner, e Renneberg (2019) √® bimodale. Ci√≤ indica che le osservazioni della distribuzione si addensano in due cluster ben distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l‚Äôaltro gruppo tende ad avere BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche, Buerkner, e Renneberg (2019).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#indici-di-posizione",
    "href": "chapters/chapter_2/03_freq_distr.html#indici-di-posizione",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.7 Indici di posizione",
    "text": "15.7 Indici di posizione\n\n15.7.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche, Buerkner, e Renneberg (2019) pu√≤ essere sintetizzata attraverso l‚Äôuso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) √® la dimensione del campione e \\(p\\) √® l‚Äôordine del quantile. Se \\(np\\) non √® un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) √® un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) √® la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che √® molto popolare e pu√≤ essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche, Buerkner, e Renneberg (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non √® un intero. Pertanto, il valore del secondo quartile √® pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che √® un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo numpy per trovare la soluzione dell‚Äôesercizio precedente.\n\nx = [19, 26, 27, 28, 28, 33, 33, 41, 43]\nnp.quantile(x, 2 / 3)\n\n33.0",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#mostrare-i-dati",
    "href": "chapters/chapter_2/03_freq_distr.html#mostrare-i-dati",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.8 Mostrare i dati",
    "text": "15.8 Mostrare i dati\n\n15.8.1 Diagramma a scatola\nIl box plot √® uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la ‚Äúscatola‚Äù) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) √® rappresentata da una linea all‚Äôinterno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti ‚Äúbaffi‚Äù, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore √® il valore pi√π basso tra le osservazioni che √® maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore √® il valore pi√π alto tra le osservazioni che √® minore o uguale al terzo quartile pi√π 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati ‚Äúvalori anomali‚Äù e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nsns.boxplot(x=\"group\", y=\"bdi\", data=df, color=color_fill)\nplt.xlabel(\"Group\")\nplt.ylabel(\"BDI-II\")\nplt.title(\"Boxplot of BDI-II Scores by Group\")\nplt.show()\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene usando un violin plot e mostrando anche i dati grezzi.\n\n\n15.8.2 Grafico a violino\nI violin plot combinano box plot e KDE plot per una rappresentazione pi√π dettagliata. Al grafico sono sovrapposti i dati grezzi.\n\nsns.violinplot(x=\"group\", y=\"bdi\", data=df, color=\"lightgray\")\nsns.stripplot(x=\"group\", y=\"bdi\", data=df, color=\"black\", size=5, jitter=True, alpha=0.3)\nplt.ylabel(\"BDI-II\")\nplt.xlabel(\"Group\")\nplt.title(\"Violin Plot with Overlay of Individual Data Points of BDI-II Scores by Group\")\nplt.show()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_2/03_freq_distr.html#commenti-e-considerazioni-finali",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.9 Commenti e considerazioni finali",
    "text": "15.9 Commenti e considerazioni finali\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densit√†. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/03_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "15.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nTukey, John W. 1962. ¬´The Future of Data Analysis¬ª. The Annals of Mathematical Statistics 33 (1): 1‚Äì67. https://doi.org/10.1214/aoms/1177704711.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html",
    "href": "chapters/chapter_2/04_loc_scale.html",
    "title": "16¬† Indici di posizione e di scala",
    "section": "",
    "text": "16.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, √® possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l‚Äôasimmetria, nonch√© la presenza di una o pi√π mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l‚Äôutilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/chapter_2/04_loc_scale.html#indici-di-tendenza-centrale",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.2 Indici di tendenza centrale",
    "text": "16.2 Indici di tendenza centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all‚Äôinterno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l‚Äôintero insieme. Gli indici di tendenza centrale sono fondamentali nell‚Äôanalisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media √® la somma di tutti i valori divisa per il numero totale di valori. √à spesso utilizzata come misura generale di tendenza centrale, ma √® sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana √® il valore che divide l‚Äôinsieme di dati in due parti uguali. A differenza della media, non √® influenzata da valori estremi ed √® quindi pi√π robusta in presenza di outlier.\nModa: La moda √® il valore che appare pi√π frequentemente in un insieme di dati. In alcuni casi, pu√≤ non essere presente o esserci pi√π di una moda.\n\nLa scelta dell‚Äôindice di tendenza centrale appropriato dipende dalla natura dei dati e dall‚Äôobiettivo dell‚Äôanalisi. Ad esempio, la mediana potrebbe essere preferita alla media se l‚Äôinsieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l‚Äôapplicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n16.2.1 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. √à calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed √® espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{16.1}\\]\ndove \\(x_i\\) rappresenta i valori nell‚Äôinsieme, \\(n\\) √® il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n16.2.1.1 Propriet√† della media\nUna propriet√† fondamentale della media √® che la somma degli scarti di ciascun valore dalla media √® zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{16.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta propriet√† implica che i dati sono equamente distribuiti intorno alla media.\n\n\n16.2.1.2 La media come centro di gravit√† dell‚Äôistogramma\nLa media aritmetica pu√≤ essere interpretata come il centro di gravit√† o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravit√† √® il punto in cui la massa di un sistema √® equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati √® in equilibrio. Ogni valore dell‚Äôinsieme di dati pu√≤ essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori pi√π grandi a destra e pi√π piccoli a sinistra, la media corrisponder√† esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n16.2.1.3 Principio dei minimi quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come ‚Äúmetodo dei minimi quadrati‚Äù. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media √® minima. Questo principio √® alla base dell‚Äôanalisi statistica dei modelli di regressione e conferma l‚Äôinterpretazione della media come centro di gravit√† dell‚Äôistogramma.\n\n\n16.2.1.4 Calcolo della media con NumPy\nPer calcolare la media di un piccolo numero di valori in Python, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n\n32.6\n\n\novvero\n\nx = np.array([12, 44, 21, 62, 24])\nnp.mean(x)\n\n32.6\n\n\n\nnp.average(x)\n\n32.6\n\n\n\n\n16.2.1.5 Le proporzioni sono medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione √® il numero di uni in essa, e la media della collezione √® la proporzione di uni.\n\nzero_one = np.array([1, 1, 1, 0])\nresult = sum(zero_one)\nprint(result) \n\n3\n\n\n\nnp.mean(zero_one)\n\n0.75\n\n\n√à possibile sostituire 1 con il valore booleano True e 0 con False:\n\nnp.mean(np.array([(True, True, True, False)]))\n\n0.75\n\n\n\n\n16.2.1.6 Limiti della media aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre √® l‚Äôindice pi√π adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, √® pi√π indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n16.2.1.7 Medie per gruppi\nMolto spesso per√≤ i nostri dati sono contenuti in file e inserire i dati manualmente non √® fattibile. Per fare un esempio, considereremo i dati del Progetto STAR, contenuti nel file STAR.csv, che rappresentano un‚Äôimportante indagine sulle prestazioni degli studenti in relazione alla dimensione delle classi. Negli anni ‚Äô80, i legislatori del Tennessee considerarono la possibilit√† di ridurre le dimensioni delle classi per migliorare il rendimento degli studenti. Al fine di prendere decisioni informate, commissionarono lo studio multimilionario ‚ÄúProgetto Student-Teacher Achievement Ratio‚Äù (Project STAR). Lo studio coinvolgeva bambini della scuola materna assegnati casualmente a classi piccole, con 13-17 studenti, o classi di dimensioni regolari, con 22-25 studenti, fino alla fine della terza elementare. I ricercatori hanno seguito il progresso degli studenti nel tempo, concentrandosi su variabili di risultato, come i punteggi dei test standardizzati di lettura (reading) e matematica (math) alla terza elementare, oltre ai tassi di diploma di scuola superiore (graduated, con valore 1 per s√¨ e 0 per no).\nPoniamoci il problema di calcolare la media dei punteggi math calcolata separatamente per i due gruppi di studenti: coloro che hanno completato la scuola superiore e coloro che non l‚Äôhanno completata.\nProcediamo all‚Äôimportazione dei dati per iniziare l‚Äôanalisi.\n\ndf = pd.read_csv(\"../../data/STAR.csv\")\ndf.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nEsaminiamo la numerosit√† di ciascun gruppo.\n\ndf.groupby(\"graduated\").size()\n\ngraduated\n0     166\n1    1108\ndtype: int64\n\n\nOra procediamo al calcolo delle medie dei punteggi math all‚Äôinterno dei due gruppi. Per rendere la risposta pi√π concisa, useremo la funzione round() per stampare solo 2 valori decimali.\n\ndf.groupby(\"graduated\")[\"math\"].mean().round(2)\n\ngraduated\n0    606.64\n1    635.33\nName: math, dtype: float64\n\n\nIn alternativa, possiamo usare il metodo .describe():\n\ndf.groupby(\"graduated\")[\"math\"].describe().round(1)\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\ngraduated\n\n\n\n\n\n\n\n\n\n\n\n\n0\n166.0\n606.6\n34.1\n526.0\n580.5\n606.0\n629.0\n711.0\n\n\n1\n1108.0\n635.3\n38.1\n515.0\n609.5\n634.0\n659.0\n774.0\n\n\n\n\n\n\n\n\n\n\n\n16.2.2 Media spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, √® un metodo di calcolo della media che prevede l‚Äôeliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all‚Äôinizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l‚Äôultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata √® calcolata come la media aritmetica dei dati rimanenti. Questo approccio √® utile quando ci sono valori anomali o quando la distribuzione √® asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\nA titolo di esempio, procediamo al calcolo della media spuntata dei valori math per i due gruppi definiti dalla variabile graduated, escludendo il 10% dei valori pi√π estremi.\n\nnot_graduated = df[df[\"graduated\"] == 0].math\nstats.trim_mean(not_graduated, 0.10)\n\n605.6492537313433\n\n\n\ngraduated = df[df[\"graduated\"] == 1].math\nstats.trim_mean(graduated, 0.10)\n\n634.4403153153153\n\n\n\n\n16.2.3 Quantili\nIl quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\) rappresenta il valore che divide la distribuzione dei dati in modo tale che una frazione \\(p\\) dei dati si trovi al di sotto di esso.\nLa formula per calcolare il quantile non interpolato √® la seguente:\n\\[\n    q_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) √® l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme di dati ordinato in modo crescente, e \\(k\\) √® calcolato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) √® il numero totale di dati nel campione, e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all‚Äôintero successivo. In questa definizione, il quantile non interpolato corrisponde al valore effettivo nell‚Äôinsieme di dati, senza effettuare alcuna interpolazione tra i valori circostanti.\nAd esempio, consideriamo il seguente insieme di dati: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}\\). Supponiamo di voler calcolare il quantile non interpolato di ordine \\(p = 0.3\\) (cio√® il 30¬∞ percentile).\nOrdiniamo i dati in modo crescente: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\\) Calcoliamo \\(k\\) utilizzando la formula \\(k = \\lceil p \\cdot n \\rceil\\), dove \\(n\\) √® il numero totale di dati nel campione. Nel nostro caso, \\(n = 10\\) e \\(p = 0.3\\):\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\nIl quantile non interpolato corrisponde al valore \\(x_{(k)}\\), ovvero l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme ordinato: \\(q_{0.3} = x_{(3)} = 23.\\)\nOltre al quantile non interpolato, esiste anche il concetto di quantile interpolato. A differenza del quantile non interpolato, il quantile interpolato pu√≤ essere calcolato anche per percentili che non corrispondono esattamente a valori presenti nell‚Äôinsieme di dati. Per ottenere il valore del quantile interpolato, viene utilizzato un procedimento di interpolazione lineare tra i valori adiacenti. In genere, il calcolo del quantile interpolato viene eseguito mediante l‚Äôuso di software dedicati.\nOra, procediamo al calcolo dei quantili di ordine 0.10 e 0.90 per i valori math all‚Äôinterno dei due gruppi. I quantili sono dei valori che dividono la distribuzione dei dati in parti specifiche. Ad esempio, il quantile di ordine 0.10 corrisponde al valore al di sotto del quale si trova il 10% dei dati, mentre il quantile di ordine 0.90 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\nCalcoliamo i quantili di ordine 0.1 e 0.9 della distribuzione dei punteggi math nei due gruppi definiti dalla variabile graduated.\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.1), \n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.9)\n]\n\n[588.0, 684.0]\n\n\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che non hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.1),\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.9),\n]\n\n[564.5, 651.0]\n\n\n\n\n16.2.4 Moda e mediana\nIn precedenza abbiamo gi√† incontrato altri due popolari indici di tendenza centrale: la moda (Mo), che rappresenta il valore centrale della classe con la frequenza massima (in alcune distribuzioni pu√≤ esserci pi√π di una moda, rendendola multimodale e facendo perdere a questo indice il suo significato di indicatore di tendenza centrale); e la mediana (\\(\\tilde{x}\\)), che rappresenta il valore corrispondente al quantile di ordine 0.5 della distribuzione.\n\n\n16.2.5 Quando usare media, moda, mediana\nLa moda pu√≤ essere utilizzata per dati a livello nominale o ordinale ed √® l‚Äôunica tra le tre statistiche che pu√≤ essere calcolata in questi casi.\nLa media, d‚Äôaltra parte, √® una buona misura di tendenza centrale solo se la distribuzione dei dati √® simmetrica, ossia se i valori sono distribuiti uniformemente a sinistra e a destra della media. Tuttavia, se ci sono valori anomali o se la distribuzione √® asimmetrica, la media pu√≤ essere influenzata in modo significativo e, pertanto, potrebbe non essere la scelta migliore come misura di tendenza centrale.\nIn queste situazioni, la mediana pu√≤ fornire una misura migliore di tendenza centrale rispetto alla media poich√© √® meno influenzata dai valori anomali e si basa esclusivamente sul valore centrale dell‚Äôinsieme di dati. Di conseguenza, la scelta tra media e mediana dipende dal tipo di distribuzione dei dati e dagli obiettivi dell‚Äôanalisi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#indici-di-dispersione",
    "href": "chapters/chapter_2/04_loc_scale.html#indici-di-dispersione",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.3 Indici di dispersione",
    "text": "16.3 Indici di dispersione\nLe misure di posizione descritte in precedenza, come le medie e gli indici di posizione, offrono una sintesi dei dati mettendo in evidenza la tendenza centrale delle osservazioni. Tuttavia, trascurano un aspetto importante della distribuzione dei dati: la variabilit√† dei valori numerici della variabile statistica. Pertanto, √® essenziale completare la descrizione della distribuzione di una variabile statistica utilizzando anche indicatori che valutino la dispersione delle unit√† statistiche. In questo modo, otterremo una visione pi√π completa e approfondita delle caratteristiche del campione analizzato.\n\n16.3.1 Indici basati sull‚Äôordinamento dei dati\nPer valutare la variabilit√† dei dati, √® possibile utilizzare indici basati sull‚Äôordinamento dei dati. L‚Äôindice pi√π semplice √® l‚Äôintervallo di variazione, che corrisponde alla differenza tra il valore massimo e il valore minimo di una distribuzione di dati. Tuttavia, questo indice ha il limite di essere calcolato basandosi solo su due valori della distribuzione, e non tiene conto di tutte le informazioni disponibili. Inoltre, l‚Äôintervallo di variazione pu√≤ essere fortemente influenzato dalla presenza di valori anomali.\nUn altro indice basato sull‚Äôordinamento dei dati √® la differenza interquartile, gi√† incontrata in precedenza. Anche se questo indice utilizza pi√π informazioni rispetto all‚Äôintervallo di variazione, presenta comunque il limite di essere calcolato basandosi solo su due valori della distribuzione, ossia il primo quartile \\(Q_1\\) e il terzo quartile \\(Q_3\\).\nPer valutare la variabilit√† in modo pi√π completo, √® necessario utilizzare altri indici di variabilit√† che tengano conto di tutti i dati disponibili. In questo modo, si otterr√† una valutazione pi√π accurata della dispersione dei valori nella distribuzione e si potranno individuare eventuali pattern o tendenze nascoste.\n\n\n16.3.2 Varianza\nDate le limitazioni delle statistiche descritte in precedenza, √® pi√π comune utilizzare una misura di variabilit√† che tenga conto della dispersione dei dati rispetto a un indice di tendenza centrale. La varianza √® la misura di variabilit√† pi√π utilizzata per valutare la variabilit√† di una variabile statistica. Essa √® definita come la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione, come segue:\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\end{equation}\n\\tag{16.3}\\]\nLa varianza √® una misura di dispersione pi√π completa rispetto a quelle descritte in precedenza. Tuttavia, √® appropriata solo nel caso di distribuzioni simmetriche ed √® fortemente influenzata dai valori anomali, come altre misure di dispersione. Inoltre, la varianza √® espressa in un‚Äôunit√† di misura che √® il quadrato dell‚Äôunit√† di misura dei dati originali, pertanto, potrebbe non essere facilmente interpretata in modo intuitivo.\nCalcoliamo la varianza dei valori math per i dati del progetto STAR. Applicando l‚Äôequazione della varianza, otteniamo:\n\nsum((df[\"math\"] - np.mean(df[\"math\"])) ** 2) / len(df[\"math\"])\n\n1507.2328523125227\n\n\nPi√π semplicemente, possiamo usare la funzione np.var():\n\nnp.var(df[\"math\"])\n\n1507.2328523125227\n\n\n\n16.3.2.1 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell‚ÄôEquazione¬†16.3, ho utilizzato \\(n\\) come denominatore (l‚Äôampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, √® possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{16.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si pu√≤ dimostrare che l‚ÄôEquazione¬†16.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l‚ÄôEquazione¬†16.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione √® illustrata nella figura seguente.\n\nx = np.arange(100 - 4 * 15, 100 + 4 * 15, 0.001)\n\nmu = 100\nsigma = 15\n\ncolor_edge = \"#8f2727\"\npdf = stats.norm.pdf(x, mu, sigma)\nplt.plot(x, pdf, color=color_edge)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()\n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza ‚Äì in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nx = rng.normal(loc=100, scale=15, size=4)\nprint(x)\n\n[ 96.66036673 119.88488115  91.43544977 110.02373805]\n\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza √® \\(15^2\\) = 225.\n\nnp.var(x)\n\n134.65656223872708\n\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nIl primo campione √®\n\nrandom_samples[0]\n\narray([133.75543403, 101.43900843,  94.59994101,  92.23138768])\n\n\nIl decimo campione √®\n\nrandom_samples[9]\n\narray([ 89.06126415, 109.72357033, 119.31191461, 125.38475089])\n\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs = np.array(random_samples)\nrs\n\narray([[133.75543403, 101.43900843,  94.59994101,  92.23138768],\n       [105.84924945, 124.12259109,  95.58010071,  76.35634967],\n       [ 80.23586783, 114.3021062 ,  98.54492676,  91.47149307],\n       [114.26794026,  86.66403178,  79.74954446, 102.23174837],\n       [110.22926012,  80.75554712, 100.93634803,  83.44336602],\n       [ 80.68461566, 122.39378237, 115.0707391 ,  85.53365763],\n       [ 82.42398628,  99.06628072,  95.40790879,  95.03682044],\n       [ 86.56471564,  97.82411638,  98.28650923,  99.23388255],\n       [120.24780337,  94.92211176,  87.6421954 ,  89.48037814],\n       [ 89.06126415, 109.72357033, 119.31191461, 125.38475089]])\n\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo cos√¨ 10 stime della varianza della popolazione del QI.\n\nx_var = np.var(rs, axis=1)  # applichiamo la funzione su ciascuna riga\nprint(x_var)\n\n[277.43209934 298.44010918 152.5955359  180.87367224 149.56472568\n 326.89426388  39.64935846  26.73631903 171.07120901 189.71979388]\n\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno √® noto con il nome di variabilit√† campionaria;\nin media le stime sembrano troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=0, axis=1)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(x_var, bins=10, color=color_fill, edgecolor=color_edge)\nplt.xlabel(\"Varianza\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Varianza del QI in campioni di n = 4\")\nplt.show()\n\n\n\n\n\n\n\n\nLa stima pi√π verosimile della varianza del QI √® dato dalla media di questa distribuzione.\n\nnp.mean(x_var)\n\n170.04960311858687\n\n\nSi noti che il nostro spospetto √® stato confermato: il valore medio della stima della varianza ottenuta con l‚ÄôEquazione¬†16.3 √® troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=1, axis=1)\n\nnp.mean(x_var)\n\n226.57872540048734\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima √® molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilit√† di un particolare campione di osservazioni. D‚Äôaltro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione √® stato estratto.\n\n\n\n16.3.3 Deviazione standard\nPer interpretare la varianza in modo pi√π intuitivo, si pu√≤ calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard √® espressa nell‚Äôunit√† di misura originaria dei dati, a differenza della varianza che √® espressa nel quadrato dell‚Äôunit√† di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo pi√π facile la comprensione della variabilit√† dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) √® definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{16.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation √® stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano ‚Äúdeviazione standard‚Äù ne √® la traduzione pi√π utilizzata nel linguaggio comune; il termine dell‚ÄôEnte Nazionale Italiano di Unificazione √® tuttavia ‚Äúscarto tipo‚Äù, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media √® una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, √® importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard pu√≤ risultare ingannevole e non rappresentare accuratamente la variabilit√† complessiva della distribuzione. Pertanto, √® fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere pi√π appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilit√† dei dati in modo pi√π accurato e affidabile.\nPer fare un esempio, calcoliamo la deviazione standard per i valori math del campione di dati del progetto STAR. Applicando l‚ÄôEquazione¬†16.5, per tutto il campione abbiamo\n\nnp.std(df.math)\n\n38.82309689234648\n\n\nPer ciascun gruppo, abbiamo:\n\ndf.groupby(\"graduated\")[\"math\"].std()\n\ngraduated\n0    34.105746\n1    38.130136\nName: math, dtype: float64\n\n\n\n16.3.3.1 Interpretazione\nLa deviazione standard pu√≤ essere interpretata in modo semplice: essa rappresenta la dispersione dei dati rispetto alla media aritmetica. √à simile allo scarto semplice medio campionario, cio√® alla media aritmetica dei valori assoluti degli scarti tra ciascuna osservazione e la media, anche se non √® identica. La deviazione standard ci fornisce un‚Äôindicazione di quanto, in media, le singole osservazioni si discostino dal centro della distribuzione.\nPer verificare l‚Äôinterpretazione della deviazione standard, utilizziamo i valori math del campione di dati del progetto STAR.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nLa deviazione standard calcolata per questi dati √® \\(\\approx 38.8\\). Questo valore ci indica che, in media, ogni osservazione si discosta di circa 38.8 punti dalla media aritmetica dei punteggi math. Maggiore √® il valore della deviazione standard, maggiore √® la dispersione dei dati attorno alla media, mentre un valore pi√π piccolo indica che i dati sono pi√π concentrati vicino alla media. La deviazione standard ci offre quindi una misura quantitativa della variabilit√† dei dati nella distribuzione.\nPer questi dati, lo scarto semplice medio campionario √®\n\nnp.mean(np.abs(df.math - np.mean(df.math)))\n\n30.9682664274501\n\n\nSi noti che i due valori sono simili, ma non identici.\n\n\n\n16.3.4 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione √® la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana. Matematicamente, la formula per calcolare la MAD √®:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{16.6}\\]\nLa deviazione mediana assoluta √® particolarmente utile quando si affrontano distribuzioni con presenza di dati anomali o asimmetrie, poich√© √® meno influenzata da questi valori estremi rispetto alla deviazione standard.\nQuando i dati seguono una distribuzione gaussiana (normale), esiste una relazione specifica tra MAD e la deviazione standard (si veda il Capitolo {ref}cont-rv-distr-notebook). In una distribuzione normale, la MAD √® proporzionale alla deviazione standard. La costante di proporzionalit√† dipende dalla forma esatta della distribuzione normale, ma in generale, la relazione √® data da:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove: - $ $ √® la deviazione standard. - MAD √® la Mediana della Deviazione Assoluta. - $ k $ √® una costante che, per una distribuzione normale, √® tipicamente presa come circa 1.4826.\nQuesta costante di 1.4826 √® derivata dal fatto che, in una distribuzione normale, circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media. Quindi, per convertire la MAD (basata sulla mediana) nella deviazione standard (basata sulla media), si usa il reciproco di 0.6745, che √® approssimativamente 1.4826.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale √®:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione √® utile per stimare la deviazione standard in modo pi√π robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un‚Äôindicazione pi√π intuitiva della variabilit√† dei dati. Tuttavia, √® importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilit√† dei dati.\nPer verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori math del campione di dati del progetto STAR.\n\n1.4826 * np.median(np.abs(df[\"math\"] - np.median(df[\"math\"])))\n\n41.5128\n\n\nIn questo caso, la MAD per i punteggi di matematica √® simile alla deviazione standard.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nInfatti, la distribuzione dei punteggi math √® approssimativamente gaussiana.\n\nplt.hist(df[\"math\"], bins=10, color=color_fill, edgecolor=color_edge)\nplt.xlabel(\"math\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione dei Punteggi di Matematica\")\nplt.show()\n\n\n\n\n\n\n\n\nVerifichiamo nuovamente il principio usando un campione di dati estratto da una popolazione normale. Usiamo, ad esempio, la distribuzione \\(\\mathcal{N}(100, 15)\\):\n\nx = np.random.normal(loc=100, scale=15, size=10000)\n1.4826 * np.median(np.abs(x - np.median(x)))\n\n15.152283592574692\n\n\n\n\n16.3.5 Quando usare la deviazione standard e MAD\nLa deviazione standard e la MAD sono entrambe misure di dispersione che forniscono informazioni su quanto i dati in un insieme si discostano dalla tendenza centrale. Tuttavia, ci sono alcune differenze tra le due misure e situazioni in cui pu√≤ essere pi√π appropriato utilizzare una rispetto all‚Äôaltra.\n\nDeviazione standard: Questa misura √® particolarmente utile per descrivere la dispersione dei dati in una distribuzione normale. La deviazione standard √® una scelta appropriata se si vuole sapere quanto i dati sono distribuiti intorno alla media, o se si vuole confrontare la dispersione di due o pi√π set di dati. Tuttavia, la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, e questo pu√≤ rappresentare una limitazione in casi in cui sono presenti valori estremi nell‚Äôinsieme di dati.\nDeviazione mediana assoluta (MAD): La MAD √® meno sensibile ai valori anomali rispetto alla deviazione standard, il che la rende una scelta migliore quando ci sono valori anomali nell‚Äôinsieme di dati. Inoltre, la MAD pu√≤ essere una buona scelta quando si lavora con dati non normalmente distribuiti, poich√© non assume una distribuzione specifica dei dati. La MAD √® calcolata utilizzando la mediana e i valori assoluti delle deviazioni dei dati dalla mediana, il che la rende una misura robusta di dispersione.\n\nIn sintesi, se si sta lavorando con dati normalmente distribuiti, la deviazione standard √® la misura di dispersione pi√π appropriata. Se si lavora con dati non normalmente distribuiti o si hanno valori anomali nell‚Äôinsieme di dati, la MAD pu√≤ essere una scelta migliore. In ogni caso, la scelta tra le due misure dipende dal tipo di dati che si sta analizzando e dall‚Äôobiettivo dell‚Äôanalisi.\n\n\n16.3.6 Indici di variabilit√† relativi\nA volte pu√≤ essere necessario confrontare la variabilit√† di grandezze incommensurabili, ovvero di caratteri misurati con differenti unit√† di misura. In queste situazioni, le misure di variabilit√† descritte in precedenza diventano inadeguate poich√© dipendono dall‚Äôunit√† di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilit√†.\nIl pi√π importante di questi indici √® il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{16.7}\\]\nIl coefficiente di variazione √® un numero puro e permette di confrontare la variabilit√† di distribuzioni con unit√† di misura diverse.\nUn altro indice relativo di variabilit√† √® la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice √® definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilit√† forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unit√† di misura e facilitando l‚Äôanalisi delle differenze di variabilit√† tra i dati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/chapter_2/04_loc_scale.html#la-fallacia-ergodica",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.4 La fallacia ergodica",
    "text": "16.4 La fallacia ergodica\nSebbene il concetto di ‚Äúmedia‚Äù possa sembrare chiaro, ci√≤ non implica che il suo utilizzo non presenti delle problematiche nell‚Äôambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi √® ci√≤ che viene definito ‚Äúfallacia ergodica‚Äù.\nIl concetto di ‚Äúfallacia ergodica‚Äù (Speelman et al. 2024) si riferisce all‚Äôerrore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all‚Äôinterno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio √® che l‚Äôuso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo √® ingiustificato, poich√© le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull‚Äôassunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere cos√¨ simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all‚Äôinterno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di pi√π individui non descrivono accuratamente nessuno di quegli individui in un dato momento, n√© possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell‚Äôassumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_2/04_loc_scale.html#commenti-e-considerazioni-finali",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.5 Commenti e considerazioni finali",
    "text": "16.5 Commenti e considerazioni finali\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un‚Äôidea della variabilit√† dei dati. In sintesi, le statistiche descrittive ci offrono un quadro chiaro e sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilit√†.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/04_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "16.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, e Marek McGann. 2024. ¬´Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals¬ª. Collabra: Psychology 10 (1).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html",
    "href": "chapters/chapter_2/05_correlation.html",
    "title": "17¬† Le relazioni tra variabili",
    "section": "",
    "text": "17.1 Introduzione\nNel linguaggio comune, termini quali ‚Äúdipendenza‚Äù, ‚Äúassociazione‚Äù e ‚Äúcorrelazione‚Äù sono spesso utilizzati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, ‚Äúassociazione‚Äù e ‚Äúdipendenza‚Äù sono sinonimi e entrambi si distinguono dalla ‚Äúcorrelazione‚Äù. L‚Äôassociazione implica una relazione molto ampia: conoscere il valore di una variabile ci fornisce informazioni su un‚Äôaltra variabile. Al contrario, la correlazione descrive una relazione pi√π specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico; ad esempio, in una tendenza crescente, se $ X &gt; _X $ allora √® probabile che anche $ Y &gt; _Y $.\n√à cruciale comprendere che non tutte le associazioni sono correlazioni e che, crucialmente, la correlazione non implica causalit√†. Questa distinzione √® vitale per interpretare accuratamente i dati e per evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, ci concentreremo su due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi strumenti sono essenziali per analizzare il grado e la direzione dell‚Äôassociazione lineare tra le variabili, permettendoci di quantificare in che modo le variabili variano congiuntamente.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#i-dati-grezzi",
    "href": "chapters/chapter_2/05_correlation.html#i-dati-grezzi",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.2 I dati grezzi",
    "text": "17.2 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione √® stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II √® uno strumento di autovalutazione utilizzato per valutare la gravit√† della depressione in adulti e adolescenti. Il test √® stato sviluppato per identificare e misurare l‚Äôintensit√† dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado pi√π basso e 3 il grado pi√π elevato di sintomatologia depressiva.\nNell‚Äôesercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche, Buerkner, e Renneberg (2019).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/chapter_2/05_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.3 Definizione delle relazioni tra variabili",
    "text": "17.3 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o pi√π variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ci√≤, prendiamo ad esempio l‚Äôaltezza e l‚Äôet√† tra un gruppo di bambini. In generale, √® possibile notare che all‚Äôaumentare dell‚Äôet√† di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l‚Äôet√† di un bambino, ad esempio tredici anni, e l‚Äôet√† di un altro, sei anni, ci fornisce un‚Äôindicazione su quale dei due bambini sia pi√π alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e et√† come positiva, il che significa che all‚Äôaumentare dei valori di una delle variabili (in questo caso, l‚Äôet√†), ci aspettiamo di vedere valori pi√π elevati anche nell‚Äôaltra variabile (l‚Äôaltezza). Tuttavia, esistono anche relazioni negative, in cui l‚Äôaumento di una variabile √® associato a un diminuzione dell‚Äôaltra (ad esempio, pi√π et√† √® correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo cos√¨ una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili pu√≤ essere categorica, rendendo difficile parlare di ‚Äúmaggioranza‚Äù o ‚Äúminoranza‚Äù ma piuttosto di ‚Äúdifferente‚Äù (ad esempio, i bambini pi√π grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini pi√π piccoli, senza necessariamente essere ‚Äúmigliori‚Äù o ‚Äúpeggiori‚Äù).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#sec-scatter-plot",
    "href": "chapters/chapter_2/05_correlation.html#sec-scatter-plot",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.4 Grafico a dispersione",
    "text": "17.4 Grafico a dispersione\nIl metodo pi√π diretto per visualizzare la relazione tra due variabili continue √® tramite un grafico a dispersione, comunemente noto come ‚Äúscatterplot‚Äù. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull‚Äôasse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l‚Äôidea pi√π chiara, consideriamo i dati dello studio condotto da Zetsche, Buerkner, e Renneberg (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II √® uno strumento di autovalutazione che valuta la presenza e l‚Äôintensit√† dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D √® una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poich√© entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf = pd.read_csv(\"../../data/data.mood.csv\", index_col=0)\n\n# Seleziona le colonne di interesse\ndf = df[[\"esm_id\", \"group\", \"bdi\", \"cesd_sum\"]]\n\n# Rimuovi le righe duplicate\ndf = df.drop_duplicates(keep=\"first\")\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf = df.dropna(subset=[\"bdi\"])\n\nPosizionando i valori del BDI-II sull‚Äôasse delle ascisse e quelli del CES-D sull‚Äôasse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. √à evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l‚Äôutilizzo di unit√† di misura arbitrarie per le due variabili. L‚Äôerrore di misurazione √® una componente inevitabile che influisce in parte su qualsiasi misurazione, ed √® particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione √® generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici √® che l‚Äôunit√† di misura della depressione √® una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all‚Äôuso di unit√† di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di ‚Äúassociazione lineare‚Äù, √® possibile esaminare i dati attraverso l‚Äôutilizzo di un diagramma a dispersione.\n\n# Crea uno scatterplot con colori diversi per i due gruppi\nplt.scatter(df[df[\"group\"] == \"mdd\"][\"bdi\"], df[df[\"group\"] == \"mdd\"][\"cesd_sum\"], label=\"Pazienti\", c=\"C0\")\nplt.scatter(df[df[\"group\"] == \"ctl\"][\"bdi\"], df[df[\"group\"] == \"ctl\"][\"cesd_sum\"], label=\"Controlli\", c=\"C2\")\n\n# Calcola i coefficienti della retta dei minimi quadrati\ncoeff_combined = np.polyfit(df[\"bdi\"], df[\"cesd_sum\"], 1)\n\n# Calcola la retta dei minimi quadrati\nline_combined = np.poly1d(coeff_combined)\n\n# Disegna la retta dei minimi quadrati\nx_values = np.linspace(df[\"bdi\"].min(), df[\"bdi\"].max(), 100)\nplt.plot(x_values, line_combined(x_values), linestyle='--', color='C3')\n\n# Etichette degli assi\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"CESD\")\n\n# Linee verticali ed orizzontali per le medie\nplt.axvline(np.mean(df[df[\"group\"] == \"mdd\"][\"bdi\"]), alpha=0.2, color=\"blue\")\nplt.axvline(np.mean(df[df[\"group\"] == \"ctl\"][\"bdi\"]), alpha=0.2, color=\"red\")\nplt.axhline(np.mean(df[df[\"group\"] == \"mdd\"][\"cesd_sum\"]), alpha=0.2, color=\"blue\")\nplt.axhline(np.mean(df[df[\"group\"] == \"ctl\"][\"cesd_sum\"]), alpha=0.2, color=\"red\")\n\n# Legenda\nplt.legend()\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, √® evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ci√≤ suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, √® importante notare che la relazione lineare tra le due variabili √® lontana dall‚Äôessere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realt√†, la dispersione dei punti dal comportamento lineare ideale √® evidente.\nDi conseguenza, sorge la necessit√† di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#covarianza",
    "href": "chapters/chapter_2/05_correlation.html#covarianza",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.5 Covarianza",
    "text": "17.5 Covarianza\nIniziamo a considerare il pi√π importante di tali indici, chiamato covarianza. In realt√† la definizione di questo indice non ci sorprender√† pi√π di tanto in quanto, in una forma solo apparentemente diversa, l‚Äôabbiamo gi√† incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) √® definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la ‚Äúcovarianza di una variabile con s√© stessa‚Äù. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) ‚Äúvariano insieme‚Äù (co-variano). √à facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{17.1}\\]\nL‚ÄôEquazione¬†17.1 ci fornisce la definizione della covarianza.\n\n17.5.1 Interpretazione\nPer capire il significato dell‚ÄôEquazione¬†17.1, supponiamo di dividere il grafico riportato nella ?sec-introduction in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avr√† un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avr√† segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avr√† un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avr√† segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l‚Äôassociazione lineare si dice positiva se la covarianza √® positiva, negativa se la covarianza √® negativa.\nEsercizio. Implemento l‚ÄôEquazione¬†17.1 in Python.\n\ndef cov_value(x, y):\n\n    mean_x = sum(x) / float(len(x))\n    mean_y = sum(y) / float(len(y))\n\n    sub_x = [i - mean_x for i in x]\n    sub_y = [i - mean_y for i in y]\n\n    sum_value = sum([sub_y[i] * sub_x[i] for i in range(len(x))])\n    denom = float(len(x))\n\n    cov = sum_value / denom\n    return cov\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD √® 207.4\n\nx = df[\"bdi\"]\ny = df[\"cesd_sum\"]\n\ncov_value(x, y)\n\n207.42653810835637\n\n\nOppure, in maniera pi√π semplice:\n\nnp.mean((x - np.mean(x)) * (y - np.mean(y)))\n\n207.42653810835628\n\n\nLo stesso risultato si ottiene con la funzione cov di NumPy.\n\nnp.cov(x, y, ddof=0)\n\narray([[236.23875115, 207.42653811],\n       [207.42653811, 222.83379247]])\n\n\nLa funzione np.cov(x, y, ddof=0) in Python, utilizzata tramite la libreria NumPy, calcola la covarianza tra due array, x e y. L‚Äôargomento ddof (Delta Degrees of Freedom) specifica il ‚Äúcorrettore‚Äù da applicare al denominatore della formula di covarianza.\nQuando si imposta ddof=0, la formula utilizzata per il calcolo della covarianza divide la somma dei prodotti delle deviazioni dalla media per n, dove n √® il numero totale degli elementi nel campione (ovvero, la dimensione del campione). Questo approccio assume che i dati forniti rappresentino l‚Äôintera popolazione da cui si vuole stimare la covarianza, producendo una stima non corretta (bias) se i dati sono effettivamente un campione di una popolazione pi√π ampia. Il ‚Äúbias‚Äù in questo contesto si riferisce al fatto che la stima tende sistematicamente a essere pi√π piccola rispetto alla vera covarianza della popolazione da cui il campione √® stato estratto.\nPer correggere questo errore sistematico e ottenere una stima non distorta (unbiased) della covarianza di una popolazione pi√π ampia basandosi su un campione, si utilizza ddof=1. Questo significa che al denominatore della formula si sottrae 1 a n, dividendo quindi per n-1. Il correttore n-1 √® noto come correttore di Bessel, e l‚Äôuso di ddof=1 rende la stima della covarianza non distorta nel contesto di un campione prelevato da una popolazione. La correzione √® importante in statistica perch√© fornisce una stima pi√π accurata delle propriet√† della popolazione, soprattutto quando la dimensione del campione √® piccola.\nIn sintesi: - Con ddof=0, si divide per n, assumendo che i dati rappresentino l‚Äôintera popolazione. Questo pu√≤ introdurre un bias nella stima della covarianza se i dati sono in realt√† un campione. - Con ddof=1, si divide per n-1, correggendo il bias e ottenendo una stima non distorta (unbiased) della covarianza se i dati rappresentano un campione di una popolazione pi√π grande. Questo approccio √® generalmente preferito per la stima delle propriet√† della popolazione basata su campioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#correlazione",
    "href": "chapters/chapter_2/05_correlation.html#correlazione",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.6 Correlazione",
    "text": "17.6 Correlazione\nLa direzione della relazione tra le variabili √® indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poich√© dipende dall‚Äôunit√† di misura delle variabili. Ad esempio, considerando l‚Äôaltezza e il peso delle persone, la covarianza sar√† pi√π grande se l‚Äôaltezza √® misurata in millimetri e il peso in grammi, rispetto al caso in cui l‚Äôaltezza √® in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l‚Äôindice di correlazione.\nLa correlazione √® ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr_{XY} = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{17.2}\\]\nLa quantit√† che si ottiene dall‚ÄôEquazione¬†17.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l‚Äôuno dall‚Äôaltro, l‚Äôhanno introdotta).\n\n17.6.1 Propriet√†\nIl coefficiente di correlazione ha le seguenti propriet√†:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\n√® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n17.6.2 Interpretazione\nAll‚Äôindice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensit√† diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza √® 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c‚Äô√® un‚Äôassociazione lineare positiva. Per capire quale sia l‚Äôintensit√† della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore √® prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\nnp.corrcoef(x, y)\n\narray([[1.        , 0.90406202],\n       [0.90406202, 1.        ]])\n\n\nReplichiamo il risultato implementando l‚Äôeq. {eq}eq-cor-def:\n\ns_xy = np.mean((x - np.mean(x)) * (y - np.mean(y)))\ns_x = x.std(ddof=0)\ns_y = y.std(ddof=0)\nr_xy = s_xy / (s_x * s_y)\nprint(r_xy)\n\n0.9040620189474861\n\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD √® quello di standardizzare le due variabili per poi applicare la formula della covarianza:\n\nz_x = (x - np.mean(x)) / np.std(x, ddof=0)\nz_y = (y - np.mean(y)) / np.std(y, ddof=0)\nnp.mean(z_x * z_y)\n\n0.9040620189474862\n\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al.¬†(2024). Il concetto di ‚Äúgender bias‚Äù si riferisce alla tendenza sistematica di favorire un sesso rispetto all‚Äôaltro, spesso a scapito delle donne. Lo studio di Guilbeault et al.¬†(2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralit√† di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella societ√†. Il lavoro di Guilbeault et al.¬†(2024) evidenzia che il preconcetto di genere √® molto pi√π evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto pu√≤ essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al.¬†(2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura √® vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi √® alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralit√† di genere. In sostanza, questa misura di frequenza pu√≤ essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell‚Äôaltro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere √® pi√π prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell‚Äôassociazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione √® stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al.¬†(2024)).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#correlazione-di-spearman",
    "href": "chapters/chapter_2/05_correlation.html#correlazione-di-spearman",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.7 Correlazione di Spearman",
    "text": "17.7 Correlazione di Spearman\nUn‚Äôalternativa per valutare la relazione lineare tra due variabili √® il coefficiente di correlazione di Spearman, che si basa esclusivamente sull‚Äôordine dei dati e non sugli specifici valori. Questo indice di associazione √® particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalit√† di risposta dei soggetti, ma non l‚Äôintensit√† della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come ‚Äúordinali‚Äù.\n\n\n\n\n\n\n√à importante ricordare che, nel caso di una variabile ordinale, non √® possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, √® possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalit√† di risposta. Come abbiamo appena visto, la direzione e l‚Äôintensit√† dell‚Äôassociazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\nstats.spearmanr([1, 2, 3, 4, 5], [5, 6, 7, 8, 7])\n\nSignificanceResult(statistic=0.8207826816681233, pvalue=0.08858700531354381)",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#correlazione-nulla",
    "href": "chapters/chapter_2/05_correlation.html#correlazione-nulla",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.8 Correlazione nulla",
    "text": "17.8 Correlazione nulla\nUn aspetto finale da sottolineare riguardo alla correlazione √® che essa descrive la direzione e l‚Äôintensit√† della relazione lineare tra due variabili. Tuttavia, la correlazione non cattura relazioni non lineari tra le variabili, anche se possono essere molto forti. √à fondamentale comprendere che una correlazione pari a zero non implica l‚Äôassenza di una relazione tra le due variabili, ma indica solamente l‚Äôassenza di una relazione lineare tra di esse.\nLa figura seguente fornisce tredici esempi di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili. In questi tredici insiemi di dati i coefficienti di correlazione di Pearson sono sempre uguali a 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n\ndatasaurus_data = pd.read_csv(\"../../data/datasaurus.csv\")\ndatasaurus_data.groupby(\"dataset\").agg(\n    {\"x\": [\"count\", \"mean\", \"std\"], \"y\": [\"count\", \"mean\", \"std\"]}\n)\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\ncount\nmean\nstd\ncount\nmean\nstd\n\n\ndataset\n\n\n\n\n\n\n\n\n\n\naway\n142\n54.266100\n16.769825\n142\n47.834721\n26.939743\n\n\nbullseye\n142\n54.268730\n16.769239\n142\n47.830823\n26.935727\n\n\ncircle\n142\n54.267320\n16.760013\n142\n47.837717\n26.930036\n\n\ndino\n142\n54.263273\n16.765142\n142\n47.832253\n26.935403\n\n\ndots\n142\n54.260303\n16.767735\n142\n47.839829\n26.930192\n\n\nh_lines\n142\n54.261442\n16.765898\n142\n47.830252\n26.939876\n\n\nhigh_lines\n142\n54.268805\n16.766704\n142\n47.835450\n26.939998\n\n\nslant_down\n142\n54.267849\n16.766759\n142\n47.835896\n26.936105\n\n\nslant_up\n142\n54.265882\n16.768853\n142\n47.831496\n26.938608\n\n\nstar\n142\n54.267341\n16.768959\n142\n47.839545\n26.930275\n\n\nv_lines\n142\n54.269927\n16.769959\n142\n47.836988\n26.937684\n\n\nwide_lines\n142\n54.266916\n16.770000\n142\n47.831602\n26.937902\n\n\nx_shape\n142\n54.260150\n16.769958\n142\n47.839717\n26.930002\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(4, 4, figsize=(15, 15))\ndatasets = datasaurus_data[\"dataset\"].unique()\n\nfor i, dataset in enumerate(datasets):\n    row = i // 4\n    col = i % 4\n    ax = axs[row, col]\n    subset = datasaurus_data[datasaurus_data[\"dataset\"] == dataset]\n    ax.scatter(subset[\"x\"], subset[\"y\"], alpha=0.7)\n    ax.set_title(dataset)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61607/188333220.py:14: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#considerazioni-conclusive",
    "href": "chapters/chapter_2/05_correlation.html#considerazioni-conclusive",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.9 Considerazioni conclusive",
    "text": "17.9 Considerazioni conclusive\nNel concludere questo capitolo dedicato allo studio di correlazione e covarianza, √® essenziale mettere in evidenza alcuni principi fondamentali. Il concetto di ‚Äúassociazione‚Äù equivale a quello di ‚Äúdipendenza‚Äù e pu√≤ manifestarsi sia attraverso cause dirette che indirette. Ci√≤ significa che variazioni in una variabile possono influenzare o essere influenzate da un‚Äôaltra, indipendentemente dalla natura diretta o mediata di questo legame.\nPer quanto riguarda la correlazione, questa descrive specifici tipi di associazione, come tendenze monotone. Ad esempio, la presenza di un incremento congiunto o di raggruppamenti in determinati intervalli tra due variabili √® indicativa di correlazione. √à per√≤ cruciale ricordare che correlazione non equivale a causalit√†; osservare una correlazione non implica necessariamente che una variabile causi l‚Äôaltra.\nNei contesti in cui il numero di variabili √® ampio rispetto alla grandezza del campione, possono emergere correlazioni elevate ma spurie. Questo accade perch√© un gran numero di variabili pu√≤ accidentalmente generare correlazioni elevate, non riflettendo un legame sostanziale tra di esse.\nD‚Äôaltra parte, con un numero elevato di osservazioni, anche le correlazioni pi√π deboli possono sembrare robuste. In campioni di grandi dimensioni, anche le pi√π piccole variazioni possono apparire accentuate rispetto alla variabilit√† generale del campione, bench√© queste correlazioni possano non avere una rilevanza pratica.\nIn conclusione, √® fondamentale adottare un approccio critico e ben informato nell‚Äôinterpretare i risultati delle analisi di correlazione e covarianza, tenendo sempre in considerazione le dimensioni del campione e il numero di variabili coinvolte. Tale prudenza aiuta a prevenire interpretazioni errate delle relazioni tra le variabili, specialmente riguardo alla causalit√†.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/05_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "17.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\npandas    : 2.2.2\nseaborn   : 0.13.2\narviz     : 0.18.0\nscipy     : 1.14.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html",
    "href": "chapters/chapter_2/06_causality.html",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "",
    "text": "18.1 Introduzione\nPer assicurare l‚Äôintegrit√† e la validit√† scientifica dei modelli statistici, √® essenziale abbinarli a un‚Äôanalisi causale. La pura osservazione dei dati pu√≤ rivelare correlazioni e pattern nei dati, ma senza un‚Äôindagine sulle cause che stanno dietro a queste correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nAnche nell‚Äôambito di una discussione sull‚Äôanalisi descrittiva dei dati (e, forse, soprattutto in un tale contesto), √® importante sottolineare le limitazioni di un tale approccio. L‚Äôaspetto cruciale da tenere a mente √® che le cause dei fenomeni non possono essere inferite solamente dall‚Äôanalisi dei dati. N√© dall‚Äôanalisi descrittiva dei dati che stiamo discutendo adesso, n√© dall‚Äôanalisi inferenziale dei dati che discuteremo in seguito. Pertanto, per giungere ad una comprensione dei fenomeni √® necessario integrare il processo di modellazione statistica con una comprensione delle cause sottostanti del fenomeno oggetto d‚Äôesame. In altre parole, per una comprensione scientificamente valida, √® necessario combinare la modellazione statistica con l‚Äôanalisi causale.\nIn questo capitolo, ci concentreremo sull‚Äôintroduzione dei concetti fondamentali dell‚Äôanalisi causale, i quali costituiscono una base cruciale per l‚Äôinterpretazione dei dati. Cominceremo con la distinzione tra correlazione e causalit√†. La correlazione indica una relazione tra due variabili, mettendo in evidenza la loro forza e direzione, mentre la causalit√† implica un legame di causa ed effetto tra le variabili. √à di importanza cruciale comprendere che il fatto che due variabili siano correlate non implica automaticamente l‚Äôesistenza di un rapporto causale tra di esse. Il noto principio ‚Äúcorrelazione non implica causalit√†‚Äù sottolinea questa distinzione critica. Numerosi esempi di correlazioni che non sono basate su una relazione causale diretta possono essere esaminati sul sito spurious correlations.\nOltre a questo concetto fondamentale, procederemo ad esplorare una serie di concetti introdotti da Judea Pearl nel suo testo ‚ÄúCausality‚Äù (Pearl 2009). Questi concetti sono essenziali per descrivere le relazioni tra variabili. Essi includono strutture di relazione come biforcazioni, catene, collider e strutture discendenti. Questa cornice concettuale ci permetter√† di distinguere tra i diversi tipi di legami causali tra le variabili, ponendo cos√¨ le basi per condurre un‚Äôanalisi dei dati pi√π completa e accurata.\nMediante esempi numerici, dimostreremo l‚Äôimportanza dei fattori confondenti nell‚Äôanalisi della correlazione e della covarianza. Questo passo ci condurr√† oltre l‚Äôanalisi delle relazioni bivariate di base, introducendoci alle dinamiche pi√π complesse che regolano le relazioni tra le variabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#cosa-significa-causalit√†",
    "href": "chapters/chapter_2/06_causality.html#cosa-significa-causalit√†",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.2 Cosa significa ‚Äúcausalit√†‚Äù?",
    "text": "18.2 Cosa significa ‚Äúcausalit√†‚Äù?\nCosa intendiamo esattamente quando diciamo che qualcosa √® ‚Äúcausale‚Äù? Perch√© √® importante capire la causalit√†?\nPerch√© molte delle domande di ricerca che ci interessano sono di natura causale. Ad esempio, non vogliamo solo sapere se le persone che fanno attivit√† fisica regolarmente hanno meno ansia; vogliamo sapere se fare attivit√† fisica riduce effettivamente i livelli di ansia. Non ci basta sapere se chi segue una terapia cognitivo-comportamentale (CBT) ha meno sintomi di depressione; vogliamo sapere se la terapia CBT ha realmente ridotto i sintomi depressivi. Non ci accontentiamo di sapere se l‚Äôuso frequente dei social media √® seguito da un calo del benessere mentale; vogliamo sapere se l‚Äôuso frequente dei social media causa un calo del benessere mentale.\nCerto, anche queste altre informazioni possono essere utili, ma in tal caso si tratta di domande di ricerca descrittive. Spesso, anche analisi e domande di ricerca non causali nascondono una domanda causale. Quante volte avete letto un titolo come ‚ÄúDormire meno di otto ore a notte √® collegato a una maggiore probabilit√† di sviluppare disturbi d‚Äôansia!‚Äù? Lo studio potrebbe non fare affermazioni causali, e ‚Äúcollegato a‚Äù non implica necessariamente causalit√†. Tuttavia, poich√© ‚Äúla mancanza di sonno provoca ansia?‚Äù (causale) √® una domanda molto pi√π intrigante di ‚Äúle persone che soffrono d‚Äôansia tendono a dormire meno?‚Äù (non causale), i lettori spesso interpretano erroneamente il risultato come causale.\nCi sono molte parole che generalmente implicano causalit√† e altre che descrivono relazioni senza implicare causalit√†. Ci sono anche alcuni termini ambigui che, pur non dicendo nulla sulla causalit√†, lasciano intendere tale relazione.\nQuali sono alcune di queste parole?\nPossiamo dire che A causa B usando espressioni come: A causa, influisce, l‚Äôeffetto di A su B, aumenta/diminuisce, cambia, porta a, determina, innesca, migliora, √® responsabile di, e cos√¨ via‚Ä¶\nPossiamo dire che A e B sono correlati senza implicare causalit√† usando espressioni come: sono associati, sono correlati, sono legati, tendono a verificarsi insieme, tendono a non verificarsi insieme, vanno insieme, e cos√¨ via‚Ä¶\nSe uno scrittore vuole suggerire la causalit√† senza affermarla esplicitamente, potrebbe usare termini come: √® collegato a, √® seguito da, ha conseguenze su, predice, le persone che sono pi√π propense a, accade mentre accade, e cos√¨ via.\nConoscere questi termini pu√≤ aiutarci a interpretare correttamente gli studi scientifici e a riconoscere quando qualcuno potrebbe cercare di ingannarci.\nAnalizzando questi termini possiamo anche comprendere meglio il concetto di causalit√†. I termini causali indicano una direzione: dicono che A influisce su B. I termini non causali, invece, non specificano quale dei due viene prima, ma descrivono solo come le due variabili sono correlate. I termini ambigui sono scritti in modo da suggerire una direzione da A a B, pur senza affermarlo esplicitamente.\nQuesta idea, che A influisce su B, ci aiuta a comprendere cos‚Äô√® la causalit√†.\nNon esiste una singola definizione di causalit√†, ma un buon modo di pensarci √® questo: possiamo dire che A causa B se, intervenendo e cambiando il valore di A, anche la distribuzione di B cambia di conseguenza.\nFacciamo un esempio. Diciamo che la terapia cognitivo-comportamentale (CBT) riduce l‚Äôansia. Se un gruppo di persone con ansia non segue alcuna terapia, i livelli di ansia rimangono invariati. Se interveniamo e iniziamo la CBT (cambiando il valore di A), i livelli di ansia nel gruppo diminuiscono (cambiando il valore di B di conseguenza). Questa definizione ci permette di distinguere tra correlazione e causalit√†.\nPossiamo anche usare questa definizione per collegare variabili lontane. Per esempio, l‚Äôautoefficacia di per s√© potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l‚Äôautoefficacia attraverso interventi mirati, probabilmente si osserver√† un miglioramento dell‚Äôimpegno nello studio. Quindi, l‚Äôaumento dell‚Äôautoefficacia causa un miglioramento dell‚Äôimpegno nello studio. E se aumentiamo l‚Äôimpegno nello studio, questo migliorer√† le prestazioni accademiche. Quindi, indirettamente, l‚Äôautoefficacia influisce sulle prestazioni accademiche. Tuttavia, dire che qualcosa causa qualcos‚Äôaltro non implica necessariamente in quale direzione. Se vogliamo essere pi√π specifici, dobbiamo dirlo chiaramente.\nUn‚Äôulteriore precisazione √® che diremo che A causa B anche se cambiare A non sempre cambia B, ma cambia solo la probabilit√† che B si verifichi. Cambia la distribuzione di B. Un‚Äôaltra precisazione √® che la definizione implica una questione su se le variabili che non possono essere effettivamente manipolate - come il tratto di personalit√† - possano causare qualcosa. Si pu√≤ comunque chiedere cosa sarebbe successo se il tratto di personalit√† di una persona fosse stato diverso, una sorta di manipolazione teorica.\nIn conclusione, la causalit√† implica che un cambiamento in A provoca un cambiamento in B, anche se non sempre in modo diretto e certo, ma cambiando la probabilit√† che B si verifichi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#inferenza-causale",
    "href": "chapters/chapter_2/06_causality.html#inferenza-causale",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.3 Inferenza Causale",
    "text": "18.3 Inferenza Causale\nL‚Äôinferenza causale si pone l‚Äôobiettivo di rappresentare il processo sottostante a un fenomeno, permettendo di prevedere gli effetti di un intervento. Oltre a prevedere le conseguenze di una causa, consente di esplorare scenari controfattuali, immaginando gli esiti alternativi che si sarebbero verificati con decisioni diverse. Questo tipo di ragionamento √® cruciale sia in contesti descrittivi che inferenziali.\nMcElreath (2020) utilizza l‚Äôanalogia dei Golem, potenti ma privi di saggezza e previsione, per descrivere un approccio limitato che √® stato a lungo lo standard in psicologia. Questo approccio si concentra sul semplice test delle ipotesi nulle e non stabilisce una relazione chiara tra le problematiche causali della ricerca e i test statistici. Tale limitazione √® stata identificata come una delle principali cause della crisi di replicabilit√† dei risultati nella ricerca psicologica (si veda il capitolo {ref}generalizability-crisis-notebook) e, di conseguenza, della crisi della psicologia stessa.\n\n\n\nEsempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall‚Äôalto, l‚Äôutente risponde a una serie di domande riguardanti la misurazione e l‚Äôintento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).\n\n\nUn problema evidenziato da McElreath (2020) √® che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sul test dell‚Äôipotesi nulla non √® in grado di distinguere tra questi diversi scenari. Questa limitazione √® dimostrata numericamente nel capitolo {ref}causal-inference-notebook.\nIl test dell‚Äôipotesi nulla, ovvero l‚Äôapproccio frequentista, nonostante sia stato ampiamente utilizzato in psicologia per decenni, ha mostrato una bassa sensibilit√† nel rilevare le caratteristiche cruciali dei fenomeni studiati e un alto tasso di falsi positivi (Zwet et al. 2023).\nLa ricerca scientifica richiede una metodologia pi√π sofisticata rispetto all‚Äôapproccio che si limita a confutare ipotesi nulle. √à essenziale sviluppare modelli causali che rispondano direttamente alle domande di ricerca. Inoltre, √® fondamentale avere una strategia razionale per l‚Äôestrazione delle stime dei modelli e per la quantificazione dell‚Äôincertezza associata ad esse. In questo contesto, l‚Äôanalisi bayesiana dei dati emerge come un approccio altamente efficace. Anche se in analisi semplici le differenze rispetto all‚Äôapproccio frequentista potrebbero sembrare minime o addirittura introdurre alcune complicazioni, quando ci si trova ad affrontare analisi pi√π realistiche e complesse, la differenza diventa sostanziale.\n\n18.3.1 Passaggi Chiave per un‚ÄôAnalisi Causale\nPer condurre un‚Äôanalisi scientifica dei dati che superi l‚Äôapproccio ‚Äúamatoriale‚Äù frequentista, McElreath (2020) suggerisce di seguire una serie di passaggi chiave:\n\nComprendere il concetto teorico del fenomeno oggetto dell‚Äôanalisi.\nSviluppare modelli causali che descrivano accuratamente le relazioni tra le variabili coinvolte nel problema di ricerca, basandosi sulla teoria sottostante.\nFormulare modelli statistici appropriati che riflettano fedelmente il contesto scientifico e le relazioni causali identificate.\nEseguire simulazioni basate sui modelli causali per verificare se i modelli statistici sviluppati siano in grado di stimare correttamente ci√≤ che √® teoricamente atteso. Questa fase di verifica √® cruciale per garantire la validit√† dei modelli.\nCondurre l‚Äôanalisi dei dati effettivi utilizzando i modelli statistici sviluppati, avendo la fiducia che riflettano accuratamente le teorie sottostanti e le relazioni causali.\n\n\n\n18.3.2 Grafi Aciclici Direzionati (DAG)\nUn elemento chiave sottolineato da McElreath (2020) nel processo di analisi √® l‚Äôutilizzo dei Grafi Aciclici Direzionati (DAG), che rappresentano uno strumento essenziale per realizzare il flusso di lavoro descritto. I DAG forniscono una rappresentazione grafica dei modelli causali, consentendo una visualizzazione chiara delle relazioni tra le variabili coinvolte. Questi grafici rendono trasparenti le assunzioni alla base dell‚Äôanalisi, creando una connessione evidente tra le teorie sottostanti e l‚Äôanalisi statistica. In contrasto, l‚Äôapproccio frequentista √® caratterizzato dall‚Äôassenza di ipotesi sulle relazioni sottostanti tra le variabili, rendendo difficile comprendere e interpretare le implicazioni scientifiche dei risultati ottenuti.\nPer un approfondimento di questi temi, consiglio fortemente la lettura del primo capitolo di Statistical Rethinking.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#due-paradossi-comuni",
    "href": "chapters/chapter_2/06_causality.html#due-paradossi-comuni",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.4 Due Paradossi Comuni",
    "text": "18.4 Due Paradossi Comuni\nEsistono due situazioni comuni in cui i dati possono ingannarci, e che vale la pena esaminare esplicitamente. Questi sono:\n\nIl paradosso di Simpson\nIl paradosso di Berkson\n\n\n18.4.1 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando stimiamo una relazione per sottoinsiemi dei nostri dati, ma otteniamo una relazione diversa considerando l‚Äôintero dataset (Simpson 1951). √à un caso particolare della fallacia ecologica, che si verifica quando cerchiamo di fare affermazioni sugli individui basandoci sui loro gruppi. Ad esempio, potrebbe esserci una relazione positiva tra i voti universitari e la performance alla scuola di specializzazione in due dipartimenti considerati individualmente. Tuttavia, se i voti universitari tendono a essere pi√π alti in un dipartimento rispetto all‚Äôaltro, mentre la performance alla scuola di specializzazione tende a essere opposta, potremmo trovare una relazione negativa tra i voti universitari e la performance alla scuola di specializzazione.\n\n\n18.4.2 Paradosso di Berkson\nIl paradosso di Berkson si verifica quando stimiamo una relazione basandoci sul dataset che abbiamo, ma a causa della selezione del dataset, la relazione risulta diversa in un dataset pi√π generale (Berkson 1946). Ad esempio, se abbiamo un dataset di ciclisti professionisti, potremmo non trovare una relazione tra il loro VO2 max e la possibilit√† di vincere una gara di ciclismo (Coyle et al.¬†1988; Podlogar, Leo, and Spragg 2022). Tuttavia, se avessimo un dataset della popolazione generale, potremmo trovare una relazione tra queste due variabili. Il dataset professionale √® cos√¨ selezionato che la relazione scompare; non si pu√≤ diventare ciclisti professionisti senza avere un VO2 max adeguato, ma tra i ciclisti professionisti, tutti hanno un VO2 max sufficiente.\n\n\n18.4.3 I Disegni di Ricerca e la Causalit√†\nPer comprendere meglio l‚Äôuso dei DAG nell‚Äôinferenza causale, √® necessario distinguere tra ricerche basate su disegni osservazionali e sperimentali (Rohrer 2018).\nNei disegni osservazionali i ricercatori osservano e registrano gli eventi senza intervenire direttamente. A differenza degli esperimenti controllati, qui non si manipolano le variabili studiate, ma si osservano le relazioni naturali che emergono. Questi studi sono preziosi quando gli esperimenti non sono fattibili per motivi etici o pratici. Tuttavia, sebbene siano efficaci nell‚Äôidentificare correlazioni e tendenze, i disegni osservazionali spesso mancano della capacit√† di stabilire con certezza relazioni causali, a causa di variabili confondenti e bias di selezione. Esempi comuni di disegni osservazionali includono studi trasversali e longitudinali.\nI disegni sperimentali, d‚Äôaltra parte, si basano sulla manipolazione controllata delle variabili e sulla randomizzazione. Quest‚Äôultima, ovvero l‚Äôassegnazione casuale dei partecipanti ai gruppi, √® fondamentale per ridurre i bias e garantire la validit√† delle conclusioni causali. Gli esperimenti randomizzati sono considerati il gold standard per indagare le relazioni causali, poich√© la randomizzazione consente di bilanciare gli effetti delle variabili osservate e non osservate tra i diversi gruppi di trattamento.\nNonostante gli esperimenti offrano un elevato grado di certezza nella determinazione delle relazioni causali, i disegni osservazionali presentano vantaggi in termini di flessibilit√† e applicabilit√† in situazioni in cui gli esperimenti non possono essere condotti per ragioni etiche o pratiche. Rohrer (2018) nota che, mentre i disegni osservazionali spesso si basano su relazioni associative piuttosto che causali, gli esperimenti potrebbero non consentire una generalizzazione al di l√† delle condizioni artificiali del laboratorio.\nNel contesto della ricerca, il concetto di causalit√† si riferisce alla relazione tra una variabile (X) e un‚Äôaltra (Y), in cui X pu√≤ influenzare Y. Il linguaggio causale utilizza termini come ‚Äúcausa‚Äù, ‚Äúinfluenza‚Äù e ‚Äúdetermina‚Äù, a differenza di termini descrittivi come ‚Äúassociato‚Äù o ‚Äúcorrelato‚Äù, che indicano semplicemente relazioni senza implicare un legame causale diretto. √à importante ribadire che la causalit√† √® concepita come un concetto probabilistico, il che significa che una variazione in X aumenta la probabilit√† di un certo risultato in Y, piuttosto che determinarlo in modo assoluto.\nNel campo della ricerca psicologica, spesso √® necessario inferire relazioni causali da dati osservazionali poich√© gli esperimenti randomizzati non sono sempre praticabili o eticamente accettabili. Tuttavia, questo approccio presenta diverse sfide che possono influenzare l‚Äôintegrit√† e l‚Äôaccuratezza delle inferenze tratte dagli studi. Per affrontare tali sfide e migliorare la solidit√† delle loro analisi, i ricercatori impiegano una serie di strategie metodologiche.\n\nUtilizzo di interventi surrogati: questa tecnica √® preziosa in situazioni in cui la manipolazione diretta di una variabile di interesse √® impraticabile o eticamente inaccettabile. Piuttosto che intervenire direttamente, i ricercatori si avvalgono di variabili surrogate (o proxy) che presumibilmente sono associate alla variabile di interesse principale. L‚Äôobiettivo √® esplorare e dedurre gli effetti indiretti di una variabile su un‚Äôaltra, stabilendo associazioni che, sebbene non dirette, possono fornire importanti informazioni sul fenomeno in esame. Tuttavia, questa strategia presenta delle sfide intrinseche, come la difficolt√† nel garantire una relazione diretta tra la variabile surrogata e quella di interesse principale.\nLinguaggio cauto nell‚Äôinterpretazione dei dati: i ricercatori adottano un linguaggio prudente quando interpretano dati osservazionali, evitando di fare affermazioni causali dirette quando i dati mostrano solo correlazioni.\nUtilizzo di metodi statistici avanzati per controllare variabili confondenti: Le variabili confondenti sono fattori esterni che possono influenzare la relazione tra le variabili studiate. L‚Äôutilizzo di tecniche statistiche avanzate, come la regressione multipla o l‚Äôanalisi di matching, aiuta a controllare l‚Äôeffetto di queste variabili confondenti, consentendo una stima pi√π accurata della relazione tra le variabili di interesse. Tuttavia, questi metodi hanno limitazioni (si veda ?sec-causal-inference) e potrebbero non riuscire a controllare completamente tutte le variabili confondenti, specialmente in situazioni complesse.\n\nRohrer (2018) sottolinea che, nonostante l‚Äôadozione di queste strategie, persistono sfide in termini di validit√† esterna (cio√® la generalizzabilit√† dei risultati) e interpretazione dei dati. La validit√† esterna potrebbe essere limitata poich√© le condizioni specifiche dello studio potrebbero non rappresentare situazioni pi√π ampie o diverse, mentre l‚Äôinterpretazione dei risultati pu√≤ essere complicata dalla natura indiretta o surrogata delle evidenze raccolte.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#modelli-causali-grafici",
    "href": "chapters/chapter_2/06_causality.html#modelli-causali-grafici",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.5 Modelli Causali Grafici",
    "text": "18.5 Modelli Causali Grafici\nL‚Äôanalisi dei dati osservazionali per trarre inferenze causali √® intrinsecamente complessa, ma con precauzioni adeguate e approcci metodologici appropriati, √® possibile estrarre preziosi insight causali anche da questo tipo di dati. In questo contesto, Rohrer (2018) sottolinea l‚Äôimportanza dei DAG come strumento fondamentale per la rappresentazione visiva delle ipotesi causali. Questi diagrammi non solo agevolano la comprensione delle relazioni causali tra le variabili, ma forniscono anche una guida per l‚Äôidentificazione e il trattamento corretto delle variabili esterne, comunemente note come ‚Äúvariabili di confondimento‚Äù.\nUna delle funzioni pi√π cruciali dei DAG √® la loro capacit√† di individuare quali variabili di confondimento debbano essere considerate nell‚Äôanalisi e quali possano essere trascurate senza compromettere l‚Äôintegrit√† dell‚Äôinferenza causale. Questa caratteristica √® essenziale poich√© sia il controllo insufficiente sia quello eccessivo delle variabili di confondimento possono condurre a conclusioni erronee. In particolare, i DAG aiutano a determinare quando l‚Äôaggiustamento per determinate variabili di confondimento pu√≤ migliorare l‚Äôaccuratezza delle inferenze causali e quando, al contrario, tale aggiustamento potrebbe introdurre distorsioni (questo punto verr√† approfondito nel capitolo sec-causal-inference).\nGrazie ai DAG, i ricercatori possono esplicitare le loro ipotesi sulle relazioni causali tra le variabili, riducendo cos√¨ il rischio di interpretare erroneamente i dati osservazionali. Questo approccio consente di sviluppare strategie di analisi pi√π informate e metodologicamente solide, mirate a comprendere al meglio le dinamiche causali sottostanti.\n\n18.5.1 Importanza delle Assunzioni\n√à cruciale comprendere che l‚Äôestrazione di conclusioni causali da dati correlazionali non pu√≤ essere basata esclusivamente sui dati stessi. √à invece necessario possedere delle conoscenze sulle dinamiche causali del fenomeno esaminato. Questo principio deriva dalla consapevolezza che una correlazione osservata pu√≤ essere attribuita a una vasta gamma di fattori, inclusa l‚Äôinfluenza potenziale di variabili terze non considerate nell‚Äôanalisi. Di conseguenza, qualsiasi tentativo di inferenza causale privo di una comprensione preliminare delle possibili relazioni causali rischia di essere fallace.\nNonostante queste sfide, √® fondamentale non rinunciare davanti alla complessit√† intrinseca della ricerca osservazionale. Pur non potendo dimostrare inequivocabilmente la causalit√†, per via della loro incapacit√† di manipolare direttamente le variabili di interesse, gli studi osservazionali svolgono un ruolo irrinunciabile nel contesto scientifico. Questi studi sono fondamentali per la generazione di ipotesi e per guidare la ricerca futura verso domande scientifiche rilevanti. Allo stesso modo, gli studi sperimentali, bench√© considerati il gold standard per la determinazione delle relazioni causali, non sono esenti da limitazioni. Gli esperimenti, soprattutto quelli condotti in ambienti altamente controllati come i laboratori, presuppongono la generalizzabilit√† dei risultati al di l√† dei confini dello studio, un‚Äôassunzione che pu√≤ non sempre trovare riscontro nella realt√†.\nIn questo contesto, ci√≤ che rende un‚Äôindagine rigorosa, sia essa osservazionale che sperimentale, √® la capacit√† di riconoscere, articolare e comunicare chiaramente le premesse su cui si basa. Questo approccio non solo facilita una valutazione critica delle conclusioni causali da parte della comunit√† scientifica, ma promuove anche un dialogo costruttivo e produttivo all‚Äôinterno della stessa, fondamentale per il progresso della conoscenza. La trasparenza nell‚Äôesposizione delle premesse rappresenta un prerequisito essenziale per un avanzamento scientifico informato, consapevole e, soprattutto, veritiero.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#introduzione-ai-dag",
    "href": "chapters/chapter_2/06_causality.html#introduzione-ai-dag",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.6 Introduzione ai DAG",
    "text": "18.6 Introduzione ai DAG\nI Grafi Aciclici Diretti (DAG) offrono una rappresentazione grafica delle relazioni causali ipotizzate tra le variabili. In un DAG, le frecce vengono utilizzate per indicare le relazioni causali tra diverse variabili.\nSono chiamati cos√¨ perch√©:\n\nLe variabili presenti nel diagramma (nodi) possono essere collegate tra loro solo attraverso frecce, anzich√© semplici linee di collegamento, da cui il termine ‚Äúdiretti‚Äù.\nPartendo da un nodo, non √® possibile ritornare allo stesso nodo seguendo il percorso delle frecce, da cui il termine ‚Äúaciclici‚Äù.\n\nLe variabili sono chiamate nodi del DAG. Un cammino tra due nodi √® una sequenza di frecce che collegano i due nodi, indipendentemente dalla direzione delle frecce.\nAll‚Äôinterno di un DAG, la freccia che va dal nodo \\(X\\) al nodo \\(Y\\) evidenzia una relazione causale, implicando che \\(X\\) abbia un‚Äôinfluenza su \\(Y\\). Tuttavia, questa relazione non √® deterministica; piuttosto, le variazioni nel livello di \\(X\\) sono associate a cambiamenti in \\(Y\\) su base probabilistica. Pertanto, la presenza della freccia nel DAG causale indica che un aumento di \\(X\\) aumenta la probabilit√† che \\(Y\\) aumenti, ma non lo garantisce.\nSe tra due nodi c‚Äô√® una sola freccia, il nodo dal quale parte la freccia √® detto ‚Äúgenitore‚Äù, mentre quello di arrivo √® detto ‚Äúfiglio‚Äù. Se, partendo da un nodo A, si arriva a un nodo B seguendo il verso di una successione di frecce, allora il nodo A √® detto ‚Äúantenato‚Äù, mentre B √® detto ‚Äúdiscendente‚Äù.\nI DAG permettono di identificare quali variabili agiscono come confondenti e quali no, basandosi sulla teoria sviluppata da Judea Pearl (Pearl 2009). √à importante rappresentare tutte le possibili relazioni nel DAG, poich√© l‚Äôassenza di una freccia tra due variabili implica una certezza dell‚Äôassenza di relazione tra di esse.\nDue dei concetti fondamentali della teoria dei DAG sono la d-separazione e il back-door path.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#concetto-di-d-separazione",
    "href": "chapters/chapter_2/06_causality.html#concetto-di-d-separazione",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.7 Concetto di d-separazione",
    "text": "18.7 Concetto di d-separazione\nLa d-separazione √® un concetto fondamentale per comprendere come le variabili all‚Äôinterno di un DAG possano influenzarsi reciprocamente. Essa definisce se un insieme di variabili pu√≤ bloccare l‚Äôinfluenza di una variabile su un‚Äôaltra. In altre parole, la d-separazione ci aiuta a capire se un percorso che collega due variabili √® attivo o inattivo, considerando un insieme di nodi specifico.\n\n18.7.1 Definizione di d-separazione\nUn cammino tra due nodi √® d-separato (o bloccato) da un insieme Œõ di nodi se e solo se si verificano le seguenti condizioni:\n\nCatena (Sequenza di frecce): Se il cammino √® costituito da una sequenza di frecce nella stessa direzione (ad esempio, \\(X \\rightarrow Z \\rightarrow Y\\)), il nodo intermedio (\\(Z\\)) deve appartenere all‚Äôinsieme Œõ affinch√© il cammino sia bloccato. Questo significa che la variabile \\(Z\\) deve essere inclusa nell‚Äôanalisi per bloccare l‚Äôinfluenza di \\(X\\) su \\(Y\\).\nFork (Nodo con due frecce in uscita): Se nel cammino c‚Äô√® un nodo da cui partono due frecce (ad esempio, \\(X \\leftarrow Z \\rightarrow Y\\)), il nodo di partenza delle frecce (\\(Z\\)) deve appartenere all‚Äôinsieme Œõ affinch√© il cammino sia bloccato. In questo caso, \\(Z\\) agisce come una variabile confondente, e includerla nell‚Äôanalisi blocca il percorso.\nCollider (Nodo con due frecce in entrata): Se nel cammino c‚Äô√® un nodo in cui convergono due frecce (ad esempio, \\(X \\rightarrow Z \\leftarrow Y\\)), n√© il nodo di convergenza (\\(Z\\)) n√© i suoi discendenti devono appartenere all‚Äôinsieme Œõ affinch√© il cammino sia bloccato. Un collider introduce un‚Äôassociazione tra \\(X\\) e \\(Y\\) solo se \\(Z\\) o i suoi discendenti sono inclusi nell‚Äôanalisi.\n\nLa d-separazione √® uno strumento potente per identificare i percorsi di confondimento e determinare quali variabili devono essere considerate nel modello statistico per ottenere inferenze causali accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#il-criterio-del-back-door",
    "href": "chapters/chapter_2/06_causality.html#il-criterio-del-back-door",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.8 Il criterio del back-door",
    "text": "18.8 Il criterio del back-door\nIl criterio del back-door √® uno strumento grafico utile per individuare le variabili confondenti che devono essere considerate per ottenere stime causali corrette. Questo criterio si basa sulla verifica dei percorsi non causali, detti ‚Äúback-door paths‚Äù, che collegano l‚Äôesposizione all‚Äôoutcome.\nIl criterio del back-door pu√≤ essere applicato mediante i seguenti passaggi:\n\nEliminare le frecce dirette: Rimuovere tutte le frecce che vanno dall‚Äôesposizione all‚Äôoutcome nel grafo.\nVerificare i percorsi non bloccati: Controllare se esistono percorsi non bloccati tra l‚Äôesposizione e l‚Äôoutcome nel grafo modificato.\n\nSe tutti i percorsi sono bloccati, significa che non c‚Äô√® confondimento, e quindi l‚Äôesposizione e l‚Äôoutcome sono indipendenti. Se invece esistono percorsi non bloccati, √® necessario individuare e aggiustare per le variabili che possono bloccarli.\n\n18.8.1 Esempi di applicazione del criterio del back-door\nConsideriamo un DAG che rappresenta la relazione tra autostima (A) e performance accademica (P), tenendo conto di variabili come il supporto familiare (S) e il livello di stress (L). Il DAG √® strutturato come segue:\n\nA ‚Üí P\nS ‚Üí A\nS ‚Üí P\nL ‚Üê S\n\nRimuovendo la freccia diretta A ‚Üí P, rimangono i percorsi:\n\nA ‚Üê S ‚Üí P\nA ‚Üê S ‚Üí L ‚Üí P\n\nPer bloccare questi percorsi, √® necessario condizionare su S, che blocca entrambi i percorsi. Pertanto, per ottenere una stima non distorta della relazione tra autostima e performance accademica, √® sufficiente aggiustare per il supporto familiare (S).\n\n18.8.1.1 Esempio 2: Relazione tra attivit√† fisica e benessere psicologico\nConsideriamo un DAG con le seguenti relazioni:\n\nAttivit√† fisica (F) ‚Üí Benessere psicologico (B)\nGenere (G) ‚Üí F\nGenere (G) ‚Üí B\nEt√† (E) ‚Üí F\nEt√† (E) ‚Üí B\n\nIn questo caso, abbiamo i percorsi:\n\nF ‚Üê G ‚Üí B\nF ‚Üê E ‚Üí B\n\nRimuovendo la freccia diretta F ‚Üí B, rimangono i percorsi non bloccati:\n\nF ‚Üê G ‚Üí B\nF ‚Üê E ‚Üí B\n\nPer bloccare questi percorsi, √® necessario condizionare sia su G (genere) che su E (et√†). Pertanto, per ottenere una stima non distorta della relazione tra attivit√† fisica e benessere psicologico, √® necessario aggiustare per le variabili genere ed et√†.\n\n\n\n18.8.2 Procedura per determinare l‚Äôinsieme sufficiente di variabili\nPer decidere se un insieme di variabili √® sufficiente per l‚Äôaggiustamento, √® possibile seguire questi passaggi:\n\nEliminare le frecce dell‚Äôesposizione: Rimuovere tutte le frecce che partono dalla variabile di esposizione.\nAggiungere archi di controllo: Aggiungere tutti gli archi necessari generati dal controllo sulle variabili dell‚Äôinsieme considerato.\nVerificare i percorsi non bloccati: Se tutti i percorsi non bloccati tra l‚Äôesposizione e l‚Äôoutcome contengono almeno una variabile dell‚Äôinsieme considerato, allora l‚Äôinsieme √® sufficiente per il controllo.\n\nL‚Äôinsieme pu√≤ anche essere vuoto se non √® necessario aggiustare per alcuna variabile.\nIn sintesi, il criterio del back-door consente di ridurre il numero di variabili da considerare per l‚Äôaggiustamento, risolvendo un importante problema pratico. Identificare l‚Äôinsieme sufficiente minimale di variabili aiuta a mantenere l‚Äôanalisi gestibile e precisa, migliorando la validit√† delle inferenze causali. Questo √® particolarmente utile in psicologia, dove le variabili confondenti sono spesso numerose e complesse.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#strutture-causali-elementari",
    "href": "chapters/chapter_2/06_causality.html#strutture-causali-elementari",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.9 Strutture Causali Elementari",
    "text": "18.9 Strutture Causali Elementari\nAll‚Äôinterno dei DAG causali, si possono riconoscere quattro tipologie fondamentali di strutture causali: confondente, catena, collider e discendenti. La comprensione di queste strutture causali di base √® fondamentale per analizzare i percorsi causali pi√π complessi.\n\n\n\nI quattro confondenti di base. (Figura tratta da McElreath (2020)).\n\n\n\n18.9.1 Catena\nIl concetto di catena (pipe) in un DAG descrive una sequenza in cui una variabile \\(X\\) influisce su una variabile \\(Y\\) attraverso una variabile intermedia \\(Z\\), formando una catena causale del tipo \\(X \\rightarrow Z \\rightarrow Y\\). In questo scenario, \\(Z\\) agisce come mediatore della relazione causale tra \\(X\\) e \\(Y\\). Controllando per \\(Z\\), la relazione diretta osservata tra \\(X\\) e \\(Y\\) scompare perch√© \\(X\\) influisce su \\(Y\\) esclusivamente attraverso \\(Z\\).\nIn sintesi,\n\n\\(X\\) e \\(Y\\) sono associati: \\(X \\not\\perp Y\\).\nL‚Äôinfluenza di \\(X\\) su \\(Y\\) viene trasmessa tramite \\(Z\\).\nStratificando i dati in base a \\(Z\\), l‚Äôassociazione tra \\(X\\) e \\(Y\\) scompare: \\(X \\perp Y \\mid Z\\).\n\nEsempio. Consideriamo l‚Äôeffetto dell‚Äôeducazione sull‚Äôoccupabilit√† attraverso l‚Äôacquisizione di competenze specifiche.\nVariabili: - \\(X\\): Livello di Educazione (ad es., nessun diploma, diploma di scuola superiore, laurea) - \\(Z\\): Competenze Specifiche Acquisite (ad es., competenze informatiche, competenze linguistiche, competenze professionali specifiche) - \\(Y\\): Occupabilit√† (misurata come probabilit√† di ottenere un lavoro nel proprio campo di studio entro un certo periodo dopo il completamento degli studi)\nRelazione Causale: Il livello di educazione (\\(X\\)) influisce sull‚Äôoccupabilit√† (\\(Y\\)) attraverso l‚Äôacquisizione di competenze specifiche (\\(Z\\)). In altre parole, non √® tanto il titolo di studio in s√© a determinare direttamente l‚Äôoccupabilit√†, quanto le competenze specifiche acquisite durante il percorso educativo. Questo √® un classico esempio di relazione di tipo ‚Äúpipe‚Äù.\nScenario senza Stratificazione: Senza stratificare per \\(Z\\), si potrebbe osservare una correlazione positiva tra \\(X\\) e \\(Y\\), suggerendo che un maggiore livello di educazione √® associato a una maggiore occupabilit√†. Tuttavia, questa osservazione non chiarisce se il titolo di studio in s√© sia il fattore determinante o se ci√≤ dipenda dalle competenze acquisite.\nScenario con Stratificazione per \\(Z\\): Quando si stratifica per le competenze specifiche acquisite (\\(Z\\)), controllando quindi per il tipo e il livello di competenze ottenute, la relazione diretta tra il livello di educazione e l‚Äôoccupabilit√† potrebbe scomparire o indebolirsi fortemente. Questo indica che, una volta considerate le competenze acquisite, il livello di educazione in s√© non ha un impatto diretto sull‚Äôoccupabilit√†. L‚Äôeffetto osservato del livello di educazione sull‚Äôoccupabilit√† √® quindi mediato completamente dalle competenze specifiche acquisite.\nQuesto esempio mostra come, in una relazione a catena, la variabile mediatrice (\\(Z\\)) spiega completamente la relazione tra la variabile indipendente (\\(X\\)) e la variabile dipendente (\\(Y\\)).\n\n\n18.9.2 Confondente\nIl concetto di confondente (fork) si riferisce a una struttura in cui una variabile comune \\(Z\\) causa due variabili \\(X\\) e \\(Y\\), formando una relazione del tipo \\(X \\leftarrow Z \\rightarrow Y\\). In questo scenario, \\(Z\\) √® una variabile confondente che pu√≤ generare una correlazione apparente tra \\(X\\) e \\(Y\\), anche se non esiste una relazione causale diretta tra di loro. Analizzare adeguatamente il ruolo di \\(Z\\) √® fondamentale per comprendere le vere relazioni causali tra \\(X\\) e \\(Y\\).\nEsempio. Consideriamo l‚Äôinfluenza dell‚Äôet√† sul numero di scarpe e abilit√† matematiche.\nVariabili: - \\(Z\\): Et√† (variabile confondente) - \\(X\\): Numero di Scarpe - \\(Y\\): Abilit√† Matematiche\nRelazione Causale: In questo esempio, l‚Äôet√† (\\(Z\\)) √® la variabile confondente che influisce sia sul numero di scarpe (\\(X\\)) che sulle abilit√† matematiche (\\(Y\\)). Con l‚Äôaumentare dell‚Äôet√†, generalmente aumenta il numero di scarpe a causa della crescita fisica e migliorano le abilit√† matematiche grazie all‚Äôapprendimento scolastico e allo sviluppo cognitivo.\nSenza Considerare l‚ÄôEt√†: Se non consideriamo l‚Äôet√† (\\(Z\\)) nell‚Äôanalisi, potremmo erroneamente concludere che esiste una relazione diretta tra il numero di scarpe (\\(X\\)) e le abilit√† matematiche (\\(Y\\)), dato che entrambi aumentano nel tempo. Tuttavia, questa correlazione non implica una relazione causale diretta tra il numero di scarpe e le abilit√† matematiche, ma √® piuttosto il risultato dell‚Äôinfluenza dell‚Äôet√†.\nConsiderando l‚ÄôEt√†: Una volta che l‚Äôet√† viene inclusa nell‚Äôanalisi come variabile confondente, diventa chiaro che qualsiasi correlazione osservata tra il numero di scarpe e le abilit√† matematiche √® spiegata dalla loro relazione comune con l‚Äôet√†. Stratificando per et√† o utilizzando metodi statistici per controllare l‚Äôeffetto dell‚Äôet√†, possiamo correttamente interpretare che non esiste una relazione causale diretta tra il numero di scarpe e le abilit√† matematiche.\nQuesto esempio illustra l‚Äôimportanza di identificare e controllare le variabili confondenti nelle analisi causali.\n\n\n18.9.3 Collider\nLa struttura causale nota come collider si verifica quando due variabili, \\(X\\) e \\(Y\\), convergono influenzando una terza variabile, \\(Z\\), formando una configurazione del tipo \\(X \\rightarrow Z \\leftarrow Y\\). In questo schema, \\(X\\) e \\(Y\\) sono indipendenti, il che significa che non esiste una relazione causale diretta o un‚Äôinfluenza reciproca evidente tra di loro. Sebbene entrambe influenzino \\(Z\\), non si pu√≤ dedurre l‚Äôesistenza di un legame causale diretto tra \\(X\\) e \\(Y\\) basandosi esclusivamente sulla loro comune influenza su \\(Z\\).\nEsempio. Consideriamo quali variabili, il talento musicale, il supporto familiare e il successo in una carriera musicale.\nVariabili: - \\(X\\): Talento Musicale - \\(Y\\): Supporto Familiare - \\(Z\\): Successo nella Carriera Musicale\nRelazione Causale: In questo esempio, sia il talento musicale (\\(X\\)) che il supporto familiare (\\(Y\\)) influenzano il successo nella carriera musicale (\\(Z\\)). Tuttavia, il talento musicale e il supporto familiare sono indipendenti l‚Äôuno dall‚Äôaltro. Non esiste una relazione causale diretta tra il talento musicale e il supporto familiare.\nSenza Considerare \\(Z\\): \\(X\\) e \\(Y\\) sono indipendenti (\\(X \\perp Y\\)). Il talento musicale e il supporto familiare non hanno alcuna influenza reciproca diretta.\nConsiderando \\(Z\\): Quando ci si concentra esclusivamente sulle persone che hanno raggiunto il successo musicale (\\(Z\\)), si potrebbe erroneamente percepire un‚Äôassociazione tra talento musicale e supporto familiare. Questo √® conosciuto come bias del collider. Questa associazione artificiale emerge perch√© stiamo selezionando un sottogruppo basato su \\(Z\\), che √® influenzato sia da \\(X\\) che da \\(Y\\). Pertanto, quando si stratifica per \\(Z\\), \\(X\\) e \\(Y\\) appaiono associati (\\(X \\not\\perp Y \\mid Z\\)).\nIn sintesi,\n\nIndipendenza: \\(X\\) e \\(Y\\) sono indipendenti: \\(X \\perp Y\\).\nInfluenza: Sia \\(X\\) che \\(Y\\) influenzano \\(Z\\).\nAssociazione Spuria: Stratificando i dati in base a \\(Z\\), emerge un‚Äôassociazione spuria: \\(X \\not\\perp Y \\mid Z\\).\n\nIl bias del collider si verifica quando la selezione di casi basata su \\(Z\\) introduce un‚Äôassociazione artificiale tra \\(X\\) e \\(Y\\), che non riflette le relazioni presenti nell‚Äôintera popolazione. Questo pu√≤ portare a interpretazioni errate e conclusioni fuorvianti.\n\n\n18.9.4 Il Discendente\nLa configurazione del discendente √® caratterizzata dalla presenza di una variabile, \\(Z\\), che riceve l‚Äôinfluenza da una variabile \\(X\\) e trasmette tale effetto a una variabile \\(Y\\). Inoltre, \\(Z\\) esercita un‚Äôinfluenza diretta su un‚Äôaltra variabile, \\(A\\). Pertanto, \\(Z\\) agisce sia come mediatore nella relazione causale tra \\(X\\) e \\(Y\\), sia come collegamento causale diretto con \\(A\\). La struttura risultante pu√≤ essere rappresentata come \\(X \\rightarrow Z \\rightarrow Y\\), con una ramificazione aggiuntiva da \\(Z\\) ad \\(A\\) (\\(Z \\rightarrow A\\)).\nEsempio. Consideriamo l‚Äôeffetto del supporto sociale sulla felicit√† attraverso l‚Äôautostima.\nVariabili: - \\(X\\): Supporto Sociale - \\(Z\\): Autostima - \\(Y\\): Felicit√† - \\(A\\): Livello di Stress\nRelazione Causale: Il supporto sociale (\\(X\\)) migliora l‚Äôautostima (\\(Z\\)), che a sua volta influisce sulla felicit√† (\\(Y\\)) e sul livello di stress (\\(A\\)). In questo caso, \\(Z\\) agisce come mediatore tra \\(X\\) e \\(Y\\) e ha un effetto diretto su \\(A\\).\nSenza Considerare \\(A\\): Concentrandosi sul percorso \\(X \\rightarrow Z \\rightarrow Y\\), si pu√≤ isolare l‚Äôeffetto del supporto sociale sulla felicit√† attraverso l‚Äôautostima, mantenendo chiara la relazione causale.\nConsiderando \\(A\\): Quando si include \\(A\\) nell‚Äôanalisi, si introduce complessit√† poich√© \\(A\\) pu√≤ aprire nuovi percorsi causali o introdurre bias, complicando l‚Äôinterpretazione dell‚Äôeffetto diretto di \\(X\\) su \\(Y\\). Se \\(A\\) ha un discendente \\(D\\) che funge da collider, influenzato sia da \\(A\\) che da una causa comune non osservata con \\(Y\\) (\\(U\\)), condizionare su \\(D\\) pu√≤ introdurre un bias aprendo un percorso non causale (\\(A \\rightarrow D \\leftarrow U \\rightarrow Y\\)). Questo esemplifica come l‚Äôinclusione di discendenti e colliders possa alterare l‚Äôinterpretazione degli effetti causali.\nIn sintesi,\n\n\\(X\\) e \\(Y\\) sono associati causalmente attraverso \\(Z\\): \\(X \\not\\perp Y\\).\n\\(A\\) fornisce informazioni su \\(Z\\).\nStratificando i dati in base ad \\(A\\), l‚Äôassociazione tra \\(X\\) e \\(Y\\) pu√≤ indebolirsi o scomparire: \\(X \\perp Y \\mid A\\).\n\nComprendere il ruolo dei discendenti e dei collider √® cruciale per evitare interpretazioni errate dei dati e per fare inferenze causali accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#considerazioni-conclusive",
    "href": "chapters/chapter_2/06_causality.html#considerazioni-conclusive",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.10 Considerazioni Conclusive",
    "text": "18.10 Considerazioni Conclusive\nNegli studi basati su dati osservazionali, districarsi tra le complesse maglie delle inferenze causali richiede un‚Äôacuta analisi e una particolare sensibilit√† verso vari aspetti critici del processo di ricerca. Ogni fase, dall‚Äôidentificazione dei fattori confondenti all‚Äôanalisi accurata dei percorsi causali, passando per la gestione dei mediatori e dei collider, fino alla valutazione della robustezza interna ed esterna degli studi, presenta sfide e opportunit√†.\nIl primo passo verso un‚Äôinterpretazione corretta dei dati osservazionali consiste nel saper riconoscere e gestire le variabili confondenti. Queste variabili, agendo su entrambe le variabili indipendenti e dipendenti, possono generare correlazioni ingannevoli che mascherano la vera natura delle relazioni in esame.\nL‚Äôuso dei DAG (Grafi Aciclici Diretti) emerge come uno strumento molto utile in questo contesto, offrendo una rappresentazione visiva dei percorsi causali e fornendo indicazioni preziose su come evitare trappole analitiche quali il sovracontrollo o il controllo inappropriato di variabili post-trattamento.\nQuando si tratta di mediatori e collider, il terreno si fa ancora pi√π insidioso. I mediatori, essendo ponti tra cause ed effetti, necessitano di una gestione oculata per non perdere di vista l‚Äôeffetto causale che si intende esplorare. Allo stesso tempo, √® fondamentale resistere alla tentazione di controllare indiscriminatamente i collider, poich√© ci√≤ pu√≤ aprire la porta a correlazioni spurie che distorcono la realt√† dei fenomeni studiati.\nLa questione del bilanciamento tra validit√† interna ed esterna ricorda che, sebbene gli esperimenti randomizzati possano offrire garanzie solide di validit√† interna, la loro capacit√† di generalizzare i risultati al mondo esterno ‚Äì la validit√† esterna ‚Äì non √® sempre garantita. Solo un approccio che valorizza la diversit√† metodologica, abbracciando tanto gli studi sperimentali quanto quelli osservazionali, pu√≤ rispondere in modo completo alle domande di ricerca.\nIn conclusione, per studiare con successo le dinamiche nascoste che regolano le relazioni tra le variabili, √® essenziale non solo un‚Äôattenta valutazione dei dati disponibili ma anche una profonda riflessione sulle strutture causali in gioco. Integrare diversi approcci di ricerca arricchisce la nostra comprensione e ci avvicina a conclusioni causali solide e generalizzabili.\nUn sommario ironico di questi concetti √® fornito nella vignetta di xkcd.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/06_causality.html#informazioni-sullambiente-di-sviluppo",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.11 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "18.11 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\nseaborn   : 0.13.0\nscipy     : 1.11.4\nmatplotlib: 3.8.2\narviz     : 0.17.0\ngraphviz  : 0.20.1\npandas    : 2.1.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nDagan, Noa, Noam Barda, Eldad Kepten, Oren Miron, Shay Perchik, Mark Katz, Miguel Hern√°n, Marc Lipsitch, Ben Reis, e Ran Balicer. 2021. ¬´BNT162b2 mRNA Covid-19 Vaccine in a Nationwide Mass Vaccination Setting¬ª. New England Journal of Medicine 384 (15): 1412‚Äì23. https://doi.org/10.1056/NEJMoa2101765.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nPearl, Judea. 2009. Causality. Cambridge University Press.\n\n\nRiederer, Emily. 2021. ¬´Causal design patterns for data analysts¬ª, gennaio. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nRohrer, Julia M. 2018. ¬´Thinking clearly about correlations and causation: Graphical causal models for observational data¬ª. Advances in methods and practices in psychological science 1 (1): 27‚Äì42.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon Schwab, e Steven N Goodman. 2023. ¬´A New Look at P Values for Randomized Clinical Trials¬ª. NEJM Evidence 3 (1): EVIDoa2300003.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/introduction_chapter_3.html",
    "href": "chapters/chapter_3/introduction_chapter_3.html",
    "title": "19¬† Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa costituisce un‚Äôintroduzione alla teoria della probabilit√†, una componente essenziale per la ricerca scientifica. Nell‚Äôambito della scienza, l‚Äôinferenza induttiva svolge un ruolo di fondamentale importanza, e la probabilit√† gioca un ruolo cruciale in questo processo. Mentre non possiamo ottenere una certezza assoluta riguardo alla veridicit√† di un‚Äôipotesi o teoria, possiamo comunque assegnare loro un grado di certezza probabilistica. L‚Äôapproccio bayesiano utilizza la probabilit√† per quantificare il grado di fiducia che possiamo assegnare a una determinata proposizione.\nL‚Äôinferenza statistica bayesiana mira a quantificare la fiducia nell‚Äôipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(E\\). Per affrontare adeguatamente l‚Äôinferenza statistica bayesiana, dunque, √® essenziale avere una solida comprensione della teoria delle probabilit√†, almeno nei suoi concetti fondamentali.\nNel corso di questa sezione, esamineremo le definizioni di probabilit√†, la probabilit√† condizionale e il teorema di Bayes. Approfondiremo inoltre le propriet√† delle variabili casuali e le principali distribuzioni di massa di probabilit√† e di densit√† di probabilit√†. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell‚Äôinferenza bayesiana sia nell‚Äôinferenza frequentista.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01a_intro_prob.html",
    "href": "chapters/chapter_3/01a_intro_prob.html",
    "title": "20¬† Interpretazione della probabilit√†",
    "section": "",
    "text": "Introduzione\nNel corso di questo capitolo, esploreremo varie concezioni della probabilit√†, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con Python per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell‚Äôambito della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01a_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "href": "chapters/chapter_3/01a_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "title": "20¬† Interpretazione della probabilit√†",
    "section": "20.1 Storia e definizioni della probabilit√†",
    "text": "20.1 Storia e definizioni della probabilit√†\nLa probabilit√† √® un modo formale di quantificare l‚Äôincertezza, assegnando plausibilit√† o credibilit√† a un insieme di possibilit√† mutuamente esclusive o risultati di un esperimento o osservazione.\n\n20.1.1 Che cos‚Äô√® la probabilit√†?\nCi sono due modi principali per interpretare la probabilit√†:\n\nFrequentista: Secondo il framework frequentista, la probabilit√† rappresenta il limite della frequenza relativa con cui un evento di interesse si verifica quando il numero di esperimenti condotti ripetutamente nelle stesse condizioni tende all‚Äôinfinito. In questa visione, chiamata ‚Äúontologica‚Äù, la probabilit√† √® considerata una propriet√† intrinseca del mondo, indipendente dalla nostra esperienza. La probabilit√† √® quindi vista come una caratteristica oggettiva della realt√†.\nBayesiana: Al contrario, il framework bayesiano interpreta la probabilit√† come una credenza soggettiva riguardo alla probabilit√† di accadimento di un evento. In questa prospettiva ‚Äúepistemica‚Äù, la probabilit√† √® una misura della nostra conoscenza del mondo piuttosto che una propriet√† oggettiva. Questa visione soggettiva della probabilit√† dipende dalle informazioni disponibili e dal punto di vista dell‚Äôosservatore.\n\n\n\n20.1.2 Storia della probabilit√†\nLa storia della probabilit√† √® lunga e complessa, come illustrato in varie opere (Tabak 2004, Stigler 1986, Weisberg 2014). L‚Äôorigine della probabilit√† moderna risale a una domanda posta da Antoine Gombaud (Chevalier de M√©r√©) a Blaise Pascal (1623‚Äì1662) su come dividere equamente le puntate di un gioco di carte interrotto.\n\n20.1.2.1 Problema dei punti\nIl problema pu√≤ essere formulato cos√¨:\n\nImmaginiamo due persone che partecipano a un gioco a pi√π round. In ogni round, entrambe le persone hanno la stessa probabilit√† di vincere. La prima persona che vince sei round consecutivi si aggiudicher√† un ricco premio in denaro. Supponiamo che A e B abbiano gi√† disputato sei round, con A che ha vinto cinque volte e B una volta. In quel momento, il gioco √® interrotto. Poich√© n√© A n√© B hanno raggiunto le sei vittorie, hanno deciso di dividere il premio. Ma qual √® il modo pi√π equo per farlo?\n\nLa discussione tra Pierre de Fermat (1607‚Äì1665) e Pascal ha portato alla formalizzazione dell‚Äôutilizzo della matematica per risolvere questo problema, proponendo di considerare le probabilit√† di vincita di ciascun giocatore. Ad esempio, se A ha una probabilit√† del 97% di vincere il premio e B ha una probabilit√† del 3%, sembrerebbe equo assegnare ad A il 97% del premio. L‚Äôinteresse pubblico per la loro corrispondenza √® sopravvissuto grazie al libro di Christian Huygens del 1657 ‚ÄúDe Ratiociniis in Ludo Aleae‚Äù (Sul Ragionamento nei Giochi di Dadi), che √® rimasto il riferimento per la probabilit√† per circa 50 anni.\n\n\n20.1.2.2 Sviluppi successivi\nIl libro postumo di Jacob Bernoulli, ‚ÄúL‚ÄôArte della Congettura‚Äù (1713), ha segnato una svolta nella storia della probabilit√†. Bernoulli ha definito la probabilit√† come un indice di incertezza compreso tra 0 e 1 e ha collegato il calcolo della probabilit√† ai dati e alla frequenza a lungo termine di un evento, noto come legge dei grandi numeri. Bernoulli ha applicato la probabilit√† anche a settori diversi dal gioco d‚Äôazzardo, come la mortalit√† umana e la giustizia penale, creando la cosiddetta ‚Äúprobabilit√† soggettiva‚Äù.\n\n\n\n20.1.3 Interpretazione ‚Äúclassica‚Äù\nStoricamente, la prima definizione di probabilit√† √® stata proposta da Pierre-Simon Laplace (1749-1827), che si √® avvalso del calcolo combinatorio. Secondo Laplace, la probabilit√†\\(P\\)di un evento √® definita come il rapporto tra il numero di casi in cui l‚Äôevento si verifica e il numero totale di casi possibili. In questa definizione, un evento √® qualcosa a cui √® possibile assegnare un valore di verit√†, ovvero qualcosa che pu√≤ essere vero o falso. Ad esempio, la probabilit√† di ottenere un 3 in un lancio di un singolo dado √® 1/6 ‚âÉ 0.17, poich√© c‚Äô√® un solo caso favorevole (il lancio ha prodotto un 3) su sei casi possibili (i numeri da 1 a 6). Tuttavia, questa definizione √® insoddisfacente in quanto si basa sull‚Äôassunzione che ogni evento sia equiprobabile, il che non √® sempre vero. Inoltre, questa definizione √® circolare poich√© per definire il concetto di probabilit√†, √® necessario prima definire cosa significa che gli eventi siano equiprobabili, e quindi si deve gi√† conoscere il concetto di probabilit√†.\n\n\n20.1.4 Interpretazione frequentista\nUn secondo tentativo di definire la probabilit√† (dopo quello ‚Äúclassico‚Äù di Laplace) si basa sull‚Äôapproccio frequentista, che pu√≤ essere attribuito a molti autori. In questo approccio, la probabilit√† √® definita sulla base delle frequenze osservate dell‚Äôoccorrenza di un evento. Questo approccio nasce dalla difficolt√† di assegnare una probabilit√† agli eventi assumendo il principio di equiprobabilit√†, come nel caso delle monete, dei dadi o delle carte di un mazzo. Sebbene la probabilit√† di ottenere testa come risultato del lancio di un dado sia 1/2 se crediamo che la moneta sia bilanciata, se cos√¨ non fosse non potremmo assegnare la stessa probabilit√† a tutti i risultati possibili. Tuttavia, possiamo stimare le probabilit√† come la frequenza\\(f_t\\), definita come il rapporto tra il numero di volte in cui un lancio ha prodotto ‚Äútesta‚Äù e il numero totale di lanci.\nSi osservi che l‚Äôosservazione della frequenza \\(f_t\\) √® solo un‚Äô approssimazione della probabilit√†, ma l‚Äôaccuratezza migliora all‚Äôaumentare del numero totale di lanci, \\(N\\). In linea di principio, la probabilit√† di ottenere ‚Äútesta‚Äù, \\(P(T)\\), √® il limite della frequenza \\(f_t\\) quando il numero totale di lanci \\(N\\) tende all‚Äôinfinito. Tuttavia, questa definizione richiede l‚Äôinfinita ripetizione di un esperimento, il che pu√≤ essere impraticabile o impossibile in molti casi. Inoltre, questa definizione assume che gli eventi futuri siano simili agli eventi passati, il che non √® sempre garantito.\n\ndef coin_flips(n, run_label):\n    # Genera un array di 0 e 1 dove 1 rappresenta 'testa' e 0 'croce'\n    # usando una distribuzione binomiale.\n    heads = np.random.binomial(1, 0.5, n)\n    \n    # Calcola la proporzione cumulativa di teste.\n    flips = np.arange(1, n + 1) \n    proportion_heads = np.cumsum(heads) / flips\n    \n    # Crea un DataFrame per un facile accesso e visualizzazione dei dati.\n    df = pd.DataFrame({'flips': flips, 'proportion_heads': proportion_heads, 'run': run_label})\n\n    return df\n\nn = 1000\n\ndf = pd.concat([coin_flips(n, f'run{i+1}') for i in range(4)], axis=0)\nax = sns.lineplot(data = df, x = 'flips', y = 'proportion_heads', hue = 'run')\n\n\n\n\n\n\n\n\n\n\n20.1.5 La Legge dei Grandi Numeri\nLa simulazione precedente fornisce un esempio della Legge dei grandi numeri. La Legge dei Grandi Numeri afferma che, man mano che il numero di esperimenti casuali ripetuti aumenta, la stima della probabilit√† di un evento \\(P(Y=y)\\) diventa sempre pi√π accurata.\nIl teorema sostiene che, con l‚Äôaumento del numero di ripetizioni di un esperimento casuale, la media dei risultati osservati tende a convergere al valore atteso teorico della variabile casuale. In altre parole, la media empirica dei risultati osservati si avvicina sempre di pi√π al valore medio teorico.\nQuesta legge √® cruciale perch√© garantisce che, con un numero sufficientemente grande di prove, la stima empirica della probabilit√† di un evento si avvicina al valore reale. Questo rende le stime probabilistiche pi√π precise e affidabili.\nDal punto di vista pratico, la Legge dei Grandi Numeri consente di utilizzare modelli probabilistici per interpretare fenomeni reali. Anche se le osservazioni singole possono variare in modo casuale, la media delle osservazioni su un ampio numero di ripetizioni rifletter√† fedelmente le probabilit√† teoriche.\nFormalmente, data una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), ciascuna con media \\(\\mu\\), la Legge dei Grandi Numeri √® espressa come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{X_1 + X_2 + \\ldots + X_n}{n} - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) √® un valore positivo arbitrariamente piccolo e \\(P(\\cdot)\\) indica la probabilit√†. Questo significa che, con un numero molto grande di ripetizioni, la media campionaria osservata sar√† vicina alla media teorica attesa, permettendo inferenze affidabili sulla probabilit√† degli eventi.\nIn sintesi, la Legge dei Grandi Numeri assicura che, aumentando il numero di prove, le stime empiriche delle probabilit√† diventano sempre pi√π precise, allineandosi con i valori teorici attesi.\n\n20.1.5.1 Problema del caso singolo\nNell‚Äôambito dell‚Äôapproccio frequentista alla probabilit√†, basato sulla concezione delle frequenze relative di eventi osservati su lunghe serie di ripetizioni, emerge un limite concettuale nel trattare la probabilit√† di eventi singolari e non ripetibili. Secondo questa prospettiva, infatti, non risulta rigorosamente appropriato discutere di probabilit√† relative a eventi unici e non replicabili nel tempo. Esempi emblematici di tali eventi includono la possibilit√† che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023 o che si verifichi pioggia a Firenze il giorno di Ferragosto del 2024. Questi scenari, essendo unici e circoscritti a un preciso momento storico, sfuggono alla logica frequentista che richiede, per definizione, la possibilit√† di osservazione ripetuta degli eventi per valutarne la probabilit√†. Nonostante ci√≤, nel linguaggio comune non specialistico, √® comune l‚Äôuso del termine ‚Äúprobabilit√†‚Äù per riferirsi anche a tali eventi specifici e non ripetibili, evidenziando cos√¨ una discrepanza tra l‚Äôuso tecnico e quello colloquiale del concetto di probabilit√†.\n\n\n\n20.1.6 Collegamento tra probabilit√† e statistica\nDurante gli anni ‚Äô20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l‚Äôinferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significativit√†, i metodi di campionamento, l‚Äôanalisi della varianza e il disegno sperimentale.\nNegli anni ‚Äô30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull‚Äôinterpretazione frequentista della probabilit√†. Definirono due tipologie di errori decisionali e utilizzarono il test di significativit√† di Fisher, interpretando i valori\\(p\\)come indicatori dei tassi di errore a lungo termine.\n\n\n20.1.7 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della ‚Äúprobabilit√† inversa‚Äù (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l‚Äôinferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell‚Äôutilizzo dell‚Äôinferenza basata sul metodo della probabilit√† inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato ‚ÄúTheory of Probability‚Äù rappresent√≤ una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ‚Äô80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell‚Äôapproccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n20.1.8 Interpretazione soggettivista\nUna visione alternativa della probabilit√† la considera come una credenza soggettiva. De Finetti (2017) ha proposto un‚Äôinterpretazione in cui la probabilit√† non √® vista come una caratteristica oggettiva degli eventi, ma piuttosto come una misura della credenza soggettiva, suggerendo di trattare \\(p(¬∑)\\) come una probabilit√† soggettiva. √à interessante notare che de Finetti era un soggettivista radicale. Infatti, la frase di apertura del suo trattato in due volumi sulla probabilit√† afferma che ‚ÄúLa probabilit√† non esiste‚Äù, intendendo che la probabilit√† non ha uno status oggettivo, ma rappresenta piuttosto la quantificazione della nostra esperienza di incertezza. Riteneva che l‚Äôidea di una probabilit√† esterna all‚Äôindividuo, con uno status oggettivo, fosse pura superstizione, paragonabile al credere in ‚ÄúEtere cosmico, Spazio e Tempo assoluti, ‚Ä¶, o Fate e Streghe‚Ä¶‚Äù. Secondo de Finetti, ‚Äú‚Ä¶ esistono solo probabilit√† soggettive - cio√®, il grado di credenza nell‚Äôoccorrenza di un evento attribuito da una determinata persona in un dato momento con un dato insieme di informazioni.‚Äù\nCome sottolineato da Press (2009), la prima menzione della probabilit√† come grado di credenza soggettiva fu fatta da Ramsey (1926), ed √® questa nozione di probabilit√† come credenza soggettiva che ha portato a una notevole resistenza alle idee bayesiane. Una trattazione dettagliata degli assiomi della probabilit√† soggettiva si trova in Fishburn (1986).\nLa denominazione ‚Äúsoggettivo‚Äù legata alla probabilit√† potrebbe risultare infelice, poich√© potrebbe suggerire un ragionamento vago o non scientifico. Lindley (2013) condivide queste riserve, proponendo l‚Äôalternativa ‚Äúprobabilit√† personale‚Äù rispetto a ‚Äúprobabilit√† soggettiva‚Äù. Analogamente, Howson e Urbach (2006) preferiscono utilizzare l‚Äôespressione ‚Äúprobabilit√† epistemica‚Äù, che riflette il grado di incertezza di un individuo di fronte al problema trattato. In sostanza, la probabilit√† epistemica si riferisce all‚Äôincertezza personale riguardo a variabili sconosciute. Questa terminologia viene adottata anche nel testo di Kaplan (2023), fornendo un linguaggio pi√π neutro per discutere di questi concetti.\nVa inoltre notato che l‚Äôinterpretazione soggettiva si adatta bene a eventi singoli, permettendo di esprimere una convinzione su eventi specifici, come la probabilit√† di pioggia in un dato giorno o l‚Äôesito di una competizione sportiva.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli‚Äôs Fallacy (Clayton 2021) offre un‚Äôintroduzione molto leggibile alle tematiche della definizione della probabilit√† nella storia della scienza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01a_intro_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/01a_intro_prob.html#commenti-e-considerazioni-finali",
    "title": "20¬† Interpretazione della probabilit√†",
    "section": "20.2 Commenti e Considerazioni Finali",
    "text": "20.2 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato il significato filosofico della nozione di probabilit√† e introdotto la simulazione come metodo per approssimare le probabilit√† empiriche quando non √® possibile ottenere soluzioni analitiche.\nNel prossimo capitolo, esamineremo la probabilit√† dal punto di vista matematico.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01a_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/01a_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "20¬† Interpretazione della probabilit√†",
    "section": "20.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "20.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nDe Finetti, Bruno. 2017. Theory of probability: A critical introductory treatment. Vol. 6. John Wiley & Sons.\n\n\nFishburn, Peter C. 1986. ¬´The axioms of subjective probability¬ª. Statistical Science 1 (3): 335‚Äì45.\n\n\nHowson, Colin, e Peter Urbach. 2006. Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, David. 2023. Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, Dennis V. 2013. Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S James. 2009. Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, Frank P. 1926. ¬´Truth and probability¬ª. In Readings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01b_prob_spaces.html",
    "href": "chapters/chapter_3/01b_prob_spaces.html",
    "title": "21¬† Misura di Probabilit√†",
    "section": "",
    "text": "Introduzione\nDal punto di vista matematico, da dove derivano i numeri che chiamiamo ‚Äúprobabilit√†‚Äù? Per rispondere a questa domanda, seguiremo l‚Äôapproccio proposto da Michael Betancourt, il quale mira a spiegare la nozione di distribuzione di probabilit√†. Questo capitolo presenta una versione leggermente semplificata del suo lavoro, mantenendone per√≤ la notazione e le figure originali.\nBetancourt afferma che le basi della teoria della probabilit√† sono piuttosto semplici. Le difficolt√† matematiche emergono principalmente quando si applica la teoria della probabilit√† a insiemi complessi come i numeri reali. Betancourt evita queste complicazioni introducendo i fondamenti della teoria della probabilit√† astratta su uno spazio campionario semplice: una collezione di un numero finito di elementi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01b_prob_spaces.html#insiemi-finiti",
    "href": "chapters/chapter_3/01b_prob_spaces.html#insiemi-finiti",
    "title": "21¬† Misura di Probabilit√†",
    "section": "21.1 Insiemi Finiti",
    "text": "21.1 Insiemi Finiti\nUn insieme finito contiene un numero finito di elementi distinti, \\[\nX = \\{x_1, ..., x_N\\}.\n\\] Qui l‚Äôindice numerico ci permette di distinguere i \\(N\\) elementi individuali, ma non implica necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, user√≤ l‚Äôinsieme di cinque elementi \\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\n\\] come esempio.\n\n\n\n\n\n\nFigura¬†21.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilit√†, gli elementi astratti \\(x_{n}\\) rappresentano oggetti significativi, ma in questo capitolo si eviter√† qualsiasi interpretazione particolare e ci si concentrer√† sui concetti matematici. Detto ci√≤, quando \\(X\\) √® inteso per catturare tutti gli oggetti di interesse in una data applicazione, viene chiamato spazio campionario.\nUna volta definito uno spazio campionario, abbiamo vari modi per organizzare i suoi elementi individuali e manipolare tali organizzazioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01b_prob_spaces.html#sottoinsiemi",
    "href": "chapters/chapter_3/01b_prob_spaces.html#sottoinsiemi",
    "title": "21¬† Misura di Probabilit√†",
    "section": "21.2 Sottoinsiemi",
    "text": "21.2 Sottoinsiemi\nUn sottoinsieme di \\(X\\) √® qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguit√†, user√≤ esclusivamente lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) √® un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicit√†, solo di appartenenza: un sottoinsieme pu√≤ includere un elemento \\(x_{n}\\) ma non pu√≤ includerlo pi√π volte.\n\n\n\n\n\n\nFigura¬†21.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) √® qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) √® un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) potrebbe contenere tutti gli elementi di \\(X\\), nel qual caso \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L‚Äôinsieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D‚Äôaltra parte, l‚Äôintero insieme stesso pu√≤ essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento √® denotato \\(\\{ x_{n} \\}\\) e chiamato insieme atomico.\nCi sono \\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\] modi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene elementi, \\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\] che √® solo l‚Äôinsieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi, \\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\] che √® solo l‚Äôinsieme completo stesso. D‚Äôaltra parte, ci sono \\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\] insiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene \\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\] sottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi √® essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01b_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/chapter_3/01b_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "21¬† Misura di Probabilit√†",
    "section": "21.3 Operazioni sui Sottoinsiemi",
    "text": "21.3 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono gi√† in \\(\\mathsf{x}\\). L‚Äôinsieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l‚Äôunico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell‚Äôinsieme vuoto √® l‚Äôintero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell‚Äôinsieme completo √® l‚Äôinsieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura¬†21.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) √® il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l‚Äôoperatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da pi√π di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi √® essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] cos√¨ come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura¬†21.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura¬†21.5: L‚Äôunione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), √® un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D‚Äôaltra parte, l‚Äôintersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), √® un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione √® l‚Äôinsieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L‚Äôunione e l‚Äôintersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poich√© l‚Äôinsieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l‚Äôinsieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l‚Äôunione di un sottoinsieme con l‚Äôinsieme completo restituisce l‚Äôinsieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l‚Äôintersezione di un sottoinsieme con l‚Äôinsieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01b_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "href": "chapters/chapter_3/01b_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "title": "21¬† Misura di Probabilit√†",
    "section": "21.4 Misura e Probabilit√† sugli Elementi",
    "text": "21.4 Misura e Probabilit√† sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l‚Äôallocazione coerente di una qualche quantit√† astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe ‚Äúmisura totale‚Äù o ‚Äúmassa totale‚Äù) di una qualche quantit√† positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poich√© \\(M\\) √® conservato, qualsiasi quantit√† \\(m_{n}\\) che viene allocata all‚Äôelemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) √® infinito. In questo scenario, possiamo allocare una quantit√† infinita dal serbatoio pur avendo ancora una quantit√† infinita rimanente. Allo stesso tempo, allocare una quantit√† infinita pu√≤ esaurire completamente il serbatoio o lasciare qualsiasi quantit√† finita residua. L‚Äôinfinito √® un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura¬†21.6: La teoria della misura riguarda l‚Äôallocazione di una qualche quantit√† continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn‚Äôallocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l‚Äôintero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione pu√≤ essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ci√≤ che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l‚Äôammontare finale allocato a \\(\\spadesuit\\) sar√†:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantit√† distribuite sia esattamente uguale a \\(M\\), svuotando cos√¨ completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n¬†\n\n\n\n\nFigura¬†21.7: Poich√© la quantit√† totale \\(M\\) √® conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantit√† disponibile per l‚Äôallocazione agli altri elementi. Un‚Äôallocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura √® qualsiasi allocazione coerente della quantit√† \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito pu√≤ essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell‚Äôinsieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) √® specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura¬†21.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) √® qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura pu√≤ essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPi√π grande √® \\(m_{n}\\), pi√π di \\(M\\) viene allocato all‚Äôelemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) √® un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poich√© richiede considerazioni pi√π complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) pu√≤ essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) √® lo spazio campionario,\n\\(x_n\\) √® un elemento di \\(X\\),\n\\(m_n\\) √® la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\n√à importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L‚Äôinsieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll‚Äôinterno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D‚Äôaltra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura¬†21.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) √® un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL‚Äôimportanza delle misure finite risiede nella possibilit√† di esprimere le allocazioni in termini relativi anzich√© assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all‚Äôintervallo unitario \\([0, 1]\\). Come per qualsiasi quantit√† che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l‚Äôimportanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull‚Äôintero spazio campionario e consente di normalizzare misure diverse, rendendo pi√π semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione ‚Äúassoluta‚Äù a una ‚Äúrelativa‚Äù della distribuzione della misura, offrendo una prospettiva pi√π intuitiva e utile per l‚Äôanalisi.\n\n\n\n\n\n\nFigura¬†21.10: Ogni misura finita pu√≤ essere caratterizzata da un‚Äôallocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste propriet√† √® chiamata simplex.\n\n\n\n\n\n\nFigura¬†21.11: Un‚Äôallocazione proporzionale √® anche conosciuta come distribuzione di probabilit√†.\n\n\n\nPi√π importante, una misura proporzionale \\(\\pi\\) √® anche conosciuta come distribuzione di probabilit√†, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilit√†. Sebbene il termine ‚Äúprobabilit√†‚Äù sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica √® piuttosto semplice: su un insieme finito, una probabilit√† rappresenta semplicemente la proporzione di una quantit√† finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01b_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "href": "chapters/chapter_3/01b_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "title": "21¬† Misura di Probabilit√†",
    "section": "21.5 Misura e Probabilit√† sui Sottoinsiemi",
    "text": "21.5 Misura e Probabilit√† sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un‚Äôallocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme √® semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) √® \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura¬†21.12: Su un insieme finito, un‚Äôallocazione sugli elementi individuali definisce anche un‚Äôallocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilit√† soddisfano una serie di propriet√† utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilit√† abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poich√© i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione √® solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPi√π in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi pi√π piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa propriet√† di coerenza √® chiamata additivit√†.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l‚Äôintero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l‚Äôadditivit√† implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme √® la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilit√†, questo concetto √® ancora pi√π evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l‚Äôunione include l‚Äôelemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL‚Äôelemento che viene contato due volte √® esattamente l‚Äôunico elemento nell‚Äôintersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura¬†21.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste propriet√† dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali pu√≤ essere utile in circostanze diverse. Questa flessibilit√† √® molto comoda quando si applica la teoria della misura e la teoria della probabilit√† nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l‚Äôintero insieme fin dall‚Äôinizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura¬†21.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura¬†21.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non √® sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre pi√π piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura¬†21.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre pi√π piccoli.\n\n\n\nQuesta flessibilit√† nelle modalit√† di costruzione delle misure √® particolarmente utile perch√© permette di adattare l‚Äôapproccio alle specifiche necessit√† del problema in questione. Ad esempio, nella pratica, potremmo trovare pi√π semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) √® cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione √® necessaria per definire misure in modo coerente su insiemi matematicamente pi√π complessi, come la retta reale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01b_prob_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/01b_prob_spaces.html#commenti-e-considerazioni-finali",
    "title": "21¬† Misura di Probabilit√†",
    "section": "21.6 Commenti e considerazioni finali",
    "text": "21.6 Commenti e considerazioni finali\nIl significato applicativo delle nozioni di misura e distribuzione di probabilit√† √® centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale √® capire cosa rappresenta \\(M\\), la ‚Äúmisura totale‚Äù. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilit√†, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilit√† √® quindi l‚Äôallocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilit√† individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la ‚Äúmisura totale‚Äù \\(M\\) √® interpretata come la somma totale delle probabilit√†, che √® sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificher√†.\nQuando creiamo una distribuzione di probabilit√†, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l‚Äôintera certezza (pari a 1) tra questi esiti. Ogni valore di probabilit√† \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nLe nozioni di misura e distribuzione di probabilit√† trovano numerose applicazioni pratiche. Ad esempio:\n\nInferenza bayesiana: Utilizziamo distribuzioni di probabilit√† per rappresentare le nostre incertezze sui parametri di interesse. Dopo aver osservato i dati, aggiorniamo queste distribuzioni tramite il teorema di Bayes.\nModellizzazione probabilistica: Costruiamo modelli che descrivono il comportamento di sistemi complessi assegnando probabilit√† agli eventi possibili. Questo ci permette di fare previsioni e prendere decisioni informate basate sulle probabilit√† assegnate.\n\nIn conclusione, le nozioni di misura e distribuzione di probabilit√† sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti √® fondamentale per comprendere le applicazioni della teoria della probabilit√† e della statistica bayesiana. La ‚Äúmisura totale‚Äù \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilit√† ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "",
    "text": "Introduzione\nNel Capitolo 21 abbiamo introdotto la teoria della misura e della probabilit√† su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilit√† a spazi pi√π generali come questi non √® sempre semplice.\nSenza entrare nei dettagli, √® stato dimostrato che la forma pi√π generale della teoria della misura e della probabilit√† applicabile a qualsiasi spazio matematico √® chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un‚Äôintroduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilit√† e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilit√† e la misura possono essere utilizzate in contesti pi√π complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html#sigma-algebre",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html#sigma-algebre",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "22.1 \\(\\sigma\\)-Algebre",
    "text": "22.1 \\(\\sigma\\)-Algebre\nUna \\(\\sigma\\)-algebra √® una struttura matematica che permette di filtrare i sottoinsiemi di un insieme in modo coerente. √à utilizzata per definire gli insiemi misurabili in uno spazio.\n\n22.1.1 Filtraggio dei Sottoinsiemi\nQuando si filtra l‚Äôinsieme delle parti di un insieme \\(X\\), √® importante che la collezione filtrata di sottoinsiemi sia chiusa rispetto a certe operazioni insiemistiche. In particolare, se un sottoinsieme \\(\\mathsf{x} \\subset X\\) appartiene alla collezione filtrata, devono appartenervi anche:\n\nIl complemento: Se \\(\\mathsf{x} \\in \\mathcal{X}\\), allora anche \\(\\mathsf{x}^{c} \\in \\mathcal{X}\\).\nL‚Äôunione numerabile: Se \\(\\mathsf{x}_1, \\mathsf{x}_2, \\ldots \\in \\mathcal{X}\\), allora \\(\\bigcup_{i=1}^{\\infty} \\mathsf{x}_i \\in \\mathcal{X}\\).\nL‚Äôintersezione numerabile: Se \\(\\mathsf{x}_1, \\mathsf{x}_2, \\ldots \\in \\mathcal{X}\\), allora \\(\\bigcap_{i=1}^{\\infty} \\mathsf{x}_i \\in \\mathcal{X}\\).\n\nQueste propriet√† assicurano che non ci siano ‚Äúbuchi‚Äù nella collezione filtrata, evitando la ricostruzione di sottoinsiemi esclusi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "22.2 Definizione di \\(\\sigma\\)-Algebra",
    "text": "22.2 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra √® una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti propriet√†:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l‚Äôunione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l‚Äôintero insieme \\(X\\) √® considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) √® stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all‚Äôinterno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non ‚Äúperda‚Äù elementi a causa di queste operazioni, mantenendo cos√¨ la coerenza e la completezza della collezione di sottoinsiemi.\n\n22.2.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), √® detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili √® cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilit√†. ## Gli Assiomi di Kolmogorov\nI tre assiomi di Kolmogorov definiscono le propriet√† fondamentali di una misura di probabilit√† e richiedono l‚Äôesistenza di una \\(\\sigma\\)-algebra.\n\nNon negativit√†: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilit√† di \\(A\\) √® non negativa. \\[\nP(A) \\geq 0.\n\\]\nNormalizzazione: La probabilit√† dell‚Äôintero spazio campionario \\(\\Omega\\) √® 1. \\[\nP(\\Omega) = 1.\n\\]\nAdditivit√† numerabile: Per qualsiasi sequenza numerabile di eventi mutuamente esclusivi \\(A_1, A_2, A_3, \\ldots\\), la probabilit√† della loro unione √® la somma delle loro probabilit√†. \\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n\n22.2.2 Connessione tra gli Assiomi di Kolmogorov e le \\(\\sigma\\)-Algebre\nGli assiomi di Kolmogorov sono definiti rispetto a una misura di probabilit√† \\(P\\) su uno spazio campionario \\(\\Omega\\) e implicano l‚Äôesistenza di una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). La \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) √® la collezione di eventi (sottoinsiemi di \\(\\Omega\\)) per i quali la misura di probabilit√† \\(P\\) √® definita.\n\nNon negativit√† garantisce che \\(P\\) assegni un valore non negativo a ogni evento nella \\(\\sigma\\)-algebra.\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), assicurando che \\(\\Omega\\) sia un elemento della \\(\\sigma\\)-algebra.\nAdditivit√† numerabile garantisce che la \\(\\sigma\\)-algebra sia chiusa rispetto alle unioni numerabili di insiemi disgiunti.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all‚Äôinterno della quale queste propriet√† valgono. La \\(\\sigma\\)-algebra √® quindi la collezione di eventi per i quali la misura di probabilit√† √® ben definita e coerente con gli assiomi di Kolmogorov.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html#probabilit√†",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html#probabilit√†",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "22.3 Probabilit√†",
    "text": "22.3 Probabilit√†\nUna volta definiti gli assiomi di Kolmogorov, √® possibile introdurre la definizione di probabilit√†.\nLa probabilit√† di un evento √® una misura numerica che indica la possibilit√† che tale evento si verifichi, in accordo con gli assiomi di Kolmogorov.\n\nSe \\(P(A) = 0\\), l‚Äôevento \\(A\\) √® impossibile.\nSe \\(P(A) = 1\\), l‚Äôevento \\(A\\) √® certo.\n\nPer denotare la probabilit√† che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove: \\[\nP(A^c) = 1 - P(A).\n\\]\n\n22.3.1 Propriet√† Derivate dagli Assiomi di Kolmogorov\nAlcune propriet√† importanti derivate dagli assiomi includono:\n\n\\(P(\\varnothing) = 0\\),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\),\n\\(0 \\leq P(A) \\leq 1\\),\n\\(P(A^c) = 1 - P(A)\\),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\).\n\n\n\n22.3.2 Regole di Addizione per Eventi\nPer eventi non mutuamente esclusivi, la probabilit√† della loro unione √® data da: \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\]\nUtilizzando il terzo assioma della probabilit√†, si ottiene: \\[\nP(A \\cup B) = P(A \\cap B^c) + P(B \\cap A^c) + P(A \\cap B).\n\\]\nQuando \\(A\\) e \\(B\\) sono mutuamente esclusivi, \\(P(A \\cap B) = 0\\), e quindi: \\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nLa legge della probabilit√† totale permette di scrivere: \\[\nP(A) = P(A \\cap B) + P(A \\cap B^c),\n\\] e analogamente per \\(B\\): \\[\nP(B) = P(B \\cap A) + P(B \\cap A^c).\n\\]\nIn conclusione, gli assiomi di Kolmogorov forniscono la base per definire la probabilit√† su una \\(\\sigma\\)-algebra, garantendo che le propriet√† fondamentali della probabilit√† siano rispettate e che la probabilit√† sia ben definita per una collezione coerente di sottoinsiemi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html#probabilit√†-e-calcolo-combinatorio",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html#probabilit√†-e-calcolo-combinatorio",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "22.4 Probabilit√† e Calcolo Combinatorio",
    "text": "22.4 Probabilit√† e Calcolo Combinatorio\nI problemi scolastici pi√π comuni sulle probabilit√† richiedono l‚Äôuso del calcolo combinatorio. La struttura generale di questi problemi √® sempre la stessa: dobbiamo contare il numero di modi in cui un evento compatibile con l‚Äôevento di ‚Äúsuccesso‚Äù definito dal problema si realizza e poi trovare la proporzione di tali eventi rispetto a tutti gli eventi possibili (inclusi quelli di ‚Äúinsuccesso‚Äù) che possono verificarsi nello spazio campionario. Questi problemi presentano due difficolt√† principali:\n\nTraduzione del problema: Trasformare la descrizione verbale del problema in una formulazione matematica chiara, suddividendo gli eventi possibili nello spazio campionario in base alle condizioni di successo e insuccesso definite dal problema.\nConteggio delle possibilit√†: Contare il numero di successi e il numero totale di eventi.\n\nPer risolvere questi problemi, dobbiamo utilizzare tecniche del calcolo combinatorio, come le permutazioni e le combinazioni, che ci permettono di contare in modo preciso il numero di possibilit√†.\nConsideriamo un esempio semplice e intuitivo per chiarire il concetto. Supponiamo di avere una scatola con 10 palline numerate da 1 a 10. Vogliamo calcolare la probabilit√† di estrarre una pallina con un numero pari.\n\nDefinizione degli eventi: In questo caso, l‚Äôevento di ‚Äúsuccesso‚Äù √® l‚Äôestrazione di una pallina con un numero pari.\n\nEventi di successo: {2, 4, 6, 8, 10}\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\nConteggio delle possibilit√†:\n\nNumero di eventi di successo: 5\nNumero totale di eventi: 10\n\nCalcolo della probabilit√†: \\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5\n\\]\n\nPer problemi pi√π complessi, come il calcolo della probabilit√† di ottenere una determinata combinazione di carte da un mazzo o di formare un particolare gruppo di persone da una popolazione pi√π grande, utilizziamo strumenti del calcolo combinatorio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "22.5 Il Problema dei Fratelli Bernoulli",
    "text": "22.5 Il Problema dei Fratelli Bernoulli\nLa soluzione dei problemi di probabilit√† non √® sempre semplice e nella storia della matematica ci sono molti esempi di celebri matematici che hanno commesso errori. Uno di questi aneddoti riguarda Jakob Bernoulli, uno dei pionieri della teoria della probabilit√†.\nJakob Bernoulli si interess√≤ al calcolo delle probabilit√† mentre cercava di formalizzare le leggi del caso nel suo libro ‚ÄúArs Conjectandi‚Äù, pubblicato postumo nel 1713. Uno dei problemi che affront√≤ riguardava il calcolo della probabilit√† di ottenere almeno una testa in 8 lanci di una moneta equa. Nonostante il suo approccio iniziale fosse corretto, Bernoulli commise un errore nel calcolo combinatorio durante il processo.\nPer risolvere il problema di calcolare la probabilit√† di ottenere almeno una testa in 8 lanci, bisogna considerare la probabilit√† complementare, ovvero la probabilit√† di non ottenere alcuna testa (ottenere solo croci) in 8 lanci, e poi sottrarla da 1:\n\nCalcolo della probabilit√† complementare: La probabilit√† di ottenere solo croci in un singolo lancio √® \\(\\frac{1}{2}\\). La probabilit√† di ottenere solo croci in 8 lanci consecutivi √®: \\[\n\\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\nCalcolo della probabilit√† di ottenere almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{nessuna testa}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nJakob Bernoulli commise un errore nel calcolo combinatorio che lo port√≤ a una soluzione errata. Egli sottostim√≤ la probabilit√† di ottenere almeno una testa, probabilmente a causa di un errore nel conteggio delle possibili combinazioni di successi e insuccessi.\nQuesto errore fu successivamente corretto da altri matematici, tra cui suo nipote Daniel Bernoulli, che dimostrarono il metodo corretto per risolvere tali problemi utilizzando il calcolo combinatorio in modo appropriato.\nLa storia del calcolo combinatorio e della probabilit√† √® ricca di aneddoti come quello di Jakob Bernoulli. Questi episodi evidenziano come i problemi di probabilit√† possano essere estremamente controintuitivi, anche per i grandi matematici. Oggi siamo in grado di risolvere molti di questi problemi grazie al lavoro e alle correzioni apportate dai matematici che ci hanno preceduto. La teoria della probabilit√†, come molte altre discipline scientifiche, √® il frutto di un lungo processo di sviluppo e comprensione che ha richiesto tempo e sforzi considerevoli.\n\nEsempio 22.1 Il problema dei compleanni, generalmente attribuito a Richard von Mises, √® un noto esempio controintuitivo di calcolo delle probabilit√† che utilizza il calcolo combinatorio, in particolare le permutazioni. Il problema chiede quanti individui sono necessari affinch√© la probabilit√† che almeno due persone abbiano lo stesso compleanno superi il 50%, assumendo che ogni giorno dell‚Äôanno sia ugualmente probabile come compleanno. Sorprendentemente, la risposta √® solo 23 persone, molto meno di quanto la maggior parte delle persone immagina.\nPer risolvere il problema dei compleanni utilizzando le permutazioni, consideriamo la seguente relazione:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - P(\\text{nessuno ha lo stesso compleanno}).\n\\]\nQuesta uguaglianza √® valida perch√© l‚Äôevento ‚Äúnessuno ha lo stesso compleanno‚Äù √® il complemento dell‚Äôevento ‚Äúalmeno due persone hanno lo stesso compleanno‚Äù. Pertanto, dobbiamo calcolare la probabilit√† che nessuno abbia lo stesso compleanno.\nSia \\(k\\) il numero di persone. Per calcolare la probabilit√† che nessuno abbia lo stesso compleanno, dobbiamo contare il numero di modi in cui \\(k\\) persone possono avere compleanni diversi. Poich√© ogni compleanno √® ugualmente probabile, possiamo usare le permutazioni per contare il numero di modi in cui \\(k\\) compleanni unici possono essere disposti su 365 giorni:\n\\[\n365P_k = \\frac{365!}{(365 - k)!}.\n\\]\nDividiamo questo numero per il numero totale di elementi nello spazio campionario, che √® il numero totale di modi in cui \\(k\\) compleanni possono essere disposti su 365 giorni:\n\\[\n365^k.\n\\]\nQuindi, la probabilit√† che nessuno abbia lo stesso compleanno √®:\n\\[\nP(\\text{nessuno ha lo stesso compleanno}) = \\frac{365P_k}{365^k} = \\frac{365!}{365^k (365 - k)!}.\n\\]\nUsando questa formula, la probabilit√† che almeno due persone abbiano lo stesso compleanno √®:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - \\frac{365!}{365^k (365 - k)!}.\n\\]\nIn sintesi, calcolando questa probabilit√†, si scopre che bastano solo 23 persone affinch√© la probabilit√† che almeno due di loro abbiano lo stesso compleanno superi il 50%, un risultato sorprendente rispetto all‚Äôintuizione comune.\n\ndef birthday(k):\n    logdenom = k * math.log(365) + math.lgamma(365 - k + 1) # log denominatore\n    lognumer = math.lgamma(366) # log numeratore\n    pr = 1 - np.exp(lognumer - logdenom) # trasformazione inversa\n    return pr\n\nk = np.arange(1, 51)\nbday = [birthday(i) for i in k]\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\n\nplt.plot(k, bday, marker=\"o\", color=color_fill)\nplt.xlabel('Numero di persone')\nplt.ylabel('Probabilit√† che almeno due persone\\nabbiano lo stesso compleanno')\nplt.axhline(\n    y=0.5,\n    color=color_edge,\n    linestyle=\"-\"\n)\nplt.xlim(0, 50)\nplt.ylim(0, 1)\nplt.grid(True)\nplt.title('Probabilit√† del Problema dei Compleanni')\nplt.show()\n\nprint(\"Probabilit√† per 20-25 persone:\", bday[19:25])\n\n\n\n\n\n\n\n\nProbabilit√† per 20-25 persone: [0.41143838358049944, 0.44368833516523465, 0.47569530766240553, 0.507297234324024, 0.5383442579144757, 0.5686997039694264]\n\n\nOsserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno supera 0.5. Quando il numero di persone √® pi√π di 50, questa probabilit√† √® quasi 1.\n\n\nEsempio 22.2 Abbiamo derivato una soluzione analitica esatta per il problema dei compleanni, ma possiamo anche produrre una soluzione approssimata utilizzando il metodo della simulazione Monte Carlo. Il nome deriva dal Casin√≤ di Monte Carlo a Monaco, ma possiamo semplicemente chiamarlo metodo di simulazione. La simulazione Monte Carlo √® una classe generale di metodi stocastici (contrariamente ai metodi deterministici) che possono essere utilizzati per risolvere approssimativamente problemi analitici generando casualmente le quantit√† di interesse.\nPer il problema dei compleanni, campioniamo \\(k\\)compleanni potenzialmente non unici su 365 giorni e verifichiamo se i \\(k\\)compleanni campionati sono tutti diversi. Utilizziamo il campionamento con reinserimento perch√© ad ogni estrazione ogni giorno dei 365 √® ugualmente probabile, indipendentemente dai giorni estratti in precedenza. In altre parole, il fatto che una persona sia nata in un certo giorno dell‚Äôanno non esclude che qualcun altro possa essere nato lo stesso giorno. Dopo aver ripetuto questa procedura di campionamento molte volte, calcoliamo la frazione di prove di simulazione in cui almeno due compleanni sono uguali, e questa frazione serve come stima della probabilit√† corrispondente. Questa procedura di simulazione √® intuitiva perch√© emula il processo di generazione dei dati descritto nel problema dei compleanni.\nPer implementare il campionamento con o senza reinserimento in Python, utilizziamo la funzione numpy.random.choice. Nel caso del campionamento con reinserimento, impostiamo l‚Äôargomento replace su True. Il campionamento senza reinserimento significa che, una volta campionato un elemento, questo non sar√† disponibile per estrazioni successive.\n\nk = 23  # numero di persone\nsims = 1000  # numero di simulazioni\nevent = 0  # contatore eventi\n\nfor _ in range(sims):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event += 1\n\n# frazione di prove in cui almeno due compleanni sono uguali\nanswer = event / sims\nprint(f\"Stima della probabilit√†: {answer}\")\n\n# Aumentare il numero di simulazioni a un milione per maggiore accuratezza\nsims_large = 1000000\nevent_large = 0\n\nfor _ in range(sims_large):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event_large += 1\n\nanswer_large = event_large / sims_large\nprint(f\"Stima con un milione di simulazioni: {answer_large}\")\n\nStima della probabilit√†: 0.523\nStima con un milione di simulazioni: 0.50748\n\n\nNel codice sopra, abbiamo impostato il numero di simulazioni a 1000. Aumentando il numero di simulazioni a un milione, otteniamo una stima pi√π accurata. Osserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno √® superiore a 0.5. Quando il numero di persone supera 50, questa probabilit√† √® vicina a 1.\nLa simulazione Monte Carlo √® una classe generale di procedure di campionamento casuale ripetuto utilizzate per risolvere approssimativamente problemi analitici. I metodi comunemente utilizzati includono il campionamento con reinserimento, in cui la stessa unit√† pu√≤ essere campionata ripetutamente, e il campionamento senza reinserimento, in cui ogni unit√† pu√≤ essere campionata al massimo una volta.\n\n\nEsempio 22.3 Supponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual √® la probabilit√† che almeno 2 psicologi clinici siano nella commissione? Per calcolare questa probabilit√†, utilizziamo la seguente uguaglianza:\n\\[\nP(\\text{almeno 2 psicologi clinici}) = 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}).\n\\]\nIl numero totale di modi per selezionare 5 persone dal gruppo di 20 √® dato da:\n\\[\n\\binom{20}{5} = \\frac{20!}{5!(15!)} = 15,504.\n\\]\nIl numero di modi per avere nessun psicologo clinico nella commissione (ovvero, selezionare solo psicologi del lavoro) √®:\n\\[\n\\binom{10}{0} \\times \\binom{10}{5} = 1 \\times 252 = 252.\n\\]\nQuindi, la probabilit√† di avere nessun psicologo clinico √®:\n\\[\nP(\\text{nessun psicologo clinico}) = \\frac{252}{15,504} \\approx 0.016.\n\\]\nIl numero di modi per avere esattamente 1 psicologo clinico nella commissione √®:\n\\[\n\\binom{10}{1} \\times \\binom{10}{4} = 10 \\times 210 = 2,100.\n\\]\nQuindi, la probabilit√† di avere esattamente 1 psicologo clinico √®:\n\\[\nP(\\text{1 psicologo clinico}) = \\frac{2,100}{15,504} \\approx 0.135.\n\\]\nLa probabilit√† di avere almeno 2 psicologi clinici nella commissione √® quindi:\n\\[\n\\begin{align}\nP(\\text{almeno 2 psicologi clinici}) &= 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}) \\notag\\\\\n&= 1 - 0.016 - 0.135 \\notag\\\\\n&= 0.849.\\notag\n\\end{align}\n\\]\nQuindi, la probabilit√† che almeno 2 psicologi clinici siano nella commissione √® circa 0.849 o 84.9%.\nSvolgiamo il problema in Python.\n\n# Funzione per calcolare le combinazioni\ndef nCk(n, k):\n    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n\n# Calcolo delle probabilit√† per il problema della commissione\ntotal_ways = nCk(20, 5)\nno_clinical = nCk(10, 0) * nCk(10, 5)\none_clinical = nCk(10, 1) * nCk(10, 4)\n\np_no_clinical = no_clinical / total_ways\np_one_clinical = one_clinical / total_ways\n\np_at_least_two_clinical = 1 - p_no_clinical - p_one_clinical\n\nprint(f\"Probabilit√† di almeno 2 psicologi clinici: {p_at_least_two_clinical:.3f}\")\n\nProbabilit√† di almeno 2 psicologi clinici: 0.848",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "22.6 Commenti e considerazioni finali",
    "text": "22.6 Commenti e considerazioni finali\nLa teoria delle probabilit√† √® fondamentale per la statistica e ha numerose applicazioni pratiche, tra cui la psicologia. Comprendere le probabilit√† ci permette di prendere decisioni informate in situazioni incerte e di sviluppare previsioni affidabili. Una solida comprensione delle nozioni di base della probabilit√† ci consente di affrontare una vasta gamma di problemi e di prendere decisioni basate sulla probabilit√† dei risultati possibili. Tuttavia, √® essenziale ricordare che i modelli probabilistici sono solo approssimazioni della realt√† e possono essere influenzati da semplificazioni e limitazioni dei dati disponibili. Pertanto, √® importante esercitare cautela nell‚Äôinterpretazione dei risultati e comprendere le assunzioni alla base delle analisi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01c_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/01c_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "22¬† Misure e distribuzioni di probabilit√†",
    "section": "22.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "22.7 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Misure e distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html",
    "href": "chapters/chapter_3/02_conditional_prob.html",
    "title": "23¬† Probabilit√† condizionata",
    "section": "",
    "text": "Introduzione\nUn principio fondamentale nel campo della probabilit√† √® il concetto di condizionamento. Il condizionamento si verifica quando, all‚Äôinterno di un esperimento aleatorio, le probabilit√† vengono calcolate focalizzandosi esclusivamente su un sottoinsieme specifico dei risultati possibili. In pratica, questo significa che la probabilit√† viene determinata tenendo conto solo di quei risultati che rientrano in un certo criterio o condizione predefinita.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/chapter_3/02_conditional_prob.html#indipendenza-stocastica",
    "title": "23¬† Probabilit√† condizionata",
    "section": "23.1 Indipendenza Stocastica",
    "text": "23.1 Indipendenza Stocastica\nNel contesto della probabilit√† condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilit√† in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull‚Äôaltro.\n\n23.1.1 Indipendenza di Due Eventi\nDue eventi \\(A\\) e \\(B\\) sono detti indipendenti se il verificarsi di uno non influenza la probabilit√† di verificarsi dell‚Äôaltro. Formalmente, questa condizione √® espressa come:\n\\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B),\\]\ndove \\(\\mathbb{P}(A \\cap B)\\) rappresenta la probabilit√† che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino simultaneamente.\nSe questa condizione √® soddisfatta, scriviamo \\(A \\text{ ‚´´ } B\\), il che significa ‚ÄúA √® indipendente da B‚Äù.\n\n\n23.1.2 Indipendenza di un Insieme di Eventi\nL‚Äôindipendenza stocastica √® un concetto fondamentale nell‚Äôapplicazione della probabilit√† in campo statistico. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) √® detto indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilit√† dell‚Äôintersezione degli eventi nel sottoinsieme \\(J\\) √® uguale al prodotto delle loro singole probabilit√†. Formalmente:\n\\[\\mathbb{P} \\left( \\cap_{i \\in J} A_i \\right) = \\prod_{i \\in J} \\mathbb{P}(A_i).\\]\nQuesto significa che ogni combinazione finita di eventi nell‚Äôinsieme √® indipendente.\nL‚Äôindipendenza pu√≤ essere assunta o derivata a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perch√© questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l‚Äôindipendenza pu√≤ essere derivata dai dati o da altre propriet√† del modello.\n\n\n23.1.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cio√® \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno una probabilit√† positiva di verificarsi, allora non possono essere indipendenti. Questo perch√© per eventi disgiunti con \\(\\mathbb{P}(A) &gt; 0\\) e \\(\\mathbb{P}(B) &gt; 0\\), l‚Äôequazione di indipendenza \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) non pu√≤ essere soddisfatta, dato che \\(\\mathbb{P}(A \\cap B) = 0\\) e \\(\\mathbb{P}(A) \\mathbb{P}(B) &gt; 0\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#sec-v",
    "href": "chapters/chapter_3/02_conditional_prob.html#sec-v",
    "title": "23¬† Probabilit√† condizionata",
    "section": "23.2 Probabilit√† condizionata su altri eventi",
    "text": "23.2 Probabilit√† condizionata su altri eventi\nLa probabilit√† di un evento √® intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilit√† specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilit√† associata all‚Äôevento verr√† corrispondentemente aggiornata.\nIn realt√†, tutte le probabilit√† possono essere intese come probabilit√† condizionate, anche quando la variabile o l‚Äôevento condizionante non √® esplicitamente specificato. Ci√≤ implica che le probabilit√† sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.\nQuesto quadro concettuale ci induce a considerare le probabilit√† come una ‚Äòmisura di plausibilit√†‚Äô che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell‚Äôacquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilit√†, e quindi la probabilit√† attribuita agli eventi, pu√≤ essere rivista.\n\nTeorema 23.1 Siano \\(A\\) e \\(B\\) due eventi definiti su uno spazio campionario \\(S\\). Supponendo che l‚Äôevento \\(B\\) si verifichi, la probabilit√† condizionata di \\(A\\) dato \\(B\\) √® data da\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{per}\\, P(B) &gt; 0,\n\\tag{23.1}\\]\ndove \\(P(A \\cap B)\\) rappresenta la probabilit√† congiunta dei due eventi, ovvero la probabilit√† che entrambi si verifichino.\n\nNell‚ÄôEquazione¬†23.1, \\(P(A \\cap B)\\) √® la probabilit√† congiunta che entrambi gli eventi si verifichino, mentre \\(P(B)\\) √® la probabilit√† marginale dell‚Äôevento \\(B\\). Riorganizzando i termini, otteniamo la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nUtilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilit√† totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c).\n\\]\nDove \\(B^c\\) rappresenta il complemento dell‚Äôevento \\(B\\).\n√à importante notare che \\(P(A \\mid B)\\) non √® definita se \\(P(B) = 0\\).\nLa probabilit√† condizionata pu√≤ essere interpretata come una ricalibrazione dello spazio campionario da \\(S\\) a \\(B\\). Per spazi campionari discreti, la probabilit√† condizionata √® espressa come\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\n\nEsempio 23.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilit√† che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilit√† in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poich√© ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilit√† di ottenere una somma minore di 8 √® 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma √® minore di 8. Quindi, la probabilit√† di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l‚Äôinformazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in Python.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nevent = [roll for roll in sample if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample)}\")\n\n21 / 36\n\n\n\nsample_odd = [roll for roll in sample if (sum(roll) % 2) != 0]\nsample_odd\n\n[(1, 2),\n (1, 4),\n (1, 6),\n (2, 1),\n (2, 3),\n (2, 5),\n (3, 2),\n (3, 4),\n (3, 6),\n (4, 1),\n (4, 3),\n (4, 5),\n (5, 2),\n (5, 4),\n (5, 6),\n (6, 1),\n (6, 3),\n (6, 5)]\n\n\n\nevent = [roll for roll in sample_odd if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample_odd)}\")\n\n12 / 18\n\n\nSe applichiamo l‚ÄôEquazione¬†23.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilit√† di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l‚Äôinformazione che la somma √® dispari, la probabilit√† di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 23.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilit√† del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificit√† del test: 90%. Ci√≤ indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo √® il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne √® affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual √® la probabilit√† che una donna scelta a caso ottenga una mammografia positiva? Poich√© il 1% delle donne ha il cancro al seno, la probabilit√† di ottenere una mammografia positiva (test positivo) √® pari alla sensibilit√† del test, ovvero 0.90 (cio√® 90%).\nSe la mammografia √® positiva, qual √® la probabilit√† che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test dar√† un risultato positivo (vera positivit√†) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test dar√† un risultato positivo (falsa positivit√†) in 99 casi (10%).\n\nQuesta situazione pu√≤ essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura¬†23.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test d√† un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilit√† di ottenere un risultato positivo al test √® \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilit√† di avere il cancro al seno, dato un risultato positivo al test, √® pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all‚Äô8.3%.\nIn questo esempio, la probabilit√† dell‚Äôevento ‚Äúottenere un risultato positivo al test‚Äù √® una probabilit√† non condizionata, poich√© calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D‚Äôaltra parte, la probabilit√† dell‚Äôevento ‚Äúavere il cancro al seno, dato che il test ha prodotto un risultato positivo‚Äù √® una probabilit√† condizionata, poich√© calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) pu√≤ influenzare la probabilit√† di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilit√† condizionate e non condizionate.\n\n\nEsempio 23.3 Il paradosso di Monty Hall rappresenta un curioso esempio di come l‚Äôintroduzione di nuove informazioni possa influenzare l‚Äôesito di una situazione probabilistica. Questo famoso problema trae origine dal popolare programma televisivo americano ‚ÄúLet‚Äôs Make a Deal‚Äù e deve la sua notoriet√† al conduttore Monty Hall.\nNel gioco ci sono tre porte chiuse: dietro una si nasconde un‚Äôautomobile, mentre dietro le altre due ci sono delle capre. Inizialmente, il concorrente sceglie una delle tre porte senza aprirla. Successivamente, Monty Hall apre una delle due porte rimaste, rivelando una capra. A questo punto, offre al concorrente la possibilit√† di cambiare la sua scelta iniziale e optare per l‚Äôaltra porta ancora chiusa. Il paradosso si presenta quando si scopre che cambiando la scelta in questa fase, il concorrente aumenta le sue probabilit√† di vincere l‚Äôautomobile, passando da 1/3 a 2/3.\nPer confermare questo risultato inaspettato, √® possibile eseguire una simulazione in Python. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilit√† del concorrente di vincere l‚Äôautomobile.\nDi seguito √® riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nporte = [\n    \"capra1\",\n    \"capra2\",\n    \"macchina\",\n]  # definisco il gioco, scelgo una porta a caso per n volte\ncounter = 0\ncontatore_cambio = 0\nn = 10000\nporta_vincente = \"macchina\"\nfor i in range(n):\n    scelta_casuale = random.choice(porte)\n    porte_rimaste = [x for x in porte if x != scelta_casuale]\n    porta_rivelata = random.choice([x for x in porte_rimaste if x != porta_vincente])\n    porta_alternativa = [\n        x for x in porte if x != scelta_casuale and x != porta_rivelata\n    ]\n    if \"macchina\" in porta_alternativa:\n        contatore_cambio += 1\n    if scelta_casuale == \"macchina\":\n        counter += 1\n\nprint(counter / n)  # quante volte vinco non cambiando porta\nprint(contatore_cambio / n)  # quante volte vinco cambiando porta\n\nQuesto script Python √® stato creato da un gruppo di studenti di Psicometria nell‚ÄôAA 2023-2023. La simulazione mostra che, effettivamente, la probabilit√† di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\nEcco una spiegazione del paradosso:\n\nFase Iniziale: Nel gioco, il concorrente deve scegliere una delle tre porte (A, B, C), dietro una delle quali si trova una macchina. Inizialmente, la probabilit√† che la macchina si trovi dietro la porta scelta √® \\(1/3\\), dato che esistono tre possibilit√† ugualmente probabili e solo una contiene la macchina.\nAggiunta di Informazioni: Dopo la scelta iniziale, Monty Hall, che conosce il contenuto dietro ogni porta, apre una delle due porte non scelte, rivelando sempre una capra. Questo passaggio √® fondamentale: non cambia la probabilit√† \\(1/3\\) che la macchina sia dietro la porta originariamente scelta dal concorrente, ma la probabilit√† che la macchina si trovi dietro l‚Äôaltra porta non scelta aumenta ora a \\(2/3\\). Questo aumento di probabilit√† deriva dal fatto che Monty ha scelto deliberatamente una porta con una capra, basando la sua scelta sulla posizione della macchina.\n\nConsideriamo i tre possibili scenari dopo che il concorrente ha scelto la porta A:\n\nLa macchina √® dietro la porta A: La probabilit√† di questo scenario √® \\(1/3\\). Monty pu√≤ aprire sia la porta B che la porta C, poich√© entrambe nascondono una capra. Se il concorrente cambia la sua scelta, perder√†.\nLa macchina √® dietro la porta B: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta C, perch√© sa che la macchina √® dietro la porta B e non pu√≤ rivelarla. Se il concorrente cambia la sua scelta da A a B, vincer√†.\nLa macchina √® dietro la porta C: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta B. Se il concorrente cambia la sua scelta da A a C, vincer√†.\n\nIn conclusione, cambiare la scelta originale porta alla vittoria in due dei tre scenari possibili. Pertanto, la probabilit√† complessiva di vincere cambiando la scelta √® \\(2/3\\).\nQuesto paradosso evidenzia come, in presenza di informazioni aggiuntive, le probabilit√† iniziali possano essere riviste significativamente. √à un classico esempio di come l‚Äôintuizione umana spesso si scontri con i principi della teoria delle probabilit√†, sottolineando l‚Äôimportanza della revisione bayesiana delle probabilit√† alla luce di nuove informazioni.\n\n\n23.2.1 Il paradosso di Simpson\nNel campo della probabilit√† condizionata, uno dei fenomeni pi√π interessanti e, nel contempo, pi√π controintuitivi, √® rappresentato dal paradosso di Simpson. Il paradosso di Simpson √® un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l‚Äôimportanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 23.4 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d‚Äôansia e coaching per migliorare le prestazioni lavorative. Ogni terapia pu√≤ avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d‚Äôansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi √® efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno √® un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere pi√π precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo √® che Rossi, presumibilmente a causa della sua reputazione come terapeuta pi√π esperto, sta effettuando un numero maggiore di terapie per disturbi d‚Äôansia, che sono intrinsecamente pi√π complesse e con una probabilit√† di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale √® inferiore non a causa di una minore abilit√† in un particolare tipo di terapia, ma perch√© una frazione maggiore delle sue terapie riguarda casi pi√π complessi.\nL‚Äôaggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilit√† dei terapeuti perch√© perdiamo l‚Äôinformazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, √® fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#teorema-della-probabilit√†-composta",
    "href": "chapters/chapter_3/02_conditional_prob.html#teorema-della-probabilit√†-composta",
    "title": "23¬† Probabilit√† condizionata",
    "section": "23.3 Teorema della probabilit√† composta",
    "text": "23.3 Teorema della probabilit√† composta\n√à possibile scrivere l‚ÄôEquazione¬†23.1 nella forma:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{23.2}\\]\nQuesto secondo modo di scrivere l‚ÄôEquazione¬†23.1 √® chiamato teorema della probabilit√† composta (o regola moltiplicativa, o regola della catena). La legge della probabilit√† composta ci dice che la probabilit√† che si verifichino contemporaneamente due eventi \\(A\\) e \\(B\\) √® pari alla probabilit√† di uno dei due eventi moltiplicata per la probabilit√† dell‚Äôaltro evento condizionata al verificarsi del primo.\nL‚Äôl‚ÄôEquazione¬†23.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{23.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 23.5 Per fare un esempio, consideriamo il problema seguente. Da un‚Äôurna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell‚Äôurna. Indichiamo con \\(B_i\\) l‚Äôevento: ‚Äúesce una pallina bianca alla \\(i\\)-esima estrazione‚Äù e con \\(N_i\\) l‚Äôestrazione di una pallina nera. L‚Äôevento: ‚Äúescono due palline bianche nelle prime due estrazioni‚Äù √® rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l‚ÄôEquazione¬†23.2, la sua probabilit√† vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perch√© nella prima estrazione \\(\\Omega\\) √® costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilit√† condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perch√© nella seconda estrazione, se √® verificato l‚Äôevento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l‚Äôesperimento consiste nell‚Äôestrazione successiva di 3 palline, la probabilit√† che queste siano tutte bianche, per l‚ÄôEquazione¬†23.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilit√† dell‚Äôestrazione di tre palline nere √® invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "href": "chapters/chapter_3/02_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "title": "23¬† Probabilit√† condizionata",
    "section": "23.4 Il teorema della probabilit√† totale",
    "text": "23.4 Il teorema della probabilit√† totale\nIl teorema della probabilit√† totale (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario \\(\\Omega\\) in \\(n\\) eventi mutualmente esclusivi e tali che la loro unione formi \\(\\Omega\\), allora la probabilit√† di un qualsiasi evento in \\(\\Omega\\) pu√≤ essere calcolata sommando la probabilit√† dell‚Äôevento su ciascun sottoinsieme della partizione, pesata in base alla probabilit√† del sottoinsieme.\nIn altre parole, se \\(H_1, H_2, \\dots, H_n\\) sono eventi mutualmente esclusivi e tali che \\(\\bigcup_{i=1}^n H_i = \\Omega\\), allora per ogni evento \\(E \\subseteq \\Omega\\), la probabilit√† di \\(E\\) √® data dalla formula:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{23.4}\\]\ndove \\(P(E \\mid H_i)\\) rappresenta la probabilit√† condizionata di \\(E\\) dato che si √® verificato l‚Äôevento \\(H_i\\), e \\(P(H_i)\\) √® la probabilit√† dell‚Äôevento \\(H_i\\).\nIl teorema della probabilit√† totale riveste un ruolo fondamentale in quanto fornisce il denominatore nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione √® di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilit√† valida. Per ulteriori dettagli e approfondimenti, √® possibile fare riferimento al Capitolo 36.\nNell‚Äôambito della probabilit√† discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilit√† di un evento, sfruttando le probabilit√† dei singoli eventi della partizione. Il caso pi√π semplice √® quello di una partizione dello spazio campione in due sottoinsiemi: \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\).\n\n\n\n\n\n\nFigura¬†23.2: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nIn tali circostanza abbiamo che\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nL‚ÄôEquazione¬†23.4 √® utile per calcolare \\(P(E)\\), se \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono facili da trovare.\n\nEsempio 23.6 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un‚Äôurna anch‚Äôessa scelta a caso. Qual √® la probabilit√† che la pallina estratta sia di colore rosso?\nSia \\(R\\) l‚Äôevento ‚Äúla pallina estratta √® rossa‚Äù e sia \\(U_i\\) l‚Äôevento che corrisponde alla scelta dell‚Äô\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilit√† totale, la probabilit√† di estrarre una pallina rossa √® dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]\n\n\n23.4.1 Indipendenza e probabilit√† condizionata\nL‚Äôindipendenza tra due eventi \\(A\\) e \\(B\\) pu√≤ essere espressa in modo intuitivo utilizzando la probabilit√† condizionata. Se \\(A\\) e \\(B\\) sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilit√† del verificarsi dell‚Äôaltro. In altre parole, la probabilit√† che \\(A\\) accada non cambia se sappiamo che \\(B\\) √® avvenuto, e viceversa.\nPossiamo esprimere questa idea con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nQuindi, due eventi \\(A\\) e \\(B\\) sono indipendenti se soddisfano le condizioni:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQuesto significa che la probabilit√† di \\(A\\) rimane invariata indipendentemente dal fatto che \\(B\\) sia accaduto o meno, e lo stesso vale per \\(B\\).\n\n23.4.1.1 Indipendenza di Tre Eventi\nTre eventi \\(A\\), \\(B\\) e \\(C\\) sono indipendenti se soddisfano le seguenti condizioni:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C), \\\\\nP(A \\cap B \\cap C) &= P(A) P(B) P(C).\n\\end{align}\n\\]\nLe prime tre condizioni verificano l‚Äôindipendenza a due a due, ovvero l‚Äôindipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l‚Äôultima condizione, che riguarda l‚Äôintersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che \\(A\\), \\(B\\) e \\(C\\) sono completamente indipendenti.\nIn sintesi, l‚Äôindipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilit√† del verificarsi degli altri.\n\nEsempio 23.7 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilit√† con un mazzo completo\nIn un mazzo completo, la probabilit√† di pescare una carta di picche (\\(P(A)\\)) √® $ = \\(, poich√© ci sono 13 picche su 52 carte totali. La probabilit√† di pescare una regina (\\)P(B)$) √® $ = $, poich√© ci sono 4 regine su 52 carte.\nOra consideriamo la probabilit√† congiunta di pescare la regina di picche (\\(P(AB)\\)). Poich√© esiste solo una regina di picche nel mazzo, la probabilit√† di pescare questa specifica carta √® $ $.\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoich√© \\(P(AB) = \\frac{1}{52}\\) √® uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilit√† dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilit√† con questo mazzo ridotto:\nLa probabilit√† di pescare la regina di picche (\\(P(AB)\\)) √® ora $ $, poich√© ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa $ $, poich√© ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa $ $, poich√© ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilit√†:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoich√© $ $, gli eventi \\(A\\) e \\(B\\) non sono pi√π indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l‚Äôindipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilit√† cambiano e gli eventi non sono pi√π indipendenti. Questo evidenzia l‚Äôimportanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilit√† e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilit√†, influenzando le relazioni di indipendenza tra eventi specifici.\nIn generale, l‚Äôindipendenza tra due eventi significa che la probabilit√† di uno non √® influenzata dal verificarsi dell‚Äôaltro. Questo concetto √® cruciale per analisi probabilistiche e modelli statistici pi√π complessi.\n\n\nEsempio 23.8 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = ‚Äúesce un 1 o un 2 nel primo lancio‚Äù e \\(B\\) = ‚Äúil punteggio totale √® 8‚Äù. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nCalcoliamo \\(P(A)\\):\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nA = [roll for roll in sample if roll[0] == 1 or roll[0] == 2]\nprint(A)\nprint(f\"{len(A)} / {len(sample)}\")\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n12 / 36\n\n\nCalcoliamo \\(P(B)\\):\n\nB = [roll for roll in sample if roll[0] + roll[1] == 8]\nprint(B)\nprint(f\"{len(B)} / {len(sample)}\")\n\n[(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)]\n5 / 36\n\n\nCalcoliamo \\(P(A \\cap B)\\):\n\nI = [\n    roll\n    for roll in sample\n    if (roll[0] == 1 or roll[0] == 2) and (roll[0] + roll[1] == 8)\n]\nprint(I)\nprint(f\"{len(I)} / {len(sample)}\")\n\n[(2, 6)]\n1 / 36\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti dato che \\(P(A \\cap B) \\neq P(A)P(B)\\):\n\n12/36 * 5/36 == 1/36\n\nFalse",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/02_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "23¬† Probabilit√† condizionata",
    "section": "23.5 Commenti e considerazioni finali",
    "text": "23.5 Commenti e considerazioni finali\nLa probabilit√† condizionata riveste un ruolo fondamentale poich√© ci permette di definire in modo preciso il concetto di indipendenza statistica. Uno degli aspetti cruciali dell‚Äôanalisi statistica riguarda la valutazione dell‚Äôassociazione tra due variabili. Nel capitolo attuale, ci siamo concentrati sul concetto di indipendenza, che indica l‚Äôassenza di relazione tra le variabili. Tuttavia, in futuro, esploreremo come fare inferenze sulla correlazione tra variabili, ovvero come determinare se le variabili sono associate tra loro o se esiste una relazione statistica credibile tra di esse.\nNell‚Äôambito dell‚Äôinferenza bayesiana, il condizionamento emerge come uno strumento essenziale. L‚Äôinferenza bayesiana √® un approccio statistico che sfrutta proprio il condizionamento per rivedere e aggiornare le credenze o le incertezze relative a determinate ipotesi, basandosi sull‚Äôintroduzione di nuove informazioni.\nIl processo inizia stabilendo una probabilit√† iniziale, denominata probabilit√† a priori (\\(P(A)\\)), che esprime la nostra convinzione o supposizione iniziale riguardo all‚Äôipotesi \\(A\\), prima di ricevere qualsiasi dato aggiuntivo. Questa probabilit√† a priori si fonda su conoscenze gi√† acquisite o su supposizioni precedentemente formulate.\nIl cuore dell‚Äôinferenza bayesiana si trova nell‚Äôaggiornamento di questa credenza iniziale in risposta all‚Äôacquisizione di nuove informazioni, rappresentate dalla variabile \\(E\\). L‚Äôaggiornamento avviene mediante il condizionamento, culminando nella determinazione di una probabilit√† a posteriori (\\(P(A | E)\\)). Questa nuova probabilit√† rappresenta la nostra credenza aggiornata sull‚Äôipotesi \\(A\\) dopo aver preso in esame l‚Äôevidenza \\(E\\) appena acquisita. In questo modo, l‚Äôinferenza bayesiana permette di affinare le nostre supposizioni e le nostre previsioni su determinati fenomeni, incorporando sistematicamente nuove prove nel nostro quadro di conoscenza.\nLa formula di Bayes governa questo processo di aggiornamento:\n\\[\nP(A | E) = \\frac{P(E | A) \\times P(A)}{P(E)}\n\\]\nIn questa formula, troviamo:\n\n\\(P(A | E)\\): la probabilit√† a posteriori, che √® la probabilit√† dell‚Äôipotesi \\(A\\) date le nuove prove \\(E\\).\n\\(P(E | A)\\): la verosimiglianza, ovvero la probabilit√† di osservare le prove \\(E\\) se l‚Äôipotesi \\(A\\) fosse vera.\n\\(P(A)\\): la probabilit√† a priori, che indica il nostro livello di convinzione iniziale nell‚Äôipotesi \\(A\\).\n\\(P(E)\\): la probabilit√† di osservare le prove \\(E\\), tenendo conto di tutte le ipotesi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/02_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "23¬† Probabilit√† condizionata",
    "section": "23.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "23.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Feb 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas: 2.2.0\nnumpy : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html",
    "href": "chapters/chapter_3/03_bayes_theorem.html",
    "title": "24¬† Il teorema di Bayes",
    "section": "",
    "text": "Introduzione\nChivers (2024) pone una domanda retorica: √® possibile prevedere il futuro? La risposta √® s√¨, in un certo senso.\nAlcuni eventi possono essere previsti con notevole accuratezza, come il nostro prossimo respiro, il battito cardiaco o il sorgere del sole il giorno seguente. Possiamo anche fare previsioni meno certe, come l‚Äôarrivo di un treno o l‚Äôarrivo di un amico a un appuntamento.\nTuttavia, tutte queste previsioni rimangono incerte. Anche se l‚Äôuniverso fosse deterministico, la nostra conoscenza non √® perfetta: non conosciamo ogni singola particella che lo compone. Le nostre informazioni sono parziali e imperfette, ottenute attraverso i nostri sensi limitati. Basandoci su ci√≤ che sappiamo, facciamo previsioni approssimative: ad esempio, sappiamo che gli esseri umani cercano cibo e compagnia, mentre le rocce tendono a rimanere immobili.\nLa vita non √® come una partita a scacchi, un gioco con informazioni perfette che pu√≤ essere ‚Äúrisolto‚Äù. √à pi√π simile al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione.\nQuesto capitolo, come il libro di Chivers (2024), tratta dell‚Äôequazione che ci consente di fare proprio questo: il teorema di Bayes.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#storia",
    "href": "chapters/chapter_3/03_bayes_theorem.html#storia",
    "title": "24¬† Il teorema di Bayes",
    "section": "25.1 Storia",
    "text": "25.1 Storia\nIl teorema di Bayes, cos√¨ denominato in onore del Reverendo Thomas Bayes, rappresenta uno dei concetti fondamentali nel campo della statistica e del calcolo delle probabilit√†.\nBayes was an eighteenth-century Presbyterian minister and a hobbyist mathematician. In his lifetime, he wrote a book about theology and another about Newton‚Äôs calculus. But what he is remembered for is his short work, ‚ÄúAn Essay towards Solving a Problem in the Doctrine of Chances.‚Äù It was published posthumously, in the journal Philosophical Transactions nel 1763, after his friend Richard Price found and edited some unfinished notes Bayes left behind.\nBellhouse, who wrote a biography of Bayes, state that the Bayes were a wealthy family. Thomas went in Edinburgh to study divinity and prepare for his life as a minister. Bayes‚Äôs first publication was a work of theology, ‚ÄúDivine benevolence: Or, an attempt to prove that the principal end of the divine providence and government is the happiness of his creatures: being an answer to a Pamphlet, entitled, Divine rectitude; or, An Inquiry concerning the Moral Perfections of the Deity. With a refutation of the notions therein advanced concerning beauty and order, the Reason of Punishment, and the Necessity of a State of Trial antecedent to perfect Happiness‚Äù, published in 1731. Thomas Bayes lived in a high-society world. His peers tended to be university-educated, often with doctorates of divinity, and many of them were members of the nobility. Thomas was an enthusiastic amateur mathematician.\nBellhouse, un suo biografo, ha scritto: ‚ÄúHe didn‚Äôt seem like a modern academic. He was more of an amateur, a virtuoso. He did it for his own pleasure rather than having a research agenda.‚Äù Bayes, clever man of considerable leisure and undemanding jobs, made hobbies of mathematics ‚ÄúWhat the rich did in the eighteenth century was to get involved in science,‚Äù Bellhouse says. ‚ÄúIt‚Äôs similar to rich people nowadays getting involved in sports teams‚Äù (ma forse oggi sono pi√π i social media).\nUn‚Äôaltra pubblicazione di Bayes √® stata ‚ÄúAn Introduction to the Doctrine of Fluxions‚Äù. Fluxions was a defense of Newton‚Äôs calculus against an attack by the philosopher George Berkeley. Bayes was a committed supporter of Newton. After that, Bayes did some work on infinite series and their relationship to derivatives. It was around this time that Bayes grew interested in probability theory.\nL‚Äôaspetto cruciale √® che il contributo maggiore di Bayes to probability theory was not mathematical, but philosophical. Secondo David Spiegelhalter, the former president of the Royal Statistical Society, for Bayes ‚Äú‚Äúprobability is an expression of our lack of knowledge about the world.‚Äù That is, for Bayes, probability is subjective. It‚Äôs a statement about our ignorance and our best guesses of the truth. It‚Äôs not a property of the world around us, but of our understanding of the world.\nWhat Bayes showed in his paper ‚ÄúAn Essay towards Solving a Problem in the Doctrine of Chances‚Äù was that in order to make inferential probability work‚Äîwhich means asking, ‚ÄúWhat are the chances that my hypothesis is true, given the data?‚Äù rather than ‚ÄúWhat are the chances that I would see this data, given my hypothesis?‚Äù‚Äîyou must take into account how likely you thought the hypothesis was in the first place. You must take your subjective beliefs into account.\nTo make his point, Bayes used a metaphor of a table, upon which balls are rolled. ‚ÄúThe table is hidden from your view, and a white ball is rolled on it in such a way that its final position is entirely random. When the white ball comes to a rest, it is removed, and a line is drawn across the table where it was. You are not told where the line is. Then a number of red balls are also rolled onto the table. All you are told is how many of the balls lie to the left of the line, and how many to the right. You have to estimate where the line is.\nBayes said that you must take into account the prior probability‚Äîyour best guess of what the situation was, before you got any information. The Bayes theorem produces the posterior probability distribution‚Äîwhat your assessment of the likely position of the line looks like now that your prior has been updated with the new information. And, crucially, it‚Äôs all subjective. With different priors we get different posteriors.\n‚ÄúAn Essay towards Solving a Problem in the Doctrine of Chances‚Äù appears to have sunk almost without trace‚Äîit was published after Bayes‚Äôs death, but was apparently unknown to Pierre-Simon Laplace, the French mathematician who independently arrived at similar conclusions in 1774. Pi√π dettagliatamente nella sua opera ‚ÄúTh√©orie analytique des probabilit√©s‚Äù del 1812, Laplace esplor√≤ l‚Äôuso della probabilit√† condizionale per aggiornare le conoscenze precedenti (probabilit√† a priori) sulla base di nuove evidenze (probabilit√† a posteriori). Sebbene Laplace abbia sviluppato questi principi senza conoscere il lavoro di Bayes, i suoi contributi hanno notevolmente esteso l‚Äôapplicazione e l‚Äôinterpretazione delle statistiche bayesiane.\nIl teorema di Bayes, nella sua essenza, fornisce un meccanismo matematico per aggiornare le probabilit√† iniziali di un‚Äôipotesi in base all‚Äôosservazione di nuove evidenze. Questo processo di revisione continua della probabilit√† si basa sulla combinazione di conoscenze preesistenti (il prior) con informazioni appena acquisite (la verosimiglianza), per produrre una nuova comprensione (il posterior). Tale meccanismo riflette un approccio olistico alla conoscenza, che considera la comprensione come un processo dinamico, iterativo, mai concluso e sempre in progress.\nNel contesto contemporaneo, l‚Äôimportanza e l‚Äôapplicabilit√† del teorema di Bayes vanno ben oltre la teoria della probabilit√† e la statistica, influenzando non soltanto tutti i campi della scienza ma anche il protagonista indiscusso del nostro panorama culturale contemporaneo: l‚Äôintelligenza artificiale. ChatGPT, Claude, Gemini ecc., tutti i Large Language Models, sono dei metodi per fare delle previsioni su quale sia il pi√π verosimile ‚Äúnext token‚Äù in una sequenza di simboli. Facendo delle previsioni, questi modelli usano il teorema di Bayes, che appunto integra le evidenze con le conoscenze precedenti, e fornisce il metodo pi√π razionale per l‚Äôaggiornamento delle conoscenze, ovvero per la previsione. In modo emblematico, potremmo affermare che rilevanza universale del teorema di Bayes nella comprensione dei fenomeni e nella previsione degli eventi √® enfatizzata nel titolo del libro di Chivers (2024): ‚ÄúEverything is predictable: how bayesian statistics explain our world‚Äù.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#teorema",
    "href": "chapters/chapter_3/03_bayes_theorem.html#teorema",
    "title": "24¬† Il teorema di Bayes",
    "section": "25.1 Teorema",
    "text": "25.1 Teorema\nConsideriamo una situazione in cui lo spazio degli eventi possibili, \\(\\Omega\\), √® diviso in due eventi distinti e mutualmente esclusivi, denominati ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo di avere gi√† una certa comprensione di questi eventi, espressa attraverso le loro probabilit√† a priori \\(P(H_1)\\) e \\(P(H_2)\\). A questo punto, introduciamo un nuovo evento \\(E\\), la cui occorrenza √® accompagnata da una probabilit√† non nulla e per il quale conosciamo le probabilit√† condizionate \\(P(E \\mid H_1)\\) e \\(P(E \\mid H_2)\\), che indicano quanto sia probabile osservare \\(E\\) assumendo che una delle due ipotesi sia vera. Se \\(E\\) si verifica, siamo interessati a determinare le probabilit√† a posteriori \\(P(H_1 \\mid E)\\) e \\(P(H_2 \\mid E)\\) delle nostre ipotesi alla luce di questa nuova evidenza.\nLa seguente illustrazione rappresenta come lo spazio totale degli eventi si suddivide tra le ipotesi \\(H_1\\) e \\(H_2\\), con l‚Äôevidenza \\(E\\) posizionata all‚Äôinterno di questo contesto.\n\n\n\n\n\n\nFigura¬†25.1: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nPer calcolare la probabilit√† a posteriori dell‚Äôipotesi 1 data l‚Äôosservazione di \\(E\\), utilizziamo la formula:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\cap H_1)}{P(E)}.\n\\]\nQuesto calcolo pu√≤ essere semplificato sfruttando la definizione di probabilit√† condizionata, che ci permette di sostituire \\(P(E \\cap H_1)\\) con \\(P(E \\mid H_1)P(H_1)\\). Applicando questa sostituzione, otteniamo:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n\\]\nDato che \\(H_1\\) e \\(H_2\\) si escludono a vicenda, la probabilit√† totale di \\(E\\) pu√≤ essere espressa come la somma delle probabilit√† di \\(E\\) occorrente in concomitanza con ciascuna ipotesi, utilizzando il teorema della probabilit√† totale:\n\\[\nP(E) = P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n\\]\nIncorporando questi valori nella formula di Bayes, giungiamo a:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n\\tag{25.1}\\]\nQuesta espressione costituisce l‚Äôessenza della formula di Bayes per il caso semplificato in cui le ipotesi si limitano a due eventi mutualmente esclusivi, \\(H_1\\) e \\(H_2\\).\nNel quadro delle probabilit√† discrete, questa formula pu√≤ essere generalizzata per accogliere un insieme pi√π ampio di ipotesi che formano una partizione completa dello spazio degli eventi \\(\\Omega\\), dove ogni \\(E\\) rappresenta un evento con probabilit√† maggiore di zero. Per ogni ipotesi \\(H_i\\) all‚Äôinterno di un insieme numerabile, la formula di Bayes si estende come segue:\n\\[\nP(H_i \\mid E) = \\frac{P(E \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(E \\mid H_j)P(H_j)}.\n\\tag{25.2}\\]\nQui, il denominatore agisce come un fattore di normalizzazione che integra i prodotti delle probabilit√† a priori e delle verosimiglianze associate a ogni ipotesi considerata.\nPer variabili continue, la formula di Bayes assume una forma integrale, adattandosi a situazioni in cui le ipotesi \\(H_i\\) rappresentano valori in un continuum. In questo contesto, la formula diventa:\n\\[\nP(H_i \\mid E) = \\frac{P(E \\mid H_i) \\cdot P(H_i)}{\\int P(E \\mid H) \\cdot P(H) \\, dH},\n\\tag{25.3}\\]\noffrendo un framework potente per aggiornare le probabilit√† a posteriori di ipotesi continue basate su nuove evidenze, sottolineando l‚Äôimportanza della formula di Bayes non solo come strumento matematico, ma anche come filosofia di apprendimento continuo e adattamento alle nuove informazioni.\n\n25.1.1 Interpretazione della Formula di Bayes\nLa formula di Bayes si articola in tre elementi fondamentali che ne facilitano la comprensione e l‚Äôapplicazione in diversi campi di studio:\n\nProbabilit√† a Priori, \\(P(H)\\): Questa componente riflette la nostra valutazione preliminare riguardo la verosimiglianza dell‚Äôipotesi \\(H\\) prima di prendere in esame nuove evidenze \\(E\\). Essa incarna il livello di credibilit√† o fiducia attribuita all‚Äôipotesi, basandosi su conoscenze preesistenti o su deduzioni logiche. In sostanza, la probabilit√† a priori quantifica le nostre convinzioni pregresse o le aspettative iniziali su quanto sia probabile che l‚Äôipotesi sia vera.\nProbabilit√† a Posteriori, \\(P(H \\mid E)\\): Questo valore aggiorna la nostra fiducia nell‚Äôipotesi \\(H\\) in seguito all‚Äôosservazione dell‚Äôevidenza \\(E\\). In termini pi√π intuitivi, rappresenta il livello di convinzione ricalibrato in \\(H\\) dopo aver considerato l‚Äôevidenza. La formula di Bayes ci offre un meccanismo matematicamente rigoroso per modulare questa probabilit√† alla luce delle nuove informazioni ricevute.\nVerosimiglianza, \\(P(E \\mid H)\\): La verosimiglianza esprime la probabilit√† di rilevare l‚Äôevidenza \\(E\\) dato che l‚Äôipotesi \\(H\\) sia vera. √à un indice di quanto l‚Äôevidenza supporti o confermi l‚Äôipotesi. Un valore elevato di verosimiglianza indica che l‚Äôevidenza √® fortemente in linea o prevista dalla veridicit√† dell‚Äôipotesi.\n\nGrazie alla formula di Bayes, possiamo adottare un processo di aggiornamento continuo delle nostre credenze in base a nuove informazioni, promuovendo un metodo dinamico per navigare tra conoscenza e incertezza. Questa metodologia ci fornisce un approccio strutturato per rivedere e adattare le nostre convinzioni riguardo l‚Äôipotesi \\(H\\) di fronte a nuovi dati o evidenze \\(E\\). La capacit√† di rielaborare costantemente le nostre aspettative in funzione di informazioni aggiuntive si rivela essenziale in una vasta gamma di ambiti, inclusi l‚Äôintelligenza artificiale, la ricerca statistica, le discipline scientifiche e umanistiche. Tale prassi ci consente di prendere decisioni pi√π informate, di interpretare con maggiore precisione i dati disponibili e di affinare significativamente le nostre previsioni e comprensioni del mondo circostante.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#alcuni-esempi",
    "href": "chapters/chapter_3/03_bayes_theorem.html#alcuni-esempi",
    "title": "24¬† Il teorema di Bayes",
    "section": "25.2 Alcuni esempi",
    "text": "25.2 Alcuni esempi\n\nEsempio 25.1 Il modo pi√π comune per spiegare il teorema di Bayes √® attraverso i test medici. Prendiamo come esempio la mammografia e la diagnosi del cancro al seno.\nSupponiamo di avere un test di mammografia con una sensibilit√† del 90% e una specificit√† del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilit√† che il test lo rilevi correttamente √® del 90%.\nIn assenza di cancro al seno, la probabilit√† che il test confermi correttamente l‚Äôassenza della malattia √® del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch‚Äôesso del 10%.\nDefiniamo due ipotesi:\n\n\\(M^+\\): presenza della malattia\n\\(M^-\\): assenza della malattia\n\nL‚Äôevidenza √® rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilit√† di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) √® la probabilit√† di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilit√† del test, ovvero la probabilit√† che il test risulti positivo in presenza effettiva del cancro. In questo caso, √® pari a 0.90.\n\\(P(M^+)\\) √® la probabilit√† a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\\(P(T^+ \\mid M^-)\\) indica la probabilit√† di un falso positivo, cio√® la probabilit√† che il test risulti positivo in assenza di cancro. Con una specificit√† del 90%, questa probabilit√† si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificit√†} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c‚Äô√® una probabilit√† del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\\(P(M^-)\\) √® la probabilit√† a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilit√† effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilit√† e specificit√† del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nQuesto calcolo dimostra che, considerando una mammografia con risultato positivo ottenuto tramite un test con una sensibilit√† del 90% e una specificit√† del 90%, la probabilit√† che il paziente sia effettivamente affetto da cancro al seno √® solo dell‚Äô8.3%.\n\n\n25.2.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicit√†, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ci√≤ che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi √® fondamentale per questo calcolo: la prevalenza della malattia, la sensibilit√† e la specificit√† del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilit√†: Indica la capacit√† del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilit√† (\\(Sens\\)) √® la seguente:\n\\[ \\text{Sensibilit√†} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilit√† misura la probabilit√† che il test risulti positivo se la malattia √® effettivamente presente.\nSpecificit√†: Misura la capacit√† del test di riconoscere gli individui sani, producendo un risultato negativo per chi non √® affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificit√† (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificit√†} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Cos√¨, la specificit√† rappresenta la probabilit√† che il test risulti negativo in assenza della malattia.\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilit√†)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilit√†)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificit√†)\n\\(P(T^- \\cap M^-)\\)  (Specificit√†)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilit√† totale di avere la malattia (\\(P(M^+)\\)) e la probabilit√† totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilit√† totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilit√† totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilit√†, che per definizione √® 1, rappresentando l‚Äôintera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilit√† post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cio√® la probabilit√† post-test che un individuo sia malato dato un risultato positivo del test, √® calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che √® la probabilit√† che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilit√†}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 25.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in Python e usiamo gli stessi dati dell‚Äôesercizio precedente.\n\ndef positive_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n\n\ndef negative_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilit√†\nspec = 0.9  # specificit√†\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo √®:\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.083\n\n\nIl valore predittivo del test negativo √®:\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\n\n\nEsempio 25.3 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test pu√≤ essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L‚ÄôIstituto Superiore di Sanit√†, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilit√† varia tra il 70% e l‚Äô86%, mentre la specificit√† si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus √® stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n\n0.002349135593220339\n\n\nL‚Äôobiettivo √® determinare la probabilit√† di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2 # specificit√†\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.044\n\n\nPertanto, se il risultato del tampone √® positivo, la probabilit√† di essere effettivamente affetti da Covid-19 √® solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cio√®, pari al 23.5%), la probabilit√† di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l‚Äô86%.\n\nprev = 138599 / 59000000 * 100\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.857\n\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilit√† di non essere infetto sarebbe del 99.9%.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2  # specificit√†\nprev = 138599 / 59000000  # prevalenza\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\nTuttavia, un‚Äôesito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia √® molto bassa; in altre parole, il risultato negativo conferma una situazione gi√† presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell‚Äôasserire l‚Äôassenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 25.4 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell‚Äôinterpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un‚Äôaccuratezza del 99%, la sua affidabilit√† varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\nSensibilit√†:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\nSpecificit√†: circa 99.9% per tutte le condizioni citate\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\nNonostante l‚Äôalta sensibilit√† e specificit√†, il VPP pu√≤ essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni pi√π rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilit√† che un risultato positivo sia effettivamente corretto dipende non solo dall‚Äôaccuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta pi√π affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT √® uno strumento prezioso per lo screening prenatale, √® fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.\n\n\nEsempio 25.5 Il teorema di Bayes non √® rilevante solo in medicina. In ambito legale √® presente un fenomeno noto come la Fallacia del Procuratore. La ‚Äúfallacia del procuratore‚Äù √® un errore logico che si verifica quando si confonde la probabilit√† di un evento dato un certo risultato con la probabilit√† di quel risultato dato l‚Äôevento. In ambito legale, si tratta spesso di confondere la probabilit√† di ottenere un risultato di un test (ad esempio, una corrispondenza del DNA) se una persona √® innocente, con la probabilit√† che una persona sia innocente dato che il test ha mostrato una corrispondenza.\nSupponiamo di avere i seguenti parametri per un test del DNA:\n\nSensibilit√†: 99% (probabilit√† di identificare correttamente il colpevole).\nSpecificit√†: 99.99997% (probabilit√† di identificare correttamente un innocente).\nPrevalenza: 1 su 65 milioni (probabilit√† a priori che una persona qualsiasi sia il colpevole, data una popolazione di 65 milioni).\n\nImmaginiamo che ci sia stato un crimine e che un campione di DNA sia stato trovato sulla scena del crimine. Il campione √® confrontato con il DNA di una persona nel database.\nSvolgiamo i calcoli:\n\nProbabilit√† a Priori (Prevalenza):\n\nLa prevalenza \\(P(C)\\) che una persona casuale sia il colpevole √® \\(\\frac{1}{65.000.000}\\).\n\nSensibilit√† e Specificit√†:\n\nSensibilit√† \\(P(T+|C) = 0.99\\).\nSpecificit√† \\(P(T-|I) = 0.9999997\\).\n\nProbabilit√† del Test Positivo:\n\nProbabilit√† di ottenere un test positivo \\(P(T+)\\) √® la somma della probabilit√† di ottenere un positivo dai veri colpevoli e dai falsi positivi:\n\n\n\\[ P(T+) = P(T+|C) \\cdot P(C) + P(T+|I) \\cdot P(I), \\]\n\ndove \\(P(T+|I)\\) √® \\(1 - \\text{Specificit√†}\\) e \\(P(I)\\) √® la probabilit√† di essere innocente (\\(1 - P(C)\\)).\n\n\\[ P(T+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000} \\]\n\\[ P(T+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999 \\]\n\\[ P(T+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7} \\]\n\\[ P(T+) \\approx 3.1523 \\times 10^{-7} \\]\n\nProbabilit√† Condizionale che il Sospetto sia Colpevole Dato un Test Positivo:\n\nUtilizzando il teorema di Bayes:\n\n\n\\[ P(C|T+) = \\frac{P(T+|C) \\cdot P(C)}{P(T+)} \\]\n\\[ P(C|T+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) = \\frac{0.99 \\times 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) \\approx 0.0483 \\]\nQuindi, la probabilit√† che il sospetto sia effettivamente il colpevole, dato che il test del DNA √® positivo, √® circa 4.83%, nonostante l‚Äôalta specificit√† del test.\nIn sintesi, quando si afferma che c‚Äô√® solo una probabilit√† su 3 milioni che il sospetto sia innocente (ovvero la specificit√†), si commette la fallacia del procuratore. In realt√†, la probabilit√† che il sospetto sia colpevole, data una corrispondenza del DNA, √® molto inferiore, come dimostrato nell‚Äôesempio numerico (circa 4.83%).\nQuesta fallacia pu√≤ portare a errori giudiziari perch√© non si considera la bassa prevalenza del colpevole nella popolazione generale e si confonde la specificit√† del test con la probabilit√† condizionale di colpevolezza. In altre parole, non si riconosce che le due domande ‚ÄòQuanto √® probabile che il DNA di una persona corrisponda al campione, se √® innocente?‚Äô e ‚ÄòQuanto √® probabile che qualcuno sia innocente, dato che il suo DNA corrisponde al campione?‚Äô non sono equivalenti. √à come confondere ‚ÄòQuanto √® probabile che un determinato essere umano sia il papa?‚Äô con ‚ÄòQuanto √® probabile che il papa sia un essere umano?‚Äô.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/03_bayes_theorem.html#commenti-e-considerazioni-finali",
    "title": "24¬† Il teorema di Bayes",
    "section": "25.4 Commenti e Considerazioni Finali",
    "text": "25.4 Commenti e Considerazioni Finali\nIn questo capitolo abbiamo esaminato una serie di esempi in campo medico e forense, dimostrando come il teorema di Bayes permetta di combinare le informazioni fornite dalle osservazioni con le nostre conoscenze precedenti (prior), per produrre una conoscenza a posteriori. Il teorema di Bayes offre un meccanismo razionale‚Äînoto come ‚Äúaggiornamento bayesiano‚Äù‚Äîper ricalibrare le nostre convinzioni iniziali in risposta a nuove informazioni o evidenze.\nSoprattutto, il teorema di Bayes ci fa comprendere che nella ricerca scientifica, cos√¨ come nella vita quotidiana, non siamo tanto interessati a conoscere la probabilit√† che qualcosa accada assumendo vera un‚Äôipotesi. Siamo invece interessati alla domanda opposta: qual √® la probabilit√† che un‚Äôipotesi sia vera, dato che abbiamo osservato una certa evidenza?\nNel contesto di questo capitolo, abbiamo focalizzato la nostra discussione sul teorema di Bayes utilizzando probabilit√† puntuali. Tuttavia, vedremo successivamente che il teorema di Bayes esprime pienamente il suo potenziale esplicativo quando l‚Äôevidenza e le conoscenze a priori sono rappresentate in termini di grado di certezza, cio√® attraverso distribuzioni di probabilit√† continue.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/03_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "24¬† Il teorema di Bayes",
    "section": "25.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "25.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\narviz     : 0.17.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html",
    "href": "chapters/chapter_3/04a_random_var.html",
    "title": "25¬† Variabili casuali",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, introdurremo il concetto di variabili casuali e delle loro distribuzioni di probabilit√†, ampliando ulteriormente l‚Äôambito delle analisi matematiche degli eventi considerati finora. Le variabili casuali possono essere discrete o continue, a seconda dei valori che possono assumere. Iniziamo con una definizione.\nLe variabili casuali si dividono in due categorie principali:\nQuesto processo di assegnazione di numeri a stati semplifica notevolmente l‚Äôanalisi dei dati, permettendoci di applicare concetti matematici e statistici agli eventi del mondo reale. In generale, le variabili casuali vengono utilizzate principalmente in due modi:\nIn sintesi, le variabili casuali ci permettono di modellare e analizzare matematicamente la complessit√† e l‚Äôincertezza del mondo reale, fornendo un ponte tra le osservazioni empiriche e la teoria statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#introduzione",
    "href": "chapters/chapter_3/04a_random_var.html#introduzione",
    "title": "25¬† Variabili casuali",
    "section": "",
    "text": "Definizione 25.1 Una variabile casuale reale √® una funzione che associa gli esiti possibili di un esperimento (lo spazio campionario \\(\\Omega\\)) a valori numerici reali. Matematicamente, si descrive come \\(X : \\Omega \\rightarrow \\mathbb{R}\\), dove \\(X\\) √® la variabile casuale e \\(\\mathbb{R}\\) rappresenta l‚Äôinsieme dei numeri reali.\n\n\n\nDiscrete: Queste variabili possono assumere solo un numero limitato di valori distinti e contabili. Un esempio √® il numero di libri letti in un mese.\nContinue: Queste variabili possono assumere qualsiasi valore in un intervallo. Un esempio √® la temperatura di un giorno, che pu√≤ variare continuamente e assumere un numero infinito di valori all‚Äôinterno di un dato range.\n\n\nEsempio 25.1 Consideriamo l‚Äôesperimento casuale del lancio di una moneta. Ogni volta che lanciamo la moneta, otteniamo un risultato specifico: testa o croce. Questi risultati sono gli esiti reali che possiamo osservare. In matematica e statistica, ci interessa analizzare tutti i possibili risultati in modo strutturato. Le variabili casuali ci permettono di trasformare questi esiti in valori numerici utilizzabili nei calcoli; per esempio, possiamo assegnare il numero 1 a testa e il numero 0 a croce.\n\n\nEsempio 25.2 Un altro esempio √® la variabile casuale \\(Y\\) che rappresenta il risultato di un lancio di dado. Se definiamo \\(Y = 1\\) per indicare che il risultato del lancio √® un numero dispari (1, 3 o 5) e \\(Y = 0\\) per indicare che il risultato del lancio √® un numero pari (2, 4 o 6), abbiamo trasformato un‚Äôosservazione fisica (il lancio del dado) in un valore numerico che rappresenta un certo tipo di evento.\n\n\n\nModellazione delle conoscenze (osservazioni): Le variabili casuali aiutano a quantificare e strutturare le informazioni raccolte da esperimenti o studi.\nModellazione delle incognite (variabili latenti, parametri, predizioni): Le variabili casuali rappresentano ci√≤ che non sappiamo o che vogliamo prevedere, come i parametri nascosti di un modello o i futuri esiti di un esperimento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#convenzioni-notazionali",
    "href": "chapters/chapter_3/04a_random_var.html#convenzioni-notazionali",
    "title": "25¬† Variabili casuali",
    "section": "25.1 Convenzioni Notazionali",
    "text": "25.1 Convenzioni Notazionali\nNella teoria della probabilit√†, √® usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come ‚ÄòX‚Äô, per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D‚Äôaltro canto, la corrispondente lettera minuscola, ‚Äòx‚Äô nel nostro esempio, √® impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale pu√≤ assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (X) o di un suo specifico valore (x).\nUlteriori convenzioni di notazione includono:\n\n‚ÄòX‚Äô √® spesso usata per rappresentare variabili casuali non osservate, come parametri sconosciuti o variabili latenti di un modello.\n‚ÄòY‚Äô, al contrario, √® generalmente riservata a variabili casuali osservate, ovvero dati che sono stati effettivamente raccolti o misurati in un esperimento",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#variabili-casuali-multiple",
    "href": "chapters/chapter_3/04a_random_var.html#variabili-casuali-multiple",
    "title": "25¬† Variabili casuali",
    "section": "25.2 Variabili casuali multiple",
    "text": "25.2 Variabili casuali multiple\nNella teoria della probabilit√†, le variabili casuali spesso non operano in isolamento ma in contesti dove interagiscono o si combinano tra loro. Per esemplificare, immaginiamo di avere una moneta perfettamente bilanciata e di decidere di lanciarla tre volte. Ogni lancio di questa moneta pu√≤ essere descritto da una variabile casuale separata: \\(Y_1\\), \\(Y_2\\), e \\(Y_3\\). Queste variabili rappresentano i risultati dei lanci individuali, e ogni lancio √® considerato indipendente dagli altri. Ci√≤ significa che l‚Äôesito di un lancio non influisce sugli esiti degli altri. Poich√© la moneta √® bilanciata, la probabilit√† di ottenere testa (che possiamo rappresentare come 1) o croce (rappresentata come 0) in ogni lancio √® del 50%, dunque abbiamo \\(P(Y_n = 1) = 0.5\\) e \\(P(Y_n = 0) = 0.5\\), per \\(n\\) uguale a 1, 2 o 3.\nQuando combiniamo variabili casuali attraverso operazioni aritmetiche, possiamo creare nuove variabili che offrono ulteriori insight. Prendiamo, per esempio, i tre lanci della moneta bilanciata menzionati prima. Se definiamo \\(Y_1\\), \\(Y_2\\), e \\(Y_3\\) come i risultati di questi lanci, possiamo introdurre una nuova variabile casuale \\(Z\\) che rappresenta la somma dei risultati:\n\\[\nZ = Y_1 + Y_2 + Y_3.\n\\]\nLa variabile \\(Z\\) √® un esempio di variabile casuale discreta, il che significa che pu√≤ assumere solo valori interi specifici. A differenza delle variabili continue che possono assumere qualsiasi valore in un intervallo, \\(Z\\) pu√≤ solo risultare in una serie limitata di numeri interi, che nel contesto dei nostri lanci di moneta sono i possibili totali di testa ottenuti nei tre tentativi. La notazione \\(\\mathbb{Z}\\) qui √® un po‚Äô fuorviante poich√© sembra riferirsi all‚Äôinsieme di tutti i numeri interi, ma nel contesto specifico di \\(Z\\) come somma dei risultati di tre lanci di moneta, i valori possibili di \\(Z\\) vanno da 0 (nessun testa in tre lanci) a 3 (testa in tutti e tre i lanci), rendendo \\(Z\\) una variabile che riflette il numero totale di testa ottenuti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#sec-fun-mass-prob",
    "href": "chapters/chapter_3/04a_random_var.html#sec-fun-mass-prob",
    "title": "25¬† Variabili casuali",
    "section": "25.3 Distribuzione di Probabilit√†",
    "text": "25.3 Distribuzione di Probabilit√†\nIl concetto di distribuzione di probabilit√† √® fondamentale per analizzare come le probabilit√† si distribuiscono tra i vari esiti possibili di una variabile casuale. Questo concetto varia a seconda che stiamo considerando variabili casuali discrete o continue.\n\n25.3.1 Variabili Casuali Discrete\nPer le variabili casuali discrete, che assumono valori specifici e contabili (come il lancio di un dado), la distribuzione di probabilit√† √® rappresentata dalla cosiddetta funzione di massa di probabilit√†, spesso abbreviata come \\(P(\\cdot)\\). Questa funzione attribuisce una probabilit√† precisa a ciascun esito possibile della variabile.\nMentre nel Capitolo 21 abbiamo discusso la distribuzione di probabilit√† in relazione agli eventi di uno spazio campionario, nel caso delle variabili casuali discrete l‚Äôintera probabilit√† (pari a 1) viene distribuita tra i valori numerici che la variabile casuale discreta pu√≤ assumere.\nPrendendo come esempio il lancio di un dado equilibrato, se ci concentriamo sul risultato ‚Äú1‚Äù, la funzione di massa di probabilit√† potrebbe essere espressa come \\(P(Y = 1) = \\frac{1}{6}\\). Questo indica che, in una serie di lanci indipendenti, il risultato ‚Äú1‚Äù si verificherebbe circa una volta su sei.\n\n25.3.1.1 Istogrammi\nLa visualizzazione dell‚Äôallocazione delle probabilit√† tra i valori di una variabile casuale discreta viene realizzata mediante un istogramma. Gli istogrammi sono estremamente utili per comunicare rapidamente alcune delle caratteristiche chiave di una distribuzione di probabilit√†. Ad esempio, gli istogrammi ci permettono di differenziare tra allocazioni che si concentrano attorno a un punto, chiamate misure unimodali, o allocazioni che si concentrano attorno a pi√π punti, chiamate misure multimodali. Allo stesso tempo, possiamo vedere come una misura si concentra attorno a un punto, ad esempio se la concentrazione √® simmetrica o asimmetrica verso valori pi√π piccoli o pi√π grandi.\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n¬†\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n¬†\n\n\n\n\nFigura¬†25.1: Gli istogrammi sono estremamente efficaci nel comunicare le caratteristiche di base di una misura. La misura in (a) √® diffusa ma decrescente, allocando pi√π probabilit√† ai punti pi√π piccoli rispetto ai punti pi√π grandi. Al contrario, la misura in (b) si concentra attorno a un singolo punto mentre la misura in (c) si concentra attorno a pi√π punti distinti. Infine, la misura in (d) si concentra attorno a un singolo punto, ma quella concentrazione √® fortemente asimmetrica, a differenza della concentrazione in (b).\n\n\n\nPer le variabili casuali discrete possiamo sempre regolare i bin di un istogramma in modo che ciascun bin copra un singolo valore della variabile casuale. In questo caso, l‚Äôaltezza di ciascun bin corrisponde a \\(\\mu(\\{ x \\})\\) e l‚Äôistogramma risultante √® una rappresentazione visiva della funzione di massa di probabilit√†.\n\n\n\n25.3.2 Variabili Casuali Continue\nNel caso delle variabili casuali continue, che possono assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo, si utilizza la funzione di densit√† di probabilit√†, indicata con \\(p(\\cdot)\\). Questa funzione non assegna probabilit√† a valori puntuali (poich√© la probabilit√† di un singolo valore esatto √® zero), ma determina la probabilit√† che la variabile si collochi entro un certo intervallo di valori.\nAnche per una variabile casuale continua possiamo rappresentare visivamente la distribuzione di probabilit√† con un istogramma. In questo caso, per√≤, i bin dell‚Äôistogramma devono sempre contenere intervalli di valori della variabile casuale. Un istogramma con bin pi√π piccoli comunica maggiori dettagli sulla funzione di densit√† di probabilit√†. Se rendiamo i bin infinitamente piccoli, il profilo dell‚Äôistogramma tende a coincidere con la funzione di densit√† di probabilit√† della variabile casuale.\n\n\n\n\n\n\nFigura¬†25.2: Istogrammi di una variabile casuale continua con bin di dimensioni progressivamente ridotte. Al limite, il profilo dell‚Äôistogramma tende a diventare una linea continua.\n\n\n\n\n\n25.3.3 Supporto della Variabile Casuale\nIl concetto di supporto di una variabile casuale si riferisce all‚Äôinsieme di tutti i valori che la variabile pu√≤ effettivamente assumere. Per esempio, il supporto di un dado standard a sei facce √® l‚Äôinsieme \\(\\{1, 2, 3, 4, 5, 6\\}\\), mentre per una variabile casuale che segue una distribuzione continua, come quella gaussiana, il supporto potrebbe essere l‚Äôintero insieme dei numeri reali.\n\n\n25.3.4 Assegnazione di Probabilit√†\nPer le variabili casuali discrete, √® essenziale specificare la probabilit√† di ogni valore possibile per definire la loro distribuzione di probabilit√† in modo completo. Per le variabili continue, invece, ci affidiamo alla densit√† di probabilit√† per capire la probabilit√† che la variabile rientri in specifici intervalli di valori.\nIn conclusione, la distribuzione di probabilit√†, rappresentata attraverso la funzione di massa di probabilit√† per le variabili discrete o la densit√† di probabilit√† per quelle continue, √® cruciale per descrivere il modo in cui le probabilit√† si distribuiscono tra i diversi esiti possibili di una variabile casuale, offrendo una visione completa del suo comportamento.\n\nEsempio 25.3 Supponiamo che la variabile casuale discreta \\(X\\) per il tipo di sangue sia definita esplicitamente come segue:\n\\[\nX =\n\\begin{cases}\n1 & \\text{se la persona ha il tipo di sangue A} \\\\\n2 & \\text{se la persona ha il tipo di sangue B} \\\\\n3 & \\text{se la persona ha il tipo di sangue AB} \\\\\n4 & \\text{se la persona ha il tipo di sangue O}\n\\end{cases}\n\\]\nPertanto, \\(X\\) √® una variabile casuale discreta con quattro possibili esiti. Possiamo anche trovare la distribuzione di probabilit√† che descrive la probabilit√† dei diversi valori possibili della variabile casuale \\(X\\). Notiamo che gli assiomi e le propriet√† delle probabilit√† che abbiamo discusso in precedenza si applicano anche alle variabili casuali (ad esempio, la probabilit√† totale per tutti i valori possibili di una variabile casuale √® pari a uno).\nLe distribuzioni di probabilit√† sono spesso presentate utilizzando tabelle di probabilit√† o grafici. Ad esempio, supponiamo che le probabilit√† individuali per i diversi tipi di sangue in una popolazione siano \\(P(A) = 0.41\\), \\(P(B) = 0.10\\), \\(P(AB) = 0.04\\), e \\(P(O) = 0.45\\). Notiamo che:\n\\[ P(A) + P(B) + P(AB) + P(O) = 0.41 + 0.10 + 0.04 + 0.45 = 1. \\]\n\n\n\nTipo di sangue\nA\nB\nAB\nO\n\n\n\n\n\\(X\\)\n1\n2\n3\n4\n\n\n\\(P(X)\\)\n0.41\n0.10\n0.04\n0.45\n\n\n\nQui, \\(x\\) denota un valore specifico (cio√® 1, 2, 3 o 4) della variabile casuale \\(X\\). Quindi, invece di dire \\(P(A) = 0.41\\), cio√® il tipo di sangue √® A con probabilit√† 0.41, possiamo dire che \\(P(X = 1) = 0.41\\), cio√® \\(X\\) √® uguale a 1 con probabilit√† 0.41.\nPossiamo usare la distribuzione di probabilit√† per rispondere a domande di probabilit√†. Ad esempio, qual √® la probabilit√† che una persona selezionata a caso dalla popolazione possa donare sangue a qualcuno con tipo di sangue B?\nSappiamo che le persone con tipo di sangue B o O possono donare a una persona con tipo di sangue B.\nPertanto, dobbiamo trovare la probabilit√† \\(P(\\text{tipo di sangue B} \\cup \\text{tipo di sangue O})\\). Poich√© gli eventi tipo di sangue B e tipo di sangue O sono mutuamente esclusivi, possiamo usare la regola dell‚Äôaddizione per eventi mutuamente esclusivi per ottenere:\n\\[ P(\\text{B} \\cup \\text{O}) = P(B) + P(O) = 0.10 + 0.45 = 0.55 \\]\nQuindi, c‚Äô√® una probabilit√† del 55% che una persona selezionata a caso nella nostra popolazione possa donare sangue a qualcuno con tipo di sangue B.\n\n\nEsempio 25.4 Immaginiamo di lanciare due dadi equilibrati, ciascuno con sei facce. Definiamo una variabile casuale discreta \\(Z\\), che rappresenta la somma dei valori ottenuti in ciascun lancio dei dadi. Indichiamo con \\(D_1\\) il risultato del primo dado e con \\(D_2\\) quello del secondo dado, quindi \\(Z = D_1 + D_2\\).\nPer analizzare questa variabile casuale, dobbiamo prima costruire lo spazio campionario associato all‚Äôesperimento. Lo spazio campionario in questo caso √® l‚Äôinsieme di tutte le possibili combinazioni dei risultati dei due lanci di dado. Dato che ogni dado ha sei facce, ci sono in totale \\(6 \\times 6 = 36\\) possibili esiti.\nOgni esito pu√≤ essere rappresentato come una coppia ordinata (i, j), dove i e j sono i risultati dei dadi \\(D_1\\) e \\(D_2\\), rispettivamente. Quindi, lo spazio campionario pu√≤ essere descritto come \\({(1,1), (1,2), (1,3), \\dots, (6,4), (6,5), (6,6)}\\).\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nprint(sample)\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\n\nelements_per_row = 6\n\nfor i in range(0, len(sample), elements_per_row):\n    print(sample[i:i+elements_per_row])\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)]\n[(2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n[(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)]\n[(4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6)]\n[(5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6)]\n[(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLe sequenze come (1, 1), (1, 2), ecc. sono gli eventi elementari di questo esperimento casuale. Lo spazio campione di questo esperimento casuale √® costituito da 36 eventi elementari:\n\nlen(sample)\n\n36\n\n\nPer ogni possibile combinazione (i, j) risultante dal lancio dei due dadi, la variabile casuale \\(Z\\) assume un valore che corrisponde alla somma dei numeri i e j. Ad esempio, se i risultati dei dadi sono 3 e 4, allora \\(Z = 3 + 4 = 7\\). Pertanto, il valore di \\(Z\\) pu√≤ variare da un minimo di 2 (ottenuto dal lancio di due 1) fino a un massimo di 12 (ottenuto dal lancio di due 6), coprendo cos√¨ tutti i possibili risultati della somma dei due dadi. La distribuzione di \\(Z\\) ci offre una panoramica sulle probabilit√† associate a ogni possibile somma risultante.\n√à importante sottolineare che l‚Äôevento \\(Z = u\\), dove \\(u\\) √® un valore compreso tra 2 e 12, rappresenta un ‚Äúevento composto‚Äù. Ci√≤ significa che pu√≤ essere formato da pi√π di un ‚Äúevento elementare‚Äù. Ad esempio, l‚Äôevento \\(Z = 2\\) corrisponde esclusivamente all‚Äôevento elementare (1, 1), mentre l‚Äôevento \\(Z = 3\\) √® il risultato di due eventi elementari differenti: (1, 2) e (2, 1). La stessa logica si applica agli altri valori di \\(Z\\), dove il numero di eventi elementari che contribuiscono a un dato evento composto \\(Z = u\\) aumenta all‚Äôaumentare del valore di \\(u\\). Questa caratteristica della distribuzione di \\(Z\\) √® fondamentale per comprendere e calcolare le probabilit√† associate ai diversi totali possibili nella somma dei due dadi.\nNel nostro esempio costruito usando Python, ogni elemento della lista sample √® una lista di due elementi. Per trovare il valore della variabile casuale \\(Z\\), quindi, dobbiamo sommare i due elementi di ciascuna lista. Nel primo punto campione (1, 1), il valore di \\(Z\\) √® 2:\n\nsum(sample[0])\n\n2\n\n\nIn corrispondenza dell‚Äôultimo punto dello spazio campione (6, 6), il valore di \\(Z\\) √® 12:\n\nsum(sample[35])\n\n12\n\n\nCreiamo ora la lista z che memorizza il valore assunto dalla variabile casuale \\(Z\\) in corrispondenza di ciascun punto dello spazio campione:\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nz = [sum(point) for point in sample]\n\n# Arrange and print `z` in a format with 6 elements per row to reflect a 6x6 sample space\nelements_per_row = 6\nformatted_output = [z[i:i+elements_per_row] for i in range(0, len(z), elements_per_row)]\n\nformatted_output\n\n[[2, 3, 4, 5, 6, 7],\n [3, 4, 5, 6, 7, 8],\n [4, 5, 6, 7, 8, 9],\n [5, 6, 7, 8, 9, 10],\n [6, 7, 8, 9, 10, 11],\n [7, 8, 9, 10, 11, 12]]\n\n\nContiamo dunque quante volte si presenta ciascun possibile valore \\(Z\\) nello spazio campione.\n\n# Inizializzo un dizionario per memorizzare le frequenze di ciascun valore di Z\nfrequenze_z = {}\n\n# Calcolo le frequenze per ciascun valore di Z\nfor valore in z:\n    if valore in frequenze_z:\n        frequenze_z[valore] += 1\n    else:\n        frequenze_z[valore] = 1\n\nfrequenze_z\n\n{2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}\n\n\nI valori di probabilit√† per ciascun valore di \\(z\\) sono calcolati in base alla frequenza con cui quel particolare valore di \\(z\\) emerge all‚Äôinterno dell‚Äôintero insieme dei risultati. In altre parole, per ogni valore \\(z\\), la probabilit√† corrispondente √® determinata dalla proporzione di occorrenze di quel valore \\(z\\) nell‚Äôelenco dei risultati prodotti dall‚Äôesperimento casuale. Questo elenco rappresenta tutti i possibili valori che la variabile casuale \\(Z\\) pu√≤ assumere, calcolati per ogni combinazione di punti nello spazio campionario dell‚Äôesperimento.\nCostruiamo ora la distribuzione di massa di probabilit√† per la variabile casuale \\(Z\\). La probabilit√† di ciascun valore di \\(Z\\) si trova dividendo la sua frequenza per il numero totale di esiti nello spazio campione.\n\n# Calcoliamo il numero totale di esiti nello spazio campione\nnumero_totale_esiti = len(z)\n\n# Inizializzo un dizionario per memorizzare la distribuzione di massa di probabilit√† di Z\ndistribuzione_massa_probabilita = {}\n\n# Calcolo della distribuzione di massa di probabilit√† per ciascun valore di Z\nfor valore, frequenza in frequenze_z.items():\n    distribuzione_massa_probabilita[valore] = frequenza / numero_totale_esiti\n\ndistribuzione_massa_probabilita\n\n{2: 0.027777777777777776,\n 3: 0.05555555555555555,\n 4: 0.08333333333333333,\n 5: 0.1111111111111111,\n 6: 0.1388888888888889,\n 7: 0.16666666666666666,\n 8: 0.1388888888888889,\n 9: 0.1111111111111111,\n 10: 0.08333333333333333,\n 11: 0.05555555555555555,\n 12: 0.027777777777777776}\n\n\nCreiamo un DataFrame con due colonne: i valori di Z e le associate probabilit√†.\n\ndf_distribuzione = pd.DataFrame(list(distribuzione_massa_probabilita.items()), columns=['Valore di Z', 'Probabilit√†'])\ndf_distribuzione\n\n\n\n\n\n\n\n\n\nValore di Z\nProbabilit√†\n\n\n\n\n0\n2\n0.027778\n\n\n1\n3\n0.055556\n\n\n2\n4\n0.083333\n\n\n3\n5\n0.111111\n\n\n4\n6\n0.138889\n\n\n5\n7\n0.166667\n\n\n6\n8\n0.138889\n\n\n7\n9\n0.111111\n\n\n8\n10\n0.083333\n\n\n9\n11\n0.055556\n\n\n10\n12\n0.027778\n\n\n\n\n\n\n\n\nPossiamo usare un un grafico a barre per rappresentare la distribuzione di probabilit√† di \\(Z\\).\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.bar(\n    df_distribuzione[\"Valore di Z\"],\n    df_distribuzione[\"Probabilit√†\"],\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.xlabel('Valore Z')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione di Probabilit√† di Z')\nplt.xticks(range(2, 13))  # Per mostrare tutte le etichette sull'asse x\nplt.show()\n\n\n\n\n\n\n\n\nNel corso di questo esercizio, abbiamo calcolato le probabilit√† determinando il numero di casi favorevoli, cio√® le occorrenze di ogni possibile somma \\(D_1 + D_2\\), all‚Äôinterno dello spazio campionario dell‚Äôesperimento di lancio di due dadi. Queste probabilit√† si ottengono dividendo il numero di tali occorrenze per il numero totale di combinazioni possibili nello spazio campionario. In termini formali, la probabilit√† di ogni valore specifico di $ Z $ √® indicata come \\(P_Z(z) = P(Z = z)\\), dove \\(P_Z(z)\\) rappresenta ‚Äúla probabilit√† che la variabile casuale \\(Z\\) assuma il valore \\(z\\)‚Äù. La funzione che associa a ogni valore $ u $ di \\(Z\\) la probabilit√† dell‚Äôevento \\(Z = u\\) √® nota come funzione di massa di probabilit√† della variabile casuale \\(Z\\).\nQuesta funzione, $ p_Z $, √® definita per ciascun valore possibile di $ Z $ come segue:\n\\[\n\\begin{array}{rclll}\np_Z(2) & = & 1/36, \\\\\np_Z(3) & = & 2/36, \\\\\np_Z(4) & = & 3/36, \\\\\np_Z(5) & = & 4/36, \\\\\np_Z(6) & = & 5/36, \\\\\np_Z(7) & = & 6/36, \\\\\np_Z(8) & = & 5/36, \\\\\np_Z(9) & = & 4/36, \\\\\np_Z(10) & = & 3/36, \\\\\np_Z(11) & = & 2/36, \\\\\np_Z(12) & = & 1/36. \\\\\n\\end{array}\n\\]\n\n\n\n25.3.5 Propriet√† della funzione di massa di probabilit√†\nOgni variabile casuale discreta possiede una funzione di massa di probabilit√† unica che rispetta le seguenti propriet√†:\n\nLa probabilit√† di ogni evento singolo √® compresa tra 0 e 1, ovvero \\(0 \\leq P(Z=z) \\leq 1\\).\nLa somma delle probabilit√† di tutti gli eventi possibili √® pari a 1, cio√® \\(\\sum_{z \\in Z} P(Z=z) = 1\\).\n\nSe consideriamo un sottoinsieme \\(A\\) della variabile casuale \\(Z\\), la probabilit√† associata a \\(A\\) dalla distribuzione \\(P_Z\\) √® data da:\n\\[\nP_Z(A) = \\sum_{z \\in A} P(Z = z).\n\\]\nPer esempio, per la variabile casuale \\(Z\\) relativa al lancio di due dadi, la probabilit√† che \\(Z\\) sia un numero dispari si calcola sommando le probabilit√† dei valori dispari:\n\\[\n\\begin{align}\nP(\\text{\"Z √® un numero dispari\"}) &= P_Z(3) + P_Z(5) + P_Z(7) + P_Z(9) + P_Z(11) \\\\\n&= \\frac{2}{36} + \\frac{4}{36} + \\frac{6}{36} + \\frac{4}{36} + \\frac{2}{36} \\\\\n&= \\frac{18}{36} \\\\\n&= \\frac{1}{2}.\n\\end{align}\n\\]\nQuesta formula ci permette di calcolare la probabilit√† di qualsiasi sottoinsieme di $ Z $ utilizzando la distribuzione di probabilit√† \\(P_Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#funzioni-di-distribuzione-cumulativa-cdf",
    "href": "chapters/chapter_3/04a_random_var.html#funzioni-di-distribuzione-cumulativa-cdf",
    "title": "25¬† Variabili casuali",
    "section": "25.4 Funzioni di Distribuzione Cumulativa (CDF)",
    "text": "25.4 Funzioni di Distribuzione Cumulativa (CDF)\nIn uno spazio ordinato, possiamo utilizzare sottoinsiemi intervallari per analizzare come la misura totale si distribuisce da valori inferiori a valori superiori. Definiamo il sottoinsieme intervallare costituito da tutti i punti minori o uguali a un dato punto \\(x\\):\n\\[\n\\mathsf{I}_{x} = \\{ x' \\in X \\mid x' \\le x \\}\n\\]\nLa misura assegnata a questi sottoinsiemi intervallari quantifica l‚Äôaccumulo della misura attraverso lo spazio. Formalizziamo questo concetto definendo la funzione di distribuzione cumulativa \\(F\\):\n\\[\nF(x) = P(X \\le x),\n\\]\ndove:\n\n\\(X\\) √® lo spazio ordinato.\n\\(P\\) rappresenta la misura di probabilit√† assegnata agli intervalli.\n\\(P(X \\le x)\\) indica la probabilit√† che la variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\n\n25.4.1 Propriet√† della Funzione di Distribuzione Cumulativa\nLa funzione \\(F\\), denominata funzione di distribuzione cumulativa (CDF), ha le seguenti propriet√†:\n\nMonotonia non decrescente: Se \\(x_1 &lt; x_2\\), allora \\(F(x_1) \\leq F(x_2)\\). Ci√≤ significa che la probabilit√† cumulativa non diminuisce mai mentre ci si sposta lungo la linea dei numeri reali.\nNormalizzazione: La CDF deve partire da 0 all‚Äôestremo inferiore dello spazio e arrivare a 1 all‚Äôestremo superiore: \\[\n\\lim_{x \\to -\\infty} F(x) = 0 \\quad \\text{e} \\quad \\lim_{x \\to \\infty} F(x) = 1.\n\\]\nContinuit√† a destra: La CDF √® continua da destra in ogni punto \\(x\\). Matematicamente, \\(F(x) = \\lim_{y \\to x^+} F(y)\\), il che significa che non ci sono salti improvvisi nella funzione.\n\n\n\n\n\n\n\nFigura¬†25.3: Una funzione di distribuzione cumulativa quantifica come la misura viene allocata agli intervalli crescenti in uno spazio ordinato. Al limite inferiore dello spazio, l‚Äôintervallo non contiene punti e la funzione di distribuzione cumulativa restituisce zero. Man mano che ci spostiamo verso valori pi√π grandi, l‚Äôintervallo si espande accumulando sempre pi√π misura. Infine, al limite superiore dello spazio, l‚Äôintervallo tende alla misura totale.\n\n\n\n\n\n25.4.2 Funzione di Distribuzione Cumulativa per Variabili Casuali Discrete\nNel contesto delle variabili casuali discrete, la funzione di distribuzione cumulativa viene spesso chiamata funzione di ripartizione. Per una variabile casuale discreta $ X $, la funzione di ripartizione, denotata \\(F(x)\\), √® definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(x_i).\n\\]\nIn questa formula, \\(F(x)\\) rappresenta la probabilit√† che la variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\). La funzione di ripartizione cumula le probabilit√† dei singoli valori fino a \\(x\\).\n\n\n25.4.3 Importanza della Funzione di Distribuzione Cumulativa\nLa CDF √® uno strumento fondamentale per comprendere come le probabilit√† si accumulano lungo uno spazio ordinato. Essa permette di visualizzare la distribuzione delle probabilit√† in modo cumulativo e fornisce informazioni essenziali sulla probabilit√† totale associata a un intervallo di valori.\n\nEsempio 25.5 Per il caso del lancio di due dadi e la variabile casuale \\(Z\\) definita come la loro somma, la funzione di ripartizione di \\(Z\\) pu√≤ essere illustrata come segue:\n\n\n\nz\np(z)\nF(z)\n\n\n\n\n2\n1/36\n1/36\n\n\n3\n2/36\n3/36\n\n\n4\n3/36\n6/36\n\n\n5\n4/36\n10/36\n\n\n6\n5/36\n15/36\n\n\n7\n6/36\n21/36\n\n\n8\n5/36\n26/36\n\n\n9\n4/36\n30/36\n\n\n10\n3/36\n33/36\n\n\n11\n2/36\n35/36\n\n\n12\n1/36\n36/36\n\n\n\nIn questa tabella, \\(F(z)\\) rappresenta la funzione di ripartizione cumulativa per ciascun valore \\(z\\). Questo aiuta a comprendere la distribuzione cumulativa delle probabilit√† per la variabile casuale \\(Z\\) nel contesto del lancio dei due dadi.\n\n\n25.4.3.1 Trovare la distribuzione di probabilit√† con una simulazione\nLa distribuzione di probabilit√† che abbiamo precedentemente calcolato per il lancio dei due dadi √® corretta, ma esiste un altro metodo per ottenere un risultato molto simile attraverso la simulazione. Questo metodo implica la generazione di un elevato numero di ripetizioni dell‚Äôesperimento casuale e l‚Äôanalisi delle frequenze relative dei risultati ottenuti. In altre parole, simulando l‚Äôesperimento numerose volte, possiamo approssimare la distribuzione di probabilit√† empirica, che si avvicina sempre di pi√π alla distribuzione teorica man mano che il numero di ripetizioni aumenta. Questo approccio √® comune in statistica ed √® particolarmente utile quando la distribuzione di probabilit√† teorica non √® facilmente calcolabile o √® troppo complessa per essere gestita in modo analitico.\n\nEsempio 25.6 Nel Capitolo 3 abbiamo visto come creare una funzione che ritorna il risultato del lancio di un dado:\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return rng.choice([1, 2, 3, 4, 5, 6])\n\nPossiamo ora definire una funzione che ritorna la somma dei punti prodotti dal lancio di due dadi. La funzione ha come argomento il numero di ripetizioni di questo esperimento casuale.\n\ndef roll_two_dice(n):\n    \"\"\"\n    returns a random int between 2 and 12\n    \"\"\"\n    rolls = []\n    for i in range(n):\n        two_dice = roll_die() + roll_die()\n        rolls.append(two_dice)\n    \n    return rolls\n\nEseguiamo 100,000 ripetizioni dell‚Äôesperimento casuale e memorizzo i risultati ottenuti.\n\nnrolls = 100000\nres = roll_two_dice(nrolls)\nprint(*res[1:20])\n\n12 10 7 10 7 9 8 7 5 9 8 7 4 9 7 2 10 10 5\n\n\nCreiamo un DataFrame che contiene la variabile y corrispondente ai risultati delle 10,000 ripetizioni dell‚Äôesperimento casuale.\n\ndf = pd.DataFrame()\ndf[\"y\"] = res \n\nUtilizziamo dunque il metodo value_counts(), che pu√≤ essere applicato a un DataFrame, come abbiamo visto nel Capitolo 15, per trovare le frequenze assolute di ciascuno dei possibili risultati dell‚Äôesperimento casuale (cio√®, 2, 3, ‚Ä¶, 12). Dividendo per il numero totale delle ripetizioni, otterremo una stima empirica della probabilit√†. Si noti che i risultati saranno simili a quelli teorici ottenuti in precedenza.\n\nabs_freqs = df[\"y\"].value_counts().sort_index()\npx = abs_freqs / nrolls\nlist(zip(list(range(2, 13)), px))\n\n[(2, 0.02775),\n (3, 0.05625),\n (4, 0.08331),\n (5, 0.11109),\n (6, 0.13915),\n (7, 0.16824),\n (8, 0.13751),\n (9, 0.11167),\n (10, 0.08238),\n (11, 0.05567),\n (12, 0.02698)]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/04a_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "25¬† Variabili casuali",
    "section": "25.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "25.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html",
    "href": "chapters/chapter_3/04b_expval_var.html",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "Introduzione\nUna variabile casuale rappresenta un elemento centrale nella teoria della probabilit√† e nelle sue applicazioni statistiche. Dal punto di vista formale, una variabile casuale √® definita come una funzione che associa elementi di uno spazio campionario \\(S\\) a valori in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di quantificare numericamente gli esiti di un fenomeno aleatorio, attribuendo un valore specifico ad ogni possibile risultato.\nLe variabili casuali possono essere classificate in due categorie principali: le variabili casuali discrete e quelle continue. Le variabili casuali discrete sono caratterizzate dal fatto di assumere valori in un insieme finito o al pi√π numerabile, mentre le variabili casuali continue si distinguono per la loro capacit√† di assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo continuo.\nCon il concetto di variabile casuale ben definito, emergono questioni relative alla descrizione dell‚Äôinsieme completo dei possibili esiti e delle probabilit√† associate a ciascun esito. Queste considerazioni portano alla nozione di ‚Äúdistribuzione‚Äù di una variabile casuale. Per le variabili casuali discrete, la distribuzione √® una funzione che elenca tutti i possibili valori che la variabile pu√≤ assumere, insieme alle probabilit√† corrispondenti a ciascun valore. In questo modo, la distribuzione di una variabile casuale fornisce un quadro completo delle sue caratteristiche probabilistiche, consentendo analisi e inferenze statistiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#valore-atteso",
    "href": "chapters/chapter_3/04b_expval_var.html#valore-atteso",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.1 Valore atteso",
    "text": "26.1 Valore atteso\nSpesso √® utile sintetizzare la distribuzione di una variabile casuale tramite indicatori caratteristici. Questi indicatori permettono di cogliere le caratteristiche principali della distribuzione, come la posizione (cio√® il baricentro) e la variabilit√† (cio√® la dispersione attorno ad un centro). In questo modo, si pu√≤ avere una descrizione sintetica della distribuzione di probabilit√† della variabile casuale. In questo capitolo introdurremo i concetti di valore atteso e di varianza di una variabile casule.\nQuando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual √® il suo ‚Äúvalore tipico‚Äù. La nozione di ‚Äúvalore tipico‚Äù, tuttavia, √® ambigua. Infatti, essa pu√≤ essere definita in almeno tre modi diversi:\n\nla media (somma dei valori divisa per il numero dei valori),\nla mediana (il valore centrale della distribuzione, quando la variabile √® ordinata in senso crescente o decrescente),\nla moda (il valore che ricorre pi√π spesso).\n\nPer esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) √® \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana √® \\(3\\) e la moda √® \\(1\\). Tuttavia, la teoria delle probabilit√† si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per ‚Äúvalore tipico‚Äù quando facciamo riferimento alle variabili casuali. Giungiamo cos√¨ alla seguente definizione.\n\nDefinizione 26.1 Sia \\(Y\\) √® una variabile casuale discreta che assume i valori \\(y_1, \\dots, y_n\\) con distribuzione \\(P(Y = y_i) = p(y_i)\\). Per definizione il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), √®\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^n y_i \\cdot p(y_i).\n\\tag{26.1}\\]\n\nA parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale √® definito come la somma di tutti i valori che la variabile casuale pu√≤ prendere, ciascuno pesato dalla probabilit√† con cui il valore √® preso.\n\nEsempio 26.1 Calcoliamo il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0).\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5.\n\\]\n\n\nEsempio 26.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente alla somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nAbbiamo visto nel Capitolo 20 che \\(X\\) pu√≤ assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con distribuzione di massa di probabilit√† pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando l‚ÄôEquazione¬†26.1 otteniamo:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n\\]\nSvolgiamo ora l‚Äôesercizio in Python.\nDefinisco i valori della variabile casuale \\(X\\) e li trasformiamo in un array NumPy:\n\nx = np.array(list(range(2, 13)))\nx\n\narray([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n\n\nPer trovare la distribuzione di massa della variabile \\(X\\) ripeto qui il codice che abbiamo usato nel Capitolo 20.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\n\npx = []\n\nfor i in range(2, 13):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n\npx = np.array(px)\npx\n\narray([0.02777778, 0.05555556, 0.08333333, 0.11111111, 0.13888889,\n       0.16666667, 0.13888889, 0.11111111, 0.08333333, 0.05555556,\n       0.02777778])\n\n\nCalcolo ora il valore atteso della \\(X\\) usando l‚Äôeq. {eq}eq-expval-discr:\n\nex = np.sum(x * px)\nex.round(3)\n\n7.0\n\n\nIn alternativa, posso usare le funzioni del modulo rv_discrete della libreria stats:\n\nx = np.arange(2, 13)\npx = np.array([1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36])\nX = stats.rv_discrete(values=(x, px))\n\nUna volta definito l‚Äôoggetto \\(X\\) con rv_discrete(), il valore atteso viene ritornato dalla funzione expect():\n\nx_ev = X.expect()\nround(x_ev, 3)\n\n7.0\n\n\n\n\n26.1.1 Interpretazione\nIl valore atteso corrisponde alla media aritmetica di un grande numero di realizzazioni indipendenti della variabile casuale.\nPer fare un esempio, ritorniamo all‚Äôesempio precedente relativo al lancio di due dadi bilanciati a sei facce nel quale \\(X\\) rappresenta la ‚Äúsomma dei due dadi‚Äù. Per interpretare il valore atteso, simuliamo un grande numero di realizzazioni indipendenti della \\(X\\) mediante la funzione random.choice() della libreria NumPy. Tale funzione prende come argomenti i valori della variabile casuale, il numero di ripetizioni indipedenti (qui 1,000,000) e la distribuzione di massa di probabilit√†:\n\nx_samples = np.random.choice(x, size=1000000, p=px)\n\nL‚Äôistruzione np.random.choice(x, size=1000000, p=px) utilizza la libreria NumPy per generare un array di 1.000.000 di elementi (parametro size), scelti casualmente dall‚Äôarray x con le probabilit√† specificate nell‚Äôarray px. In particolare, x √® l‚Äôarray di cui si vuole effettuare una scelta casuale e px √® un array che contiene le probabilit√† associate ad ogni elemento di x.\nCome ci aspettavamo, per un grande numero di realizzazioni indipendenti della \\(X\\), la media aritmetica approssima il valore atteso:\n\nnp.mean(x_samples).round(3)\n\n7.002\n\n\n\n\n26.1.2 Propriet√† del valore atteso\nLa propriet√† pi√π importante del valore atteso √® la linearit√†: il valore atteso di una somma di variabili casuali √® uguale alla somma dei lori rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{26.2}\\]\nL‚ÄôEquazione¬†26.2 sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma √® anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{26.3}\\]\nL‚ÄôEquazione¬†26.3 ci dice che possiamo estrarre una costante dall‚Äôoperatore di valore atteso. Tale propriet√† si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che\n\\[\n\\mathbb{E}(X Y) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{26.4}\\]\nLa media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione di media \\(\\mu\\) ha valore atteso\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\mathbb{E}(X_1)+ \\dots \\mathbb{E}(X_n) = \\frac{1}{n} n \\mathbb{E}(X) = \\mu.\n\\]\n\nEsempio 26.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell‚Äôesperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado √® indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avr√† la stessa probabilit√† di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) √® dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l‚ÄôEquazione¬†26.2:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\nSvolgiamo ora l‚Äôesercizio in Python.\n\ncoin = range(0, 2)\ndie = range(1, 7)\n\nsample = [(c, d) for c in coin for d in die]\nlist(sample)\n\n[(0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (0, 5),\n (0, 6),\n (1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6)]\n\n\n\npx = []\nfor i in range(1, 8):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n    print(f\"P(X + Y = {i}) = {len(event)} / {len(sample)}\")\n\nP(X + Y = 1) = 1 / 12\nP(X + Y = 2) = 2 / 12\nP(X + Y = 3) = 2 / 12\nP(X + Y = 4) = 2 / 12\nP(X + Y = 5) = 2 / 12\nP(X + Y = 6) = 2 / 12\nP(X + Y = 7) = 1 / 12\n\n\n\nx = np.arange(1, 8)\nsum(x * px)\n\n4.0\n\n\n\n\nEsempio 26.4 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilit√† congiunta \\(P(X, Y)\\) √® fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l‚ÄôEquazione¬†26.4. Infatti, il valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerci√≤\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\nSvolgiamo l‚Äôesercizio in Python.\n\nr = range(0, 2)\nsample = [(i, j, w) for i in r for j in r for w in r]\n\nfor i in range(0, 4):\n    event = [toss for toss in sample if sum(toss) * toss[0] == i]\n    print(f\"P(Z = {i}) : {len(event)} / {len(sample)}\")\n\nP(Z = 0) : 4 / 8\nP(Z = 1) : 1 / 8\nP(Z = 2) : 2 / 8\nP(Z = 3) : 1 / 8\n\n\n\nz = np.array([0, 1, 2, 3])\npz = np.array([4/8, 1/8, 2/8, 1/8])\nsum(z * pz)\n\n1.0\n\n\n\n\n\n26.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa:\n\\[\n\\mathbb{E}(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname{d}\\!y.\n\\tag{26.5}\\]\nAnche in questo caso il valore atteso √® una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) √® ponderato per il corrispondente valore della densit√† \\(p(y)\\). Possiamo leggere l‚Äôintegrale pensando che \\(y\\) rappresenti l‚Äôampiezza delle barre infinitamente strette di un istogramma, con la densit√† \\(p(y)\\) che corrisponde all‚Äôaltezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma.1\n\n26.1.3.1 Moda\nUn‚Äôaltra misura di tendenza centrale delle variabili casuali continue √® la moda. La moda di \\(Y\\) individua il valore \\(y\\) pi√π plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densit√† \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{26.6}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#varianza",
    "href": "chapters/chapter_3/04b_expval_var.html#varianza",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.2 Varianza",
    "text": "26.2 Varianza\nLa seconda pi√π importante propriet√† di una variabile casuale, dopo che conosciamo il suo valore atteso, √® la varianza.\n\nDefinizione 26.2 Se \\(Y\\) √® una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), √®\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big].\n\\tag{26.7}\\]\n\nA parole: la varianza √® la deviazione media quadratica della variabile dalla sua media.2 Se denotiamo \\(\\mathbb{E}(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\).\n\nEsempio 26.5 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilit√†:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\nSvolgiamo l‚Äôesercizio in Python.\n\nx = np.arange(2, 13)\npx = np.array(\n    [\n        1 / 36,\n        2 / 36,\n        3 / 36,\n        4 / 36,\n        5 / 36,\n        6 / 36,\n        5 / 36,\n        4 / 36,\n        3 / 36,\n        2 / 36,\n        1 / 36,\n    ]\n)\nX = stats.rv_discrete(values=(x, px))\nex = X.expect()\nex\n\n6.999999999999998\n\n\nApplichiamo l‚ÄôEquazione¬†26.7:\n\n((x - ex) ** 2 * px).sum()\n\n5.833333333333333\n\n\nUsiamo la funzione var() di rv_discrete:\n\nX.var()\n\n5.833333333333364\n\n\n\n\n26.2.1 Formula alternativa per la varianza\nC‚Äô√® un modo pi√π semplice per calcolare la varianza:\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big] &= \\mathbb{E}\\big(Y^2 - 2Y\\mathbb{E}(Y) + \\mathbb{E}(Y)^2\\big)\\notag\\\\\n&= \\mathbb{E}(Y^2) - 2\\mathbb{E}(Y)\\mathbb{E}(Y) + \\mathbb{E}(Y)^2,\n\\end{align}\n\\]\ndato che \\(\\mathbb{E}(Y)\\) √® una costante. Pertanto\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2.\n\\tag{26.8}\\]\nA parole: la varianza √® la media dei quadrati meno il quadrato della media della variabile.\n\nEsempio 26.6 Consideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilit√† di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) √®\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\nSvolgiamo l‚Äôesercizio in Python:\n\ny = np.array([0, 1])\npy = np.array([0.2, 0.8])\n\nsum(y**2 * py) - (sum(y * py)) ** 2\n\n0.15999999999999992\n\n\n\n\n\n26.2.2 Propriet√†\nSegno della varianza. La varianza di una variabile aleatoria non √® mai negativa, ed √® zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza √® invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\nx = np.array([2, 1, 4, 7])\ny = 100 + 2 * x\n\nnp.var(y) == 2**2 * np.var(x)\n\nTrue\n\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio √® fornita sotto.\n\nx = np.array([2, 1, 4, 7])\ny = np.array([1, 3, 5, 11])\n\nnp.var(x + y, ddof=0)\n\n35.25\n\n\n\nnp.var(x, ddof=0) + np.var(y, ddof=0) + 2 * np.cov(x, y, ddof=0)[0, 1]\n\n35.25\n\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente √® illustrato dalla seguente simulazione.\n\n# Set up the population distribution\npopulation = np.random.normal(loc=50, scale=10, size=10000)\n\n# Set up the sample size and number of samples\nsample_size = 30\nnum_samples = 100000\n\n# Create an array to hold the sample means\nsample_means = np.zeros(num_samples)\n\n# Generate the samples and compute their means\nfor i in range(num_samples):\n    sample = np.random.choice(population, size=sample_size)\n    sample_means[i] = np.mean(sample)\n\n# Calculate the variance of the sample means\nsampling_dist_mean_var = np.var(sample_means)\nsampling_dist_mean_var\n\n3.4103710835201433\n\n\nIl valore teorico della varianza della distribuzione campionaria della media √®\n\n10**2 / 30\n\n3.3333333333333335\n\n\n\n\n26.2.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\), la varianza diventa:\n\\[\n\\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\mathbb{E}(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y.\n\\tag{26.9}\\]\nCome nel caso discreto, la varianza di una v.c. continua \\(Y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(y\\) dalla loro media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#deviazione-standard",
    "href": "chapters/chapter_3/04b_expval_var.html#deviazione-standard",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.3 Deviazione standard",
    "text": "26.3 Deviazione standard\nQuando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell‚Äôunit√† di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente √® denotato dalla lettera greca \\(\\sigma\\).\n\nDefinizione 26.3 Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:\n\\[\n\\sigma_Y = \\sqrt{\\mathbb{V}(Y)}.\n\\tag{26.10}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media.\nPer i dadi equilibrati dell‚Äôesemio precedebte, la deviazione standard della variabile casuale \\(S\\) √® uguale a \\(\\sqrt{5.833} = 2.415\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#standardizzazione",
    "href": "chapters/chapter_3/04b_expval_var.html#standardizzazione",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.4 Standardizzazione",
    "text": "26.4 Standardizzazione\n\nDefinizione 26.4 Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l‚Äôespressione\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}.\n\\tag{26.11}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/chapter_3/04b_expval_var.html#momenti-di-variabili-casuali",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.5 Momenti di variabili casuali",
    "text": "26.5 Momenti di variabili casuali\n\nDefinizione 26.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densit√† \\(p(x)\\), la quantit√†\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{26.12}\\]\nSe \\(X\\) √® una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i).\n\\tag{26.13}\\]\n\nI momenti sono importanti parametri indicatori di certe propriet√† di \\(X\\). I pi√π noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x ‚àí \\mathbb{E}(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#alcuni-esempi-in-python",
    "href": "chapters/chapter_3/04b_expval_var.html#alcuni-esempi-in-python",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.6 Alcuni esempi in Python",
    "text": "26.6 Alcuni esempi in Python\nUtilizzando il modulo stats di scipy, √® possibile semplificare i calcoli del valore atteso e della varianza di variabili casuali discrete.\nConsideriamo ad esempio una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilit√†: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx = np.arange(7)\nprint(x)\n\n[0 1 2 3 4 5 6]\n\n\nIl vettore px conterr√† le probabilit√† associate ai valori x:\n\npx = [0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\nprint(px)\n\n[0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\n\n\nControlliamo che la somma sia 1:\n\nnp.sum(px)\n\n1.0\n\n\nUsiamo ora la funzione rv_discrete() che √® una funzione della libreria stats di Python. Tale funzione viene utilizzata per creare una distribuzione discreta personalizzata. La funzione richiede che vengano forniti dei valori discreti (ossia interi) e le rispettive probabilit√† di occorrenza.\nUna volta definita la distribuzione discreta, rv_discrete() permette di eseguire operazioni come la generazione di numeri casuali dalla distribuzione, il calcolo della funzione di probabilit√† cumulativa (CDF) e della funzione di densit√† di probabilit√† (PDF), e la valutazione della media, della varianza e di altre statistiche della distribuzione.\nLa sintassi di base della funzione rv_discrete() √® la seguente:\nrv = stats.rv_discrete(name='rv', values=(xk, pk))\ndove name √® il nome della distribuzione discreta, xk sono i valori discreti e pk sono le rispettive probabilit√† di occorrenza. Ad esempio, creiamo la variabile casuale X:\n\nX = stats.rv_discrete(name='rv', values=(x, px))\n\n\n# Distribuzione di massa di probabilit√† di X.\nprint(X.pmf(x))\n\n[0.1 0.2 0.3 0.1 0.1 0.  0.2]\n\n\n\n# Distribuzione comulativa di probabilit√† di X.\nprint(X.cdf(x))\n\n[0.1 0.3 0.6 0.7 0.8 0.8 1. ]\n\n\nGeneriamo un grafico che rappresenta la distribuzione di massa con Matplotlib.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.plot(x, X.pmf(x), \"o\", ms=6, color=color_fill, markeredgecolor=color_edge)\nplt.vlines(x, 0, X.pmf(x), lw=2, colors=color_edge)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso, ovvero utilizzando i vettori x e px.\n\nx_ev = (x * px).sum()\nx_ev\n\n2.7\n\n\nLo stesso risultato si ottience applicando il metodo .expect() all‚Äôoggetto X.\n\nx_ev = X.expect()\nx_ev\n\n2.7\n\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px.\n\nx_var = ((x - x_ev)**2 * X.pmf(x)).sum()\nx_var\n\n3.8100000000000005\n\n\nOtteniamo lo stesso risultato applicando il metodo .var() all‚Äôoggetto X.\n\nX.var()\n\n3.8099999999999987\n\n\nCalcoliamo la deviazione standard di \\(X\\) prendento la radice quadrata della varianza.\n\nnp.sqrt(x_var)\n\n1.9519221295943137\n\n\nOppure, in maniera equivalente, applicando il metodo .std() all‚Äôoggetto X.\n\nX.std()\n\n1.9519221295943132",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/04b_expval_var.html#commenti-e-considerazioni-finali",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.7 Commenti e considerazioni finali",
    "text": "26.7 Commenti e considerazioni finali\nL‚Äôinferenza bayesiana mira a descrivere la distribuzione a posteriori di variabili casuali che rappresentano i parametri di un modello statistico. Nel capitolo precedente, abbiamo esaminato le caratteristiche principali delle variabili casuali, concentrandoci sul caso discreto. In questo capitolo, abbiamo approfondito le propriet√† di una singola variabile casuale. Nel prossimo capitolo, invece, esploreremo il problema di descrivere il verificarsi congiunto di due o pi√π variabili casuali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/04b_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "26.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "26.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nscipy     : 1.14.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#footnotes",
    "href": "chapters/chapter_3/04b_expval_var.html#footnotes",
    "title": "26¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "Per il significato della notazione di integrale, si veda l‚ÄôAppendice L.‚Ü©Ô∏é\nData una variabile casuale \\(Y\\) con valore atteso \\(\\mathbb{E}(Y)\\), le ‚Äúdistanze‚Äù tra i valori di \\(Y\\) e il valore atteso \\(\\mathbb{E}(Y)\\) definiscono la variabile casuale \\(Y - \\mathbb{E}(Y)\\) chiamata scarto, oppure deviazione oppure variabile casuale centrata. La variabile \\(Y - \\mathbb{E}(Y)\\) equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell‚Äôorigine degli assi. Si pu√≤ dimostrare facilmente che il valore atteso della variabile scarto \\(Y - \\mathbb{E}(Y)\\) vale zero, dunque la media di tale variabile non pu√≤ essere usata per quantificare la ‚Äúdispersione‚Äù dei valori di \\(Y\\) relativamente al suo valore medio. Occorre rendere sempre positivi i valori di \\(Y - \\mathbb{E}(Y)\\) e tale risultato viene ottenuto considerando la variabile casuale \\(\\left(Y - \\mathbb{E}(Y)\\right)^2\\).‚Ü©Ô∏é",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html",
    "href": "chapters/chapter_3/04c_sampling_distr.html",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† verranno utilizzate per costruire gli strumenti fondamentali dell‚Äôinferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/chapter_3/04c_sampling_distr.html#popolazione-e-campioni",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.1 Popolazione e campioni",
    "text": "27.1 Popolazione e campioni\nNell‚Äôanalisi dei dati, l‚Äôobiettivo spesso √® comprendere una quantit√† specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantit√† sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta √® chiamata stima, e la formula che utilizziamo per ottenerla √® conosciuta come stimatore. In termini formali, uno stimatore √® una funzione dei dati osservati, utilizzata per fornire un‚Äôapprossimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo √® inferire determinate propriet√† della popolazione intera dalla quale il campione √® stato tratto. Il parametro √® l‚Äôindicatore numerico di queste propriet√†, ma poich√© spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore √® la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\n√à importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "href": "chapters/chapter_3/04c_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.2 La relazione tra stime e parametri",
    "text": "27.2 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo √® capire e caratterizzare l‚Äôincertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l‚Äôapproccio frequentista, facendo uso di un importante strumento statistico chiamato distribuzione campionaria.\n\n27.2.1 Distribuzione campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, √® fondamentale notare che le propriet√† e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci d√† una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all‚Äôintera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornir√† una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell‚Äôincertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL‚Äôistogramma seguente descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l‚Äôistogramma.\n\nprint(\"Intervalli utilizzati per l'istogramma:\", intervalli)\nprint(\"Frequenze relative utilizzate per l'istogramma:\", conteggi)\n\nIntervalli utilizzati per l'istogramma: [2.  2.7 3.4 4.1 4.8 5.5]\nFrequenze relative utilizzate per l'istogramma: [0.35714286 0.         0.         0.35714286 0.71428571]\n\n\nLe frequenze assolute si ottengono usando l‚Äôargomento density=False.\n\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=False,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\nprint(\"Frequenze assolute utilizzate per l'istogramma:\", conteggi)\n\n\n\n\n\n\n\n\nFrequenze assolute utilizzate per l'istogramma: [1. 0. 0. 1. 2.]\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nSupponiamo ora di voler considerare l‚Äôestrazione di tutti i possibili campioni di dimensione \\(n\\) = 2 da una popolazione rappresentata dall‚Äôarray x. Per fare ci√≤, possiamo fare uso di uno strumento di programmazione, come la funzione product del modulo itertools in Python.\nSpecificamente, possiamo utilizzare product con l‚Äôargomento repeat impostato a 2, che indica che vogliamo formare tutte le possibili coppie di valori. In altre parole, stiamo cercando tutte le combinazioni in cui ogni valore nell‚Äôarray x pu√≤ essere abbinato a se stesso o a un altro valore nell‚Äôarray.\nDopo aver utilizzato la funzione product, otteniamo una lista di tuple, che rappresenta tutte le possibili coppie di valori. Possiamo convertire questa lista in un array NumPy pi√π maneggevole utilizzando la funzione np.array. Stampando il risultato, otteniamo un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie che possono essere formate dall‚Äôarray x.\nQuesta rappresentazione di tutte le possibili coppie √® coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento pu√≤ essere scelto pi√π di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sar√† $4^2 = 16 $. Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di \\(4 \\times 4 = 16\\) possibili coppie.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nConvertiamo l‚Äôoutput di itertools.product in un array NumPy per sfruttare le funzionalit√† di questa libreria. L‚Äôarray risultante, samples, √® un array 2D, dove ogni riga rappresenta una coppia di valori.\n\nsamples.shape\n\n(16, 2)\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), possiamo utilizzare la funzione mean del modulo NumPy e applicarla lungo l‚Äôasse delle colonne dell‚Äôarray di coppie di valori. In questo modo otterremo un array unidimensionale contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nLa funzione np.mean(samples, axis=1) calcola la media lungo l‚Äôasse specificato, che in questo caso √® l‚Äôasse 1. In NumPy, l‚Äôasse 0 rappresenta le righe (verticale) e l‚Äôasse 1 rappresenta le colonne (orizzontale).\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\n_ = plt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x.\n\n\n27.2.2 Valore atteso della media campionaria\nSupponiamo che $ X_1, X_2, , X_n $ siano variabili aleatorie iid con valore atteso $ $ e varianza $ ^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nEcco la dimostrazione:\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n\\]\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid √® uguale al valore atteso di ciascuna variabile singola, che in questo caso √® $ $.\nVerifichiamo che ci√≤ sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\n\n\n27.2.3 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid √® uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso √® \\(\\sigma^2/n\\).\nPer l‚Äôesempio in discussione, il valore della varianza delle medie dei campioni √® dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione √® diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall‚Äôanalisi delle medie campionarie:\n\nMedia delle medie campionarie e media della popolazione: La media della distribuzione delle medie campionarie √® identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ $ √®:\n\n\\[\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\nVarianza delle medie campionarie e varianza della popolazione: La varianza della distribuzione delle medie campionarie √® inferiore alla varianza della popolazione e, precisamente, √® pari alla varianza della popolazione divisa per la dimensione del campione:\n\n\\[\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\nInoltre, √® importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\nSe la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sar√† anch‚Äôessa normale.\nSe la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/chapter_3/04c_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale",
    "text": "27.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale\nNella statistica inferenziale, l‚Äôerrore standard √® una misura frequentemente utilizzata per rappresentare l‚Äôincertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L‚Äôerrore standard quantifica quanto possa variare la stima di una statistica da un campione all‚Äôaltro; un errore standard minore indica una stima pi√π precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di ‚Äúmedia pi√π o meno uno (o due) errori standard.‚Äù Questa espressione fornisce una gamma di valori entro cui √® plausibile che ricada il valore vero del parametro della popolazione.\nL‚Äôuso dell‚Äôerrore standard nei grafici non √® soltanto una convenzione; esso √® uno strumento per quantificare e visualizzare l‚Äôincertezza inferenziale. Contribuisce alla comprensione dell‚Äôaffidabilit√† delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, √® importante notare che questo utilizzo dell‚Äôerrore standard pu√≤ essere problematico (Ward e Mann 2022).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/chapter_3/04c_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.4 Legge dei Grandi Numeri",
    "text": "27.4 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) √® un principio fondamentale della teoria delle probabilit√† che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione ‚Äúforte‚Äù e quella ‚Äúdebole‚Äù, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n27.4.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilit√† 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell‚Äôinsieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilit√† √® zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) ‚Äúquasi certamente‚Äù.\n\n\n27.4.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantit√† maggiore di \\(\\epsilon\\) tende a zero all‚Äôaumentare di \\(n\\). Questo fenomeno √® definito come convergenza in probabilit√† verso la media teorica \\(\\mu\\).\n\n\n27.4.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, pi√π in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l‚Äôutilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l‚Äôaffidabilit√† delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 27.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di ‚ÄúTesta‚Äù in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di ‚ÄúTesta‚Äù dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilit√† 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) converger√† a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di ‚ÄúTesta‚Äù (HHHHHH‚Ä¶) o sequenze irregolari come HHTHHTHHTHHT‚Ä¶, ma queste hanno una probabilit√† collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che \\(\\bar{X}_n\\) sia distante pi√π di \\(\\epsilon\\) da \\(1/2\\) pu√≤ essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realt√† non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All‚Äôinizio, notiamo una certa variazione nella proporzione cumulativa di ‚ÄúTesta‚Äù. Tuttavia, con l‚Äôaumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Number of sequences\nnum_sequences = 6\n# Number of tosses\nnum_tosses = 300\n# Initialize a figure\nplt.figure()\n\n# Loop through each sequence\nfor i in range(num_sequences):\n    \n    # Generate a sequence of fair coin tosses (Heads=1, Tails=0)\n    coin_tosses = np.random.choice([0, 1], num_tosses)\n    \n    # Calculate the running proportion of Heads\n    running_proportion = np.cumsum(coin_tosses) / np.arange(1, num_tosses + 1)\n    \n    # Plot the running proportion as a function of the number of tosses\n    plt.plot(np.arange(1, num_tosses + 1), running_proportion, label=f'Sequence {i+1}')\n\n# Plotting the true mean (1/2)\nplt.axhline(y=0.5, color='r', linestyle='--', label='True Mean (1/2)')\n\n# Adding labels and title\nplt.xlabel('Number of Tosses')\nplt.ylabel('Running Proportion of Heads')\nplt.title('Running Proportion of Heads in Six Sequences of Fair Coin Tosses')\nplt.legend()\nplt.legend(fontsize='small')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/chapter_3/04c_sampling_distr.html#teorema-del-limite-centrale",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.5 Teorema del Limite Centrale",
    "text": "27.5 Teorema del Limite Centrale\nIl teorema del limite centrale √® un risultato fondamentale in statistica che √® stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare cos√¨ frequentemente nei fenomeni naturali. Ecco la formulazione essenziale:\n\n27.5.1 Enunciato\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all‚Äôinfinito, la distribuzione di \\(Z\\) converger√† a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n\n27.5.2 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma pu√≤ essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacit√† di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l‚Äôaltezza degli esseri umani adulti pu√≤ essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalit√† rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 27.2 Per visualizzare il TLC in azione, si pu√≤ condurre una simulazione. Immaginiamo una popolazione iniziale con una distribuzione asimmetrica, come una Beta(2, 1). Estraiamo 50.000 campioni di dimensione \\(n\\) da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornir√† un‚Äôillustrazione concreta dell‚Äôefficacia del TLC nell‚Äôapprossimare distribuzioni reali.\n\n# parameters of the beta distribution\na=2\nb=1\n\ndef plot_samples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n            v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together\n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(\n        sample_means,\n        color=color_fill,\n        edgecolor=color_edge,\n    )\n    ax2 = ax.twinx()\n    sns.lineplot(x=x, y=y, ax=ax2, color=color_edge)\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l‚Äôampiezza campionaria √® 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non √® certamente Normale, inizia ad avvicinarsi alla gaussianit√†.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c‚Äô√® ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l‚Äôapprossimazione migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, √® possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ci√≤ avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed √® espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/chapter_3/04c_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.6 Distribuzioni campionarie di altre statistiche",
    "text": "27.6 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax, color=color_fill)\nax2 = ax.twinx()\nsns.lineplot(x=x, y=y, ax=ax2, color=color_edge);\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione √® uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto √® stato interessante: in media, l‚Äôutilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard\n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find\n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n177.69769879129643\n\n\n\n\n\n\n\n\n\nAbbiamo gi√† visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n226.51417694562372\n\n\n\n\n\n\n\n\n\nLa differenza tra la stima di un parametro e il valore vero del parametro √® chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici √® uguale al valore del parametro che si vuole stimare. In altre parole, l‚Äôerrore medio di stima √® zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) √® uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#considerazioni-conclusive",
    "href": "chapters/chapter_3/04c_sampling_distr.html#considerazioni-conclusive",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.7 Considerazioni conclusive",
    "text": "27.7 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#watermark",
    "href": "chapters/chapter_3/04c_sampling_distr.html#watermark",
    "title": "27¬† Stime, stimatori e parametri",
    "section": "27.8 Watermark",
    "text": "27.8 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nWard, Andrew, e Traci Mann. 2022. ¬´Control yourself: Broad implications of narrowed attention¬ª. Perspectives on Psychological Science 17 (6): 1692‚Äì1703.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html",
    "href": "chapters/chapter_3/05_joint_prob.html",
    "title": "28¬† Probabilit√† congiunta",
    "section": "",
    "text": "Introduzione\nLa probabilit√† congiunta √® la probabilit√† che due o pi√π eventi si verifichino contemporaneamente. In questo capitolo verr√† esaminato il caso discreto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#sec-fun-join-prob",
    "href": "chapters/chapter_3/05_joint_prob.html#sec-fun-join-prob",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.1 Funzione di Probabilit√† Congiunta",
    "text": "28.1 Funzione di Probabilit√† Congiunta\nDopo aver esplorato la distribuzione di probabilit√† di singole variabili casuali, che associa un unico numero reale ad ogni possibile risultato di un esperimento, si procede naturalmente all‚Äôestensione di questo concetto al caso di due o pi√π variabili casuali.\n\n28.1.1 Esempio: Lancio di Tre Monete Equilibrate\nConsideriamo l‚Äôesperimento del lancio di tre monete equilibrate. Lo spazio campione \\(\\Omega\\) √® dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove T rappresenta ‚Äútesta‚Äù e C rappresenta ‚Äúcroce‚Äù. Assumendo che i lanci siano indipendenti, ogni risultato nell‚Äôinsieme \\(\\Omega\\) ha la stessa probabilit√† di occorrenza, ovvero \\(1/8\\).\nDefiniamo le seguenti variabili casuali sullo spazio campione \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il ‚Äúnumero di teste ottenute nei tre lanci‚Äù.\n\\(Y \\in \\{0, 1\\}\\) indica se ‚Äúla testa √® stata ottenuta nel primo lancio‚Äù (1) o no (0).\n\nLa tabella seguente illustra lo spazio campione e le variabili casuali \\(X\\) e \\(Y\\), insieme alle rispettive probabilit√†:\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nPer ogni coppia \\((x, y)\\) definita su \\(\\Omega\\), associamo una probabilit√† come segue:\n\n\\(P(X=0, Y=0) = P(\\text{CCC}) = 1/8\\),\n\ne similmente per le altre coppie.\nLe probabilit√† calcolate per tutte le possibili coppie \\((X, Y)\\) sono:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= 1/8, \\\\\nP(X = 2, Y = 0) &= 1/8, \\\\\nP(X = 2, Y = 1) &= 1/4, \\\\\nP(X = 3, Y = 1) &= 1/8.\n\\end{aligned}\n\\]\nQueste probabilit√† compongono la distribuzione di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\).\n\n\n28.1.2 Definizione: Funzione di Probabilit√† Congiunta\nLa funzione di probabilit√† congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilit√† \\(P(X = x, Y = y)\\).\n\n\n28.1.3 Propriet√†\nUna distribuzione di probabilit√† congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilit√† su tutte le coppie deve essere 1.\n\n\n\n28.1.4 Calcolo della Probabilit√† di Eventi Specifici\nData la distribuzione di probabilit√† congiunta, possiamo determinare la probabilit√† di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilit√† che \\(X + Y \\leq 1\\), sommiamo le probabilit√† di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).\n\n\n28.1.5 Funzioni di Probabilit√† Marginali\nLa distribuzione marginale di un insieme di variabili casuali descrive la distribuzione di probabilit√† di queste variabili considerate singolarmente, indipendentemente dalle altre. La ‚Äúmarginalizzazione‚Äù √® un processo che permette di ottenere la distribuzione di probabilit√† di una o pi√π variabili casuali marginali sommando o integrando la distribuzione congiunta su tutte le possibili realizzazioni delle altre variabili casuali, ovvero quelle non considerate (e quindi ‚Äúmarginalizzate‚Äù).\nPer esempio, data la distribuzione congiunta di due variabili casuali discrete \\(X\\) e \\(Y\\), la distribuzione marginale di \\(X\\), indicata come \\(P(X=x)\\), si calcola come:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilit√† congiunta di \\(X\\) e \\(Y\\). Le distribuzioni marginali e congiunte di variabili casuali discrete sono frequentemente rappresentate in tabelle di contingenza. Si garantisce che le distribuzioni marginali siano normalizzate:\n\\[\n\\sum_x P(X=x) = 1, \\quad \\sum_y P(Y=y) = 1.\n\\]\nPer variabili casuali continue, la somma √® sostituita dall‚Äôintegrazione.\n\nEsempio 28.1 Prendiamo come riferimento l‚Äôesperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilit√† marginali di \\(X\\) e \\(Y\\), sommiamo le probabilit√† congiunte su una dimensione. La probabilit√† marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilit√† lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilit√† marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilit√† lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilit√† congiunta \\(P(X, Y)\\) e le probabilit√† marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n28.1.6 Marginalizzazione per Variabili Casuali Continue\nNell‚Äôambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo √®:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l‚Äôestensione dell‚Äôapproccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/chapter_3/05_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.2 Indipendenza tra Variabili Casuali",
    "text": "28.2 Indipendenza tra Variabili Casuali\nL‚Äôindipendenza tra variabili casuali √® un concetto fondamentale in statistica e probabilit√†, parallelo all‚Äôidea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l‚Äôinformazione su una non altera in alcun modo la distribuzione di probabilit√† dell‚Äôaltra. Questa sezione offre una formalizzazione dell‚Äôindipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilit√† congiunta.\n\n28.2.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ci√≤ significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilit√† congiunta √® il prodotto delle rispettive distribuzioni di probabilit√† marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l‚Äôindipendenza si verifica quando la funzione di densit√† congiunta √® il prodotto delle funzioni di densit√† marginali.\n\n\n28.2.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, √® utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile √® associata alla variazione dell‚Äôaltra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l‚Äôindipendenza tra variabili casuali √® un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate √® fondamentale per l‚Äôanalisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#covarianza",
    "href": "chapters/chapter_3/05_joint_prob.html#covarianza",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.3 Covarianza",
    "text": "28.3 Covarianza\nLa covarianza √® un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell‚Äôaltra. Per esempio, considerando l‚Äôaltezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando cos√¨ una covarianza positiva. La covarianza √® denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n28.3.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) √® definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini pi√π espliciti, la covarianza pu√≤ essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) √® la funzione di probabilit√† congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che √® la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza pu√≤ essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n28.3.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n28.3.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si pu√≤ ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) √®:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 28.2 Per fare un esempio con Python, consideriamo l‚Äôesempio precedente nel quale \\(X\\) √® il numero che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) √® il numero di teste al primo lancio. Troviamo \\(Cov(X, Y)\\).\nCreiamo il prodotto cartesiano che si ottiene per tutti i possibili valori \\(X\\) e i possibili valori \\(Y\\).\n\nc3 = np.arange(0, 4)\nc1 = np.arange(0, 2)\nsample = [(i, j) for i in c1 for j in c3]\nsample\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo numero √® il valore di \\(X\\). Come abbiamo visto in precedenza, per√≤, quete coppie di valori \\(X, Y\\) non hanno tutte la stessa probabilit√† di verificarsi. Infatti, la probabilit√† che ciascuna coppia \\(X, Y\\) si osservi √® data, in sequenza, dai valori 1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8. Questi valori rappresentano la distribuzione di massa di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\). Possiamo quindi applicare l‚Äôeq. {eq}eq-cov-def-rv:\n\nres = []\n\npmf = np.array([1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8])\n\nfor i in range(8):\n    res.append((sample[i][0] - 0.5) * (sample[i][1] - 1.5) * pmf[i])\n\nsum(res)\n\nLa covarianza tra \\(X\\) e \\(Y\\) √® dunque uguale a 0.25.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#correlazione",
    "href": "chapters/chapter_3/05_joint_prob.html#correlazione",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.4 Correlazione",
    "text": "28.4 Correlazione\nMentre la covarianza fornisce un‚Äôindicazione della tendenza di due variabili casuali a variare insieme, essa √® influenzata dalle unit√† di misura delle variabili, rendendo difficile valutare l‚Äôintensit√† della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo cos√¨ una misura standardizzata dell‚Äôassociazione lineare tra di esse.\n\nDefinizione 28.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), √® definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) √® un valore adimensionale, ovvero non dipende dalle unit√† di misura delle variabili, e varia nell‚Äôintervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#propriet√†-1",
    "href": "chapters/chapter_3/05_joint_prob.html#propriet√†-1",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.5 Propriet√†",
    "text": "28.5 Propriet√†\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) √® sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza √® simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unit√† di Misura: La correlazione √® indipendente dalle unit√† di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) √® una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, √® \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n28.5.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza √® nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza pi√π debole rispetto all‚Äôindipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 28.3 Consideriamo una distribuzione di probabilit√† congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilit√† uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilit√† congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilit√† congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) √® zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ci√≤ non implica la loro indipendenza. L‚Äôindipendenza richiede che la funzione di probabilit√† congiunta si possa esprimere come il prodotto delle funzioni di probabilit√† marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l‚Äôassenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l‚Äôincorrelazione non garantisce l‚Äôindipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#variabili-continue",
    "href": "chapters/chapter_3/05_joint_prob.html#variabili-continue",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.6 Variabili continue",
    "text": "28.6 Variabili continue\nConsideriamo ora le distribuzioni di densit√†. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilit√† congiunta \\(p(A,B)\\), le probabilit√† marginali \\(p(A)\\) e \\(p(B)\\), e le probabilit√† condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densit√† (figura tratta da Martin (2024)).\n\n\n\nProbabilit√† congiunta \\(p(A,B)\\): rappresenta la probabilit√† che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa √® data dall‚Äôintegrazione della funzione di densit√† congiunta su un‚Äôarea o volume di interesse.\nProbabilit√† marginale \\(p(A)\\) e \\(p(B)\\): √® la probabilit√† di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densit√† congiunta sull‚Äôintero intervallo di valori dell‚Äôaltra variabile.\nProbabilit√† condizionale \\(p(A \\mid B)\\): esprime la probabilit√† di A dato B. Si calcola dividendo la probabilit√† congiunta per la probabilit√† marginale di B, applicando la definizione di probabilit√† condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilit√† congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/05_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.7 Commenti e considerazioni finali",
    "text": "28.7 Commenti e considerazioni finali\nIn alcune situazioni, ogni singolo elemento di una popolazione pu√≤ essere associato a diverse variabili casuali. Ad esempio, consideriamo l‚Äôelenco di tutti gli studenti iscritti a un‚Äôuniversit√† e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione √® associato a due variabili casuali, l‚Äôaltezza e il peso. Quando si hanno due o pi√π variabili casuali associate ad ogni elemento di una popolazione, √® possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilit√† congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/05_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "28¬† Probabilit√† congiunta",
    "section": "28.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "28.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMartin, Osvaldo. 2024. Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html",
    "href": "chapters/chapter_3/06_density_func.html",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Introduction\nIn precedenza abbiamo trattato solo variabili casuali discrete, ossia variabili che assumono solo valori interi. Tuttavia, se vogliamo rappresentare grandezze come lunghezze, volumi, distanze o qualsiasi altra propriet√† continua del mondo fisico o psicologico, √® necessario generalizzare l‚Äôapproccio utilizzato finora.\nLe variabili casuali continue assumono valori reali, e l‚Äôinsieme dei numeri reali √® non numerabile in quanto √® pi√π grande dell‚Äôinsieme degli interi.1 Le leggi della probabilit√† valgono sia per le variabili casuali discrete che per quelle continue. Tuttavia, la nozione di funzione di massa di probabilit√† deve essere sostituita dal suo equivalente continuo, la funzione di densit√† di probabilit√†. In questo capitolo, il nostro obiettivo √® chiarire il significato di questa nozione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "chapters/chapter_3/06_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "29.1 Spinner e variabili casuali continue uniformi",
    "text": "29.1 Spinner e variabili casuali continue uniformi\nConsideriamo l‚Äôesperimento casuale in cui facciamo ruotare ad alta velocit√† uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma, identificata dall‚Äôangolo acuto con segno tra il suo asse e l‚Äôasse orizzontale del goniometro. Denotiamo con \\(\\Theta\\) la variabile casuale corrispondente alla ‚Äúpendenza dello spinner‚Äù. In questo contesto, l‚Äôassunzione che lo spinner sia simmetrico implica che, in ogni prova, la rotazione produce un angolo qualunque da 0 a 360 gradi con la stessa probabilit√†. In altre parole, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilit√† di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, dal momento che 36 gradi corrisponde a un decimo del percorso intorno al cerchio, la probabilit√† di ottenere un qualsiasi intervallo di 36 gradi sar√† sempre uguale al 10%. Pi√π precisamente, si ha \\(P(0 \\leq \\Theta \\leq 36) = \\frac{1}{10}\\) e \\(P(200 \\leq \\Theta \\leq 236) = \\frac{1}{10}\\).\n√à importante sottolineare che le probabilit√† sopra menzionate non si riferiscono al fatto che la variabile casuale \\(\\Theta\\) assuma un valore specifico, ma piuttosto all‚Äôevento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilit√† che la pendenza \\(\\Theta\\) cada in un intervallo specificato √® data dalla frazione del cerchio rappresentata dall‚Äôintervallo, cio√® \\(P(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}\\), per ogni intervallo \\([\\theta_1, \\theta_2]\\) tale che \\(0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360\\).\nNel caso di una variabile casuale continua, come l‚Äôangolo dello spinner, dunque, √® facile capire come assegnare una probabilit√† all‚Äôevento in cui la variabile casuale assuma un valore compreso in un intervallo.\n\n29.1.1 Distribuzione uniforme\nL‚Äôesempio dello spinner rappresenta il ‚Äúmeccanismo generatore dei dati‚Äù della variabile casuale continua pi√π semplice, ovvero la distribuzione continua uniforme. In teoria della probabilit√†, la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna la stessa probabilit√† a tutti i punti appartenenti ad un intervallo [a, b] contenuto in un certo insieme.\nLa distribuzione uniforme continua definita sull‚Äôintervallo \\({\\displaystyle S=[a,b]\\subset \\mathbb {R}}\\) viene denotata con \\({\\displaystyle {\\mathcal {U}}(a,b)={\\mathcal {U}}([a,b])}\\). La sua densit√† di probabilit√† √®\n\\[\nf(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n\\]\ne 0 altrimenti. La distribuzione uniforme continua √® caratterizzata dalla sua propriet√† di equidistribuzione: tutti gli intervalli di pari lunghezza all‚Äôinterno dell‚Äôintervallo [a, b] hanno la stessa probabilit√†. In altre parole, se \\({\\displaystyle [c,d]}\\) √® un sottointervallo di \\({\\displaystyle [a,b]}\\), allora la probabilit√† che una variabile casuale continua con distribuzione uniforme in \\({\\displaystyle [a,b]}\\) cada in \\({\\displaystyle [c,d]}\\) √® \\({\\displaystyle (d-c)/(b-a)}\\).\nSvolgiamo un esercizio con Python in cui, per continuare il nostro esempio dello spinner, consideriamo una \\(\\mathcal {U}(0, 360)\\).\n\na = 0\nb = 360\nsize = 101\nx = np.linspace(a, b, size)\ny = st.uniform.pdf(x, loc=a, scale=b)\n\nplt.figure()\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.ylabel(\"Densit√†\");\n\n\n\n\n\n\n\n\nGeneriamo 100,000 valori casuali di una v.c. \\(\\Theta \\sim \\mathcal {U}(0, 360)\\).\n\ndata = rng.uniform(0, 360, size=100000)\n\nL‚Äôistogramma delle 100,000 realizzazioni di \\(\\Theta\\) √® il seguente.\n\nplt.figure()\nplt.hist(data, density=True, alpha=0.5)\nplt.xlabel(\"Theta ~ U[0, 360]\")\nplt.ylabel(\"Densit√†\")\nplt.title(\"Distribuzione uniforme\")\nplt.show()\n\n\n\n\n\n\n\n\n√à chiaro che, all‚Äôaumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell‚Äôistogramma tender√† a diventare una linea retta. Ci√≤ significa che la funzione di densit√† di una variabile casuale uniforme continua √® una costante: \\(f(\\Theta) = c\\).\nDalla figura precedente vediamo che l‚Äôarea sottesa alla funzione di densit√† √® \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densit√† di una variabile casuale uniforme continua non dipende da \\(\\theta\\) ‚Äì √® costante e identica per ogni possibile valore \\(\\theta\\).\nIl valore atteso di \\(X \\sim \\mathcal {U}(a,b)\\) √® dato da\n\\[\n\\mathbb{E} = \\frac{b - a}{2}.\n\\]\nNel caso della presente simulazione otteniamo\n\ndata.mean()\n\n180.44171561785456\n\n\nSvolgiamo un altro semplice esercizio. Consideriamo una variabile casuale uniforme \\(X\\) definita sull‚Äôintervallo [0, 100]. Poniamoci il problema di trovare la probabilit√† \\(P(20 &lt; X &lt; 60)\\).\nPer trovare la soluzione √® sufficiente calcolare l‚Äôarea di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilit√† cercata √® dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/chapter_3/06_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "29.2 Il paradosso delle variabili casuali continue",
    "text": "29.2 Il paradosso delle variabili casuali continue\nConsideriamo ora la probabilit√† che la variabile casuale continua assuma un valore specifico, come ad esempio una pendenza dello spinner esattamente uguale a 36 gradi. Sorprendentemente, la risposta √® zero:\n\\[\nP(\\Theta = 36) = 0.\n\\]\nCi√≤ √® dovuto al fatto che se la probabilit√† di un valore specifico fosse maggiore di zero, allora ogni altro possibile valore dovrebbe avere la stessa probabilit√†, poich√© abbiamo assunto che tutti i valori \\(\\Theta\\) sono egualmente probabili. Ma se sommiamo tutte queste probabilit√†, il totale sarebbe maggiore di uno, il che √® impossibile.\nNel caso delle variabili casuali continue, dobbiamo quindi rinunciare all‚Äôidea che ogni singolo valore della variabile casuale possa avere una massa di probabilit√† maggiore di zero. Invece, una massa di probabilit√† viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. Questo √® ci√≤ che differenzia le variabili casuali continue dalle variabili casuali discrete, dove ogni singolo valore ha una probabilit√† di massa non nulla. In sintesi, le variabili casuali continue non hanno una massa di probabilit√†, ma una densit√† di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#dagli-istogrammi-alle-densit√†",
    "href": "chapters/chapter_3/06_density_func.html#dagli-istogrammi-alle-densit√†",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "29.3 Dagli istogrammi alle densit√†",
    "text": "29.3 Dagli istogrammi alle densit√†\nLe considerazioni precedenti ci fanno comprendere che, a differenza delle variabili casuali discrete, non esiste l‚Äôequivalente di una funzione di massa di probabilit√† per le variabili casuali continue. Invece, esiste una funzione di densit√† di probabilit√† che pu√≤ essere definita in termini di una simulazione. Considerando un numero enorme di casi e facendo tendere l‚Äôampiezza \\(\\Delta\\) di ciascuna classe a 0, il profilo dell‚Äôistogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) √® detta funzione di densit√† di probabilit√†.\nIn un istogramma, l‚Äôarea di ogni barra √® proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo considerato. Dato che tutti gli intervalli hanno la stessa ampiezza, l‚Äôaltezza di ogni barra sar√† proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo. Nella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore nell‚Äôintervallo considerato. Con l‚Äôaumentare del numero di osservazioni \\(M\\), le probabilit√† stimate si avvicinano sempre di pi√π ai valori effettivi della probabilit√†. Inoltre, all‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo tende a 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® appunto la funzione di densit√† di probabilit√† della variabile casuale.\nIn precedenza, nella statistica descrittiva, abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico utilizzato per stimare la funzione di densit√† di probabilit√† di una variabile casuale.\nPer fare un esempio, generiamo 50 valori dalla distribuzione del quoziente di intelligenza. Stampiamo i primi 5 valori.\n\nmu, sigma = 100, 15\nsize = 50\nx = rng.normal(loc=mu, scale=sigma, size=size)\nx[:5]\n\narray([ 91.33354594, 104.82329102, 112.23027301, 123.44901535,\n        98.12903873])\n\n\nCreiamo ora un istogramma a cui sovrapponiamo la funzione di densit√† Normale con parametri corrispondenti alla media e deviazione standard del campione. Con poche osservazioni, non c‚Äô√® una buona corrispondenza tra l‚Äôistogramma e la curva continua che abbiamo chiamato ‚Äúfunzione di densit√†‚Äù.\n\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=25, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.58 e 13.34')\n\n\n\n\n\n\n\n\n\nOra aumentiamo il numero di osservazioni. In questo caso consideriamo 20,000 valori del QI. Generiamo dunque una figura simile alla precedente, solo considerando un campione di dati pi√π grande.\n\nsize = 10000\nx = rng.normal(loc=mu, scale=sigma, size=size)\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=50, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.39 e 15.05')\n\n\n\n\n\n\n\n\n\nOra vediamo che c‚Äô√® una corrispondenza molto buona tra il profilo dell‚Äôistogramma e la curva continua. Questo ci consente la seguente interpretazione: la funzione di densit√† √® una curva che approssima il profilo di un istogramma, quando consideriamo un grande numero di osservazioni. In altre parole, una funzione di densit√† non √® altro che un (profilo di un) istogramma nel caso di un numero infinito di osservazioni e intervalli di ampiezza \\(\\Delta\\) infinitamente piccoli.\nIn un istogramma, l‚Äôarea di ciascuna barra √® proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo. Perch√© tutti gli intervalli hanno la stessa ampiezza, anche l‚Äôaltezza di ciascuna barra sar√† proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo.\nNella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore compreso nell‚Äôintervallo considerato. All‚Äôaumentare del numero \\(M\\) di osservazioni, le probabilit√† stimate si avvicinano sempre di pi√π ai veri valori della probabilit√†. All‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo \\(\\rightarrow\\) 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® la funzione di densit√† di probabilit√† della variabile casuale.\nNella statistica descrittiva abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico per stimare la funzione di densit√† di probabilit√† di una variabile casuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "href": "chapters/chapter_3/06_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "29.4 Funzione di densit√† di probabilit√†",
    "text": "29.4 Funzione di densit√† di probabilit√†\nDa un punto di vista matematico, l‚Äôintuizione precedente si pu√≤ esprimere nel modo seguente.\nPer descrivere le probabilit√† che possono essere associate ad una variabile casuale continua \\(X\\) √® necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due propriet√†:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l‚Äôordinata della funzione di densit√† √® 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l‚Äôarea sottesa dalla \\(p(x)\\) √® unitaria2;\n\\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l‚Äôarea sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilit√† che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. √à possibile che \\(p(x) &gt; 1\\), quindi una densit√† di probabilit√† non pu√≤ essere interpretata come una probabilit√†. Piuttosto, la densit√† \\(p(x)\\) pu√≤ essere utilizzata per confrontare la credibilit√† relativa che pu√≤ essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui √® disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che √® pi√π credibile, in termini relativi, osservare realizzazioni \\(X\\) nell‚Äôintorno di \\(x_k\\) piuttosto che nell‚Äôintorno di \\(x_l\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/chapter_3/06_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "29.5 La funzione di ripartizione per una variabile casuale continua",
    "text": "29.5 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) √® definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCio√®, √® la probabilit√† che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua pu√≤ essere utilizzata per calcolare la probabilit√† che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/06_density_func.html#informazioni-sullambiente-di-sviluppo",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "29.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "29.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.3\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#footnotes",
    "href": "chapters/chapter_3/06_density_func.html#footnotes",
    "title": "29¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Georg Cantor dimostr√≤ che era impossibile mappare uno a uno i reali negli interi, dimostrando cos√¨ che l‚Äôinsieme dei reali √® non numerabile.‚Ü©Ô∏é\nPer quel che riguarda la notazione dell‚Äôintegrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html‚Ü©Ô∏é",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html",
    "href": "chapters/chapter_3/07_discr_rv_distr.html",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esploreremo le distribuzioni di probabilit√† discrete, che sono fondamentali per la comprensione dei fenomeni aleatori con un numero finito o numerabile di esiti.\nOgni distribuzione di probabilit√† pu√≤ essere parametrizzata specificando dei parametri che permettono di controllare certi aspetti della distribuzione per raggiungere un obiettivo specifico.\nInizieremo con la distribuzione Bernoulliana, che rappresenta esperimenti con due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù. Questi esperimenti costituiscono il nucleo di ci√≤ che √® definito un processo Bernoulliano. Il parametro della distribuzione Bernoulliana √® la probabilit√† di successo in ciascuna prova.\nQuando tali prove Bernoulliane vengono ripetute per un numero fisso di volte \\(n\\), il conteggio totale dei successi segue una distribuzione binomiale. Anche la distribuzione binomiale dipende da un parametro, la probabilit√† di successo in ciascuna singola prova. Questa distribuzione nasce dalla somma di prove Bernoulliane indipendenti, quando il numero totale di prove \\(n\\) √® stabilito in anticipo.\nSe, invece, il numero stesso di prove diventa una variabile casuale, la distribuzione dei successi all‚Äôinterno di questa serie di prove segue la distribuzione di Poisson. Questa distribuzione √® particolarmente adatta a modellare eventi che avvengono raramente o su intervalli variabili. La distribuzione di Poisson dipende da un unico parametro: il tasso medio di successo per unit√† di tempo o spazio.\nSe la probabilit√† di successo in una serie di prove Bernoulliane non √® costante, ma varia seguendo una distribuzione Beta, il numero di successi osservati in \\(N\\) prove non seguir√† pi√π la distribuzione binomiale, ma seguir√† invece la distribuzione Beta-Binomiale. Questa distribuzione offre una rappresentazione pi√π flessibile e aderente alla realt√† in alcuni contesti.\nInfine, esamineremo la distribuzione uniforme discreta, dove ogni evento all‚Äôinterno di un determinato intervallo finito ha la stessa probabilit√† di verificarsi. Questa distribuzione √® particolarmente utile quando non esistono motivi per privilegiare un risultato rispetto a un altro. La distribuzione uniforme √® molto specifica e non dipende da alcun parametro: una volta stabilito il supporto della distribuzione, c‚Äô√® un unico modo per assegnare le probabilit√† agli eventi.\nIn sintesi, attraverso queste distribuzioni, possiamo modellare e analizzare matematicamente una vasta gamma di situazioni reali, fornendo strumenti utili per comprendere e prevedere fenomeni aleatori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-bernoulliana",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-bernoulliana",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "30.1 Distribuzione Bernoulliana",
    "text": "30.1 Distribuzione Bernoulliana\nIn statistica, un esperimento che presenta soltanto due esiti possibili viene modellato attraverso ci√≤ che √® noto come ‚Äúprova Bernoulliana‚Äù. Un esempio classico √® il lancio di una moneta, che pu√≤ risultare in testa o croce.\n\nDefinizione 30.1 Una variabile casuale \\(Y\\) che assume valori in \\(\\{0, 1\\}\\) √® definita come variabile di Bernoulli. La sua distribuzione di probabilit√† √® descritta come segue:\n\\[\nP(Y \\mid \\theta) =\n  \\begin{cases}\n    \\theta     & \\text{se $Y = 1$ (successo)}, \\\\\n    1 - \\theta & \\text{se $Y = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq \\theta \\leq 1\\). Il parametro \\(\\theta\\) rappresenta la probabilit√† dell‚Äôevento ‚Äúsuccesso‚Äù (\\(Y = 1\\)), mentre \\(1 - \\theta\\) quella dell‚Äôevento ‚Äúinsuccesso‚Äù (\\(Y = 0\\)).\n\nNella distribuzione Bernoulliana, la probabilit√† di osservare l‚Äôesito 1 √® \\(\\theta\\), mentre quella di osservare 0 √® \\(1 - \\theta\\). Questa distribuzione viene utilizzata per modellare situazioni in cui esistono due sole possibili risposte, come un ‚Äús√¨‚Äù o un ‚Äúno‚Äù, un ‚Äúsuccesso‚Äù o un ‚Äúinsuccesso‚Äù.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\\n\\mathbb{V}(Y) &= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta).\n\\end{align}\n\\tag{30.1}\\]\nEsplicitando ulteriormente la formula della varianza con \\(P(Y=0) = 1 - \\theta\\) e \\(P(Y=1) = \\theta\\), abbiamo:\n\\[ \\mathbb{V}(Y) = (0 - \\theta)^2 \\cdot (1 - \\theta) + (1 - \\theta)^2 \\cdot \\theta \\]\nCalcoliamo ora le singole parti dell‚Äôespressione: 1. $ (0 - )^2 = ^2 $ 2. $ (1 - )^2 = 1 - 2+ ^2 $\nSostituendo queste espressioni nell‚Äôequazione della varianza, otteniamo:\n\\[ \\mathbb{V}(Y) = \\theta^2 \\cdot (1 - \\theta) + (1 - 2\\theta + \\theta^2) \\cdot \\theta \\]\n\\[ \\mathbb{V}(Y) = \\theta^2 - \\theta^3 + \\theta - 2\\theta^2 + \\theta^3 \\]\nSemplificando:\n\\[ \\mathbb{V}(Y) = \\theta - \\theta^2 \\]\n\\[ \\mathbb{V}(Y) = \\theta(1-\\theta) \\]\nQuindi, l‚Äôequazione iniziale mostra come la varianza di una variabile casuale binaria \\(Y\\), che segue una distribuzione di Bernoulli con parametro \\(\\theta\\), sia espressa come \\(\\theta(1-\\theta)\\). Questo rispecchia il fatto che la varianza di una distribuzione di Bernoulli raggiunge il suo massimo quando \\(\\theta = 0.5\\), indicando la massima incertezza (o variabilit√†) quando la probabilit√† di successo √® uguale a quella di fallimento.\n\n# Define theta values between 0 and 1\ntheta = np.linspace(0, 1, 100)\n\n# Variance of a Bernoulli distribution is theta(1-theta)\nvariance = theta * (1 - theta)\n\nplt.plot(theta, variance, label='Varianza', color='blue')\nplt.title('Varianza di una variabile Bernoulliana in funzione di $\\\\theta$')\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Varianza')\nplt.show()\n\n\n\n\n\n\n\n\nUtilizziamo la notazione \\(Y \\sim Bernoulli(\\theta)\\) per indicare che la variabile casuale \\(Y\\) segue una distribuzione Bernoulliana di parametro \\(\\theta\\).\nAd esempio, nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilit√† di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilit√† assegna una probabilit√† di \\(\\frac{1}{2}\\) sia per \\(Y = 0\\) che per \\(Y = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-binomiale",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "30.2 Distribuzione Binomiale",
    "text": "30.2 Distribuzione Binomiale\nLa distribuzione binomiale √® una distribuzione di probabilit√† discreta fondamentale, che si concentra sul conteggio del numero di successi in una serie di prove Bernoulliane indipendenti. Queste prove sono caratterizzate dal fatto che ogni evento ha solo due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù, con una probabilit√† di successo costante denotata da \\(\\theta\\).\n\nDefinizione 30.2 La distribuzione binomiale quantifica la probabilit√† di osservare esattamente \\(y\\) successi in \\(n\\) tentativi indipendenti di Bernoulli:\n\\[\nP(Y=y) = \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} = \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y},\n\\] (eq-binomialdistribution)\nQui, \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di combinazioni possibili per ottenere \\(y\\) successi in \\(n\\) prove, mentre \\(\\theta\\) √® la probabilit√† costante di successo per ogni prova.\n\nLa distribuzione binomiale √® spesso illustrata con esempi come il lancio di una moneta o l‚Äôestrazione da un‚Äôurna. Ad esempio, nel caso del lancio ripetuto di una moneta, questa distribuzione descrive la probabilit√† di ottenere un numero specifico di teste in un certo numero di lanci, con ciascun lancio che segue una distribuzione di Bernoulli con probabilit√† di successo \\(\\theta\\).\nUn aspetto interessante della distribuzione binomiale √® la sua propriet√† di riproducibilit√†: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\), ma con diversi numeri di prove (\\(N_1\\) e \\(N_2\\)), allora la loro somma, \\(y = y_1 + y_2\\), sar√† anch‚Äôessa distribuita binomialmente, con parametri \\(N_1 + N_2\\) e \\(\\theta\\).\n\n30.2.1 Calcolo delle Probabilit√†\nPer approfondire il calcolo delle probabilit√† in questa distribuzione, esaminiamo una serie di prove Bernoulliane. Consideriamo una serie di \\(n\\) prove che risultano in \\(y\\) successi:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots I}^\\text{$n-y$ volte}\n\\]\nOgni sequenza con \\(y\\) successi specifici ha una probabilit√† di \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\). Tuttavia, siamo interessati alla probabilit√† complessiva di osservare qualsiasi sequenza con \\(y\\) successi, che si ottiene moltiplicando la probabilit√† di una sequenza singola per il numero totale di sequenze possibili, dato dal coefficiente binomiale \\(\\binom{n}{y}\\).\nIn questo modo, la distribuzione binomiale diventa uno strumento statistico per analizzare fenomeni che presentano esiti binari, con prove che sono indipendenti e identicamente distribuite. Questa distribuzione trova applicazione in una moltitudine di scenari, dalla valutazione del numero di successi in una serie di tentativi, come i lanci di moneta, fino a sondaggi di opinione e altro ancora.\n\n\n30.2.2 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l‚Äôapplicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilit√† di successo in ogni prova √® \\(\\theta = 0.2\\). La probabilit√† di ottenere questo risultato specifico √® calcolata utilizzando l‚Äôeq. {eq}eq-binomialdistribution:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo pu√≤ essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\nn = 4\ntheta = 0.2\ny = 2\n\nprob = math.comb(n, y) * theta**y * (1 - theta) ** (n - y)\nprint(prob)\n\n0.15360000000000007\n\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\nstats.binom.pmf(y, n, theta)\n\n0.15359999999999993\n\n\nUtilizzando scipy.stats.binom.pmf(y, n, p), possiamo trovare le probabilit√† per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\ny = np.arange(0, n + 1)\nprint(y)\n\n[0 1 2 3 4]\n\n\n\nprobabilities = stats.binom.pmf(y, n, theta)\nprint(*probabilities)\n\n0.40959999999999985 0.4096 0.15359999999999993 0.02559999999999999 0.0016000000000000003\n\n\nVisualizziamo la distribuzione di massa di probabilit√†:\n\nplt.figure()\nplt.plot(y, probabilities, \"o\", ms=8)\nplt.vlines(y, 0, probabilities, linestyles=\"-\", lw=1)\nplt.title(f\"Distribuzione binomiale: $n$={n}, $\\\\theta$={theta}\")\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.xlim(-0.5, n + 0.5)\nplt.ylim(0, max(probabilities) + 0.05)\nplt.show()\n\n\n\n\n\n\n\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilit√† di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\nplt.figure()\n\nfor theta in np.arange(0.3, 1.0, 0.3):\n    y = np.arange(0, 25)\n    binom_dist = stats.binom.pmf(y, 20, theta)\n    plt.plot(y, binom_dist, \"-o\", label=f\"theta = {theta:.1f}\")\n\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.title(\"Distribuzione binomiale al variare di $\\\\theta$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nUn‚Äôaltra propriet√† interessante della distribuzione binomiale √® la sua riproducibilit√†. Se abbiamo due variabili casuali indipendenti che seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\) ma con diversi numeri di prove, la loro somma seguir√† anch‚Äôessa una distribuzione binomiale. Questo pu√≤ essere dimostrato analiticamente o sperimentato empiricamente.\n\n# Parameters\nn1, n2 = 10, 15  # Number of trials\ntheta = 0.5  # Success probability\n\n# Analytical binomial distributions\nx1 = np.arange(0, n1+1)\ny1 = stats.binom.pmf(x1, n1, theta)\nx2 = np.arange(0, n2+1)\ny2 = stats.binom.pmf(x2, n2, theta)\n\n# Combined analytical distribution\nx_combined = np.arange(0, n1+n2+1)\ny_combined = stats.binom.pmf(x_combined, n1+n2, theta)\n\n# Simulated distributions\nsimulated1 = rng.binomial(n1, theta, 10000)\nsimulated2 = rng.binomial(n2, theta, 10000)\nsimulated_combined = simulated1 + simulated2\n\n# Plotting\nplt.figure(figsize=(18, 6))\n\n# Plot 1: Binomial 1\nplt.subplot(1, 3, 1)\nplt.bar(x1, y1, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated1, bins=range(n1+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n1}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.ylabel('Probability')\nplt.legend()\n\n# Plot 2: Binomial 2\nplt.subplot(1, 3, 2)\nplt.bar(x2, y2, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated2, bins=range(n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\n# Plot 3: Combined Binomial\nplt.subplot(1, 3, 3)\nplt.bar(x_combined, y_combined, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated_combined, bins=range(n1+n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Combined Binomial Distribution n={n1+n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual √® la probabilit√† che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\nstats.binom.pmf(2, n=5, p=0.5) + stats.binom.pmf(3, n=5, p=0.5) + stats.binom.pmf(4, n=5, p=0.5) +  stats.binom.pmf(5, n=5, p=0.5)\n\n0.8125\n\n\n\nnp.sum([stats.binom.pmf(k, n=5, p=0.5) for k in range(2, 6)])\n\n0.8125\n\n\nPi√π facilmente, si trova la risposta usando la funzione di ripartizione stats.binom.cdf.\n\n1 - stats.binom.cdf(1, n=5, p=0.5) \n\n0.8125\n\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\nn = 5\ntheta = 0.5\ny = np.arange(0, n+1)\n\nplt.figure()\nplt.plot(y, stats.binom.cdf(y, n=n, p=theta))\nplt.scatter(y, stats.binom.cdf(y, n=n, p=theta))\nplt.axhline(1, color=\"k\", alpha=0.7, linestyle=\"--\", lw=1)\nplt.title(f\"Funzione di ripartizione binomiale: $n$={n}, $\\\\theta$={theta}\", loc=\"left\")\nplt.xlabel(\"y\")\n_ = plt.ylabel(\"Probabilit√†\")\n\n\n\n\n\n\n\n\nUn‚Äôaltra funzione utile √® quella che trova il numero di successi in una distribuzione binomiale che corrisponde ad una data probabilit√† (nella coda sinistra della funzione ripartizione). Per l‚Äôesempio presente:\n\ntarget_probability = 1 - 0.8125\nstats.binom.ppf(target_probability, n, theta)\n\n1.0\n\n\nUtilizzando la funzione punto percentuale (PPF), che √® l‚Äôinverso della funzione di distribuzione cumulativa (CDF), possiamo trovare il numero di successi corrispondente alla probabilit√† target di \\(1 - 0.8125 = 0.1875\\) in una distribuzione binomiale con parametri \\(n = 5\\) e \\(\\theta = 0.5\\). Il risultato mostra che il numero di successi cercato per questa probabilit√† target √® 1.\nFacciamo un altro esempio. Consideriamo la probabilit√† cumulativa \\(P(Y \\leq 4)\\) per una variabile casuale \\(Y\\) che segue una distribuzione binomiale con numero di prove \\(n = 10\\) e probabilit√† di successo \\(\\theta = 0.2\\). La funzione stats.binom.cdf(4, n=10, p=0.2) calcola la probabilit√† che ci siano al massimo 4 successi in 10 tentativi, dove la probabilit√† di successo in ogni tentativo √® del 20%.\n\ntarget_probability = stats.binom.cdf(4, n=10, p=0.2)\ntarget_probability\n\n0.9672065024\n\n\nDi conseguenza, la funzione inversa √®:\n\nstats.binom.ppf(target_probability, n=10, p=0.2)\n\n4.0\n\n\nPer generare una sequenza di valori casuali seguendo una distribuzione binomiale possiamo utilizzare la funzione random() di NumPy. Dopo aver inizializzato rng = np.random.default_rng(RANDOM_SEED), per esempio,\n\nrng = np.random.default_rng(42)\n\npossiamo impiegare rng per generare valori casuali da una distribuzione binomiale:\n\nx = rng.binomial(p=.5, n=5, size=30)\nprint(*x)\n\n3 5 1 2 3 2 3 3 3 1 2 4 2 3 0 2 2 2 3 3 4 4 2 0 4 2 2 1 3 2\n\n\nPer una discussione sulla generazione di numeri pseudo-casuali in Python, si veda il capitolo {ref}appendix-rng.\n\n\n30.2.3 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si trovano nel modo seguente:\n\\[\n\\begin{align}\n\\mu    &= n\\theta,  \\notag \\\\\n\\sigma &= \\sqrt{n\\theta(1-\\theta)}.\n\\end{align}\n\\tag{30.2}\\]\nDimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), √® facile vedere che\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = n\\theta, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = n \\theta (1-\\theta).\n\\end{align}\n\\]\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilit√† di ottenere testa (successo) pari a \\(\\theta = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo √® dato da \\(\\mu = n \\theta\\), dove \\(n\\) √® il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(\\theta = 0.2\\), abbiamo:\n\\[\n\\mu = n \\theta = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale √® calcolata come \\(n \\theta (1-\\theta)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n \\theta (1-\\theta) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nx = rng.binomial(p=.2, n=4, size=1000000)\n\n\nnp.mean(x)\n\n0.79956\n\n\n\nnp.var(x, ddof=0)\n\n0.6397598064000003\n\n\n\n\n30.2.4 Funzioni Python associate alle distribuzioni di probabilit√†\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (y | n, Œ∏)\nEsempio: Normale (y | Œº, œÉ)\n\n\n\n\nFunzione di verosimiglianza\nbinom.pmf(y, n, Œ∏)\nnorm.pdf(y, Œº, œÉ)\n\n\nProb Y=y\nbinom.pmf(y, n, Œ∏)\nsempre 0\n\n\nProb Y ‚â• y, Y ‚â§ y, y1 &lt; Y &lt; y2\nbinom.cdf(y, n, Œ∏) o binom.sf(y, n, Œ∏)\nnorm.cdf(y, Œº, œÉ) o norm.sf(y, Œº, œÉ)\n\n\nInversa della CDF\nbinom.ppf(q, n, Œ∏)\nnorm.ppf(q, Œº, œÉ)\n\n\nGenerazione di dati simulati\nrng.binomial(p, n, size)\nrng.normal(Œº, œÉ, size\n\n\n\nIn seguito, utilizzeremo altre distribuzioni, come Uniforme, Beta, ecc., e ognuna di queste ha il proprio insieme di funzioni in Python trovate in scipy.stats. √à possibile consultare queste diverse distribuzioni in opere di riferimento o documentazione online.\nSi noti che pmf (funzione di massa di probabilit√†) √® usato per le distribuzioni discrete come la binomiale, mentre pdf (funzione di densit√† di probabilit√†) √® usata per le distribuzioni continue come la normale. cdf (funzione di distribuzione cumulativa) e sf (funzione di sopravvivenza, che √® 1 - cdf) sono utilizzate per calcolare le probabilit√† cumulative. ppf (percent point function) √® l‚Äôinverso della cdf e viene utilizzata per determinare il valore di variabile al di sotto del quale cade una certa percentuale delle osservazioni. rvs (random variates) √® usata per generare dati simulati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "30.3 Distribuzione Discreta Uniforme",
    "text": "30.3 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme √® un tipo particolare di distribuzione di probabilit√†, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilit√† \\(p\\) di verificarsi. Questa distribuzione √® caratterizzata dalla sua semplicit√† e dalla sua propriet√† fondamentale di equiprobabilit√†.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che pu√≤ assumere valori nell‚Äôinsieme \\(\\{1, 2, \\dots, N\\}\\). Un‚Äôistanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilit√† di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilit√† che \\(X\\) assuma un valore specifico \\(x\\) √® uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilit√† di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci d√† un‚Äôidea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che √® la somma dei primi \\(N\\) numeri naturali. Questa somma √® data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) √® \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo √® calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilit√† (che √® \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l‚Äôidentit√† per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo gi√† stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l‚Äôespressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) √® \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-di-poisson",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-di-poisson",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "30.4 Distribuzione di Poisson",
    "text": "30.4 Distribuzione di Poisson\nLa distribuzione di Poisson √® utilizzata per modellare il numero di eventi indipendenti che si verificano in un intervallo di tempo o spazio prefissato. La variabile casuale discreta \\(Y\\) denota il numero di tali eventi, mentre il parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza di questi eventi in un intervallo specifico.\nLa funzione di massa di probabilit√† associata alla distribuzione di Poisson, che indica la probabilit√† che si verifichino esattamente \\(y\\) eventi, √® definita come segue:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\tag{30.3}\\]\nQuesta equazione illustra:\n\n\\(P(Y = y \\mid \\lambda)\\), la probabilit√† che esattamente \\(y\\) eventi si verifichino.\n\\(\\lambda\\), il tasso medio di occorrenza degli eventi per l‚Äôintervallo considerato.\n\\(y\\), il numero di eventi, che √® limitato ai valori interi non negativi.\n\nUna peculiarit√† della distribuzione di Poisson √® che sia il valore atteso (\\(E[Y]\\)) sia la varianza (\\(Var[Y]\\)) sono equivalenti a \\(\\lambda\\). Questo significa che con l‚Äôaumentare del valore di \\(\\lambda\\), aumenta anche la dispersione dei dati attorno al valore medio, evidenziando un incremento della variabilit√† degli eventi.\nQuale esempio, presentiamo qui sotto un grafico con la distribuzione di Poisson di parametro \\(\\lambda\\) = 2.\n\n# Tasso medio di occorrenza di eventi\nlambda_value = 2\n\n# Creazione della distribuzione di Poisson con il tasso medio specificato\npoisson_dist = stats.poisson(mu=lambda_value)\n\n# Calcolo della probabilit√† di avere un certo numero di eventi\nk_values = range(0, 11)  # Consideriamo valori da 0 a 10\n\n# Calcolo delle probabilit√† corrispondenti\nprobabilities = poisson_dist.pmf(k_values)\n\nplt.figure()\n\n# Plot della distribuzione di massa di probabilit√†\nplt.bar(k_values, probabilities, alpha=0.5)\nplt.xlabel('Numero di Eventi (k)')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione di Massa di Probabilit√† di Poisson')\nplt.show()\n\n\n\n\n\n\n\n\nLa probabilit√† di ottenere un singolo valore \\(y\\) si calcola utilizzando la funzione di massa di probabilit√† (pmf), dove l‚Äôargomento k rappresenta il numero di eventi (\\(y\\)) e mu √® uguale a \\(\\lambda\\). Ad esempio, per determinare la probabilit√† di osservare esattamente tre eventi (\\(y = 3\\)) con un tasso di occorrenza \\(\\lambda\\) = 2, indicata come \\(P(Y = 3)\\), si utilizza la seguente istruzione:\n\nstats.poisson.pmf(k=3, mu=2)\n\n0.18044704431548356\n\n\nLa probabilit√† di non pi√π di 3 eventi, indicata come \\(P(Y \\leq 3)\\), si ottiene nel modo seguente:\n\np = stats.poisson.pmf(k=0, mu=2) + stats.poisson.pmf(k=1, mu=2) + stats.poisson.pmf(k=2, mu=2) + stats.poisson.pmf(k=3, mu=2)\np\n\n0.857123460498547\n\n\nLa funzione ppf, con la probabilit√† e \\(\\lambda\\) come argomenti, restituisce il quantile della distribuzione di Poisson. Ad esempio, nel caso precedente, abbiamo:\n\nstats.poisson.ppf(p, mu=2)\n\n3.0\n\n\nLa funzione di distribuzione cumulativa si calcola utilizzando cdf. Ad esempio, per calcolare \\(P(Y \\leq 3)\\) si utilizza:\n\nstats.poisson.cdf(3, mu=2)\n\n0.857123460498547\n\n\nLa generazione di numeri casuali dalla distribuzione di Poisson pu√≤ essere ottenuta utilizzando rng. Ad esempio:\n\nmu = 2\nx = rng.poisson(mu, 1000000)\n\nVerifichiamo:\n\nnp.mean(x)\n\n1.998219\n\n\n\nnp.var(x, ddof=0)\n\n1.996941828039\n\n\nEsempio. I dati provenienti dal reparto di maternit√† di un certo ospedale mostrano che c‚Äô√® una media storica di 4.5 bambini nati in questo ospedale ogni giorno. Qual √® la probabilit√† che domani nascano 6 bambini in questo ospedale?\nPer prima cosa, calcoliamo la probabilit√† teorica di questo evento utilizzando dpois(). Il numero di successi che stiamo considerando √® 6, quindi imposteremo x = 6. Inoltre, questa media storica di 4,5 nascite al giorno √® il nostro valore per lambda, quindi imposteremo lambda = 6.\n\np = stats.poisson.pmf(k=6, mu=4.5)\nprint(f\"La probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: {p:.4f}\")\n\nLa probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: 0.1281\n\n\nSimuliamo le nascite in questo ospedale per un anno (n = 365) utilizzando la funzione np.random.poisson e confrontiamo la proporzione di giorni in cui ci sono stati 6 nascite con la probabilit√† teorica che abbiamo calcolato in precedenza.\n\n# Simuliamo le nascite in un anno (365 giorni) con una media storica di 4.5 nascite al giorno\nn_days = 365\nmean_births_per_day = 4.5\nsimulated_births = rng.poisson(mean_births_per_day, n_days)\n\n# Calcoliamo la proporzione di giorni in cui sono nati esattamente 6 bambini nella simulazione\nproportion_six_births = np.mean(simulated_births == 6)\n\n# Stampiamo la proporzione calcolata\nprint(f\"La proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: {proportion_six_births:.4f}\")\n\nLa proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: 0.0959\n\n\nVisualizziamo i risultati della simulazione.\n\n# Visualizziamo l'istogramma delle nascite simulate\nplt.hist(simulated_births, bins=np.arange(12) - 0.5, density=True, alpha=0.5)\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\nplt.xticks(np.arange(11));\n\n\n\n\n\n\n\n\nCalcoliamo la probabilit√† teorica della nascita di pi√π di 6 bambini in un giorno.\n\nprob_more_than_six = 1 - stats.poisson.cdf(6, mean_births_per_day)\nprint(f\"La probabilit√† teorica di pi√π di 6 bambini nati √®: {prob_more_than_six:.4f}\")\n\nLa probabilit√† teorica di pi√π di 6 bambini nati √®: 0.1689\n\n\nCalcoliamo la proporzione corrispondente nella simulazione\n\nproportion_more_than_six = np.mean(simulated_births &gt; 6)\nprint(f\"La proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: {proportion_more_than_six:.4f}\")\n\nLa proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: 0.1836\n\n\n\nbins = np.arange(12) - 0.5\nhist, edges = np.histogram(simulated_births, bins=bins, density=True)\n\n# Disegna l'istogramma\nfor i in range(len(hist)):\n    if edges[i] &gt;= 6:\n        color = 'red'  # Colore per x &gt; 6\n    else:\n        color = 'blue'  # Colore per x &lt;= 6\n    plt.bar(edges[i], hist[i], width=1, align='edge', color=color, alpha=0.5)\n\n# Imposta etichette e titolo\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\n_ = plt.xticks(np.arange(11))",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "30.5 Distribuzione Beta-Binomiale",
    "text": "30.5 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilit√† nella probabilit√† di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilit√† per la distribuzione beta-binomiale √® data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{30.4}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilit√† nella probabilit√† di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, √® definita tramite l‚Äôuso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL‚Äôimportanza della distribuzione beta-binomiale deriva dalla sua capacit√† di modellare situazioni in cui la probabilit√† di successo non √® fissa, ma segue una distribuzione di probabilit√†, specificatamente una distribuzione beta. Ci√≤ la rende particolarmente adatta per applicazioni in cui le probabilit√† di successo cambiano in maniera incerta da un tentativo all‚Äôaltro, come pu√≤ avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilit√† di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione pi√π realistica e flessibile per dati empirici che presentano variabilit√† nelle probabilit√† di successo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#considerazioni-conclusive",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#considerazioni-conclusive",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "30.6 Considerazioni Conclusive",
    "text": "30.6 Considerazioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarit√†. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilit√† nella probabilit√† di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilit√† a ogni evento in un insieme finito e discreto. Questa distribuzione √® particolarmente utile quando non abbiamo ragioni per assegnare probabilit√† diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell‚Äôanalisi statistica discreta e trovano applicazione in un‚Äôampia gamma di settori. In particolare, nel contesto dell‚Äôanalisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale √® cruciale, poich√© queste distribuzioni forniscono le basi per l‚Äôaggiornamento bayesiano, un concetto chiave che sar√† esplorato nei capitoli successivi.\nPer coloro interessati a tecniche pi√π avanzate, la generazione di valori casuali a partire da queste distribuzioni √® trattata nell‚Äôappendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l‚Äôapplicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni √® cruciale per chiunque desideri esplorare il vasto campo della probabilit√† e della statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "30¬† Distribuzioni di v.c. discrete",
    "section": "30.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "30.7 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html",
    "href": "chapters/chapter_3/08_cont_rv_distr.html",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "Introduzione\nDopo avere introdotto con una simulazione il concetto di funzione di densit√† nel Capitolo 29, prendiamo ora in esame alcune delle densit√† di probabilit√† pi√π note. Iniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-uniforme",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-uniforme",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.1 Distribuzione uniforme",
    "text": "31.1 Distribuzione uniforme\nLa distribuzione uniforme √® la pi√π sempilce funzione di densit√† di probabilit√†. Consideriamo nuovamente l‚Äôesperimento con lo spinner che abbiamo introdotto nel capitolo {ref}density-function-notebook. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\ny = rng.uniform(low=0, high=360, size=20)\nprint(y)\n\n[272.91158643 127.62934853 349.45128878 321.52360368 280.21805895\n  70.06993483 168.01956134  15.76935568  55.54421714 245.89762317\n 268.11437613 348.30350368 117.29712893 133.36549417 169.04009206\n  68.20968927  46.77174192 171.25377344  81.68736566 241.13303809]\n\n\n\nplt.figure()\ncount, bins, ignored = plt.hist(y, bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\nplt.ylabel(\"Frequenza relativa\");\n\n\n\n\n\n\n\n\nSebbene possiamo pensare che sia ugualmente probabile che si verifichi qualsiasi risultato tra 0 e 360, l‚Äôistogramma non sembra suggerire questo. Ma lo spinner √® stato fatto ruotare solo 20 volte. Proviamo con 100,000 ripetizioni.\n\nplt.figure()\ncount, bins, ignored = plt.hist(rng.uniform(0, 360, 100000), bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\n_ = plt.ylabel(\"Frequenza relativa\")\n\n\n\n\n\n\n\n\nIn questo caso, anche se c‚Äô√® una variazione nelle altezze delle barre (con \\(\\Delta\\) = 10), la forma generale dell‚Äôistogramma sembra essere piuttosto piatta, ovvero uniforme, nell‚Äôintero intervallo dei valori possibili di \\(X\\), ovvero \\(0 &lt;= X &lt;= 360\\). Se potessimo ottenere un numero enorme di risultati dello spinner, il profilo dell‚Äôistogramma assumerebbe la forma della funzione di densit√† uniforme mostratra nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 100)\nplt.plot(x, stats.uniform.pdf(x, 0, 360), lw=2, label=\"uniform pdf\")\nplt.xlabel(\"x\")\nplt.ylabel(\"p(x)\");\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) √® continua, come nel caso del risultato della rotazione dello spinner, allora per rappresentare le probabilit√† usiamo una curva chiamata funzione di densit√† di probabilit√†. Poich√© la scala dello spinner va da 0 a 360, sappiamo che tutti i risultati possibili devono cadere in questo intervallo, quindi la probabilit√† che \\(X\\) assuma un valore nell‚Äôintervallo [0, 360] √® 1.0. Questa probabilit√† √® rappresentata dall‚Äôarea totale sotto la funzione di densit√† della figura precedente tra 0 e 360. Poich√© l‚Äôarea di questo rettangolo √® data dall‚Äôaltezza per la base e la base √® uguale a 360, l‚Äôaltezza di questa curva di densit√† deve essere 1/360 = 0.00278. L‚Äôordinata della funzione di densit√† (qui 0.00278 nell‚Äôintervallo [0, 360] e 0 altrove) √® chiamata densit√†.\nLe probabilit√† corrispondono alle aree sottese alla curva di densit√† nell‚Äôintervallo di valori \\(X\\) specificato. Per esempio, nell‚Äôesperimento dello spinner possiamo chiederci quale sia la probabilit√† di ottenere un numero compreso tra 150 e 250, ovvero \\(P(150 &lt; X &lt; 250)\\). Per trovare la risposta dobbiamo calcolare l‚Äôarea di un rettangolo. La base √® 250 - 150 = 100. L‚Äôaltezza √® 0.00278. Dunque, la probabilit√† √®\n\n100*1/360\n\n0.2777777777777778\n\n\nPer svolgere questo calcolo i software utilizzano la funzione di ripartizione, \\(P(X &lt; x)\\). Per trovare l‚Äôarea in un intervallo √® necessario sottrarre due aree. Nel caso presente abbiamo \\(P(x &lt; 250) - P(x &lt; 150)\\), ovvero:\n\nstats.uniform.cdf(250, 0, 360) - stats.uniform.cdf(150, 0, 360)\n\n0.27777777777777773\n\n\nLa probabilit√† cercata √® rappresentata dal rettangolo indicato nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 1000)\nfx = stats.uniform.pdf(x, 0, 360)\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 150) & (x &lt;= 250), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera pi√π formale possiamo dire che la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l‚Äôintervallo unitario \\(I=[0,1]\\).\nLa densit√† di probabilit√† di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) √®\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto √®\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza √®\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn Python √® possibile manipolare la distribuzione uniforme mediante la funzione uniform del modulo scipy.stats. Di default, la funzione scipy.stats.uniform() √® un‚Äôistanziazione di \\({\\mathcal{U}}(0,1)\\). Se utilizziamo la funzione pdf() (probability density function) otteniamo l‚Äôordinata della funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei valori \\(x\\) passati in input. Per esempio, esaminiamo la funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza di 0.5, 0.8 e 1.2. Per i primi due valori ci aspettiamo di ottenere 1; in corrispondenza di 1.2 ci aspettiamo di ottenere 0, poich√© questo valore √® al di fuori dell‚Äôintervallo \\([ 0, 1]\\).\n\nstats.uniform.pdf([0.5, 0.8, 1.2])\n\narray([1., 1., 0.])\n\n\nCon la funzione cdf() (cumulative density function) otteniamo la funzione di ripartizione. Per esempio, per \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei punti 0.5 e 0.8 otteniamo\n\nstats.uniform.cdf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nUsando la funzione di ripartizione √® possibile calcolare la probabilit√† che la variabile casuale continua assuma un valore nell‚Äôintervallo specificato. Per esempio, per \\({\\mathcal{U}}(0,1)\\) troviamo \\(P(0.5 &lt; x &lt; 0.8)\\)\n\nstats.uniform.cdf(0.8) - stats.uniform.cdf(0.5)\n\n0.30000000000000004\n\n\nI quantili di una funzione di densit√† (ovvero, il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input) si ottengono con la funzione ppf() (probability point function). Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di una \\({\\mathcal  {U}}(0,1)\\).\n\nstats.uniform.ppf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nInfine, √® possibile simulare dei valori casuali della distribuzione \\({\\mathcal{U}}(0,1)\\) usando la funzione stats.uniform(). Se vogliamo 5 valori da una \\({\\mathcal{U}}(0,1)\\), scriviamo:\n\nrng.uniform(0, 1, 5)\n\narray([0.51383373, 0.32883263, 0.16402071, 0.13786892, 0.15572435])\n\n\nVerifico il valore atteso di 100,000 realizzazioni di \\({\\mathcal {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).mean()\n\n0.4993283752250098\n\n\nVerifico la varianza di 100,000 realizzazioni di \\({\\mathcal  {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).var()\n\n0.0832097723457758\n\n\n\n1 / 12\n\n0.08333333333333333",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.2 Distribuzione esponenziale",
    "text": "31.2 Distribuzione esponenziale\nUn‚Äôaltra distribuzione di densit√† molto semplice √® la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale √® l‚Äôunica distribuzione di probabilit√† continua che possiede la propriet√† di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinch√© un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si √® rotto dopo 3 anni dal primo utilizzo. L‚Äôassenza di memoria significa che la probabilit√† che questo bicchiere da vino non si rompa nel prossimo anno √® la stessa della probabilit√† che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densit√† esponenziale √®\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{31.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale √®\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale √®\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard √® dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\nPer disegnare un grafico della funzione esponenziale possiamo usare la funzione stats.expon(). La densit√† √® data da pdf(x, loc, scale), laddove il parametro loc √® 0 e scale √® la deviazione standard. Nel caso presente abbiamo:\n\nx = np.arange(0, 20, 0.01)\nmu = 4\nlam = 1 / mu\nstdev = 1 / lam\npdf = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\");\n\n\n\n\n\n\n\n\nChiediamoci, ad esempio, quale sia la probabilit√† di dovere aspettare non pi√π di un giorno e mezzo per conoscere il voto dell‚Äôesame. La risposta a questa domanda √® data dalla funzione di ripartizione in corrispondenza di 1.5, ovvero \\(F(1.5) = P(X \\leq 1.5)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 0) & (x &lt;= 1.5), color=\"0.75\");\n\n\n\n\n\n\n\n\nPossiamo trovare la risposta usando la funzione cdf():\n\nstats.expon.cdf(1.5, loc=0, scale=stdev) \n\n0.3127107212090278\n\n\nChiediamoci, ad esempio quale sia la probabilit√† di conoscere il voto in un tempo compreso tra 1 e 6 giorni. Dobbiamo trovare l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo [1, 6]. Usando la fuzione di ripartizione, calcoliamo \\(F(6) - F(1) = P(X &lt;= 6) - P(X &lt;= 1)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1) & (x &lt;= 6), color=\"0.75\");\n\n\n\n\n\n\n\n\n\nstats.expon.cdf(6, loc=0, scale=stdev) - stats.expon.cdf(1, loc=0, scale=stdev)\n\n0.5556706229229751\n\n\nTroviamo la probabilit√† di dovere aspettare almeno 5 giorni e mezzo.\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 5.5) & (x &lt;= 21), color=\"0.75\");\n\n\n\n\n\n\n\n\nLa probabilit√† cercata √® data dalla probabilit√† dell‚Äôevento complementare di quello fornito dalla funzione di ripartizione.\n\n1 - stats.expon.cdf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\n\nstats.expon.sf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\nSe la media del tempo di attesa nel Corso di Laurea fosse di 4 giorni, allora circa una volta su 4 lo studente dovr√† aspettare almeno 5.5 giorni per conoscere il voto dello scritto.\nLa figura seguente mostra un istogramma di 1000000 valori casuali estratti dalla distribuzione esponenziale di parametro \\(\\lambda = 1/4\\). All‚Äôistogramma √® sovrapposta la funzione di densit√†.\n\nsamps = rng.exponential(stdev, 100000)\n\nplt.figure()\ncount, bins, ignored = plt.hist(samps, bins=100, density=True, alpha=0.5)\nplt.plot(x, fx)\nplt.xlim([0, 20])\nplt.ylabel(\"Frequenza relativa\")\nplt.xlabel(\"Tempo di attesa\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.3 Distribuzione Gaussiana",
    "text": "31.3 Distribuzione Gaussiana\nLa pi√π importante distribuzione di densit√† √® la Gaussiana. Non c‚Äô√® un‚Äôunica distribuzione gaussiana (o Normale): la distribuzione gaussiana √® una famiglia di distribuzioni. Tali distribuzioni sono dette ‚Äúgaussiane‚Äù in onore di Carl Friedrich Gauss (uno dei pi√π grandi matematici della storia il quale, tra le altre cose, scopr√¨ l‚Äôutilit√† di tale funzione di densit√† per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densit√† alle misurazioni dell‚Äôuomo. Karl Pearson us√≤ per primo il termine ‚Äúdistribuzione normale‚Äù anche se ammise che questa espressione ‚Äúha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell‚Äôaltro, non siano normali.‚Äù\n\n31.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre not√≤ che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilit√† di successo di 0.9, la distribuzione √® chiaramente asimmetrica.\n\nn = 10\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist);\n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilit√† di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densit√† di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilit√† binomiale.\n\nn = 1000\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist)\nplt.xlim(850, 950);\n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.4 La Normale prodotta con una simulazione",
    "text": "31.4 La Normale prodotta con una simulazione\nIl libro ‚ÄúRethinking Statistics‚Äù di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo pu√≤ variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall‚Äôorigine, che √® il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non √® possibile determinare la posizione esatta di ogni individuo, ma √® possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall‚Äôorigine.\nAd esempio, √® possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall‚Äôorigine. Queste previsioni sono fattibili perch√© la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sar√† usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando cos√¨ il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps √® un elenco di numeri di passi in cui il codice traccer√† linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array √® riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verr√† utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri della simulazione\nnumero_passi = 16  # Numero di passi per passeggiata\nripetizioni = 1000  # Numero di passeggiate da generare\npunti_da_evidenziare = [4, 8, 16]  # Punti da evidenziare sul grafico\n\n# Inizializza l'array per registrare le passeggiate casuali\nx = np.zeros((numero_passi + 1, ripetizioni))\n\n# Genera le passeggiate casuali\nfor i in range(ripetizioni):\n    passi = rng.uniform(-1, 1, numero_passi)  # Genera passi casuali\n    x[1:, i] = np.cumsum(passi)  # Calcola la posizione cumulativa\n\n# Prepara il grafico\nfig, ax = plt.subplots()\nplt.plot(x, color=\"blue\", alpha=0.05)  # Disegna tutte le passeggiate\nplt.plot(x[:, 0], color=\"black\")  # Evidenzia la prima passeggiata\n\n# Evidenzia i punti specifici\nfor punto in punti_da_evidenziare:\n    plt.axvline(punto, linestyle=\"--\", color=\"black\", alpha=0.5)\n\n# Imposta etichette e aspetti del grafico\nplt.xlabel(\"Numero di passi\")\nplt.ylabel(\"Distanza dall'origine\")\nax.set_xticks(punti_da_evidenziare)\nplt.xlim(0, numero_passi + 0.1)\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota √® che, man mano che procediamo nel numero di passi, le densit√† iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\n# Crea una figura con 3 subplots in orizzontale, condividendo l'asse X\nfig, axs = plt.subplots(1, 3, figsize=(9, 3), sharex=True)\n\n# Itera sui punti da evidenziare e sugli assi corrispondenti\nfor step, ax in zip(punti_da_evidenziare, axs):\n    # Estrae le posizioni al passo specificato per tutte le ripetizioni\n    posizioni_al_passo = x[step, :]\n    \n    az.plot_kde(posizioni_al_passo, bw=0.01, ax=ax)\n    \n    ax.set_title(f\"{step} passi\")\n    ax.set_ylabel(\"Densit√†\")\n    ax.set_xlabel(\"Posizioni\")\n    ax.set_xlim(-6, 6)\n    ax.set_xticks([-6, -3, 0, 3, 6])\n\nplt.tight_layout() \nplt.show()\n\n\n\n\n\n\n\n\nLa chiarezza dell‚Äôinformazione presentata nei grafici precedenti pu√≤ essere migliorata utilizzando un KDE plot.\n\n# Genera la distribuzione uniforme e calcola la somma come prima\npos = rng.uniform(-1, 1, size=(16, 1000)).sum(0)\n\n# Calcola media e deviazione standard dei dati generati\nmedia, dev_std = np.mean(pos), np.std(pos)\n\n# Spazio dei valori per la distribuzione normale\nvalori = np.linspace(np.min(pos), np.max(pos), 1000)\n\n# Calcola la distribuzione normale con la stessa media e deviazione standard\ndistribuzione_normale = stats.norm.pdf(valori, media, dev_std)\n\n# Disegna la stima della densit√† kernel dei dati\naz.plot_kde(pos, label='Distribuzione KDE')\n\n# Sovrappone la distribuzione normale\nplt.plot(valori, distribuzione_normale, label='Distribuzione Normale', color = \"C1\", linestyle='--')\n\nplt.xlabel(\"Posizione\")\nplt.ylabel(\"Densit√†\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilit√†: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che pu√≤ essere uniforme, come nell‚Äôesempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocit√† con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocit√† di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno √® rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana √® quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa pu√≤ essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ci√≤, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni pi√π lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densit√† di probabilit√† √® distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{31.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densit√† normale √® unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densit√† in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell‚Äôeq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densit√† Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 √® fornita nella figura seguente.\n\nx = np.arange(-5, 6, 0.001)\n\nmus = [-1.0, -0.5, 0.0, 1.0]\nsigmas = [0.25, 0.5, 1, 2]\n\nplt.figure()\n\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.norm.pdf(x, mu, sigma)\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n31.4.1 Concentrazione\n√à istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media √® superiore a 3 volte la deviazione standard presenti un carattere di eccezionalit√† perch√© meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n31.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) √® l‚Äôarea sottesa alla curva di densit√† \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilit√† \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEsaminiamo le funzioni per la densit√† Normale. Il metodo rng.normal(loc, scale, size) produce size valori casuali estratti dalla distribuzione Normale specificata. Per esempio, un singolo valore casuale dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\) √®:\n\nrng.normal(loc=100, scale=15, size=1)\n\narray([77.8271813])\n\n\nEstraiamo ora 10 valori a caso dalla \\(\\mathcal{N}(100, 15)\\):\n\nqi = rng.normal(loc=100, scale=15, size=10)\nprint(qi)\n\n[107.37134121  74.33288092  70.05953321 100.16099998  67.01041676\n 102.19573565 114.68076458  58.88627549  69.38274746 112.14401099]\n\n\nPer trovare la probabilit√† che un‚Äôosservazione estratta a caso dalla \\(\\mathcal{N}(100, 15)\\) abbia un valore minore o uguale a, diciamo, 115, troviamo il valore della funzione di ripartizione (o funzione cumulativa di densit√†) nel punto 115.\n\nstats.norm.cdf(115, 100, 15)\n\n0.8413447460685429\n\n\nQuesta √® l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo \\([-\\infty, 115]\\), come indicato nella figura seguente.\n\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\n\nplt.figure()\nplt.plot(x, fx)\n_ = plt.fill_between(x, fx, where=x &lt;= 115, color=\"0.75\")\n\n\n\n\n\n\n\n\nSolo per fare un esempio, qui di seguito fornisco il codice Python per calcolare l‚Äôintegrale che stiamo discutendo per mezzo della funzione quad della libreria SciPy:\n\ndef gaussian(x, mu, sig):\n    return (\n        1.0 / (np.sqrt(2.0 * np.pi) * sig) * np.exp(-np.power((x - mu) / sig, 2.0) / 2)\n    )\n\nmu = 100\nsigma = 15\nresult, error = quad(gaussian, -1000, 115, args=(mu, sigma))\nprint(\"Il risultato √®\", result, \"con errore\", error)\n\nIl risultato √® 0.8413447460685429 con errore 4.0191197364560644e-10\n\n\nIl risultato replica quello prodotto da .norm.cdf().\nPer trovare la proporzione di persone nella popolazione che hanno un QI maggiore di 2 deviazioni standard dalla media consideriamo l‚Äôevento complementare:\n\n1 - stats.norm.cdf(130, 100, 15)\n\n0.02275013194817921\n\n\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=x &gt;= 130, color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo usare la Survival Function:\n\nstats.norm.sf(130, 100, 15)\n\n0.022750131948179198\n\n\nLa funzione ppf restituisce il quantile della Normale. Ad esempio:\n\nstats.norm.ppf(1 - 0.022750131948179195, 100, 15)\n\n130.0\n\n\n\n\n31.4.3 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale √® l‚Äôinsieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL‚Äôarea sottesa alla curva di densit√† di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) √® uguale all‚Äôarea sottesa alla densit√† Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) √® il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l‚Äôarea sottesa nella semiretta \\([1, \\infty)\\) √® uguale all‚Äôarea sottesa nella semiretta \\((-\\infty, 1]\\) e quest‚Äôultima coincide con \\(F(-1)\\). Analogamente, l‚Äôarea sottesa nell‚Äôintervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), √® pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema √® quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato √® detto quantile di ordine \\(p\\) della Normale standard e pu√≤ essere trovato mediante un software.\nSupponiamo che l‚Äôaltezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un‚Äôaltezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l‚Äôarea sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell‚Äôintervallo \\([1.7, 1.8]\\):\n\nstats.norm.cdf(1.8, 1.7, 0.1) - stats.norm.cdf(1.7, 1.7, 0.1)\n\n0.34134474606854315\n\n\n\nmu = 1.7\nsigma = 0.1\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1.7) & (x &lt;= 1.8), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l‚Äôintervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell‚Äôintervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\nstats.norm.cdf(1.0, 0, 1) - stats.norm.cdf(0, 0, 1)\n\n0.3413447460685429\n\n\nIl modo pi√π semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilit√† richiesta non √® altro che la met√† dell‚Äôarea sottesa dalle distribuzioni Normali nell‚Äôintervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l‚Äôinverso della CDF della distribuzione normale.\n\n# Definisco i parametri della distribuzione\nmu = 100\nsigma = 15\n\n# Creo un range di valori su cui calcolare le funzioni\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\n\n# Calcolo la PDF, CDF, e l'inverso della CDF\npdf = stats.norm.pdf(x, mu, sigma)\ncdf = stats.norm.cdf(x, mu, sigma)\nppf = stats.norm.ppf(np.linspace(0.01, 0.99, 100), mu, sigma)  # Evitiamo 0 e 1 per l'inverso\n\n# Creo i grafici in una sola riga\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n# Grafico della PDF\naxs[0].plot(x, pdf, label='PDF')\naxs[0].set_title('PDF')\naxs[0].set_xlabel('Valori')\naxs[0].set_ylabel('Probabilit√†')\naxs[0].legend()\n\n# Grafico della CDF\naxs[1].plot(x, cdf, label='CDF', color='orange')\naxs[1].set_title('CDF')\naxs[1].set_xlabel('Valori')\naxs[1].set_ylabel('Cumulativa')\naxs[1].legend()\n\n# Grafico dell'inverso della CDF\naxs[2].plot(np.linspace(0.01, 0.99, 100), ppf, label='Inverse CDF', color='green')\naxs[2].set_title('Inverse CDF')\naxs[2].set_xlabel('Probabilit√†')\naxs[2].set_ylabel('Valori')\naxs[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalit√† di osservare la stessa informazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.5 Distribuzione Chi-quadrato",
    "text": "31.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libert√† descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libert√†. La densit√† di probabilit√† di \\(\\chi^2_{~\\nu}\\) √®\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) √® una costante positiva.\nLa figura seguente mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\n\nx = np.arange(0, 40, 0.1)\n\nnus = [2, 4, 8, 16]\nplt.figure()\nfor nu in nus:\n    pdf = stats.chi2.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n31.5.1 Propriet√†\n\nLa distribuzione di densit√† \\(\\chi^2_{~\\nu}\\) √® asimmetrica.\nIl valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(\\nu\\).\nLa varianza di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(2\\nu\\).\nPer \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).\nSe \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libert√†, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti.\n\nPer fare un esempio, consideriamo la v.c. \\(\\chi^2_5\\).\n\n# Set the degrees of freedom\ndf = 5\n\n# Create a chi-square distribution object\nchi2_dist = stats.chi2(df)\n\n# Generate x values for the plot\nx = np.linspace(0, 20, 200)\n\n# Calculate the probability density function (PDF) of the chi-square distribution for x values\npdf = chi2_dist.pdf(x)\n\n# Plot the PDF\nplt.figure()\nplt.plot(x, pdf)\nplt.title('Chi-Square Distribution (df=5)')\nplt.xlabel('x')\nplt.ylabel('PDF');\n\n\n\n\n\n\n\n\nGeneriamo 1000000 valori da questa distribuzione.\n\nx = rng.chisquare(5, 1000000)\nx[0:20]\n\narray([3.66284512, 2.96353593, 4.93609572, 4.67151242, 4.10927523,\n       4.16530706, 3.36823832, 9.92342755, 7.02541475, 3.23262943,\n       2.73771833, 3.01973299, 4.83304038, 3.16952063, 5.98040985,\n       6.26951139, 8.73351727, 7.28411818, 7.75225854, 5.77346535])\n\n\nCalcoliamo la media di questi valori.\n\nnp.mean(x)\n\n5.0050584059950385\n\n\nCalcolo la varianza.\n\nnp.var(x, ddof=0)\n\n10.013703149640937",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.6 Distribuzione \\(t\\) di Student",
    "text": "31.6 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un‚Äôaltra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\tag{31.3}\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libert√†. Si usa scrivere \\(T \\sim t_{\\nu}\\). L‚Äôandamento della distribuzione \\(t\\) di Student √® simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code pi√π pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa seguente mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\nx = np.arange(-5, 5, 0.1)\n\nnus = [1, 2, 5, 30]\n\nplt.figure()\nfor nu in nus:\n    pdf = stats.t.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.plot(x, stats.norm.pdf(x, 0, 1), label=\"N(Œº = 0, œÉ = 1)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n31.6.1 Propriet√†\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti propriet√†:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densit√† della \\(t_{\\nu}\\) √® una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto √® sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\).\n\nPer esempio, calcoliamo il valore della funzione di ripartizione di ordine 0.025 nel caso di una \\(t_{30}\\).\n\nstats.t.ppf(0.025, 30)\n\n-2.042272456301238\n\n\nAumentiamo i gradi di libert√†: \\(\\nu\\) = 1000.\n\nstats.t.ppf(0.025, 1000)\n\n-1.9623390808264078\n\n\nQuesto valore √® quasi identico a quello della Normale stanardizzata.\n\nstats.norm.ppf(0.025, 0, 1)\n\n-1.9599639845400545\n\n\nLa ragione per cui il quantile della distribuzione \\(t\\) con \\(\\nu=30\\) √® maggiore (in valore assoluto) del quantile omotetico della distribuzione Normale Standard √® che la distribuzione \\(t\\) ha una varianza maggiore rispetto alla distribuzione Normale Standard.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.7 Funzione Beta di Eulero",
    "text": "31.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero √® una funzione matematica, non una densit√† di probabilit√†. La menzioniamo qui perch√© viene utilizzata nella densit√† di probabilit√† Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si pu√≤ scrivere in molti modi diversi; per i nostri scopi la presentiamo cos√¨:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{31.4}\\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, ovvero il fattoriale discendente, cio√®\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore\n\nalpha = 3\nbeta = 9\nsc.beta(alpha, beta)\n\n0.00202020202020202\n\n\nSi noti che abbiamo usato la funzione beta della libreria scipy.special. Lo stesso risultato si ottiene svolgendo i calcoli in maniera esplicita:\n\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n\n0.00202020202020202\n\n\n\n(math.factorial(alpha-1)*math.factorial(beta-1)) / math.factorial(alpha+beta-1)\n\n0.00202020202020202\n\n\noppure usando la funzione gamma di scipy.special:\n\nsc.gamma(alpha) * sc.gamma(beta) / sc.gamma(alpha + beta)\n\n0.00202020202020202",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-beta",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.8 Distribuzione Beta",
    "text": "31.8 Distribuzione Beta\nLa distribuzione di probabilit√† Beta, denotata comunemente come \\(Beta(\\alpha, \\beta)\\), √® utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione √® la sua definizione esclusiva nell‚Äôintervallo \\((0, 1)\\). In pratica, ci√≤ significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l‚Äô1 come estremi.\n\n31.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale pu√≤ assumere qualunque valore nell‚Äôintervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densit√† √® descritta dalla seguente formula:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) √® la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n31.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. √à essenziale che entrambi questi parametri siano positivi.\n\n\n31.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta pu√≤ essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilit√† di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilit√† di successo √® un parametro fisso; nella distribuzione Beta, questa probabilit√† diventa una variabile aleatoria.\n\n\n31.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione √® analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall‚Äôaspettativa iniziale della probabilit√† di successo: - Se si presume un‚Äôalta probabilit√† di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa pi√π stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali √® dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un‚Äôillustrazione √® fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\nx = np.linspace(0, 1, 200)\nalphas = [0.5, 5.0, 1.0, 2.0, 2.0]\nbetas = [0.5, 1.0, 3.0, 2.0, 5.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.beta.pdf(x, a, b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.ylim(0, 4.5)\nplt.legend(loc=9);\n\n\n\n\n\n\n\n\n\n\n31.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densit√† di probabilit√† che si estende sull‚Äôintervallo \\([0,1]\\), con l‚Äôarea sottesa dalla curva (l‚Äôintegrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo\n\ndef integrand(p, a, b):\n    return p ** (a - 1) * (1 - p) ** (b - 1)\n\na = 3\nb = 9\nresult, error = quad(integrand, 0, 1, args=(a, b))\nprint(result)\n\n0.00202020202020202\n\n\novvero\n\nresult = (math.gamma(a) * math.gamma(b)) / math.gamma(a + b)\nprint(result)\n\n0.00202020202020202\n\n\novvero, usando la funzione beta di Eulero di scipy.special\n\nsc.beta(a, b)\n\n0.00202020202020202\n\n\n\n\n31.8.6 Propriet√†\nIl valore atteso, la moda e la varianza di una densit√† di probabilit√† Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire la funzione beta_mean_mode_variance() in Python per calcolare la media, la moda e la varianza di una distribuzione di probabilit√† Beta:\n\ndef beta_mean_mode_variance(alpha, beta):\n    mean = alpha / (alpha + beta)\n    mode = (alpha - 1) / (alpha + beta - 2)\n    variance = alpha * beta / ((alpha + beta) ** 2 * (alpha + beta + 1))\n    return mean, mode, variance\n\nPer esempio\n\nalpha = 7\nbeta = 3\nmean, mode, variance = beta_mean_mode_variance(alpha, beta)\nprint(f\"Mean: {mean}, Mode: {mode}, Variance: {variance}\")\n\nMean: 0.7, Mode: 0.75, Variance: 0.019090909090909092\n\n\n\n\n31.8.7 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell‚Äôambito dell‚Äôinferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poich√© permette di bypassare onerose computazioni numeriche tipicamente associate all‚Äôinferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(Œ±, Œ≤), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterr√† la forma funzionale della distribuzione Beta. Ci√≤ significa che, una volta raccolti i dati, l‚Äôaggiornamento a posteriori pu√≤ essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri Œ± e Œ≤ del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (Œ±+x, Œ≤+n-x), senza la necessit√† di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\n√à importante prestare attenzione all‚Äôuso del termine ‚ÄúBeta‚Äù in questo contesto, poich√© assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilit√† continua. - La funzione Beta, una funzione matematica speciale. - Il parametro Œ≤, che insieme ad Œ±, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.9 Distribuzione di Cauchy",
    "text": "31.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy √® un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libert√†. √à definita da una densit√† di probabilit√† che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{31.5}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\nx = np.linspace(-5, 5, 500)\nalphas = [0.0, 0.0, 0.0, -2.0]\nbetas = [0.5, 1.0, 2.0, 1.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.cauchy.pdf(x, loc=a, scale=b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gamma",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.10 Distribuzione Gamma",
    "text": "31.10 Distribuzione Gamma\nLa densit√† di probabilit√† Gamma √® una distribuzione di probabilit√† continua che gioca un ruolo chiave nella modellazione del tempo di attesa per l‚Äôoccorrenza di un certo numero di eventi indipendenti e rari. Essa √® caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti come parametro di forma e parametro di scala, rispettivamente.\n\n31.10.1 Parametro \\(\\alpha\\) ‚Äì parametro di forma\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione gamma si riduce a una distribuzione esponenziale.\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco attorno a \\((\\alpha - 1) \\cdot \\beta\\).\nSe \\(\\alpha &lt; 1\\), la distribuzione √® inclinata verso destra, mostrando una coda lunga che si estende verso valori pi√π bassi.\n\nIn termini interpretativi, \\(\\alpha\\) rappresenta il numero di eventi che si stanno aspettando. Ad esempio, potrebbe rappresentare il numero di ricordi vividi che ci si aspetta di esperire in un certo periodo di tempo.\n\n\n31.10.2 Parametro \\(\\beta\\) ‚Äì parametro di scala\nIl parametro di scala, \\(\\beta\\), controlla la ‚Äúlarghezza‚Äù della distribuzione:\n\nUn valore pi√π grande di \\(\\beta\\) produce una curva pi√π piatta, indicando una maggiore variabilit√† nel tempo di attesa.\nUn valore pi√π piccolo di \\(\\beta\\) rende la curva pi√π appuntita, indicando una minore variabilit√†.\n\nNel contesto del tempo di attesa, \\(\\beta\\) agisce come una scala temporale, con un valore pi√π grande che indica un periodo di tempo pi√π lungo tra gli eventi, e un valore pi√π piccolo che indica un periodo di tempo pi√π breve.\n\n\n31.10.3 Formula della funzione di densit√† di probabilit√†\nLa formula matematica per la funzione di densit√† di probabilit√† (PDF) della distribuzione gamma √®:\n\\[\nf(x|\\alpha, \\theta) = \\frac{x^{\\alpha-1}e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove,\n\n\\(x\\) √® la variabile casuale continua, con \\(x &gt; 0\\).\n\\(\\theta = \\frac{1}{\\beta}\\).\n\\(\\Gamma(\\alpha)\\) √® la funzione Gamma di Eulero, che estende la nozione di fattoriale ai numeri reali e complessi. Per numeri interi \\(n\\), si ha che \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma √® definita come \\(\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1}e^{-x}dx\\).\n\nLe espressioni per media e varianza della distribuzione Gamma sono le seguenti:\n\nLa media (\\(\\mu\\)) della distribuzione Gamma √® \\(\\mu = \\alpha / \\beta\\), o equivalentemente \\(\\mu = \\alpha \\theta\\), usando il parametro di scala.\nLa varianza (\\(\\sigma^2\\)) della distribuzione Gamma √® \\(\\sigma^2 = \\alpha / \\beta^2\\), o equivalentemente \\(\\sigma^2 = \\alpha \\theta^2\\), adottando il parametro di scala.\n\nQuesto chiarisce la relazione tra i parametri \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso) o \\(\\theta\\) (scala), e come influenzano la distribuzione Gamma.\nPer esempio, qui √® riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\nalpha = 3\nbeta = 5/3\n\nmean = alpha / beta\nprint(mean)\n\n1.7999999999999998\n\n\n\n# Standard deviation = sqrt(alpha / beta^2)\n\nsigma = np.sqrt(alpha / beta**2)\nprint(sigma)\n\n1.0392304845413263\n\n\n\n# Generazione di dati dalla distribuzione Gamma\ndata = rng.gamma(shape=alpha, scale=1/beta, size=100000)\n\n# Plot dell'istogramma dei dati generati\nplt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n\n# Plot della PDF (Probability Density Function) della distribuzione Gamma\nx = np.linspace(0, 10, 1000)\nplt.plot(x, stats.gamma.pdf(x, a=alpha, scale=1/beta), 'r-', lw=2, label='PDF')\n\nplt.xlabel('Valore')\nplt.ylabel('Densit√† di probabilit√†')\nplt.title('Distribuzione Gamma con alpha=3 e beta=5/3')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-log-normale",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-log-normale",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.11 Distribuzione log-normale",
    "text": "31.11 Distribuzione log-normale\nSia \\(y\\) una variabile casuale avente distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo poi una nuova variabile casuale \\(x\\) attraverso la relazione\n\\[\nx = e^y \\quad \\Longleftrightarrow \\quad y = \\log x.\n\\]\nIl dominio di definizione della \\(x\\) √® il semiasse \\(x &gt; 0\\) e la densit√† di probabilit√† \\(f(x)\\) √® data da\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\frac{1}{x} \\exp \\left\\{-\\frac{(\\log x -  \\mu)^2}{2 \\sigma^2} \\right\\}.\n\\tag{31.6}\\]\nQuesta funzione di densit√† √® chiamata log-normale.\nIl valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(x) = \\exp \\left\\{\\mu + \\frac{\\sigma^2}{2} \\right\\}.\n\\]\n\\[\n\\mathbb{V}(x) = \\exp \\left\\{2 \\mu + \\sigma^2 \\right\\} \\left(\\exp \\left\\{\\sigma^2 \\right\\}  -1\\right).\n\\]\nSi puoÃÄ dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale.\nLa figura mostra tre distribuzioni log-normali con \\(\\mu\\) = 0.0 e \\(\\sigma\\) = .25, .5, 1.0.\n\nx = np.linspace(0, 3, 100)\nmus = [0.0, 0.0, 0.0]\nsigmas = [0.25, 0.5, 1.0]\nplt.figure()\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.lognorm.pdf(x, sigma, scale=np.exp(mu))\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.12 Commenti e considerazioni finali",
    "text": "31.12 Commenti e considerazioni finali\nLa statistica bayesiana impiega le distribuzioni di probabilit√† come motore inferenziale per la stima dei parametri e dell‚Äôincertezza. Immaginiamo che le distribuzioni di probabilit√† siano piccoli pezzi di ‚ÄúLego‚Äù con cui possiamo costruire qualsiasi cosa desideriamo. Questo principio si applica analogamente ai modelli statistici bayesiani. Possiamo costruire modelli che vanno dai pi√π semplici ai pi√π complessi, utilizzando le distribuzioni di probabilit√† e le loro interrelazioni.\nPython, oltre al modulo stats, offre la capacit√† di generare campioni casuali da varie distribuzioni di probabilit√† attraverso il generatore di numeri casuali disponibile in NumPy. Dopo aver importato NumPy con il comando:\nimport numpy as np\n√® possibile inizializzare il generatore di numeri casuali (rng) con un valore di seme (seed) specifico, garantendo cos√¨ la riproducibilit√† degli esperimenti:\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nA questo punto, si possono generare campioni da diverse distribuzioni di probabilit√†. Ad esempio, per generare un campione dalla distribuzione normale (gaussiana), si pu√≤ procedere nel seguente modo:\nmedia, deviazione_standard = 0, 1  # Valori per media e deviazione standard\ncampione_normale = rng.normal(media, deviazione_standard, size=100)\nIn questo esempio, size=100 indica che vogliamo generare un campione di 100 valori dalla distribuzione. Analogamente, si possono generare campioni da altre distribuzioni di probabilit√† specificando i relativi parametri:\nDistribuzione Uniforme: Per generare valori da una distribuzione uniforme, definita in un intervallo da a a b, si pu√≤ usare:\na, b = 0, 10  # Estremi dell'intervallo\ncampione_uniforme = rng.uniform(a, b, size=100)  # Aggiunta del parametro 'size'\nDistribuzione t di Student: Per ottenere valori dalla distribuzione t di Student, con un dato numero di gradi di libert√†:\ngradi_libert√† = 10  # Gradi di libert√†\ncampione_t = rng.standard_t(gradi_libert√†, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Beta: Per la distribuzione Beta, specificando i parametri alpha e beta:\nalpha, beta = 2, 5  # Parametri alpha e beta\ncampione_beta = rng.beta(alpha, beta, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Gamma: Infine, per generare un campione dalla distribuzione Gamma, con i parametri di forma e scala:\nforma, scala = 2, 1  # Parametri di forma e scala\ncampione_gamma = rng.gamma(forma, scala, size=100)  # Aggiunta del parametro 'size'\nIn tutti i casi, l‚Äôaggiunta del parametro size consente di specificare la dimensione del campione desiderato.\nPer analizzare le propriet√† statistiche di diverse distribuzioni di probabilit√†, oltre alla generazione di campioni casuali, si utilizzano le funzioni di densit√† di probabilit√† (PDF), le funzioni di ripartizione cumulativa (CDF) e le funzioni quantili. Queste operazioni possono essere effettuate efficacemente utilizzando la libreria SciPy in Python.\nPer determinare la funzione densit√† di probabilit√† (PDF), la quale rappresenta la probabilit√† relativa di osservare un valore all‚Äôinterno di un intervallo continuo, il procedimento √® il seguente. Per la distribuzione normale, ad esempio:\nimport numpy as np\nfrom scipy.stats import norm, uniform, t, beta, gamma\n\nmedia, deviazione_standard = 0, 1\nx = np.linspace(media - 4*deviazione_standard, media + 4*deviazione_standard, 100)\npdf_normale = norm.pdf(x, loc=media, scale=deviazione_standard)\nSimili operazioni possono essere effettuate per altre distribuzioni, come mostrato di seguito:\nDistribuzione Uniforme:\na, b = 0, 10\nx = np.linspace(a, b, 100)\npdf_uniforme = uniform.pdf(x, loc=a, scale=b-a)\nDistribuzione t di Student:\ngradi_libert√† = 10\nx = np.linspace(-5, 5, 100)\npdf_t = t.pdf(x, df=gradi_libert√†)\nDistribuzione Beta:\nalpha, beta_param = 2, 5\nx = np.linspace(0, 1, 100)\npdf_beta = beta.pdf(x, alpha, beta_param)\nDistribuzione Gamma:\nforma, scala = 2, 1\nx = np.linspace(0, 10, 100)\npdf_gamma = gamma.pdf(x, a=forma, scale=scala)\nPer determinare i quantili, ovvero i valori corrispondenti a specifiche probabilit√† cumulate nella funzione di distribuzione, si utilizza la funzione ppf (Percent Point Function). Ad esempio, per la distribuzione normale:\nprobabilit√† = 0.5\nquantile_normale = norm.ppf(probabilit√†, loc=media, scale=deviazione_standard)\nE per le altre distribuzioni:\nDistribuzione Uniforme:\nquantile_uniforme = uniform.ppf(probabilit√†, loc=a, scale=b-a)\nDistribuzione t di Student:\nquantile_t = t.ppf(probabilit√†, df=gradi_libert√†)\nDistribuzione Beta:\nquantile_beta = beta.ppf(probabilit√†, alpha, beta_param)\nDistribuzione Gamma:\nquantile_gamma = gamma.ppf(probabilit√†, a=forma, scale=scala)\nInfine, per calcolare la probabilit√† cumulativa associata a un dato quantile (ovvero la probabilit√† che una variabile casuale sia minore o uguale a quel quantile), si utilizza la funzione cdf (Cumulative Distribution Function). Questo permette di determinare la probabilit√† che si verifichi un evento entro un certo intervallo di valori per la distribuzione considerata. Ad esempio, per la distribuzione normale:\nquantile = 0\nprobabilit√†_normale = norm.cdf(quantile, loc=media, scale=deviazione_standard)\nE analogamente per le altre distribuzioni:\nDistribuzione Uniforme:\nprobabilit√†_uniforme = uniform.cdf(quantile, loc=a, scale=b-a)\nDistribuzione t di Student:\nprobabilit√†_t = t.cdf(quantile, df=gradi_libert√†)\nDistribuzione Beta:\nprobabilit√†_beta = beta.cdf(quantile, alpha, beta_param)\nDistribuzione Gamma:\nprobabilit√†_gamma = gamma.cdf(quantile, a=forma, scale=scala)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "31¬† Distribuzioni di v.c. continue",
    "section": "31.13 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "31.13 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\npandas    : 2.2.1\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html",
    "href": "chapters/chapter_3/09_likelihood.html",
    "title": "32¬† La verosimiglianza",
    "section": "",
    "text": "Introduzione\nOltre agli approcci frequentisti e bayesiani, esiste un terzo metodo fondamentale nell‚Äôambito dell‚Äôinferenza statistica: la metodologia basata sulla verosimiglianza. Questo approccio consente ai ricercatori di valutare l‚Äôevidenza relativa quando si confrontano due modelli o ipotesi, in maniera simile alla metodologia bayesiana. Ci√≤ che lo distingue √® il suo esplicito rifiuto di incorporare informazioni pregresse (priori) nelle analisi statistiche.\nQuesto capitolo si concentra sulla funzione di verosimiglianza, concetto centrale che si estende attraverso tutti e tre gli approcci statistici, fungendo da collegamento tra i dati osservati e i parametri di un modello statistico specifico. La rilevanza della funzione di verosimiglianza risiede nella sua capacit√† di fornire un fondamento robusto per l‚Äôinterpretazione e la quantificazione dell‚Äôadeguatezza dei dati ai modelli teorici. Questo la rende uno strumento cruciale per l‚Äôinferenza statistica, indispensabile per comprendere e valutare la conformit√† dei dati rispetto alle teorie proposte.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/chapter_3/09_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "32¬† La verosimiglianza",
    "section": "32.1 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "32.1 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza e la funzione di densit√† (o massa) di probabilit√† sono due concetti fondamentali in statistica che, nonostante condividano la stessa espressione matematica, rivestono ruoli e interpretazioni distinti a seconda del contesto in cui vengono applicati. La chiave per distinguere tra i due concetti risiede nel modo in cui trattiamo i dati e i parametri del modello.\nNel caso della funzione di densit√† (o massa) di probabilit√†, i parametri del modello sono fissati e l‚Äôobiettivo √® valutare la probabilit√† di osservare un certo insieme di dati. Qui, i dati sono variabili, mentre i parametri sono considerati costanti. Per esempio, in un esperimento in cui lanciamo una moneta diverse volte, potremmo usare una distribuzione binomiale per calcolare la probabilit√† di ottenere un certo numero di teste, assumendo un valore noto e fisso per la probabilit√† di ottenere testa in un singolo lancio.\nAl contrario, nella funzione di verosimiglianza, manteniamo i dati osservati come fissi e variamo i parametri del modello per valutare quanto bene questi ultimi si adattino ai dati osservati. Questo processo ci permette di esplorare la plausibilit√† di diversi valori dei parametri dati gli stessi dati. L‚Äôobiettivo √® identificare il set di parametri che meglio spiega i dati osservati.\nFormalmente, la relazione tra la funzione di verosimiglianza e la funzione di densit√† di probabilit√† √® espressa come segue:\n\\[\nL(\\theta | y) \\propto p(y | \\theta),\n\\]\ndove \\(L(\\theta | y)\\) rappresenta la funzione di verosimiglianza per i parametri \\(\\theta\\) dati gli osservazioni \\(y\\), e \\(p(y | \\theta)\\) indica la probabilit√† (o densit√†) di osservare i dati \\(y\\) dato un certo set di parametri \\(\\theta\\).\nPrendiamo l‚Äôesempio del lancio di una moneta. Se osserviamo 7 teste su 10 lanci, la funzione di massa di probabilit√† della distribuzione binomiale ci permette di calcolare la probabilit√† di questo esito per un dato valore di \\(p\\) (la probabilit√† di testa). In questo contesto, \\(p\\) √® fisso e i dati (\\(y = 7\\) teste in \\(n = 10\\) lanci) sono variabili.\nDall‚Äôaltro lato, se consideriamo \\(p\\) variabile, la funzione di verosimiglianza ci permette di valutare come diversi valori di \\(p\\) si adattano all‚Äôesito osservato di 7 teste su 10 lanci, mantenendo i dati osservati fissi.\n√à importante sottolineare che, bench√© le due funzioni condividano la stessa forma matematica, il loro utilizzo e interpretazione sono profondamente diversi. La funzione di densit√† di probabilit√† si concentra sulla probabilit√† degli esiti dati i parametri, mentre la funzione di verosimiglianza valuta la plausibilit√† dei parametri dati gli esiti. Questa distinzione √® cruciale per l‚Äôinferenza statistica, permettendoci di stimare i parametri del modello che meglio si adattano ai dati osservati e di comprendere in modo pi√π approfondito la struttura e le caratteristiche del fenomeno studiato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/chapter_3/09_likelihood.html#verosimiglianza-binomiale",
    "title": "32¬† La verosimiglianza",
    "section": "32.2 Verosimiglianza Binomiale",
    "text": "32.2 Verosimiglianza Binomiale\nProseguendo con l‚Äôesempio della distribuzione binomiale, approfondiamo la rilevanza della funzione di verosimiglianza nell‚Äôanalisi statistica attraverso uno scenario pratico. Supponiamo di condurre un esperimento con un numero definito di prove \\(n\\), ognuna delle quali pu√≤ terminare con un successo o un fallimento, come nel caso dei lanci di una moneta. Se registriamo \\(y\\) successi e \\(n - y\\) fallimenti, la probabilit√† di osservare esattamente \\(y\\) successi segue la funzione di massa di probabilit√† (FMP) binomiale, che √® definita come:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\theta\\) √® la probabilit√† di successo in una singola prova di Bernoulli.\nNell‚Äôutilizzo della funzione di verosimiglianza, ci concentriamo su come i diversi valori di \\(\\theta\\) possono spiegare i dati osservati \\(y\\). La verosimiglianza √® espressa come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y},\n\\]\ndato che il coefficiente binomiale \\(\\binom{n}{y}\\), non dipendendo da \\(\\theta\\), pu√≤ essere omesso per la semplicit√† della formulazione.\n\nEsempio 32.1 Per esemplificare, immaginiamo uno studio su un gruppo di 30 individui, di cui 23 presentano un atteggiamento negativo verso il futuro, un indicatore comune in pazienti con depressione (Zetsche, Buerkner, e Renneberg 2019). Qui, i nostri dati \\(y\\) e \\(n\\) sono fissi, e la funzione di verosimiglianza per \\(\\theta\\) sconosciuto diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} (1 - \\theta)^7.\n\\]\nValutando questa funzione per una serie di valori di \\(\\theta\\) possiamo determinare quale valore di \\(\\theta\\) rende i dati osservati pi√π verosimili. Procediamo simulando 100 valori equidistanti di \\(\\theta\\) nell‚Äôintervallo [0, 1] e calcoliamo la verosimiglianza per ciascuno di questi valori.\n\nn = 30\ny = 23\n\nCreiamo i possibili valori del parametro \\(\\theta\\) per i quali calcoleremo la verosimiglianza.\n\ntheta = np.linspace(0.0, 1.0, num=100)\nprint(theta)\n\n[0.         0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n 0.06060606 0.07070707 0.08080808 0.09090909 0.1010101  0.11111111\n 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n 0.18181818 0.19191919 0.2020202  0.21212121 0.22222222 0.23232323\n 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n 0.3030303  0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n 0.36363636 0.37373737 0.38383838 0.39393939 0.4040404  0.41414141\n 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.5959596\n 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n 0.66666667 0.67676768 0.68686869 0.6969697  0.70707071 0.71717172\n 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n 0.78787879 0.7979798  0.80808081 0.81818182 0.82828283 0.83838384\n 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.8989899\n 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n 0.96969697 0.97979798 0.98989899 1.        ]\n\n\nPer esempio, ponendo \\(\\theta = 0.1\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.1)\n\n9.7371682902e-18\n\n\nPonendo \\(\\theta = 0.2\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.2)\n\n3.58141723492221e-11\n\n\nSe ripetiamo questo processo 100 volte, una volta per ciascuno dei valori \\(\\theta\\) che abbiamo elencato sopra, otteniamo 100 coppie di punti \\(\\theta\\) e \\(f(\\theta)\\). A tale fine, definiamo la seguente funzione.\n\ndef like(r, n, theta):\n    return math.comb(n, r) * theta**r * (1 - theta) ** (n - r)\n\nLa curva che interpola i punti ottenuti √® la funzione di verosimiglianza, come indicato dalla figura seguente.\n\nplt.figure()\nplt.plot(theta, like(r=y, n=n, theta=theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");\n\n\n\n\n\n\n\n\n\n\n32.2.1 Interpretazione della Funzione di Verosimiglianza\nL‚Äôinterpretazione della funzione di verosimiglianza ci permette di misurare l‚Äôadattamento dei vari valori di \\(\\theta\\) ai dati. Il valore che massimizza la funzione indica la stima pi√π plausibile di \\(\\theta\\) dati i dati osservati. In termini pratici, se per esempio il valore che massimizza la verosimiglianza √® \\(\\theta = 0.767\\), ci√≤ suggerisce che la probabilit√† pi√π plausibile di successo (o atteggiamento negativo) nella nostra popolazione di studio √® del 76.7%.\nLa determinazione numerica di questo valore ottimale pu√≤ avvenire attraverso tecniche computazionali, come l‚Äôidentificazione del punto di massimo della funzione di verosimiglianza tramite metodi di ottimizzazione. L‚Äôuso di librerie statistiche e matematiche in linguaggi di programmazione come Python consente di effettuare queste analisi con precisione e efficienza, offrendo una stima accurata del parametro \\(\\theta\\) che meglio si adatta ai dati osservati.\nQuesta metodologia, basata sull‚Äôuso della funzione di verosimiglianza, √® cruciale per l‚Äôinferenza statistica, permettendo agli scienziati di stimare i parametri dei modelli statistici in modo informato e di valutare l‚Äôadeguatezza di tali modelli in rappresentanza dei dati reali.\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si pu√≤ localizzare l‚Äôindice nel vettore dei valori di verosimiglianza dove questa raggiunge il suo picco. Metodi computazionali, come l‚Äôuso della funzione argmax in NumPy, possono automatizzare questo processo. Una volta individuato l‚Äôindice che massimizza la verosimiglianza, si pu√≤ risalire al valore corrispondente di \\(\\theta\\) nel vettore dei parametri, ottenendo cos√¨ la stima di \\(\\theta\\) che rende i dati osservati pi√π plausibili.\n\nl = like(r=y, n=n, theta=theta)\nl.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\n√à importante notare che, invece di utilizzare la funzione like() che abbiamo definito precedentemente per motivi didattici, √® possibile ottenere lo stesso risultato utilizzando in modo equivalente la funzione binom.pmf().\n\nplt.figure()\nplt.plot(theta, stats.binom.pmf(y, n, theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#massima-verosimiglianza",
    "href": "chapters/chapter_3/09_likelihood.html#massima-verosimiglianza",
    "title": "32¬† La verosimiglianza",
    "section": "32.3 Massima verosimiglianza",
    "text": "32.3 Massima verosimiglianza\nTra tutti i possibili valori \\(\\theta\\) cerchiao il valore che massimizzi la probabilit√† dei dati osservati, ovvero, cerchiamo il valore \\(\\theta\\) che corrisponde al massimo della funzione di verosimiglianza.\nParliamo di ‚Äúminimizzazione‚Äù quando l ‚Äôobiettivo √® trovare il punto pi√π basso in una valle (minimizzare) o di ‚Äúmassimizzazione‚Äù, quando l‚Äôobiettivo √® quello di trovare il punto pi√π alto su una collina, a seconda della funzione. Nel caso della funzione di verosimiglianza, cerchiamo il punto in cui questa funzione raggiunge il suo valore massimo, ma poich√© molti algoritmi sono progettati per trovare minimi, possiamo cercare il minimo del negativo della funzione di verosimiglianza, che corrisponde al massimo della funzione stessa.\nLa Strategia di Base\n\nPunto di Partenza: L‚Äôalgoritmo inizia da un punto di partenza, che pu√≤ essere scelto casualmente o basato su una qualche ipotesi ragionevole.\nEsplorazione: L‚Äôalgoritmo esplora la ‚Äúsuperficie‚Äù della funzione, muovendosi in direzioni che sembrano portare verso il punto pi√π basso (o pi√π alto, se stiamo massimizzando). Questo √® simile a sentire la pendenza del terreno intorno a noi per decidere in quale direzione camminare.\nAggiustamento: Man mano che procede, l‚Äôalgoritmo aggiusta la sua traiettoria basandosi su ci√≤ che ha ‚Äúsentito‚Äù durante l‚Äôesplorazione. Se trova una discesa, continua in quella direzione; se incontra una salita, prova una direzione differente.\nConvergenza: Il processo continua finch√© l‚Äôalgoritmo non trova un punto in cui non ci sono pi√π discese significative in nessuna direzione, suggerendo che ha trovato il punto pi√π basso (o il punto pi√π alto, se stiamo massimizzando) raggiungibile da quel percorso.\n\nEsistono diversi metodi che l‚Äôalgoritmo pu√≤ utilizzare per decidere come muoversi. Alcuni esempi includono:\n\nDiscesa pi√π ripida (Gradient Descent): Utilizza il gradiente (la direzione e la pendenza della collina) per decidere in quale direzione muoversi.\nNewton-Raphson: Utilizza sia il gradiente sia la ‚Äúcurvatura‚Äù della funzione per fare passi pi√π informati verso il minimo.\nAlgoritmi Genetici: Ispirati dall‚Äôevoluzione biologica, questi algoritmi ‚Äúevolvono‚Äù una soluzione attraverso iterazioni che simulano la selezione naturale.\n\nIn termini intuitivi, dunque, l‚Äôottimizzazione √® un processo metodico di esplorazione e aggiustamento basato su feedback immediato dalla funzione che stiamo cercando di ottimizzare, con l‚Äôobiettivo di trovare il punto di massimo o minimo valore.\nDefiniamo dunque il negativo della funzione di verosimiglianza per l‚Äôottimizzazione (trovare il massimo della funzione):\n\ndef negative_likelihood(theta, n, y):\n    # Calcolo del negativo della funzione di verosimiglianza\n    return - (math.comb(n, y) * theta**y * (1 - theta) ** (n - y))\n\nUtilizziamo ora scipy.optimize.minimize per trovare il valore di theta che massimizza la verosimiglianza. Bisogna specificare un valore iniziale per theta, qui assumiamo 0.5 come punto di partenza. I vincoli su theta sono che deve essere compreso tra 0 e 1.\n\nresult = minimize(negative_likelihood, x0=0.5, args=(n, y), bounds=[(0, 1)])\nresult.x\n\narray([0.76666666])\n\n\n\n32.3.1 La Funzione di Log-Verosimiglianza\nProseguendo con il nostro approfondimento sull‚Äôanalisi statistica mediante la funzione di verosimiglianza, ci spostiamo verso una sua trasformazione matematica spesso preferita dagli statistici: la funzione di log-verosimiglianza. Il passaggio alla log-verosimiglianza, definita come il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y),\n\\tag{32.1}\\]\nnon altera la posizione del massimo della funzione originale grazie alla propriet√† di monotonicit√† del logaritmo. In termini pratici, ci√≤ significa che il valore di \\(\\theta\\) che massimizza la log-verosimiglianza, \\(\\hat{\\theta}\\), √® lo stesso che massimizza la verosimiglianza originale:\n\\[\n\\hat{\\theta} = \\arg \\max_{\\theta \\in \\Theta} \\ell(\\theta) = \\arg \\max_{\\theta \\in \\Theta} \\mathcal{L}(\\theta).\n\\]\nNell‚Äôanalisi di un campione di osservazioni, l‚Äôuso della log-verosimiglianza semplifica il processo di massimizzazione, che pu√≤ risultare complicato con la verosimiglianza tradizionale, soprattutto quando si gestiscono numeri molto piccoli. Questa semplificazione avviene perch√© la log-verosimiglianza trasforma il prodotto delle probabilit√† in una somma di logaritmi, rendendo il problema pi√π semplice e numericamente stabile. L‚Äôespressione della log-verosimiglianza per un modello binomiale, ad esempio, si presenta come segue:\n\\[\n\\ell(\\theta \\mid y) = \\log(\\theta^y (1 - \\theta)^{n - y}) = y \\log(\\theta) + (n - y) \\log(1 - \\theta).\n\\]\nQuesta formulazione trasforma il prodotto delle probabilit√† di osservazioni indipendenti in una somma, facilitando notevolmente i calcoli, specialmente per dataset di grandi dimensioni o in presenza di calcoli complessi. La forma logaritmica √® pi√π gestibile e si presta meglio all‚Äôapplicazione di tecniche di ottimizzazione numerica, grazie alla sua maggiore stabilit√† e alla riduzione di problemi come l‚Äôunderflow, comuni quando si lavora con probabilit√† molto piccole.\nRitornando all‚Äôesempio della distribuzione binomiale, l‚Äôapplicazione della log-verosimiglianza per il calcolo del parametro \\(\\theta\\) che meglio si adatta ai dati osservati pu√≤ essere eseguita con efficienza attraverso metodi computazionali. Per esempio, l‚Äôutilizzo di funzioni specifiche disponibili in pacchetti statistici, come binom.logpmf() in Python, permette di calcolare direttamente la log-verosimiglianza di un dato set di osservazioni per diversi valori di \\(\\theta\\). Questo approccio facilita la ricerca del valore di \\(\\theta\\) che massimizza la log-verosimiglianza, fornendo una stima accurata e computazionalmente efficiente del parametro.\nL‚Äôadozione della funzione di log-verosimiglianza, quindi, non solo consente di affrontare i limiti pratici legati alla manipolazione di piccole probabilit√†, ma offre anche un quadro concettuale chiaro per l‚Äôinterpretazione della plausibilit√† dei parametri del modello alla luce dei dati osservati. Questa trasformazione logaritmica rappresenta un passaggio cruciale nell‚Äôanalisi inferenziale, consentendo di stimare i parametri dei modelli statistici con maggiore precisione e affidabilit√†.\nPer illustrare questo concetto, riprendiamo l‚Äôesempio precedente e applichiamo la funzione di log-verosimiglianza per identificare il valore di $ $ che massimizza questa funzione. La rappresentazione grafica della funzione di log-verosimiglianza fornisce ulteriori intuizioni sul comportamento di questa funzione.\n\nn = 30\nr = 23\nplt.figure()\nplt.plot(theta, stats.binom.logpmf(y, n, theta), \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Log-verosimiglianza\");\n\n\n\n\n\n\n\n\nIl risultato replica quello trovato in precedenza con la funzione di verosimiglianza.\n\nll = stats.binom.logpmf(y, n, theta)\nll.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\nDefinizione della funzione del negativo della log-verosimiglianza con correzioni per evitare errori di dominio:\n\ndef corrected_negative_log_likelihood(theta, n, y):\n    # Assicurarsi che theta sia all'interno di un intervallo valido per evitare errori di logaritmo\n    theta = np.clip(theta, 1e-10, 1-1e-10)\n    return - (y * np.log(theta) + (n - y) * np.log(1 - theta))\n\nUtilizzo di scipy.optimize.minimize per trovare il valore di theta che massimizza la log-verosimiglianza:\n\nresult_log_likelihood_corrected = minimize(\n    corrected_negative_log_likelihood, x0=[0.5], args=(n, y), bounds=[(0, 1)]\n)\n\n\n# Il risultato ottimizzato per theta utilizzando la log-verosimiglianza corretta\noptimized_theta = result_log_likelihood_corrected.x\noptimized_theta\n\narray([0.76666666])\n\n\n\n\n32.3.2 Verosimiglianza Congiunta\nProseguendo nella nostra esplorazione dell‚Äôinferenza statistica attraverso la funzione di verosimiglianza, ci concentriamo ora sul caso in cui abbiamo pi√π osservazioni, tutte provenienti dalla stessa distribuzione binomiale e considerate indipendenti ed identicamente distribuite (IID). Tale scenario si presenta frequentemente nelle applicazioni pratiche, dove un insieme di \\(n\\) osservazioni \\(Y = [y_1, y_2, \\ldots, y_n]\\) viene raccolto sotto le stesse condizioni sperimentali.\nLa chiave per analizzare queste osservazioni congiuntamente risiede nel calcolo della probabilit√† congiunta di \\(y_1, y_2, \\ldots, y_n\\) data un‚Äôunica probabilit√† di successo \\(\\theta\\) comune a tutte le prove. L‚Äôindipendenza delle osservazioni ci consente di esprimere questa probabilit√† congiunta come il prodotto delle probabilit√† individuali di ciascuna osservazione:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa bellezza di questo approccio sta nel fatto che la verosimiglianza congiunta, che rappresenta la plausibilit√† complessiva di \\(\\theta\\) data l‚Äôintera sequenza di osservazioni \\(Y\\), √® semplicemente il prodotto delle verosimiglianze individuali di ogni osservazione \\(y_i\\) rispetto a \\(\\theta\\):\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta formulazione della verosimiglianza congiunta non solo evidenzia quanto bene il parametro \\(\\theta\\) si adatta all‚Äôintero set di dati \\(Y\\), ma offre anche una base metodologica solida per stimare \\(\\theta\\). Il parametro che massimizza la verosimiglianza congiunta, noto come stimatore di massima verosimiglianza (MLE) di \\(\\theta\\), √® quello che si ritiene essere il pi√π plausibile data l‚Äôosservazione dei dati.\nQuando abbiamo pi√π gruppi di osservazioni bernoulliane indipendenti ed identicamente distribuite (iid), la funzione di log-verosimiglianza congiunta per tutti i gruppi pu√≤ essere espressa come la somma delle log-verosimiglianze di ciascun gruppo. Ci√≤ √® dovuto alla propriet√† che il logaritmo del prodotto √® la somma dei logaritmi.\nSupponiamo di avere i seguenti dati per 4 gruppi di osservazioni:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 21 successi\nGruppo 3: 40 prove con 31 successi\nGruppo 4: 36 prove con 29 successi\n\nLa funzione di log-verosimiglianza congiunta per questi dati, assumendo una singola probabilit√† di successo \\(\\theta\\) per tutti i gruppi, √® data da:\n\\[\n\\log L(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove \\(n_i\\) e \\(y_i\\) sono rispettivamente il numero di prove e il numero di successi nel \\(i\\)-esimo gruppo.\nPer trovare il valore di \\(\\theta\\) che massimizza questa funzione di log-verosimiglianza, possiamo usare il metodo di ottimizzazione scipy.optimize.minimize, come abbiamo fatto in precedenza. Definiamo prima la funzione di log-verosimiglianza congiunta (usiamo np.clip per evitare errori):\n\ndef log_verosimiglianza_congiunta(theta, dati):\n    theta = np.clip(theta, 1e-10, 1-1e-10)  # Evita valori esattamente 0 o 1\n    log_likelihood = 0\n    for n, y in dati:\n        log_likelihood += y * np.log(theta) + (n - y) * np.log(1 - theta)\n    return -log_likelihood  # Restituisce il negativo per l'ottimizzazione\n\n\n# Dati dei gruppi: (prove, successi)\ndati_gruppi = [(30, 23), (28, 20), (40, 29), (36, 29)]\nprint(dati_gruppi)\n\n[(30, 23), (28, 20), (40, 29), (36, 29)]\n\n\nOttimizzazione con la funzione log_verosimiglianza_congiunta\n\nresult = minimize(\n    log_verosimiglianza_congiunta, x0=[0.5], args=(dati_gruppi,), bounds=[(0, 1)]\n)\n\n# Il risultato ottimizzato per theta con la funzione corretta\nresult.x\n\narray([0.75373134])\n\n\n\n# Intervallo di valori di theta da esplorare\ntheta_values = np.linspace(0.01, 0.99, 100)\n\n# Calcolo dei valori di log-verosimiglianza per ogni theta\nlog_likelihood_values = [log_verosimiglianza_congiunta(theta, dati_gruppi) for theta in theta_values]\n\n# Creazione del grafico\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, log_likelihood_values, label='Log-verosimiglianza')\nplt.xlabel('Theta')\nplt.ylabel('Log-verosimiglianza negativa')\nplt.title('Funzione di Log-verosimiglianza')\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/chapter_3/09_likelihood.html#la-verosimiglianza-marginale",
    "title": "32¬† La verosimiglianza",
    "section": "32.4 La Verosimiglianza Marginale",
    "text": "32.4 La Verosimiglianza Marginale\nAvanzando nella nostra discussione sulla verosimiglianza, approfondiamo ora un passaggio cruciale nell‚Äôapplicazione della teoria bayesiana: il concetto di verosimiglianza marginale. Questo approccio si rivela essenziale quando affrontiamo situazioni in cui il parametro di interesse, \\(\\theta\\), non √® definito da un valore singolo e fisso, ma √® invece descritto da una distribuzione di probabilit√† che riflette la nostra incertezza o variabilit√† su di esso.\nIn contesti pratici, non √® raro incontrare scenari in cui \\(\\theta\\) pu√≤ assumere una gamma di valori, ciascuno con una probabilit√† associata, piuttosto che un valore deterministico. L‚Äôintegrazione del parametro \\(\\theta\\) permette di calcolare la probabilit√† complessiva (o verosimiglianza) di osservare un determinato risultato dati tutti i possibili valori di \\(\\theta\\), piuttosto che appoggiarsi a un‚Äôanalisi basata su un singolo valore di \\(\\theta\\).\nConsideriamo, per esempio, una situazione in cui stiamo osservando una sequenza di prove binomiali, con un risultato specifico di interesse (ad esempio, \\(k=7\\) successi su \\(n=10\\) prove). Se \\(\\theta\\) rappresenta la probabilit√† di successo in ciascuna prova e pu√≤ assumere un insieme discreto di valori (per esempio, 0.1, 0.5, e 0.9) con probabilit√† uniforme, la verosimiglianza di osservare il nostro risultato specifico pu√≤ essere espressa come:\n\\[p(k=7, n=10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta),\\]\ndove \\(p(\\theta)\\) rappresenta la probabilit√† associata a ciascun possibile valore di \\(\\theta\\).\nTuttavia, in molte applicazioni reali, \\(\\theta\\) pu√≤ variare continuamente all‚Äôinterno di un intervallo, come tra 0 e 1 per una distribuzione binomiale. In questi casi, il calcolo della verosimiglianza marginale richiede l‚Äôutilizzo dell‚Äôintegrazione su tutto lo spazio dei valori possibili di \\(\\theta\\), riflettendo la gamma continua di possibili probabilit√† di successo. La formula si estende quindi a:\n\\[p(k=7, n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta) d\\theta,\\]\ndove \\(p(\\theta) d\\theta\\) rappresenta la densit√† di probabilit√† di \\(\\theta\\) su un intervallo infinitesimale, e l‚Äôintegrale copre tutti i possibili valori di \\(\\theta\\) da 0 a 1. Implementare questo calcolo nell‚Äôambito di uno spazio continuo richiede l‚Äôutilizzo di tecniche di integrazione.\nVediamo come sia possibile eseguire questo calcolo in Python, utilizzando la libreria scipy per l‚Äôintegrazione su uno spazio continuo:\n\n# Definire la funzione di verosimiglianza\ndef likelihood(theta):\n    return stats.binom.pmf(k=7, n=10, p=theta)\n\n# Calcolare la verosimiglianza marginale integrando su Œ∏\nmarginal_likelihood, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(\"La verosimiglianza marginale √®:\", marginal_likelihood)\n\nLa verosimiglianza marginale √®: 0.09090909090909094\n\n\nQuesto codice esegue l‚Äôintegrazione della funzione di verosimiglianza binomiale su tutti i possibili valori di Œ∏ (da 0 a 1), fornendo cos√¨ la verosimiglianza marginale per il nostro esempio. Questo processo ci permette di considerare l‚Äôincertezza su Œ∏, offrendo una visione completa della verosimiglianza dell‚Äôevento osservato senza fissare Œ∏ a un singolo valore.\nNumericamente, nell‚Äôesempio della verosimiglianza basata su una distribuzione binomiale precedente, la verosimiglianza marginale √® effettivamente interpretata come l‚Äôarea sottesa dalla funzione di verosimiglianza, calcolata integrandola su tutto l‚Äôintervallo dei possibili valori di \\(\\theta\\) (da 0 a 1, nel contesto di probabilit√†). Questa operazione di integrazione fornisce un valore che quantifica l‚Äôarea sotto la curva della funzione di verosimiglianza. Importante sottolineare, questo valore non corrisponde alla probabilit√† dei dati dati i parametri, dato che la verosimiglianza non √® una densit√† di probabilit√† sui parametri. Piuttosto, esso misura in che misura l‚Äôintero modello, considerando tutti i possibili valori del parametro, √® in grado di spiegare i dati osservati.\nLa vera importanza della verosimiglianza marginale emerge nel contesto dell‚Äôinferenza bayesiana: essa agisce come fattore di normalizzazione nella formula di Bayes. Nello specifico, la verosimiglianza marginale normalizza la funzione risultante dal prodotto tra la verosimiglianza e la distribuzione a priori dei parametri (il numeratore nella formula di Bayes), garantendo che il risultato sia una distribuzione di probabilit√† valida sullo spazio dei parametri. In altre parole, la verosimiglianza marginale assicura che l‚Äôarea sotto la curva della distribuzione posteriore sia esattamente 1, rendendola cos√¨ una vera distribuzione di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/chapter_3/09_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "32¬† La verosimiglianza",
    "section": "32.5 Modello Gaussiano e Verosimiglianza",
    "text": "32.5 Modello Gaussiano e Verosimiglianza\nAmpliamo ora la nostra analisi al caso della distribuzione gaussiana. Inizieremo con la verosimiglianza associata a una singola osservazione $ Y $, per poi estendere la discussione a un insieme di osservazioni gaussiane indipendenti e identicamente distribuite (IID).\n\n32.5.1 Caso di una Singola Osservazione\nIniziamo esaminiamo il caso di una singola osservazione. Quale esempio, prendiamo in considerazione la situazione in cui una variabile casuale rappresenta il Quoziente d‚ÄôIntelligenza (QI) di un individuo. Se consideriamo la distribuzione del QI come gaussiana, possiamo esprimere la funzione di verosimiglianza per un singolo valore osservato di QI tramite la formula della distribuzione gaussiana, che misura la probabilit√† di osservare quel particolare valore di QI dato un insieme di parametri specifici, \\(\\mu\\) (la media) e \\(\\sigma\\) (la deviazione standard). La verosimiglianza offre quindi un modo per quantificare quanto bene i parametri \\(\\mu\\) e \\(\\sigma\\) si accordano con il valore osservato di QI.\nSupponiamo che il QI osservato sia 114 e, per semplicit√†, assumiamo che la deviazione standard \\(\\sigma\\) sia conosciuta e pari a 15. Vogliamo esaminare un‚Äôampia gamma di possibili valori per la media \\(\\mu\\), diciamo tra 70 e 160, e valutare quale di questi valori rende pi√π plausibile l‚Äôosservazione fatta Definiamo quindi un insieme di 1000 valori per \\(\\mu\\) da esplorare:\n\nmu = np.linspace(70.0, 160.0, num=1000)\ny = 114\n\nLa nostra analisi consiste nell‚Äôapplicare la funzione di densit√† di probabilit√† gaussiana a ciascuno di questi 1000 valori di \\(\\mu\\), mantenendo fisso il valore osservato di QI, \\(y=114\\), e la deviazione standard, \\(\\sigma=15\\). In questo modo, possiamo costruire la funzione di verosimiglianza che esprime la plausibilit√† di ciascun valore di \\(\\mu\\) alla luce del QI osservato.\nIl calcolo specifico della densit√† di probabilit√† per ogni valore di \\(\\mu\\) pu√≤ essere eseguito con la funzione norm.pdf di scipy.stats, che accetta il valore osservato \\(y\\), un array di medie (i nostri valori di \\(\\mu\\)) e la deviazione standard \\(\\sigma\\). Per un singolo valore mu = 70, otteniamo\n\nstats.norm.pdf(y, loc=70, scale=15)\n\n0.00036007041207962535\n\n\nPer il valore mu = 70.05 otteniamo\n\nstats.norm.pdf(y, loc=70.05, scale=15)\n\n0.00036360634900376967\n\n\ne cos√¨ via. Se usiamo utti i 1000 valori possibili di mu, otteniamo un vettore di 1000 risultati:\n\nf_mu = stats.norm.pdf(y, loc=mu, scale=15)\n\nQuesto passaggio ci fornisce un array di valori che rappresentano la verosimiglianza di ciascun valore di \\(\\mu\\) data l‚Äôosservazione \\(y\\). Tracciando questi valori f_mu in funzione di \\(\\mu\\), otteniamo una curva di verosimiglianza che illustra visivamente quanto bene ciascun valore di \\(\\mu\\) si adatta al dato osservato y = 114:\n\nplt.figure()\nplt.plot(mu, f_mu, \"-\")\nplt.title(\"Funzione di verosimiglianza per QI = 114\")\nplt.xlabel(\"Valore di mu [70, 160]\")\nplt.ylabel(\"Verosimiglianza\")\nplt.xlim([70, 160])\nplt.show()\n\n\n\n\n\n\n\n\nAbbiamo dunque proceduto come nel caso della distribuzione binomiale esaminata in precedenza. Abbiamo utilizzato la formula\n\\[\nf(x | \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ntenendo costante il valore \\(x\\) = 114 e considerando noto \\(\\sigma\\) = 15, e abbiamo applicato la formula 1000 volte facendo variare mu ogni volta utilizziando ciascuno dei valori definiti con np.linspace(70.0, 160.0, num=1000).\nLa moda della distribuzione, si trova con\n\noptimal_mu = mu[f_mu.argmax()]\nprint(optimal_mu)\n\n113.96396396396396\n\n\nIn questo esempio, otteniamo il valore \\(\\mu\\) = 113.96 che massimizza la verosimiglianza.\nPer calcolare il massimo della log-verosimiglianza per una distribuzione Gaussiana usando la funzione optimize() di SciPy, possiamo seguire questi passi. Partiamo dalla formula della densit√† di probabilit√† della distribuzione gaussiana per una singola osservazione \\(y\\), con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La formula √®:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\n\\]\nPoich√© abbiamo una singola osservazione \\(y\\), la funzione di verosimiglianza coincide con la funzione di densit√† di probabilit√†. Quindi, prendiamo il logaritmo naturale di entrambi i lati della equazione della densit√† di probabilit√† gaussiana per ottenere la log-verosimiglianza:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log \\left( \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right) \\right)\n\\]\nApplichiamo le propriet√† dei logaritmi. Ricordiamo che:\n\n\\(\\log(ab) = \\log(a) + \\log(b)\\)\n\\(\\log\\left(\\frac{1}{a}\\right) = -\\log(a)\\)\n\\(\\log(e^x) = x\\)\n\nQuindi, possiamo scrivere:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log\\left(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\right) + \\log\\left(\\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\\right)\n\\]\n\\[\n= -\\log(\\sigma \\sqrt{2\\pi}) -\\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nRicordando che \\(\\log(ab) = \\log(a) + \\log(b)\\), possiamo scrivere \\(\\log(\\sigma \\sqrt{2\\pi})\\) come la somma di due logaritmi:\n\\[\n-\\log(\\sigma \\sqrt{2\\pi}) = -\\log(\\sigma) - \\log(\\sqrt{2\\pi}).\n\\]\nE dato che \\(\\log(\\sqrt{2\\pi}) = \\frac{1}{2}\\log(2\\pi)\\), possiamo sostituire per ottenere:\n\\[\n-\\log(\\sigma) - \\frac{1}{2}\\log(2\\pi).\n\\]\nCombinando tutto, otteniamo:\n\\[\n\\log L(\\mu; y, \\sigma) = -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2 \\sigma^2}.\n\\]\nQuesta √® la trasformata logaritmica della funzione di densit√† di probabilit√† gaussiana per una singola osservazione, che rappresenta la log-verosimiglianza di osservare \\(y\\) dato \\(\\mu\\) e \\(\\sigma\\).\nVogliamo trovare il valore di \\(\\mu\\) che massimizza questa funzione di log-verosimiglianza. Siccome optimize() di SciPy minimizza una funzione, possiamo passare il negativo della log-verosimiglianza per trovare il massimo.\n\n# Dati osservati\ny_obs = 114\nsigma = 15\n\n# Definizione della funzione negativa della log-verosimiglianza\ndef negative_log_likelihood(mu, y, sigma):\n    return 0.5 * np.log(2 * np.pi) + np.log(sigma) + ((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza\nresult = minimize(negative_log_likelihood, x0=0, args=(y_obs, sigma))\n\n# Il risultato ottimizzato per mu\nresult.x\n\narray([113.99997648])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per una distribuzione Gaussiana con \\(y = 114\\) e \\(\\sigma = 15\\) √® circa \\(114\\). Questo risultato dimostra che, nel caso di una distribuzione Gaussiana con una singola osservazione e deviazione standard nota, il massimo della log-verosimiglianza si ottiene quando la media stimata \\(\\mu\\) √® molto vicina al valore osservato \\(y\\).\n\n\n32.5.2 Campione indipendente di osservazioni da una distribuzione gaussiana\nPassiamo ora all‚Äôesame di un contesto pi√π complesso: quello di un campione composto da \\(n\\) osservazioni indipendenti, tutte provenienti da una distribuzione gaussiana. Consideriamo questo insieme di osservazioni come realizzazioni indipendenti ed identicamente distribuite (i.i.d.) di una variabile casuale \\(X\\), che segue una distribuzione normale con media $ $ e deviazione standard \\(\\sigma\\), entrambi parametri sconosciuti. Denotiamo questa situazione con la notazione \\(X \\sim N(\\mu, \\sigma^2)\\).\nIn presenza di osservazioni i.i.d., la densit√† di probabilit√† congiunta del campione √® il prodotto delle funzioni di densit√† per ogni singola osservazione. Matematicamente, ci√≤ si esprime attraverso l‚Äôequazione:\n\\[ p(y_1, y_2, \\ldots, y_n | \\mu, \\sigma) = \\prod_{i=1}^{n} p(y_i | \\mu, \\sigma), \\]\ndove \\(p(y_i | \\mu, \\sigma)\\) indica la funzione di densit√† gaussiana per l‚Äôosservazione \\(y_i\\), parametrizzata da \\(\\mu\\) e \\(\\sigma\\).\nSe manteniamo i dati osservati come costanti, ci√≤ che cambia in questa equazione quando variamo $ $ e \\(\\sigma\\) sono le probabilit√† associate ad ogni configurazione dei parametri, portandoci cos√¨ alla funzione di verosimiglianza congiunta per il campione.\n\nEsempio 32.2 Consideriamo, per illustrare questa dinamica, il caso di uno studio clinico che misura i punteggi del Beck Depression Inventory II (BDI-II) su trenta partecipanti. Supponiamo che questi punteggi seguano una distribuzione normale. Dati i punteggi BDI-II per i trenta partecipanti, il nostro obiettivo √® costruire una funzione di verosimiglianza per questi dati, assumendo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria di 6.50.\nPer la totalit√† del campione, la densit√† di probabilit√† congiunta diventa quindi il prodotto delle densit√† per ogni osservazione. Di conseguenza, la funzione di verosimiglianza per il campione intero √® rappresentata dal prodotto delle densit√† di probabilit√† di tutte le osservazioni.\nIn questo contesto, ogni possibile valore di \\(\\mu\\) viene valutato in termini di verosimiglianza. Per esemplificare, consideriamo un range di 1000 valori per \\(\\mu\\) e calcoliamo la funzione di verosimiglianza per ognuno di questi. Per rendere pi√π gestibili i calcoli, utilizziamo il logaritmo della funzione di verosimiglianza.\nDefinendo una funzione log_likelihood in Python che accetta i punteggi BDI-II \\(y\\), un valore medio \\(\\mu\\), e imposta \\(\\sigma\\) al valore noto, possiamo calcolare la log-verosimiglianza per un‚Äôampia gamma di valori di \\(\\mu\\) entro un intervallo specifico. Ci√≤ ci permette di visualizzare la credibilit√† relativa di ciascun valore di \\(\\mu\\) alla luce dei dati osservati.\nInfine, il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza corrisponde alla stima di massima verosimiglianza di \\(\\mu\\) data la distribuzione dei punteggi BDI-II nel campione. Questo valore, nel nostro esempio, coincide con la media campionaria dei punteggi BDI-II, offrendo una stima concorde con l‚Äôintuizione che la media del campione sia un buon rappresentante del parametro \\(\\mu\\) in una distribuzione normale.\nI dati sono:\n\ny = [\n    26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25,\n    28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n]\n\nIl nostro scopo √® sviluppare una funzione di verosimiglianza utilizzando le 30 osservazioni indicate sopra. Basandoci su studi precedenti, ipotizziamo che questi punteggi seguano una distribuzione normale. Assumiamo inoltre che la deviazione standard \\(\\sigma\\) sia nota e corrisponda a quella osservata nel campione, ossia 6.50.\nPer la prima osservazione del campione, dove \\(y_1 = 26\\), la funzione di densit√† di probabilit√† si esprime come:\n\\[\nf(26 \\,|\\, \\mu, \\sigma = 6.50) = \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(26 - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\]\nEstendendo questo calcolo all‚Äôintero campione, la funzione di densit√† di probabilit√† congiunta si ottiene come il prodotto delle densit√† di tutte le osservazioni individuali:\n\\[\nf(y \\,|\\, \\mu, \\sigma = 6.50) = \\prod_{i=1}^{n} f(y_i \\,|\\, \\mu, \\sigma = 6.50).\n\\]\nDi conseguenza, la funzione di verosimiglianza, indicata con \\(\\mathcal{L}(\\mu, \\sigma = 6.50 \\,|\\, y)\\), si determina moltiplicando insieme le densit√† di probabilit√† di tutte le osservazioni nel campione:\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu, \\sigma=6.50 \\,|\\, y) &= \\prod_{i=1}^{30} \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right) \\\\\n&= \\left( \\frac{1}{6.50\\sqrt{2\\pi}} \\right)^{30} \\exp\\left( -\\sum_{i=1}^{30} \\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\end{aligned}\n\\]\nIn questa formula, \\(\\mu\\) rappresenta il parametro di interesse, la media della distribuzione, la cui stima massimizza la funzione di verosimiglianza. Se si considerano 1000 valori differenti per \\(\\mu\\), dovremmo calcolare la funzione di verosimiglianza per ciascuno di questi valori.\nPer rendere i calcoli pi√π gestibili, √® consigliabile utilizzare il logaritmo della funzione di verosimiglianza. In Python, possiamo definire una funzione log_likelihood() che accetta come argomenti y, mu e sigma = true_sigma. Per semplificare, impostiamo true_sigma uguale alla deviazione standard osservata nel campione.\n\ntrue_sigma = np.std(y)\nprint(true_sigma)\n\n6.495810615739622\n\n\n\ndef log_likelihood(y, mu, sigma=true_sigma):\n    return np.sum(stats.norm.logpdf(y, loc=mu, scale=true_sigma))\n\nConsideriamo, ad esempio, il valore \\(\\mu_0 = \\bar{y}\\), ovvero\n\nbar_y = np.mean(y)\nprint(bar_y)\n\n30.933333333333334\n\n\nL‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di \\(\\mu = 30.93\\) √®\n\nlog_likelihood(y, 30.93, sigma=true_sigma)\n\n-98.70288339960591\n\n\nTroviamo ora i valori della log-verosimiglianza per ciascuno dei 1000 valori \\(\\mu\\) nell‚Äôintervallo \\([\\bar{y} - 2 \\sigma, \\bar{y} + 2 \\sigma]\\). Iniziamo a definire il vettore mu.\n\nmu = np.linspace(np.mean(y) - 2 * np.std(y), np.mean(y) + 2 * np.std(y), num=1000)\n\nTroviamo il valore dell‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di ciascuno dei 1000 valori mu che abbiamo definito.\n\nll = [log_likelihood(y, mu_val, true_sigma) for mu_val in mu]\n\nNel caso di un solo parametro sconosciuto (nel caso presente, \\(\\mu\\)) √® possibile rappresentare la log-verosimiglianza con una curva che interpola i punti (mu, ll). Tale funzione descrive la credibilit√† relativa che pu√≤ essere attribuita ai valori del parametro \\(\\mu\\) alla luce dei dati osservati.\n\nplt.figure()\nplt.plot(mu, ll, \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale mu\")\nplt.ylabel(\"Log-verosimiglianza\")\nplt.axvline(x=np.mean(y), alpha=0.4, ls=\"--\");\n\n\n\n\n\n\n\n\nIl valore \\(\\mu\\) pi√π credibile corrisponde al massimo della funzione di log-verosimiglinza e viene detto stima di massima verosimiglianza.\nIl massimo della funzione di log-verosimiglianza, ovvero 30.93 per l‚Äôesempio in discussione, √® identico alla media dei dati campionari.\nPer applicare lo stesso approccio usato precedentemente con optimize ad un campione di dati, anzich√© a una singola osservazione, possiamo modificare la funzione di log-verosimiglianza per prendere in considerazione tutte le osservazioni nel campione. La log-verosimiglianza per un campione da una distribuzione Gaussiana, dove ogni osservazione \\(y_i\\) ha la stessa media \\(\\mu\\) e deviazione standard \\(\\sigma\\), √® la somma delle log-verosimiglianze di ogni osservazione individuale.\nLa formula modificata per il campione sar√†:\n\\[\n\\log L(\\mu; y, \\sigma) = \\sum_{i=1}^{n} \\left[ -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y_i - \\mu)^2}{2 \\sigma^2} \\right],\n\\]\ndove \\(y\\) √® l‚Äôarray delle osservazioni e \\(n\\) √® il numero di osservazioni nel campione.\nPoich√©, per semplicit√†, assumiamo \\(\\sigma\\) come la deviazione standard del campione, prima calcoleremo \\(\\sigma\\) dal campione fornito e poi useremo quel valore per l‚Äôottimizzazione della log-verosimiglianza, cercando il valore di \\(\\mu\\) che la massimizza.\n\n# Calcolo della deviazione standard del campione\nsigma_sample = np.std(y, ddof=1)\n\n# Definizione della funzione negativa della log-verosimiglianza per il campione\ndef negative_log_likelihood_sample(mu, y, sigma):\n    n = len(y)\n    return n * 0.5 * np.log(2 * np.pi) + n * np.log(sigma) + np.sum((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza per il campione\nresult_sample = minimize(negative_log_likelihood_sample, x0=np.mean(y), args=(y, sigma_sample))\n\n# Il risultato ottimizzato per mu\nresult_sample.x\n\narray([30.93333333])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per il campione di dati fornito, assumendo noto il valore di \\(\\sigma\\) (la deviazione standard del campione), √® circa \\(30.93\\). Questo rappresenta la stima ottimale per la media della distribuzione Gaussiana che meglio si adatta al campione di dati dato.\n\n\n\n32.5.3 La Stima di Massima Verosimiglianza per \\(\\mu\\)\nPer determinare il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza, procediamo calcolando la sua derivata parziale rispetto a \\(\\mu\\) e impostando il risultato uguale a zero:\n\nPartiamo dalla funzione di log-verosimiglianza, che √® data da:\n\\[\n\\ell = -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\nCalcoliamo la derivata parziale di $ $ rispetto a $ $:\n\\[\n\\frac{\\partial \\ell}{\\partial \\mu} = \\sum_{i=1}^n \\frac{(y_i - \\mu)}{\\sigma^2}.\n\\]\nImpostiamo la derivata uguale a zero per trovare il punto di massimo:\n\\[\n\\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu) = 0.\n\\]\n\nRisolvendo questa equazione per $ $, otteniamo la stima di massima verosimiglianza:\n\\[\n\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar{y}.\n\\]\nQuesta formula ci mostra che la stima di massima verosimiglianza per \\(\\mu\\) corrisponde semplicemente alla media aritmetica delle osservazioni.\nQuesto processo pu√≤ essere analogamente applicato per stimare \\(\\sigma^2\\), la varianza, e si trova che la stima di massima verosimiglianza per \\(\\sigma^2\\) √® pari alla varianza campionaria.\nIn conclusione, all‚Äôinterno di una distribuzione gaussiana, le stime di massima verosimiglianza per \\(\\mu\\) (la media) e \\(\\sigma^2\\) (la varianza) coincidono con la media campionaria e la varianza campionaria, rispettivamente.\n\nEsempio 32.3 Consideriamo un esempio relativo all‚Äôapprendimento per rinforzo. Lo scopo degli studi sull‚Äôapprendimento per rinforzo √® quello di comprendere come le persone imparano a massimizzare le loro ricompense in situazioni in cui la scelta migliore √® inizialmente sconosciuta. In modo pi√π specifico, consideriamo il seguente problema di apprendimento. Un partecipante deve effettuare ripetutamente delle scelte tra diverse opzioni o azioni, e dopo ogni scelta riceve una ricompensa numerica estratta da una distribuzione di probabilit√† che dipende dall‚Äôazione selezionata. L‚Äôobiettivo del partecipante √® massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte. Per descrivere questa situazione, viene spesso utilizzata la metafora di un giocatore che deve fare una serie di \\(T\\) scelte tra \\(K\\) slot machine (conosciute anche come ‚Äúmulti-armed bandits‚Äù) al fine di massimizzare le sue vincite. Se nella scelta \\(t\\) viene selezionata la slot machine \\(k\\), viene ottenuta una ricompensa \\(r_t\\) che ha valore 1 con una probabilit√† di successo \\(\\mu^k_t\\), altrimenti ha valore 0. Le probabilit√† di successo sono diverse per ogni slot machine e inizialmente sono sconosciute al partecipante. Nella versione pi√π semplice di questo compito, le probabilit√† di successo rimangono costanti nel tempo.\nIl modello di Rescorla-Wagner √® un modello di apprendimento associativo che descrive come gli animali o gli umani aggiornano le loro aspettative di rinforzo in risposta a stimoli. Il modello pu√≤ essere descritto con la seguente formula di aggiornamento:\n\\[ V_{t+1} = V_t + \\alpha (\\lambda - V_t), \\]\ndove:\n\n\\(V_t\\) √® il valore predetto del rinforzo al tempo \\(t\\),\n\\(\\alpha\\) √® il tasso di apprendimento, un parametro che vogliamo stimare,\n\\(\\lambda\\) √® l‚Äôintensit√† del rinforzo,\n\\(V_{t+1}\\) √® il valore aggiornato dopo aver sperimentato il rinforzo.\n\nPer semplificare, consideriamo un caso in cui gli stimoli si presentano in maniera binaria (rinforzo presente o assente), e \\(\\lambda\\) √® noto. L‚Äôobiettivo √® stimare il valore di \\(\\alpha\\) che massimizza la verosimiglianza dei dati osservati sotto il modello.\nLa funzione di verosimiglianza per questo modello dipende dalla differenza tra i valori predetti e gli effettivi rinforzi ricevuti. Tuttavia, la formulazione esatta della funzione di verosimiglianza pu√≤ variare a seconda della specifica formulazione del problema e dei dati disponibili. Per mantenere le cose semplici, consideriamo una versione semplificata in cui la ‚Äúverosimiglianza‚Äù √® basata sulla somma dei quadrati degli errori (SSE) tra i rinforzi previsti e quelli osservati (anche se tecnicamente questo non √® un approccio basato sulla verosimiglianza nel senso statistico classico).\nPer questo esempio, assumiamo di avere un semplice set di dati di rinforzi osservati e vogliamo trovare il valore di \\(\\alpha\\) che minimizza l‚ÄôSSE:\n\\[ SSE = \\sum_{t=1}^{n} (\\lambda - V_t)^2. \\]\nEcco un esempio di implementazione in Python che utilizza scipy.optimize.minimize per stimare \\(\\alpha\\):\n\n# Dati di esempio: rinforzi osservati (lambda)\n# In questo esempio, assumiamo lambda = 1 per rinforzo presente e lambda = 0 per rinforzo assente\n# per semplicit√†. In pratica, lambda potrebbe essere diverso a seconda degli esperimenti.\nrinforzi_osservati = [1, 0, 1, 1, 0, 1]  # Esempio di sequenza di rinforzi\n\n\n# Funzione che calcola l'SSE per un dato valore di alpha\ndef sse(alpha, rinforzi, V0=0):\n    V = V0\n    sse = 0\n    for lambda_ in rinforzi:\n        sse += (lambda_ - V)**2\n        V += alpha * (lambda_ - V)  # Aggiornamento del valore secondo il modello Rescorla-Wagner\n    return sse\n\n# Ottimizzazione per trovare il valore di alpha che minimizza l'SSE\nresult_alpha = minimize(sse, x0=0.5, args=(rinforzi_osservati,))\n\n# Il risultato ottimizzato per alpha\nresult_alpha.x\n\narray([0.29739989])\n\n\nIl valore di \\(\\alpha\\) (tasso di apprendimento) che minimizza la somma dei quadrati degli errori (SSE) per il modello di Rescorla-Wagner, dato il campione di rinforzi osservati, √® circa \\(0.297\\). Questo suggerisce che il tasso di apprendimento ottimale per adattare il modello ai dati osservati in questo esempio semplificato √® di circa 0.297, secondo l‚Äôapproccio di minimizzazione dell‚Äôerrore utilizzato qui.\n\n\nEsempio 32.4 Consideriamo ora un esempio relativo alla distribuzione esponenziale. Supponiamo che i seguenti siano i tempi di attesa per un certo evento:\n\ndata = np.array([27, 64, 3, 18, 8])\n\nDefiniamo la funzione di log-verosimiglianza negativa. Per iniziare, ricordiamo che la funzione di densit√† di probabilit√† (PDF) per una distribuzione esponenziale, dato un tasso \\(\\lambda\\), √® definita come:\n\\[\nf(x; \\lambda) = \\lambda e^{-\\lambda x} \\quad \\text{per } x \\geq 0.\n\\]\nLa verosimiglianza (\\(L\\)) di osservare un insieme di dati \\(\\{x_1, x_2, ..., x_n\\}\\) dato un parametro \\(\\lambda\\) √® il prodotto delle funzioni di densit√† di probabilit√† per ogni punto dati, assumendo che ciascun dato sia indipendente dagli altri. Quindi, per \\(n\\) dati osservati, la funzione di verosimiglianza √®:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} f(x_i; \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\n\\]\nLa log-verosimiglianza (\\(\\log(L(\\lambda))\\)) √® il logaritmo naturale di \\(L(\\lambda)\\). Utilizziamo il logaritmo per semplificare la moltiplicazione in una somma, il che rende pi√π semplici sia il calcolo che la differenziazione. Pertanto, la log-verosimiglianza diventa:\n\\[\n\\log(L(\\lambda)) = \\log\\left(\\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\\right) = \\sum_{i=1}^{n} \\log(\\lambda e^{-\\lambda x_i}) = \\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nIl motivo per utilizzare il negativo della log-verosimiglianza, cio√® \\(-\\log(L(\\lambda))\\), nelle tecniche di ottimizzazione, √® perch√© molte librerie e funzioni di ottimizzazione sono progettate per minimizzare una funzione obiettivo piuttosto che massimizzarla. Dato che vogliamo trovare il valore di \\(\\lambda\\) che massimizza la log-verosimiglianza (e quindi la verosimiglianza), possiamo invece minimizzare il suo negativo. Di conseguenza, la funzione obiettivo che passiamo all‚Äôalgoritmo di minimizzazione √®:\n\\[\n-\\log(L(\\lambda)) = -\\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nScriviamo la funzione in Python:\n\ndef neg_log_likelihood(lambda_, data, eps=1e-8):\n    lambda_ = np.clip(lambda_, eps, None)  # Assicura che lambda_ sia almeno eps\n    return -np.sum(np.log(lambda_) - lambda_ * data)\n\nMinimizzaziamo la funzione di log-verosimiglianza negativa:\n\nresult = minimize(neg_log_likelihood, x0=0.1, args=(data,), bounds=[(0, None)])\nprint(f\"Il valore di lambda che massimizza la log-verosimiglianza √®: {result.x[0]}\")\n\nIl valore di lambda che massimizza la log-verosimiglianza √®: 0.04166666292998713\n\n\nAvendo trovato il tasso \\(\\lambda\\), la stima di massima verosimiglianza del tempo di attesa medio diventa:\n\n1 / result.x\n\narray([24.00000215])\n\n\nVisualizzazione.\n\nlambda_opt = result.x[0]\nlambda_array = np.geomspace(0.01, 0.1, 100)\nLL = [-neg_log_likelihood(L, data) for L in lambda_array]\n\nplt.plot(lambda_array, LL, label='Log-likelihood')\nplt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\nplt.xlabel('$\\lambda$')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood over a range of $\\lambda$ values')\nplt.legend()\nplt.show()\n\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:6: SyntaxWarning: invalid escape sequence '\\l'\n  plt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:7: SyntaxWarning: invalid escape sequence '\\l'\n  plt.xlabel('$\\lambda$')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:9: SyntaxWarning: invalid escape sequence '\\l'\n  plt.title('Log-likelihood over a range of $\\lambda$ values')",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#conclusione-e-riflessioni-finali",
    "href": "chapters/chapter_3/09_likelihood.html#conclusione-e-riflessioni-finali",
    "title": "32¬† La verosimiglianza",
    "section": "32.6 Conclusione e Riflessioni Finali",
    "text": "32.6 Conclusione e Riflessioni Finali\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilit√† dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l‚Äôinsieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza √® centrale nella pratica dell‚Äôinferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo √® fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto √® indispensabile per un‚Äôanalisi dati rigorosa e per un‚Äôinterpretazione accurata dei risultati.\nUn‚Äôapplicazione pratica e illustrativa dei principi esposti in questo capitolo √® fornita nella sezione sul modello Rescorla-Wagner, che √® un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l‚Äôapplicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi √® impegnato nella ricerca empirica e nell‚Äôinterpretazione di dati complessi.\n\n\n\n\n\n\nAll‚Äôesame ti verr√† chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/09_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "32¬† La verosimiglianza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nSyntaxError: invalid syntax (2307612016.py, line 1)\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html",
    "href": "chapters/chapter_3/10_grid_gauss.html",
    "title": "33¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo √® estendere la discussione precedente sul calcolo della distribuzione a posteriori utilizzando la verosimiglianza gaussiana, introducendo il metodo basato sulla griglia.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#un-prior-uniforme",
    "href": "chapters/chapter_3/10_grid_gauss.html#un-prior-uniforme",
    "title": "33¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "33.1 Un prior uniforme",
    "text": "33.1 Un prior uniforme\nConsideriamo il caso in cui abbiamo un campione di 10 osservazioni. Questo campione √® generato mediante il campionamento casuale da una Normale di media 50 e deviazione standard pari a 5. Nella simulazione successiva considereremo \\(\\sigma\\) nota.\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilit√†\nvera_media = 50  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione)\nprint(campione)\n\n[48.54283933 43.64834594 54.59899393 61.47236626 48.30510499 43.11175964\n 60.88971922 39.33729382 52.25731836 50.64725801]\n\n\nCreiamo ora una griglia di 100 elementi con valori compresi tra 40 e 60.\n\nmedia_griglia = np.linspace(start=40, stop=60, num=100)  # 100 punti tra 40 e 60\nprint(media_griglia)\n\n[40.         40.2020202  40.4040404  40.60606061 40.80808081 41.01010101\n 41.21212121 41.41414141 41.61616162 41.81818182 42.02020202 42.22222222\n 42.42424242 42.62626263 42.82828283 43.03030303 43.23232323 43.43434343\n 43.63636364 43.83838384 44.04040404 44.24242424 44.44444444 44.64646465\n 44.84848485 45.05050505 45.25252525 45.45454545 45.65656566 45.85858586\n 46.06060606 46.26262626 46.46464646 46.66666667 46.86868687 47.07070707\n 47.27272727 47.47474747 47.67676768 47.87878788 48.08080808 48.28282828\n 48.48484848 48.68686869 48.88888889 49.09090909 49.29292929 49.49494949\n 49.6969697  49.8989899  50.1010101  50.3030303  50.50505051 50.70707071\n 50.90909091 51.11111111 51.31313131 51.51515152 51.71717172 51.91919192\n 52.12121212 52.32323232 52.52525253 52.72727273 52.92929293 53.13131313\n 53.33333333 53.53535354 53.73737374 53.93939394 54.14141414 54.34343434\n 54.54545455 54.74747475 54.94949495 55.15151515 55.35353535 55.55555556\n 55.75757576 55.95959596 56.16161616 56.36363636 56.56565657 56.76767677\n 56.96969697 57.17171717 57.37373737 57.57575758 57.77777778 57.97979798\n 58.18181818 58.38383838 58.58585859 58.78787879 58.98989899 59.19191919\n 59.39393939 59.5959596  59.7979798  60.        ]\n\n\nCalcoliamo la likelihood.\n\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\nlikelihood\n\narray([4.43497974e-25, 1.00961743e-24, 2.26116493e-24, 4.98216199e-24,\n       1.07997486e-23, 2.30313636e-23, 4.83209939e-23, 9.97383700e-23,\n       2.02534436e-22, 4.04618453e-22, 7.95248204e-22, 1.53769396e-21,\n       2.92514449e-21, 5.47437998e-21, 1.00793553e-20, 1.82574775e-20,\n       3.25356129e-20, 5.70410371e-20, 9.83843533e-20, 1.66945554e-19,\n       2.78698020e-19, 4.57723393e-19, 7.39575534e-19, 1.17563407e-18,\n       1.83853539e-18, 2.82866831e-18, 4.28156219e-18, 6.37577071e-18,\n       9.34056882e-18, 1.34624518e-17, 1.90890888e-17, 2.66290968e-17,\n       3.65458340e-17, 4.93434508e-17, 6.55437614e-17, 8.56531629e-17,\n       1.10119860e-16, 1.39282995e-16, 1.73316833e-16, 2.12174698e-16,\n       2.55538678e-16, 3.02781890e-16, 3.52950131e-16, 4.04768775e-16,\n       4.56678807e-16, 5.06903062e-16, 5.53540208e-16, 5.94680409e-16,\n       6.28533301e-16, 6.53556524e-16, 6.68572052e-16, 6.72858096e-16,\n       6.66206627e-16, 6.48940106e-16, 6.21885576e-16, 5.86308990e-16,\n       5.43817056e-16, 4.96237176e-16, 4.45487960e-16, 3.93452986e-16,\n       3.41869158e-16, 2.92238345e-16, 2.45767628e-16, 2.03339784e-16,\n       1.65512287e-16, 1.32540414e-16, 1.04418297e-16, 8.09310345e-17,\n       6.17111697e-17, 4.62937824e-17, 3.41658127e-17, 2.48068172e-17,\n       1.77198703e-17, 1.24526055e-17, 8.60934527e-18, 5.85585374e-18,\n       3.91850601e-18, 2.57965137e-18, 1.67075095e-18, 1.06456606e-18,\n       6.67334716e-19, 4.11552289e-19, 2.49698841e-19, 1.49045282e-19,\n       8.75246011e-20, 5.05652605e-20, 2.87398541e-20, 1.60704142e-20,\n       8.84056013e-21, 4.78456761e-21, 2.54750949e-21, 1.33444023e-21,\n       6.87689899e-22, 3.48655374e-22, 1.73904286e-22, 8.53364173e-23,\n       4.11972976e-23, 1.95665048e-23, 9.14256335e-24, 4.20274369e-24])\n\n\nLa likelihood rappresenta quanto sono verosimili i dati osservati dato un certo parametro (o set di parametri) del modello. Nel contesto della distribuzione gaussiana, la likelihood di un insieme di osservazioni dato un valore specifico della media (\\(\\mu\\)) e conoscendo la deviazione standard (\\(\\sigma\\)) si calcola come il prodotto delle densit√† di probabilit√† di ogni osservazione data quella media e deviazione standard. Questo approccio si basa sull‚Äôassunzione di indipendenza tra le osservazioni.\nIl codice precedente calcola la likelihood per una serie di valori possibili della media (\\(\\mu\\)), mantenendo la deviazione standard (\\(\\sigma\\)) come un valore noto e fisso. Ecco come funziona passo dopo passo:\nlikelihood = np.array([np.prod(norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\nnorm.pdf(campione, loc=media, scale=sigma_conosciuta): Per ogni valore di media nella griglia specificata (media_griglia), questa espressione calcola la densit√† di probabilit√† (PDF) della distribuzione normale per ciascun punto nel campione (campione). loc=media specifica il valore medio della distribuzione normale considerata in quel momento, mentre scale=sigma_conosciuta indica la deviazione standard della distribuzione, che √® considerata nota e costante per tutti i calcoli. Il risultato di norm.pdf per ogni valore di media √® un array che contiene le probabilit√† di ogni osservazione del campione date quella media e la deviazione standard conosciuta.\nnp.prod(...): Calcola il prodotto degli elementi nell‚Äôarray restituito da norm.pdf, ovvero moltiplica tra loro le probabilit√† di tutte le osservazioni del campione per il valore corrente di media. Questo prodotto rappresenta la likelihood complessiva del campione dato quel valore specifico della media, assumendo che le osservazioni siano indipendenti. Il concetto di indipendenza √® cruciale qui perch√© ci permette di moltiplicare le probabilit√† delle singole osservazioni per ottenere la probabilit√† complessiva (likelihood) del set di dati.\nComprehension list [...] for media in media_griglia: Questa parte del codice esegue il calcolo della likelihood per ogni valore di media nella griglia e salva i risultati in un array NumPy. Quindi, per ciascun valore possibile della media considerata, calcoliamo quanto il campione osservato sia verosimile, data quella media e la deviazione standard nota.\n\nIl risultato finale, likelihood, √® un array dove ogni elemento corrisponde alla likelihood del campione di dati osservati per un specifico valore della media sulla griglia.\nPer fare un esempio, consideriamo il primo punto della griglia, corrispondente ad una una media di \\(40\\) (dato che media_griglia √® definita da 40 a 60). Calcoliamo la densit√† di probabilit√† (PDF) per ogni osservazione nel campione dato questo valore della media (\\(40\\)) e una deviazione standard conosciuta di \\(5\\). Ecco le PDF per ciascuna osservazione nel campione:\n[2.28493333e-02, 4.62542534e-02, 3.31420922e-02, 3.00464741e-02,\n 1.11418804e-05, 1.96649746e-02, 2.18282203e-02, 2.11292630e-02,\n 4.05476440e-03, 1.40537162e-07]\nQuesti valori rappresentano la densit√† di probabilit√† di osservare ciascuna misurazione data una distribuzione normale con media \\(40\\) e deviazione standard \\(5\\). La likelihood del campione dato questo valore della media √® calcolata come il prodotto di queste densit√† di probabilit√†, risultando in \\(6.060521630996206 \\times 10^{-26}\\).\nQuesto numero molto piccolo riflette il fatto che, dato un valore medio di \\(40\\), la probabilit√† complessiva di osservare questo specifico campione √® estremamente bassa.\nPer costruire la likelihood completa, ripetiamo questa procedura per ogni punto della nostra griglia di valori.\nDopo aver calcolato la likelihood per ogni punto, procediamo moltiplicandola per il valore del prior corrispondente. Questo passaggio ci consente di ottenere una distribuzione a posteriori non ancora normalizzata.\nNel contesto di una griglia discreta, la normalizzazione della distribuzione a posteriori pu√≤ essere facilmente conseguita dividendo ogni valore per la somma totale dei valori della distribuzione a posteriori.\n\nprior = np.ones(len(media_griglia))  # Una prior uniforme\nposterior_non_norm = likelihood * prior  # Calcoliamo la posterior non normalizzata moltiplicando per la prior\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizziamo la posterior\n\nLa figura successiva presenta una rappresentazione grafica della distribuzione a posteriori normalizzata.\n\nplt.plot(media_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media')\nplt.xlabel('Media')\nplt.ylabel('Probabilit√†')\nplt.show()\n\n\n\n\n\n\n\n\nPer fare un altro esempio, consideriamo un prior non uniforme corrispondente ad una distribuzione gaussiana con media 40 e \\(\\sigma\\) = 3.\n\n# Calcolo della prior gaussiana per ogni valore della griglia della media\nprior = stats.norm.pdf(media_griglia, loc=40, scale=3)\n\n# Calcolo della likelihood (rimane invariato)\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\n# Calcolo della distribuzione a posteriori (aggiornamento con la nuova prior)\nposterior_non_norm = likelihood * prior  # Moltiplicazione element-wise\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizzazione\n\nRiesaminiamo la distribuzione a posteriori calcolata in questo caso, confrontandola con la distribuzione a priori. √à importante notare che, in questo secondo esempio, la distribuzione a posteriori mostra una ‚Äútraslazione‚Äù in direzione del prior.\n\nplt.plot(media_griglia, posterior, label='Posterior')\nplt.plot(media_griglia, prior / np.sum(prior), label='Prior', linestyle='--')\nplt.title('Distribuzione a Posteriori e Prior della Media')\nplt.xlabel('Media')\nplt.ylabel('Densit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nDopo aver calcolato la distribuzione a posteriori come mostrato sopra, per ottenere un campione casuale da questa distribuzione possiamo seguire un approccio di campionamento discreto. Poich√© la distribuzione a posteriori √® definita su una griglia di valori della media, possiamo utilizzare il campionamento ponderato per selezionare casualmente un valore dalla griglia secondo le probabilit√† a posteriori.\nQuesto metodo ci permette di ‚Äúcampionare‚Äù dalla distribuzione a posteriori nonostante essa sia rappresentata in forma discreta anzich√© continua. Ecco come si pu√≤ fare in Python:\n\n# Selezione casuale di un indice dalla griglia secondo le probabilit√† a posteriori\nindice_campionato = np.random.choice(a=len(media_griglia), size=1000, p=posterior)\n\n# Estrazione del valore della media corrispondente all'indice campionato\nmedia_campionata = media_griglia[indice_campionato]\nmedia_campionata.shape\n\n(1000,)\n\n\nIl metodo np.random.choice permette di selezionare un indice dalla griglia con probabilit√† proporzionale ai valori della distribuzione a posteriori. In questo modo, i valori della media con probabilit√† a posteriori pi√π alta saranno selezionati pi√π frequentemente, riflettendo la loro maggiore plausibilit√† data la combinazione dei dati osservati e della prior.\nQuesto campione dalla distribuzione a posteriori rappresenta quindi una possibile stima della media della popolazione, tenendo conto sia dei dati osservati (attraverso la likelihood) sia delle nostre conoscenze o supposizioni precedenti (attraverso la prior).\nL‚Äôistogramma seguente mostra la distribuzione di un campione casuale ottenuto dalla distribuzione a posteriori.\n\n_ = sns.histplot(media_campionata)\n\n\n\n\n\n\n\n\nCalcoliamo ora la media a posteriori:\n\nnp.mean(media_campionata)\n\n48.07676767676767\n\n\nL‚Äôintervallo di credibilit√† al 94% √® dato da:\n\n# Calcolo del 3¬∞ e 97¬∞ percentile dei campioni per ottenere l'intervallo di credibilit√† al 95%\nlimite_inferiore = np.percentile(media_campionata, 3)\nlimite_superiore = np.percentile(media_campionata, 97)\n\nprint(f\"Intervallo di credibilit√† al 94% per la media: [{limite_inferiore}, {limite_superiore}]\")\n\nIntervallo di credibilit√† al 94% per la media: [45.45454545454545, 50.511111111111106]\n\n\nL‚Äôintervallo di credibilit√† al 94%, calcolato come descritto sopra, rappresenta un intervallo all‚Äôinterno del quale ci aspettiamo che si trovi il vero valore della media della popolazione con una probabilit√† del 94%. In altre parole, basandoci sulle informazioni ottenute dai campioni e su precedenti conoscenze rappresentate dalla distribuzione a priori, possiamo essere il 94% confidenti che l‚Äôintervallo definito dal 3¬∞ al 97¬∞ percentile includa la vera media della popolazione.\nL‚Äôintervallo di credibilit√† che √® stato calcolato offre una stima probabilitica di dove si trova il vero valore della media della popolazione, basandosi sui dati del campione e sull‚Äôapproccio inferenziale bayesiano. Questo intervallo fornisce quindi una misura diretta dell‚Äôincertezza della nostra stima, riflettendo la forza e la precisione delle evidenze a nostra disposizione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#la-log-verosimiglianza",
    "href": "chapters/chapter_3/10_grid_gauss.html#la-log-verosimiglianza",
    "title": "33¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "33.2 La Log-Verosimiglianza",
    "text": "33.2 La Log-Verosimiglianza\nNell‚Äôesempio presente abbiamo calcolato la verosimiglianza con una somma. Tuttavia questo produce dei problemi e, in generale, √® preferibile lavorare con i logaritmi.\nStabilit√† Numerica I prodotti di molte probabilit√† piccole possono portare a un ‚Äúunderflow‚Äù numerico, dove il valore risultante √® cos√¨ piccolo che viene arrotondato a zero dalla rappresentazione in virgola mobile del computer. I logaritmi trasformano questi prodotti in somme, riducendo significativamente il rischio di underflow.\nSemplificazione dei Calcoli Il logaritmo di un prodotto √® uguale alla somma dei logaritmi (log(ab) = log(a) + log(b)). Questo trasforma il prodotto di molte verosimiglianze in una somma di logaritmi, semplificando i calcoli e migliorando l‚Äôefficienza computazionale.\nMiglioramento della Precisione I calcolatori sono generalmente pi√π precisi nel sommare che nel moltiplicare numeri, specialmente quando si tratta di numeri molto grandi o molto piccoli. L‚Äôuso dei logaritmi pu√≤ quindi aiutare a mantenere una maggiore precisione nei calcoli.\nFacilit√† di Ottimizzazione Molti algoritmi di ottimizzazione lavorano meglio con somme piuttosto che con prodotti, soprattutto perch√© le derivate delle funzioni somma sono pi√π semplici da calcolare rispetto a quelle dei prodotti. Questo √® particolarmente utile nella stima di massima verosimiglianza e in altri contesti di ottimizzazione bayesiana.\nGestione di Valori Estremi I logaritmi possono aiutare a gestire meglio un ampio range di valori, riducendo gli effetti di valori estremamente grandi o piccoli che potrebbero altrimenti dominare il prodotto di verosimiglianze e portare a risultati distorti.\nIn conclusione, l‚Äôuso dei logaritmi nella stima delle distribuzioni posteriori e in altri calcoli probabilistici offre numerosi vantaggi in termini di stabilit√† numerica, precisione e efficienza computazionale, rendendolo un approccio preferibile in molte situazioni.\nPer riprodurre l‚Äôesempio precedente utilizzando la log-verosimiglianza, anzich√© lavorare direttamente con i valori delle verosimiglianze, convertiremo i calcoli in termini di logaritmi. Questo approccio migliora la stabilit√† numerica e l‚Äôefficienza dei calcoli, come discusso precedentemente. Seguiamo il processo passo dopo passo:\n\nGenerazione del Campione: Iniziamo generando un campione dalla distribuzione normale con una media vera e una deviazione standard conosciuta.\nDefinizione della Griglia per la Media: Stabiliremo una griglia di valori possibili per la media sulla quale calcoleremo la log-verosimiglianza.\nCalcolo della Log-Likelihood: Calcoleremo la log-verosimiglianza per ciascun valore della griglia, utilizzando la densit√† di probabilit√† normale.\nApplicazione della Prior e Calcolo della Posterior: Moltiplicheremo la log-verosimiglianza per la log-prior (se applicabile) e normalizzeremo per ottenere la distribuzione a posteriori.\nVisualizzazione: Infine, visualizzeremo la distribuzione a posteriori della media.\n\nProcediamo con l‚Äôimplementazione in Python:\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilit√†\nvera_media = 50  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione)\n\n# Definizione della griglia per la media\nmedia_griglia = np.linspace(start=40, stop=60, num=100)  \n\n# Calcolo della log-likelihood\nlog_likelihood = np.array([np.sum(stats.norm.logpdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\n# Calcoliamo la log-prior gaussiana\nlog_prior = stats.norm.logpdf(media_griglia, loc=40, scale=3)\n\n# Calcoliamo la log-posterior non normalizzata sommando log-likelihood e log-prior\nlog_posterior_non_norm = log_likelihood + log_prior  \n\n# Normalizziamo la log-posterior\nlog_posterior = log_posterior_non_norm - np.log(np.sum(np.exp(log_posterior_non_norm - np.max(log_posterior_non_norm))))\nposterior = np.exp(log_posterior)\n\n# Visualizzazione della distribuzione a posteriori\nplt.plot(media_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media (Log-verosimiglianza)')\nplt.xlabel('Media')\nplt.ylabel('Probabilit√†')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#deviazione-standard-ignota",
    "href": "chapters/chapter_3/10_grid_gauss.html#deviazione-standard-ignota",
    "title": "33¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "33.3 Deviazione Standard Ignota",
    "text": "33.3 Deviazione Standard Ignota\nEstendere l‚Äôapproccio usato sopra al caso in cui la deviazione standard (\\(\\sigma\\)) della popolazione non √® conosciuta introduce una complessit√† maggiore nell‚Äôinferenza bayesiana, poich√© ora dobbiamo stimare due parametri (la media e la deviazione standard) invece di uno solo. In questo contesto, la distribuzione a posteriori diventa una funzione delle due dimensioni (media e \\(\\sigma\\)), e la sua esplorazione richiede metodi pi√π sofisticati per navigare efficacemente lo spazio dei parametri. Vediamo come affrontare questo problema:\n\n33.3.1 1. Definizione dello Spazio dei Parametri\nDobbiamo definire una griglia bidimensionale che copra le possibili combinazioni di valori per la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)). Questo approccio, sebbene computazionalmente intensivo, √® fattibile per problemi di dimensioni moderate.\n\nmu_griglia = np.linspace(start=40, stop=60, num=100)\nsigma_griglia = np.linspace(start=1, stop=10, num=50)\n\n\n\n33.3.2 2. Calcolo della Log-Likelihood Bidimensionale\nPer ogni coppia di valori (\\(\\mu\\), \\(\\sigma\\)) nella griglia, calcoliamo la log-likelihood del campione. Questo richiede un‚Äôiterazione su entrambe le dimensioni della griglia.\n\nlog_likelihood_2d = np.array([[np.sum(stats.norm.logpdf(campione, loc=mu, scale=sigma))\n                                for sigma in sigma_griglia] for mu in mu_griglia])\n\n\n\n33.3.3 3. Applicazione delle Priors\nLe priors per \\(\\mu\\) e \\(\\sigma\\) possono essere definite in modo indipendente e poi combinate, o si pu√≤ definire una prior congiunta che rifletta la conoscenza o le assunzioni sui parametri. Le log-priors per \\(\\mu\\) e \\(\\sigma\\) sono calcolate su ogni griglia rispettivamente e poi sommate per ottenere una log-prior congiunta.\n\nlog_prior_mu = stats.norm.logpdf(mu_griglia, loc=40, scale=5)\nlog_prior_sigma = stats.norm.logpdf(sigma_griglia, loc=5, scale=2)\nlog_prior_2d = log_prior_mu[:, np.newaxis] + log_prior_sigma\n\n\n\n33.3.4 4. Calcolo della Distribuzione a Posteriori Bidimensionale\nSommando la log-likelihood con la log-prior congiunta e normalizzando, otteniamo la distribuzione a posteriori bidimensionale.\n\nlog_posterior_2d = log_likelihood_2d + log_prior_2d\nlog_posterior_2d -= np.max(log_posterior_2d)  # Stabilizzazione\nposterior_2d = np.exp(log_posterior_2d)\nposterior_2d /= np.sum(posterior_2d)\n\n\n\n33.3.5 5. Visualizzazione\nLa visualizzazione di distribuzioni bidimensionali pu√≤ essere effettuata tramite contour plot o heatmaps.\n\nplt.contourf(mu_griglia, sigma_griglia, posterior_2d.T)\nplt.xlabel('Media ($\\mu$)')\nplt.ylabel('Deviazione Standard ($\\sigma$)')\nplt.colorbar(label='Densit√† Posterior')\nplt.title('Distribuzione a Posteriori Bidimensionale')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#conclusione-e-riflessioni-finali",
    "href": "chapters/chapter_3/10_grid_gauss.html#conclusione-e-riflessioni-finali",
    "title": "33¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "33.4 Conclusione e Riflessioni Finali",
    "text": "33.4 Conclusione e Riflessioni Finali\nQuesto approccio richiede di navigare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, rendendo l‚Äôanalisi pi√π computazionalmente intensiva. Inoltre, la scelta delle priors per pi√π parametri richiede attenzione, poich√© influenzer√† direttamente le stime a posteriori.\nPer problemi con pi√π dimensioni o quando l‚Äôesplorazione della griglia diventa impraticabile, metodi come il campionamento di Markov Chain Monte Carlo (MCMC) diventano essenziali. Questi metodi permettono di campionare efficacemente dalla distribuzione a posteriori senza dover esplorare esplicitamente tutto lo spazio dei parametri.\nIn sintesi, l‚Äôestensione dell‚Äôapproccio bayesiano a casi in cui pi√π parametri sono sconosciuti richiede una maggiore attenzione nella definizione dello spazio dei parametri, nella scelta delle priors, e nel calcolo delle distribuzioni a posteriori",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/10_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "33¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Mar 20 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.1\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/introduction_chapter_4.html",
    "href": "chapters/chapter_4/introduction_chapter_4.html",
    "title": "34¬† Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa fornisce un‚Äôintroduzione all‚Äôinferenza bayesiana, una metodologia statistica per stimare un parametro di interesse \\(\\theta\\) (come la media di una popolazione o il coefficiente di regressione) utilizzando il Teorema di Bayes. L‚Äôapproccio bayesiano tiene conto sia dei dati osservati che delle conoscenze iniziali per ottenere una stima del parametro \\(\\theta\\) sotto forma di una distribuzione di probabilit√†, comunemente definita come distribuzione a posteriori.\nIn questa parte del materiale, esploreremo il processo di aggiornamento bayesiano e le tecniche per sintetizzare la distribuzione a posteriori. Discuteremo le famiglie di distribuzioni coniugate, concentrandoci principalmente sul caso beta-binomiale, poich√© consentono una derivazione analitica della distribuzione a posteriori. Esamineremo anche le procedure Monte Carlo a Catena di Markov, in particolare l‚Äôalgoritmo di Metropolis, che permette di approssimare la distribuzione a posteriori quando non √® possibile ottenere una soluzione analitica.\nIntrodotto il concetto di predizione bayesiana, fondamentale per costruire la distribuzione predittiva a posteriori, discuteremo anche della distribuzione predittiva a priori. Applicheremo l‚Äôinferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esploreremo inoltre il modello bayesiano di Poisson per le frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento efficace per affrontare situazioni in cui le osservazioni sono organizzate in diversi livelli di incertezza.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html",
    "href": "chapters/chapter_4/01_intro_bayes.html",
    "title": "35¬† Modellazione bayesiana",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo Capitolo √® di introdurre il quadro concettuale dela modellizzazione bayesiana.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#inferenza-statistica",
    "href": "chapters/chapter_4/01_intro_bayes.html#inferenza-statistica",
    "title": "35¬† Modellazione bayesiana",
    "section": "35.1 Inferenza Statistica",
    "text": "35.1 Inferenza Statistica\nL‚Äôinferenza statistica si configura come un processo che integra deduzione e induzione, finalizzato all‚Äôesame di dati campionari per dedurre le propriet√† di una popolazione pi√π ampia. Immaginiamo di analizzare l‚Äôaltezza di cinque soggetti selezionati casualmente. Un meccanismo sottostante, che chiameremo ‚Äúprocesso T‚Äù, governa la determinazione delle loro altezze. Comprendere o stimare questo processo √® l‚Äôobiettivo dell‚Äôinferenza statistica. La natura di T √® spesso avvolta nel mistero, oscurata dalla variabilit√† dei dati che osserviamo. Questa variabilit√† pu√≤ essere scissa in due grandi cause: la variabilit√† intrinseca del fenomeno sotto osservazione (come differenze genetiche o ambientali) e le limitazioni delle nostre capacit√† di osservazione e analisi.\nMcElreath (2020) nel suo lavoro ‚ÄúStatistical Rethinking‚Äù introduce il concetto di ‚ÄúGrande Mondo‚Äù, che rappresenta l‚Äôinfinit√† di processi possibili che potrebbero spiegare le nostre osservazioni. Di fronte a questa infinit√†, effettuare inferenze dirette su tutte le possibili propriet√† del Grande Mondo si rivela impraticabile. Ci orientiamo quindi verso il ‚ÄúPiccolo Mondo‚Äù, una rappresentazione semplificata che considera un insieme finito di modelli e parametri ritenuti rilevanti per il nostro studio. Per esempio, nell‚Äôanalisi dell‚Äôaltezza, potremmo proporre un modello probabilistico in cui l‚Äôaltezza segue una distribuzione normale, caratterizzata da una media (¬µ) e una deviazione standard (œÉ), con l‚Äôintento di stimare questi parametri ignoti.\nLa collezione di distribuzioni di probabilit√† derivante dalla variazione dei parametri del modello nel Piccolo Mondo costituisce la funzione di verosimiglianza. Questo insieme, tuttavia, √® spesso troppo ampio per essere gestito con facilit√†. La nostra conoscenza pregressa o le nostre convinzioni riguardo al fenomeno in esame ci assistono nel restringere le possibilit√†.\nNell‚Äôinferenza bayesiana, queste convinzioni iniziali vengono espresse tramite una densit√† di probabilit√† a priori, che attribuisce un peso ai possibili parametri del modello in base alle nostre convinzioni iniziali. La regola di Bayes sta al cuore dell‚Äôinferenza bayesiana, permettendoci di aggiornare queste convinzioni alla luce dei nuovi dati osservati. Attraverso questo processo, otteniamo la probabilit√† a posteriori dei parametri, che fornisce una stima pi√π accurata del processo generativo dei dati, T.\nL‚Äôinferenza statistica, dunque, ci avvicina alla comprensione di fenomeni complessi attraverso la modellazione delle osservazioni via processi semplificati nel ‚ÄúPiccolo Mondo‚Äù. Grazie all‚Äôinferenza bayesiana, che integra le conoscenze pregresse ai nuovi dati, perfezioniamo le nostre stime per una comprensione pi√π profonda del vero processo sottostante.\nLa nota affermazione di Box, Luceno, e del Carmen Paniagua-Quinones (2011)\n\nTutti i modelli sono sbagliati, ma alcuni sono utili\n\ncattura l‚Äôessenza dell‚Äôinferenza statistica. Non miriamo a un ‚Äúmodello perfetto‚Äù che rifletta ogni dettaglio del ‚ÄúGrande Mondo‚Äù, bens√¨ a individuare modelli del ‚ÄúPiccolo Mondo‚Äù che siano efficaci nel fare previsioni sul fenomeno studiato.\nAttraverso la statistica, disponiamo degli strumenti per costruire, valutare e selezionare modelli basati sull‚Äôinferenza bayesiana, che ci consentono di aggiornare e rifinire i nostri modelli in risposta a nuove informazioni. Questo processo ci guida verso modelli ‚Äúutili‚Äù, che, seppur non perfetti, ci permettono di fare previsioni accurate e di approfondire la nostra comprensione del fenomeno di interesse.\n\n35.1.1 I Metodi Bayesiani in Psicologia\nNell‚Äôambito dell‚Äôinferenza statistica, i metodi bayesiani hanno guadagnato sempre popolarit√† anche in psicologia, dove l‚Äôadozione di approcci bayesiani ha visto una crescita esponenziale, grazie anche alla disponibilit√† di risorse educative e pubblicazioni specializzate. In particolare, diversi testi di rilievo hanno contribuito in modo significativo a fornire agli studiosi gli strumenti necessari per applicare con successo l‚Äôinferenza bayesiana all‚Äôanalisi dei dati psicologici. Tra questi testi spiccano opere come quelle di Albert e Hu (2019), Johnson, Ott, e Dogucu (2022), McElreath (2020) e Kruschke (2014), che hanno svolto un ruolo fondamentale nel facilitare l‚Äôintegrazione dei metodi bayesiani nella pratica analitica della psicologia.\n\n\n35.1.2 Approccio Bayesiano alla Statistica\nL‚Äôapproccio bayesiano alla statistica si distingue non solo per l‚Äôuso del Teorema di Bayes, ma anche per il suo modo di gestire l‚Äôincertezza e di valutare l‚Äôintero spettro di possibili esiti attraverso le distribuzioni di probabilit√†. Questo approccio rifiuta l‚Äôadozione acritica di stime puntuali, favorendo invece una visione probabilistica che accoglie una vasta gamma di esiti, rimanendo fedele alla concezione bayesiana della probabilit√†.\n\n\n35.1.3 Elementi Fondamentali della Modellazione Statistica Bayesiana\nI fondamenti della modellazione statistica bayesiana includono variabili casuali, distribuzioni di probabilit√† priori e posteriori, e il processo di aggiornamento bayesiano.\n\nVariabili casuali rappresentano elementi chiave nella modellazione bayesiana, consentendoci di esprimere e quantificare relazioni probabilistiche.\nDistribuzioni di probabilit√† sono strumenti cruciali per rappresentare quantitativamente l‚Äôincertezza e le conoscenze pregresse. Le distribuzioni priori esprimono le nostre convinzioni iniziali, mentre le distribuzioni posteriori risultano dall‚Äôintegrazione delle nuove evidenze.\nL‚Äôaggiornamento bayesiano √® il meccanismo che affina le distribuzioni priori alla luce di nuovi dati, riducendo l‚Äôincertezza e migliorando le stime dei parametri.\n\nLa modellazione bayesiana segue un approccio metodologico strutturato in progettazione del modello, applicazione del teorema di Bayes, e valutazione critica del modello. Questo flusso di lavoro bayesiano (Baribault e Collins 2023) costituisce un ciclo di apprendimento e affinamento continuo, che esploreremo nei capitoli successivi per una comprensione approfondita del processo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#riesame-del-teorema-di-bayes",
    "href": "chapters/chapter_4/01_intro_bayes.html#riesame-del-teorema-di-bayes",
    "title": "35¬† Modellazione bayesiana",
    "section": "35.2 Riesame del Teorema di Bayes",
    "text": "35.2 Riesame del Teorema di Bayes\nPrima di approfondire il flusso di lavoro bayesiano, √® opportuno rivisitare il teorema di Bayes. Quando ci riferiamo ad eventi osservabili discreti, possiamo esprimere la regola nel modo seguente:\n\\[ P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)} \\]\nDato un vettore di dati \\(y\\), il teorema di Bayes ci permette di calcolare le distribuzioni posteriori dei parametri di interesse, che possiamo rappresentare con il vettore dei parametri \\(\\theta\\). Questo calcolo si realizza riformulando la formula precedente come quella scritta di seguito. La differenza qui consiste nel fatto che il teorema di Bayes √® scritto in termini di distribuzioni di probabilit√†. In questo contesto, \\(p(\\cdot)\\) rappresenta una funzione di densit√† di probabilit√† (nel caso continuo) o una funzione di massa di probabilit√† (nel caso discreto).\n\\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta) \\times p(\\theta)}{p(y)} \\]\nLa suddetta affermazione pu√≤ essere riscritta in parole nel modo seguente:\n\\[\n\\text{Posteriore} = \\frac{\\text{Verosimiglianza √ó A Priori}}{\\text{Verosimiglianza Marginale}}  \n\\]\nI termini qui presentati hanno il seguente significato.\n\nIl Posteriore, \\(p(\\theta \\mid y)\\), √® la distribuzione di probabilit√† dei parametri condizionata ai dati.\nLa Verosimiglianza, \\(p(y \\mid \\theta)\\), come descritto nel capitolo {ref}notebook-likelihood, √® la PMF (nel caso discreto) o la PDF (nel caso continuo) espressa come funzione di \\(\\theta\\).\nL‚ÄôA Priori, \\(p(\\theta)\\), √® la distribuzione di probabilit√† iniziale dei parametri, prima di osservare i dati.\nLa Verosimiglianza Marginale, \\(p(y)\\) standardizza la distribuzione posteriore per garantire che l‚Äôarea sotto la curva della distribuzione sommi a 1, ossia, si assicura che il posteriore sia una distribuzione di probabilit√† valida.\n\nNell‚Äôambito bayesiano, si utilizzano le distribuzioni posteriori aggiornate dei parametri per l‚Äôinferenza, ad esempio per calcolare la probabilit√† che un parametro si trovi entro un determinato intervallo.\nLe distribuzioni a priori, indicate con \\(p(\\theta)\\), sono basate su risultati precedenti, o possono assumere la forma di ‚Äúdistribuzioni di regolarizzazione‚Äù non informative. Un vantaggio significativo delle distribuzioni a priori emerge quando si lavora con campioni di dati di piccole dimensioni; in tali contesti, le distribuzioni a priori di regolarizzazione possono esercitare un effetto moderatore, attenuando le fluttuazioni causate dalla limitata numerosit√† del campione.\nNel definire il processo di modellazione, consideriamo una variabile casuale \\(Y\\), con un valore osservato \\(y\\). Ad esempio, il punteggio ottenuto da uno studente in un test di psicometria pu√≤ essere modellato come \\(Y\\), che assume uno specifico valore \\(y\\) una volta osservato il punteggio. Per spiegare come i dati osservati \\(y\\) siano generati, specificiamo un modello di probabilit√†, il cosiddetto processo generatore di dati (DGP).\nIl parametro \\(\\theta\\) caratterizza il modello di probabilit√† di interesse, potendo essere uno scalare (come media o varianza) o un vettore (ad esempio, coefficienti di regressione). L‚Äôobiettivo dell‚Äôinferenza statistica √® stimare questi parametri sconosciuti a partire dai dati. A differenza dell‚Äôinferenza frequentista, che considera \\(\\theta\\) come fisso ma sconosciuto, l‚Äôinferenza bayesiana tratta \\(\\theta\\) come una variabile casuale soggetta a una distribuzione di probabilit√† a priori.\nIn questo contesto, la probabilit√† congiunta di parametri e dati si calcola come funzione della distribuzione condizionale dei dati dati i parametri e della distribuzione a priori dei parametri. La distribuzione posteriore di \\(\\theta\\) dato \\(y\\) si deriva moltiplicando la funzione di verosimiglianza dei dati \\(p(y \\mid \\theta)\\) per la distribuzione a priori \\(p(\\theta)\\), e normalizzando per \\(p(y)\\). Nei modelli complessi con numerosi parametri, l‚Äôelaborazione della distribuzione posteriore pu√≤ richiedere tecniche computazionali avanzate.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#costruzione-del-modello-dellaggiornamento-bayesiano",
    "href": "chapters/chapter_4/01_intro_bayes.html#costruzione-del-modello-dellaggiornamento-bayesiano",
    "title": "35¬† Modellazione bayesiana",
    "section": "35.3 Costruzione del Modello dell‚ÄôAggiornamento Bayesiano",
    "text": "35.3 Costruzione del Modello dell‚ÄôAggiornamento Bayesiano\nPer spiegare il concetto di aggiornamento bayesiano in maniera intuitiva, McElreath (2020) propone il seguente esempio. Supponiamo di avere un mappamondo e di volere stimare qual √® la proporzione coperta d‚Äôacqua del globo. Per stimare questa proporzione eseguiamo il seguente esperimento casuale: lanciamo in aria il mappamondo e poi lo afferriamo quando cade. Registriamo se la superficie sotto il nostro indice destro √® terra o acqua. Ripetiamo questa procedura un certo numero di volte e calcoliamo la proporzione di volte in cui abbiamo osservato ‚Äúacqua‚Äù. In ogni lancio, ogni valore della proporzione sconosciuta \\(p\\) pu√≤ essere pi√π o meno plausibile, date le evidenze fornite dai lanci precedenti.\nUn modello bayesiano inizia assegnando un insieme di plausibilit√† iniziali a ciascuno dei possibili valori \\(p\\), dette plausibilit√† priori. Poi, queste plausibilit√† vengono aggiornate alla luce dei dati raccolti, producendo le plausibilit√† posteriori. Questo processo di aggiornamento √® una forma di apprendimento, conosciuto come aggiornamento bayesiano.\nNell‚Äôesempio di McElreath (2020), supponiamo che il nostro modello bayesiano assegni inizialmente la stessa plausibilit√† a ogni possibile valore di \\(p\\) (proporzione di acqua). Ora, osserviamo il primo grafico in alto a sinistra nella figura generata dallo script. La linea tratteggiata orizzontale rappresenta la plausibilit√† iniziale di ciascun possibile valore di \\(p\\). Dopo aver visto il primo lancio, che risulta in ‚ÄúW‚Äù (acqua), il modello aggiorna le plausibilit√† alla linea continua. La plausibilit√† che \\(p\\) = 0 scende a zero, indicando che √® ‚Äúimpossibile‚Äù non avere acqua, dato che abbiamo osservato almeno una traccia di acqua sul globo. Allo stesso modo, la plausibilit√† che \\(p\\) &gt; 0.5 aumenta, poich√© non c‚Äô√® ancora evidenza di terra sul globo, quindi le plausibilit√† iniziali vengono modificate per essere coerenti con questa osservazione. Tuttavia, le differenze nelle plausibilit√† non sono ancora molto grandi, poich√© le evidenze raccolte finora sono limitate. In questo modo, la quantit√† di evidenza vista finora si riflette nelle plausibilit√† di ciascun valore di \\(p\\): la plausibilit√† che \\(p\\) sia 0 √® zero e la plausibilit√† che \\(p\\) sia 1 √® massima. Quindi, la distribuzione a posteriori di \\(p\\) √® rappresentata dalla linea continua che collega questi due estremi.\nNei grafici successivi, vengono introdotti ulteriori campioni dal globo, uno alla volta. Ogni curva tratteggiata rappresenta la curva continua dal grafico precedente, spostandosi da sinistra a destra e dall‚Äôalto in basso. La seconda osservazione √® ‚Äúterra‚Äù (L). La distribuzione a priori √® la linea tratteggiata del secondo pannello e la distribuzione a postriori √® la linea curva. Otteniamo questa curva perch√© assegniamo una verosimiglianza 0 agli eventi \\(p\\) = 0 (abbiamo osservato ‚Äúacqua‚Äù) e \\(p\\) = 1 (abbiamo osservato ‚Äúterra‚Äù). In due lanci abbiamo osservato una volta ‚Äúterra‚Äù e una volta ‚Äúacqua‚Äù. Dunque la plausibilit√† che \\(p\\) = 0.5 √® massima. Da cui la curva che abbiamo disegnato.\nIl terzo lancio del mappamondo produce nuovamente ‚Äúacqua‚Äù. Quindi a questo punto il valore pi√π plausibile di \\(p\\) √® 0.75. modifichiamo dunque la distribuzione a priori (linea tratteggiata nel terzo pannello) in modo da rappresentare le nostre nuove conoscenze, come indicato dalla linea continua.\nOgni volta che viene osservato un ‚ÄúW‚Äù, il picco della curva di plausibilit√† si sposta a destra, verso valori maggiori di \\(p\\). Ogni volta che viene osservato un ‚ÄúL‚Äù (terra), si sposta nella direzione opposta. L‚Äôaltezza massima della curva aumenta con ogni campione, significando che la plausibilit√† complessiva (1) viene ridistribuita ad un numero minore di valori di \\(p\\) i quali accumulano una maggiore plausibilit√† man mano che aumenta la quantit√† di evidenza. Con l‚Äôaggiunta di ogni nuova osservazione, la curva viene aggiornata in modo coerente con tutte le osservazioni precedenti.\n√à importante notare che ogni set aggiornato di plausibilit√† diventa la plausibilit√† iniziale per l‚Äôosservazione successiva. Ogni conclusione √® il punto di partenza per l‚Äôinferenza futura. Questo processo di aggiornamento funziona anche al contrario: conoscendo l‚Äôultimo set di plausibilit√† e l‚Äôultima osservazione, √® possibile matematicamente dedurre la curva di plausibilit√† precedente. I dati potrebbero essere presentati al modello in qualsiasi ordine, o anche tutti insieme. Nella maggior parte dei casi, i dati verranno considerati tutti insieme per comodit√†, ma √® importante capire che ci√≤ rappresenta solo l‚Äôabbreviazione di un processo di apprendimento iterato.\n\ndef beta(W, L, p):\n    return factorial(W + L + 1) / (factorial(W) * factorial(L)) * p ** W * (1-p) ** L\n\n\ndef plot_beta_from_observations(observations: str, resolution: int = 50, **plot_kwargs):\n    \"\"\"Calcualte the posterior for a string of observations\"\"\"\n    n_W = len(observations.replace(\"L\", \"\"))\n    n_L = len(observations) - n_W\n    proportions = np.linspace(0, 1, resolution)\n        \n    probs = beta(n_W, n_L, proportions)\n    plt.plot(proportions, probs, **plot_kwargs)\n    plt.yticks([])\n    plt.title(observations)\n    \n\n# Tossing the globe\nobservations = \"WLWWWLWLW\"\nfig, axs = plt.subplots(3, 3, figsize=(8, 8))\nfor ii in range(9):\n    ax = axs[ii // 3][ii % 3]\n    plt.sca(ax)\n    # Plot previous\n    if ii &gt; 0:\n        plot_beta_from_observations(observations[:ii], color='k', linestyle='--')\n    else:\n        # First observation, no previous data\n        plot_beta_from_observations('', color='k', linestyle='--')\n        \n    color = 'C1' if observations[ii] == 'W' else 'C0'\n    plot_beta_from_observations(observations[:ii+1], color=color, linewidth=4, alpha=.5)\n    \n    if not ii % 3:\n        plt.ylabel(\"posterior probability\")\n\n\n\n\n\n\n\n\nIl lettore attento si sar√† chiesto se la curva continua dell‚Äôultimo pannello non sia in realt√† identica alla funzione di verosimiglianza binomiale con 6 successi in 9 prove ‚Äì si veda il Capitolo 32. In effetti √® proprio cos√¨. Lo stesso vale, ovviamente, per ciascuno dei pannelli della figura.\n\ny = 6\nn = 9\ntheta = np.linspace(0.0, 1.0, num=100)\n\nlike = stats.binom.pmf(y, n, theta)\n\nplt.plot(theta, like, \"-\", linewidth=4, alpha=.5)\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\n_ = plt.ylabel(\"Verosimiglianza\")\n\n\n\n\n\n\n\n\nQuesto esempio illustra come la funzione di probabilit√† a posteriori si modifichi progressivamente con l‚Äôacquisizione di nuove evidenze. Tale processo avviene in maniera automatica, riflettendo il meccanismo di aggiornamento delle credenze che caratterizza l‚Äôinferenza bayesiana. In ogni pannello, la transizione dalla linea tratteggiata alla linea piena simboleggia questo aggiornamento: la linea tratteggiata rappresenta la distribuzione di probabilit√† a priori, ovvero le nostre credenze iniziali prima dell‚Äôosservazione dei nuovi dati; la linea piena, invece, rappresenta la distribuzione di probabilit√† a posteriori, che integra le nuove evidenze ai preconcetti iniziali. Quest‚Äôultima rispecchia dunque una sintesi ottimizzata delle informazioni pregresse e attuali, offrendo una rappresentazione aggiornata e pi√π accurata della realt√† in esame.\n\n35.3.1 Il flusso di lavoro bayesiano\nMetaforicamente descritto come ‚Äúgirare la manovella bayesiana‚Äù, il flusso di lavoro bayesiano √® composto da diverse fasi.\n\nStudio di Simulazione: Questa fase prevede la generazione di dati sintetici che riproducono il contesto di ricerca. Questo aiuta a valutare la robustezza del disegno sperimentale e ad assicurare che il modello sia adeguato.\nRaccolta e Identificazione dei Dati: Qui si acquisiscono e analizzano i dati reali, assicurandosi che siano appropriati per le analisi successive.\nSelezione del Modello Statistico: In questa fase si formula un modello statistico che rappresenta le teorie e le ipotesi alla base della ricerca, basandosi su una solida comprensione del fenomeno e su principi statistici.\nDefinizione delle Distribuzioni a Priori: Si stabiliscono le distribuzioni a priori dei parametri del modello, basandosi su conoscenze pregresse e un ragionamento teorico robusto.\nCalcolo delle Distribuzioni a Posteriori: Utilizzando metodi analitici o tecniche di campionamento come le Catene di Markov Monte Carlo (MCMC), si derivano le distribuzioni a posteriori dei parametri.\nRisoluzione dei Problemi e Diagnostica: In questa fase si eseguono controlli per assicurare la convergenza del modello e la validit√† delle inferenze, utilizzando metriche e diagnosi specializzate.\nControlli di Coerenza: Oltre alla diagnostica tecnica, si valuta la coerenza e la plausibilit√† del modello rispetto ai dati e al contesto teorico, incluso un esame predittivo a posteriori.\nInterpretazione e Comunicazione dei Risultati: Infine, i risultati vengono interpretati nel contesto della teoria sottostante e comunicati in modo chiaro, integrandoli nell‚Äôambito pi√π ampio della comprensione del fenomeno in studio.\n\nQuesto processo iterativo mira a ottenere inferenze valide, fornendo una base solida per la ricerca scientifica. Una rappresentazione visiva di questo flusso di lavoro bayesiano √® illustrata nella figura tratta dall‚Äôarticolo di Baribault e Collins (2023).\n\n\n\n\n\n\nFigura¬†35.1: Una rappresentazione abbreviata del flusso di lavoro bayesiano. L‚Äôoutput del modello che non supera il filtro (che rappresenta i necessari controlli computazionali e di coerenza) deve essere respinto. √à necessario migliorare la specifica del modello in modo che l‚Äôoutput possa superare tutti i controlli. Solo allora il modello bayesiano pu√≤ essere utilizzato come base per l‚Äôinferenza. (Figura tratta da Baribault e Collins (2023)).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#notazione",
    "href": "chapters/chapter_4/01_intro_bayes.html#notazione",
    "title": "35¬† Modellazione bayesiana",
    "section": "35.4 Notazione",
    "text": "35.4 Notazione\nLa costruzione di modelli statistici bayesiani che incorporano questo approccio probabilistico per caratterizzare l‚Äôincertezza richiede innanzitutto una familiarizzazione con il linguaggio e le notazioni matematiche utilizzate nella formulazione di questi modelli. Questa conoscenza facilita la comunicazione delle caratteristiche del modello e l‚Äôestensione del linguaggio di modellazione a vari domini.\nNel seguito utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo invece \\(x\\) per denotare le quantit√† note, come ad esempio i predittori di un modello lineare.\nAl fine di rappresentare in modo pi√π conciso i modelli probabilistici, adotteremo una notazione specifica. Ad esempio, anzich√© scrivere la distribuzione di probabilit√† di \\(\\theta\\) come \\(p(\\theta) = Beta(1, 1)\\), scriveremo semplicemente \\(\\theta \\sim Beta(1, 1)\\). Il simbolo ‚Äú\\(\\sim\\)‚Äù viene comunemente letto come ‚Äúsegue la distribuzione di‚Äù. Possiamo anche interpretarlo nel senso che \\(\\theta\\) √® un campione casuale estratto dalla distribuzione Beta(1, 1). Analogamente, la verosimiglianza di un modello binomiale sar√† espressa come \\(y \\sim \\text{Bin}(n, \\theta)\\), dove ‚Äú\\(\\sim\\)‚Äù indica che \\(y\\) segue una distribuzione binomiale con parametri \\(n\\) e \\(\\theta\\). Questa notazione semplifica la rappresentazione dei modelli probabilistici, rendendo pi√π chiara la relazione tra i dati, i parametri e le distribuzioni di probabilit√† coinvolte nelle analisi statistiche.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#metodi-di-stima-della-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/01_intro_bayes.html#metodi-di-stima-della-distribuzione-a-posteriori",
    "title": "35¬† Modellazione bayesiana",
    "section": "35.5 Metodi di Stima della Distribuzione a Posteriori",
    "text": "35.5 Metodi di Stima della Distribuzione a Posteriori\nLa formulazione completa della distribuzione posteriore √® data da:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) \\cdot p(\\theta)}{\\int_{\\Theta} p(y \\mid \\theta) \\cdot p(\\theta) \\, d\\theta}, \\quad \\text{dove} \\quad \\theta \\in \\Theta,\n\\]\nin cui \\(\\Theta\\) denota l‚Äôinsieme di tutti i possibili valori del parametro \\(\\theta\\).\nIl calcolo di \\(p(\\theta \\mid y)\\) richiede la normalizzazione del prodotto tra la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) e la distribuzione a priori \\(p(\\theta)\\) attraverso una costante di normalizzazione. Questa costante, nota come verosimiglianza marginale, assicura che l‚Äôintegrale di \\(p(\\theta \\mid y)\\) su tutto lo spazio dei parametri \\(\\Theta\\) sia pari a uno.\nIn questa sezione, approfondiremo il concetto di likelihood marginale (che significa semplicemente la verosimiglianza media) attraverso il processo noto come integrazione di un parametro. Tale processo consente il calcolo della likelihood marginale, rimuovendo effettivamente il parametro incognito dalla distribuzione in esame. Per illustrare questo concetto, utilizzeremo la distribuzione binomiale, ma √® importante sottolineare che l‚Äôapplicabilit√† di questa tecnica si estende ben oltre, coprendo una vasta gamma di distribuzioni.\nConsideriamo una variabile casuale binomiale \\(Y\\) caratterizzata da una funzione di massa di probabilit√† (PMF) \\(p(Y)\\), definita in relazione a un parametro \\(\\theta\\). Supponiamo che quest‚Äôultimo pu√≤ assumere uno di tre valori specifici: 0.1, 0.5, o 0.9, ognuno dei quali ha identica probabilit√† di verificarsi, ossia \\(\\frac{1}{3}\\).\nFissiamo i dati a \\(n = 10\\) prove e \\(k = 7\\) successi, ottenendo la seguente funzione di likelihood:\n\\[\np(k = 7, n = 10 | \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la likelihood marginale, denotata con \\(p(k = 7, n = 10)\\), ‚Äúmarginalizziamo‚Äù il parametro \\(\\theta\\). Questo si realizza valutando la likelihood per ciascun valore possibile di \\(\\theta\\), moltiplicandola per la probabilit√†/densit√† di quel particolare valore di \\(\\theta\\) e sommando i risultati ottenuti.\nDati i valori di \\(\\theta\\), \\(\\theta_1 = 0.1\\), \\(\\theta_2 = 0.5\\), e \\(\\theta_3 = 0.9\\), ciascuno con una probabilit√† di \\(\\frac{1}{3}\\), calcoliamo la likelihood marginale nel seguente modo:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 | \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e la loro probabilit√† di \\(\\frac{1}{3}\\), otteniamo:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesta espressione ci consente di calcolare la likelihood marginale, basandoci sui valori discreti di \\(\\theta\\). Tale processo evidenzia come la marginalizzazione faccia emergere una comprensione globale della likelihood, incorporando tutte le possibili variazioni del parametro \\(\\theta\\) per ottenere una misura complessiva che tenga conto dell‚Äôincertezza su \\(\\theta\\).\nIn questo esempio abbiamo mostrato come sia possibile applicare la marginalizzazine (ovvero, l‚Äôintegrazione di un parametro) non solo in contesti continui, tramite l‚Äôuso dell‚Äôintegrale, ma anche in scenari discreti, sommando semplicemente i valori di likelihood moltiplicati per le rispettive probabilit√† di occorrenza del parametro.\nPer implementare un calcolo analogo in Python, possiamo definire una funzione che calcoli la likelihood per i valori discreti di \\(\\theta\\) e poi sommare i risultati. Per l‚Äôintegrazione su un intervallo continuo tra 0 e 1, invece, possiamo utilizzare la libreria scipy.\n\n# Funzione di likelihood\ndef likelihood(theta, k=7, n=10):\n    return comb(n, k) * (theta**k) * ((1 - theta)**(n - k))\n\n# Likelihood marginale per valori discreti di theta\ntheta_vals = np.array([0.1, 0.5, 0.9])\nprob_theta = 1/3\nmarginal_likelihood_discrete = sum([likelihood(theta) * prob_theta for theta in theta_vals])\n\nprint(f\"Likelihood Marginale (discreta): {marginal_likelihood_discrete}\")\n\n# Likelihood marginale su un intervallo continuo [0, 1]\nmarginal_likelihood_continuous, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(f\"Likelihood Marginale (continua): {marginal_likelihood_continuous}\")\n\nLikelihood Marginale (discreta): 0.05819729199999999\nLikelihood Marginale (continua): 0.09090909090909091\n\n\nIl punto da notare, tuttavia, √® che il calcolo analitico della verosimiglianza marginale √® fattibile solo in circostanze particolari. In generale, √® necessario procedere per approssimazione numerica.\n\n35.5.1 Metodi per determinare la distribuzione a posteriori\nPer determinare la distribuzione posteriore, dunque, si possono adottare due approcci principali:\n\nApproccio Analitico: Questa strategia si applica quando la distribuzione a priori e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, dette coniugate. In tali circostanze, √® possibile calcolare analiticamente la distribuzione posteriore. Questo metodo si distingue per la sua eleganza e efficienza computazionale, ma √® limitato alle situazioni in cui esiste una coniugazione tra le distribuzioni a priori e le funzioni di verosimiglianza.\nApproccio Numerico: Quando l‚Äôapproccio analitico non √® applicabile, ad esempio a causa dell‚Äôassenza di coniugazione tra distribuzioni a priori e funzioni di verosimiglianza, l‚Äôintegrale al denominatore (la likelihood marginale) della regola di Bayes non pu√≤ essere risolto con metodi analitici. In questi casi, l‚Äôinferenza bayesiana procede attraverso tecniche di approssimazione numerica. Tecniche come le catene di Markov Monte Carlo (MCMC) vengono impiegate per stimare numericamente la distribuzione posteriore. Questo metodo √® pi√π versatile e adattabile a un‚Äôampia gamma di problemi, ma richiede un maggiore impegno computazionale e pu√≤ essere pi√π oneroso in termini di tempo rispetto all‚Äôapproccio analitico.\n\n\n\n35.5.2 Linguaggi di programmazione probabilistici\nL‚Äôapproccio moderno alla statistica bayesiana si avvale ampiamente di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. In questo contesto, si fa largo uso di linguaggi di programmazione probabilistica, noti come ‚ÄúProbabilistic Programming Languages‚Äù (PPL), che facilitano l‚Äôimplementazione computazionale dell‚Äôaggiornamento bayesiano.\nQuesto sviluppo ha trasformato radicalmente il modo in cui si effettuano le analisi statistiche bayesiane, democratizzando l‚Äôaccesso a modelli statistici avanzati. L‚Äôintroduzione di metodi computazionali ha reso la modellazione bayesiana pi√π accessibile, riducendo le barriere di competenza matematica e computazionale precedentemente necessarie. Questi strumenti hanno inoltre ampliato le possibilit√† di affrontare questioni analitiche complesse, che prima sarebbero state difficili da gestire. Utilizzando i linguaggi di programmazione probabilistica, gli analisti possono formulare modelli probabilistici con maggiore chiarezza e flessibilit√†, facilitando l‚Äôesplorazione delle distribuzioni posteriori e l‚Äôanalisi di questioni complesse con tecniche bayesiane. Questo ha aperto nuovi orizzonti nell‚Äôanalisi bayesiana, permettendo di affrontare e risolvere problemi in modi precedentemente impensabili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "title": "35¬† Modellazione bayesiana",
    "section": "35.6 Commenti e considerazioni finali",
    "text": "35.6 Commenti e considerazioni finali\nL‚Äôapproccio bayesiano rappresenta un modo distintivo di affrontare l‚Äôincertezza associata ai parametri di interesse, contrapponendosi in modo significativo alla metodologia classica. Mentre il paradigma classico tratta i parametri come valori fissi e sconosciuti, l‚Äôapproccio bayesiano li considera come quantit√† probabilistiche, attribuendo loro una distribuzione a priori che riflette le nostre credenze e intuizioni iniziali prima dell‚Äôesperimento. Grazie all‚Äôapplicazione del teorema di Bayes, queste credenze vengono progressivamente raffinate e aggiornate sulla base dei dati osservati, conducendo alla definizione della distribuzione a posteriori. Tale distribuzione rappresenta una prospettiva aggiornata dell‚Äôincertezza, integrando sia l‚Äôevidenza empirica che le informazioni pregresse.\nLa potenza dell‚Äôapproccio bayesiano risiede nella sua capacit√† di amalgamare le conoscenze pregresse con le nuove osservazioni, producendo stime dei parametri di interesse che non solo sono pi√π accurate ma anche pi√π significative dal punto di vista interpretativo. Oltre a essere un semplice strumento statistico, il bayesianesimo si rivela un potente strumento decisionale che favorisce un‚Äôinterazione dinamica tra teoria ed esperienza.\nTuttavia, uno svantaggio dell‚Äôapproccio bayesiano risiede nella sua potenziale lentezza e inefficienza nel trattare dataset molto estesi. Ci√≤ significa che quando si applicano metodi basati sulla teoria bayesiana all‚Äôanalisi dei dati, potrebbero sorgere problemi di scalabilit√† e di efficienza computazionale, specialmente di fronte a insiemi di dati di dimensioni considerevoli. Per superare questa difficolt√†, √® in sviluppo la variational inference, un insieme di metodi approssimativi per calcolare la distribuzione a posteriori. Questi metodi, a differenza del campionamento MCMC, producono risultati in tempi significativamente ridotti.\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nBaribault, Beth, e Anne GE Collins. 2023. ¬´Troubleshooting Bayesian cognitive models.¬ª Psychological Methods.\n\n\nBox, G. E., A. Luceno, e M. del Carmen Paniagua-Quinones. 2011. Statistical control by monitoring and adjustment. John Wiley; Sons.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html",
    "href": "chapters/chapter_4/02_subj_prop.html",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Introduzione\nQuesto capitolo mira a esplorare in profondit√† il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L‚Äôobiettivo √® dimostrare come le nostre credenze preesistenti sulla probabilit√† \\(\\theta\\) di un evento specifico possano essere affinate mediante l‚Äôosservazione di nuovi dati.\nInizieremo descrivendo come rappresentare le nostre convinzioni iniziali, ovvero quelle formulate prima di raccogliere qualsiasi dato, tramite una distribuzione a priori. Successivamente, delineeremo i passaggi calcolativi necessari per derivare la distribuzione a posteriori di \\(\\theta\\). Questa distribuzione rappresenta le nostre credenze aggiornate su \\(\\theta\\) una volta considerati i dati osservati. L‚Äôottenimento della distribuzione a posteriori avviene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, seguita da una normalizzazione per garantire che il risultato sia una distribuzione di probabilit√† valida.\nIl capitolo si focalizza principalmente sul modello binomiale, un contesto elementare ma cruciale per l‚Äôinferenza bayesiana. Questo modello √® utilizzato per stimare una proporzione di popolazione sconosciuta a partire da una serie di ‚Äúprove di Bernoulli‚Äù, ovvero dati \\(y_1, \\ldots, y_n\\), ciascuno dei quali assume valore 0 o 1. Questo problema rappresenta un punto di partenza relativamente semplice ma fondamentale per la discussione dell‚Äôinferenza bayesiana. Inizieremo esplorando il caso in cui la distribuzione a priori √® discreta, per poi passare all‚Äôanalisi di scenari in cui essa √® continua.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/chapter_4/02_subj_prop.html#verosimiglianza-binomiale",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.1 Verosimiglianza Binomiale",
    "text": "36.1 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova d√† origine a uno dei due possibili esiti, convenzionalmente etichettati come ‚Äòsuccesso‚Äô e ‚Äòfallimento‚Äô. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilit√† di successo in ciascuna prova. Il modello di campionamento binomiale √®:\n\\[ p(y|\\theta) = \\text{Bin}(y|n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}, \\]\ndove nella parte sinistra dell‚Äôequazione non si indica la dipendenza da \\(n\\) perch√© viene considerato parte del disegno sperimentale e fissato; tutte le probabilit√† discusse per questo problema sono considerate condizionate su \\(n\\), cio√® assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/chapter_4/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.2 Applicazione Specifica del Modello Binomiale",
    "text": "36.2 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, consideriamo un‚Äôapplicazione specifica del modello binomiale per stimare la proporzione di presenza di ideazione suicidaria all‚Äôinterno di una popolazione specifica. Prenderemo in esame lo studio di Comtois et al. (2023), in cui viene valutata l‚Äôefficacia di un intervento volto a prevenire l‚Äôideazione suicidaria nella comunit√† universitaria. I partecipanti allo studio erano pazienti reclutati secondo i seguenti criteri: 1. Ricovero ospedaliero o accesso al pronto soccorso per rischio suicidario. 2. Tentativo di suicidio nel mese precedente (compresi tentativi interrotti o auto-interrotti).\nNel gruppo di controllo dello studio, composto da 75 pazienti, √® stato somministrato il trattamento standard (TAU), che seguiva le politiche e procedure standard per i servizi brevi e orientati alla crisi. Questo trattamento comprendeva una valutazione iniziale seguita da 1-11 visite con un clinico (con una media di 4,5 visite) e gestione dei farmaci, se necessario, terminando con un rinvio a un altro servizio per il follow-up delle cure primarie o per un ulteriore trattamento per la salute mentale o l‚Äôabuso di sostanze.\nDopo 12 mesi, l‚Äôideazione suicidaria √® stata misurata utilizzando la Beck Scale for Suicide Ideation (BSS; Beck & Steer, 1993), la versione self-report della Scale for Suicide Ideation (Beck, Brown, & Steer, 1997), una misura valida e affidabile dell‚Äôideazione suicidaria. I dati mostrano che, dopo 12 mesi, 35 pazienti del gruppo TAU hanno riportato almeno un episodio di ideazione suicidaria. L‚Äôobiettivo dell‚Äôanalisi √® quantificare l‚Äôincertezza di questa stima di \\(\\theta\\), la proporzione di presenza di ideazione suicidaria in questa popolazione dopo un anno.\nConsideriamo ogni paziente come una prova bernoulliana in cui emerge (1) o non emerge (0) almeno un episodio di ideazione suicidaria nel corso dell‚Äôanno considerato. Utilizzando il modello binomiale, stimiamo quindi la probabilit√† \\(\\theta\\) di ideazione suicidaria nella popolazione e quantifichiamo l‚Äôincertezza associata a questa stima.\n\n36.2.1 Processo di Lavoro\nMcElreath (2020) descrive il flusso lavoro bayesiano nel modo seguente.\n\nDefinire un Modello Generativo per i Dati: Un modello generativo spiega come i dati sono stati prodotti. Nel nostro caso, consideriamo ogni paziente come un esperimento di Bernoulli con due possibili esiti: presenza (1) o assenza (0) di ideazione suicidaria. Definiamo \\(\\theta\\) come la probabilit√† di osservare ideazione suicidaria in un singolo paziente. Il modello generativo dei dati si esprime quindi come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, ..., 75\\) e \\(X_i\\) assume valore 1 in caso di presenza e 0 in caso di assenza di ideazione suicidaria.\nDefinire uno Stimatore per il Parametro di Interesse: Uno stimatore √® una regola o una formula che utilizza i dati del campione per calcolare una stima del parametro di interesse. Nel nostro caso, lo stimatore che cerchiamo √® la probabilit√† \\(\\theta\\) di osservare un episodio di ideazione suicidaria dopo 12 mesi dall‚Äôepisodio di crisi. L‚Äôobiettivo √® stimare l‚Äôincertezza di questa probabilit√† basandoci sui dati raccolti.\nSviluppare un Metodo Statistico per la Stima del Parametro di Interesse: Per stimare \\(\\theta\\), applichiamo l‚Äôapproccio bayesiano. Nella statistica bayesiana, partiamo da una distribuzione a priori che esprime le nostre convinzioni iniziali su \\(\\theta\\), per poi aggiornarla con i dati osservati e ottenere una distribuzione a posteriori. Una scelta comune per la priori in un contesto Bernoulli/Binomiale √® la distribuzione Beta. Partiamo da una priori non informativa, \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme.\nLa verosimiglianza dei nostri dati (35 ‚Äúsuccessi‚Äù, 40 ‚Äúinsuccessi‚Äù) √® data dalla distribuzione binomiale:\n\\[\nL(p) = {75 \\choose 35} \\theta^{35} (1-\\theta)^{40}.\n\\]\nUtilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}\n\\]\nValidazione del Modello attraverso Simulazioni: Prima di esaminare i dati concreti, effettuiamo una simulazione predittiva a priori per verificare se il modello pu√≤ generare dati plausibili. Dopo l‚Äôadattamento del modello ai dati veri, conduciamo una simulazione predittiva a posteriori per testare la capacit√† del modello di produrre dati comparabili a quelli osservati.\nAnalisi e Sintesi dei Risultati: Infine, procediamo con l‚Äôanalisi dei dati veri, calcolando la distribuzione a posteriori, solitamente attraverso metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per inferire su \\(\\theta\\), utilizzando statistiche descrittive quali media, mediana e intervalli di credibilit√†.\n\nNel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano",
    "text": "36.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano\nDopo aver discusso l‚Äôaggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia √® un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l‚Äôuso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilit√† sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l‚Äôarea totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "36.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente considerare un valore di 0.5, suggerendo una probabilit√† ugualmente bilanciata tra la presenza e l‚Äôassenza di ideazione suicidaria. Tuttavia, questo valore non rappresenta adeguatamente l‚Äôintero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilit√† distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilit√† a priori uguale, creando cos√¨ una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) pi√π probabili.\nDopo aver osservato i dati ‚Äî ad esempio, 35 casi di ideazione suicidaria su 75 ‚Äî applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilit√† a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilit√† a posteriori aggiornata per \\(\\theta\\).\nLa distribuzione a posteriori integra quindi le nostre conoscenze pregresse con le nuove informazioni ottenute dalle osservazioni, offrendoci una visione aggiornata e quantitativamente informata del parametro \\(\\theta\\). Attraverso questo esempio, possiamo osservare un approccio sistematico ed efficace per affinare le nostre credenze alla luce di nuove prove.\n\ntheta = np.linspace(0, 1, 11)\nprint(theta)\n\n[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n\n\nNel caso in cui non vi siano motivi fondati per assegnare probabilit√† diverse ai vari valori di \\(\\theta\\), √® possibile attribuire la stessa probabilit√† a ciascun valore, creando cos√¨ una distribuzione uniforme. √à importante prestare attenzione alla seconda riga di codice, che esegue una standardizzazione. Poich√© unif_discr_pdf √® un vettore composto da un numero finito di elementi, questi elementi devono essere considerati come probabilit√†, e tali probabilit√† devono obbligatoriamente sommarsi a uno.\n\nunif_distr_pdf = stats.uniform.pdf(theta) \nunif_distr_pdf = unif_distr_pdf / np.sum(unif_distr_pdf)\nunif_distr_pdf\n\narray([0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909])\n\n\nUna rappresentazione visiva di questa distribuzione di massa di probabilit√† si ottiene nel modo seguente.\n\nplt.stem(theta, unif_distr_pdf, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nSe, al contrario, riteniamo che i valori centrali nella distribuzione di \\(\\theta\\) siano pi√π credibili rispetto a quelli situati agli estremi, potremmo esprimere questa opinione soggettiva mediante la seguente distribuzione di massa di probabilit√†.\n\nnot_unif_distr_pdf = [0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05]\nplt.stem(theta, not_unif_distr_pdf, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nLa prima distribuzione di probabilit√† √® una distribuzione discreta uniforme, in quanto assegna la stessa probabilit√† a ciascun elemento dell‚Äôinsieme discreto su cui √® definita, ossia i valori \\(\\{0, 0.1, 0.2, \\dots, 1.0\\}\\). La seconda distribuzione di probabilit√†, pur essendo discreta, segue un andamento non uniforme: si presume che \\(\\theta\\) abbia una probabilit√† maggiore di assumere un valore nell‚Äôinsieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) rispetto all‚Äôinsieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).\nLe credenze iniziali riguardo ai possibili valori di \\(\\theta\\) costituiscono la ‚Äúdistribuzione a priori‚Äù. L‚Äôinferenza bayesiana aggiorna queste credenze iniziali utilizzando le informazioni ottenute dai dati. Queste informazioni vengono combinate con le credenze iniziali su \\(\\theta\\) attraverso l‚Äôapplicazione del teorema di Bayes, allo scopo di ottenere la ‚Äúdistribuzione a posteriori‚Äù. Quest‚Äôultima rappresenta le nostre credenze aggiornate sui possibili valori di \\(\\theta\\) dopo l‚Äôosservazione dei dati.\nSupponiamo di aver osservato 35 ‚Äúsuccessi‚Äù in 75 prove. Per calcolare la distribuzione a posteriori, utilizzeremo la seconda delle due distribuzioni a priori precedentemente descritte. In base al teorema di Bayes, la distribuzione a posteriori si ottiene moltiplicando la verosimiglianza per la distribuzione a priori e quindi dividendo per una costante di normalizzazione (la verosimiglianza marginale):\n\\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}. \\]\nPer calcolare la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), dobbiamo comprendere il processo mediante il quale i dati sono stati generati. Nel nostro contesto, i dati rappresentano i risultati di 75 ripetizioni di un esperimento casuale che pu√≤ produrre solo due risultati possibili: ‚Äúpresenza‚Äù e ‚Äúassenza‚Äù di ideazione suicidaria. Inoltre, i 75 casi esaminati sono tra loro indipendenti (i pazienti non si influenzano reciprocamente). In tali circostanze, possiamo assumere che il modello generativo dei dati sia il modello binomiale con probabilit√† sconosciuta \\(\\theta\\).\nUtilizzando Python, √® possibile calcolare la funzione di verosimiglianza tramite la funzione binom.pmf().\n\nlk = stats.binom.pmf(35, 70, theta)\nlk = lk / np.sum(lk)\nlk\n\narray([0.00000000e+00, 1.99180385e-16, 1.10906788e-07, 1.50811359e-03,\n       1.61492440e-01, 6.73998671e-01, 1.61492440e-01, 1.50811359e-03,\n       1.10906788e-07, 1.99180385e-16, 0.00000000e+00])\n\n\nPer i 10 valori \\(\\theta\\) considerati, la funzione di verosimiglianza assume la forma indicata dalla figura seguente.\n\nplt.stem(theta, lk, markerfmt=\" \")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"$L(\\\\theta)$\");\n\n\n\n\n\n\n\n\nPer calcolare la distribuzione a posteriori, eseguiamo una moltiplicazione elemento per elemento tra il vettore contenente i valori della distribuzione a priori e il vettore contenente i valori della funzione di verosimiglianza. Usando Python, il risultato si trova nel modo seguente.\n\nnot_unif_distr_pdf * lk\n\narray([0.00000000e+00, 9.95901924e-18, 5.54533942e-09, 7.54056793e-05,\n       2.82611770e-02, 1.17949767e-01, 2.82611770e-02, 2.63919878e-04,\n       5.54533942e-09, 9.95901924e-18, 0.00000000e+00])\n\n\nPer illustrare con un esempio, il valore dell‚Äôottavo elemento della distribuzione a posteriori si calcola come segue (tenendo presente che in Python gli indici partono da 0):\n\nnot_unif_distr_pdf[7] * lk[7]\n\n0.0002639198775144677\n\n\nDopo questa moltiplicazione, otteniamo una distribuzione che rappresenta le probabilit√† condizionate dei possibili valori di \\(\\theta\\) alla luce dei dati osservati. Tuttavia, questa distribuzione potrebbe non √® normalizzata, il che significa che la somma di tutte le probabilit√† condizionate non √® uguale a 1.\nPer ottenere una distribuzione di probabilit√† correttamente normalizzata, dobbiamo dividere ciascun valore ottenuto precedentemente per la probabilit√† marginale dei dati \\(y\\). La probabilit√† marginale dei dati \\(y\\) √® una costante di normalizzazione e pu√≤ essere calcolata utilizzando la legge della probabilit√† totale (si veda l‚Äôeq. {eq}eq-prob-tot).\nPer chiarire, ricordiamo che, nel capitolo {ref}cond-prob-notebook abbiamo considerato il caso di una partizione dello spazio campione in due eventi mutualmente esclusivi ed esaustivi, \\(H_1\\) e \\(H_2\\). All‚Äôinterno dello spazio campione abbiamo definito un evento \\(E\\) non nullo e abbiamo visto che \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\), ovvero \\(P(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2)\\). Usando la terminologia che stiamo usando qui, \\(P(E \\mid H_i)\\) corrisponde alla funzione di verosimiglianza e \\(P(H_i)\\) corrisponde alla funzione a priori. Nel caso discreto, come quello che stiamo considerando ora, il teorema della probabilit√† totale ci dice dunque che dobbiamo fare la somma dei prodotti tra i valori della funzione di verosimiglianza e i corrispondenti valori della distribuzione a priori.\n\nnp.sum(not_unif_distr_pdf * lk)\n\n0.17481145807507814\n\n\nOtteniamo dunque il seguente risultato.\n\npost = (not_unif_distr_pdf * lk) / np.sum(not_unif_distr_pdf * lk)\nprint(post)\n\n[0.00000000e+00 5.69700599e-17 3.17218304e-08 4.31354330e-04\n 1.61666617e-01 6.74725608e-01 1.61666617e-01 1.50974015e-03\n 3.17218304e-08 5.69700599e-17 0.00000000e+00]\n\n\nVerifichiamo di avere ottenuto una distribuzione di massa di probabilit√†:\n\nnp.sum(post)\n\n1.0000000000000002\n\n\nEsaminiamo la distribuzione a posteriori di \\(\\theta\\) con un grafico.\n\nplt.stem(theta, post, markerfmt=\" \")\nplt.title(\"Distribuzione a posteriori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\");\n\n\n\n\n\n\n\n\nUna volta trovata la distribuzione a posteriori di \\(\\theta\\), possiamo calcolare altre quantit√† di interesse. Ad esempio, la moda a posteriori di \\(\\theta\\) pu√≤ essere individuata direttamente dal grafico precedente e risulta pari a 0.5. Per calcolare invece la media a posteriori, ci avvaliamo della formula del valore atteso delle variabili casuali.\n\nnp.sum(theta * post)\n\n0.5002156771647586\n\n\nLa varianza della distribuzione a posteriori √®\n\nnp.sum(theta**2 * post) - (np.sum(theta * post)) ** 2\n\n0.0033109353091205773\n\n\nCon questo metodo, possiamo calcolare la distribuzione a posteriori di \\(\\theta\\) per qualsiasi distribuzione a priori discreta.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "36.5 Aggiornamento bayesiano con una distribuzione a priori continua\nA fini didattici, abbiamo esaminato il caso di una distribuzione a priori discreta. Tuttavia, √® importante notare che l‚Äôimpiego di una distribuzione a priori continua, come la distribuzione Beta, risulta pi√π appropriato in quanto permette di rappresentare un‚Äôampia gamma di possibili valori per il parametro non noto \\(\\theta\\), senza essere vincolati a un insieme discreto di valori. Inoltre, la distribuzione Beta presenta l‚Äôulteriore vantaggio di avere un dominio definito nell‚Äôintervallo [0, 1], che corrisponde alla gamma dei possibili valori per la proporzione \\(\\theta\\).\nPer esempio, consideriamo la distribuzione Beta(2, 2), caratterizzata da una simmetria nella sua forma. Per valutare la distribuzione Beta in corrispondenza di punti specifici, come ad esempio 0.5, 0.8 e 1.2, possiamo fare affidamento sulla funzione beta.pdf. A titolo illustrativo, la densit√† di probabilit√† della distribuzione Beta(2, 2) nel caso del valore 0.5 risulta essere 1.5, suggerendo che i valori di \\(\\theta\\) vicini a 0.5 appaiono pi√π plausibili rispetto a quelli intorno a 0.8, dove la funzione assume un valore di 0.96. √à importante sottolineare che la densit√† di probabilit√† della distribuzione Beta(2, 2) relativa al valore 1.2 √® pari a 0, poich√© tale valore esula dall‚Äôintervallo di definizione della distribuzione (0 e 1). La distribuzione Beta(2, 2) √® illustrata nella figura qui di seguito.\n\nalpha = 2\nbeta = 2\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nSupponiamo ‚Äì solo allo scopo di illustrare la procedura ‚Äì che le nostre credenze a priori siano rappresentate da una Beta(2, 5).\n\nalpha = 2\nbeta = 5\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nNel seguente esempio, useremo la funzione beta.pdf() per generare una distribuzione a priori discretizzata.\n\nprint(stats.beta.pdf(theta, 2, 5))\n\n[0.     1.9683 2.4576 2.1609 1.5552 0.9375 0.4608 0.1701 0.0384 0.0027\n 0.    ]\n\n\n\n_ = plt.plot(theta, stats.beta.pdf(theta, 2, 5))\n\n\n\n\n\n\n\n\nOra per√≤ usiamo un numero maggiore di valori \\(\\theta\\).\n\ntheta = np.linspace(0, 1, 1001)\nprint(theta)\n\n[0.    0.001 0.002 ... 0.998 0.999 1.   ]\n\n\nCalcoliamo la distribuzione a priori normalizzata.\n\nprior = stats.beta.pdf(theta, 2, 5) \nprior = prior / np.sum(prior)\nprint(prior)\n\n[0.00000000e+00 2.98802546e-05 5.95215869e-05 ... 4.79041198e-13\n 2.99700749e-14 0.00000000e+00]\n\n\n\nsum(prior)\n\n1.0000000000000002\n\n\nPer calcolare la verosimiglianza, seguiamo la medesima procedura illustrata nel capitolo {ref}cap-likelihood. In aggiunta, effettuiamo la normalizzazione dei valori discretizzati della verosimiglianza, come precedentemente descritto.\n\nlk = stats.binom.pmf(6, 9, theta)\nlk = lk / np.sum(lk)\nprint(lk)\n\n[0.00000000e+00 8.37482519e-19 5.34380847e-17 ... 6.63976213e-09\n 8.34972583e-10 0.00000000e+00]\n\n\nInfine, otteniamo la distribuzione a posteriori moltiplicando la distribuzione a priori per la verosimiglianza e dividendo per la costante di normalizzazione.\n\npost = (prior * lk) / np.sum(prior * lk)\n\n\nnp.sum(post)\n\n1.0\n\n\n\nplt.plot(theta, prior, linestyle=\"solid\", color=\"C0\", label=\"Prior\")\nplt.plot(theta, lk, linestyle=\"solid\", color=\"C2\", label=\"Likelihood\")\nplt.plot(theta, post, linestyle=\"solid\", color=\"C3\", label=\"Posterior\")\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nPossiamo calcolare la media e la deviazione standard della distribuzione a posteriori come abbiamo fatto in precedenza.\n\n# media\nnp.sum(theta * post)\n\n0.5000000000000001\n\n\n\n# deviazione standard\nnp.sqrt(np.sum(theta**2 * post) - (np.sum(theta * post)) ** 2)\n\n0.12126781251816628",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori",
    "text": "36.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori\nUna volta ottenuta la distribuzione a posteriori, √® possibile generare un campione casuale da questa distribuzione. A titolo di esempio, possiamo estrarre un campione di 10000 punti dalla distribuzione a posteriori di \\(\\theta\\) che abbiamo calcolato.\n\nsamples = np.random.choice(theta, p=post, size=int(1e4), replace=True)\n\nL‚Äôistruzione precedente genera un array denominato samples contenente 10000 punti campionati dalla distribuzione a posteriori calcolata. La funzione np.random.choice viene impiegata per selezionare casualmente i valori theta basandosi sulle probabilit√† definite da post.\n\n# First subplot: Scatter plot\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\nplt.plot(samples, 'o', alpha=0.1)\nplt.xlabel(\"sample number\")\nplt.ylabel(r\"$\\theta$\")\n\n# Second subplot: KDE plot\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\naz.plot_kde(samples)\nplt.xlabel(r\"$\\theta$\")\n_ = plt.ylabel(\"density\")\n\n\n\n\n\n\n\n\nSfruttando il campione estratto dalla distribuzione a posteriori, √® possibile calcolare diverse quantit√† di interesse. Ad esempio, la stima della media a posteriori di \\(\\theta\\) si ottiene semplicemente calcolando la media dei valori cos√¨ ottenuti.\n\nnp.mean(samples)\n\n0.499356\n\n\nIn maniera analoga possiamo calcolare la deviazione standard della distribuzione a posteriori di \\(\\theta\\).\n\nnp.std(samples)\n\n0.1199298022344738\n\n\nLa moda a posteriori si pu√≤ calcolare nel modo seguente.\n\nprint(theta[post == max(post)])\n\n[0.5]\n\n\nOppure, usando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo\n\nstats.mode(samples)[0]\n\n0.507\n\n\nUsando il campione estratto dalla distribuzione a posteriori, √® immediato trovare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(samples)\n\n0.5\n\n\nPossiamo calcolare la probabilit√† di varie ipotesi relative a \\(\\theta\\) nella distribuzione a posteriori. Per esempio, calcoliamo la probabilit√† \\(P(\\theta &lt; 0.5)\\).\n\nsum(post[theta &lt; 0.5])\n\n0.49842895507812507\n\n\nAlternativamente, utilizzando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo un risultato analogo, sebbene soggetto a variazioni dovute all‚Äôapprossimazione numerica.\n\nsum(samples &lt; 0.5) / 1e4\n\n0.4996\n\n\nPossiamo trovare la probabilit√† a posteriori che \\(\\theta\\) sia compresa in un dato intervallo. Per esempio, troviamo \\(P(0.5 &lt; \\theta &lt; 0.75)\\).\n\nsum((samples &gt; 0.6) & (samples &lt; 0.8)) / 1e4\n\n0.2073\n\n\nUtilizzando il campionamento effettuato dalla distribuzione a posteriori di \\(\\theta\\), √® possibile risolvere il problema inverso, ovvero determinare l‚Äôintervallo che contiene \\(\\theta\\) con una specifica probabilit√†. Ad esempio, si pu√≤ calcolare l‚Äôintervallo che ha una probabilit√† pari a 0.94 di contenere \\(\\theta\\), basandosi sulla distribuzione a posteriori campionata.\n\nnp.percentile(samples, [2, 98])\n\narray([0.261, 0.741])\n\n\nL‚Äôintervallo specificato √® noto come intervallo di credibilit√† e rappresenta una quantificazione statistica dell‚Äôincertezza associata alla stima del parametro \\(\\theta\\). In termini probabilistici, si pu√≤ affermare con il 94% di credibilit√† che il valore ‚Äúvero‚Äù di \\(\\theta\\) √® contenuto nell‚Äôintervallo [0.26, 0.74].\nSe vogliamo trovare l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPD), usiamo la funzione ArviZ hdi() (si veda il capitolo {ref}sintesi-distr-post-notebook).\n\naz.hdi(samples, hdi_prob=0.94)\n\narray([0.278, 0.721])\n\n\nNel contesto attuale, la distribuzione a posteriori √® simmetrica. Di conseguenza, l‚Äôintervallo di credibilit√† calcolato attraverso i quantili e l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPDI) sono molto simili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "href": "chapters/chapter_4/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?",
    "text": "36.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?\nNonostante abbiamo discusso in precedenza dei diversi metodi di stima puntuale e intervallare per riassumere la distribuzione a posteriori di \\(\\theta\\), la migliore stima del parametro che stiamo cercando di inferire √® rappresentata dall‚Äôintera distribuzione a posteriori. Per citare le parole di McElreath (2020):\n\nThat an arbitrary interval contains an arbitrary value is not meaningful. Use the whole distribution.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.8 Metodo basato su griglia",
    "text": "36.8 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori √® noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l‚Äôapprossimazione della distribuzione a posteriori pu√≤ essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l‚Äôapprossimazione della densit√† a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densit√† a posteriori normalizzata.\n\nQuesto metodo pu√≤ essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all‚Äôaumentare della dimensionalit√† dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l‚Äôapproccio basato sulla griglia √® intuitivo e non richiede competenze di programmazione avanzate per l‚Äôimplementazione. Inoltre, fornisce un risultato che pu√≤ essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilit√† a posteriori condizionata ai dati. Tuttavia, questo metodo √® limitato a causa della maledizione della dimensionalit√†1, il che significa che pu√≤ essere applicato soltanto a modelli statistici semplici con non pi√π di due parametri. Di conseguenza, in pratica, √® spesso sostituito da altre tecniche pi√π efficienti, poich√© i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/02_subj_prop.html#commenti-e-considerazioni-finali",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "36.9 Commenti e Considerazioni Finali",
    "text": "36.9 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato l‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l‚Äôelaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell‚Äôinferenza relativa alle proporzioni, dove la distribuzione a priori √® modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, √® possibile derivare analiticamente la distribuzione a posteriori. L‚Äôanalisi dettagliata di questo caso sar√† trattata nel capitolo successivo.\nL‚Äôaspetto fondamentale della discussione presente risiede nell‚Äôapproccio adottato per affrontare una specifica questione di ricerca, ossia la quantificazione dell‚Äôincertezza relativa alla proporzione di presenza di ideazione suicidaria nella popolazione considerata. Abbiamo illustrato come sia possibile mettere in pratica alcuni dei passaggi del flusso di lavoro bayesiano proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nComtois, Katherine Anne, Karin E Hendricks, Christopher R DeCou, Samantha A Chalker, Amanda H Kerbrat, Jennifer Crumlish, Tierney K Huppert, e David Jobes. 2023. ¬´Reducing short term suicide risk after hospitalization: A randomized controlled trial of the Collaborative Assessment and Management of Suicidality¬ª. Journal of affective disorders 320: 656‚Äì66.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#footnotes",
    "href": "chapters/chapter_4/02_subj_prop.html#footnotes",
    "title": "36¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalit√†, possiamo considerare l‚Äôesempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). √à evidente che la quantit√† di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, √® necessario utilizzare un approccio diverso.‚Ü©Ô∏é",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/03_conjugate_families_1.html",
    "href": "chapters/chapter_4/03_conjugate_families_1.html",
    "title": "37¬† Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduction\nIn questo capitolo, ci focalizziamo sulla derivazione della distribuzione a posteriori attraverso l‚Äôuso di una distribuzione a priori coniugata. Sar√† esaminato in dettaglio il modello beta-binomiale, un esempio paradigmatico che evidenzia il vantaggio dell‚Äôuso delle distribuzioni a priori coniugate in inferenza bayesiana. L‚Äôimpiego di tali distribuzioni facilita notevolmente il processo di inferenza, permettendo di ottenere una distribuzione a posteriori attraverso calcoli analitici diretti e semplificati. Questa metodologia non solo rende il processo di inferenza pi√π gestibile ma anche pi√π intuitivo, offrendo una chiara dimostrazione di come le scelte a priori influenzino l‚Äôanalisi bayesiana.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/03_conjugate_families_1.html#derivazione-analitica-della-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/03_conjugate_families_1.html#derivazione-analitica-della-distribuzione-a-posteriori",
    "title": "37¬† Distribuzioni coniugate (1)",
    "section": "37.1 Derivazione analitica della distribuzione a posteriori",
    "text": "37.1 Derivazione analitica della distribuzione a posteriori\nLe distribuzioni a priori coniugate costituiscono una classe speciale di distribuzioni di probabilit√† aventi una particolare caratteristica: se la distribuzione a priori appartiene a questa classe, anche la distribuzione a posteriori appartiene alla stessa classe, ovvero mantiene la stessa forma funzionale. Questo aspetto semplifica notevolmente l‚Äôaggiornamento delle nostre credenze riguardo al parametro di interesse, in quanto coinvolge semplicemente la modifica dei parametri della distribuzione a priori. Ad esempio, quando selezioniamo una distribuzione a priori Beta e la verosimiglianza corrisponde a una distribuzione binomiale, la distribuzione a posteriori sar√† anch‚Äôessa una distribuzione Beta.\nNonostante le distribuzioni a priori coniugate siano la scelta preferibile dal punto di vista matematico, in quanto permettono di calcolare analiticamente la distribuzione a posteriori evitando calcoli complessi, le moderne tecniche di inferenza bayesiana offrono flessibilit√† nell‚Äôutilizzo di una vasta gamma di distribuzioni a priori. Questa flessibilit√† elimina la necessit√† di vincolarsi esclusivamente alle distribuzioni coniugate. Tuttavia, le distribuzioni a priori coniugate continuano a giocare un ruolo didattico rilevante, poich√© presentano una soluzione analitica per il processo di aggiornamento bayesiano. Nel presene capitolo, esploreremo dettagliatamente il modello beta-binomiale, in cui la verosimiglianza binomiale si combina con la scelta di una distribuzione a priori Beta. Questo modello rappresenta la base dell‚Äôinferenza bayesiana su una proporzione.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/03_conjugate_families_1.html#lo-schema-beta-binomiale",
    "href": "chapters/chapter_4/03_conjugate_families_1.html#lo-schema-beta-binomiale",
    "title": "37¬† Distribuzioni coniugate (1)",
    "section": "37.2 Lo schema beta-binomiale",
    "text": "37.2 Lo schema beta-binomiale\nLa distribuzione Beta √® utilizzata per descrivere la variabilit√† di una variabile casuale che √® limitata all‚Äôintervallo [0,1]. Questa distribuzione √® definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\]\ndove \\(B(\\alpha, \\beta)\\) rappresenta la funzione Beta di Eulero, espressa attraverso la funzione Gamma (\\(\\Gamma\\)) come segue:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}.\n\\]\nLa funzione Gamma, a sua volta, √® definita per i valori positivi di \\(x\\) e generalizza il concetto di fattoriale. I parametri \\(\\alpha\\) e \\(\\beta\\) modulano la forma della distribuzione Beta, influenzando la sua varianza e la sua moda.\nNel contesto bayesiano, la distribuzione Beta √® spesso usata come distribuzione a priori per modellare la nostra conoscenza preliminare sulla probabilit√† di successo \\(\\theta\\) in una serie di eventi di Bernoulli. Dopo aver raccolto i dati, possiamo aggiornare questa conoscenza a priori in base alle osservazioni effettive mediante l‚Äôapproccio di aggiornamento bayesiano.\nLa densit√† a priori, data da \\(\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}\\), viene combinata con la funzione di verosimiglianza che, in caso di dati binomiali, assume la forma \\(\\theta^{y} (1 - \\theta)^{n - y}\\). Moltiplicando la densit√† a priori per la verosimiglianza e tralasciando il fattore di normalizzazione (che sar√† calcolato in seguito), otteniamo una forma che ricorda quella di una distribuzione Beta:\n\\[\n\\theta^{\\alpha + y - 1} (1 - \\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta √® la distribuzione a posteriori non normalizzata per \\(\\theta\\). Per convertirla in una distribuzione di probabilit√† valida, dobbiamo normalizzarla in modo che l‚Äôintegrale su tutto il suo dominio sia pari a 1. Questo si ottiene dividendo per la funzione Beta \\(B(\\alpha', \\beta')\\), dove \\(\\alpha' = \\alpha + y\\) e \\(\\beta' = \\beta + n - y\\).\nIn conclusione, la distribuzione a posteriori per \\(\\theta\\), dopo aver osservato \\(y\\) successi in \\(n\\) prove, diventa una distribuzione Beta con i parametri aggiornati \\(\\alpha'\\) e \\(\\beta'\\):\n\\[\n\\text{Beta}(\\theta \\mid \\alpha + y, \\beta + n - y).\n\\]\nLa normalizzazione richiede il calcolo di \\(B(\\alpha + y, \\beta + n - y)\\), che utilizza la funzione Gamma per garantire che l‚Äôarea sotto la curva della funzione di densit√† di probabilit√† sia esattamente 1 sull‚Äôintervallo [0,1].\nQuesto esempio illustra un‚Äôapplicazione dell‚Äôanalisi coniugata, dove la scelta di una distribuzione a priori Beta, combinata con una funzione di verosimiglianza binomiale, produce una distribuzione a posteriori che √® ancora una distribuzione Beta. Questo risultato √® noto come ‚Äúcaso coniugato beta-binomiale‚Äù, riassunto nel seguente teorema:\n\nTeorema: Se la funzione di verosimiglianza √® binomiale, data da \\(Bin(n, y \\mid \\theta)\\), e la distribuzione a priori √® una Beta con parametri \\((\\alpha, \\beta)\\), allora la distribuzione a posteriori di \\(\\theta\\) sar√† una distribuzione Beta con parametri aggiornati \\((\\alpha + y, \\beta + n - y)\\).\n\nQuesta relazione facilita l‚Äôaggiornamento bayesiano delle nostre credenze sulla proporzione di successi in una serie di prove, utilizzando un approccio analitico e computazionalmente efficiente.\n\nEsempio 37.1 In un esempio ispirato da McElreath (2020) nel suo libro ‚ÄúStatistical Rethinking‚Äù, consideriamo un esperimento dove otteniamo 6 successi (indicati come ‚Äúacqua‚Äù) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento √® data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) √® il numero di successi e \\(n = 9\\) √® il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l‚Äôaggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l‚Äôesito delle nostre prove. L‚Äôapplicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definiamo i parametri\nalpha_prior, beta_prior = 2, 2\ny, n = 6, 9\nalpha_post, beta_post = alpha_prior + y, beta_prior + n - y\n\n# Creiamo un array di valori theta\ntheta = np.linspace(0, 1, 1000)  # Aumentiamo la risoluzione per un calcolo pi√π preciso\n\n# Calcoliamo le PDF\nprior_pdf = stats.beta.pdf(theta, alpha_prior, beta_prior)\nlikelihood = theta**y * (1-theta)**(n-y)\n\n# Normalizziamo la verosimiglianza\nlikelihood_integral = trapezoid(likelihood, theta)\nnormalized_likelihood = likelihood / likelihood_integral\n\nposterior_pdf = stats.beta.pdf(theta, alpha_post, beta_post)\n\n# Disegnamo le distribuzioni\nplt.plot(theta, prior_pdf, label=f'Prior Beta({alpha_prior}, {beta_prior})', color='blue')\nplt.plot(theta, normalized_likelihood, label='Likelihood (normalizzata)', linestyle='--', color='green')\nplt.plot(theta, posterior_pdf, label=f'Posterior Beta({alpha_post}, {beta_post})', color='red')\n\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Density')\nplt.title('Distribuzioni Prior, Likelihood e Posterior')\n_ = plt.legend()\n\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l‚Äôintegrale della funzione di verosimiglianza non normalizzata su Œ∏, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] √® uguale a 1. La normalizzazione della verosimiglianza √® eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 37.2 Esaminiamo ora un esempio discuso da Johnson, Ott, e Dogucu (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorit√†, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell‚Äôarticolo, Milgram descrive lo studio come segue:\n\nconsistente nell‚Äôordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che √® un complice addestrato dell‚Äôesperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‚Äòesperimento di apprendimento‚Äô apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l‚Äôesperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre pi√π intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realt√† era un attore addestrato) sulla loro capacit√† di memorizzare una serie di item. Se l‚Äôattore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all‚Äôattore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l‚Äôattore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello ‚ÄúPericolo: Scossa Grave‚Äù. Il problema richiede di costruire la distribuzione a posteriori della probabilit√† \\(\\theta\\) di infliggere una scossa a l livello ‚ÄúPericolo: Scossa Grave‚Äù, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha = 1\nbeta_val = 10\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha, beta_val)\n\n# Plot della densit√† di probabilit√†\nplt.plot(x_values, beta_pdf, label='Beta(1, 10)')\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('x')\nplt.ylabel('Densit√† di probabilit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori √® una Beta di parametri aggiornati\n\ny = 26\nn = 40\n\nalpha_prior = 1\nbeta_prior = 10\n\nalpha_post = alpha_prior + y\nbeta_post = beta_prior + n - y\n\nalpha_post, beta_post\n\n(27, 24)\n\n\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha_post, beta_post)\n\n# Plot della densit√† di probabilit√†\nplt.plot(x_values, beta_pdf, label='Beta(27, 24)')\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('theta')\nplt.ylabel('Densit√† di probabilit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n\n0.5294117647058824\n\n\nCalcoliamo la moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n\n0.5306122448979592\n\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\)\n\nstats.beta.sf(0.6, alpha_post, beta_post)\n\n0.15616833089995472\n\n\novvero\n\n1 - stats.beta.cdf(0.6, alpha_post, beta_post)\n\n0.15616833089995474\n\n\nSvolgiamo ora il problema usando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta = np.linspace(0, 1, 100)\n\n\nalpha_prior = 1  \nbeta_prior = 10   \n\n# Calcolo della PDF della distribuzione Beta per i valori x\nprior = stats.beta.pdf(theta, alpha_prior, beta_prior)\n\nplt.vlines(theta, 0, prior / np.sum(prior), color='black', linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione a priori')\n\nplt.show()\n\n\n\n\n\n\n\n\nCreiamo la verosimiglianza.\n\nlk = stats.binom.pmf(y, n, theta)\n\nplt.vlines(theta, 0, lk / np.sum(lk), color='black', linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Verosimiglianza')\n\nplt.show()\n\n\n\n\n\n\n\n\n\npost = (prior * lk) / np.sum(prior * lk)\n\nplt.vlines(theta, 0, post, color='black', linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione a posteriori')\n\nplt.show()\n\n\n\n\n\n\n\n\nEstraiamo un campione dalla distribuzione a posteriori.\n\nsamples = np.random.choice(theta, p=post, size=int(1e6), replace=True)\n\nTroviamo la media a posteriori.\n\nnp.mean(samples)\n\n0.5294427575757579\n\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\).\n\nnp.mean(samples &gt; 0.6)\n\n0.15274",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/03_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/chapter_4/03_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "37¬† Distribuzioni coniugate (1)",
    "section": "37.3 Principali distribuzioni coniugate",
    "text": "37.3 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle pi√π note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori √® \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori √® \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori √® \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori √® \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/03_conjugate_families_1.html#conclusioni",
    "href": "chapters/chapter_4/03_conjugate_families_1.html#conclusioni",
    "title": "37¬† Distribuzioni coniugate (1)",
    "section": "37.4 Conclusioni",
    "text": "37.4 Conclusioni\nIn conclusione, l‚Äôutilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell‚Äôadozione di distribuzioni a priori coniugate risiede nella loro capacit√† di rendere l‚Äôanalisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, √® cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e pi√π realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilit√†. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale √® sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la pi√π adeguata (Johnson, Ott, e Dogucu 2022).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/03_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/03_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "37¬† Distribuzioni coniugate (1)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/04_conjugate_families_2.html",
    "href": "chapters/chapter_4/04_conjugate_families_2.html",
    "title": "38¬† Distribuzioni coniugate (2)",
    "section": "",
    "text": "Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale √® che, attraverso l‚Äôaggiornamento bayesiano, l‚Äôincertezza sulla stima del parametro si riduce. Questo √® dovuto al fatto che l‚Äôinformazione aggiuntiva fornita dai dati osservati consente di ‚Äúrestringere‚Äù la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo cos√¨ la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle {ref}distr-coniugate-1-notebook, focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello √® la sua capacit√† di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini pi√π semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l‚Äôadozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/04_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "href": "chapters/chapter_4/04_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "title": "38¬† Distribuzioni coniugate (2)",
    "section": "38.1 Perch√© Usare la Distribuzione Normale?",
    "text": "38.1 Perch√© Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori √® nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma √® solo approssimativamente normale. Nei casi in cui il ricercatore abbia un‚Äôidea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza pu√≤ offrire buone approssimazioni alla densit√† a posteriori desiderata, con la consapevolezza che, con l‚Äôaumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede propriet√† frequentiste desiderabili. Sebbene l‚Äôenfasi nell‚Äôanalisi bayesiana non sia sulle stime puntuali, si pu√≤ dimostrare che, con campioni sempre pi√π grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa propriet√† esiste perch√© la distribuzione a posteriori √® un compromesso ponderato tra la distribuzione a priori specificata dall‚Äôutente, che in questo capitolo √® normale, e la funzione di verosimiglianza derivata dai dati, anch‚Äôessa normale in questo capitolo. Con l‚Äôaumentare delle dimensioni del campione, la verosimiglianza diventa sempre pi√π dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l‚Äôaumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/04_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/chapter_4/04_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "38¬† Distribuzioni coniugate (2)",
    "section": "38.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "38.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo √® stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n38.2.1 Distribuzione a Priori\nNell‚Äôapproccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n\n38.2.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilit√† di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza √® data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n\n38.2.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l‚Äôevidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoich√© la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulter√† anch‚Äôessa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n\n38.2.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula √®:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) √® una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con pi√π dati, la nostra fiducia nella media campionaria cresce, mentre l‚Äôincertezza a priori diminuisce.\n\n\n38.2.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l‚Äôincertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula √®:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) √® sempre inferiore o uguale. In altre parole, l‚Äôincertezza sulla stima di \\(\\mu\\) si riduce con l‚Äôaumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l‚Äôincertezza a priori (\\(\\sigma_0^2\\)) e l‚Äôinformazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un‚Äôintegrazione bilanciata tra l‚Äôinformazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l‚Äôaumento del numero di osservazioni.\n\nEsempio 38.1 I test standard di QI sono progettati per misurare l‚Äôintelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un‚Äôulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poich√© le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L‚Äôidea chiave nella descrizione della distribuzione a posteriori √® se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq = np.array(\n    [\n        96,\n        100,\n        100,\n        85,\n        83,\n        97,\n        92,\n        99,\n        87,\n        72,\n        86,\n        85,\n        67,\n        99,\n        94,\n        103,\n        97,\n        101,\n        87,\n        98,\n        87,\n        73,\n        97,\n        59,\n        98,\n        79,\n        81,\n        93,\n        105,\n        92,\n        78,\n        98,\n        95,\n        96,\n        72,\n        104,\n        90,\n        96,\n        98,\n        102,\n        78,\n        90,\n        63,\n        84,\n        84,\n        107,\n        86,\n        102,\n        106,\n        94,\n        102,\n        72,\n        101,\n        89,\n        72,\n        101,\n        91,\n        100,\n        100,\n        66,\n        107,\n        86,\n        78,\n        84,\n        78,\n        64,\n        72,\n        101,\n        91,\n        100,\n        67,\n        86,\n    ]\n)\n\n\n# Numero di osservazioni\nn = len(iq)\n\n# Media campionaria\ny_bar = np.mean(iq)\n\n# Deviazione standard nota\nsigma = 15\n\n# Parametri a priori\nmu_0 = 100\nsigma_0 = 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\\(\\mu_0\\) √® la media a priori\n\\(\\sigma_0\\) √® la deviazione standard a priori\n\\(n\\) √® il numero di osservazioni\n\\(\\sigma\\) √® la deviazione standard delle osservazioni (nota)\n\\(\\bar{y}\\) √® la media campionaria\n\n\nmu_p = ((1 / sigma_0**2) * mu_0 + (n / sigma**2) * y_bar) / (\n    (1 / sigma_0**2) + (n / sigma**2)\n)\nprint(f\"Media a posteriori (mu_p): {mu_p}\")\n\nMedia a posteriori (mu_p): 89.35616438356165\n\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq = 1 / ((1 / sigma_0**2) + (n / sigma**2))\nprint(f\"Varianza a posteriori (sigma_p_sq): {sigma_p_sq}\")\n\nVarianza a posteriori (sigma_p_sq): 3.082191780821918\n\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\nsigma_p = np.sqrt(sigma_p_sq)\n\n# Definizione dei valori sull'asse x\nx = np.linspace(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, 1000)\n\n# Calcolo della densit√† di probabilit√†\npdf = stats.norm.pdf(x, mu_p, sigma_p)\n\n# Creazione del grafico\nplt.plot(x, pdf, label=f\"N({mu_p:.2f}, {sigma_p:.2f})\", color=\"blue\")\nplt.fill_between(x, pdf, color=\"blue\", alpha=0.2)\nplt.title(\"Distribuzione a Posteriori\")\nplt.xlabel(\"Media del Quoziente di Intelligenza\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nL‚Äôanalisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un‚Äôinterpretazione completa di questo dato, √® fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori √® ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo pu√≤ innescare un effetto di aggregazione, dove la media ‚Äúsmussata‚Äù risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilit√† potrebbero essere mascherate da questa media aggregata.\n√à importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ci√≤ significa che nazioni con popolazioni pi√π piccole, anche se con punteggi QI mediamente pi√π alti o pi√π bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni pi√π grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell‚Äôintelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l‚Äôaccesso all‚Äôistruzione, la qualit√† della nutrizione e l‚Äôesposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilit√† osservata tra le nazioni.\nInoltre, √® fondamentale considerare la possibilit√† di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l‚Äôimportanza di un‚Äôattenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L‚Äôeffetto di aggregazione, l‚Äôutilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un‚Äôanalisi pi√π approfondita che consideri questi fattori e utilizzi metodi statistici pi√π sofisticati per ottenere una comprensione pi√π completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/04_conjugate_families_2.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/04_conjugate_families_2.html#commenti-e-considerazioni-finali",
    "title": "38¬† Distribuzioni coniugate (2)",
    "section": "38.3 Commenti e considerazioni finali",
    "text": "38.3 Commenti e considerazioni finali\nIn questa sezione, abbiamo approfondito il meccanismo dell‚Äôaggiornamento bayesiano attraverso l‚Äôimplementazione del modello normale-normale.\nIl processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l‚Äôacquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori $ _0 $ e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media √® determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) √® determinata utilizzando un‚Äôespressione che incorpora entrambe le varianze.\nIn sintesi, l‚Äôadozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la propriet√† di coniugatezza, semplificando cos√¨ l‚Äôintero processo analitico.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/04_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/04_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "38¬† Distribuzioni coniugate (2)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.8.4\nscipy     : 1.13.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGill, Jeff. 2015. Bayesian methods: A social and behavioral sciences approach. 3rd Edition. Chapman; Hall/CRC.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/05_summary_posterior.html",
    "href": "chapters/chapter_4/05_summary_posterior.html",
    "title": "39¬† Sintesi a posteriori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell‚Äôinformazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell‚Äôinferenza.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/05_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/chapter_4/05_summary_posterior.html#riepilogo-numerico",
    "title": "39¬† Sintesi a posteriori",
    "section": "39.1 Riepilogo numerico",
    "text": "39.1 Riepilogo numerico\nLa distribuzione a posteriori contiene in s√© tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con pi√π di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilit√†.\n\n\n39.1.1 Stima puntuale\nNel contesto dell‚Äôinferenza bayesiana, il processo di stima del valore pi√π credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori √® un compito cruciale. Comunemente, tale processo si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta √® guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il ‚Äúvalore pi√π credibile‚Äù del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\nMedia a posteriori: La media a posteriori √® il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, √® espressa dalla formula:\n\\[ E(\\theta | y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta | y) \\, d\\theta. \\]\nModa (Massimo a posteriori, MAP): La moda identifica il valore pi√π probabile del parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore √® noto come ‚Äúmassimo a posteriori‚Äù (MAP). La stima MAP inizia con il concetto di stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta | y)\\), come segue:\n\\[ \\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta | y). \\]\nNell‚Äôinferenza bayesiana, \\(\\theta\\) √® considerato come una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere la nostra incertezza su \\(\\theta\\). Integrando la distribuzione a priori, otteniamo la formula per la stima MAP:\n\\[ \\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta | y)p(\\theta). \\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densit√† a posteriori di \\(\\theta\\) dati \\(y\\), che coincide con la moda della densit√† a posteriori.\nMediana: La mediana √® il valore del parametro per cui il 50% della massa di probabilit√† a posteriori si distribuisce equamente a sinistra e a destra. √à una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore pi√π probabile del parametro.\n\nPer valutare l‚Äôincertezza associata al parametro \\(\\theta\\), √® utile calcolare la varianza a posteriori. Questa varianza √® basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l‚Äôincertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unit√† di misura dei dati. La formula per la varianza a posteriori √® data da:\n\\[ V(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2. \\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l‚Äôincertezza associata a \\(\\theta\\) in modo informativo.\n\n\n39.1.2 Intervallo di credibilit√†\nNel contesto dell‚Äôinferenza bayesiana, l‚Äôintervallo di credibilit√† √® uno strumento fondamentale per valutare l‚Äôampiezza dell‚Äôintervallo che racchiude una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo fornisce informazioni sulla nostra incertezza relativa al valore del parametro: un intervallo pi√π ampio indica una maggiore incertezza associata. L‚Äôobiettivo primario dell‚Äôintervallo di credibilit√† √® di fornire una misura quantitativa dell‚Äôincertezza legata alla stima del parametro \\(\\theta\\).\nLa definizione di intervallo di credibilit√† non determina un unico intervallo di ordine \\((1 - \\alpha) \\cdot 100\\%\\), ma rende possibile una gamma infinita di tali intervalli. Di conseguenza, √® essenziale introdurre condizioni aggiuntive per la selezione dell‚Äôintervallo di credibilit√†. Due delle condizioni aggiuntive pi√π comuni sono l‚Äôintervallo di credibilit√† simmetrico e l‚Äôintervallo di credibilit√† pi√π stretto.\n\nIntervallo di Credibilit√† Simmetrico: Questa condizione richiede che l‚Äôintervallo di credibilit√† sia simmetrico rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) √® il valore stimato del parametro, l‚Äôintervallo di credibilit√† avr√† la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) √® un valore positivo adeguato. Un intervallo di credibilit√† simmetrico al livello \\(\\alpha\\) pu√≤ essere rappresentato come:\n\\[ I_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}], \\]\ndove \\(q_z\\) √® un quantile della distribuzione a posteriori. Ad esempio, un intervallo di credibilit√† simmetrico al 94% sar√†:\n\\[ I_{0.06} = [q_{0.03}, q_{0.97}] \\]\nassicurando che il 3% della densit√† di probabilit√† a posteriori sia compreso in ciascuna coda dell‚Äôintervallo.\nIntervallo di Credibilit√† Pi√π Stretto (Intervallo di Massima Densit√† Posteriore, HPD): Questo intervallo √® scelto in modo da avere la larghezza minima tra tutti gli intervalli di ordine \\((1 - \\alpha) \\cdot 100\\%\\), rappresentando la stima pi√π precisa possibile del parametro \\(\\theta\\). A differenza dell‚Äôintervallo di credibilit√† simmetrico, l‚Äôintervallo di credibilit√† pi√π stretto, o Intervallo di Massima Densit√† Posteriore (HPD), √® costruito per includere tutti i valori di \\(\\theta\\) che godono di maggiore credibilit√† a posteriori. Questo intervallo pu√≤ essere ottenuto tracciando una linea orizzontale sulla rappresentazione grafica della distribuzione a posteriori e regolando l‚Äôaltezza della linea in modo che l‚Äôarea sottesa alla curva sia pari a \\(1 - \\alpha\\). L‚Äôintervallo HPD √® il pi√π stretto possibile tra tutti gli intervalli possibili con lo stesso livello di fiducia. Quando la distribuzione a posteriori √® unimodale e simmetrica, l‚Äôintervallo di credibilit√† pi√π stretto coincide con l‚Äôintervallo di credibilit√† simmetrico.\n\nIl calcolo degli intervalli di credibilit√† pu√≤ richiedere l‚Äôuso di software statistici dedicati, data la complessit√† nel determinarli manualmente, specialmente in situazioni con modelli bayesiani pi√π complessi o quando il calcolo coinvolge simulazioni numeriche.\nUn aspetto importante del trattare i parametri in modo probabilistico riguarda l‚Äôinterpretazione degli intervalli di confidenza. Nell‚Äôambito frequentista, √® necessario immaginare un parametro fisso, ad esempio la media della popolazione \\(\\mu\\), e immaginare un numero infinito di campioni ripetuti dalla popolazione caratterizzata da \\(\\mu\\). Per ogni campione, possiamo ottenere la media del campione \\(\\bar{x}\\) e quindi formare un intervallo di confidenza al \\(100(1 ‚àí \\alpha)\\%\\). L‚Äôinterpretazione corretta in termini frequentisti √® che il \\(100(1 ‚àí \\alpha)\\%\\) degli intervalli di confidenza formati in questo modo cattura il vero parametro \\(\\mu\\) sotto l‚Äôipotesi nulla. In questo contesto, la probabilit√† che il parametro sia nell‚Äôintervallo √® o 0 o 1.\nIn contrasto, il framework bayesiano assume che un parametro abbia una distribuzione di probabilit√†. Campionando dalla distribuzione a posteriori dei parametri del modello, possiamo ottenere i suoi quantili e, dai quantili, possiamo ottenere direttamente la probabilit√† che un parametro rientri in un determinato intervallo. Quindi, in questo caso, un intervallo di probabilit√† a posteriori del 95% significherebbe che la probabilit√† che il parametro rientri nell‚Äôintervallo √® 0.95. Questo √® completamente diverso dall‚Äôinterpretazione frequentista, e si allinea pi√π sensatamente con il senso comune.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/05_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/chapter_4/05_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "39¬† Sintesi a posteriori",
    "section": "39.2 Verifica di ipotesi bayesiana",
    "text": "39.2 Verifica di ipotesi bayesiana\nL‚Äôinferenza bayesiana pu√≤ anche procedere attraverso un altro approccio, conosciuto come verifica di ipotesi bayesiana. Questo secondo tipo di inferenza bayesiana si concentra su problemi in cui intendiamo valutare la plausibilit√† dell‚Äôaffermazione che il parametro \\(\\theta\\) assuma valori all‚Äôinterno di un intervallo specifico (ad esempio, \\(\\theta &gt; 0.5\\)). In questa situazione, √® possibile calcolare la probabilit√† a posteriori che \\(\\theta\\) cada all‚Äôinterno dell‚Äôintervallo di interesse (come ad esempio, [0.5, 1.0]), integrando la distribuzione a posteriori su tale intervallo.\n\nEsempio 39.1 Per comprendere meglio attraverso un esempio pratico, esaminiamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche, Buerkner, e Renneberg (2019). Il BDI-II √® un questionario utilizzato per valutare la gravit√† dei sintomi depressivi.\n\nbdi = np.array([\n    26,\n    35,\n    30,\n    25,\n    44,\n    30,\n    33,\n    43,\n    22,\n    43,\n    24,\n    19,\n    39,\n    31,\n    25,\n    28,\n    35,\n    30,\n    26,\n    31,\n    41,\n    36,\n    26,\n    35,\n    33,\n    28,\n    27,\n    34,\n    27,\n    22,\n])\nprint(*bdi)\n\n26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33 28 27 34 27 22\n\n\nUn valore BDI-II \\(\\geq 30\\) indica la presenza di un livello grave di depressione. Nel campione clinico di {cite:t}zetsche_2019future, 17 pazienti su 30 manifestano un livello grave di depressione.\n\nnp.sum(bdi &gt;= 30)\n\n17\n\n\nSupponiamo di volere stimare la distribuzione a posteriori della probabilit√† \\(\\theta\\) di depressione grave nei pazienti clinici, cos√¨ come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione a priori \\(Beta(8, 2)\\).\nPoich√© i dati possono essere concepiti come una sequenza di prove Bernoulliane indipendenti, laddove la presenza di depressione grave viene concepita come un ‚Äúsuccesso‚Äù, la verosimiglianza sar√† Binomiale con paramentri \\(n\\) = 30 e \\(y\\) = 17.\nAvendo scelto, quale distribuzione a priori, una \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sar√† una \\(Beta(8 + 17, 2 + 30 - 17)\\):\n\\[\nf(\\theta \\mid y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ for } \\theta \\in [0,1] \\; .\n\\] (eq-post-beta-25-15)\n\ntheta = np.linspace(0, 1, 200)\nalpha = 25\nbeta = 15\npdf = stats.beta.pdf(theta, alpha, beta)\nplt.plot(theta, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(alpha, beta))\nplt.xlabel(r\"$\\theta$\", fontsize=14)\nplt.ylabel(\"Densit√† di probabilit√†\", fontsize=14)\nplt.legend(loc=1)\nplt.show()\n\n\n\n\n\n\n\n\nVediamo ora come ottenere delle stime puntuali da tale distribuzione a posteriori.\nper il presente esempio, la media della distribuzione a posteriori di \\(\\theta\\) √®\n\\[\n\\mathbb{E}(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625.\n\\]\nUna stima del massimo della probabilit√† a posteriori, o brevemente massimo a posteriori, MAP (da maximum a posteriori probability), √® la moda della distribuzione a posteriori. Nel caso presente, abbiamo\n\\[\nMo(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316.\n\\]\nLa mediana si ottiene con la funzione beta.ppf():\n\nstats.beta.ppf(0.5, alpha, beta)\n\n0.6271031100419254\n\n\nL‚Äôintervallo di credibilit√† simmetrico al 94% √® dato dalla chiamata a beta.ppf().\n\n[stats.beta.ppf(0.03, alpha, beta), stats.beta.ppf(0.97, alpha, beta)]\n\n[0.4781025861696672, 0.7612890799836668]\n\n\nIl calcolo precedente evidenzia l‚Äôinterpretazione intuitiva dell‚Äôintervallo di credibilit√†. Tale intervallo, infatti, pu√≤ essere interpretato nel modo seguente: possiamo attribuire una certezza soggettiva del 94% all‚Äôevento che \\(\\theta\\) assuma un valore compreso tra 0.478 e 0.761. Il valore di 0.94 corrisponde infatti all‚Äôarea sottesa dalla distribuzione a posteriori nell‚Äôintervallo \\[0.478, 0.761\\].\n\\[\nP(\\theta \\in (0.478, 0.761) \\mid Y = 17) = \\int_{0.478}^{0.761} f(\\theta \\mid y=17) d\\theta = 0.94.\n\\]\n\nbetacdf = stats.beta(alpha, beta).cdf\nbetacdf(0.7612890799836668) - betacdf(0.4781025861696672)\n\n0.9400000000000001\n\n\nPossiamo costruire vari intervalli di credibilit√† simmetrici. Ad esempio, l‚Äôintervallo di credibilit√† compreso tra il 25-esimo e il 75-esimo percentile:\n\n[stats.beta.ppf(0.25, alpha, beta), stats.beta.ppf(0.75, alpha, beta)]\n\n[0.5743877928498646, 0.6778673380880944]\n\n\nIn questo secondo caso, possiamo affermare con una certezza soggettiva del 50% che la probabilit√† di depressione grave tra i pazienti clinici si situa tra 0.57 e 0.68.\nNon esiste un livello ‚Äúgiusto‚Äù di credibilit√† soggettiva. I ricercatori adottano livelli differenti, come il 50%, l‚Äô80% o il 94%, a seconda del contesto dell‚Äôanalisi statistica. Ogni intervallo offre una prospettiva unica sulla nostra comprensione della distribuzione a posteriori del parametro d‚Äôinteresse.\nNon sempre √® appropriato presentare un intervallo di credibilit√† con le stesse code. Quando la distribuzione a posteriori √® marcatamente asimmetrica, risulta pi√π adeguato fornire l‚Äôintervallo di credibilit√† pi√π stretto (o Intervallo di Massima Densit√† Posteriore, HPD). L‚Äôintervallo HPD √® pi√π facilmente calcolabile quando si approssima la distribuzione a posteriori con il metodo MCMC.\nPassiamo ora alla verifica di ipotesi bayesiana. Supponiamo che la nostra ipotesi sia: \\(\\theta &gt;\\) 0.5. La credibilit√† soggettiva dell‚Äôevento \\(\\theta &gt; 0.5\\) pu√≤ essere ottenuta calcolando il seguente integrale:\n\\[\nf(\\theta &gt; 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;,\n\\]\ndove \\(f(\\cdot)\\) √® la distribuzione Beta(25, 15).\n√à facile trovare questo valore con Python.\n\n# Parametri della distribuzione Beta\nalpha = 25\nbeta = 15\n\n# Calcoliamo la probabilit√† P(theta &lt; 0.5) utilizzando la funzione cdf \nprobability = stats.beta.cdf(0.5, alpha, beta)\n\n# La probabilit√† P(theta &lt; 0.5) √® data da 1 - P(theta &gt; 0.5)\nprobability_less_than_0_5 = 1 - probability\n\nprint(f\"La probabilit√† P(theta &lt; 0.5) per una Beta(25, 15) √®: {probability_less_than_0_5:.4f}\")\n\nLa probabilit√† P(theta &lt; 0.5) per una Beta(25, 15) √®: 0.9459",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/05_summary_posterior.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/05_summary_posterior.html#commenti-e-considerazioni-finali",
    "title": "39¬† Sintesi a posteriori",
    "section": "39.3 Commenti e considerazioni finali",
    "text": "39.3 Commenti e considerazioni finali\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L‚Äôimpiego delle statistiche descrittive e l‚Äôanalisi degli intervalli di credibilit√† contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilit√† forniscono un intervallo di valori all‚Äôinterno del quale si ritiene, con un certo grado di probabilit√† soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l‚Äôincertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l‚Äôanalisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale pu√≤ essere condotto agevolmente calcolando l‚Äôarea appropriata sotto la distribuzione a posteriori, in accordo con l‚Äôipotesi in questione.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/05_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/05_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "39¬† Sintesi a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 28 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\nsys       : 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:51:20) [Clang 16.0.6 ]\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/06_balance_prior_post.html",
    "href": "chapters/chapter_4/06_balance_prior_post.html",
    "title": "40¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo si focalizza sull‚Äôimportanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi tratti dal libro ‚ÄúBayes Rules!‚Äù di Johnson e collaboratori {cite:p}Johnson2022bayesrules.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/06_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/chapter_4/06_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "40¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "40.1 La Distribuzione a Priori",
    "text": "40.1 La Distribuzione a Priori\nLa distribuzione a priori assume un ruolo centrale nell‚Äôapproccio bayesiano, poich√© riflette le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto √® di fondamentale importanza perch√© consente di integrare le informazioni pregresse con i dati osservati al fine di ottenere una stima pi√π precisa dei parametri. Le distribuzioni a priori possono variare in base al grado di certezza attribuito ai valori dei parametri.\n\n40.1.1 Distribuzioni a Priori Non Informative\nLe distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilit√† a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa √® la distribuzione uniforme, basata sul ‚ÄúPrincipio della Ragione Insufficiente‚Äù formulato da Laplace (1774/1951). Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\n\n\n40.1.2 Distribuzioni a Priori Debolmente Informative\nLe distribuzioni a priori debolmente informative consentendo di integrare una quantit√† limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori ‚Äúragionevoli‚Äù dei parametri del modello, tenendo conto delle incertezze presenti nell‚Äôanalisi. L‚Äôuso di informazioni a priori debolmente informative pu√≤ contribuire a migliorare la stabilit√† dell‚Äôanalisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non ‚Äúspostare‚Äù in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori ‚Äúneutri‚Äù dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ci√≤ che rende queste distribuzioni debolmente informative √® la specifica definizione di un intervallo ‚Äúplausibile‚Äù di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo pi√π stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l‚Äôanalisi verso soluzioni pi√π verosimili senza imporre vincoli eccessivi sui risultati.\n\n\n40.1.3 Distribuzioni a Priori Informativa\nLe conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l‚Äôincorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull‚Äôanalisi statistica, fornendo una solida base di conoscenza su cui fondare l‚Äôinferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L‚Äôincorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l‚Äôaccuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull‚Äôanalisi bayesiana.\nNell‚Äôambito della ricerca psicologica, l‚Äôutilizzo di distribuzioni a priori informative √® attualmente poco diffuso, tuttavia emergono segnali che all‚Äôinterno della comunit√† statistica sta crescendo l‚Äôinteresse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/06_balance_prior_post.html#il-caso-beta-binomiale",
    "href": "chapters/chapter_4/06_balance_prior_post.html#il-caso-beta-binomiale",
    "title": "40¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "40.2 Il caso beta-binomiale",
    "text": "40.2 Il caso beta-binomiale\nLa formula \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\) √® fondamentale per la comprensione dell‚Äôinferenza bayesiana. Essa illustra chiaramente che la distribuzione a posteriori emerge dalla congiunzione tra la distribuzione a priori e la funzione di verosimiglianza associata ai dati osservati. Questa sinergia permette di integrare informazioni a priori con evidenze empiriche recenti, risultando in una stima a posteriori del parametro \\(\\theta\\) che √® caratterizzata da un elevato grado di precisione e informativit√†.\nNel corso di questo capitolo, faremo uso di due funzioni specifiche per esplorare il modello beta-binomiale: plot_beta_binomial e summarize_beta_binomial. La prima funzione permette di visualizzare graficamente le distribuzioni a priori, di verosimiglianza e a posteriori, offrendo quindi un quadro intuitivo dell‚Äôaggiornamento bayesiano. La seconda funzione, invece, si concentra sull‚Äôestrazione di statistiche descrittive come la media, la moda e la varianza dalla distribuzione a posteriori. Entrambe queste risorse provengono dal testo di Johnson, Ott, e Dogucu (2022) e saranno strumentali per una comprensione approfondita del modello in esame.\n\ndef plot_beta_binomial(alpha, beta, y=None, n=None, prior=True, likelihood=True, posterior=True) -&gt; None:\n    \"\"\"Plot a Beta-Binomial Bayesian Model\n    \n    Parameters:\n    - alpha, beta: positive shape parameters of the prior Beta distribution\n    - y: observed number of successes\n    - n: observed number of trials\n    - prior: indicates whether the prior distribution should be plotted\n    - likelihood: indicates whether the scaled likelihood should be plotted\n    - posterior: indicates whether the posterior distribution should be plotted\n    \"\"\"\n    \n    Œ∏ = np.linspace(0, 1, 100)  # Range of possible values for Œ∏\n    \n    if prior:\n        p_theta = stats.beta.pdf(Œ∏, alpha, beta)\n        plt.fill_between(Œ∏, p_theta, step='mid', alpha=0.2, color='blue', label='Prior')\n    \n    if y is not None and n is not None:\n        if likelihood:\n            likelihood_values = stats.binom.pmf(y, n, Œ∏)\n            scale_factor = integrate.simpson(y=likelihood_values, x=Œ∏)  # Corrected to use keyword arguments\n            plt.plot(Œ∏, likelihood_values / scale_factor, color='orange', label='Likelihood (scaled)', lw=2)\n        \n        if posterior:\n            alpha_post = alpha + y\n            beta_post = beta + n - y\n            p_theta_post = stats.beta.pdf(Œ∏, alpha_post, beta_post)\n            plt.fill_between(Œ∏, p_theta_post, step='mid', alpha=0.4, color='green', label='Posterior')\n    \n    plt.xlabel(r'$\\theta$')\n    plt.ylabel('Density')\n    plt.legend(loc='upper left')\n    plt.title('Beta-Binomial Model')\n    plt.show()\n\n\ndef summarize_beta_binomial(alpha, beta, y=None, n=None):\n    \"\"\"Summarize a Beta-Binomial Bayesian model\n\n    @param alpha,beta positive shape parameters of the prior Beta model\n    @param y number of successes\n    @param n number of trials\n\n    Return: Pandas dataframe summarizing beta binomial\n    \"\"\"\n\n    def beta_mean(a, b):\n        return a / (a + b)\n\n    def beta_mode(a, b):\n        if a &lt; 1 and b &lt; 1:\n            return \"0 and 1\"\n        elif a &lt;= 1 and b &gt; 1:\n            return 0\n        elif a &gt; 1 and b &lt; 1:\n            return 1\n        else:\n            return (a - 1) / (a + b - 2)\n\n    def beta_var(a, b):\n        return a * b / ((a + b) ** 2 * (a + b + 1))\n\n    prior_mean = beta_mean(alpha, beta)\n    prior_mode = beta_mode(alpha, beta)\n    prior_var = beta_var(alpha, beta)\n    prior_sd = np.sqrt(prior_var)\n    if y is None and n is None:\n        summary = pd.DataFrame(\n            {\n                \"alpha\": alpha,\n                \"beta\": beta,\n                \"mean\": prior_mean,\n                \"mode\": prior_mode,\n                \"var\": prior_var,\n                \"sd\": prior_sd,\n            },\n            index=[\"prior\"],\n        )\n    else:\n        post_alpha = y + alpha\n        post_beta = n - y + beta\n        post_mean = beta_mean(post_alpha, post_beta)\n        post_mode = beta_mode(post_alpha, post_beta)\n        post_var = beta_var(post_alpha, post_beta)\n        post_sd = np.sqrt(post_var)\n        summary = pd.DataFrame(\n            {\n                \"alpha\": [alpha, post_alpha],\n                \"beta\": [beta, post_beta],\n                \"mean\": [prior_mean, post_mean],\n                \"mode\": [prior_mode, post_mode],\n                \"var\": [prior_var, post_var],\n                \"sd\": [prior_sd, post_sd],\n            },\n            index=[\"prior\", \"posterior\"],\n        )\n    return summary\n\nNel caso in cui disponiamo di un campione di dati di dimensioni molto ridotte, come ad esempio 15 successi su 20 tentativi in una distribuzione beta-binomiale, la distribuzione a priori pu√≤ esercitare un notevole impatto sulla distribuzione a posteriori. In contrasto, se consideriamo una distribuzione a priori uniforme, la distribuzione a posteriori assomiglier√† alla funzione di verosimiglianza, con l‚Äôeccezione dell‚Äôarea sotto le due curve. In parole pi√π semplici, quando la distribuzione a priori √® uniforme, la distribuzione a posteriori presenter√† un picco nella stima di massima verosimiglianza. Tuttavia, quando adottiamo diverse distribuzioni a priori, la distribuzione a posteriori potrebbe notevolmente discostarsi.\nCominciamo esaminando il caso in cui viene adottata una distribuzione a priori uniforme.\n\nplot_beta_binomial(alpha=1, beta=1, y=15, n=20)\n\n\n\n\n\n\n\n\nEsaminiamo ora l‚Äôeffetto di una distribuzione a priori poco informativa, come ad esempio una Beta(2, 2). In questa situazione, l‚Äôimpatto di tale scelta sulla distribuzione a posteriori √® di modesta entit√†, ma comunque presente. Questo fenomeno pu√≤ essere interpretato come un effetto di ‚Äúregolarizzazione‚Äù, il quale influisce sulla nostra stima in modo pi√π cauto rispetto a quanto ottenuto tramite il principio di massima verosimiglianza. In altre parole, la stima risultante risulta essere pi√π ‚Äúbilanciata‚Äù verso il valore intermedio di 0.5.\n\nplot_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n17\n7\n0.708333\n0.727273\n0.008264\n0.090906\n\n\n\n\n\n\n\n\nSe il campione √® di dimensioni maggiori, l‚Äôadozione di una distribuzione a priori Beta(2, 2) ha un effetto trascurabile: infatti, il valore massimo della distribuzione a posteriori risulta essere quasi identico alla stima di massima verosimiglianza.\n\nplot_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n152\n52\n0.745098\n0.747525\n0.000926\n0.030438\n\n\n\n\n\n\n\n\nSe optiamo per una distribuzione a priori informativa, questa avr√† un notevole impatto sulla distribuzione a posteriori quando ci si trova di fronte a un campione di dimensioni ridotte.\n\nplot_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.20\n0.025510\n0.159719\n\n\nposterior\n17\n10\n0.629630\n0.64\n0.008328\n0.091260\n\n\n\n\n\n\n\n\nAl contrario, la medesima distribuzione a priori ha un effetto insignificante sulla distribuzione a posteriori quando il campione √® di dimensioni considerevoli.\n\nplot_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n152\n55\n0.734300\n0.736585\n0.000938\n0.030627\n\n\n\n\n\n\n\n\n\nplot_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n1502\n505\n0.748381\n0.748628\n0.000094\n0.009684",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/06_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/chapter_4/06_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "40¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "40.3 Connessione tra intuizioni e teoria",
    "text": "40.3 Connessione tra intuizioni e teoria\nL‚Äôequilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessit√† matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che pu√≤ essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL‚Äôequazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) √® significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sar√† principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) √® piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente √® \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilit√† a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletter√† l‚Äôimportanza attribuita all‚Äôinformazione a priori: maggiore √® il valore di \\(\\alpha + \\beta\\), maggiore sar√† il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) √® considerevolmente grande, la distribuzione a posteriori avr√† un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/06_balance_prior_post.html#un-esempio-controintuitivo",
    "href": "chapters/chapter_4/06_balance_prior_post.html#un-esempio-controintuitivo",
    "title": "40¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "40.4 Un Esempio Controintuitivo",
    "text": "40.4 Un Esempio Controintuitivo\nEsaminiamo ora un altro esempio proposto in un tweet di McElreath:\n\nLesson: Don‚Äôt trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi scenari in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libert√†) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code pi√π spesse.\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento pi√π ‚Äúprevedibile‚Äù e concentrato attorno al valore medio.\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code pi√π spesse. La presenza di ‚Äúextra massa‚Äù nelle code significa che ciascuna distribuzione trova il modo dell‚Äôaltra pi√π plausibile, portando a una media che non rappresenta il miglior ‚Äúcompromesso‚Äù. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa √® molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non √® sorpreso dalla likelihood. Questo porta a un posterior che √® pi√π influenzato dalla likelihood normale.\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, √® il prior normale a dominare. Il ragionamento √® simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code pi√π spesse della likelihood di Student-t.\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code pi√π spesse e quindi eserciti una maggiore influenza sul posterior.\nDi seguito √® riportato il codice per riprodurre i risultati delle figure precedenti.\n\n# Observed data\nyobs = 0\n\n# Number of samples\nn_samples = 2000\n\n# Model with normal prior and normal likelihood\nwith pm.Model() as mnn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and t likelihood\nwith pm.Model() as mtt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and normal likelihood\nwith pm.Model() as mnt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with normal prior and t likelihood\nwith pm.Model() as mtn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n\n# Function to plot the results\ndef plot_posterior(trace, model_name):\n    mu_samples = trace.posterior['mu'].values.flatten()  # Extracting 'mu' samples\n    plt.hist(mu_samples, density=True, bins=30, alpha=0.7, label=f'{model_name} Posterior')\n    plt.xlabel('mu')\n    plt.ylabel('Density')\n    plt.legend()\n\n# Plotting the results\nplt.figure(figsize=(9, 7))\n\nplt.subplot(2, 2, 1)\nplot_posterior(trace_mnn, 'Normal Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 2)\nplot_posterior(trace_mtt, 't Prior, t Likelihood')\n\nplt.subplot(2, 2, 3)\nplot_posterior(trace_mnt, 't Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 4)\nplot_posterior(trace_mtn, 'Normal Prior, t Likelihood')\nplt.tight_layout()\nplt.show()\n\n/var/folders/hl/dt523djx7_q7xjrthzjpdvc40000gn/T/ipykernel_61930/765634110.py:23: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nIn conclusione, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non √® una scelta consigliabile. √à invece fondamentale procedere con l‚Äôesecuzione dei calcoli.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/06_balance_prior_post.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/06_balance_prior_post.html#commenti-e-considerazioni-finali",
    "title": "40¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "40.5 Commenti e considerazioni finali",
    "text": "40.5 Commenti e considerazioni finali\nLa conclusione dell‚Äôesempio presentato da Johnson (2022) ci offre una panoramica intuitiva ma fondamentale: l‚Äôaggiornamento bayesiano rispecchia i processi di ragionamento che intuitivamente utilizziamo nel quotidiano. Quando ci troviamo di fronte a nuove evidenze deboli, le nostre credenze preesistenti rimangono invariate. Al contrario, evidenze robuste ci costringono a rivedere e aggiornare le nostre credenze in linea con i nuovi dati. Questa √® la quintessenza dell‚Äôapproccio bayesiano: un meccanismo quantitativo e preciso che formalizza le nostre intuizioni.\nQuesto √® in netto contrasto con l‚Äôapproccio frequentista, che ignora le credenze o le conoscenze preesistenti. In questo schema, i risultati di un test statistico basato su un campione limitato di dati possono portare a una modifica delle credenze senza alcuna considerazione per le evidenze o le intuizioni pregresse. Questo divario metodologico tra i due approcci √® sintetizzata con efficacia nella celebre striscia comica di xkcd.\nEntrando nel dettaglio del contesto bayesiano, la scelta delle distribuzioni a priori √® un elemento cruciale, con due obiettivi principali. In primo luogo, l‚Äôutilizzo di distribuzioni a priori debolmente informative agisce come un meccanismo di regolarizzazione, contribuendo a ottenere inferenze pi√π prudenti mitigando l‚Äôeffetto di osservazioni estreme. Questo aspetto √® generalmente accettato e ritenuto non controverso nel campo statistico.\nIn secondo luogo, un settore in rapida crescita e di grande interesse √® l‚Äôintegrazione esplicita di conoscenza esperta preesistente. Tale processo, noto come ‚Äòelicitazione della conoscenza esperta‚Äô (expert knowledge elicitation) Brownstein et al. (2019), va ben oltre la semplice intervista con gli esperti. Esso richiede un elevato grado di rigore metodologico per prevenire l‚Äôinsorgenza di bias cognitivi. Questo aspetto √® particolarmente rilevante in ambiti come la psicologia, dove gli sviluppi teorici possono essere meno frequenti. Tale necessit√† √® supportata da un‚Äôampia letteratura accademica e da protocolli ben definiti, quali Cooke, SHELF e Delphi probabilistico O‚ÄôHagan (2019).\nIn conclusione, pur aspirando all‚Äôobiettivit√† come ideale della ricerca scientifica, √® indispensabile riconoscere e affrontare la soggettivit√† intrinseca nel processo di scelta dei priori. Attraverso l‚Äôuso di protocolli rigorosi di elicitazione della conoscenza esperta, √® possibile realizzare analisi bayesiane robuste e ben informate, che riflettano in modo accurato sia le incertezze intrinseche che la competenza specifica nel campo di studio.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/06_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/06_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "40¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p jax\n\nLast updated: Tue Apr 09 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\njax: 0.4.25\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.0\nrequests  : 2.31.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\npymc      : 5.10.4\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBrownstein, Naomi C, Thomas A Louis, Anthony O‚ÄôHagan, e Jane Pendergast. 2019. ¬´The role of expert judgment in statistical inference and evidence-based decision-making¬ª. The American Statistician 73 (sup1): 56‚Äì68.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO‚ÄôHagan, Anthony. 2019. ¬´Expert knowledge elicitation: subjective but scientific¬ª. The American Statistician 73 (sup1): 69‚Äì81.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html",
    "href": "chapters/chapter_4/10_metropolis.html",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "",
    "text": "Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana relativi alla distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche discusso l‚Äôutilizzo di approcci come l‚Äôapprossimazione tramite griglia e i metodi dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione e spiegheremo perch√© sono necessari approcci speciali noti come metodi di Monte Carlo a Catena di Markov (MCMC).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/chapter_4/10_metropolis.html#il-denominatore-bayesiano",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.1 Il denominatore bayesiano",
    "text": "41.1 Il denominatore bayesiano\nNell‚Äôapproccio bayesiano, il nostro obiettivo principale √® determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando sia i dati osservati $ y $ che la distribuzione a priori \\(p(\\theta)\\). Questo processo si basa sul teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIn questa formula, il denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta l‚Äôintegrazione (o la somma, nel caso di variabili discrete) su tutti i possibili valori di \\(\\theta\\), fornendo cos√¨ la probabilit√† marginale di \\(y\\). Questo assicura che $ p(y) $ sia una distribuzione di probabilit√† valida che si integra (o si somma) a 1.\nTuttavia, spesso incontriamo una sfida significativa: il calcolo dell‚Äôevidenza \\(p(y) = \\int p(y \\mid \\theta) p(\\theta) d\\theta\\) pu√≤ essere estremamente complesso, specialmente per modelli pi√π articolati, rendendo difficile ottenere con precisione la distribuzione a posteriori.\nUna soluzione possibile √® rappresentata dalle distribuzioni a priori coniugate, che offrono un metodo analitico per determinare la distribuzione a posteriori. Tuttavia, questo limita la selezione delle distribuzioni a priori e di verosimiglianza.\nUn metodo per superare questa limitazione √® ricorrere a soluzioni numeriche, ma i metodi di campionamento a griglia sono applicabili solo nel caso di modelli con un numero di parametri molto piccolo.\nLa soluzione generale √® utilizzare i Metodi di Monte Carlo a Catena di Markov (MCMC). Questi metodi consentono di derivare la distribuzione a posteriori basandosi su presupposti teorici e senza restrizioni nella scelta delle distribuzioni. L‚Äôapproccio Monte Carlo si basa sulla generazione di sequenze di numeri casuali per creare un ampio campione di osservazioni dalla distribuzione a posteriori. Da questi campioni, possiamo poi stimare empiricamente le propriet√† di interesse. Questo approccio richiede l‚Äôuso di metodi computazionalmente intensivi e, con la crescente potenza di calcolo dei computer moderni, tali metodi stanno diventando sempre pi√π accessibili e popolari nell‚Äôanalisi dei dati.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#il-metodo-di-monte-carlo",
    "href": "chapters/chapter_4/10_metropolis.html#il-metodo-di-monte-carlo",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.2 Il Metodo di Monte Carlo",
    "text": "41.2 Il Metodo di Monte Carlo\nNei capitoli precedenti abbiamo gi√† esplorato l‚Äôefficacia della simulazione nel campo della teoria delle probabilit√†. Un esempio classico √® il problema di Monty Hall, che mostra come la simulazione ripetuta possa fornire stime affidabili per la media e la varianza di variabili casuali. Inoltre, applicando la legge dei grandi numeri, queste stime diventano pi√π accurate all‚Äôaumentare del numero di simulazioni. Ci√≤ evidenzia la potenza dei metodi Monte Carlo, che evitano la necessit√† di calcolare integrali complessi.\nIl Metodo di Monte Carlo, sviluppato durante il Progetto Manhattan negli anni ‚Äô40, utilizza numeri casuali per risolvere problemi matematici complessi. Originariamente ideato da Stanislaw Ulam e successivamente implementato da John von Neumann, il metodo prende il nome dallo zio giocatore d‚Äôazzardo di Ulam, come suggerito da Nicholas Metropolis. Da allora, questo metodo √® diventato una tecnica fondamentale in diverse discipline, contribuendo significativamente alla risoluzione di problemi complessi.\nLa metodologia di Monte Carlo genera un‚Äôampia serie di punti casuali per stimare quantit√† di interesse, come l‚Äôintegrazione numerica. Un esempio classico √® l‚Äôapprossimazione dell‚Äôintegrale di un cerchio in 2D, dove il rapporto tra il numero di punti che cadono all‚Äôinterno del cerchio e tutti i campioni fornisce un‚Äôapprossimazione dell‚Äôarea (per un esempio numerico, si veda Appendice P).\nPer illustrare ulteriormente questo concetto, consideriamo ora una distribuzione continua \\(p(\\theta \\mid y)\\) con una media \\(\\mu\\). Se siamo in grado di generare una sequenza di campioni casuali \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) indipendenti e identicamente distribuiti secondo \\(p(\\theta \\mid y)\\), possiamo stimare il valore atteso teorico di \\(\\theta\\) utilizzando la media campionaria \\(\\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}\\). Questa approssimazione diventa sempre pi√π accurata man mano che aumenta il numero di campioni \\(T\\), grazie alla Legge Forte dei Grandi Numeri.\nUn altro vantaggio del Metodo di Monte Carlo √® la sua capacit√† di approssimare la probabilit√† che una variabile casuale \\(\\theta\\) cada all‚Äôinterno di un intervallo specifico \\((l, u)\\). Questo pu√≤ essere ottenuto calcolando la media campionaria della funzione indicatrice \\(I(l &lt; \\theta &lt; u)\\) per ogni realizzazione \\(\\theta^{(t)}\\), cio√® \\(Pr(l &lt; \\theta &lt; u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\in (l, u)}{T}\\).\nNonostante la loro efficacia, un limite dei metodi Monte Carlo tradizionali risiede nella generazione efficiente di un elevato numero di campioni \\(X_1, X_2, \\ldots, X_n\\). In risposta a questa sfida, i metodi di Monte Carlo basati su catene di Markov (MCMC) offrono una soluzione potente per simulare da distribuzioni complesse attraverso catene di Markov. L‚Äôevoluzione di questi algoritmi ha trasformato radicalmente la statistica e il calcolo scientifico, permettendo la simulazione da una vasta gamma di distribuzioni, anche in spazi di alta dimensionalit√†.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#le-catene-di-markov",
    "href": "chapters/chapter_4/10_metropolis.html#le-catene-di-markov",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.3 Le Catene di Markov",
    "text": "41.3 Le Catene di Markov\nLe catene di Markov, ideate da Andrey Markov nel 1906, rappresentano un tentativo di estendere la legge dei grandi numeri a contesti in cui le variabili casuali non sono indipendenti. Tradizionalmente, la statistica si concentra su sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), simboleggiate come \\(X_0, X_1, \\ldots, X_n, \\ldots\\). In tali sequenze, ogni variabile √® indipendente dalle altre e segue la stessa distribuzione, con \\(n\\) che rappresenta un indice temporale discreto. Tuttavia, questa assunzione di indipendenza non √® sempre realistica nei modelli di fenomeni complessi, portando alla necessit√† di esplorare forme alternative di dipendenza tra variabili.\nPer superare le limitazioni dell‚Äôindipendenza, le catene di Markov introducono una cosiddetta ‚Äúdipendenza a un passo‚Äù, incarnata nella ‚Äúpropriet√† di Markov‚Äù. Questa propriet√† stabilisce che la previsione di un evento futuro \\(X_{n+1}\\) dipende unicamente dall‚Äôevento immediatamente precedente \\(X_n\\), indipendentemente dagli eventi passati \\(X_0, X_1, X_2, \\ldots, X_{n-1}\\). La propriet√† di Markov √® espressa matematicamente come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta propriet√† afferma che la previsione di un evento futuro dipende solo dall‚Äôevento immediatamente precedente, semplificando i calcoli relativi alle probabilit√† condizionali.\nLe catene di Markov rappresentano un framework fondamentale per la modellazione delle dipendenze tra variabili casuali, una nozione cruciale in numerosi campi della statistica e della scienza dei dati, inclusa la metodologia MCMC (Markov Chain Monte Carlo). In particolare, nell‚Äôambito dell‚Äôanalisi bayesiana, l‚Äôuso di MCMC si rivela di estrema importanza, soprattutto quando non √® possibile calcolare in modo analitico la distribuzione a posteriori.\nL‚Äôalgoritmo di Metropolis rappresenta una delle implementazioni pi√π semplici del metodo MCMC. Questo algoritmo sfrutta la natura dipendente delle catene di Markov per navigare in modo efficace attraverso lo spazio della distribuzione a posteriori. Questo aspetto rende il MCMC uno strumento di grande potenza per affrontare problemi complessi in cui i metodi analitici tradizionali non possono essere applicati (per ulteriori dettagli, si veda Appendice P). In breve, il MCMC consente di generare un vasto insieme di valori per il parametro \\(\\theta\\). Idealmente, questi valori riflettono la distribuzione a posteriori \\(p(\\theta \\mid y)\\) quando questa non pu√≤ essere ottenuta direttamente. Questa caratteristica rende il MCMC uno strumento essenziale per risolvere problemi complessi in cui i metodi analitici convenzionali non sono applicabili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/10_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.4 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "41.4 Estrazione di campioni dalla distribuzione a posteriori\nNella discussione seguente ci porremo l‚Äôobiettivo di comprendere come utilizzare l‚Äôalgoritmo di Metropolis per approssimare la distribuzione a posteriori \\(p(\\theta \\mid y)\\). A questo fine, il capitolo √® strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o ‚Äúa posteriori,‚Äù sia gi√† conosciuta o disponibile per l‚Äôanalisi.\nIn seguito, passeremo a illustrare come l‚Äôalgoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non √® direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un‚Äôapprossimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse √® focalizzato sulla determinazione della probabilit√† che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilit√† sar√† indicata come \\(\\pi\\). Iniziamo importando i dati.\n\nmoma_sample = pd.read_csv(\"../../data/moma_sample.csv\")\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample.head()\n\n\n\n\n\n\n\n\n\nartist\ncountry\nbirth\ndeath\nalive\ngenx\ngender\ncount\nyear_acquired_min\nyear_acquired_max\n\n\n\n\n0\nAd Gerritsen\ndutch\n1940\n2015.0\nFalse\nFalse\nmale\n1\n1981\n1981\n\n\n1\nKirstine Roepstorff\ndanish\n1972\nNaN\nTrue\nTrue\nfemale\n3\n2005\n2005\n\n\n2\nLisa Baumgardner\namerican\n1958\n2015.0\nFalse\nFalse\nfemale\n2\n2016\n2016\n\n\n3\nDavid Bates\namerican\n1952\nNaN\nTrue\nFalse\nmale\n1\n2001\n2001\n\n\n4\nSimon Levy\namerican\n1946\nNaN\nTrue\nFalse\nmale\n1\n2012\n2012\n\n\n\n\n\n\n\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\nresult = moma_sample[\"genx\"].value_counts()\nprint(result)\n\ngenx\nFalse    86\nTrue     14\nName: count, dtype: int64\n\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che √® stato osservato. Tuttavia, poich√© il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilit√† di appartenere alla generazione X o a una generazione successiva) all‚Äôinterno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l‚Äôesito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le propriet√† delle distribuzioni coniugate, possiamo calcolare la distribuzione a posteriori esatta:\nY ~ Binomiale(100, œÄ)\nŒ∏ = Beta(4, 6)\nŒ∏ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) ‚Üí Beta(18, 92)\nNella figura successiva √® rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori scelta.\n\nx = np.linspace(0, 1, 1000)\n\nprior_density = stats.beta.pdf(x, 4, 6)\nposterior_density = stats.beta.pdf(x, 18, 92)\n\nplt.fill_between(x, prior_density, alpha=0.5, label=\"Prior: Beta(4, 6)\")\nplt.fill_between(x, posterior_density, alpha=0.5, label=\"Posterior: Beta(18, 92)\")\nplt.xlabel(\"Parameter Value\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.title(\"Prior and Posterior Densities\")\nplt.show()\n\n\n\n\n\n\n\n\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto √®\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n41.4.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un‚Äôapprossimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con poche osservazioni (ad esempio, 10), possiamo procedere con la seguente simulazione:\n\ny = stats.beta(18, 92).rvs(10)\nprint(y)\n\n[0.18694021 0.12067309 0.17576971 0.1608302  0.12912987 0.20527983\n 0.14209658 0.15057358 0.12001648 0.13024873]\n\n\n\nnp.mean(y)\n\n0.1521558285153169\n\n\nTuttavia, con solo 10 campioni l‚Äôapprossimazione potrebbe non essere molto accurata. Pi√π aumentiamo il numero di campioni (cio√® il numero di osservazioni casuali generate), pi√π precisa sar√† l‚Äôapprossimazione. Aumentando il numero di campioni, ad esempio a 10000, otteniamo un risultato pi√π preciso:\n\nstats.beta(18, 92).rvs(10000).mean()\n\n0.16380917953899665\n\n\nQuando il numero di campioni a posteriori diventa molto grande, la distribuzione campionaria converge alla densit√† della popolazione. Questo concetto si applica non solo alla media, ma anche ad altre statistiche descrittive, come la moda e la varianza.\n√à importante sottolineare che l‚Äôapplicazione della simulazione di Monte Carlo √® efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ci√≤ √® stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poich√© le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l‚Äôespressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l‚Äôutilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, per√≤, √® possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l‚Äôuso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l‚Äôalgoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#algoritmo-di-metropolis",
    "href": "chapters/chapter_4/10_metropolis.html#algoritmo-di-metropolis",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.5 Algoritmo di Metropolis",
    "text": "41.5 Algoritmo di Metropolis\nL‚Äôalgoritmo di Metropolis √® un metodo avanzato per il campionamento da distribuzioni probabilistiche complesse. Appartiene alla famiglia dei metodi Monte Carlo Markov Chain (MCMC) e combina strategie di campionamento Monte Carlo con catene di Markov per navigare nello spazio dei parametri in modo intelligente. Questo consente di ottenere campioni rappresentativi della distribuzione di interesse indipendentemente dal punto di partenza, riducendo il rischio di bias nei risultati.\n\n41.5.1 Passaggi Fondamentali dell‚ÄôAlgoritmo di Metropolis\n\nScegli un valore iniziale \\(\\theta_1\\). Imposta \\(t = 1\\).\nCampiona un possibile nuovo valore \\(\\theta_p\\) basato su una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\). Di solito, si usa una distribuzione normale \\(N(\\theta_t, \\tau)\\) come distribuzione di proposta, dove \\(\\tau\\) funge da parametro di regolazione che controlla la dimensione del passo.\nCalcola il rapporto \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\).\nSe \\(\\alpha \\geq 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\).\nSe \\(\\alpha &lt; 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\) con probabilit√† \\(\\alpha\\). Altrimenti, imposta \\(\\theta_{t+1} = \\theta_t\\).\nRipeti dal passo 2 per campionare un nuovo valore \\(\\theta_p\\).\n\n\n\n41.5.2 Dettagli dell‚ÄôAlgoritmo\n\nDistribuzione di Proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) √® usata per generare nuovi campioni di \\(\\theta_p\\) basati sul valore corrente \\(\\theta_t\\). Una scelta comune √® la distribuzione normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) √® un parametro di tuning che controlla la dimensione dei passi del campionamento. Un valore di \\(\\tau\\) troppo grande o troppo piccolo pu√≤ influenzare negativamente l‚Äôefficienza del campionamento.\nCalcolo del Rapporto \\(\\alpha\\): Il rapporto \\(\\alpha\\) √® dato dalla probabilit√† a posteriori del nuovo valore \\(\\theta_p\\) rispetto alla probabilit√† a posteriori del valore corrente \\(\\theta_t\\). Questo rapporto determina l‚Äôaccettazione o il rifiuto del nuovo campione.\nDecisione di Accettazione:\n\nSe \\(\\alpha \\geq 1\\), il nuovo valore \\(\\theta_p\\) √® sempre accettato.\nSe \\(\\alpha &lt; 1\\), il nuovo valore \\(\\theta_p\\) √® accettato con probabilit√† \\(\\alpha\\). Se non viene accettato, il valore corrente \\(\\theta_t\\) √® mantenuto per il prossimo passo.\n\n\nQuesto processo permette di esplorare lo spazio dei parametri \\(\\theta\\) generando una catena di Markov che, nel tempo, converge verso la distribuzione a posteriori \\(p(\\theta \\mid y)\\). Utilizzando questa catena, possiamo stimare empiricamente le propriet√† della distribuzione a posteriori.\nLa procedura continua con l‚Äôiterazione dei passi dal 2 al 5, permettendo alla catena di campioni di convergere alla distribuzione target. Inizialmente, i campioni potrebbero non essere rappresentativi, ma dopo un sufficiente numero di iterazioni (il cosiddetto ‚Äúburn-in‚Äù), la distribuzione dei punti accettati dovrebbe avvicinarsi a quella che si intende esplorare.\nL‚Äôefficienza di questo algoritmo deriva dalla sua abilit√† nel mantenere un equilibrio tra l‚Äôesplorazione di nuove possibilit√† e l‚Äôutilizzo di quelle gi√† note. Questo viene realizzato attraverso l‚Äôadozione di un meccanismo che accetta i punti suggeriti in modo probabilistico, facilitando cos√¨ la raccolta di un campione che riflette accuratamente la distribuzione di probabilit√† complessa sotto indagine.\nPer una visualizzazione del comportamento dell‚Äôalgoritmo di Metropolis nell‚Äôesplorare lo spazio dei parametri, si pu√≤ consultare questo post. La distinzione tra i diversi metodi MCMC si basa principalmente sul tipo di distribuzione proposta e sul criterio di accettazione dei punti nel campionamento.\n\n\n41.5.3 Implementazione dell‚ÄôAlgoritmo di Metropolis\nIniziamo col definire la distribuzione a priori. In questo esempio, la distribuzione a priori √® una distribuzione Beta(4, 6).\n\ndef prior(p):\n    alpha = 4\n    beta = 6\n    return stats.beta.pdf(p, alpha, beta)\n\nDefiniamo la verosimiglianza. Il problema presente richiede una verosimiglianza binomiale.\n\ndef likelihood(p):\n    y = 14\n    n = 100\n    return stats.binom.pmf(y, n, p)\n\nLa distribuzione a posteriori non normalizzata √® il prodotto della distribuzione a priori e della verosimiglianza. Si noti che, per il motivo spiegato prima, non √® necessario normalizzare la distribuzione a posteriori.\n\ndef posterior(p):\n    return likelihood(p) * prior(p)\n\nNell‚Äôimplementazione di un algoritmo di Metropolis in ambito bayesiano, vi sono diversi aspetti da considerare attentamente. Ecco alcuni punti cruciali:\n\nSimmetria della Distribuzione Proposta: √à fondamentale che la distribuzione proposta sia simmetrica. Questa √® una condizione necessaria per il funzionamento dell‚Äôalgoritmo di Metropolis, ma non per quello di Metropolis-Hastings.\nValore Iniziale: Il valore iniziale scelto dovrebbe essere plausibile in base alla distribuzione a priori, in modo da facilitare la convergenza dell‚Äôalgoritmo.\nProbabilit√† Zero: Nel caso in cui la verosimiglianza o il prior assumano un valore di zero, il rapporto tra le densit√† di probabilit√† (pdfratio) all‚Äôinterno dell‚Äôalgoritmo di Metropolis risulter√† indefinito. Pertanto, √® importante garantire che il valore x_star, generato dalla distribuzione proposta, cada sempre entro i limiti del supporto sia del prior che della verosimiglianza.\n\nDi seguito √® presentato il codice dell‚Äôalgoritmo di Metropolis.\n\n# Definizione della funzione dell'algoritmo di Metropolis.\n# nsamp: Numero di campioni da generare.\n# xinit: Valore iniziale da cui iniziare il sampling.\ndef metropolis(nsamp, xinit):\n    # Inizializza un array vuoto per conservare i campioni generati.\n    samples = np.empty(nsamp)\n\n    # Imposta il primo valore (valore iniziale) da cui partire per la generazione dei campioni.\n    x_prev = xinit\n\n    # Inizia un ciclo che si ripeter√† per il numero di volte specificato da nsamp (numero di campioni da generare).\n    for i in range(nsamp):\n        # Genera un nuovo punto (x_star) usando una distribuzione normale (gaussiana).\n        # Questo nuovo punto √® generato in modo da essere \"vicino\" al punto precedente (x_prev),\n        # con una deviazione standard di 0.1. Questo significa che la maggior parte dei punti\n        # sar√† entro 0.1 unit√† da x_prev, ma alcuni potrebbero essere pi√π lontani.\n        x_star = np.random.normal(x_prev, 0.1)\n\n        # Verifica che il nuovo punto (x_star) sia un valore plausibile nel contesto del problema.\n        # Qui, l'assunzione √® che x_star debba essere tra 0 e 1. Se non lo √®, il punto √® rifiutato.\n        if 0 &lt;= x_star &lt;= 1:\n            # Calcola il valore della funzione di densit√† di probabilit√† posterior per il nuovo punto e il punto precedente.\n            # La funzione posterior √® definita altrove e rappresenta il prodotto del prior e della likelihood.\n            p_star = posterior(x_star)\n            p_prev = posterior(x_prev)\n\n            # Calcola il rapporto tra le densit√† posterior del nuovo punto e del punto precedente.\n            # Questo rapporto determina la probabilit√† di accettare il nuovo punto.\n            # Se p_prev √® 0, per evitare la divisione per zero, il rapporto √® impostato a 1.\n            pdfratio = p_star / p_prev if p_prev &gt; 0 else 1\n\n            # Genera un numero casuale tra 0 e 1.\n            random_chance = np.random.uniform()\n\n            # Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n            # Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n            # Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\n            acceptance_probability = min(1, pdfratio)\n\n            # Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n            # Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n            # mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\n            if random_chance &lt; acceptance_probability:\n                samples[i] = x_star  # Accetta il nuovo punto.\n                x_prev = (\n                    x_star  # Aggiorna il punto precedente con il nuovo punto accettato.\n                )\n            else:\n                samples[i] = (\n                    x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\n                )\n        else:\n            samples[i] = (\n                x_prev  # Se x_star non √® nel supporto, conserva il punto precedente.\n            )\n\n    # Dopo aver generato il numero desiderato di campioni, ritorna l'array dei campioni.\n    return samples\n\nL‚Äôidea fondamentale dietro la fase dell‚Äôalgoritmo di Metropolis successiva al calcolo di p_star e p_prev √® decidere se ‚Äúmuoversi‚Äù verso un nuovo punto basandosi su quanto √® probabile (o ‚Äúbuono‚Äù) quel punto rispetto al punto attuale, in termini della densit√† posteriore. Qui, la ‚Äúprobabilit√†‚Äù di un punto √® data dalla sua densit√† posteriore, che √® un modo per misurare quanto bene un certo valore del parametro si adatta ai dati osservati, dato un modello.\nEcco come funziona:\n\nGenerazione di un numero casuale.\nConfronto tra i punti: Si confronta il ‚Äúvalore‚Äù del nuovo punto (x_star) con quello del punto precedente (x_prev). Questo ‚Äúvalore‚Äù √® dato dalla densit√† posteriore: pi√π alto √®, meglio √®.\nDecisione:\n\nSe il nuovo punto √® migliore del precedente (ovvero, ha una densit√† posteriore maggiore o uguale), lo accettiamo sempre.\nSe il nuovo punto √® peggiore del precedente (ha una densit√† posteriore minore), non lo rifiutiamo subito. Invece, gli diamo una chance di essere scelto, ma questa chance √® pi√π piccola quanto pi√π il nuovo punto √® ‚Äúpeggiore‚Äù.\n\n\nIn termini di codice, questa logica si traduce cos√¨:\n# Genera un numero casuale tra 0 e 1.\nrandom_chance = np.random.uniform()\n\n# Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n# Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n# Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\nacceptance_probability = min(1, pdfratio)\n\n# Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n# Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n# mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\nif random_chance &lt; acceptance_probability:\n    samples[i] = x_star  # Accetta il nuovo punto.\n    x_prev = x_star      # Aggiorna il punto precedente con il nuovo punto accettato.\nelse:\n    samples[i] = x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\nIn sintesi, questo meccanismo consente all‚Äôalgoritmo di esplorare lo spazio dei parametri in modo efficiente, accettando sempre miglioramenti e, occasionalmente, facendo passi in direzioni non ottimali per evitare di rimanere intrappolati in ‚Äúminimi locali‚Äù, ovvero in soluzioni che sembrano buone rispetto a quelle vicine ma non sono le migliori globalmente.\nSi osservi un punto importante: nel calcolo di pdfratio, il rapporto tra la densit√† a posteriori del parametro proposto x_star e quella del parametro corrente x_prev, la costante di normalizzazione si annulla grazie alla regola di Bayes. Questo lascia nel rapporto solamente le componenti relative alla verosimiglianza e alla distribuzione a priori, che sono entrambe facilmente calcolabili. Matematicamente, questo si esprime come:\n\\[\n\\begin{equation}\n\\text{pdfratio} = \\frac{p(\\theta^* \\mid y)}{p(\\theta^{\\text{prev}} \\mid y)} = \\frac{\\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y)}}{\\frac{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}{p(y)}}\n= \\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}\n\\end{equation}\n\\] (eq-ratio-metropolis)\nEseguiamo dunque il campionamento usando l‚Äôalgoritmo che abbiamo definito.\n\nn_samples = 100_000\nsamps = metropolis(n_samples, 0.5)\n\nIn somma, l‚Äôalgoritmo Metropolis accetta come input il numero nsamp di passi da simulare e il punto di partenza. Come output, l‚Äôalgoritmo restituisce una catena di valori del parametro, specificamente la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{\\text{nsamp}}\\). Uno degli aspetti cruciali per la riuscita dell‚Äôalgoritmo √® il raggiungimento della stazionariet√† da parte della catena. In genere, i primi 1000-5000 valori vengono scartati in quanto rappresentano il periodo di ‚Äúburn-in‚Äù della catena. Dopo un determinato numero di passi \\(k\\), la catena converge e i valori diventano campioni effettivi dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nIl modello descritto √® stato inizialmente proposto da Metropolis et al.¬†nel 1953 (Metropolis et al. 1953). Hastings nel 1970 introdusse un‚Äôestensione nota come algoritmo Metropolis-Hastings (Hastings 1970). Altre varianti includono il campionatore di Gibbs, introdotto da Geman e Geman nel 1984 (Geman e Geman 1984), l‚ÄôHamiltonian Monte Carlo (Duane et al. 1987), e il No-U-Turn Sampler (NUTS) utilizzato in pacchetti come PyMC e Stan (Hoffman, Gelman, et al. 2014). Per un‚Äôanalisi pi√π dettagliata e intuitiva dell‚Äôalgoritmo Metropolis, si rimanda a Kruschke (2014).\nUn elemento chiave da considerare nell‚Äôuso dell‚Äôalgoritmo Metropolis √® il tasso di accettazione, che √® il rapporto tra il numero di valori del parametro proposti e il numero di quei valori che vengono effettivamente accettati. Un limite di questo algoritmo √® la sua inefficienza relativa: rispetto alle sue varianti pi√π moderne, l‚Äôalgoritmo Metropolis tende ad essere meno efficiente.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#aspetti-computazionali",
    "href": "chapters/chapter_4/10_metropolis.html#aspetti-computazionali",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.6 Aspetti computazionali",
    "text": "41.6 Aspetti computazionali\n\n41.6.1 Warm-up/Burn-in\nUna catena di Markov ha bisogno di alcune iterazioni per raggiungere la distribuzione stazionaria. Queste iterazioni sono comunemente chiamate iterazioni di warm-up o burn-in (a seconda dell‚Äôalgoritmo e del software utilizzato) e vengono di solito scartate. In molti programmi software, la prima met√† delle iterazioni viene considerata come iterazioni di warm-up, quindi, nel caso presente, anche se abbiamo ottenuto 100000 iterazioni, ne utilizzeremo solo 50000.\n\n\n41.6.2 Sintesi della distribuzione a posteriori\nL‚Äôarray samps contiene 100000 valori di una catena di Markov. Escludiamo i primi 50000 valori considerati come burn-in e consideriamo i restanti 50000 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nMediante i valori della catena cos√¨ ottenuta √® facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, possiamo trovare la stima della media a posteriori.\n\nburnin = int(n_samples * 0.5)\nburnin\n\n50000\n\n\n\nnp.mean(samps[burnin:])\n\n0.16408968344081415\n\n\nOppure possiamo stimare la deviazione standard della distribuzione a posteriori.\n\nnp.std(samps[burnin:])\n\n0.03513787973422409\n\n\nVisualizziamo un trace plot dei valori della catena di Markov dopo il periodo di burn-in.\n\nplt.plot(samps[burnin:])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nIl trace plot indica che la catena inizia con un valore casuale per poi spostarsi rapidamente nell‚Äôarea intorno a 0.16, che √® l‚Äôarea con alta densit√† a posteriori. Successivamente, oscilla intorno a quel valore per le iterazioni successive.\n\nplt.plot(samps[:500])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nL‚Äôistogramma mostrato di seguito, sul quale √® stata sovrapposta la distribuzione a posteriori derivata analiticamente ‚Äì specificamente una \\(\\text{Beta}(25, 17)\\) ‚Äì dimostra che la catena converge effettivamente alla distribuzione a posteriori desiderata.\n\nplt.hist(samps[burnin:], bins=30, alpha=0.4, label=\"MCMC distribution\", density=True)\n# plot the true function\nx = np.linspace(0, 1, 1000)\nplt.plot(x, stats.beta.pdf(x, 18, 92), \"C0\", label=\"True distribution\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n√à possibile usare la funzione summary del pacchetto AriviZ per calolare l‚Äôintervallo di credibilit√†, ovvero l‚Äôintervallo che contiene la proporzione indicata dei valori estratti a caso dalla distribuzione a posteriori.\n\naz.summary(samps[burnin:], kind=\"stats\", hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nx\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\n\nUn KDE plot corrispondente all‚Äôistogramma precedente si pu√≤ generare usando az.plot_posterior(). La curva rappresenta l‚Äôintera distribuzione a posteriori e viene calcolata utilizzando la stima della densit√† del kernel (KDE) che serve a ‚Äúlisciare‚Äù l‚Äôistogramma.\n\naz.plot_posterior(samps[burnin:])\nplt.show()\n\n\n\n\n\n\n\n\nL‚ÄôHDI √® una scelta comune nelle statistiche bayesiane e valori arrotondati come 50% o 95% sono molto popolari. Ma ArviZ utilizza il 94% come valore predefinito. La ragione di questa scelta √® che il 94% √® vicino al valore ampiamente utilizzato del 95%, ma √® anche diverso da questo, cos√¨ da servire da ‚Äúamichevole promemoria‚Äù che non c‚Äô√® niente di speciale nella soglia del 5%. Idealmente sarebbe opportuno scegliere un valore che si adatti alle specifiche esigenze dell‚Äôanalisi statistica che si sta svolgendo, o almeno riconoscere che si sta usando un valore arbitrario.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/chapter_4/10_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.7 Diagnostiche della soluzione MCMC",
    "text": "41.7 Diagnostiche della soluzione MCMC\n\n41.7.1 Catene multiple\nPoich√© ciascuno stato in una catena di Markov dipende dagli stati precedenti, il valore o i valori iniziali possono influenzare i valori campionati. Una soluzione per verificare la sensibilit√† rispetto ai valori iniziali √® utilizzare pi√π catene, ognuna con diversi valori iniziali. Se pi√π catene campionano la stessa distribuzione target, queste dovrebbero mescolarsi bene, ovvero intersecarsi l‚Äôuna con l‚Äôaltra in un trace plot.\n\n\n41.7.2 Stazionariet√†\nUn punto importante da verificare √® se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta ‚Äúmixing‚Äù.\n\n\n41.7.3 Autocorrelazione\nOgni passo nell‚Äôalgoritmo MCMC √® chiamato iterazione. I valori campionati sono dipendenti, il che significa che il valore all‚Äôiterazione \\(m\\) dipende dal valore all‚Äôiterazione \\(m-1\\). Questa √® una differenza importante rispetto alle funzioni che generano campioni casuali indipendenti, come beta(25, 17).rvs(). I valori campionati formano una catena di Markov, il che significa che ciascun valore campionato √® correlato con il valore precedente (ad esempio, se \\(\\theta(m)\\) √® grande, \\(\\theta(m+1)\\) sar√† anch‚Äôesso grande).\nInformazioni sul ‚Äúmixing‚Äù della catena di Markov sono fornite dall‚Äôautocorrelazione. L‚Äôautocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantit√† \\(k\\) (dove \\(k\\) √® l‚Äôentit√† del ritardo) per verificare quanto si correli al variare di \\(k\\). L‚Äôautocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l‚Äôautocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due ‚Äúpassi‚Äù (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e cos√¨ via.\nL‚Äôautocorrelazione di ordine \\(k\\) √® data da \\(\\rho_k\\) e pu√≤ essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\] (eq-autocor)\nPer fare un esempio pratico, simuliamo dei dati autocorrelati.\n\nx = pd.array([22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51])\nprint(x)\n\n&lt;IntegerArray&gt;\n[22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51]\nLength: 15, dtype: Int64\n\n\nL‚Äôautocorrelazione di ordine 1 √® semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza.\n\nsm.tsa.acf(x)\n\narray([ 1.        ,  0.83174224,  0.65632458,  0.49105012,  0.27863962,\n        0.03102625, -0.16527446, -0.30369928, -0.40095465, -0.45823389,\n       -0.45047733, -0.36933174])\n\n\nNell‚Äôesempio, il vettore x √® una sequenza temporale di 15 elementi. Il vettore \\(x'\\) include gli elementi con gli indici da 0 a 13 nella sequenza originaria, mentre il vettore \\(x''\\) include gli elementi 1:14. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((0, 1)\\), \\((1, 2), (2, 3), \\dots (13, 14)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori \\(x'\\) e \\(x''\\) corrisponde all‚Äôautocorrelazione di ordine 1 della serie temporale.\nNell‚Äôoutput precedente\n\n0.83174224 √® l‚Äôautocorrelazione di ordine 1 (lag = 1),\n0.65632458 √® l‚Äôautocorrelazione di ordine 2 (lag = 2),\n0.49105012 √® l‚Äôautocorrelazione di ordine 3 (lag = 3),\necc.\n\n√à possibile specificare il numero di ritardi (lag) da utilizzare con l‚Äôargomento nlags:\n\nsm.tsa.acf(x, nlags=4)\n\narray([1.        , 0.83174224, 0.65632458, 0.49105012, 0.27863962])\n\n\nIn Python possiamo creare un grafico della funzione di autocorrelazione (correlogramma) per una serie temporale usando la funzione tsaplots.plot_acf() dalla libreria statsmodels.\n\ntsaplots.plot_acf(x, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nPer i dati dell‚Äôesempio in discussione otteniamo la situazione seguente.\n\ntsaplots.plot_acf(samps[burnin:], lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nIl correlogramma √® uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall‚Äôautocorrelazione \\(\\rho_k\\) di una catena di Markov in funzione del ritardo \\(k\\) con cui l‚Äôautocorrelazione √® calcolata: nel grafico ogni barretta verticale riporta il valore dell‚Äôautocorrelazione (sull‚Äôasse delle ordinate) in funzione del ritardo (sull‚Äôasse delle ascisse).\nIn situazioni ottimali l‚Äôautocorrelazione diminuisce rapidamente ed √® effettivamente pari a 0 per piccoli lag. Ci√≤ indica che i valori della catena di Markov che si trovano a pi√π di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del ‚Äúmixing‚Äù della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l‚Äôautocorrelazione √® quella di assottigliare l‚Äôoutput immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning.\nNel seguente correlogramma, analizziamo la medesima catena di Markov. Tuttavia, in questa occasione applichiamo un ‚Äúthinning‚Äù (sottocampionamento) con un fattore di 5.\n\nthin = 5\nsampsthin = samps[burnin::thin]\ntsaplots.plot_acf(sampsthin, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nSi pu√≤ notare come l‚Äôautocorrelazione diminuisce molto pi√π rapidamente.\n\n41.7.3.1 Tasso di accettazione\nQuando si utilizza l‚Äôalgoritmo Metropolis, √® importante monitorare il tasso di accettazione e assicurarsi che sia nell‚Äôintervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegher√† molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D‚Äôaltra parte, se il tasso di accettazione √® molto basso, la catena rimarr√† bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l‚Äôalgoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale √® compreso tra il 40% e il 50%.\n\n\n41.7.3.2 Test di convergenza\nPer valutare la convergenza di una catena di Markov Monte Carlo (MCMC), esistono diversi metodi, tra cui approcci grafici e test statistici. Ecco una spiegazione pi√π chiara e dettagliata:\n\n\n\n41.7.4 Approcci Grafici: Tracce delle Serie Temporali (Trace Plots)\nLe tracce delle serie temporali, o trace plots, sono grafici che mostrano l‚Äôevoluzione dei valori campionati rispetto al numero di iterazioni. Questi grafici sono utili per valutare visivamente se la catena ha raggiunto la convergenza. Segni che indicano una potenziale convergenza includono:\n\nAssenza di Tendenze: Non ci sono trend ascendenti o discendenti nel corso delle iterazioni.\nCostanza dell‚ÄôAmpiezza: La variabilit√† dei valori campionati rimane costante nel tempo, senza significative fluttuazioni.\nMancanza di Periodicit√†: Non si osservano cicli o ripetizioni regolari che potrebbero indicare la presenza di correlazioni residue.\n\n\n\n41.7.5 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n41.7.5.1 Test di Geweke\nIl test di Geweke √® una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l‚Äôultimo 50% dei campioni, dopo aver escluso un iniziale periodo di ‚Äúburn-in‚Äù (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base √® che, se la catena √® in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n\n41.7.5.2 Geweke Z-score\nUna variante del test di Geweke √® lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in pi√π esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. √à importante notare che nessun test pu√≤ garantire con certezza la convergenza, ma l‚Äôutilizzo congiunto di approcci grafici e test statistici pu√≤ offrire una buona indicazione dello stato della catena.\n\n\n\n41.7.6 Effective sample size (ESS)\nQuando le iterazioni sono dipendenti, ogni iterazione contiene informazioni sovrapposte con le iterazioni precedenti. In altre parole, quando si ottengono 500 campioni dipendenti dalla distribuzione a posteriori, questi contengono solo informazioni equivalenti a &lt; 500 campioni indipendenti. L‚ÄôESS (Effective Sample Size) quantifica la quantit√† effettiva di informazioni, quindi una catena con ESS = n conterr√† approssimativamente la stessa quantit√† di informazioni di n campioni indipendenti. In generale, vogliamo che l‚ÄôESS sia almeno 400 per un‚Äôutilizzazione generale nel riassumere la distribuzione a posteriori.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#caso-normale-normale",
    "href": "chapters/chapter_4/10_metropolis.html#caso-normale-normale",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.8 Caso Normale-Normale",
    "text": "41.8 Caso Normale-Normale\nConsideriamo ora il caso Normale-Normale di cui √® possibile trovare una soluzione analitica. Supponiamo, come prior, una \\(\\mathcal{N}(30, 5\\).\n\ndef prior(mu):\n    return stats.norm.pdf(mu, 30, 5)\n\nPer la verosimiglianza del parametro \\(\\mu\\), supponiamo \\(\\sigma\\) nota e uguale alla deviazione standard del campione.\n\ndef likelihood(mu, data):\n    std_data = np.std(data)  # Calcola la deviazione standard dei dati\n    return np.prod(stats.norm.pdf(data, mu, std_data))\n\nDefiniamo il posterior non normalizzato:\n\ndef posterior(mu, data):\n    return likelihood(mu, data) * prior(mu)\n\nModifichiamo ora l‚Äôalgoritmo di Metropolis descritto sopra per adattarlo al caso presente.\n\n# Algoritmo di Metropolis per il caso normale-normale\ndef metropolis_for_normal(nsamp, xinit, data):\n    samples = np.empty(nsamp)\n    x_prev = xinit\n\n    for i in range(nsamp):\n        x_star = np.random.normal(x_prev, 0.5)  # Genera un nuovo punto dalla proposta\n\n        # Calcola il rapporto di accettazione e accetta il nuovo punto con una certa probabilit√†\n        if posterior(x_star, data) / posterior(x_prev, data) &gt; np.random.uniform():\n            x_prev = x_star\n\n        samples[i] = x_prev\n\n    return samples\n\nVediamo cosa fa la presente versione dell‚Äôalgoritmo di Metropolis passo dopo passo:\n\nCiclo sui Campioni: for i in range(nsamp): inizia un ciclo che si ripeter√† nsamp volte, dove nsamp √® il numero totale di campioni che vogliamo generare. Ogni iterazione di questo ciclo produrr√† un campione dalla distribuzione di interesse.\nGenerazione di un Nuovo Punto: x_star = np.random.normal(x_prev, 0.5) genera un nuovo punto (x_star) come proposta per il prossimo passo del campionamento. Questo √® fatto campionando da una distribuzione normale con media uguale all‚Äôultimo punto accettato (x_prev) e una deviazione standard di 0.5. Questa distribuzione √® detta distribuzione di proposta e serve a esplorare lo spazio dei parametri.\nCalcolo del Rapporto di Accettazione:\n\nIl rapporto di accettazione √® calcolato come posterior(x_star, data) / posterior(x_prev, data), che √® il rapporto tra la probabilit√† del posterior del nuovo punto proposto (x_star) e la probabilit√† del posterior dell‚Äôultimo punto accettato (x_prev).\nQuesto rapporto indica quanto sia preferibile il nuovo punto rispetto al precedente, basandosi sulla funzione posterior, che calcola la probabilit√† a posteriori del modello dato il parametro e i dati osservati.\n\nDecisione di Accettazione del Nuovo Punto:\n\nLa decisione se accettare o meno il nuovo punto (x_star) si basa su un confronto del rapporto di accettazione con un numero casuale uniformemente distribuito tra 0 e 1 (np.random.uniform()).\nSe il rapporto di accettazione √® maggiore di questo numero casuale, il nuovo punto √® accettato come il prossimo punto nella catena (x_prev = x_star). Ci√≤ significa che il nuovo punto ha una probabilit√† a posteriori pi√π alta rispetto al punto precedente, o √® stato ‚Äúfortunato‚Äù nel processo di selezione casuale, consentendo all‚Äôalgoritmo di esplorare lo spazio dei parametri anche in zone di minore probabilit√†.\nSe il nuovo punto non viene accettato, la catena rimane nel punto precedente (x_prev), e questo punto viene nuovamente aggiunto all‚Äôarray dei campioni.\n\nSalvataggio del Campione: samples[i] = x_prev salva il punto corrente (che pu√≤ essere il nuovo punto accettato o il punto precedente se il nuovo punto √® stato rifiutato) nell‚Äôarray samples. Questo processo si ripete fino a quando non si raggiunge il numero desiderato di campioni.\n\nCome dati, usiamo il campione di 30 valori BDI-II ottenuti dai soggetti clinici esaminati da {cite}zetsche_2019future.\n\ny = np.array([\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n    41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n])\n\nProcediamo con l‚Äôesecuzione dell‚Äôalgoritmo di Metropolis.\n\nsamples = metropolis_for_normal(100_000, np.mean(y), y)\nsamples.shape\n\n(100000,)\n\n\n\n41.8.1 Calcolo dei Parametri del Posterior Analitico\nNel caso normale-normale, possiamo derivare analiticamente la distribuzione posteriore quando sia il prior che la likelihood sono distribuzioni normali. La bellezza di questo approccio sta nella forma chiusa del posterior, che √® anch‚Äôesso una distribuzione normale con parametri specifici facilmente calcolabili. Ecco come si fa:\n\nMedia Posteriore (\\(\\mu_{post}\\)): La media del posterior √® un peso tra la media del campione e la media del prior, dove i pesi sono determinati dalle varianze del prior e dei dati.\n\\[\n\\mu_{post} = \\frac{\\frac{\\mu_{prior}}{\\sigma_{prior}^2} + \\frac{\\sum y_i}{\\sigma_{data}^2}}{\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}}\n\\]\nVarianza Posteriore (\\(\\sigma_{post}^2\\)): La varianza del posterior √® determinata dalle varianze del prior e dei dati.\n\\[\n\\sigma_{post}^2 = \\left(\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}\\right)^{-1}\n\\]\n\nDove: - \\(\\mu_{prior}\\) √® la media del prior (in questo caso, 30), - \\(\\sigma_{prior}^2\\) √® la varianza del prior (\\(5^2\\) in questo caso), - \\(\\sigma_{data}^2\\) √® la varianza dei dati (calcolata dai dati), - \\(n\\) √® il numero di osservazioni, - \\(\\sum y_i\\) √® la somma delle osservazioni.\n\n\n41.8.2 Codice per il Grafico\nPer produrre il grafico con l‚Äôistogramma dei campioni dal posterior (usando l‚Äôalgoritmo di Metropolis) e la curva della distribuzione posteriore analitica, usiamo i parametri calcolati:\n\n# Parametri del prior\nmu_prior = 30\nstd_prior = 5\nvar_prior = std_prior ** 2\n\n# Dati osservati\nn = len(y)\nsum_y = np.sum(y)\nvar_data = np.var(y, ddof=1)  # ddof=1 for sample variance\n\n# Calcolo dei parametri posterior\nmu_post = (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post = 1 / (1 / var_prior + n / var_data)\nstd_post = np.sqrt(var_post)\n\n# Generazione dei punti x per il grafico\nx = np.linspace(mu_post - 4 * std_post, mu_post + 4 * std_post, 1000)\n\n# Istogramma dei campioni dal posterior\nplt.hist(samples[burnin:], bins=30, alpha=0.4, density=True, label=\"MCMC Samples Distribution\")\n\n# Curva della distribuzione posteriore analitica\nplt.plot(x, stats.norm.pdf(x, mu_post, std_post), \"C1\", label=\"Analytical Posterior Distribution\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice mostra come integrare l‚Äôanalisi MCMC con l‚Äôapproccio analitico per il caso normale-normale, offrendo sia una visualizzazione dei risultati del sampling che la conferma attraverso la soluzione analitica.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/10_metropolis.html#commenti-e-considerazioni-finali",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "41.9 Commenti e considerazioni finali",
    "text": "41.9 Commenti e considerazioni finali\nIn generale, la distribuzione a posteriori dei parametri di un modello statistico non pu√≤ essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilit√† che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre pi√π semplice l‚Äôuso dei metodi MCMC, insieme all‚Äôincremento della potenza di calcolo dei computer, ha contribuito a rendere sempre pi√π popolare il metodo dell‚Äôinferenza bayesiana che, in questo modo, pu√≤ essere estesa a problemi di qualunque grado di complessit√†.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/10_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "41¬† Monte Carlo a Catena di Markov",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 15 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nsys        : 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:35:20) [Clang 16.0.6 ]\nmatplotlib : 3.8.4\narviz      : 0.18.0\nstatsmodels: 0.14.2\nscipy      : 1.13.1\nnumpy      : 1.26.4\nseaborn    : 0.13.2\npymc       : 5.15.1\npandas     : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, e Duncan Roweth. 1987. ¬´Hybrid monte carlo¬ª. Physics letters B 195 (2): 216‚Äì22.\n\n\nGeman, Stuart, e Donald Geman. 1984. ¬´Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images¬ª. IEEE Transactions on pattern analysis and machine intelligence 6: 721‚Äì41.\n\n\nHastings, W. Keith. 1970. ¬´Monte Carlo sampling methods using Markov chains and their applications¬ª. Biometrika 57 (1): 97‚Äì109.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ¬´The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.¬ª Journal of Machine Learning Research 15 (1): 1593‚Äì623.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, e Edward Teller. 1953. ¬´Equation of state calculations by fast computing machines¬ª. The Journal of Chemical Physics 21 (6): 1087‚Äì92.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html",
    "title": "42¬† Linguaggio Stan",
    "section": "",
    "text": "42.1 Introduzione\nNel presente capitolo, presenteremo un linguaggio di programmazione probabilistica denominato Stan. Stan consente di estrarre campioni da distribuzioni di probabilit√† mediante la costruzione di una catena di Markov, la cui distribuzione di equilibrio (o stazionaria) coincide con la distribuzione desiderata. Il nome del linguaggio deriva da uno dei pionieri del metodo Monte Carlo, Stanislaw Ulam. Un‚Äôintroduzione dettagliata al linguaggio Stan √® fornita nell‚ÄôAppendice R. In questo capitolo, utilizzeremo Stan per fare inferenza su una proporzione.\nIl linguaggio di programmazione probabilistica Stan √® compatibile con diverse piattaforme e offre varie interfacce (R, Python, Julia). In questo corso, useremo CmdStanPy, un‚Äôinterfaccia per Stan pensata per gli utenti di Python. CmdStanPy √® un pacchetto puramente in Python3 che √® un wrapper di CmdStan, l‚Äôinterfaccia a riga di comando per Stan scritta in C++. Pertanto, oltre a Python3, CmdStanPy richiede un toolchain C++ per compilare ed eseguire i modelli Stan.\nLa procedura per installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge √® descritta nel capitolo Appendice E.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#inferenza-bayesiana-e-metodi-mcmc",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#inferenza-bayesiana-e-metodi-mcmc",
    "title": "42¬† Linguaggio Stan",
    "section": "42.2 Inferenza Bayesiana e Metodi MCMC",
    "text": "42.2 Inferenza Bayesiana e Metodi MCMC\nL‚Äôinferenza bayesiana, impiegata per la stima dei parametri, la previsione e la valutazione della probabilit√† di eventi, si basa sulle aspettative a posteriori. Queste aspettative si configurano come integrali multidimensionali nello spazio dei parametri. Stan, un software all‚Äôavanguardia per l‚Äôanalisi statistica, si avvale del metodo Monte Carlo per risolvere questi integrali complessi. I metodi Monte Carlo sfruttano il campionamento casuale per affrontare integrali ad alta dimensionalit√†.\nTuttavia, per la maggior parte dei problemi bayesiani, non √® possibile utilizzare i metodi Monte Carlo standard, poich√© non √® fattibile generare campioni indipendenti dalla densit√† a posteriori di interesse, fatta eccezione per modelli estremamente semplici con prior coniugati. Di conseguenza, √® necessario ricorrere ai metodi Monte Carlo a Catena di Markov (MCMC), che producono campioni correlati tra loro. Stan implementa il Monte Carlo Hamiltoniano (HMC), il metodo MCMC pi√π efficiente e scalabile per le densit√† target. Altri metodi, come il Metropolis-Hastings e il campionamento di Gibbs, risultano pi√π semplici ma meno efficienti dell‚ÄôHMC.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "title": "42¬† Linguaggio Stan",
    "section": "42.3 Stan e la Programmazione Probabilistica",
    "text": "42.3 Stan e la Programmazione Probabilistica\nStan si configura come un linguaggio di programmazione probabilistica (PPL) concepito per definire modelli statistici complessi e effettuare inferenze su di essi. Un PPL consente di esprimere modelli probabilistici in modo conciso e di utilizzare algoritmi avanzati per l‚Äôinferenza. Ci√≤ risulta particolarmente utile nell‚Äôinferenza bayesiana, dove si aggiornano le distribuzioni a priori con dati osservati per ottenere distribuzioni a posteriori.\n\n42.3.1 Struttura di un Programma Stan\nUn programma Stan richiede la specificazione di variabili e parametri, definendo le distribuzioni a priori dei parametri del modello statistico e la funzione di verosimiglianza. In sostanza, un programma Stan descrive l‚Äôinterazione tra dati e parametri e le distribuzioni probabilistiche che li governano. Questo consente di effettuare inferenze sulle distribuzioni a posteriori dei parametri del modello, dedotte dai dati osservati e dalle distribuzioni a priori.\n\n\n42.3.2 Esecuzione di un Programma Stan\nUn programma Stan utilizza metodi di inferenza avanzati:\n\nCampionamento MCMC: Stan impiega metodi come il Monte Carlo a Catena di Markov per generare campioni dalle distribuzioni a posteriori.\nInferenza Variazionale: Un metodo approssimativo che fornisce stime delle distribuzioni a posteriori.\nApprossimazione di Laplace: Un ulteriore metodo approssimativo per l‚Äôinferenza.\n\nStan √® accessibile attraverso vari linguaggi di programmazione e strumenti di analisi open-source, tra cui Python, R e Julia, ed √® compatibile con gli strumenti di analisi bayesiana integrati in questi linguaggi. √à inoltre disponibile in ambienti come Mathematica, Stata e MATLAB, sebbene queste interfacce siano meno complete.\nStan genera dati attraverso procedure pseudo-casuali, applicabili sia per simulazioni in avanti che per risolvere il problema inverso.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#simulazione-in-avanti",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#simulazione-in-avanti",
    "title": "42¬† Linguaggio Stan",
    "section": "42.4 Simulazione in Avanti",
    "text": "42.4 Simulazione in Avanti\nLa simulazione in avanti consiste nella generazione di dati simulati a partire da un insieme di parametri noti di un modello probabilistico. In altri termini, date determinate assunzioni sui parametri di un modello, si utilizza la simulazione in avanti per prevedere i possibili risultati.\nAd esempio, consideriamo uno studio clinico con \\(N\\) soggetti e una probabilit√† \\(\\theta\\) di esito positivo per ciascun soggetto. Conoscendo il valore di \\(\\theta\\) e il numero di soggetti \\(N\\), possiamo impiegare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci consente di generare dati che riflettono le nostre assunzioni sui parametri del modello.\nIn notazione statistica, questo si esprime come:\n\\[\nY \\sim \\text{Binomiale}(N, \\theta)\n\\]\ndove \\(Y\\) rappresenta il numero di esiti positivi su \\(N\\) pazienti, con probabilit√† \\(\\theta\\) di esito positivo per ciascun paziente.\n\n42.4.0.1 Esempio di Simulazione in Avanti\nSupponiamo di avere \\(N = 100\\) soggetti in uno studio clinico e un tasso di successo \\(\\theta = 0.3\\). Possiamo simulare un risultato \\(Y\\) generando casualmente il numero di soggetti con esito positivo. Utilizzando una distribuzione binomiale, possiamo calcolare la probabilit√† di ottenere esattamente \\(y\\) esiti positivi su \\(N\\) tentativi:\n\\[\np(Y = y \\mid N, \\theta) = \\binom{N}{y} \\cdot \\theta^y \\cdot (1 - \\theta)^{N - y}\n\\]\nQuesta espressione ci permette di calcolare la probabilit√† di ottenere un certo numero di successi, dato il numero di soggetti e la probabilit√† di successo.\n\n\n42.4.1 Un Primo Programma in Stan: Generazione di Dati Casuali\nSupponiamo di voler generare dei valori casuali \\(Y\\) da una distribuzione binomiale con parametri \\(N\\) e \\(\\theta\\). Ad esempio, possiamo impostare \\(\\theta = 0.3\\), per rappresentare una probabilit√† del 30% di un esito positivo (in statistica, il termine ‚Äòsuccesso‚Äô indica un esito positivo), e possiamo impostare \\(N = 100\\). Il seguente programma Stan pu√≤ essere utilizzato per generare valori di \\(Y\\) compresi tra 0 e 100.\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\n\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;\n  y = binomial_rng(N, theta);\n}\n\n\n42.4.2 Organizzazione di un Programma Stan\nLa prima cosa da notare √® che un programma Stan √® organizzato in blocchi. Qui abbiamo due blocchi: un blocco dei dati (data)contenente le dichiarazioni delle variabili che devono essere fornite come dati e un blocco delle quantit√† generate (generated quantities), che non solo dichiara variabili ma assegna loro un valore. In questo programma Stan, la variabile y viene assegnata come risultato di una singola estrazione da una distribuzione \\(\\textrm{binomiale}(N, \\theta)\\), che Stan fornisce attraverso la funzione binomial_rng.\n\n\n42.4.3 Tipi di Variabili in Stan\nLa seconda cosa da notare √® che tutte le variabili in un programma Stan sono dichiarate con tipi specifici. Stan utilizza la tipizzazione statica, il che significa che, a differenza di Python o R, il tipo di una variabile √® dichiarato nel programma prima del suo utilizzo, piuttosto che essere determinato al momento dell‚Äôesecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile non cambia mai.\nIl programma in esame dichiara tre variabili: N e y di tipo int (interi) e theta di tipo real (numeri reali). Nei computer, gli interi hanno limiti precisi e i numeri reali possono avere errori di calcolo. Stan utilizza numeri reali con precisione doppia (64 bit) secondo lo standard IEEE 754, tranne in alcune operazioni ottimizzate che possono perdere un po‚Äô di precisione.\n\n\n42.4.4 Vincoli sui Tipi\nUn tipo di variabile pu√≤ avere dei vincoli. Poich√© N √® un conteggio, deve essere maggiore o uguale a zero, cosa che indichiamo con il vincolo lower=0. Allo stesso modo, la variabile y, che rappresenta il numero di esiti positivi su N, deve essere compresa tra 0 e N (inclusi); questo √® indicato con il vincolo lower=0, upper=N. Infine, la variabile theta √® un numero reale e deve essere compresa tra 0 e 1, cosa che indichiamo con il vincolo lower=0, upper=1. Anche se tecnicamente i limiti per i numeri reali sono aperti, in pratica possiamo ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.\n\n\n42.4.5 Esecuzione del Programma Stan\nLa funzione cmdstan_model() crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan. In background, CmdStan traduce un programma Stan in C++ e creare un eseguibile compilato.\n\nmodel = CmdStanModel(stan_file='../../stan/binomial-rng.stan')\n\nDurante l‚Äôesecuzione, il programma Stan compilato richiede i valori di N e theta. Ad ogni iterazione, il programma campiona un valore di y utilizzando il suo generatore di numeri pseudocasuali integrato. I valori di N e theta devono essere forniti in un dizionario Python.\n\nN = 100\ntheta = 0.3\ndata = {\n    'N': N, \n    'theta': theta\n}\n\nInfine campioniamo dal modello utilizzando il metodo sample di CmdStanModel.\n\ntrace = model.sample(\n    data=data, \n    seed=123, \n    chains=1,\n    iter_sampling=30, \n    iter_warmup=1,\n    show_progress=False, \n    show_console=False\n)\n\n\n\n42.4.6 Costruzione del Modello\nIl costruttore di CmdStanModel viene utilizzato per creare un modello a partire da un programma Stan presente nel file specificato. Si consiglia vivamente di utilizzare un file separato per i programmi Stan. In pratica, il processo inizia con la traduzione del programma Stan in una classe C++ utilizzando un traduttore specifico. Successivamente, il programma C++ viene compilato.\n\n\n42.4.7 Interfaccia Python\nNell‚Äôinterfaccia Python, il metodo sample() accetta i seguenti argomenti:\n\ndata: i dati letti nel blocco dati del programma Stan,\nseed: generatore di numeri pseudocasuali per la riproducibilit√†,\nchains: il numero di simulazioni da eseguire (parallel_chains indica quante eseguire in parallelo),\niter_sampling: numero di estrazioni (cio√®, dimensione del campione) da restituire,\niter_warmup: numero di iterazioni di riscaldamento per tarare i parametri dell‚Äôalgoritmo di campionamento (non necessari qui, quindi impostato a 0),\nshow_progress: se True, stampa aggiornamenti di progresso,\nshow_console: apre un monitor di progresso GUI.\n\nIl risultato della chiamata a sample() sull‚Äôistanza del modello viene assegnato alla variabile trace e contiene le 10 estrazioni richieste con l‚Äôargomento iter_sampling = 30.\nQuando si chiama model.sample(...), CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell‚Äôargomento data di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poich√© il nostro programma Stan ha solo un blocco di quantit√† generate, l‚Äôunico compito rimanente della classe C++ √® generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da iter_sampling, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.\nLa generazione di numeri casuali √® determinata dal valore seed specificato nella chiamata.\n\n\n42.4.8 Estrazione dei Risultati\nUna volta completato il campionamento, possiamo estrarre il campione di 30 valori per la variabile scalare y sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.\n\ny = trace.stan_variable('y')\nprint(\"N =\", N, \";  theta =\", theta, \";  y(0:30) =\", *y.astype(int))\n\nN = 100 ;  theta = 0.3 ;  y(0:30) = 28 34 31 29 26 25 31 28 30 36 29 36 37 27 29 23 29 34 30 42 37 29 34 28 35 31 30 31 23 28",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#integrazione-monte-carlo",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#integrazione-monte-carlo",
    "title": "42¬† Linguaggio Stan",
    "section": "42.5 Integrazione Monte Carlo",
    "text": "42.5 Integrazione Monte Carlo\nIl calcolo bayesiano si basa sulla media delle incertezze nella stima dei parametri. In generale, ci√≤ implica il calcolo di aspettative, che sono medie ponderate con pesi dati dalle densit√† di probabilit√†. In questa sezione, introdurremo i metodi Monte Carlo per calcolare un semplice integrale che corrisponde all‚Äôaspettativa di una variabile indicatrice discreta. Utilizzeremo l‚Äôesempio classico del lancio di freccette su un bersaglio per stimare la costante matematica \\(\\pi\\) ‚Äì si veda l‚ÄôAppendice P.\n\n42.5.1 Metodi Monte Carlo a Catena di Markov\nNelle sezioni precedenti, abbiamo visto come generare un campione eseguendo una serie di estrazioni indipendenti e calcolare la media dei risultati per ottenere stime delle aspettative.\nNei moderni modelli bayesiani, raramente √® possibile generare estrazioni indipendenti dalle distribuzioni di interesse. Questo rende i semplici metodi Monte Carlo non applicabili. Solo in rari casi, con modelli molto semplici, √® possibile ottenere estrazioni indipendenti, ma questi casi sono limitati (Diaconis e Ylvisaker 1979). Prima della rivoluzione dei metodi Monte Carlo a catena di Markov (MCMC) negli anni ‚Äô90, l‚Äôinferenza bayesiana era per lo pi√π limitata a questi modelli semplici.\nL‚Äôintroduzione dei metodi MCMC ha rivoluzionato l‚Äôinferenza bayesiana. Questi metodi permettono di generare campioni da distribuzioni complesse dove non √® possibile ottenere estrazioni indipendenti. Tra questi, il metodo Hamiltonian Monte Carlo (HMC) √® particolarmente efficiente e scalabile, grazie all‚Äôuso della differenziazione automatica. HMC √® implementato in Stan e ha ampliato notevolmente la gamma di modelli che possono essere analizzati in tempi ragionevoli.\n\n\n42.5.2 Catene di Markov\nNei metodi Monte Carlo a catena di Markov, ogni estrazione dipende dall‚Äôestrazione precedente. Una sequenza di variabili casuali in cui ciascuna dipende solo dalla variabile precedente √® chiamata catena di Markov. In altre parole, una catena di Markov √® una sequenza di variabili casuali dove ogni variabile √® condizionatamente indipendente dalle precedenti, dato il valore della variabile immediatamente precedente.\nIn conclusione, i metodi Monte Carlo a catena di Markov, come l‚ÄôHamiltonian Monte Carlo, hanno ampliato notevolmente le capacit√† dell‚Äôinferenza bayesiana, permettendo di affrontare modelli complessi che non possono essere analizzati con semplici estrazioni indipendenti.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#il-problema-inverso",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#il-problema-inverso",
    "title": "42¬† Linguaggio Stan",
    "section": "42.6 Il Problema Inverso",
    "text": "42.6 Il Problema Inverso\nIl problema inverso consiste nella stima dei parametri del modello, come la probabilit√† di successo \\(\\theta\\), dato un insieme di dati osservati. Supponiamo di avere i seguenti dati: \\(N = 100\\) soggetti e \\(y = 32\\) esiti positivi. L‚Äôobiettivo √® stimare \\(\\theta\\), la probabilit√† di successo.\nNell‚Äôapproccio bayesiano, si inizia specificando una distribuzione a priori per \\(\\theta\\). Supponiamo di utilizzare una distribuzione Beta(\\(\\alpha\\), \\(\\beta\\)) come prior per \\(\\theta\\), dove \\(\\alpha\\) e \\(\\beta\\) sono parametri scelti in base alle conoscenze precedenti. La distribuzione a posteriori di \\(\\theta\\) data l‚Äôosservazione \\(y\\) √® ancora una distribuzione Beta, ma con parametri aggiornati:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + N - y)\n\\]\nAd esempio, scegliendo una distribuzione a priori non informativa con \\(\\alpha = 1\\) e \\(\\beta = 1\\), la distribuzione a posteriori diventa:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(1 + 32, 1 + 100 - 32) = \\text{Beta}(33, 69)\n\\]\nQuesta distribuzione a posteriori fornisce una stima aggiornata della probabilit√† di successo \\(\\theta\\) considerando i dati osservati. Utilizzando Stan, √® possibile ottenere campioni da questa distribuzione a posteriori per calcolare statistiche riassuntive e effettuare previsioni.\nIn sintesi, la simulazione in avanti e il problema inverso rappresentano due approcci complementari: la simulazione in avanti genera dati simulati da parametri noti, mentre il problema inverso stima i parametri del modello dai dati osservati.\nQuando si dispone di un modello che genera dati a partire dai parametri, il problema inverso consiste nell‚Äôinferire i valori dei parametri dai dati osservati. Questo tipo di problema richiede di ragionare a ritroso dalle osservazioni, attraverso il modello di misurazione e il modello diretto, per stimare parametri come, ad esempio, la probabilit√† di successo. La risoluzione dei problemi inversi √® uno degli ambiti in cui le statistiche bayesiane eccellono.\n\n42.6.1 Storia e Applicazione\nUn decennio dopo la pubblicazione della regola di Bayes, Laplace utilizz√≤ la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori. In questa sezione, analizzeremo il problema di Laplace utilizzando Stan.\nLaplace raccolse dati sul sesso dei bambini nati vivi a Parigi tra il 1745 e il 1770:\n\n\n\nSesso\nNascite vive\n\n\n\n\nFemmina\n105.287\n\n\nMaschio\n110.312\n\n\n\nLaplace si chiese se, sulla base di questi dati, la probabilit√† di nascita dei maschi fosse superiore a quella delle femmine.\n\n\n42.6.2 Modello di Laplace\nLaplace adott√≤ la seguente distribuzione campionaria per modellare il numero di maschi nati su un totale di \\(N\\) nascite:\n\\[\ny \\sim \\text{binomiale}(N, \\theta),\n\\]\ndove \\(N\\) √® il numero totale di nascite, \\(\\theta\\) √® la probabilit√† di nascita di un maschio e \\(y\\) √® il numero di nascite maschili.\n\n\n42.6.3 Distribuzione a Priori\nLaplace utilizz√≤ la seguente distribuzione a priori per \\(\\theta\\):\n\\[\n\\theta \\sim \\text{beta}(1, 1),\n\\]\ndove la distribuzione \\(\\text{beta}(1, 1)\\) √® uniforme sull‚Äôintervallo \\(\\theta \\in (0, 1)\\) poich√© la densit√† √® proporzionale a una costante:\n\\[\n\\text{beta}(\\theta \\mid 1, 1) \\propto \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} = 1.\n\\]\n\n\n42.6.4 Distribuzione a Posteriori\nIl modello di Laplace √® abbastanza semplice da permettere una soluzione analitica della distribuzione a posteriori:\n\\[\n\\begin{aligned}\n    p(\\theta \\mid y, N) &\\propto p(y \\mid N, \\theta) \\cdot p(\\theta) \\\\\n    &= \\text{binomiale}(y \\mid N, \\theta) \\cdot \\text{beta}(\\theta \\mid 1, 1) \\\\\n    &\\propto \\theta^y \\cdot (1 - \\theta)^{N - y} \\cdot \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} \\\\\n    &= \\theta^{y} \\cdot (1 - \\theta)^{N - y} \\\\\n    &\\propto \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\end{aligned}\n\\]\nQuindi, possiamo concludere che:\n\\[\np(\\theta \\mid y, N) = \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\]\n\n\n42.6.5 Implementazione in Stan\nA differenza del primo modello Stan che abbiamo visto, che generava solo dati, il seguente programma Stan richiede che vengano forniti dati, specificamente il numero di nascite maschili (\\(y\\)) e il numero totale di nascite (\\(N\\)). Il modello ci permetter√† di stimare la probabilit√† di nascita di un maschio (\\(\\theta\\)) e la probabilit√† che nascano pi√π maschi che femmine (\\(\\theta &gt; 0.5\\)).\nEcco come possiamo specificare il modello Stan:\n\nstan_file = os.path.join(project_directory, 'stan', 'sex-ratio.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che sia il numero totale di nascite (\\(N\\)) sia il numero di nascite maschili (\\(y\\)) sono forniti come dati. Poi ci sono due blocchi aggiuntivi: un blocco dei parametri, usato per dichiarare valori sconosciuti (qui, solo il tasso di nascite maschili \\(\\theta\\)), e un blocco del modello, dove specifichiamo la distribuzione a priori e la verosimiglianza. La distribuzione a posteriori viene calcolata da Stan combinando queste due componenti. Inoltre, c‚Äô√® un blocco delle quantit√† generate dove viene calcolata una variabile booleana che indica se la probabilit√† di nascita dei maschi \\(\\theta\\) √® maggiore di 0.5.\nIl modello di Laplace e la sua implementazione in Stan ci permettono di affrontare il problema inverso delle nascite, inferendo la probabilit√† di nascita di un maschio dai dati osservati. Utilizzando le tecniche bayesiane, possiamo stimare non solo la probabilit√† di nascita di un maschio, ma anche la probabilit√† che nascano pi√π maschi che femmine.\n\n\n42.6.6 Campionare dalla Distribuzione a Posteriori\nQuando eseguiamo un programma Stan, esso genera una serie di campioni casuali che approssimano la distribuzione a posteriori. Con il proseguire delle estrazioni, questi campioni tendono a diventare sempre pi√π simili a veri campioni della distribuzione a posteriori, fino a diventare numericamente indistinguibili da essa.\nStan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che pu√≤ introdurre autocorrelazione nei campioni della distribuzione a posteriori. In altre parole, i campioni non sono indipendenti tra loro, ma ogni campione √® correlato (o anti-correlato) con il campione precedente.\nL‚Äôautocorrelazione non introduce bias nelle stime Monte Carlo, ma i campioni positivamente autocorrelati, che si osservano nei modelli pi√π complessi, aumentano la varianza delle stime rispetto ai campioni indipendenti. Questo incremento della varianza aumenta l‚Äôerrore quadratico medio atteso, che √® una combinazione di errore dovuto al bias (qui nullo) e alla varianza. Al contrario, nei modelli molto semplici, l‚Äôautocorrelazione negativa riduce la varianza rispetto ai campioni indipendenti, riducendo quindi l‚Äôerrore quadratico medio atteso.\nPer affrontare problemi ad alta dimensionalit√†, Duane et al.¬†(1987) hanno introdotto l‚Äôalgoritmo Hamiltonian Monte Carlo (HMC) che migliora l‚Äôefficienza del campionamento. Per Stan, Hoffman e Gelman (2014) hanno sviluppato una versione adattiva dell‚ÄôHMC chiamata No-U-Turn Sampler (NUTS), successivamente migliorata da Betancourt (2017a). NUTS pu√≤ essere estremamente efficiente, generando campioni anti-correlati che possono portare a stime Monte Carlo pi√π precise rispetto ai campioni indipendenti.\n\n\n42.6.7 Compilazione del Codice Stan\nPer utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato model.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nInseriamo i dati in un dizionario.\n\nboys = 110312\ngirls = 105287\n\ndata = {\n    'N': boys + girls, \n    'y': boys,\n    \"alpha_prior\" : 1,\n    \"beta_prior\" : 1\n    }\n\nprint(data)\n\n{'N': 215599, 'y': 110312, 'alpha_prior': 1, 'beta_prior': 1}\n\n\nEseguiamo il campionamento MCMC con la seguente chiamata.\n\nsample = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 10_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\nIl metodo $sample() viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato model.\nAvendo assunto una distribuzione a priori per il parametro \\(\\theta\\), l‚Äôalgoritmo procede in maniera ciclica, aggiornando la distribuzione a priori di \\(\\theta\\) condizionandola ai valori gi√† generati. Dopo un certo numero di iterazioni, l‚Äôalgoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di \\(\\theta\\).\nAll‚Äôinizio del campionamento, la distribuzione dei campioni pu√≤ essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale √® chiamato ‚Äúburn-in‚Äù. Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e sono tipicamente scartati. Man mano che il numero di iterazioni aumenta, la distribuzione dei campioni si avvicina sempre pi√π alla distribuzione target.\nDopo aver eseguito il modello in Stan, otteniamo una serie di campioni \\(\\theta^{(m)}\\) dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\). Ogni campione rappresenta un possibile valore di \\(\\theta\\) compatibile con i dati osservati \\(y\\). Procediamo quindi a estrarre i campioni a posteriori per le variabili theta e boys_gt_girls.\n\ntheta_draws = sample.stan_variable('theta')\nboys_gt_girls_draws = sample.stan_variable('boys_gt_girls')\n\nTracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di \\(\\theta\\) sono pi√π probabili e comprendere meglio la forma della distribuzione a posteriori. L‚Äôistogramma ci fornisce diverse informazioni:\n\nValore pi√π probabile di \\(\\theta\\): Questo √® il valore intorno al quale i campioni sono pi√π concentrati, noto come la moda della distribuzione.\nDistribuzione dei possibili valori di \\(\\theta\\): Questo ci d√† un‚Äôidea dell‚Äôincertezza nella stima di \\(\\theta\\).\n\nSe l‚Äôistogramma √® stretto e concentrato attorno a un valore specifico, significa che c‚Äô√® poca incertezza nella stima di \\(\\theta\\). In altre parole, possiamo essere abbastanza sicuri che il valore vero di \\(\\theta\\) sia vicino a questo valore.\nSe l‚Äôistogramma √® largo e distribuito, significa che c‚Äô√® maggiore incertezza nella stima di \\(\\theta\\). Questo indica che i dati osservati non forniscono una stima precisa e che il valore di \\(\\theta\\) potrebbe variare notevolmente.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    theta_draws,\n    bins=30,\n    alpha=0.5,\n    color=color_fill,\n    edgecolor=color_edge,\n    density=True,\n)\nplt.title('Istogramma della distribizione a posteriori di theta')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\nplt.show()",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "title": "42¬† Linguaggio Stan",
    "section": "42.7 Stime Puntuali Bayesiane",
    "text": "42.7 Stime Puntuali Bayesiane\nIn termini bayesiani, una stima puntuale per un parametro \\(\\Theta\\) condizionato sui dati osservati \\(Y = y\\) √® un singolo valore \\(\\hat{\\theta} \\in \\mathbb{R}^D\\) che riassume la distribuzione a posteriori \\(p(\\theta \\mid y)\\). La notazione \\(\\hat{\\theta}\\) √® convenzionale nella statistica per indicare una stima di un parametro \\(\\theta\\). In questa sezione definiamo tre stimatori e discutiamo come i due stimatori bayesiani minimizzino una funzione di perdita tra il valore vero e la stima. Torneremo alla funzione di perdita e alle propriet√† degli stimatori dopo averli definiti.\n\n42.7.1 Stimatore della Media Posteriori\nLa stima puntuale bayesiana pi√π comune per un parametro √® la media posteriori,\n\\[\n\\begin{align}\n\\widehat{\\theta}\n&= \\mathbb{E}[\\Theta \\mid Y = y] \\\\\n&= \\int_{\\Theta} \\theta \\cdot p(\\theta \\mid y) \\, \\textrm{d}\\theta \\\\\n&= \\lim_{M \\rightarrow \\infty} \\, \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)} \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)},\n\\end{align}\n\\]\ndove nelle ultime due righe, ogni estrazione √® distribuita approssimativamente secondo la distribuzione a posteriori,\n\\[\n\\theta^{(m)} \\sim p(\\theta \\mid y).\n\\]\nAbbiamo introdotto la notazione di aspettativa condizionale nella prima riga di questa definizione. Le aspettative sono semplicemente medie ponderate, con i pesi dati da una densit√† di probabilit√†. L‚Äôinferenza bayesiana coinvolge aspettative sulla distribuzione a posteriori, la cui notazione concisa √® quella dell‚Äôaspettativa condizionale,\n\\[\n\\mathbb{E}\\!\n\\left[ f(\\Theta) \\mid Y = y \\right]\n= \\int_{\\mathbb{R^N}} f(\\theta) \\cdot p_{\\Theta \\mid Y}(\\theta \\mid y) \\, \\textrm{d}\\theta,\n\\]\ndove \\(\\Theta\\) e \\(Y\\) sono variabili casuali, mentre \\(\\theta\\) e \\(y\\) sono variabili vincolate ordinarie.\nPer il modello di Laplace, la stima per il tasso di nascite maschili \\(\\theta\\) condizionata sui dati di nascita \\(y\\) √® calcolata come la media campionaria delle estrazioni per theta.\n\ntheta_hat = np.mean(theta_draws)\nprint(f\"estimated theta = {theta_hat:.3f}\")\n\nestimated theta = 0.512\n\n\n\n\n42.7.2 Stimatore della Mediana Posteriori, Quantili e Intervalli\nUn‚Äôalternativa popolare alla stima puntuale bayesiana √® la mediana posteriori, \\(\\theta^+\\). La mediana √® il valore tale che, per ogni dimensione \\(d \\in 1{:}D\\),\n\\[\n\\Pr[\\Theta_d \\leq \\theta^+_d] = \\frac{1}{2}.\n\\]\nIn altre parole, la mediana √® il valore che divide la distribuzione a posteriori in due parti uguali: il 50% dei campioni √® al di sotto della mediana e il 50% √® al di sopra. La mediana posteriori pu√≤ essere calcolata prendendo la mediana dei campioni dalla distribuzione a posteriori.\nEcco come calcolare la mediana posteriori utilizzando Python:\n\ntheta_plus = np.median(theta_draws)\nprint(f\"estimated (median) theta = {theta_plus:.3f}\")\n\nestimated (median) theta = 0.512\n\n\nPoich√© la distribuzione a posteriori per i dati di Laplace √® quasi simmetrica, la media posteriori e la mediana posteriori sono molto simili.\n\n\n42.7.3 Quantili e Intervalli di Credibilit√†\nOltre alla mediana, possiamo anche calcolare i quantili e gli intervalli di credibilit√† per fornire ulteriori informazioni sulla distribuzione a posteriori. I quantili sono valori che dividono la distribuzione in intervalli con una probabilit√† specificata. Gli intervalli di credibilit√† indicano l‚Äôintervallo entro il quale cade una certa percentuale della distribuzione a posteriori.\n\n42.7.3.1 Quantili\nAd esempio, se vogliamo calcolare il quantile al 95% della distribuzione a posteriori, possiamo semplicemente prendere il valore che si trova al 95¬∞ percentile nella sequenza ordinata dei campioni. Di seguito sono riportati i quantili al 5% e al 95% della distribuzione a posteriori di Laplace, calcolati utilizzando i quantili empirici.\n\nquantile_05 = np.quantile(theta_draws, 0.05)\nquantile_95 = np.quantile(theta_draws, 0.95)\nprint(f\"\"\"0.05 quantile = {quantile_05:.3f};\n0.95 quantile = {quantile_95:.3f}\"\"\")\n\n0.05 quantile = 0.510;\n0.95 quantile = 0.513\n\n\n\n\n42.7.3.2 Intervalli Posteriori\nInsieme, il quantile al 5% e al 95% ci forniscono i limiti del nostro intervallo di probabilit√† centrale al 90%. Questo intervallo √® definito come l‚Äôintervallo che contiene il 90% della massa di probabilit√† a posteriori, con il 5% della massa rimanente al di sotto dell‚Äôintervallo e il 5% al di sopra.\n\n\n\n42.7.4 Errore di Stima e Bias\nL‚Äôerrore di una stima √® la differenza tra la stima stessa e il valore vero del parametro,\n\\[\n\\textrm{err} = \\hat{\\theta} - \\theta.\n\\]\nLa nostra stima \\(\\hat{\\theta}\\) √® implicitamente una funzione dei dati \\(y\\), quindi anche l‚Äôerrore dipende dai dati. Possiamo rendere esplicita questa dipendenza scrivendo\n\\[\n\\text{err}(y) = \\hat{\\theta}(y) - \\theta.\n\\]\nIl bias di uno stimatore √® definito come l‚Äôerrore atteso, cio√® la media dell‚Äôerrore rispetto alla distribuzione dei dati per la variabile casuale \\(Y\\),\n\\[\n\\begin{align}\n\\text{bias}\n&= \\mathbb{E}[\\text{err}(Y)] \\\\\n&= \\mathbb{E}[\\hat{\\theta}(Y) - \\theta] \\\\\n&= \\int_Y (\\hat{\\theta}(y) - \\theta) \\, \\text{d}y.\n\\end{align}\n\\]\nIn altre parole, il bias misura quanto, in media, la stima \\(\\hat{\\theta}\\) si discosta dal valore vero \\(\\theta\\) considerando tutte le possibili realizzazioni dei dati \\(Y\\). Un bias nullo indica che lo stimatore √® corretto in media, cio√® non tende a sovrastimare o sottostimare il valore vero del parametro.\n\n\n42.7.5 Stimatore della Moda Posteriori\nUno stimatore popolare, sebbene non strettamente bayesiano, √® la moda a posteriori, che rappresenta il valore del parametro \\(\\theta\\) per cui la densit√† a posteriori √® massima. Formalmente, √® definita come:\n\\[\n\\theta^* = \\text{arg max}_\\theta \\ p(\\theta \\mid y).\n\\]\nLa stima \\(\\theta^*\\) √® spesso chiamata stima MAP (Maximum A Posteriori). La moda a posteriori non √® considerata un vero stimatore bayesiano perch√© non tiene conto dell‚Äôincertezza nella stessa misura in cui lo fanno altri metodi bayesiani. In altre parole, non minimizza una funzione di perdita basata sui valori veri dei parametri, ma cerca semplicemente il valore pi√π probabile dato i dati osservati.\n\n\n42.7.6 Caratteristiche della Moda Posteriori\n\nNon considera l‚Äôincertezza: La stima MAP si focalizza solo sul valore pi√π probabile della distribuzione a posteriori, senza tenere conto della variabilit√† dei dati.\nMassimo della densit√† a posteriori: La moda a posteriori rappresenta il punto in cui la densit√† a posteriori raggiunge il suo massimo.\nPossibili limitazioni: La stima MAP potrebbe non esistere in alcuni casi, come nei modelli in cui la densit√† cresce senza limiti. Questo pu√≤ accadere, ad esempio, nei modelli bayesiani gerarchici o in distribuzioni semplici come la distribuzione esponenziale con parametro 1 (\\(\\textrm{esponenziale}(1)\\)).\n\n\n\n42.7.7 Funzioni di Perdita e Propriet√† degli Stimatori\nLa media a posteriori √® uno stimatore bayesiano popolare per due ragioni principali. Primo, √® uno stimatore non distorto, il che significa che ha un bias nullo. Secondo, ha l‚Äôerrore quadratico medio atteso minimo tra tutti gli stimatori non distorti. L‚Äôerrore quadratico di una stima √® definito come:\n\\[\n\\text{err}^2(y) = \\left(\\hat{\\theta}(y) - \\theta\\right)^2.\n\\]\nQuesta √® una funzione di perdita, che misura la differenza tra una stima \\(\\hat{\\theta}\\) e il valore vero \\(\\theta\\). Tuttavia, la media a posteriori potrebbe non esistere se la distribuzione a posteriori ha code molto ampie, come accade nella distribuzione di Cauchy standard.\n\n\n42.7.8 Propriet√† della Mediana Posteriori\nLa mediana a posteriori \\(\\theta^+\\) ha tre propriet√† interessanti:\n\nSempre ben definita: La mediana a posteriori √® sempre ben definita, anche per densit√† con poli o code molto ampie.\nMinimizzazione dell‚Äôerrore assoluto atteso: La mediana minimizza l‚Äôerrore assoluto atteso, il che la rende robusta.\nRobustezza ai valori anomali: La mediana √® meno sensibile ai valori anomali rispetto alla media, perch√© minimizza l‚Äôerrore assoluto anzich√© l‚Äôerrore quadrato.\n\n\n\n42.7.9 Concentrazione sulle Medie a Posteriori\nIn questa introduzione a Stan, ci concentreremo principalmente sulle medie a posteriori. La media a posteriori non solo fornisce una stima non distorta, ma minimizza anche l‚Äôerrore quadratico medio atteso, rendendola uno strumento potente per l‚Äôinferenza bayesiana. Tuttavia, √® importante essere consapevoli delle sue limitazioni, specialmente in presenza di distribuzioni a posteriori con code molto ampie.\n\n\n42.7.10 Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo\nQuando utilizziamo un campionatore di catene di Markov per stimare parametri, otteniamo una sequenza di campioni casuali. Questa sequenza √® essa stessa una variabile casuale, perch√© √® composta da molte variabili casuali. A causa di questa natura casuale, ogni esecuzione del campionatore pu√≤ produrre risultati leggermente diversi, introducendo quello che √® noto come errore Monte Carlo.\nL‚Äôerrore Monte Carlo √® l‚Äôerrore introdotto dal fatto che utilizziamo solo un numero finito di campioni ($ M $) per stimare i parametri. Questo tipo di errore si verifica perch√©, con un numero limitato di campioni, non possiamo catturare perfettamente l‚Äôintera distribuzione a posteriori.\n\n42.7.10.1 Errore Standard di Monte Carlo (MCMC)\nStan riporta l‚Äôerrore standard di Monte Carlo (MCMC) insieme alle stime della media. L‚Äôerrore standard MCMC per un parametro scalare $ _d $ √® definito come:\n\\[\n\\text{mcmc-se} = \\frac{\\textrm{sd}[\\Theta_d \\mid Y = y]}{\\sqrt{N^{\\text{eff}}}},\n\\]\ndove: - \\(\\text{sd}[\\Theta_d \\mid Y = y]\\) √® la deviazione standard del parametro $ _d $ nella distribuzione a posteriori. - \\(N^{\\text{eff}}\\) √® la dimensione del campione effettivo, che riflette il numero di campioni indipendenti equivalenti ottenuti dal campionatore.\n\n\n42.7.10.2 Dimensione del Campione Effettivo\nNel classico teorema del limite centrale, la dimensione del campione (numero di estrazioni indipendenti) appare al posto di \\(N^{\\text{eff}}\\). Tuttavia, nel contesto delle catene di Markov, i campioni successivi sono correlati tra loro. La dimensione del campione effettivo (\\(N^{\\text{eff}}\\)) tiene conto di questa correlazione e rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle nostre estrazioni correlate.\nLa dimensione del campione effettivo per un campione di dimensione $ M $ √® definita come:\n\\[\nN^{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(\\text{IAT}\\) √® il tempo di autocorrelazione integrata. Sebbene non sia definito formalmente qui, pu√≤ essere considerato come l‚Äôintervallo tra estrazioni effettivamente indipendenti nella nostra catena di Markov. Se l‚Äôautocorrelazione √® bassa, \\(\\text{IAT}\\) sar√† vicino a 1; se l‚Äôautocorrelazione √® alta, \\(\\text{IAT}\\) sar√† molto pi√π alto.\nIn sintesi, \\(N^{\\text{eff}}\\) rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle estrazioni correlate della nostra catena di Markov.\nIn conclusione, l‚Äôerrore standard di Monte Carlo (MCMC) fornisce una misura di quanto varierebbero le nostre stime se ripetessimo il processo di campionamento pi√π volte. √à un indicatore dell‚Äôaffidabilit√† delle nostre stime, tenendo conto della casualit√† introdotta dall‚Äôutilizzo di un numero finito di campioni. Conoscere questo errore ci aiuta a valutare la precisione delle nostre stime e a comprendere meglio l‚Äôincertezza associata ai risultati ottenuti tramite il campionamento di catene di Markov.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "title": "42¬† Linguaggio Stan",
    "section": "42.8 Stima delle Probabilit√† di Evento",
    "text": "42.8 Stima delle Probabilit√† di Evento\nLaplace non cercava semplicemente un valore specifico per \\(\\theta\\). Voleva sapere qual era la probabilit√† che \\(\\theta\\) fosse maggiore di \\(\\frac{1}{2}\\) dopo aver osservato \\(y\\) nascite maschili su un totale di \\(N\\) nascite. In termini di teoria della probabilit√†, voleva stimare la probabilit√† di un evento.\nUn sottoinsieme di parametri √® noto come evento. Possiamo convertire le condizioni sui parametri in eventi. Ad esempio, la condizione \\(\\theta &gt; \\frac{1}{2}\\) pu√≤ essere espressa come l‚Äôevento:\n\\[ A = \\left\\{ \\theta \\in \\Theta : \\theta &gt; \\frac{1}{2} \\right\\}. \\]\nData una misura di probabilit√†, la probabilit√† dell‚Äôevento \\(A\\), ossia che il tasso di nascite maschili sia superiore a quello delle nascite femminili, sar√† ben definita. Poich√© possiamo convertire le condizioni in eventi, possiamo trattarle come tali. Questo ci permette di scrivere \\(\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\, \\big| \\, N, y\\right]\\) per indicare la probabilit√† dell‚Äôevento \\(\\Theta &gt; \\frac{1}{2}\\).\n\n42.8.1 Probabilit√† di Evento tramite Indicatori\nLa funzione indicatrice \\(\\textrm{I}\\) assegna il valore 1 alle proposizioni vere e 0 a quelle false. Ad esempio, \\(\\textrm{I}(\\theta &gt; \\frac{1}{2}) = 1\\) se la proposizione \\(\\theta &gt; \\frac{1}{2}\\) √® vera, cio√® quando \\(\\theta\\) √® maggiore di un mezzo.\nLe probabilit√† di evento sono definite come aspettative condizionali posteriori delle funzioni indicatrici per eventi:\n\\[\n\\begin{align}\n\\Pr[\\Theta &gt; 0.5 \\mid N, y]\n&= \\mathbb{E}\\!\\left[\\textrm{I}[\\Theta &gt; 0.5] \\mid N, y\\right] \\\\\n&= \\int_{\\Theta} \\textrm{I}(\\theta &gt; 0.5) \\cdot p(\\theta \\mid N, y) \\, \\textrm{d}\\theta \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\textrm{I}(\\theta^{(m)} &gt; 0.5),\n\\end{align}\n\\]\ndove \\(\\theta^{(m)}\\) rappresenta i campioni dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\) per \\(m = 1, 2, \\ldots, M\\).\n\n\n42.8.2 Eventi come Indicatori in Stan\nIn Stan, possiamo codificare direttamente il valore della funzione indicatrice e assegnarlo a una variabile nel blocco delle quantit√† generate.\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\nLe espressioni condizionali come theta &gt; 0.5 assumono il valore 1 se sono vere e 0 se sono false. In notazione matematica, scriveremmo \\(\\textrm{I}(\\theta &gt; 0.5)\\), che assume valore 1 se \\(\\theta &gt; 0.5\\) e 0 altrimenti. In Stan, come in C++, trattiamo &gt; come un operatore binario che restituisce 0 o 1, quindi scriviamo semplicemente theta &gt; 0.5.\n\n\n42.8.3 La Risposta alla Domanda di Laplace\nLa media a posteriori della variabile boys_gt_girls √® quindi la nostra stima per \\(\\Pr[\\theta &gt; 0.5 \\mid N, y]\\). √à essenzialmente 1. Stampando a 15 cifre decimali, vediamo\n\nPr_boy_gt_girl = np.mean(boys_gt_girls_draws)\nprint(f\"estimated Pr[boy more likely] = {Pr_boy_gt_girl:.15f}\")\n\nestimated Pr[boy more likely] = 1.000000000000000\n\n\nCome possiamo vedere di seguito, tutti i nostri campioni per \\(\\theta\\) sono maggiori di \\(\\frac{1}{2}\\), ovvero boys_gt_girls_draws √® sempre uguale a 1:\n\nnp.unique(boys_gt_girls_draws)\n\narray([1.])\n\n\nIl valore 1 restituito come stima solleva l‚Äôimportante problema della precisione numerica. Laplace calcol√≤ il risultato analiticamente, che √®\n\\[\n\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\ \\bigg| \\ N, y\\right] \\approx 1 - 10^{-27}.\n\\]\nQuindi avremmo bisogno di un numero astronomico di campioni a posteriori prima di generare un valore di \\(\\theta\\) inferiore a \\(\\frac{1}{2}\\). Come detto, la risposta di 1.0 √® molto vicina alla risposta vera e ben entro il nostro errore Monte Carlo atteso.\n\n\n42.8.4 Statistiche di riepilogo MCMC da Stan\nCon Stan, possiamo ottenere un riepilogo completo della variabile \\(\\theta\\) nella distribuzione a posteriori. Per fare ci√≤, basta chiamare la funzione .summary() sul campione. Questo riepilogo include tutte le statistiche rilevanti.\n\nsample.summary(sig_figs = 3)\n\n\n\n\n\n\n\n\n\nMean\nMCSE\nStdDev\n5%\n50%\n95%\nN_Eff\nN_Eff/s\nR_hat\n\n\n\n\nlp__\n-149000.000\n0.004770\n6.720000e-01\n-149000.00\n-149000.000\n-149000.000\n19800.0\n51300.0\n1.0\n\n\ntheta\n0.512\n0.000009\n1.090000e-03\n0.51\n0.512\n0.513\n13700.0\n35400.0\n1.0\n\n\nboys_gt_girls\n1.000\nNaN\n9.380000e-14\n1.00\n1.000\n1.000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nL‚Äôistruzione print(sample.diagnose()) in Stan viene utilizzata per eseguire una diagnosi completa del campionamento MCMC. Questa funzione fornisce una serie di statistiche diagnostiche che aiutano a valutare la qualit√† e la convergenza del campionamento.\nQuesti sono alcuni degli aspetti che possono essere diagnosticati:\n\nConvergenza: La diagnosi verifica se le catene di Markov sono convergenti, ad esempio controllando il valore di \\(\\hat{R}\\). Un valore di \\(\\hat{R}\\) vicino a 1 indica che le catene sono ben mescolate e convergenti.\nAutocorrelazione: Fornisce informazioni sull‚Äôautocorrelazione delle catene, che pu√≤ influire sull‚Äôefficienza del campionamento. Bassa autocorrelazione √® desiderabile per ottenere campioni indipendenti.\nEfficienza del campionamento: Viene calcolata la dimensione del campione effettivo (\\(N_{\\text{eff}}\\)), che indica quanti campioni indipendenti equivarrebbero ai campioni correlati ottenuti.\nVarianza e Deviazione Standard: Viene riportata la varianza e la deviazione standard dei campioni, aiutando a comprendere la distribuzione a posteriori del parametro.\n\n\nprint(sample.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nUn grafico con le tracce si ottiene nel modo seguente:\n\n_ = az.plot_trace(sample, var_names=(\"theta\"), combined=False)",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#riscaldamento",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#riscaldamento",
    "title": "42¬† Linguaggio Stan",
    "section": "43.1 Riscaldamento",
    "text": "43.1 Riscaldamento\nDurante le fasi iniziali di riscaldamento, Stan cerca di trovare la regione di alta probabilit√† da cui campionare, adattare una buona dimensione del passo e stimare la varianza a posteriori. La varianza stimata viene utilizzata per migliorare l‚Äôefficienza del campionatore, un processo chiamato ‚Äúprecondizionamento‚Äù. Precondizionare significa ridimensionare i parametri per rendere il campionamento pi√π efficiente.\nStan pu√≤ anche stimare una matrice di covarianza completa, che rappresenta le relazioni tra tutti i parametri. Utilizzando questa matrice, Stan pu√≤ effettuare rotazioni e ridimensionamenti dei parametri per campionare in modo pi√π efficace. In questo contesto, ‚Äúrotazione e scalatura‚Äù si riferiscono alla trasformazione dei parametri in una nuova base (rotazione) e alla regolazione delle loro scale (scalatura) per facilitare il campionamento, rendendolo pi√π rapido e affidabile. Per ulteriori dettagli su questi processi, si pu√≤ fare riferimento a Neal (2011).\nIl riscaldamento converge quando la dimensione del passo e le stime della covarianza a posteriori diventano stabili. Con pi√π catene, √® possibile verificare che tutte convergano verso una dimensione del passo e una stima della covarianza simili. A meno che non ci siano problemi, generalmente non misuriamo la convergenza dell‚Äôadattamento, ma piuttosto se otteniamo campioni a posteriori ragionevoli dopo il riscaldamento.\nDurante la fase di riscaldamento, Stan non produce una catena di Markov coerente perch√© utilizza la memoria per adattarsi alle condizioni del modello. Questo adattamento serve a trovare i migliori parametri di campionamento. Tuttavia, una volta terminato il riscaldamento e iniziata la fase di campionamento, Stan inizia a produrre una vera e propria catena di Markov.\nLe nostre analisi a posteriori si baseranno esclusivamente sui campioni generati durante questa fase di campionamento, non sui campioni raccolti durante il riscaldamento. √à comunque possibile salvare ed esaminare i campioni del riscaldamento per comprendere meglio come il processo di adattamento √® avvenuto e se ci sono stati problemi.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#riduzione-potenziale-della-scala-e-widehatr",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#riduzione-potenziale-della-scala-e-widehatr",
    "title": "42¬† Linguaggio Stan",
    "section": "43.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)",
    "text": "43.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)\nStan utilizza la statistica di riduzione potenziale della scala \\(\\widehat{R}\\) (pronunciata ‚ÄúR hat‚Äù). Dato un insieme di catene di Markov, Stan divide ciascuna di esse a met√† per assicurarsi che la prima met√† e la seconda met√† della catena concordino, quindi calcola le varianze all‚Äôinterno di ciascuna catena e tra tutte le catene e le confronta. La statistica \\(\\widehat{R}\\) converge a 1 quando le catene di Markov convergono alla stessa distribuzione.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#quante-catene-per-quanto-tempo",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#quante-catene-per-quanto-tempo",
    "title": "42¬† Linguaggio Stan",
    "section": "43.3 Quante catene per quanto tempo?",
    "text": "43.3 Quante catene per quanto tempo?\nUna semplice regola empirica consiste nell‚Äôeseguire quattro catene finch√© \\(\\widehat{R} \\leq 1.01\\) e la dimensione campionaria effettiva (ESS) √® superiore a 100. La raccomandazione di avere una dimensione campionaria effettiva di ‚Äúsoli‚Äù 100 √® dovuta al fatto che questo valore implica un errore standard pari a \\(\\frac{1}{10}\\) della deviazione standard. Poich√© la deviazione standard a posteriori rappresenta l‚Äôincertezza residua, calcolare le medie con una precisione maggiore √® raramente utile.\nIl modo pi√π semplice per ottenere \\(\\widehat{R} \\leq 1.01\\) e \\(N_{\\text{eff}} &gt; 100\\) √® iniziare con 100 iterazioni di riscaldamento e 100 iterazioni di campionamento. Se i valori di \\(\\widehat{R}\\) sono troppo alti o se la dimensione campionaria effettiva √® troppo bassa, raddoppiare il numero di iterazioni di riscaldamento e di campionamento e riprovare. Eseguire pi√π iterazioni di riscaldamento √® importante perch√© il campionamento non sar√† efficiente se il riscaldamento non √® convergente. Utilizzare lo stesso numero di iterazioni di riscaldamento e di campionamento pu√≤ comportare un costo massimo doppio rispetto alle impostazioni ottimali, che non sono note in anticipo.\nAnche se si utilizzano pi√π di quattro catene, √® necessario assicurarsi che la dimensione campionaria effettiva sia almeno 25 per catena. Non √® tanto per l‚Äôinferenza, quanto per garantire la fiducia nello stimatore della dimensione campionaria effettiva, che non √® affidabile se √® molto inferiore. Un modo per verificare l‚Äôadeguatezza dello stimatore ESS √® raddoppiare il numero di campioni e assicurarsi che anche l‚ÄôESS raddoppi. Se ci√≤ non accade, significa che la prima stima dell‚ÄôESS non √® affidabile.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#esecuzione-delle-catene-contemporaneamente",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#esecuzione-delle-catene-contemporaneamente",
    "title": "42¬† Linguaggio Stan",
    "section": "43.4 Esecuzione delle catene contemporaneamente",
    "text": "43.4 Esecuzione delle catene contemporaneamente\n√à possibile impostare il numero di catene da eseguire utilizzando l‚Äôargomento chains del metodo sample(). Inoltre, √® possibile controllare quante catene possono essere eseguite contemporaneamente con l‚Äôargomento parallel_cores (che per default √® impostato su 1, ovvero esecuzione sequenziale).\nSe il numero massimo di catene parallele √® impostato troppo basso, le risorse della CPU potrebbero non essere sfruttate appieno. Al contrario, se √® impostato troppo alto, la CPU o la memoria potrebbero diventare il collo di bottiglia, rallentando le prestazioni complessive rispetto all‚Äôesecuzione con un numero inferiore di catene parallele.\nIn progetti personali sul nostro hardware, l‚Äôobiettivo √® solitamente ottenere la massima dimensione campionaria effettiva nel minor tempo possibile. Tuttavia, a volte √® necessario lasciare abbastanza potenza di elaborazione per continuare a lavorare su altre attivit√† come documenti, email, ecc.\n\n43.4.1 Matrici, Vettori o Array in Stan\nStan offre vari tipi di dati per gestire operazioni di algebra lineare e per definire strutture di dati pi√π generali come gli array. Capire le differenze tra questi tipi √® fondamentale per sapere cosa possiamo fare con essi e per ottimizzare la velocit√† di esecuzione del nostro modello.\n\nTipi di base per l‚Äôalgebra lineare:\n\nvector: un vettore colonna di dimensione N.\nrow_vector: un vettore riga di dimensione N.\nmatrix: una matrice di dimensioni N1 √ó N2.\n\nArray:\n\nGli array possono essere creati con qualsiasi tipo di elemento e possono avere pi√π dimensioni. Ad esempio:\n\narray[N] real a; definisce un array unidimensionale di numeri reali.\narray[N1, N2] real m; definisce un array bidimensionale di numeri reali.\n\n\nIntercambiabilit√† e limitazioni:\n\nAnche se possiamo usare sia vector che array per contenitori unidimensionali, l‚Äôalgebra matriciale (come la moltiplicazione) √® definita solo per vettori e matrici, non per array.\nAlcune funzioni, come normal_lpdf, accettano sia vettori che array.\n\nEsempi pratici:\n\nQuando definiamo una media (mu) come somma di un parametro (alpha) e il prodotto di un vettore di carichi (c_load) con un coefficiente (beta), dobbiamo usare i vettori:\nvector[N] mu = alpha + c_load * beta;\nPer utilizzare un generatore di numeri casuali (_rng) in modo vettoriale, dobbiamo usare un array:\narray[N] real p_size_pred = normal_rng(alpha + c_load * beta, sigma);\n\n\nIn sintesi, la scelta tra vector, row_vector, matrix e array dipende dalle operazioni che si desidera eseguire e dalle specifiche esigenze del modello. Scegliere il tipo di dato appropriato permette di sfruttare appieno le funzionalit√† di Stan e ottimizzare le prestazioni del modello.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#modello-di-esecuzione-di-stan",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#modello-di-esecuzione-di-stan",
    "title": "42¬† Linguaggio Stan",
    "section": "43.5 Modello di esecuzione di Stan",
    "text": "43.5 Modello di esecuzione di Stan\nI programmi Stan sono composti da diversi blocchi. Ecco una panoramica di ciascun blocco, di quando viene eseguito e di cosa fa. Nessuno di questi blocchi √® obbligatorio, ma se presenti, devono seguire quest‚Äôordine.\n\n\n\n\n\n\n\n\nBlocco\nQuando viene eseguito\nCosa fa\n\n\n\n\nfunctions\nsecondo necessit√†\nDefinizione delle funzioni create dall‚Äôutente\n\n\ndata\nuna volta\nLettura dei dati per costruire il modello\n\n\ntransformed data\nuna volta\nDefinizione dei dati trasformati\n\n\nparameters\nuna volta / densit√† logaritmica\nDefinizione dei parametri con i relativi vincoli\n\n\ntransformed parameters\nuna volta / densit√† logaritmica\nDefinizione dei parametri trasformati\n\n\nmodel\nuna volta / densit√† logaritmica\nValutazione della densit√† logaritmica del modello\n\n\ngenerated quantities\nuna volta / per estrazione\nDefinizione delle quantit√† generate\n\n\n\n\n43.5.1 Dati e dati trasformati\nIl blocco data contiene solo le dichiarazioni delle variabili. Queste variabili vengono lette una volta durante il caricamento dei dati.\nIl blocco transformed data contiene sia dichiarazioni che definizioni delle variabili. Questo blocco serve per calcolare nuove variabili a partire dai dati originali, come predittori standardizzati o costanti per i priori. Pu√≤ anche includere la generazione pseudocasuale di numeri. Viene eseguito una volta, dopo la lettura dei dati, per definire le nuove variabili trasformate.\nIn ogni blocco, tutte le variabili devono avere il loro tipo e dimensione dichiarati (che possono dipendere dai dati). Le variabili locali all‚Äôinterno dei blocchi, invece, sono dichiarate senza specificare la dimensione.\nI vincoli sulle variabili nel blocco data vengono controllati mentre i dati vengono letti, mentre quelli nel blocco transformed data vengono verificati alla fine dell‚Äôesecuzione del blocco. Se ci sono violazioni dei vincoli nei dati o nei dati trasformati, si genera un‚Äôeccezione che interrompe l‚Äôesecuzione del programma.\nLe variabili definite nel blocco transformed data possono essere assegnate una volta, ma non possono essere riassegnate dopo l‚Äôesecuzione del blocco.\n\n\n43.5.2 Parametri e Parametri Trasformati\nIl blocco parameters serve a dichiarare le variabili su cui √® basato il modello. In pratica, si tratta di elencare i parametri che il modello utilizzer√†, specificandone le dimensioni. Quando il blocco viene eseguito, vengono forniti i valori concreti di questi parametri.\nI vincoli sui parametri sono utilizzati per trasformare le variabili vincolate in variabili non vincolate. Ad esempio, se una variabile ha un vincolo lower=0 (cio√® deve essere maggiore o uguale a zero), questa variabile viene trasformata usando il logaritmo per renderla non vincolata. √à essenziale dichiarare tutti i vincoli necessari sui parametri affinch√© il modello funzioni correttamente su tutto lo spazio dei parametri.\nIl blocco transformed parameters permette di definire nuove variabili che sono funzioni dei parametri originali e dei dati. Gli utenti possono creare le loro trasformazioni dei parametri in questo blocco. I vincoli su queste nuove variabili vengono verificati alla fine dell‚Äôesecuzione del blocco. Se questi vincoli non sono rispettati, viene generata un‚Äôeccezione che di solito porta al rifiuto della proposta corrente.\nLe variabili dichiarate nel blocco parameters sono simili agli argomenti di una funzione: la funzione di densit√† logaritmica del programma Stan prende questi parametri come input. Quindi, i valori dei parametri vengono sempre forniti dall‚Äôesterno del programma Stan.\nDopo l‚Äôesecuzione del blocco transformed parameters, le variabili dichiarate in esso non possono essere modificate ulteriormente.\nLa differenza principale tra le variabili dichiarate come locali nel blocco model e quelle nel blocco transformed parameters √® che le variabili trasformate vengono stampate e sono disponibili anche nel blocco generated quantities.\n\n\n43.5.3 Modello\nLo scopo del blocco model √® definire la funzione che calcola la densit√† logaritmica del modello. Una volta caricati i dati, il compito principale di un programma Stan √® fornire questa funzione di densit√† logaritmica non normalizzata sui parametri non vincolati. Algoritmi esterni, come ottimizzatori, campionatori o metodi di inferenza variazionale, forniranno i valori dei parametri non vincolati per la valutazione.\nIl valore della densit√† logaritmica non normalizzata calcolato dal modello viene conservato in una variabile chiamata target. Le densit√† posteriori (che ci interessano) sono calcolate moltiplicando i fattori delle funzioni di densit√† o massa di probabilit√†. In termini logaritmici, questo equivale ad aggiungere i termini delle funzioni di densit√† o massa non normalizzate alla target.\nL‚Äôaccumulatore target parte da zero e viene incrementato durante l‚Äôesecuzione del programma Stan. Come accennato prima, la prima cosa che questa funzione di densit√† logaritmica non normalizzata fa √® trasformare i parametri vincolati in non vincolati e aggiungere un aggiustamento logaritmico per il cambio di variabili alla target. Questo processo √® automatico e fornisce i valori dei parametri trasformati al codice che verr√† eseguito successivamente nel blocco model.\nLa densit√† logaritmica accumulata in target pu√≤ essere incrementata direttamente, come mostrato nell‚Äôesempio seguente:\ntarget += -0.5 * x^2;\nAnche se non √® possibile usare direttamente target come variabile, il suo valore attuale pu√≤ essere recuperato tramite la funzione target(), utile per il debugging.\nLe istruzioni di campionamento sono una scorciatoia per incrementare target. Ad esempio, l‚Äôistruzione\nx ~ normal(0, 1);\n√® equivalente a\ntarget += normal_lupdf(x | 0, 1);\nQui, _lupdf indica che si tratta di una funzione di densit√† di probabilit√† logaritmica non normalizzata.\nLa barra verticale | √® utilizzata per separare le variabili osservate dai parametri. La notazione lpdf denota una funzione di densit√† di probabilit√† logaritmica, mentre lpmf indica una funzione di massa di probabilit√† logaritmica. Le varianti lupdf e lupmf sono le loro controparti non normalizzate, che possono omettere le costanti di normalizzazione che non dipendono dai parametri. A meno che non siano necessarie, ad esempio in un componente di un modello di mescolanza, √® pi√π efficiente usare le forme lupdf e lupmf incrementando direttamente target o tramite istruzioni di campionamento.\n\n\n43.5.4 Quantit√† generate\nIl blocco generated quantities viene eseguito una volta per ogni campione generato, anzich√© ogni volta che viene calcolata la densit√† logaritmica. Con algoritmi come il campionamento Monte Carlo Hamiltoniano, ogni campione pu√≤ richiedere diverse valutazioni della densit√† logaritmica.\nUn vantaggio delle quantit√† generate √® che vengono calcolate utilizzando numeri in virgola mobile a doppia precisione, il che le rende molto efficienti. Questo blocco pu√≤ anche utilizzare numeri pseudocasuali. I vincoli sui dati generati vengono verificati alla fine del blocco, ma eventuali errori non causano il rigetto del campione, solo possibili avvertimenti o valori non definiti (NaN).\nLe quantit√† generate non influenzano il calcolo della densit√† logaritmica, ma sono comunque una parte importante del modello statistico. Sono utilizzate principalmente per fare previsioni su nuovi dati, basandosi sui parametri stimati dal modello. Questo processo √® noto come inferenza predittiva posteriore. In altre parole, ci permette di fare previsioni su nuovi dati utilizzando i valori dei parametri generati dal modello.\nEsempi di utilizzo delle quantit√† generate includono la previsione di nuovi valori o il calcolo di statistiche derivate dai parametri stimati. Le quantit√† generate offrono un modo per esplorare ulteriormente il comportamento del modello e fare inferenze utili dai dati simulati.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "title": "42¬† Linguaggio Stan",
    "section": "43.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "43.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® quello di descrivere i metodi di sintesi della distribuzione a posteriori mediante l‚Äôutilizzo della tecnica MCMC.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.1 Sintesi della Distribuzione a Posteriori",
    "text": "43.1 Sintesi della Distribuzione a Posteriori\nIl risultato di un‚Äôanalisi bayesiana √® una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. √à prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un‚Äôidea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l‚Äôincertezza delle stime. La deviazione standard √® adeguata per distribuzioni simili alla normale, ma pu√≤ risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l‚ÄôIntervallo di Densit√† Pi√π Alta (HDI, Highest-Density Interval). L‚ÄôHDI √® l‚Äôintervallo pi√π breve che contiene una data porzione della densit√† di probabilit√†. Ad esempio, se diciamo che l‚ÄôHDI al 95% per un‚Äôanalisi √® [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilit√† di 0.95. Non vi √® nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l‚Äôintervallo HDI all‚Äô89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma √® accettabile stabilire un valore comune come il 95%. Per ricordarci della natura arbitraria di questa scelta, il valore predefinito in ArviZ √® del 94%.\nArviZ √® un pacchetto Python per l‚Äôanalisi esplorativa di modelli bayesiani e offre numerose funzioni utili per riassumere la distribuzione a posteriori.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#campionamento-con-stan",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.2 Campionamento con Stan",
    "text": "43.2 Campionamento con Stan\nA scopo illustrativo, utilizziamo ancora una volta i dati relativi agli artisti della Generazione X presenti al MOMA. I dati consistono in 14 casi di successo, ovvero artisti della Generazione X, su un totale di 100 opere selezionate casualmente dal MOMA. Come fatto in precedenza, impostiamo il parametro \\(\\theta\\), che rappresenta la probabilit√† di appartenere alla Generazione X o alle successive, seguendo una distribuzione Beta(4, 6).\nPer iniziare, eseguiamo il processo di campionamento MCMC usando Stan.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'moma.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y_rep;\n  y_rep = binomial_rng(N, theta);\n}\n\n\n\nCompiliamo il modello:\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nDefiniamo il dizionario con i dati:\n\nN = 100\ny = 14\n\ndata = {\n    'N': N, \n    'y': y,\n    \"alpha_prior\" : 4,\n    \"beta_prior\" : 6\n    }\n\nprint(data)\n\n{'N': 100, 'y': 14, 'alpha_prior': 4, 'beta_prior': 6}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 4_000,\n    chains = 4,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.3 Analisi della distribuzione a posteriori",
    "text": "43.3 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.\nLa distribuzione a posteriori rappresenta un aggiornamento delle nostre credenze a priori in base ai dati osservati.\nIn genere, il primo passo da fare dopo il campionamento √® quello di verificare l‚Äôaspetto dei risultati.\n\ntrace.draws().shape\n\n(4000, 4, 9)\n\n\nLe dimensioni (4000, 4, 9) restituite dall‚Äôistruzione trace.draws().shape in CmdStanPy si riferiscono alla struttura dei dati campionati ottenuti dall‚Äôesecuzione del modello Stan. Vediamo cosa rappresenta ciascuna dimensione:\n\n4000: Questo rappresenta il numero di iterazioni di campionamento per catena. Qui, abbiamo specificato iter_sampling = 4000, quindi ci sono 4000 campioni per ciascuna catena.\n4: Questo √® il numero di catene. Abbiamo specificato chains = 4, quindi ci sono 4 catene di campionamento eseguite in parallelo.\n9: Questo rappresenta il numero di parametri o quantit√† di interesse (inclusi parametri trasformati e quantit√† generate) che sono stati campionati. Include tutte le variabili definite nei blocchi parameters, transformed parameters e generated quantities del modello Stan.\n\nPossiamo recuperare i nomi delle variabili dall‚Äôoggetto trace e il numero di campioni a posteriori per ciascuna variabile nel modo seguente:\n\nvars = trace.stan_variables()\nfor (k,v) in vars.items():\n    print(k, v.shape)\n\ntheta (16000,)\ny_rep (16000,)\n\n\nRecuperiamo i campioni posteriori per theta:\n\ntheta_samples = trace.stan_variable('theta')\ntheta_samples.shape\n\n(16000,)\n\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\nplt.hist(theta_samples, bins=30, density=True, alpha=0.5, color='blue')\nplt.xlabel('Valori di $\\\\theta$')\nplt.ylabel('Frequenza')\nplt.title('Istogramma della Distribuzione a Posteriori di $\\\\theta$')\nplt.show()\n\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l‚Äôoggetto trace alle funzioni di ArviZ. La funzione plot_trace di ArviZ √® particolarmente adatta a questo scopo:\n\n_ = az.plot_trace(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nLa figura illustra il risultato predefinito ottenuto chiamando az.plot_trace; vengono generati due subplot per ogni variabile non osservata. Nella configurazione del nostro modello, l‚Äôunica variabile non osservata √® Œ∏. A sinistra, viene visualizzato un grafico di stima della densit√† del kernel (KDE), che rappresenta una versione liscia dell‚Äôistogramma. √à auspicabile che tutte le catene abbiano un KDE molto simile ad una gaussiana, come mostrato nella figura. A destra, vengono mostrati i valori individuali ad ogni passo di campionamento, con tante linee quanti sono i percorsi delle catene. L‚Äôideale √® che questa rappresentazione appaia rumorosa, senza un pattern chiaro, rendendo difficile l‚Äôidentificazione di una catena rispetto alle altre. Il concetto chiave √® che, eseguendo molte catene, ci aspettiamo che risultino praticamente indistinguibili l‚Äôuna dall‚Äôaltra. Nel caso presente, il campionatore ha svolto un buon lavoro e possiamo fiduciosi nei risultati ottenuti.\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha, beta_param = 4, 6\n\n# Creazione di un range di valori\nx = np.linspace(0, 1, 1000)\n\n# Calcolo della PDF\npdf = stats.beta.pdf(x, alpha, beta_param)\n\n# Visualizzazione della PDF\n_ = plt.plot(x, pdf, lw=2)\n\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ci√≤ indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.\n\n43.3.1 Intervallo di credibilit√†\nLa funzione az.plot_posterior ci consente di generare un grafico della distribuzione a posteriori che include la media e l‚Äôintervallo di credibilit√† HDI al 94%. Questo tipo di grafico √® stato presentato da John K. Kruschke nel suo libro ‚ÄúDoing Bayesian Data Analysis‚Äù Kruschke (2014).\n\n_ = az.plot_posterior(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nL‚Äôintervallo di credibilit√† fornisce una stima dell‚Äôintervallo entro cui il parametro si trova con una certa probabilit√†. Nel caso presente, l‚Äôintervallo di credibilit√† del 94% ci dice che, data la nostra comprensione a posteriori del parametro, c‚Äô√® il 94% di probabilit√† che il vero valore del parametro si trovi all‚Äôinterno dell‚Äôintervallo [0.1, 0.23].\nA differenza dell‚Äôintervallo di confidenza frequentista, che √® interpretato in termini di lungo termine su ripetuti campionamenti, l‚Äôintervallo di credibilit√† bayesiano √® direttamente interpretato come la probabilit√† che il parametro si trovi all‚Äôinterno di un certo intervallo dato il set di dati specifico.\nUn sommario numerico della distribuzione a posteriori si ottiene con la funzione az.summary, la quale ritorna una Pandas Data Frame:\n\naz.summary(trace, var_names=['theta'], kind=\"stats\").round(2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\ntheta\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\n\nNella prima colonna abbiamo il nome della variabile, nella seconda colonna troviamo la media del posteriore, nella terza colonna la deviazione standard del posteriore, e nelle ultime due colonne troviamo i limiti inferiore e superiore dell‚Äôintervallo di densit√† pi√π alta al 94%. Di conseguenza, secondo il nostro modello e i dati a disposizione, riteniamo che il valore di Œ∏ sia probabilmente 0.16, con una probabilit√† del 94% che si trovi effettivamente tra 0.1 e 0.23. Possiamo riportare un riassunto simile utilizzando la deviazione standard. Il vantaggio della deviazione standard rispetto all‚ÄôHDI √® che √® una statistica pi√π conosciuta. Come svantaggio, dobbiamo essere pi√π attenti nell‚Äôinterpretarla; altrimenti, potrebbe portare a risultati privi di significato. Nel caso presente, se calcoliamo la media ¬± 2 deviazioni standard, otterremo gli intervalli (0.08, 0.24) che sono simili ai limiti dell‚Äôintervallo HDI riportato sopra.\n\n[0.16 + i*0.04 for i in (-2, 2)]\n\n[0.08, 0.24]\n\n\nTuttavia, in alcuni casi, questa procedura potrebbe generare un limite inferiore o superiore al di fuori dell‚Äôintervallo consentito per i valori di Œ∏, il quale √® compreso tra 0 e 1.\n\n\n43.3.2 Test di Ipotesi Bayesiane\nIn alcune situazioni, la mera descrizione della distribuzione a posteriori non basta. Spesso ci troviamo di fronte alla necessit√† di fare scelte basate sulle nostre inferenze, traducendo stime continue in decisioni binarie: ad esempio, affermare se un individuo √® sano o malato, se un intervento ha avuto successo o meno, e cos√¨ via.\nPrendiamo come esempio la questione se, nel Museum of Modern Art (MoMA), gli artisti appartenenti alla generazione X rappresentino il 50% dell‚Äôintero corpus. Avvalendoci di un campione casuale di 100 opere, unitamente alle nostre convinzioni pregresse (prior), abbiamo determinato un Intervallo di Massima Densit√† (HDI) che va da 0.1 a 0.23. La nostra ipotesi prevede che Œ∏ (la proporzione degli artisti della generazione X) sia 0.5. Confrontando questo valore con l‚ÄôHDI ottenuto, osserviamo che 0.5 non rientra nell‚Äôintervallo [0.1, 0.23]. Questo risultato pu√≤ essere interpretato come un‚Äôindicazione che il MoMA manifesti una preferenza per artisti nati prima del periodo 1965-1980. Tuttavia, non possiamo escludere del tutto la possibilit√† che la generazione X contribuisca per met√† alle opere presenti nel museo. Per arrivare a una conclusione pi√π definita, sarebbe necessario raccogliere ulteriori dati per ridurre la variabilit√† della distribuzione a posteriori, o considerare l‚Äôadozione di un prior pi√π informativo per affinare la nostra analisi.\nOppure possiamo chiederci quale sia la probabilit√† che il valore a posteriori \\(\\theta\\) assuma un valore minore di 0.5. La funzione az.plot_posterior(idata, ref_val=0.5) ci dice che questa probabilit√† √® uguale a 1. Ovvero, possiamo essere del tutto certi che la proporzione di opere d‚Äôarte della generazione X rappresentate al MoMA sia minore del 50% del totale.\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.5)\n\n\n\n\n\n\n\n\nPossiamo usare qualsiasi valore di riferimento. Per esempio\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.20)",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.4 La Regione di Equivalenza Pratica (ROPE)",
    "text": "43.4 La Regione di Equivalenza Pratica (ROPE)\nLa Regione di Equivalenza Pratica (ROPE) costituisce un elemento chiave nei test di equivalenza, mirando a stabilire la rilevanza pratica di un parametro. Questa regione si allinea a un‚Äôipotesi nulla predefinita, permettendo di valutare se un parametro pu√≤ essere considerato equivalente rispetto a tale ipotesi.\n√à fondamentale comprendere che, data l‚Äôinfinita precisione teorica nella misurazione dei parametri, la probabilit√† di identificare un valore esatto di un parametro √® sempre uguale a zero. Pertanto, l‚Äôanalisi si concentra non sull‚Äôottenimento di valori precisi, ma piuttosto su valori che rientrano in un intervallo di accettabilit√† prefissato.\nIl metodo decisionale ‚ÄúHDI+ROPE‚Äù (Kruschke, 2014; Kruschke & Liddell, 2018) viene frequentemente utilizzato per determinare se i valori di un parametro debbano essere considerati accettabili o meno in relazione all‚Äôipotesi nulla delineata dalla ROPE. Questo metodo esamina la percentuale dell‚ÄôIntervallo Credibile (CI) che si trova all‚Äôinterno della ROPE, considerata come regione corrispondente all‚Äôipotesi nulla. Se questa percentuale √® notevolmente bassa, l‚Äôipotesi nulla viene scartata; viceversa, se √® elevata, l‚Äôipotesi viene accettata.\nPer illustrare, consideriamo l‚Äôesempio di una moneta teoricamente equilibrata, la cui probabilit√† di ottenere ‚Äútesta‚Äù si vuole sia vicina al valore teorico di 0.5. Al posto di focalizzarsi esclusivamente sul valore esatto di 0.5, possiamo definire una ROPE, ad esempio tra [0.45, 0.55]. Tale intervallo viene considerato praticamente equivalente a 0.5 ai fini della nostra analisi, consentendo di valutare l‚Äôequit√† della moneta tenendo conto delle naturali fluttuazioni nelle misurazioni.\nDopo aver definito la ROPE, confrontiamo il nostro risultato con l‚Äôintervallo di densit√† pi√π alta (HDI). Da questo confronto emergono tre possibili scenari:\n\nAssenza di sovrapposizione tra ROPE e HDI: Indica che i risultati ottenuti sono sufficientemente distanti dall‚Äôintervallo di equivalenza pratica, portando al rifiuto dell‚Äôipotesi di equivalenza. Questo scenario suggerisce che il parametro analizzato ha un impatto pratico che va oltre l‚Äôipotesi di nullit√† considerata dalla ROPE.\nLa ROPE include completamente l‚ÄôHDI: Questo scenario si verifica quando l‚Äôintero intervallo di densit√† pi√π alta cade all‚Äôinterno della ROPE, indicando che i risultati sono pienamente compatibili con l‚Äôipotesi di nullit√†. In questo caso, possiamo accettare l‚Äôipotesi che il parametro sia praticamente equivalente all‚Äôipotesi nulla, suggerendo una mancanza di significativit√† pratica del parametro in esame.\nSovrapposizione parziale tra ROPE e HDI: In questo caso, una porzione dell‚ÄôHDI si sovrappone con la ROPE, ma non completamente. Questo risultato implica che non possiamo trarre conclusioni definitive riguardo all‚Äôequivalenza pratica del parametro rispetto all‚Äôipotesi nulla. Si rende necessaria un‚Äôulteriore analisi o l‚Äôimpiego di altri criteri decisionali per determinare la rilevanza pratica del parametro.\n\nConsiderando un esempio relativo all‚Äôanalisi dei dati della Generazione X, con una ROPE definita come [0.25, 0.35].\n\n_ = az.plot_posterior(trace, var_names=['theta'], rope=[0.25, .35])\n\n\n\n\n\n\n\n\nLa ROPE cos√¨ definita corrisponde all‚Äôipotesi del parametro \\(\\theta\\) = 0.3 e considerando equivalenti i valori osservati nell‚Äôintervallo [0.25, 0.35].\nL‚Äôanalisi mostra che l‚ÄôHDI non si sovrappone alla ROPE. Inoltre, solo l‚Äô1.3% della distribuzione a posteriori √® contenuta nella ROPE. Possiamo dunque rifiutare l‚Äôipotesi specificata dalla ROPE.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.5 Estrazione degli attributi da InferenceData",
    "text": "43.5 Estrazione degli attributi da InferenceData\nVediamo ora nei dettagli come sia possibile effettuare le varie operazioni sulla distribuzione a posteriori, ovvero la stima puntuale, gli intervalli di credibilit√† e i test di ipotesi, mediante la manipolazione dell‚Äôoggetto theta_draws ottenuto dalla funzione sample.stan_variable().",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#stima-puntuale",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#stima-puntuale",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.6 Stima puntuale",
    "text": "43.6 Stima puntuale\nPossiamo recuperare la traccia di campionamento dalla variabile latente theta nel modo seguente:\n\ntheta_draws = trace.stan_variable('theta')\ntheta_draws.shape\n\n(16000,)\n\n\nIn cmdstanpy, quando si utilizza il metodo stan_variable per estrarre i campioni di un parametro specifico dai campioni posteriori, questo restituisce un array numpy contenente i campioni.\nIl metodo stan_variable('theta') estrae tutti i campioni per il parametro theta dalla distribuzione posteriore. Questo include i campioni da tutte le catene e tutte le iterazioni dopo il warmup. Il risultato, theta_draws, √® un array numpy in cui i campioni di tutte le catene sono concatenati insieme. La forma di theta_draws √® tipicamente (num_samples * num_chains, ) se theta √® un parametro scalare, o (num_samples * num_chains, dim1, dim2, ...) se theta √® un vettore o una matrice. I campioni delle 4 catene sono concatenati. Questo significa che i campioni di ciascuna catena sono aggiunti uno dopo l‚Äôaltro in un singolo array. Non sono mescolati insieme in modo casuale; piuttosto, sono semplicemente posizionati in sequenza.\nPer visualizzare il primi 30 valori di theta_draws, ad esempio, usiamo:\n\ntheta_draws[0:30]\n\narray([0.152399, 0.164544, 0.185841, 0.210788, 0.210788, 0.158488,\n       0.152418, 0.117835, 0.161514, 0.168753, 0.137032, 0.162867,\n       0.168521, 0.182565, 0.123249, 0.114717, 0.123867, 0.128263,\n       0.171871, 0.142336, 0.204677, 0.221803, 0.171478, 0.121296,\n       0.108108, 0.199047, 0.133709, 0.138647, 0.144356, 0.174385])\n\n\nDi conseguenza, possiamo calcolare su theta_draws tutte le misure statistiche descrittive che si possono ottenere da un vettore di dati. Per esempio, possiamo calcolare la media a posteriori.\n\nnp.mean(theta_draws)\n\n0.16424613186875\n\n\nPossiamo calcolare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(theta_draws)\n\n0.16208250000000002\n\n\nOppure la deviazione standard della stima a posteriori di \\(\\theta\\).\n\nnp.std(theta_draws)\n\n0.03521655992174475",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#intervallo-di-credibilit√†-1",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#intervallo-di-credibilit√†-1",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.7 Intervallo di credibilit√†",
    "text": "43.7 Intervallo di credibilit√†\nL‚Äôinferenza bayesiana tramite l‚Äôintervallo di credibilit√† riguarda invece la stima dell‚Äôintervallo che contiene il parametro \\(\\theta\\) ad un dato livello di probabilit√† soggettiva.\nUsando l‚Äôoggetto sample, possiamo ottenere un sommario della distribuzione a posteriori con il metodo az.summary().\n\naz.summary(trace, var_names=['theta'], hdi_prob=0.94, round_to=3)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta\n0.164\n0.035\n0.1\n0.231\n0.0\n0.0\n5412.045\n7678.797\n1.0\n\n\n\n\n\n\n\n\nSi ottiene cos√¨ l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPD) al 94%. Questo intervallo ci informa sul fatto che, a posteriori, possiamo essere certi al 94%, che il vero valore del parametro \\(\\theta\\) sia contenuto nell‚Äôintervallo [0.103, 0.23].\nDato che, nel caso presente, conosciamo la soluziona analitica, possiamo verificare il risultato precedente calcolando i quantili della distribuzione a posteriori Beta(18, 92) di ordine 0.03 e 0.97.\n\nll = stats.beta.ppf(0.03, 18, 92)\nul = stats.beta.ppf(0.97, 18, 92)\nlist([ll, ul])\n\n[0.10303527075398665, 0.23457657606771784]",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.8 Verifica di ipotesi bayesiana",
    "text": "43.8 Verifica di ipotesi bayesiana\nUn secondo tipo di inferenza bayesiana riguarda problemi in cui siamo interessati a valutare la plausibilit√† che il parametro \\(\\theta\\) assuma valori contenuti in un dato intervallo di valori. Per esempio, ci potrebbe interessare l‚Äôipotesi \\(\\theta &gt; 0.5\\). In questo caso, possiamo calcolare la probabilit√† a posteriori che \\(\\theta\\) cada nell‚Äôintervallo di interesse, integrando la distribuzione a posteriori Beta su tale intervallo.\nNel caso dell‚Äôesempio degli artisti della Generazione X, supponiamo di essere interessati alle due seguenti ipotesi:\n\\[\n\\begin{split}\nH_0: & \\; \\; \\pi \\ge 0.2 \\\\\nH_a: & \\; \\; \\pi &lt; 0.2\n\\end{split}\n\\]\nLa nostra domanda √® la seguente: Date le nostre credenze iniziali e i dati disponibili, quale importanza relativa possiamo attribuire a queste due ipotesi?\nPer affrontare questa questione, iniziamo a calcolare la probabilit√† \\(P(\\theta &lt; 0.2)\\).\n\nprint(np.mean(theta_draws &lt; 0.2))\n\n0.846125\n\n\nPassiamo ora a calcolare gli odds a posteriori:\n\npost_odds = (np.mean(theta_draws &lt; 0.2)) / (1 - np.mean(theta_draws &lt; 0.2))\nprint(post_odds)\n\n5.498781478472787\n\n\nCi√≤ implica che la probabilit√† che \\(\\pi\\) sia inferiore al 20% √® circa 6 volte superiore rispetto alla probabilit√† che sia al di sopra del 20%.\nQuesto risultato si basa solo sulle informazioni relative alla distribuzione a posteriori. Prima di avere osservato i dati del campione, avevamo una distribuzione a priori \\(\\operatorname{Beta}(6, 4)\\), e in quel contesto avevamo una probabilit√† del 9% che \\(H_a\\) fosse vera e una probabilit√† del 91% che fosse falsa.\n\nthreshold = 0.2\nprior_prob = stats.beta.cdf(threshold, a=4, b=6)\n\n\nprior_odds = prior_prob / (1 - prior_prob)\nprint(prior_odds)\n\n0.09366320688790145\n\n\nOra possiamo combinare le informazioni degli odds a posteriori e degli odds a priori in una quantit√† chiamata Bayes Factor, che √® semplicemente il rapporto tra le due:\n\nBF = post_odds / prior_odds\nprint(BF)\n\n58.70802058970575\n\n\nIn conclusione, dopo aver appreso informazioni riguardo a 14 artisti appartenenti alla generazione X, le probabilit√† posteriori della nostra ipotesi \\(H_a: \\; \\pi &lt; 0.2\\) sono circa 60 volte superiori rispetto alle probabilit√† a priori.\nQuesto √® un esempio di test di ipotesi bayesiano.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "43.9 Commenti e considerazioni finali",
    "text": "43.9 Commenti e considerazioni finali\nLa crescente popolarit√† dei metodi bayesiani in psicologia e nelle scienze sociali √® stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un‚Äôintroduzione a cmdstanpy, un‚Äôimplementazione in Python di cmdstan, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, √® possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacit√† di effettuare inferenze bayesiane e rendendo l‚Äôanalisi di modelli complessi pi√π accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalit√† per ottenere intervalli di credibilit√†. Successivamente, √® stata discussa l‚Äôanalisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\). In alcune situazioni, questo confronto viene tradotto in una misura denominata Fattore di Bayes.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/16_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/16_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "43¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nmatplotlib: 3.8.4\ncmdstanpy : 1.2.3\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n# Stampa la versione di CmdStan\nprint(\"CmdStan version:\", cmdstanpy.utils.cmdstan_version())\n\nCmdStan version: (2, 35)\n\n\n\n\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html",
    "href": "chapters/chapter_4/17_stan_diagnostics.html",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "",
    "text": "Introduzione\nLe catene di Markov sono utilizzate per approssimare la distribuzione a posteriori. Tuttavia, √® fondamentale riconoscere che tale approssimazione √® soggetta a errori e imperfezioni. Schoot et al. (2020) propongono una When-to-Worry- and-How-to-Avoid-the-Misuse-of-Bayesian-Statistics (WAMBS) checklist.\nLa diagnostica delle catene Markoviane, quindi, si configura come un insieme di pratiche e strumenti mirati a indagare vari aspetti della convergenza. Questi includono l‚Äôaccuratezza dell‚Äôapprossimazione della distribuzione a posteriori, l‚Äôefficienza del campionamento e l‚Äôesplorazione esaustiva dello spazio dei parametri. Tali strumenti diagnostici possono essere sia grafici che numerici e dovrebbero essere applicati in un contesto olistico per fornire una panoramica completa della qualit√† della catena di Markov.\nNon esiste un‚Äôunica metrica o diagnostico che possa fornire un quadro completo; piuttosto, √® l‚Äôanalisi combinata di pi√π metriche e diagnostici che permette di acquisire una comprensione pi√π profonda del comportamento della catena. Inoltre, l‚Äôesperienza del ricercatore gioca un ruolo significativo nel distinguere tra una ‚Äúbuona‚Äù e una ‚Äúcattiva‚Äù catena di Markov e nel suggerire strategie per migliorare la qualit√† del campionamento.\nIn sintesi, l‚Äôanalisi della convergenza e la diagnostica delle catene Markoviane sono fasi imprescindibili nel processo di inferenza bayesiana, soprattutto quando si utilizzano metodi MCMC. La loro applicazione consente di garantire che le stime a posteriori siano tanto accurate e affidabili quanto possibile.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#grafici-di-tracciamento",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#grafici-di-tracciamento",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.1 Grafici di Tracciamento",
    "text": "44.1 Grafici di Tracciamento\nUn metodo diagnostico comunemente utilizzato per valutare la convergenza nei metodi di Monte Carlo basati su catene di Markov (MCMC) √® l‚Äôanalisi dei grafici di tracciamento, o ‚Äútrace plots‚Äù. Questi grafici rappresentano sequenzialmente le stime dei parametri posteriori ottenute ad ogni iterazione della catena. In generale, si tende a interpretare che un parametro sta convergendo quando le stime campionarie si aggregano in una banda orizzontale ristretta lungo l‚Äôasse delle iterazioni che compongono la catena. Tuttavia, considerare questa disposizione come prova conclusiva di convergenza √® piuttosto grossolano, in quanto una traccia compatta non garantisce che la convergenza sia stata effettivamente raggiunta. Di fatto, questa metodologia risulta essere pi√π un indicatore di non-convergenza. Ad esempio, se due catene per lo stesso parametro sono campionate da regioni diverse della distribuzione target e le stime rimangono separate lungo la storia della catena, ci√≤ costituisce un‚Äôevidenza di non-convergenza. Allo stesso modo, se il grafico mostra fluttuazioni significative o salti nella catena, √® probabile che la catena associata a quel parametro non abbia raggiunto la convergenza.\nUn trace plot ideale presenta una dispersione casuale dei valori attorno a un livello medio stabile, indicando una buona miscelazione delle catene e un‚Äôadeguata configurazione del processo MCMC. Questo pattern suggerisce che l‚Äôalgoritmo √® assestato su una distribuzione stabile e le inferenze tratte dai dati campionati sono affidabili.\nApprofondendo con l‚Äôesempio di Martin, Kumar, e Lao (2022), √® possibile osservare diversi esempi di trace plots per catene MCMC. Questi esempi illustrano sia scenari in cui il comportamento √® ottimale, segnalando una convergenza adeguata, sia casi in cui le catene mostrano segni di problemi di convergenza o di miscelazione. Tali situazioni indicano la necessit√† di un‚Äôulteriore affinazione dei parametri dell‚Äôalgoritmo MCMC per garantire l‚Äôaffidabilit√† delle stime statistiche ottenute.\n\ngood_chains = stats.beta.rvs(2, 5, size=(2, 2000))\nbad_chains0 = np.random.normal(\n    np.sort(good_chains, axis=None), 0.05, size=4000\n).reshape(2, -1)\n\nbad_chains1 = good_chains.copy()\nfor i in np.random.randint(1900, size=4):\n    bad_chains1[i % 2 :, i : i + 100] = np.random.beta(i, 950, size=100)\n\nchains = {\n    \"good_chains\": good_chains,\n    \"bad_chains0\": bad_chains0,\n    \"bad_chains1\": bad_chains1,\n}\n\n\naz.plot_trace(chains)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2425599176.py:2: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe cattive catene non convergono n√© si mescolano tra loro. Uno dei motivi per l‚Äôesecuzione di pi√π catene √® che ogni singola catena potrebbe convergere verso un target, mentre un‚Äôaltra catena potrebbe convergere su un target diverso, e questo sarebbe un problema. Inoltre, catene altrimenti sane possono bloccarsi occasionalmente nel corso della serie, il che suggerirebbe la necessit√† di modifiche al modello o alle impostazioni del campionatore. Un altro modo per valutare la convergenza dell‚Äôalgoritmo √® plottando la densit√† della distribuzione a posteriori degli effetti stimati, per assicurarsi che si avvicini ad una classica curva a campana.\nIn pratica, non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perch√© la diagnostica delle catene di Markov √® cos√¨ importante: se vediamo trace-plots come le precedenti ‚Äúbad chains‚Äù, sappiamo che non abbiamo ottenuto una approssimazione adeguata della distribuzione a posteriori. In tali circostanze possiamo ricorrere ad alcuni rimedi.\n\nControllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?\nUtilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#i-grafici-della-densit√†-posteriore-sono-adeguati",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#i-grafici-della-densit√†-posteriore-sono-adeguati",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.2 I Grafici della Densit√† Posteriore Sono Adeguati?",
    "text": "44.2 I Grafici della Densit√† Posteriore Sono Adeguati?\nI grafici della densit√† posteriore rappresentano uno degli strumenti diagnostici pi√π efficaci per identificare eventuali anomalie nella convergenza delle catene di Markov nell‚Äôanalisi bayesiana. Questi grafici mostrano la distribuzione dei valori campionati per ogni parametro del modello statistico e per ogni catena di Markov. L‚Äôimportanza di questi grafici √® primaria: essi sono la base da cui deriviamo le statistiche riassuntive dei parametri del modello, quali la media, la mediana, o l‚Äôintervallo di credibilit√†.\nPrendiamo come esempio un parametro di interesse in un modello di regressione che assume una distribuzione a priori gaussiana (normale). In un contesto ideale, senza problemi di convergenza, ci aspetteremmo che la densit√† posteriore del parametro sia anch‚Äôessa normalmente distribuita, centrata intorno a una media con una certa varianza. Questo andamento simmetrico e unimodale della densit√† posteriore √® un segnale che la catena di Markov ha esplorato adeguatamente lo spazio dei parametri e che i campioni estratti possono essere considerati rappresentativi della distribuzione posteriore effettiva del parametro.\nTuttavia, se il grafico della densit√† posteriore mostra deviazioni significative dalla forma attesa, come ad esempio asimmetrie marcate o bimodalit√†, questo suggerisce che potrebbero esserci problemi nella convergenza della catena al vero valore del parametro. Una distribuzione bimodale, in particolare, pu√≤ indicare che la catena √® rimasta ‚Äúintrappolata‚Äù in aree locali dello spazio dei parametri, senza riuscire a esplorare adeguatamente l‚Äôintero spazio e raggiungere l‚Äôequilibrio.\nPer risolvere tali problemi e ottenere una stima pi√π accurata della distribuzione posteriore, potremmo considerare diverse strategie:\n\nAumentare il Numero di Iterazioni: Incrementare il numero delle iterazioni delle catene di Markov pu√≤ permettere una migliore esplorazione dello spazio dei parametri e aiutare a superare le barriere tra i picchi di una distribuzione bimodale.\nOttimizzazione delle Distribuzioni a Priori: La scelta delle distribuzioni a priori pu√≤ influenzare fortemente la convergenza della catena. Selezionare priori pi√π informativi o pi√π flessibili pu√≤ aiutare la catena a guidare l‚Äôesplorazione dello spazio dei parametri in modo pi√π efficace.\nAffinamento dei Parametri dell‚ÄôAlgoritmo MCMC: Modificare i parametri di configurazione dell‚Äôalgoritmo MCMC, come il passo del campionamento o i criteri di accettazione, pu√≤ migliorare la qualit√† del campionamento e favorire una convergenza pi√π rapida e stabile.\n\nIn definitiva, l‚Äôanalisi dei grafici della densit√† posteriore non solo fornisce una stima visiva dell‚Äôandamento dei parametri, ma serve anche come fondamento per decisioni metodologiche che possono migliorare la robustezza e l‚Äôaffidabilit√† delle inferenze bayesiane.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-√®-troppo-alta",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-√®-troppo-alta",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.3 L‚ÄôAutocorrelazione nelle Catene di Markov Monte Carlo √à Troppo Alta?",
    "text": "44.3 L‚ÄôAutocorrelazione nelle Catene di Markov Monte Carlo √à Troppo Alta?\nNell‚Äôambito dell‚Äôanalisi bayesiana tramite le catene di Markov Monte Carlo (MCMC), √® di fondamentale importanza valutare la rapidit√† con cui i campioni estratti dalla distribuzione a posteriori raggiungono l‚Äôindipendenza. Inizialmente, come √® noto, i campioni della distribuzione a posteriori non sono indipendenti l‚Äôuno dall‚Äôaltro, ma ci si aspetta che, nel tempo, la catena ‚Äúdimentichi‚Äù il suo stato iniziale e converga verso un insieme di estrazioni indipendenti e stazionarie dalla distribuzione a posteriori.\nUna metodologia per determinare la velocit√† con cui la catena si allontana dallo stato iniziale √® l‚Äôanalisi della funzione di autocorrelazione (ACF), che si basa sull‚Äôosservazione che un campione \\(\\theta^{(s)}\\) tende a essere pi√π simile al campione immediatamente precedente \\(\\theta^{(s-1)}\\) rispetto a quelli pi√π distanti come \\(\\theta^{(s-2)}\\), \\(\\theta^{(s-3)}\\), e cos√¨ via. La correlazione di lag-l per una catena stazionaria di Markov, dove \\(s = 1, \\ldots, S\\), pu√≤ essere espressa come:\n\\[\n\\rho_l = \\text{cor}(\\theta^{(s)}, \\theta^{(s+l)}).\n\\]\nIn generale, ci aspettiamo che l‚Äôautocorrelazione a lag-1 sia vicina a 1, ma che diminuisca man mano che il lag aumenta, indicando che i componenti della catena stanno diventando indipendenti. Una riduzione rapida dell‚Äôautocorrelazione con il numero di iterazioni √® preferibile, poich√© una lenta diminuzione pu√≤ suggerire che la catena sia ‚Äúintrappolata‚Äù e non esplori completamente il supporto della distribuzione target.\nIl correlogramma, che mostra l‚Äôautocorrelazione in funzione dei ritardi fino a un certo valore (ad esempio 20), √® utile per valutare questa caratteristica. Se l‚Äôautocorrelazione a lag 1 non √® eccessivamente alta e diminuisce rapidamente con l‚Äôincremento dei lag, ci√≤ indica che la catena sta fornendo una buona approssimazione di un campionamento casuale dalla distribuzione \\(p(\\theta \\mid y)\\).\nCatene che mostrano un rapido ‚Äúmixing‚Äù si comportano in modo simile a un campione indipendente: i valori si concentrano nei range pi√π plausibili della distribuzione a posteriori e l‚Äôautocorrelazione tra i campioni diminuisce rapidamente, risultando in un rapporto campionario effettivo alto. Al contrario, catene che non sono rapidamente ‚Äúmixing‚Äù tendono a non concentrarsi nei valori pi√π plausibili, presentano un‚Äôautocorrelazione che diminuisce lentamente e un rapporto campionario effettivo basso.\nIn caso di catene non rapidamente ‚Äúmixing‚Äù, si possono adottare due strategie:\n\nAumento del Numero di Iterazioni: Anche una catena lenta nel ‚Äúmixing‚Äù pu√≤ alla fine fornire una buona approssimazione della distribuzione a posteriori se si permette un numero sufficientemente grande di iterazioni.\nThinning (Diradamento): Questo processo consiste nel selezionare solo alcuni campioni a intervalli regolari, come ogni secondo o ogni decimo valore della catena, con l‚Äôobiettivo di ridurre le autocorrelazioni presenti nei lag pi√π brevi.\n\nUn esempio pratico √® fornito da Martin, Kumar, e Lao (2022).\n\nfig, ax = plt.subplots(3, 1)  \naz.plot_autocorr(chains, combined=True, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/4208770402.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#la-dimensione-effettiva-del-campione-√®-sufficiente",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#la-dimensione-effettiva-del-campione-√®-sufficiente",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.4 La Dimensione Effettiva del Campione √à Sufficiente?",
    "text": "44.4 La Dimensione Effettiva del Campione √à Sufficiente?\nNell‚Äôambito delle analisi con catene di Markov Monte Carlo (MCMC), un aspetto strettamente correlato alla diagnosi di autocorrelazione √® la dimensione effettiva del campione, indicata con \\(N_{\\text{eff}}\\) nell‚Äôoutput del software Stan. Questa grandezza rappresenta una stima del numero di estrazioni indipendenti dalla distribuzione a posteriori. In altre parole, corrisponde al numero di campioni indipendenti che possiede lo stesso potere di stima di \\(T\\) campioni autocorrelati. Seguendo la notazione di Stan, la \\(N_{\\text{eff}}\\) √® calcolata come segue:\n\\[\nN_{\\text{eff}} = \\frac{T}{1 + 2 \\sum_{s=1}^{S} \\rho_{s}},\n\\]\ndove \\(T\\) √® il numero totale di campioni e \\(\\rho_{s}\\) rappresenta l‚Äôautocorrelazione a lag \\(s\\).\nPoich√© i campioni della distribuzione a posteriori non sono indipendenti, ci aspettiamo che la \\(N_{\\text{eff}}\\) sia minore del numero totale di estrazioni. Se il rapporto tra la dimensione effettiva del campione e il numero totale di estrazioni √® vicino a 1, ci√≤ indica che l‚Äôalgoritmo ha raggiunto un campionamento sostanzialmente indipendente. Valori molto inferiori potrebbero essere motivo di preoccupazione poich√© indicano una forte dipendenza tra i campioni, ma √® importante notare che questo rapporto dipende fortemente dalla scelta dell‚Äôalgoritmo MCMC, dal numero di iterazioni di ‚Äúwarmup‚Äù (o ‚Äúburn-in‚Äù), e dal numero di iterazioni successive al ‚Äúwarmup‚Äù.\nUn metodo per affrontare il problema dell‚Äôautocorrelazione e del conseguente abbassamento della dimensione effettiva del campione coinvolge l‚Äôuso del diradamento (thinning). Supponiamo che l‚Äôalgoritmo venga impostato per effettuare 3.000 estrazioni dalla distribuzione a posteriori. Questo pu√≤ essere paragonato a effettuare 30.000 estrazioni ma conservando solo ogni decima. Sebbene questo metodo sia un modo per ridurre il carico sulla memoria, il vantaggio √® che tipicamente l‚Äôautocorrelazione viene ridotta, risultando in una dimensione effettiva del campione maggiore.\nPer distinguere tra buone e cattive catene MCMC, possiamo utilizzare la statistica \\(N_{\\text{eff}}\\). Un basso valore di \\(N_{\\text{eff}}\\) pu√≤ indicare una catena con una mescolanza insufficiente, suggerendo la necessit√† di aumentare il numero di iterazioni o di implementare il diradamento. In contrasto, un valore alto di \\(N_{\\text{eff}}\\) √® indice di una catena con una buona mescolanza, che assicura un campionamento efficace dalla distribuzione a posteriori. Esempi pratici di queste considerazioni sono illustrati in Martin, Kumar, e Lao (2022), dove la statistica \\(N_{\\text{eff}}\\) √® utilizzata per valutare la qualit√† delle catene MCMC.\n\n_, axes = plt.subplots(2, 3, sharey=True, sharex=True)\naz.plot_ess(chains, kind=\"local\", ax=axes[0])\naz.plot_ess(chains, kind=\"quantile\", ax=axes[1])\n\nfor ax_ in axes[0]:\n    ax_.set_xlabel(\"\")\nfor ax_ in axes[1]:\n    ax_.set_title(\"\")\n\nfor ax_ in axes[:, 1:].ravel():\n    ax_.set_ylabel(\"\")\nplt.ylim(-100, 5000);",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#la-statistica-hatr-√®-prossima-a-uno",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#la-statistica-hatr-√®-prossima-a-uno",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.5 La Statistica \\(\\hat{R}\\) √à Prossima a Uno?",
    "text": "44.5 La Statistica \\(\\hat{R}\\) √à Prossima a Uno?\nNell‚Äôambito dell‚Äôanalisi bayesiana, √® cruciale assicurarsi che ogni catena di Markov sia stazionaria e che le diverse catene mostrino coerenza tra loro. La statistica \\(\\hat{R}\\), introdotta da Gelman e Rubin nel 1992, serve proprio a valutare il grado di convergenza tra pi√π catene per ciascun parametro in esame. Questo indicatore si basa sul confronto tra due tipi di varianza: la varianza media all‚Äôinterno di ogni singola catena (W) e la varianza tra le diverse catene (B). Questo metodo ricorda l‚Äôapproccio dell‚Äôanalisi della varianza unidirezionale, in cui si confrontano stime di varianza per determinare se esistono differenze significative, in questo caso tra le catene.\nLa formula per calcolare \\(\\hat{R}\\) √® \\(\\hat{R} = \\frac{W + \\frac{1}{n} (B - W)}{W}\\), e tale metrica viene calcolata automaticamente dalla maggior parte dei software Bayesiani, come indicato da Gelman e collaboratori nel 2014. Nel contesto pratico, un valore di \\(\\hat{R}\\) superiore a 1.1 √® generalmente considerato un segnale di convergenza inadeguata delle catene. Inoltre, √® fondamentale esaminare visivamente la convergenza delle catene attraverso il confronto delle distribuzioni posteriori di ciascun parametro per ogni catena. In condizioni ideali, \\(\\hat{R}\\) dovrebbe essere pari a 1. Se \\(\\hat{R}\\) si discosta notevolmente da questo valore, ci√≤ indica che la convergenza non √® stata ancora raggiunta.\nPi√π specificamente, un valore di \\(\\hat{R}\\) maggiore di 1.01, secondo Vehtari et al. (2021), segnala una mancanza di coerenza nelle approssimazioni della distribuzione a posteriori ottenute dalle diverse catene parallele. Un valore cos√¨ elevato di \\(\\hat{R}\\) suggerisce una simulazione non stabile, indicando la necessit√† di ulteriori iterazioni o di un raffinamento del modello per garantire una convergenza affidabile. Questo aspetto √® fondamentale per assicurare che le simulazioni Monte Carlo basate su catene di Markov (MCMC) forniscano risultati consistenti e attendibili per l‚Äôanalisi statistica in corso.\n\naz.rhat(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 2.43\n    bad_chains1  float64 8B 1.018\n    good_chains  float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float642.43array(2.42962207)bad_chains1()float641.018array(1.01782964)good_chains()float641.001array(1.00080843)Indexes: (0)Attributes: (0)\n\n\nNell‚Äôesempio di Martin, Kumar, e Lao (2022) vediamo come \\(\\hat{R}\\) √® in grado di distinguere tra le buone e le cattive catene MCMC. Mentre bad_chains0 ha valori \\(\\hat{R}\\) totalmente inadeguati, bad_chains1 tende ad avere valori accettabili e good_chains ha un valore \\(\\hat{R}\\) praticamente uguale a 1.0.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#la-diagnostica-di-geweke-√®-prossima-a-zero",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#la-diagnostica-di-geweke-√®-prossima-a-zero",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.6 La Diagnostica di Geweke √à Prossima a Zero?",
    "text": "44.6 La Diagnostica di Geweke √à Prossima a Zero?\nLa statistica diagnostica di convergenza di Geweke √® basata su un test per l‚Äôuguaglianza delle medie della prima e dell‚Äôultima parte di una catena di Markov (di default il primo 10% e l‚Äôultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.\nInterpretazione: la statistica di Geweke √® uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali; valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#lerrore-standard-di-monte-carlo-√®-piccolo",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#lerrore-standard-di-monte-carlo-√®-piccolo",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.7 L‚ÄôErrore Standard di Monte Carlo √à Piccolo?",
    "text": "44.7 L‚ÄôErrore Standard di Monte Carlo √à Piccolo?\nQuando utilizziamo i metodi MCMC introduciamo un ulteriore livello di incertezza poich√© stiamo approssimando il posteriore con un numero finito di campioni. Possiamo stimare la quantit√† di questo tipo di errore mediante la statistica errore standard di Monte Carlo (MCSE). Il MCSE √® definitp come la deviazione standard delle catene MCMC divisa per la loro numerosit√† campionaria effettiva (ESS). Il MCSE ci fornisce dunque un‚Äôindicazione quantitativa di quanto √® grande sia il ‚Äúrumore‚Äù della stima.\nPer l‚Äôesempio di Martin, Kumar, e Lao (2022) otteniamo i valori seguenti.\n\naz.mcse(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 0.1087\n    bad_chains1  float64 8B 0.01616\n    good_chains  float64 8B 0.002583xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float640.1087array(0.10870935)bad_chains1()float640.01616array(0.01615769)good_chains()float640.002583array(0.00258312)Indexes: (0)Attributes: (0)\n\n\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 9))  \naz.plot_mcse(chains, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/1242931680.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.8 I Grafici di Rango Sono Piatti?",
    "text": "44.8 I Grafici di Rango Sono Piatti?\nIn alcune situazioni, l‚Äôinterpretazione dei grafici di traccia pu√≤ risultare estremamente complessa. Ad esempio, quando si raccolgono un numero molto elevato di campioni, comprimere lunghe tracce in un grafico di dimensioni standard pu√≤ occultare alcuni comportamenti problematici delle catene, facendo apparire erroneamente buone le tracce. Giudicare i grafici di traccia pu√≤ essere difficile anche quando le distribuzioni sono fortemente asimmetriche e/o a code pesanti. Per queste ragioni, ora si raccomanda di utilizzare i grafici di rango oltre, se non al posto, dei grafici di traccia, in modo che qualsiasi differenza nei valori campionati da ogni catena possa essere riconosciuta in un modo pi√π affidabile (Vehtari et al., 2021).\nIn statistica, il ‚Äúrango‚Äù di un‚Äôosservazione √® la sua posizione in un insieme di dati ordinati. Ad esempio, consideriamo il seguente insieme di dati: [5, 3, 8, 10]. Se ordiniamo questi dati in ordine crescente otterremo [3, 5, 8, 10]. In questo caso, il rango del numero 5 √® 2 perch√© √® il secondo numero nell‚Äôinsieme ordinato. Allo stesso modo, il rango del numero 10 √® 4 perch√© √® il quarto numero nell‚Äôinsieme ordinato.\nI grafici di rango rappresentano un nuovo strumento diagnostico che si ottiene ordinando i campioni aggregati da tutte le catene, e poi presentando un istogramma dei ranghi derivanti da ogni catena separatamente. Se tutte le catene hanno come target la stessa distribuzione, allora la distribuzione dei ranghi per ogni catena dovrebbe approssimare una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ci√≤ indica una buon mixing delle catene. Le deviazioni dall‚Äôuniformit√† possono indicare una vasta gamma di problemi di convergenza. Qui sotto √® riportato l‚Äôesempio fornito da Martin, Kumar, e Lao (2022):\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"bars\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2441558539.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa (con dei segmenti verticali al posto delle barre) √® la seguente:\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"vlines\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_24737/353816278.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.9 Ci Sono Transizioni Divergenti?",
    "text": "44.9 Ci Sono Transizioni Divergenti?\nQuando usiamo l‚Äôalgoritmo di campionamento Hamiltonian Monte Carlo (HMC), √® molto importante assicurarci che non ci siano ‚Äútransizioni divergenti‚Äù riportate nei risultati. Idealmente, il numero di queste transizioni dovrebbe essere zero. Una transizione divergente √® come un segnale di allarme che ci avverte di possibili problemi nella fase in cui l‚Äôalgoritmo esplora i vari parametri. In pratica, indica che l‚Äôalgoritmo non √® riuscito a esaminare correttamente alcune aree dello spazio dei parametri.\nOgni volta che notiamo una transizione divergente, dobbiamo indagare attentamente il motivo. La presenza di queste transizioni ci dice che l‚Äôalgoritmo potrebbe non avere esplorato adeguatamente certe zone, mettendo a rischio l‚Äôaffidabilit√† delle conclusioni del nostro studio. In presenza di divergenze, i campioni risultanti non possono essere considerati affidabili e, pertanto, non dovrebbero essere impiegati per la stima dei parametri, il confronto tra modelli, o qualsiasi altra forma di inferenza statistica Gelman et al. (2020).\nPer capire e risolvere il problema delle transizioni divergenti, possiamo considerare diverse soluzioni:\n\nControllo dei dati: √à utile controllare se ci sono dati anormali o estremi che potrebbero complicare il lavoro dell‚Äôalgoritmo.\nValutazione delle distribuzioni a priori: Dobbiamo assicurarci che le distribuzioni a priori usate si adattino bene al modello e ai dati che stiamo analizzando. Se non sono appropriate, possono creare problemi durante l‚Äôesplorazione dello spazio dei parametri.\nRegolazione della dimensione del passo: √à importante controllare e, se necessario, modificare la dimensione del passo (o step size) dell‚Äôalgoritmo HMC. Un passo troppo lungo o troppo breve pu√≤ causare instabilit√† e favorire l‚Äôoccorrenza di transizioni divergenti.\n\nAffrontando questi problemi con attenzione, possiamo migliorare la performance dell‚Äôalgoritmo HMC e ridurre il rischio di incontrare transizioni divergenti. Risolvere questi problemi √® fondamentale per assicurare che l‚Äôalgoritmo fornisca una rappresentazione precisa della distribuzione a posteriori e per garantire inferenze statistiche corrette.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#la-bmfi-√®-sufficientemente-grande",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#la-bmfi-√®-sufficientemente-grande",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.10 LA BMFI √à Sufficientemente Grande?",
    "text": "44.10 LA BMFI √à Sufficientemente Grande?\nUn altro strumento diagnostico che √® stato recentemente sviluppato per il campionamento HMC/NUTS si chiama Bayesian Fraction of Missing Information (BFMI), calcolato in modo bayesiano. Questo indicatore si basa sull‚Äôanalisi delle variazioni di energia durante ciascuna iterazione del campionamento nelle catene. Esso ci permette di capire con maggiore precisione quanto bene l‚Äôalgoritmo HMC/NUTS sta funzionando a un livello pi√π dettagliato rispetto ad altre tecniche di diagnostica.\nUn valore basso di BFMI in una catena specifica indica che l‚Äôalgoritmo non sta esplorando efficacemente la distribuzione dei dati che stiamo analizzando, il che pu√≤ portare a risultati distorti o fuorvianti. √à generalmente accettato che il valore di BFMI debba essere almeno 0.2 per ogni catena. Se in una o pi√π catene il valore scende al di sotto di 0.2, si considera che i risultati ottenuti non siano affidabili per fare inferenze corrette, poich√© le stime prodotte potrebbero essere distorte (Betancourt 2016).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?",
    "text": "44.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?\nLa Leave-One-Out Cross-Validation (LOO) rappresenta un metodo ampiamente impiegato nell‚Äôambito dell‚Äôanalisi bayesiana per valutare quanto adeguatamente un modello statistico si adatta ai dati osservati. Immaginiamo di avere una serie di foto e di voler valutare quanto bene un software riesce a riconoscere le persone in queste foto. La LOO ci aiuta a testare il software in un modo accurato.\nIl processo √® semplice: prendiamo tutte le foto tranne una, e usiamo queste per insegnare al software come riconoscere le persone. Poi, usiamo la foto che abbiamo messo da parte per vedere se il software riesce a riconoscere la persona in quella foto. Ripetiamo questo processo per ogni singola foto, una alla volta. Ogni volta, il software apprende da tutte le foto tranne una, e quella esclusa serve per testarlo.\nQuesto metodo √® molto efficace perch√© assicura che il software non impari solo a riconoscere le persone nelle foto specifiche che ha gi√† visto (questo si chiama ‚Äúoverfitting‚Äù, ovvero sovraadattamento), ma che sia davvero capace di riconoscere persone anche in foto nuove che non ha mai analizzato. Inoltre, evita il problema opposto, chiamato ‚Äúunderfitting‚Äù, dove il software non impara abbastanza dai dati e quindi non riesce a fare buone previsioni.\nNel contesto dell‚Äôanalisi bayesiana, dove si utilizzano modelli statistici complessi, la LOO √® spesso accompagnata da calcoli come il logaritmo della verosimiglianza, che aiutano a quantificare quanto bene il modello riesce a prevedere i dati esclusi. I risultati di questi calcoli possono essere usati per calcolare un indice chiamato LOOIC (Leave-One-Out Information Criterion), che permette di confrontare diversi modelli per scegliere quello che si adatta meglio ai dati.\nIn conclusione, la LOO √® uno strumento molto utile per valutare in modo imparziale e preciso quanto bene un modello statistico possa prevedere nuovi dati, garantendo che le nostre previsioni siano il pi√π accurate possibile.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#il-parametro-k",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#il-parametro-k",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "44.12 Il Parametro \\(k\\)",
    "text": "44.12 Il Parametro \\(k\\)\nIl parametro \\(k\\), noto anche come parametro di coda di Pareto, riveste un ruolo importante nell‚Äôambito del campionamento MCMC. √à utilizzato per valutare l‚Äôefficienza e la convergenza delle catene di campionamento, nonch√© per misurare la qualit√† del processo di campionamento di importanza, come nel caso del Pareto Smoothed Importance Sampling (PSIS).\nImmaginiamo di essere a una festa dove stai cercando di scoprire quale gusto di gelato √® il preferito tra gli invitati. Invece di chiedere a tutti, decidiamo di assaggiare solo alcuni gelati per avere un‚Äôidea generale. Questo processo di selezionare solo alcuni gelati per fare un‚Äôassunzione sul gusto preferito √® simile a quello che avviene nel campionamento per l‚ÄôImportance Sampling: scegliamo solo alcuni punti (o ‚Äúcampioni‚Äù) da un insieme molto grande per fare delle stime su tutta la popolazione.\nNel Pareto Smoothed Importance Sampling (PSIS), dopo aver scelto i campioni, cerchiamo di ‚Äúlisciare‚Äù le nostre stime per renderle pi√π precise e meno variabili. Pensalo come se stessi cercando di bilanciare le risposte per non dare troppo peso a poche opinioni estreme.\nIl parametro \\(k\\) ci dice quanto siamo vicini a raggiungere questo obiettivo di bilanciamento. Se \\(k\\) √® vicino a 0, significa che abbiamo fatto un buon lavoro: le nostre stime sono affidabili e non troppo dipendenti da pochi campioni estremi. Se, invece, \\(k\\) √® pi√π alto, specialmente sopra 0.7, ci indica che ci sono problemi: forse abbiamo dato troppo peso a poche opinioni estreme, o non abbiamo un buon mix di opinioni per fare una stima affidabile. In pratica, un \\(k\\) alto √® come un campanello d‚Äôallarme che ci dice che dobbiamo essere cauti con le nostre conclusioni e, possibilmente, raccogliere pi√π dati o ripensare come li stiamo campionando.\nIn sostanza, il parametro \\(k\\) √® uno strumento per aiutarci a capire quanto possiamo fidarci delle nostre stime basate su un campione limitato di dati. Un valore basso √® buono, indicando che le stime sono solide e ben equilibrate, mentre un valore alto suggerisce che potremmo avere dei problemi e che dovremmo esaminare pi√π attentamente i dati che abbiamo raccolto.\nPer calcolare il parametro \\(\\hat{\\kappa}\\), √® possibile fare uso di ArviZ, uno strumento appositamente progettato per le analisi bayesiane avanzate.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/17_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/17_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "title": "44¬† Diagnostica delle catene markoviane",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nlogging   : 0.5.1.2\ncmdstanpy : 1.2.3\nscipy     : 1.13.1\narviz     : 0.18.0\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBetancourt, Michael. 2016. ¬´Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo¬ª. arXiv preprint arXiv:1604.00695.\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian B√ºrkner, e Martin Modr√°k. 2020. ¬´Bayesian workflow¬ª. arXiv preprint arXiv:2011.01808.\n\n\nMartin, Osvaldo A, Ravin Kumar, e Junpeng Lao. 2022. Bayesian Modeling and Computation in Python. CRC Press.\n\n\nSchoot, Van Rens de, Duco Veen, Laurent Smeets, e Sonja Winter. 2020. ¬´A tutorial on using the WAMBS checklist to avoid the misuse of Bayesian statistics¬ª. Routledge.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, e Paul-Christian B√ºrkner. 2021. ¬´Rank-normalization, folding, and localization: An improved R ÃÇ for assessing convergence of MCMC (with discussion)¬ª. Bayesian analysis 16 (2): 667‚Äì718.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html",
    "href": "chapters/chapter_4/18_stan_prediction.html",
    "title": "45¬† La predizione bayesiana",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo il concetto e l‚Äôimportanza delle distribuzioni predittive a priori e a posteriori nel contesto dell‚Äôanalisi di dataset. La distribuzione predittiva a posteriori √® cruciale per verificare l‚Äôaderenza delle previsioni del modello ai dati osservati. Un allineamento tra queste previsioni e i dati effettivamente raccolti ci consente di convalidare l‚Äôaccuratezza del modello nel rappresentare il processo generativo sottostante.\nParallelamente, la distribuzione predittiva a priori modella le aspettative dei dati prima di qualsiasi osservazione effettiva. Essa integra le nostre conoscenze preesistenti e le ipotesi sui parametri del modello, fornendo un quadro essenziale per la proiezione e l‚Äôinterpretazione di fenomeni complessi in un contesto statistico avanzato. Questa distribuzione non solo predispone una struttura per l‚Äôanalisi inferenziale, ma √® anche fondamentale per la formulazione di nuove ipotesi e per la progettazione di esperimenti futuri.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "href": "chapters/chapter_4/18_stan_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "title": "45¬† La predizione bayesiana",
    "section": "45.1 La distribuzione predittiva a posteriori",
    "text": "45.1 La distribuzione predittiva a posteriori\nLa distribuzione predittiva a posteriori (PPD) √® un concetto essenziale nell‚Äôinferenza bayesiana e permette di valutare quanto bene un modello si adatti ai dati osservati. Secondo Gelman e Shalizi (2013), questa metodologia fornisce una valutazione critica della coerenza tra i dati reali e quelli simulati dal modello. La verifica predittiva a posteriori (PPC) utilizza la PPD per confrontare direttamente i dati osservati con quelli generati dal modello, rivelando eventuali discrepanze che possono indicare problemi nella specificazione del modello. In pratica, la PPC funge da test diagnostico, consentendo di individuare e correggere eventuali lacune nel modello al fine di migliorarne le capacit√† predittive.\nPer comprendere meglio il concetto, √® utile considerare la distribuzione predittiva a posteriori in termini di un modello coniugato normale-normale. Supponiamo di voler predire la media di una distribuzione normale futura, basandoci sui dati osservati e sulle nostre conoscenze a priori. La PPD ci offre uno strumento per calcolare queste probabilit√†, combinando le informazioni provenienti dai dati osservati con quelle fornite dalla distribuzione a priori.\nAd esempio, immaginiamo di aver raccolto dati sulle altezze di 100 persone, ottenendo una media campionaria di 170 cm e una deviazione standard campionaria di 10 cm. Il nostro obiettivo √® stimare la media delle altezze in un futuro campione di \\(n=100\\) persone. La nostra conoscenza a priori sulla media delle altezze √® rappresentata da una distribuzione normale con media 175 cm e deviazione standard di 5 cm.\nIn termini di notazione, possiamo esprimere questa distribuzione come \\(P(\\tilde{y}|\\theta=\\theta_1)\\), dove \\(\\tilde{y}\\) rappresenta un nuovo dato che √® diverso dai dati attuali \\(y\\), e \\(\\theta_1\\) √® la media a posteriori. Tuttavia, in statistica bayesiana, √® fondamentale incorporare tutta l‚Äôincertezza nei risultati. Poich√© \\(\\theta_1\\) √® solo uno dei possibili valori per \\(\\theta\\), dovremmo includere ogni valore di \\(\\theta\\) per la nostra previsione. Per ottenere la migliore previsione, possiamo ‚Äúmediare‚Äù le previsioni attraverso i diversi valori di \\(\\theta\\), ponderando ciascun valore secondo la sua probabilit√† a posteriori.\nLa distribuzione risultante √® la distribuzione predittiva a posteriori, che in notazione matematica √® data da:\n\\[ P(\\tilde{y}|y) = \\int_\\theta p(\\tilde{y}|\\theta, y) p(\\theta|y) d\\theta \\]\nIn questo modo, la PPD combina le informazioni dai dati osservati con la conoscenza a priori, fornendo una previsione che riflette l‚Äôincertezza associata a tutti i possibili valori dei parametri del modello.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "href": "chapters/chapter_4/18_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "title": "45¬† La predizione bayesiana",
    "section": "45.2 Distribuzione predittiva a posteriori nel modello normale-normale",
    "text": "45.2 Distribuzione predittiva a posteriori nel modello normale-normale\nNel modello coniugato normale-normale, se i dati osservati \\(Y = \\{y_1, y_2, ..., y_n\\}\\) sono modellati come provenienti da una distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e assumendo una distribuzione a priori normale per \\(\\mu\\), la distribuzione a posteriori di \\(\\mu\\) sar√† anch‚Äôessa normale.\n\n45.2.1 Formule della distribuzione predittiva a posteriori\nDato che:\n\nI dati osservati \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nLa prior per \\(\\mu\\) √® \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)\\)\n\nLa distribuzione a posteriori per \\(\\mu\\) sar√†:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)\n\\]\ndove:\n\\[\n\\mu_n = \\frac{\\tau_0^2 \\bar{y} + \\sigma^2 \\mu_0}{\\tau_0^2 + \\sigma^2}\n\\]\ne\n\\[\n\\tau_n^2 = \\frac{\\tau_0^2 \\sigma^2}{\\tau_0^2 + \\sigma^2}\n\\]\nQui, \\(\\bar{y}\\) √® la media campionaria dei dati osservati.\n\nEsempio 45.1 Consideriamo che:\n\n\\(\\mu_0 = 175\\) cm (media a priori)\n\\(\\tau_0 = 5\\) cm (deviazione standard a priori)\n\\(\\bar{y} = 170\\) cm (media campionaria)\n\\(\\sigma = 10\\) cm (deviazione standard campionaria)\n\\(n = 100\\) (numero di osservazioni)\n\nI parametri della distribuzione a posteriori sono:\n\\[\n\\mu_n = \\frac{(5^2 \\cdot 170) + (10^2 \\cdot 175)}{5^2 + 10^2} = \\frac{42500 + 175000}{25 + 100} = \\frac{217500}{125} = 174 \\quad \\text{cm}\n\\]\n\\[\n\\tau_n^2 = \\frac{5^2 \\cdot 10^2}{5^2 + 10^2} = \\frac{2500}{125} = 20 \\quad \\text{cm}^2 \\Rightarrow \\tau_n = \\sqrt{20} \\approx 4.47 \\quad \\text{cm}\n\\]\nPertanto, la distribuzione a posteriori per \\(\\mu\\) √®:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(174, 4.47^2)\n\\]\nPer la distribuzione predittiva a posteriori, dobbiamo considerare anche la varianza della distribuzione futura. Se stiamo predicendo per \\(n_{\\text{fut}}=100\\) nuove osservazioni, la varianza della media predittiva sar√†:\n\\[\n\\sigma_{\\text{pred}}^2 = \\tau_n^2 + \\frac{\\sigma^2}{n_{\\text{fut}}}\n\\]\n\\[\n\\sigma_{\\text{pred}}^2 = 20 + \\frac{10^2}{100} = 20 + 1 = 21 \\quad \\text{cm}^2 \\Rightarrow \\sigma_{\\text{pred}} = \\sqrt{21} \\approx 4.58 \\quad \\text{cm}\n\\]\nQuindi, la distribuzione predittiva a posteriori √®:\n\\[\n\\tilde{Y} \\sim \\mathcal{N}(174, 4.58^2)\n\\]",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html#implementazione-con-cmdstanpy",
    "href": "chapters/chapter_4/18_stan_prediction.html#implementazione-con-cmdstanpy",
    "title": "45¬† La predizione bayesiana",
    "section": "45.3 Implementazione con cmdstanpy",
    "text": "45.3 Implementazione con cmdstanpy\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanpy per eseguire l‚Äôanalisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\ny_observed = np.random.normal(170, 10, 100)\nmean_y = np.mean(y_observed)\nstd_y = np.std(y_observed)\n\n# Parametri a priori\nmu_0 = 175\ntau_0 = 5\n\n# Parametri posteriori\ntau_n_sq = (tau_0**2 * std_y**2) / (tau_0**2 + std_y**2)\ntau_n = np.sqrt(tau_n_sq)\nmu_n = (tau_0**2 * mean_y + std_y**2 * mu_0) / (tau_0**2 + std_y**2)\n\n# Parametri predittivi\nn_fut = 100\nsigma_pred_sq = tau_n_sq + (std_y**2 / n_fut)\nsigma_pred = np.sqrt(sigma_pred_sq)\nmu_pred = mu_n\n\n# Simulazioni\ny_pred_samples = np.random.normal(mu_pred, sigma_pred, 1000)\n\n# Grafico\nplt.hist(y_pred_samples, bins=30, density=True, alpha=0.5, label='Posterior Predictive')\nx = np.linspace(160, 190, 200)\nplt.plot(x, stats.norm.pdf(x, mu_pred, sigma_pred), 'r-', lw=2, label='Predictive Distribution')\nplt.axvline(x=mu_pred, color='k', linestyle='--', label='Mean Prediction')\nplt.xlabel('Heights (cm)')\nplt.ylabel('Density')\nplt.title('Posterior Predictive Distribution for Heights')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori √® stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html#metodo-mcmc",
    "href": "chapters/chapter_4/18_stan_prediction.html#metodo-mcmc",
    "title": "45¬† La predizione bayesiana",
    "section": "45.4 Metodo MCMC",
    "text": "45.4 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che √® particolarmente utile in scenari complessi dove l‚Äôanalisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un‚Äôosservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l‚Äôistogramma risultante approssimer√† la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell‚Äôesempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\n\nstan_ncp_file = os.path.join(\n    project_directory, 'stan', 'gaussian_ncp.stan')\n\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\n\n\nprint(model_ncp.code())\n\ndata {\n    int&lt;lower=1&gt; N;  // Total number of trials\n    vector[N] y;  // Score in each trial\n}\ntransformed data {\n    real y_mean = mean(y);\n    real y_sd = sd(y);\n}\nparameters {\n    real mu_raw;\n    real&lt;lower=0&gt; sigma_raw;\n}\ntransformed parameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Priors:\n    mu_raw ~ normal(0, 1);  // Standard normal prior\n    sigma_raw ~ normal(0, 1);  // Standard normal prior\n    // Likelihood:\n    y ~ normal(mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\n\n\nDefiniamo un dizionario che contiene i dati.\n\nstan_data = {\n    'N': len(y_observed), \n    'y': y_observed\n}\n\nprint(stan_data)\n\n{'N': 100, 'y': array([168.14536923, 173.1595972 , 165.38905562, 161.48402377,\n       182.33872652, 160.50081077, 157.37344086, 169.87969743,\n       173.52140772, 179.57240082, 194.97163119, 163.4736973 ,\n       170.29884075, 163.3873392 , 162.23838646, 174.20206219,\n       184.88715608, 180.67782759, 160.60662457, 165.66459583,\n       162.32331458, 164.49285877, 173.28093158, 164.85738101,\n       166.99408888, 180.43609625, 169.9803307 , 172.81648151,\n       179.06330662, 161.40913737, 175.60219523, 168.5208698 ,\n       156.58317344, 166.53164329, 171.10069679, 178.24919458,\n       158.22641899, 162.11893871, 160.3029094 , 167.66546673,\n       179.32963235, 174.07840582, 164.40224397, 183.75797002,\n       176.3917848 , 193.59998641, 186.97123321, 168.12774959,\n       171.05639079, 176.4378439 , 173.19480422, 160.01796348,\n       164.27668464, 158.54222597, 165.33810663, 163.40878836,\n       175.73205979, 168.61024057, 163.78918889, 155.58907542,\n       192.15010371, 171.3494613 , 173.49035129, 168.73725808,\n       154.08405749, 171.67722833, 165.7939559 , 164.42218118,\n       158.49065136, 181.73249072, 192.34380002, 172.92864345,\n       162.59512493, 169.47352592, 165.47893326, 160.29635642,\n       182.96622908, 161.30676368, 165.295616  , 180.68487196,\n       178.26565399, 175.61658296, 173.69561404, 154.39250558,\n       166.76821114, 168.17206601, 189.08411628, 176.0644623 ,\n       164.47151613, 175.77349865, 168.42638105, 175.84318793,\n       156.91061429, 169.41245559, 180.24791095, 167.37948251,\n       184.89118518, 177.00553514, 175.360598  , 140.59436124])}\n\n\nEseguiamo il campionamento MCMC:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n170.28\n0.96\n168.40\n171.99\n0.01\n0.01\n6359.14\n5009.64\n1.0\n\n\nsigma\n9.69\n0.68\n8.44\n10.97\n0.01\n0.01\n6026.87\n4699.36\n1.0\n\n\n\n\n\n\n\n\nConvertiamo l‚Äôoggetto sample_ncp in un oggetto di classe InferenceData:\n\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp, \n    posterior_predictive='y_rep', \n    observed_data={\"y\": y_observed}\n)\n\nLa distribuzione predittiva a posteriori √® utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato √® adeguato per descrivere le propriet√† dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), √® possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma √® possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un‚Äôanalisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi pi√π adatti ai dati in esame.\nPossiamo ora usare ArviZ per generare il posterior-predictive plot:\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html#distribuzione-predittiva-a-priori",
    "href": "chapters/chapter_4/18_stan_prediction.html#distribuzione-predittiva-a-priori",
    "title": "45¬† La predizione bayesiana",
    "section": "45.5 Distribuzione Predittiva a Priori",
    "text": "45.5 Distribuzione Predittiva a Priori\nLe verifiche predittive a priori generano dati utilizzando unicamente le distribuzioni a priori, ignorando i dati osservati, al fine di valutare se tali distribuzioni a priori sono appropriate (Gabry et al.¬†2019). La distribuzione predittiva a priori √® quindi simile alla distribuzione predittiva a posteriori, ma senza dati osservati, rappresentando il caso limite di una verifica predittiva a posteriori senza dati.\nQuesto processo pu√≤ essere realizzato facilmente simulando i parametri secondo le distribuzioni a priori e poi simulando i dati in base al modello dati i parametri simulati. Il risultato √® una simulazione dalla distribuzione congiunta, che √® quindi una simulazione dalla distribuzione predittiva a priori.\nQuesta procedura √® fondamentale per verificare se le ipotesi a priori sono realistiche e adeguate prima di raccogliere o utilizzare i dati osservati. Se i dati simulati dalla distribuzione predittiva a priori non risultano plausibili, potrebbe essere necessario rivedere le scelte delle distribuzioni a priori.\nConsideriamo, quale esempio, il caso discusso in precedenza di un campione di dati gaussiani e di un modello gaussiano in cui le distribuzioni a priori per Œº e œÉ sono gaussiane.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian_model_prior.stan')\n\nmodel_gauss = CmdStanModel(stan_file=stan_file)\n\n\nprint(model_gauss.code())\n\ndata {\n  int&lt;lower=0&gt; N;            // number of observations\n}\ngenerated quantities {\n  real mu;                   // parameter of interest\n  real&lt;lower=0&gt; sigma;       // known standard deviation of y\n  array[N] real y_rep;       // prior predictive samples\n\n  // Priors\n  mu = normal_rng(175, 5);\n  sigma = 10;\n\n  // Generate prior predictive samples\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\n\n\nIl codice precedente illustra come definire il modello Stan per generare campioni predittivi a priori. In questo esempio, mu e sigma sono generati dalle loro rispettive distribuzioni a priori e usati per generare campioni di dati simulati y_rep.\n\n# Stan data dictionary\nstan_data = {\n    'N': len(y_observed)\n}\n\n\nprior_predictive_samples = model_gauss.sample(\n    data=stan_data, \n    fixed_param=True, \n    iter_sampling=1000, \n    iter_warmup=1, \n    chains=1,\n    show_progress=False, \n    show_console=False\n)\n\n\n# Extract the relevant variables\ny_rep_samples = prior_predictive_samples.stan_variable('y_rep')\ny_rep_flattened = y_rep_samples.flatten()\n\n# Check the statistics of y_rep values\ny_rep_mean = np.mean(y_rep_flattened)\ny_rep_std = np.std(y_rep_flattened)\n\nprint(f'Mean of y_rep: {y_rep_mean}')\nprint(f'Standard Deviation of y_rep: {y_rep_std}')\n\nMean of y_rep: 174.81334741999999\nStandard Deviation of y_rep: 11.287000139411681\n\n\n\n# Create a KDE plot\nplt.figure(figsize=(10, 6))\nsns.kdeplot(y_rep_flattened, fill=True)\nplt.title('Prior Predictive Check')\nplt.xlabel('Height (cm)')\nplt.ylabel('Density')\nplt.axvline(x=y_rep_mean, color='r', linestyle='--', label=f'Mean: {y_rep_mean:.2f}')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto approccio assicura che le distribuzioni a priori siano realistiche e adeguate, permettendo di identificare e correggere eventuali ipotesi errate prima di procedere con l‚Äôanalisi dei dati osservati.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html#considerazioni-conclusive",
    "href": "chapters/chapter_4/18_stan_prediction.html#considerazioni-conclusive",
    "title": "45¬† La predizione bayesiana",
    "section": "45.6 Considerazioni conclusive",
    "text": "45.6 Considerazioni conclusive\nLe distribuzioni predittive a priori e a posteriori sono generate in maniera simile, con la seguente differenza.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre previsioni sui dati prima di osservare qualsiasi dato effettivo. In questo caso, prendiamo valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati predittivi. La distribuzione di questi dati generati √® la nostra distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze prima dell‚Äôosservazione dei dati.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sulla distribuzione dei parametri usando il teorema di Bayes, ottenendo cos√¨ la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene generata prendendo valori dei parametri dalla distribuzione a posteriori (che incorpora le informazioni dai dati osservati) e inserendoli nella funzione di verosimiglianza per generare nuovi dati predittivi. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver considerato i dati attuali.\n\nLa differenza chiave tra le due distribuzioni predittive √® quindi la distribuzione dei parametri utilizzata per generare i dati: il prior nel caso della distribuzione predittiva a priori, e il posterior nel caso della distribuzione predittiva a posteriori. La distribuzione predittiva a posteriori √® generalmente pi√π informativa perch√© tiene conto dei dati osservati.\n√à fondamentale, per l‚Äôintegrit√† del modello, che la distribuzione predittiva a posteriori rifletta la distribuzione dei dati osservati. Per validare questa corrispondenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite stime di densit√† Kernel (KDE). Questo confronto consente di valutare l‚Äôefficacia del modello nell‚Äôapprossimare la struttura sottostante dei dati e la sua capacit√† di guidare previsioni affidabili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/18_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/18_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "title": "45¬† La predizione bayesiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p jax\n\nLast updated: Tue Jun 11 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\njax: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nlogging   : 0.5.1.2\nseaborn   : 0.13.2\narviz     : 0.18.0\nscipy     : 1.13.1\nnumpy     : 1.26.4\npandas    : 2.2.2\ncmdstanpy : 1.2.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, Andrew, e Cosma Rohilla Shalizi. 2013. ¬´Philosophy and the practice of Bayesian statistics¬ª. British Journal of Mathematical and Statistical Psychology 66 (1): 8‚Äì38.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo l‚Äôapplicazione degli strumenti statistici descritti nei capitoli precedenti all‚Äôanalisi bayesiana di due proporzioni. Inizieremo definendo i concetti di odds, odds ratio e logit. Successivamente, mostreremo come effettuare l‚Äôanalisi bayesiana per il confronto tra due proporzioni.\nUn rapporto di odds (OR) √® una misura di associazione tra un‚Äôesposizione (o un certo gruppo o una certa conditione) e un risultato. L‚ÄôOR rappresenta gli odds che si verifichi un risultato dato un‚Äôesposizione particolare, confrontate con gli odds del risultato che si verifica in assenza di tale esposizione.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#odds",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#odds",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "46.1 Odds",
    "text": "46.1 Odds\nIl termine ‚Äúodds‚Äù rappresenta il rapporto tra la probabilit√† che un evento si verifichi e la probabilit√† che l‚Äôevento opposto si verifichi. Matematicamente, l‚Äôodds pu√≤ essere calcolato come:\n\\[ \\text{odds} = \\frac{\\pi}{1-\\pi}, \\]\ndove \\(\\pi\\) rappresenta la probabilit√† dell‚Äôevento di interesse.\nMentre una probabilit√† \\(\\pi\\) √® sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilit√† di un evento.\nSe la probabilit√† di un evento √® \\(\\pi = \\frac{2}{3}\\), allora la probabilit√† che l‚Äôevento non si verifichi √® \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell‚Äôevento sono:\n\\[ \\text{odds} = \\frac{2/3}{1-2/3} = 2. \\]\nQuesto significa che la probabilit√† che l‚Äôevento si verifichi √® il doppio della probabilit√† che non si verifichi.\nSe, invece, la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{3}\\), allora gli odds che l‚Äôevento si verifichi sono la met√† rispetto agli odds che non si verifichi:\n\\[ \\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}. \\]\nInfine, se la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{2}\\), allora gli odds dell‚Äôevento sono pari a 1:\n\\[ \\text{odds} = \\frac{1/2}{1-1/2} = 1. \\]\n\n46.1.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilit√† \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull‚Äôincertezza dell‚Äôevento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilit√† dell‚Äôevento sono inferiori al 50-50, cio√® \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilit√† dell‚Äôevento sono del 50-50, cio√® \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilit√† dell‚Äôevento sono superiori al 50-50, cio√® \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l‚Äôuso dell‚Äôodds rispetto alla probabilit√†, nonostante quest‚Äôultima sia un concetto pi√π intuitivo, risiede nel fatto che quando le probabilit√† si avvicinano ai valori estremi (cio√® 0 o 1), √® pi√π facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilit√†.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#odds-ratio",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#odds-ratio",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "46.2 Odds Ratio",
    "text": "46.2 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l‚Äôodds ratio. L‚Äôodds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[ OR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}. \\]\nInterpretazione:\n\nOR = 1: l‚Äôappartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR aumenta la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR riduce la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore.\n\nL‚Äôodds ratio √® particolarmente utile quando vogliamo confrontare due gruppi e vedere come l‚Äôappartenenza a uno di essi influenza la probabilit√† di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l‚Äôefficacia di una terapia comportamentale per ridurre l‚Äôansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l‚Äôodds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilit√† di riduzione dell‚Äôansia. Se l‚Äôodds ratio √® maggiore di 1, significa che la terapia ha aumentato le probabilit√† di riduzione dell‚Äôansia; se √® inferiore a 1, significa che il trattamento ha ridotto le probabilit√† di riduzione dell‚Äôansia. L‚Äôodds ratio ci fornisce quindi una misura dell‚Äôeffetto della terapia rispetto al controllo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "46.3 Logaritmo dell‚ÄôOdds Ratio",
    "text": "46.3 Logaritmo dell‚ÄôOdds Ratio\nIl logaritmo dell‚Äôodds ratio √® una trasformazione matematica molto utilizzata nell‚Äôanalisi statistica, specialmente nella regressione logistica. Essa permette di rendere l‚Äôodds ratio interpretabile su una scala lineare, semplificando l‚Äôanalisi e l‚Äôinterpretazione dei risultati.\nLa formula per calcolare il logaritmo dell‚Äôodds ratio √® la seguente:\n\\[ \\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right). \\]\nIn altre parole, il logaritmo dell‚Äôodds ratio √® il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n46.3.1 Interpretazione\nL‚Äôinterpretazione del logaritmo dell‚Äôodds ratio √® pi√π intuitiva rispetto all‚Äôodds ratio stesso. Una variazione di una unit√† nel logaritmo dell‚Äôodds ratio corrisponde a un cambiamento costante nell‚Äôodds ratio stesso.\nSe il logaritmo dell‚Äôodds ratio √® positivo, significa che l‚Äôodds dell‚Äôevento nel primo gruppo √® maggiore rispetto al secondo gruppo. Pi√π il valore del logaritmo dell‚Äôodds ratio si avvicina a zero, pi√π l‚Äôodds dell‚Äôevento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell‚Äôodds ratio √® negativo, l‚Äôodds dell‚Äôevento nel primo gruppo √® inferiore rispetto al secondo gruppo. Un valore di logaritmo dell‚Äôodds ratio vicino a zero indica che l‚Äôodds dell‚Äôevento √® simile nei due gruppi.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "46.4 Analisi bayesiana delle proporzioni",
    "text": "46.4 Analisi bayesiana delle proporzioni\nUna volta compresi i concetti di odds, odds ratio e logit, possiamo procedere all‚Äôanalisi bayesiana delle proporzioni. Questo approccio consente di confrontare le proporzioni di due gruppi, ottenendo stime delle probabilit√† a posteriori e degli intervalli di credibilit√†.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nIn questo capitolo, analizzeremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Hoffmann, Hofman, e Wagenmakers (2022). Von Frisch (1914) ha voluto verificare se le api possiedono la visione dei colori confrontando il comportamento di due gruppi di api. L‚Äôesperimento si compone di una fase di addestramento e di una fase di test.\nNella fase di addestramento, le api del gruppo sperimentale vengono esposte a un disco blu e a un disco verde. Solo il disco blu √® ricoperto di una soluzione zuccherina, molto appetita dalle api. Il gruppo di controllo, invece, non riceve alcun addestramento.\nNella fase di test, la soluzione zuccherina viene rimossa dal disco blu e si osserva il comportamento di entrambi i gruppi. Se le api del gruppo sperimentale hanno appreso che solo il disco blu contiene la soluzione zuccherina e sono in grado di distinguere tra il blu e il verde, dovrebbero preferire esplorare il disco blu piuttosto che quello verde durante la fase di test.\nIl ricercatore osserva che in 130 casi su 200, le api del gruppo sperimentale continuano ad avvicinarsi al disco blu dopo la rimozione della soluzione zuccherina. Le api del gruppo di controllo, che non sono state addestrate, si avvicinano al disco blu 100 volte su 200.\nPer confrontare il comportamento delle api nelle due condizioni, useremo l‚Äôodds ratio, cos√¨ da confrontare le probabilit√† dell‚Äôevento critico (scelta del disco blu) tra i due gruppi.\nCalcoliamo la proporzione delle api che scelgono il disco blu nella condizione sperimentale:\n\\[ p_e = \\frac{130}{200} = 0.65 \\]\nCalcoliamo gli odds nella condizione sperimentale:\n\\[ \\text{odds}_e = \\frac{p_e}{1 - p_e} \\approx 1.86 \\]\nQuesto ci indica che, nel gruppo sperimentale, ci sono circa 1.86 ‚Äúsuccessi‚Äù (ossia la scelta del disco blu) per ogni ‚Äúinsuccesso‚Äù (scelta del disco verde).\nProcediamo calcolando gli odds nella condizione di controllo:\n\\[ p_c = \\frac{100}{200} = 0.5 \\]\n\\[ \\text{odds}_c = \\frac{p_c}{1 - p_c} = 1.0 \\]\nQuesto ci indica che, nel gruppo di controllo, il numero di ‚Äúsuccessi‚Äù e ‚Äúinsuccessi‚Äù √® uguale.\nInfine, confrontiamo gli odds tra la condizione sperimentale e la condizione di controllo per calcolare l‚Äôodds ratio (OR):\n\\[ \\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = 1.86 \\]\nGli odds di scelta del disco blu aumentano di circa 1.86 volte nel gruppo sperimentale rispetto al gruppo di controllo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "46.5 Analisi Bayesiana dell‚ÄôOdds Ratio",
    "text": "46.5 Analisi Bayesiana dell‚ÄôOdds Ratio\nNella nostra analisi, ci focalizziamo sull‚ÄôOdds Ratio (OR) per valutare la differenza nel comportamento di scelta delle api nelle due condizioni dell‚Äôesperimento discusso. L‚ÄôOR fornisce una stima puntuale della differenza basata sul nostro campione specifico. Tuttavia, per realizzare un‚Äôinferenza statistica robusta, √® essenziale considerare l‚Äôincertezza nelle nostre stime, caratterizzata attraverso la distribuzione a posteriori.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le nostre conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo ci permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nPer affrontare questa questione, adottiamo un approccio bayesiano, costruendo la distribuzione a posteriori dell‚ÄôOR. A partire da questa distribuzione, determiniamo un intervallo di credibilit√† del 90%, che rappresenta l‚Äôintervallo entro il quale, con il 90% di confidenza, possiamo aspettarci che ricada il vero valore dell‚ÄôOR della popolazione.\nSe questo intervallo non include il valore 1, disponiamo di una solida evidenza (con un livello di credibilit√† del 90%) che la differenza tra le due condizioni esaminate corrisponde a una differenza reale nella popolazione, il che suggerisce che non si tratta di un artefatto generato dalla nostra incertezza. In altre parole, possiamo affermare con ragionevole certezza che le api dispongono di una visione cromatica.\nD‚Äôaltro canto, se l‚Äôintervallo di credibilit√† includesse il valore 1, ci√≤ indicherebbe che la differenza osservata nel nostro campione potrebbe non riflettere una differenza significativa nella popolazione generale, suggerendo che potrebbe essere una peculiarit√† del nostro campione specifico.\nL‚Äôanalisi bayesiana e il calcolo dell‚Äôintervallo di credibilit√† verranno condotti utilizzando cmdstanpy, che ci permette di implementare modelli bayesiani in modo efficiente e rigoroso. Utilizzeremo una distribuzione a priori debolmente informativa per l‚ÄôOR, in modo da non influenzare eccessivamente i risultati con assunzioni preliminari.\nUna volta ottenuta la distribuzione a posteriori dell‚ÄôOR, possiamo calcolare il nostro intervallo di credibilit√† del 90%. Questo intervallo fornir√† una rappresentazione della nostra incertezza riguardo il vero valore dell‚ÄôOR nella popolazione. Se il nostro intervallo di credibilit√† esclude il valore 1, possiamo concludere che esiste una differenza significativa tra i due gruppi, confermando che le api possono distinguere i colori e preferire il disco blu.\nIn sintesi, l‚Äôapproccio bayesiano non solo ci permette di stimare l‚ÄôOR, ma anche di quantificare la nostra incertezza e fare inferenze pi√π solide e informative sulla capacit√† delle api di distinguere tra colori.\n\n46.5.1 Likelihood\nLa likelihood del modello descrive la probabilit√† di osservare i dati dati i parametri del modello. Nel nostro caso, abbiamo due gruppi con eventi binomiali.\nPer il gruppo 1:\n\\[ y_1 \\sim \\text{Binomiale}(N_1, \\theta_1) .\\]\nPer il gruppo 2:\n\\[ y_2 \\sim \\text{Binomiale}(N_2, \\theta_2) .\\]\n\n\n46.5.2 Priors\nI priors del modello descrivono le nostre convinzioni iniziali sui parametri prima di osservare i dati. Nel nostro caso, i parametri \\(\\theta_1\\) e \\(\\theta_2\\) seguono una distribuzione Beta(2, 2).\nPer \\(\\theta_1\\):\n\\[ \\theta_1 \\sim \\text{Beta}(2, 2) .\\]\nPer \\(\\theta_2\\):\n\\[ \\theta_2 \\sim \\text{Beta}(2, 2) .\\]\nCompiliamo e stampiamo il modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'odds-ratio.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n//  Comparison of two groups with Binomial\ndata {\n  int&lt;lower=0&gt; N1; // number of experiments in group 1\n  int&lt;lower=0&gt; y1; // number of events in group 1\n  int&lt;lower=0&gt; N2; // number of experiments in group 2\n  int&lt;lower=0&gt; y2; // number of events in group 2\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta1; // probability of event in group 1\n  real&lt;lower=0, upper=1&gt; theta2; // probability of event in group 2\n}\nmodel {\n  // model block creates the log density to be sampled\n  theta1 ~ beta(2, 2); // prior\n  theta2 ~ beta(2, 2); // prior\n  y1 ~ binomial(N1, theta1); // observation model / likelihood\n  y2 ~ binomial(N2, theta2); // observation model / likelihood\n}\ngenerated quantities {\n  real oddsratio = (theta1 / (1 - theta1)) / (theta2 / (1 - theta2));\n}\n\n\n\nNel blocco generated quantities, calcoliamo l‚Äôodds ratio:\n\\[ \\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}. \\]\nQuesto rapporto delle odds ci d√† una misura della forza dell‚Äôassociazione tra l‚Äôevento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.\nCreiamo un dizionario che contiene i dati.\n\nn1 = 200\ny1 = 130\nn2 = 200\ny2 = 100\n\nstan_data = {\n    'N1': n1,\n    'y1': y1,\n    'N2': n2,\n    'y2': y2\n}\n\nprint(stan_data)\n\n{'N1': 200, 'y1': 130, 'N2': 200, 'y2': 100}\n\n\nEseguiamo il campionamento.\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEstraiamo la distribuzione a posteriori dell‚Äôodds ratio e generiamo un istogramma.\n\nor_draws = trace.stan_variable('oddsratio')\n\n\nplt.hist(or_draws, bins=30, alpha=0.5, color='b', edgecolor='black', density=True)\nplt.title('Istogramma della distribizione a posteriori di OR')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds √® il modo pi√π semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi √® un‚Äôelevata probabilit√† che la differenza tra i due gruppi sia affidabile e relativamente grande.\nUn sommario della distribuzione a posteriori dell‚Äôodds ratio si ottine nel modo seguente.\n\naz.summary(trace, var_names=['oddsratio'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.88\n0.39\n1.2\n2.6\n0.0\n0.0\n6936.86\n5183.54\n1.0\n\n\n\n\n\n\n\n\nPossiamo determinare la probabilit√† che il rapporto di probabilit√† (odds ratio) superi 1. Per farlo, √® sufficiente analizzare gli 8000 campioni della distribuzione posteriore dell‚Äôodds ratio\n\nlen(or_draws)\n\n8000\n\n\ne calcolare la proporzione di questi che presenta un valore maggiore di 1:\n\nnp.mean(or_draws &gt; 1.0)\n\n0.9985",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "46.6 Diagnostica delle catene markoviane",
    "text": "46.6 Diagnostica delle catene markoviane\nPrima di esaminare i risultati, eseguiamo la diagnostica delle catene markoviane.\n\n46.6.1 Mixing\nIl trace plot precedente dimostra un buon mixing. Questo √® evidenza che il campionamento MCMC ha raggiunto uno stato stazionario.\n\n_ = az.plot_trace(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n46.6.2 NumerositaÃÄ campionaria effettiva\nQuando si utilizzano metodi di campionamento MCMC, √® ragionevole chiedersi se un particolare campione estratto dalla distribuzione a posteriori sia sufficientemente grande per calcolare con sicurezza le quantit√† di interesse, come una media o un HDI. Questo non √® qualcosa che possiamo rispondere direttamente guardando solo il numero di punti della catena MCMC, e il motivo √® che i campioni ottenuti dai metodi MCMC hanno un certo grado di autocorrelazione, quindi la quantit√† effettiva di informazioni contenute in quel campione sar√† inferiore a quella che otterremmo da un campione iid della stessa dimensione. Possiamo pensare alla dimensione del campione effettivo (ESS) come a un stimatore che tiene conto dell‚Äôautocorrelazione e fornisce il numero di estrazioni che avremmo se il nostro campione fosse effettivamente iid.\nPer le catene buone, solitamente, il valore della dimensione del campione effettivo sar√† inferiore al numero di campioni. Ma l‚ÄôESS pu√≤ essere in realt√† pi√π grande del numero di campioni estratti. Quando si utilizza il campionatore NUTS, valori di ESS maggiori del numero totale di campioni possono verificarsi per parametri le cui distribuzioni posteriori sono vicine alla Gaussiana e che sono quasi indipendenti da altri parametri nel modello.\nNell‚Äôoutput di PyCM si considera ESS_BULK. Un euristica √® che deve essere almeno uguale a 400. Nel caso presente questo si verifica, quindi il valore ESS_BULK non fornisce alcuna evidenza di cattivo mixing.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.881\n0.386\n1.198\n2.597\n0.005\n0.003\n6937.0\n5184.0\n1.0\n\n\ntheta1\n0.647\n0.033\n0.585\n0.710\n0.000\n0.000\n6865.0\n5296.0\n1.0\n\n\ntheta2\n0.499\n0.035\n0.434\n0.564\n0.000\n0.000\n7465.0\n5391.0\n1.0\n\n\n\n\n\n\n\n\n\n\n46.6.3 R hat\nIn condizioni molto generali, i metodi di Markov chain Monte Carlo hanno garanzie teoriche che otterranno la risposta corretta indipendentemente dal punto di partenza. Sfortunatamente, tali garanzie sono valide solo per campioni infiniti. Quindi, nella pratica, abbiamo bisogno di modi per stimare la convergenza per campioni finiti. Un‚Äôidea diffusa √® quella di generare pi√π di una catena, partendo da punti molto diversi e quindi controllare le catene risultanti per vedere se sembrano simili tra loro. Questa nozione intuitiva pu√≤ essere formalizzata in un indicatore numerico noto come R-hat. Esistono molte versioni di questo stimatore, poich√© √® stato perfezionato nel corso degli anni. In origine il R-hat veniva interpretato come la sovrastima della varianza dovuta al campionamento MCMC finito. Ci√≤ significa che se si continua a campionare all‚Äôinfinito si dovrebbe ottenere una riduzione della varianza della stima di un fattore R-hat. E quindi il nome ‚Äúfattore di riduzione potenziale della scala‚Äù (potential scale reduction factor), con il valore target di 1 che significa che aumentare il numero di campioni non ridurr√† ulteriormente la varianza della stima. Tuttavia, nella pratica √® meglio pensarlo solo come uno strumento diagnostico senza cercare di sovra-interpretarlo.\nL‚ÄôR-hat per il parametro theta viene calcolato come la deviazione standard di tutti i campioni di theta, ovvero includendo tutte le catene insieme, diviso per la radice quadratica media delle deviazioni standard separate all‚Äôinterno della catena. Il calcolo effettivo √® un po‚Äô pi√π complesso ma l‚Äôidea generale √® questa. Idealmente dovremmo ottenere un valore di 1, poich√© la varianza tra le catene dovrebbe essere la stessa della varianza all‚Äôinterno della catena. Da un punto di vista pratico, valori di R-hat inferiori a 1.1 sono considerati sicuri.\nNel caso presente questo si verifica. Possiamo ottenere R hat con Arviz:\n\naz.rhat(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 1.0\n    theta1     float64 8B 1.001\n    theta2     float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float641.0array(1.00038283)theta1()float641.001array(1.00052497)theta2()float641.001array(1.00059406)Indexes: (0)Attributes: (0)\n\n\nIl valore di \\(\\hat{R}\\), al massimo, raggiunge il valore di 1.001. Essendo il valore molto simile a 1 nel caso presente, possiamo dire che non ci sono evidenza di assenza di convergenza.\n\n\n46.6.4 Errore standard di Monte Carlo\nQuando si utilizzano metodi MCMC introduciamo un ulteriore livello di incertezza poich√© stiamo approssimando la posteriore con un numero finito di campioni. Possiamo stimare la quantit√† di errore introdotta utilizzando l‚Äôerrore standard di Monte Carlo (MCSE). L‚ÄôMCSE tiene conto del fatto che i campioni non sono veramente indipendenti l‚Äôuno dall‚Äôaltro e sono in realt√† calcolati dall‚ÄôESS. Mentre i valori di ESS e R-hat sono indipendenti dalla scala dei parametri, la statistica MCSE non lo √®. Se vogliamo riportare il valore di un parametro stimato al secondo decimale, dobbiamo essere sicuri che MCSE sia al di sotto del secondo decimale altrimenti, finiremo, erroneamente, per riportare una precisione superiore a quella che abbiamo realmente. Dovremmo controllare MCSE solo una volta che siamo sicuri che ESS sia abbastanza alto e R-hat sia abbastanza basso; altrimenti, MCSE non √® utile.\nNel nostro caso il MCSE √® sufficientemente piccolo.\n\naz.mcse(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 0.004636\n    theta1     float64 8B 0.0004029\n    theta2     float64 8B 0.0004034xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float640.004636array(0.00463567)theta1()float640.0004029array(0.00040294)theta2()float640.0004034array(0.00040337)Indexes: (0)Attributes: (0)\n\n\nCome per l‚ÄôESS, l‚ÄôMCSE varia nello spazio dei parametri e quindi potremmo anche volerlo valutare per diverse regioni dello spazio dei parametri.\n\n_ = az.plot_mcse(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nL‚Äôerrore standard di Monte Carlo ci informa della precisione della stima ottenuta usando il metodo MCMC. Non possiamo riportare una precisione dei risultati maggiore di quella indicata dalla MCSE. Pertanto, per il caso presente relativo all‚ÄôOdds Ratio (OR), possiamo affermare che la precisione massima raggiungibile √® limitata a due decimali.\n\n\n46.6.5 Autocorrelazione\nL‚Äôautocorrelazione riduce la quantit√† effettiva di informazioni contenute in un campione e quindi √® qualcosa che vogliamo mantenere al minimo. Possiamo ispezionare direttamente l‚Äôautocorrelazione con az.plot_autocorr.\n\n_ = az.plot_autocorr(trace, combined=True, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n46.6.6 Rank Plots\nI grafici dei ranghi sono un altro strumento diagnostico visivo che possiamo utilizzare per confrontare il comportamento del campionamento sia all‚Äôinterno che tra le catene. I grafici dei ranghi, in parole semplici, sono istogrammi dei campioni della distribuzione a posteriori espressi in termini di ranghi. Nei grafici dei ranghi, i ranghi sono calcolati combinando prima tutte le catene ma poi rappresentando i risultati separatamente per ogni catena. Se tutte le catene stimano la stessa distribuzione, ci aspettiamo che i ranghi abbiano una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ci√≤ indica un buon mix delle catene.\nPossiamo ottenere i grafici dei ranghi con az.plot_rank.\n\n_ = az.plot_rank(trace, kind=\"bars\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa √® la seguente.\n\n_ = az.plot_rank(trace, kind=\"vlines\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nPossiamo vedere nella figura che i ranghi sono molto simili ad una distribuzione uniforme e che tutte le catene sono simili tra loro senza alcuno scostamento distintivo.\n\n\n46.6.7 Divergenza\nFinora abbiamo diagnosticato il funzionamento di un campionatore esaminando i campioni generati. Un altro modo per eseguire una diagnosi √® monitorare il comportamento dei meccanismi interni del metodo di campionamento. Un esempio importante di tali diagnosi √® il concetto di divergenza presente in alcuni metodi Hamiltonian Monte Carlo (HMC). Le divergenze (o transizioni divergenti) sono un modo potente e sensibile per diagnosticare i campioni e funzionano come complemento alle diagnosi che abbiamo visto nelle sezioni precedenti.\nPyMC riporta il numero di transizioni divergenti. Se non viene riportato alcun messaggio che informa della presenza di transizioni divergenti, questo vuol dire che la distribuzione a posteriori √® stata stimata correttamente.\n\n\n46.6.8 BFMI\nIl BFMI (Fraction of Missing Information) serve a valutare quanto bene il processo di campionamento si allinea con la distribuzione della ‚Äúenergia‚Äù associata a ciascun campione. Nel contesto del campionamento Hamiltoniano, il termine ‚Äúenergia‚Äù si riferisce a una quantit√† calcolata durante il processo di campionamento che aiuta a valutare quanto √® probabile un certo set di parametri alla luce dei dati osservati e del modello statistico in esame.\nIl BFMI √® uno strumento che ci aiuta a valutare se il processo di campionamento sta ‚Äúesplorando‚Äù adeguatamente lo spazio dei parametri possibili. In altre parole, ci dice se il nostro processo di campionamento sta dando un‚Äôimmagine accurata delle regioni dello spazio dei parametri che sono realmente plausibili dati i nostri dati e il nostro modello. Un valore BFMI basso indica che il campionamento non √® riuscito a esplorare adeguatamente alcune regioni dello spazio dei parametri che dovrebbero essere state esplorate, e quindi i risultati del campionamento potrebbero non essere affidabili.\nGeneralmente, un valore inferiore a 0.3 indica un campionamento insufficiente.\nNel caso presente, dal momento che i valori BFMI sono superiori a 0.3 per tutte le catene, sembra che il processo di campionamento sia riuscito a esplorare adeguatamente lo spazio dei parametri.\n\naz.bfmi(trace)\n\narray([1.14346921, 1.11602384, 1.1467078 , 1.03197001])\n\n\nLa validazione del processo di campionamento pu√≤ essere efficacemente eseguita analizzando graficamente le quantit√† note come ‚Äúenergy transition‚Äù e ‚Äúmarginal energy‚Äù. Queste metriche sono strettamente legate alla funzione obiettivo che l‚Äôalgoritmo di campionamento intende ottimizzare e giocano un ruolo cruciale nel rilevare potenziali problematiche che possono emergere durante il campionamento.\n\nEnergy transition: questa metrica illustra l‚Äô‚Äúenergia‚Äù calcolata in ogni singolo passo dell‚Äôalgoritmo di campionamento, offrendo una visione dettagliata delle fluttuazioni che intervengono ad ogni iterazione. Facilita l‚Äôidentificazione delle aree dello spazio dei parametri dove l‚Äôalgoritmo potrebbe incontrare difficolt√† nel campionare in modo corretto.\nMarginal energy: fornisce un profilo dell‚Äô‚Äúenergia‚Äù marginale per l‚Äôintero set di campioni, riflettendo l‚Äô‚Äúenergia‚Äù media in ogni punto del campione. √à una rappresentazione grafica dell‚Äô‚Äúenergia‚Äù associata alla distribuzione a posteriori che si intende campionare.\n\nPer un‚Äôanalisi diagnostica efficace, √® auspicabile che il tracciato dell‚Äô‚Äúenergy transition‚Äù coincida sostanzialmente con quello della ‚Äúmarginal energy‚Äù. Tale congruenza √® indicativa di una esplorazione ben riuscita dello spazio dei parametri, assicurando che le regioni ad alta probabilit√† nella distribuzione a posteriori siano state correttamente campionate. Pertanto, una buona sovrapposizione tra i grafici delle due metriche attesterebbe un funzionamento ottimale del modello, conferendo un grado di affidabilit√† elevato alle stime dei parametri derivanti dal processo di campionamento.\n\n_ = az.plot_energy(trace)\n\n\n\n\n\n\n\n\n\n\n46.6.9 Conclusione\nIn questo capitolo abbiamo approfondito l‚Äôanalisi bayesiana focalizzandoci sulla stima dell‚Äôodds ratio (OR). I risultati della diagnosi delle catene Markoviane non evidenziano problematiche relative alla convergenza dell‚Äôalgoritmo n√© discrepanze nel modello statistico adottato, permettendoci di procedere con l‚Äôanalisi dei risultati ottenuti.\nL‚Äôanalisi ha determinato un valore a posteriori per l‚ÄôOR di 1.88, accompagnato da un intervallo di credibilit√† del 94% compreso tra 1.20 e 2.60. Poich√© questo intervallo non include il valore 1, possiamo affermare, con un grado di certezza del 94%, che il comportamento delle api differisce nelle due condizioni sperimentali. Questo fornisce evidenza a supporto dell‚Äôipotesi che le api dispongano di una visione cromatica.\nL‚Äôapproccio bayesiano adottato ci ha permesso di integrare le conoscenze a priori con i dati ottenuti dall‚Äôanalisi, risultando in una stima dell‚Äôodds ratio pi√π affidabile e accurata.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "46¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jul 14 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\ncmdstanpy : 1.2.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHoffmann, Tabea, Abe Hofman, e Eric-Jan Wagenmakers. 2022. ¬´Bayesian tests of two proportions: A tutorial with R and JASP¬ª. Methodology 18 (4): 239‚Äì77.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html",
    "href": "chapters/chapter_4/22_stan_normal_normal.html",
    "title": "47¬† Inferenza bayesiana su una media",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo principale di questo capitolo √® esaminare un contesto che abbiamo gi√† preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione √® stato estratto. Tuttavia, anzich√© procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo i metodi MCMC con Stan.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#il-modello-normale",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#il-modello-normale",
    "title": "47¬† Inferenza bayesiana su una media",
    "section": "47.1 Il modello Normale",
    "text": "47.1 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l‚Äôapprossimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l‚Äôesercizio descritto nel capitolo {ref}distr-coniugate-2-notebook usando Stan.\n\n47.1.1 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell‚Äôarea di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ‚Äô60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un‚Äôeconomia basata su caccia e raccolta. Riprodurremo l‚Äôanalisi descritta da {cite:t}McElreath_rethinking, esaminando unicamente i valori di altezza per individui di et√† superiore ai 18 anni.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\ndf.head()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\n\nlen(df[\"height\"])\n\n352\n\n\n\nsns.kdeplot(df[\"height\"], bw_adjust=0.5, fill=True)  # Adjust bw_adjust for smoothing\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\nLa media dei valori dell‚Äôaltezza nel campione √®:\n\nnp.mean(df[\"height\"])\n\n154.5970926136364\n\n\ncon una deviazione standard pari a:\n\nnp.std(df[\"height\"], ddof=1)\n\n7.742332137351995\n\n\n\n\n47.1.2 Modello di Base\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo {cite:t}McElreath_rethinking, ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell‚Äôaltezza.\nPertanto, il modello Normale si definisce nel seguente modo:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilit√†, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l‚Äôoggetto dell‚Äôinferenza.\n\nstan_file = os.path.join(project_directory, 'stan', 'gaussian_height.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\nparameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  sigma ~ normal(0, 20);\n  mu ~ normal(181, 30);\n}\n\n\n\nCreaiamo un dizionario con i dati in formato appropriato per Stan:\n\nstan_data = {'N': len(df[\"height\"]), 'y': df[\"height\"]}\nprint(stan_data)\n\n{'N': 352, 'y': 0      151.765\n1      139.700\n2      136.525\n3      156.845\n4      145.415\n        ...   \n347    162.560\n348    142.875\n349    162.560\n350    156.210\n351    158.750\nName: height, Length: 352, dtype: float64}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\mu\\) e \\(\\sigma\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\nUna sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente.\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.60\n0.42\n153.84\n155.39\n0.0\n0.0\n7864.52\n5825.33\n1.0\n\n\nsigma\n7.77\n0.30\n7.21\n8.34\n0.0\n0.0\n6655.48\n5167.04\n1.0",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#parametrizzazione-non-centrata",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#parametrizzazione-non-centrata",
    "title": "47¬† Inferenza bayesiana su una media",
    "section": "47.2 Parametrizzazione Non Centrata",
    "text": "47.2 Parametrizzazione Non Centrata\nNella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell‚Äôinferenza (\\(\\mu\\) e \\(\\sigma\\)) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro \\(\\mu\\) abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro \\(\\sigma\\) abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare.\n√à possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura √® chiamata ‚Äúparametrizzazione non centrata‚Äù (non-centered parametrization). In questo modello, utilizziamo variabili latenti \\(\\mu_{\\text{raw}}\\) e \\(\\sigma_{\\text{raw}}\\), che seguono una distribuzione normale standard:\n\\[\n\\begin{align}\n\\mu_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\\\\\n\\sigma_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\n\\end{align}\n\\]\nQueste variabili vengono poi trasformate per ottenere i parametri \\(\\mu\\) e \\(\\sigma\\) sulla scala originale:\n\\[\n\\begin{align}\n\\mu &= y_{\\text{mean}} + y_{\\text{sd}} \\cdot \\mu_{\\text{raw}} \\notag\\\\\n\\sigma &= y_{\\text{sd}} \\cdot \\sigma_{\\text{raw}} \\notag\n\\end{align}\n\\]\nDove: - \\(y_{\\text{mean}}\\) √® la media dei dati osservati \\(y\\). - \\(y_{\\text{sd}}\\) √® la deviazione standard dei dati osservati \\(y\\).\n\nstan_ncp_file = os.path.join(project_directory, 'stan', 'gaussian_ncp.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\n\nDi seguito √® riportato il codice Stan per questo modello con la parametrizzazione non centrata:\n\nprint(model_ncp.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\ntransformed data {\n    real y_mean = mean(y);\n    real y_sd = sd(y);\n}\nparameters {\n    real mu_raw;\n    real&lt;lower=0&gt; sigma_raw;\n}\ntransformed parameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Priors:\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    // Likelihood:\n    y ~ normal(mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\n\n\nEcco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.\n\nBlocco Dati:\n\nint&lt;lower=1&gt; N;: Il numero totale di prove o osservazioni.\nvector[N] y;: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.\n\nBlocco Dati Trasformati:\n\nreal y_mean = mean(y);: La media dei dati osservati y.\nreal y_sd = sd(y);: La deviazione standard dei dati osservati y.\n\nBlocco Parametri:\n\nreal mu_raw;: Un parametro latente che segue una distribuzione normale standard.\nreal&lt;lower=0&gt; sigma_raw;: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.\n\nBlocco Parametri Trasformati:\n\nreal mu;: La media della distribuzione normale per y sulla sua scala originale.\nreal&lt;lower=0&gt; sigma;: La deviazione standard della distribuzione normale per y sulla sua scala originale.\nQuesti parametri trasformati sono definiti come:\nmu = y_mean + y_sd * mu_raw;\nsigma = y_sd * sigma_raw;\n\n\nLa parametrizzazione non centrata comporta la riparametrizzazione del modello in termini di variabili standardizzate (mu_raw e sigma_raw) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e propriet√† di convergenza, specialmente nei modelli gerarchici.\n\nParametri Latenti (mu_raw e sigma_raw):\n\nmu_raw ~ normal(0, 1);: mu_raw √® una variabile normale standardizzata.\nsigma_raw ~ normal(0, 1);: sigma_raw √® una variabile normale standardizzata vincolata a essere positiva.\n\nTrasformazione alla Scala Originale:\n\nmu = y_mean + y_sd * mu_raw;: Questo scala e trasla mu_raw alla posizione e scala dei dati osservati y.\nsigma = y_sd * sigma_raw;: Questo scala sigma_raw alla scala dei dati osservati y.\n\n\nLa dichiarazione della verosimiglianza y ~ normal(mu, sigma); indica che i dati osservati y seguono una distribuzione normale con media mu e deviazione standard sigma. Ecco perch√© ha senso anche se y √® sulla sua scala originale:\n\nDati Osservati sulla Scala Originale: I dati osservati y sono sulla loro scala originale.\nParametri sulla Scala Originale: I parametri mu e sigma, dopo la trasformazione nel blocco transformed parameters, sono anch‚Äôessi sulla scala originale di y.\n\nQuindi, la dichiarazione y ~ normal(mu, sigma); specifica correttamente che i dati osservati y (sulla loro scala originale) sono modellati da una distribuzione normale con media mu e deviazione standard sigma, entrambe sulla scala originale di y.\nInfine, il blocco generated quantities viene utilizzato per i controlli predittivi posteriori generando nuovi dati (y_rep) dalla distribuzione posteriore dei parametri (mu e sigma):\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\ny_rep: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore mu e la deviazione standard posteriore sigma. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.\n\nEseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\n_ = az.plot_trace(trace_ncp, var_names=['mu', 'sigma'])\n\n\n\n\n\n\n\n\nOtteniamo una sintesi delle distribuzioni a posteriori dei parametri:\n\nsummary = az.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\nprint(summary)\n\n         mean    sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nmu     154.61  0.42  153.83   155.39       0.01      0.0   6329.64   5029.29   \nsigma    7.76  0.29    7.20     8.30       0.00      0.0   7836.78   5829.76   \n\n       r_hat  \nmu       1.0  \nsigma    1.0  \n\n\nI risultati sono molto simili a quelli ottenuti in precedenza.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#posterior-predictive-check",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#posterior-predictive-check",
    "title": "47¬† Inferenza bayesiana su una media",
    "section": "47.3 Posterior predictive check",
    "text": "47.3 Posterior predictive check\nUno dei vantaggi del toolkit bayesiano √® che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(Œ∏|Y) √® possibile utilizzarla per generare le previsioni p(·ª∏). Matematicamente, questo pu√≤ essere fatto calcolando:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta distribuzione √® nota come distribuzione predittiva posteriore. √à predittiva perch√© viene utilizzata per fare previsioni e posteriore perch√© √® calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.\nUtilizzando Stan √® facile per ottenere campioni predittivi posteriori: non √® necessario calcolare alcun integrale. Dobbiamo convertire l‚Äôoggetto creato dalla funzione sample() nel formato ArviZ InferenceData:\n\n# Convert to ArviZ InferenceData object\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nUn uso comune della distribuzione predittiva posteriore √® quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello √® una buona rappresentazione dei dati. Possiamo utilizzare la funzione plot_ppc di ArviZ per visualizzare la distribuzione predittiva posteriore e i dati osservati. Il codice √®:\n\n# Plot the posterior predictive check\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nNella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee blu sono KDE calcolate da ciascuno dei 500 campioni predittivi posteriori. Le linee blu riflettono l‚Äôincertezza associata alla distribuzione dei dati previsti.\nDi default, in ArviZ le KDE vengono stimati all‚Äôinterno dell‚Äôintervallo effettivo dei dati e si assume che siano zero al di fuori di questo intervallo.\nDato che il tracciato del KDE plot √® contenuto nell‚Äôinsieme di profili dei KDE plot dei campioni predittivi a posteriori, si pu√≤ concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed √® utile per la maggior parte delle analisi. Tuttavia, √® importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all‚Äôintero dataset. Esploreremo ora come poter sviluppare un modello alternativo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#modello-robusto",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#modello-robusto",
    "title": "47¬† Inferenza bayesiana su una media",
    "section": "47.4 Modello ‚Äúrobusto‚Äù",
    "text": "47.4 Modello ‚Äúrobusto‚Äù\nNon √® necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianit√† possono essere considerate attraverso l‚Äôutilizzo della distribuzione t di Student, che √® particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello ‚Äòrobusto‚Äô, maggiormente adatto a gestire osservazioni che si discostano dalla normalit√† nelle code della distribuzione.\nLa distribuzione t di Student √® caratterizzata dal parametro \\(\\nu\\), noto come ‚Äògradi di libert√†‚Äô. Quando \\(\\nu\\) √® pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale.\n\nnu_values = [1, 2, 10]\n\nfig, ax = plt.subplots()\n\nfor nu in nu_values:\n    x = np.linspace(-5, 5, 1000)\n    y = stats.t.pdf(x, df=nu, loc=0, scale=1)\n    ax.plot(x, y, label=f\"ŒΩ={nu}\")\n\nx = np.linspace(-5, 5, 1000)\ny = stats.t.pdf(x, df=np.inf, loc=0, scale=1)\nax.plot(x, y, linestyle=\"--\", color=\"k\", label=\"ŒΩ=‚àû\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTuttavia, le code della distribuzione t di Student risultano pi√π pesanti rispetto a quelle della normale quando \\(\\nu\\) √® basso. Pertanto, proponiamo di assegnare a \\(\\nu\\) una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.\n\n# Define the rate parameter for the exponential distribution\nrate = 1 / 30\n\n# Generate samples from the exponential distribution\nsamples = np.random.exponential(scale=1 / rate, size=10000)\n\n# Create the histogram plot of the samples\nplt.hist(samples, bins=50, density=True, alpha=0.75, label=\"Sampled Distribution\")\nplt.title(\"Exponential Distribution (Œª = 1/30)\")\nplt.xlabel(\"Values\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nstan_student_file = os.path.join(project_directory, 'stan', 'student-model.stan')\nmodel_student = CmdStanModel(stan_file=stan_student_file)\nprint(model_student.code())\n\ndata {\n    int&lt;lower=1&gt; N;  // Numero totale di prove\n    vector[N] y;  // Punteggio in ciascuna prova\n}\ntransformed data {\n    real y_mean = mean(y);  // Media dei dati osservati\n    real y_sd = sd(y);  // Deviazione standard dei dati osservati\n}\nparameters {\n    real mu_raw;  // Parametro latente standardizzato per mu\n    real&lt;lower=0&gt; sigma_raw;  // Parametro latente standardizzato per sigma\n    real&lt;lower=1&gt; nu;  // Gradi di libert√† per la distribuzione t di Student\n}\ntransformed parameters {\n    real mu;  // Media sulla scala originale\n    real&lt;lower=0&gt; sigma;  // Deviazione standard sulla scala originale\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Distribuzioni a priori non centrate\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    nu ~ exponential(1.0 / 30.0);  // Prior esponenziale per i gradi di libert√†\n    // Verosimiglianza\n    y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = student_t_rng(nu, mu, sigma);\n    }\n}\n\n\n\n\ntrace_student = model_student.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori e le tracce dei parametri del nuovo modello.\n\n_ = az.plot_trace(trace_student, var_names=['mu', 'sigma', 'nu'])\n\n\n\n\n\n\n\n\nConvertiamo i risultati in un oggetto InferenceData di ArviZ.\n\nidata = az.from_cmdstanpy(\n    posterior=trace_student,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nGeneriamo la distribuzione predittiva a posteriori.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nLa figura illustra che la situazione √® analoga a quella del caso gaussiano. Questo non √® sorprendente, dato che i dati relativi all‚Äôaltezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l‚Äôimpiego della distribuzione t di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto.\n\naz.summary(trace_student, var_names=['mu', 'sigma', 'nu'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.57\n0.42\n153.85\n155.40\n0.00\n0.00\n8798.72\n6040.50\n1.0\n\n\nsigma\n7.63\n0.30\n7.08\n8.21\n0.00\n0.00\n7145.94\n6226.65\n1.0\n\n\nnu\n62.39\n36.10\n11.40\n129.62\n0.41\n0.31\n7870.31\n5565.90\n1.0",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "title": "47¬† Inferenza bayesiana su una media",
    "section": "47.5 Commenti e considerazioni finali",
    "text": "47.5 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato il metodo per calcolare l‚Äôintervallo di credibilit√† per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l‚Äôinferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "title": "47¬† Inferenza bayesiana su una media",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\narviz     : 0.18.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html",
    "href": "chapters/chapter_4/23_stan_two_groups.html",
    "title": "48¬† Confronto tra due gruppi",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® di ampliare la discussione del Capitolo 47, affrontando il confronto tra le medie di due gruppi indipendenti.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "href": "chapters/chapter_4/23_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.1 Stima bayesiana e test dell‚Äôipotesi nulla",
    "text": "48.1 Stima bayesiana e test dell‚Äôipotesi nulla\nSpesso, ci troviamo ad affrontare la necessit√† di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo √® maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, √® fondamentale utilizzare un modello statistico, poich√© le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o pi√π gruppi √® quello di utilizzare un test statistico. Questo approccio prevede l‚Äôindividuazione di un‚Äôipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l‚Äôutilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L‚Äôipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significativit√† adottare) √® spesso arbitraria e basata su convenzioni piuttosto che sulla specificit√† del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l‚Äôipotesi nulla (Goodman, 1999).\nUn approccio pi√π informativo ed efficace per il confronto tra gruppi √® quello basato sulla stima invece che sul test dell‚Äôipotesi nulla, ed √® guidato dalla probabilit√† bayesiana anzich√© dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio √® intrinsecamente pi√π informativo. Inoltre, viene inclusa una stima dell‚Äôincertezza associata a tale differenza, che tiene conto sia dell‚Äôincertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell‚Äôincertezza causata dalla variabilit√† intrinseca del sistema (incertezza aleatoria).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#un-esempio-illustrativo",
    "href": "chapters/chapter_4/23_stan_two_groups.html#un-esempio-illustrativo",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.2 Un esempio illustrativo",
    "text": "48.2 Un esempio illustrativo\nIn questo esempio, l‚Äôobiettivo √® stimare la differenza tra le medie del quoziente di intelligenza dei bambini di due gruppi distinti in base al livello di scolarit√† della madre. Il primo gruppo include i bambini la cui madre non ha completato le scuole superiori, mentre il secondo gruppo comprende quelli la cui madre ha ottenuto il diploma superiore. Per questo, useremo i dati kidiq e un modello bayesiano al fine di ottenere una stima affidabile della differenza tra le medie dei due gruppi nella popolazione.\nI dati utilizzati sono forniti da Gelman e Hill (2007) e costituiscono un sottocampione estratto dal National Longitudinal Survey of Youth.\nLeggiamo i dati.\n\ndf = pd.read_stata(\"../../data/kidiq.dta\")\ndf.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nIl dataset contiene le seguenti colonne:\n\n‚Äúkid_score‚Äù: il quoziente intellettivo (QI) dei bambini. √à una misura dell‚Äôintelligenza del bambino.\n‚Äúmom_hs‚Äù: una variabile binaria che indica se la madre del bambino ha completato o meno la scuola superiore. Pu√≤ assumere i valori 0 o 1, dove 0 rappresenta ‚Äúno‚Äù (la madre non ha completato la scuola superiore) e 1 rappresenta ‚Äús√¨‚Äù (la madre ha completato la scuola superiore).\n\nCi sono 93 bambini la cui madre non ha completato la scuola superiore e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\ndf.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nLe statistiche descrittive si ottengono nel modo seguente.\n\ndf[\"kid_score\"].mean()\n\n86.79723502304148\n\n\n\nsummary_stats = [np.mean, stat.stdev]\ndf.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1859022749.py:2: FutureWarning: The provided callable &lt;function mean at 0x11c1f6660&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  df.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\nI bambini la cui madre ha completato le superiori tendono ad avere un QI maggiore di 11.8 punti rispetto ai bambini la cui madre non ha concluso le superiori.\n\n89.319648 - 77.548387\n\n11.771260999999996\n\n\nCreiamo due vettori che contengono il QI dei bambini dei due gruppi.\n\n# Vector of kid_score when mom_hs is 1\nkid_score_mom_hs_1 = df[df[\"mom_hs\"] == 1][\"kid_score\"]\n\n# Vector of kid_score when mom_hs is 0\nkid_score_mom_hs_0 = df[df[\"mom_hs\"] == 0][\"kid_score\"]",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#dimensione-delleffetto",
    "href": "chapters/chapter_4/23_stan_two_groups.html#dimensione-delleffetto",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.3 Dimensione dell‚Äôeffetto",
    "text": "48.3 Dimensione dell‚Äôeffetto\nNel caso presente, la differenza tra le medie dei due gruppi √® di 11.8 punti sulla scala del QI, e potrebbe sembrare un risultato rilevante, considerando che la metrica del QI √® facilmente interpretabile. Tuttavia, √® importante notare che il test utilizzato in questo studio non √® il WISC, che ha una distribuzione normale con media 100 e deviazione standard 15, ma il test PIAT.\nIn generale, √® difficile comprendere il significato di una differenza tra le medie di due gruppi quando viene presentata solo come valore assoluto, soprattutto quando le varianze dei gruppi sono diverse. Per ottenere una misura pi√π informativa, √® necessario considerare sia la differenza tra le medie dei gruppi che l‚Äôincertezza associata a queste stime delle medie della popolazione. L‚Äôindice statistico che soddisfa questo scopo √® noto come ‚Äúdimensione dell‚Äôeffetto‚Äù (effect size).\nLa dimensione dell‚Äôeffetto √® una misura della forza dell‚Äôassociazione osservata, che tiene conto sia della grandezza della differenza tra i gruppi attesi che dell‚Äôincertezza sui dati. Tra gli indici pi√π comunemente utilizzati per quantificare la dimensione dell‚Äôeffetto, vi √® l‚Äôindice \\(d\\) di Cohen.\nNel caso di due medie, questo indice √® dato da:\n\\[\nd={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{s}},\n\\]\nladdove\n\\[\ns={\\sqrt {\\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}\n\\]\ne la varianza di ciascun gruppo √® calcolata come\n\\[\ns_{1}^{2}={\\frac {1}{n_{1}-1}}\\sum _{i=1}^{n_{1}}(x_{1,i}-{\\bar {x}}_{1})^{2}.\n\\]\nSolitamente, l‚Äôindice \\(d\\) di Cohen si interpreta usando la metrica seguente:\n\n\n\nDimensione dell‚Äôeffetto\n\\(d\\)\n\n\n\n\nVery small\n0.01\n\n\nSmall\n0.20\n\n\nMedim\n0.50\n\n\nLarge\n0.80\n\n\nVery large\n1.20\n\n\nHuge\n2.0\n\n\n\nPer una trattazione bayesiana della stima della dimensione dell‚Äôeffetto, si veda Kruschke (2014).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#modello-bayesiano",
    "href": "chapters/chapter_4/23_stan_two_groups.html#modello-bayesiano",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.4 Modello bayesiano",
    "text": "48.4 Modello bayesiano\nIl modello bayesiano per il confronto tra le medie di due gruppi indipendenti comprende la definizione della verosimiglianza per i dati di ciascun gruppo e la descrizione delle distribuzioni a priori dei parametri rilevanti. Inoltre, in questo caso, abbiamo incluso anche la stima della dimensione dell‚Äôeffetto, che ci permette di valutare la forza dell‚Äôassociazione osservata tra i gruppi, tenendo conto dell‚Äôincertezza sui dati.\nCreiamo un dizonario con i dati rilevanti.\n\nstan_data = {\n    'N1': len(kid_score_mom_hs_1), \n    'N2': len(kid_score_mom_hs_0), \n    'y1': kid_score_mom_hs_1,\n    'y2': kid_score_mom_hs_0\n}\nstan_data\n\n{'N1': 341,\n 'N2': 93,\n 'y1': 0       65\n 1       98\n 2       85\n 3       83\n 4      115\n       ... \n 425    102\n 426    104\n 430     76\n 432     88\n 433     70\n Name: kid_score, Length: 341, dtype: int32,\n 'y2': 5       98\n 14     102\n 19     101\n 24      99\n 33     106\n       ... \n 422    100\n 427     59\n 428     93\n 429     94\n 431     50\n Name: kid_score, Length: 93, dtype: int32}",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#modello-stan",
    "href": "chapters/chapter_4/23_stan_two_groups.html#modello-stan",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.5 Modello Stan",
    "text": "48.5 Modello Stan\nPer analizzare questi dati ci serviremo del seguente modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'kid-score.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response times (group 1)\n  vector[N2] y2;  // response times (group 2)\n}\n\nparameters {\n  real mu_1;  // mean of group 1\n  real mu_2;  // mean of group 2\n  real&lt;lower=0&gt; sigma_1;  // standard deviation of group 1\n  real&lt;lower=0&gt; sigma_2;  // standard deviation of group 2\n}\n\ntransformed parameters {\n  real delta;  // difference in means\n  real cohen_d;  // Cohen's d effect size\n  delta = mu_1 - mu_2;\n  cohen_d = delta / sqrt((sigma_1^2 + sigma_2^2) / 2);\n}\n\nmodel {\n  // Priors\n  mu_1 ~ normal(80, 20);  // Prior for mean of group 1\n  mu_2 ~ normal(80, 20);  // Prior for mean of group 2\n  sigma_1 ~ normal(0, 10);  // Prior for standard deviation of group 1\n  sigma_2 ~ normal(0, 10);  // Prior for standard deviation of group 2\n\n  // Likelihood\n  y1 ~ normal(mu_1, sigma_1);\n  y2 ~ normal(mu_2, sigma_2);\n}\n\ngenerated quantities {\n  vector[N1] y1_rep;  // replicated data for group 1\n  vector[N2] y2_rep;  // replicated data for group 2\n  for (i in 1:N1) {\n    y1_rep[i] = normal_rng(mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2_rep[i] = normal_rng(mu_2, sigma_2);\n  }\n}\n\n\n\nNel nostro modello: - N1 √® il numero di osservazioni nel primo gruppo (bambini le cui madri hanno completato le superiori) - N2 √® il numero di osservazioni nel secondo gruppo (bambini le cui madri non hanno completato le superiori) - y1 √® un vettore contenente i valori di QI per il primo gruppo - y2 √® un vettore contenente i valori di QI per il secondo gruppo\n\n48.5.1 Spiegazione del modello\n\n48.5.1.1 Parametri\n\nmu_1 e mu_2: Rappresentano le medie dei valori di QI per i due gruppi.\nsigma_1 e sigma_2: Rappresentano le deviazioni standard dei valori dei QI per i due gruppi.\n\n\n\n48.5.1.2 Parametri trasformati\n\ndelta: √à la differenza tra le medie dei due gruppi (mu_1 - mu_2).\ncohen_d: √à la dimensione dell‚Äôeffetto di Cohen, che quantifica la differenza tra i gruppi in unit√† di deviazione standard.\n\n\n\n48.5.1.3 Prior\nImpostiamo delle prior per i parametri:\nmu_1 ~ normal(80, 20);\nmu_2 ~ normal(80, 20);\nsigma_1 ~ normal(0, 10);\nsigma_2 ~ normal(0, 10);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri. Per esempio, ci aspettiamo che i QI medi siano intorno a 80, ma con una certa variabilit√†.\n\n\n48.5.1.4 Likelihood\ny1 ~ normal(mu_1, sigma_1);\ny2 ~ normal(mu_2, sigma_2);\nQuesta parte del modello descrive come i dati osservati (y1 e y2) sono generati, date le medie e le deviazioni standard per ciascun gruppo. Assumiamo che i valori del QI seguano una distribuzione normale in ciascun gruppo.\n\n\n\n48.5.2 Quantit√† generate\ny1_rep[i] = normal_rng(mu_1, sigma_1);\ny2_rep[i] = normal_rng(mu_2, sigma_2);\nQueste righe generano dati ‚Äúreplicati‚Äù basati sul modello stimato. Questi possono essere utilizzati per il controllo del modello (posterior predictive checks).\n\n\n48.5.3 Interpretazione dei risultati\n\nmu_1 e mu_2: Ci dicono i valori QI medi stimati per ciascun gruppo.\nsigma_1 e sigma_2: Ci dicono quanto variano i valori del QI all‚Äôinterno di ciascun gruppo.\ndelta: Ci dice quanto √® grande la differenza nei valori dei QI medi tra i due gruppi.\ncohen_d: Ci fornisce una misura standardizzata della dimensione dell‚Äôeffetto.\n\n\n\n48.5.4 Conclusione\nQuesto modello ci permette di:\n\nStimare i valori dei QI medi e la loro variabilit√† per ciascun gruppo.\nQuantificare la differenza tra i gruppi e la sua incertezza.\nCalcolare una misura standardizzata della dimensione dell‚Äôeffetto (Cohen‚Äôs d).\nGenerare previsioni basate sul modello per future osservazioni.\n\nIl vantaggio principale di questo approccio bayesiano √® che otteniamo distribuzioni di probabilit√† complete per tutti i parametri di interesse, permettendoci di fare affermazioni probabilistiche sulla differenza tra i gruppi e sulla dimensione dell‚Äôeffetto.\nEseguiamo il campionamento MCMC:\n\nsample = model.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:30:52 - cmdstanpy - INFO - CmdStan start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] start processing\n10:30:52 - cmdstanpy - INFO - Chain [2] start processing\n10:30:52 - cmdstanpy - INFO - Chain [3] start processing\n10:30:52 - cmdstanpy - INFO - Chain [4] start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] done processing\n10:30:52 - cmdstanpy - INFO - Chain [3] done processing\n10:30:52 - cmdstanpy - INFO - Chain [2] done processing\n10:30:52 - cmdstanpy - INFO - Chain [4] done processing\n10:30:52 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\n    Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(\n    sample, \n    figsize=(9, 12), \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    divergences=\"bottom\"\n)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1925110735.py:7: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe distribuzioni predittive a posteriori sono adeguate, senza essere perfette.\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y1_rep'], \n    observed_data={\"y1\": stan_data[\"y1\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y1\": \"y1_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y2_rep'], \n    observed_data={\"y2\": stan_data[\"y2\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y2\": \"y2_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(\n    sample, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.28\n1.04\n87.33\n91.18\n0.02\n0.01\n3990.38\n2947.67\n1.0\n\n\nmu_2\n77.61\n2.27\n73.61\n82.01\n0.03\n0.02\n4317.58\n2940.56\n1.0\n\n\nsigma_1\n19.03\n0.73\n17.70\n20.42\n0.01\n0.01\n4729.21\n3162.76\n1.0\n\n\nsigma_2\n22.27\n1.63\n19.35\n25.38\n0.02\n0.02\n4419.97\n2908.53\n1.0\n\n\ndelta\n11.67\n2.47\n6.89\n16.32\n0.04\n0.03\n4346.03\n2887.27\n1.0\n\n\ncohen_d\n0.56\n0.12\n0.33\n0.78\n0.00\n0.00\n4334.34\n2953.62\n1.0",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#modello-robusto",
    "href": "chapters/chapter_4/23_stan_two_groups.html#modello-robusto",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.6 Modello Robusto",
    "text": "48.6 Modello Robusto\nUn modello bayesiano robusto per il confronto tra due medie indipendenti pu√≤ gestire deviazioni standard disuguali e outlier sostituendo la verosimiglianza normale con quella della distribuzione t di Student. Utilizzare una distribuzione t di Student al posto di una normale rende il modello pi√π resistente agli outlier. La distribuzione t di Student ha code pi√π pesanti rispetto alla normale, il che significa che √® meno influenzata da valori estremi nei dati. Questo √® particolarmente utile quando si sospetta la presenza di outlier nei dati o quando le deviazioni standard tra i gruppi sono disuguali. In questo modo, il modello bayesiano robusto offre stime pi√π affidabili delle medie e delle deviazioni standard dei gruppi, nonch√© della differenza tra le medie e della dimensione dell‚Äôeffetto.\n\nstan_file_t = os.path.join(project_directory, 'stan', 'kid-score-t.stan')\nmodel_t = CmdStanModel(stan_file=stan_file_t)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_t = model_t.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:31:20 - cmdstanpy - INFO - CmdStan start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] start processing\n10:31:20 - cmdstanpy - INFO - Chain [2] start processing\n10:31:20 - cmdstanpy - INFO - Chain [3] start processing\n10:31:20 - cmdstanpy - INFO - Chain [4] start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] done processing\n10:31:20 - cmdstanpy - INFO - Chain [3] done processing\n10:31:20 - cmdstanpy - INFO - Chain [2] done processing\n10:31:20 - cmdstanpy - INFO - Chain [4] done processing\n10:31:20 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nNel caso presente, usare un modello robusto non produce nessuna differenza rispetto al modello precedente in quanto non ci sono deviazoni importanti rispetto alla gaussianit√† e le due deviazioni standard sono simili.\n\naz.summary(\n    sample_t, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.49\n1.07\n87.43\n91.37\n0.02\n0.01\n3892.59\n3003.83\n1.0\n\n\nmu_2\n78.39\n2.29\n74.04\n82.63\n0.05\n0.03\n2486.44\n2273.07\n1.0\n\n\nsigma_1\n18.43\n0.77\n17.04\n19.94\n0.01\n0.01\n3278.45\n2545.50\n1.0\n\n\nsigma_2\n21.71\n1.62\n18.77\n24.82\n0.03\n0.02\n3175.33\n2299.83\n1.0\n\n\ndelta\n11.11\n2.50\n6.40\n15.82\n0.05\n0.04\n2487.74\n2084.50\n1.0\n\n\ncohen_d\n0.55\n0.13\n0.33\n0.81\n0.00\n0.00\n2496.90\n2123.93\n1.0",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#modello-con-iper-priors",
    "href": "chapters/chapter_4/23_stan_two_groups.html#modello-con-iper-priors",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.7 Modello con Iper-priors",
    "text": "48.7 Modello con Iper-priors\nIl seguente modello bayesiano per il confronto tra due medie indipendenti utilizza una distribuzione di Student‚Äôs t per gestire deviazioni standard disuguali e outlier. Inoltre, include iper-priors per una maggiore flessibilit√† nella definizione dei parametri delle distribuzioni a priori, che vengono stimate dai dati. Questo approccio permette di incorporare in modo pi√π efficace le incertezze sui parametri dei priors stessi, migliorando la robustezza del modello.\n\nstan_file_h = os.path.join(project_directory, 'stan', 'kid-score-h.stan')\nmodel_h = CmdStanModel(stan_file=stan_file_h)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_h = model_h.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=2_000, iter_warmup=1_000,\n    show_progress=False, show_console=False\n)\n\n10:31:27 - cmdstanpy - INFO - CmdStan start processing\n10:31:27 - cmdstanpy - INFO - Chain [1] start processing\n10:31:27 - cmdstanpy - INFO - Chain [2] start processing\n10:31:27 - cmdstanpy - INFO - Chain [3] start processing\n10:31:27 - cmdstanpy - INFO - Chain [4] start processing\n10:31:28 - cmdstanpy - INFO - Chain [1] done processing\n10:31:28 - cmdstanpy - INFO - Chain [4] done processing\n10:31:28 - cmdstanpy - INFO - Chain [2] done processing\n10:31:28 - cmdstanpy - INFO - Chain [3] done processing\n10:31:28 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n10:31:28 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 1 had 25 divergent transitions (1.2%)\n    Chain 2 had 8 divergent transitions (0.4%)\n    Chain 3 had 24 divergent transitions (1.2%)\n    Chain 4 had 12 divergent transitions (0.6%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\nAnche in questo caso, la risposta non cambia:\n\naz.summary(\n    sample_h, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.52\n1.03\n87.65\n91.54\n0.01\n0.01\n8653.78\n6400.92\n1.0\n\n\nmu_2\n78.30\n2.29\n73.95\n82.52\n0.03\n0.02\n5688.16\n5777.55\n1.0\n\n\nsigma_1\n18.43\n0.79\n16.97\n19.94\n0.01\n0.01\n7954.84\n5392.71\n1.0\n\n\nsigma_2\n21.88\n1.65\n18.88\n25.08\n0.02\n0.01\n9745.94\n5250.42\n1.0\n\n\ndelta\n11.22\n2.50\n6.51\n15.83\n0.03\n0.02\n5590.51\n6029.02\n1.0\n\n\ncohen_d\n0.56\n0.13\n0.32\n0.79\n0.00\n0.00\n5626.06\n5815.05\n1.0\n\n\n\n\n\n\n\n\nIl nostro obiettivo √® comprendere se le medie dei due gruppi sono diverse, e l‚Äôincertezza associata alla stima a posteriori del parametro delta √® fondamentale per rispondere a questa domanda. Se l‚Äôintervallo di credibilit√† associato a delta non include lo 0, allora possiamo concludere con un certo grado di sicurezza che le medie dei due gruppi sono diverse. In altre parole, se l‚Äôintervallo di credibilit√† non contiene lo 0, allora ci sono prove convincenti che le medie dei due gruppi sono diverse.\nNel caso presente, l‚Äôintervallo di credibilit√† al 94% non include lo 0. Pertanto, possiamo concludere, con un livello di sicurezza soggettivo del 94%, che il QI dei bambini le cui madri hanno completato le scuole superiori tende ad essere pi√π elevato rispetto a quello dei bambini le cui madri non hanno completato le scuole superiori.\n\n_ = az.plot_posterior(sample_h, var_names=\"delta\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nLa figura seguente mostra la distribuzione a posteriori della grandezza dell‚Äôeffetto.\n\n_ = az.plot_posterior(sample_h, var_names=\"cohen_d\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nPossiamo dunque concludere che, per ci√≤ che concerne l‚Äôeffetto della scolarit√† della madre sul quoziente di intelligenza del bambino, la dimensione dell‚Äôeffetto √® ‚Äúmedia‚Äù.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/chapter_4/23_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.8 Verifica di ipotesi bayesiana",
    "text": "48.8 Verifica di ipotesi bayesiana\nCome ulteriore approfondimento di questa analisi statistica, possiamo esaminare l‚Äôapproccio bayesiano equivalente al test di ipotesi tradizionale.\nDopo aver ottenuto un campione dalla distribuzione a posteriori del parametro di interesse \\(\\mu\\) per ciascun gruppo, possiamo porci la domanda: qual √® la probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo? Per rispondere a questa domanda, utilizzeremo campioni casuali dalle distribuzioni a posteriori dei parametri. Confronteremo le coppie di valori campionati dalle due distribuzioni a posteriori del parametro di interesse e calcoleremo la media di tali confronti. Questo ci fornir√† un‚Äôindicazione sulla probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo, basandoci sulla distribuzione a posteriori dei parametri stimati dal modello.\nPer eseguire un test d‚Äôipotesi per calcolare la probabilit√† che $ _1 &gt; _2 $ utilizzando il modello Stan fornito e cmdstanpy, √® necessario estrarre i campioni posteriori per i parametri \\(\\mu_1\\) e \\(\\mu_2\\) dopo aver adattato il modello. Successivamente, √® possibile calcolare la probabilit√† basandosi sui campioni posteriori. Ad esempio, ci possiamo chiedere quale sia la probabilit√† che un bambino la cui madre ha completato la scuola superiore abbia un QI maggiore di un bambino la cui madre non ha completato la scuola superiore.\n\n# Extract the posterior samples for mu_1 and mu_2\nposterior = sample_h.draws_pd()\nposterior['mu_1'] = posterior['mu_2'] + posterior['delta']\n\n# Compute the probability that mu_1 &gt; mu_2\nprob_mu1_greater_mu2 = np.mean(posterior['mu_1'] &gt; posterior['mu_2'])\n\nprint(f\"Probability that mu_1 &gt; mu_2: {prob_mu1_greater_mu2:.4f}\")\n\nProbability that mu_1 &gt; mu_2: 1.0000\n\n\nUna tale probabilit√† √® effettivamente uguale a 1 il che conferma il risultato precedente, ovvero l‚Äôiportanza del livello di istruzione della madre per il QI del figlio.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/23_stan_two_groups.html#commenti-e-considerazioni-finali",
    "title": "48¬† Confronto tra due gruppi",
    "section": "48.9 Commenti e considerazioni finali",
    "text": "48.9 Commenti e considerazioni finali\nIn questo capitolo abbiamo esaminato la procedura bayesiana per calcolare la distribuzione a posteriori della differenza tra le medie di due gruppi indipendenti. Inoltre, abbiamo esplorato il calcolo della dimensione dell‚Äôeffetto in termini bayesiani. Nell‚Äôesempio trattato, abbiamo considerato il caso in cui la verosimiglianza √® descritta da una distribuzione Gaussiana. Tuttavia, va sottolineato che la scelta di una distribuzione specifica per la verosimiglianza non √® vincolante nella statistica bayesiana. √à possibile utilizzare qualsiasi distribuzione di probabilit√†, purch√© sia adeguata ai dati del campione.\nNel caso del confronto tra le medie di due gruppi indipendenti, una distribuzione molto utilizzata √® la distribuzione \\(t\\) di Student. Questa distribuzione √® particolarmente vantaggiosa quando si desidera condurre un‚Äôanalisi statistica ‚Äúrobusta‚Äù, ovvero un‚Äôanalisi che non sia influenzata da osservazioni anomale o outlier presenti nei dati. Per questo motivo, la distribuzione \\(t\\) di Student √® spesso preferita quando si lavora con dati che potrebbero contenere valori anomali.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/23_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/23_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "title": "48¬† Confronto tra due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBland, J Martin, e Douglas G Altman. 2011. ¬´Comparisons within randomised groups can be very misleading¬ª. Bmj 342.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/24_stan_hier_beta_binom.html",
    "href": "chapters/chapter_4/24_stan_hier_beta_binom.html",
    "title": "49¬† Modello gerarchico beta-binomiale con Stan",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo il concetto di modellazione gerarchica nel contesto Bayesiano. Partiamo da un esempio semplice per introdurre la stima statistica: consideriamo un‚Äôurna con palline di colore blu e rosso. Estraendo un campione di 10 palline, possiamo stimare la proporzione di palline blu presenti nell‚Äôurna. Questo scenario classico ci introduce ai fondamenti della stima statistica.\nImmaginiamo ora una situazione pi√π complessa: abbiamo a disposizione una grande urna che contiene al suo interno 10 urne pi√π piccole, ciascuna delle quali √® riempita con proprie palline blu e rosse. Supponiamo di scegliere 7 di queste urne minori ed estrarre 10 palline da ciascuna. La questione √®: come analizziamo questi dati?\nUna possibile soluzione √® trattare ogni urna piccola come un‚Äôentit√† completamente indipendente, ripetendo il problema statistico base per sette volte. Questo metodo, tuttavia, non √® ideale perch√© assume che non ci sia nessuna correlazione tra le urne piccole, ignorando il fatto che tutte provengono da una urna comune pi√π grande che potrebbe influenzarne il contenuto.\nUn altro metodo potrebbe essere quello di ignorare completamente la presenza delle urne minori e focalizzarsi unicamente sulla stima della proporzione totale di palline blu nell‚Äôurna grande. Questo approccio, per√≤, trascura completamente la struttura gerarchica dei dati, ossia il fatto che le palline sono organizzate in urne separate.\nIl metodo pi√π appropriato per analizzare questa situazione √® attraverso la modellazione gerarchica. Con questo approccio, ci proponiamo di stimare non solo la proporzione di palline blu in ogni urna minore, ma anche di comprendere quanto le urne sono correlate tra loro. L‚Äôurna grande funge da modello generativo per le urne pi√π piccole, e comprendere questa relazione sottostante ci consente di fare previsioni pi√π accurate sulla proporzione di palline blu in ogni urna minore, riconoscendo e sfruttando la struttura gerarchica dei dati.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/24_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "href": "chapters/chapter_4/24_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "title": "49¬† Modello gerarchico beta-binomiale con Stan",
    "section": "49.1 Analisi bayesiana della ‚Äúterapia tattile‚Äù",
    "text": "49.1 Analisi bayesiana della ‚Äúterapia tattile‚Äù\nEsaminiamo un problema presentato nel lavoro di {cite:t}doing_bayesian_data_an riguardante la ‚Äúterapia tattile‚Äù (Therapeutic Touch), una pratica infermieristica incentrata sulla manipolazione del presunto ‚Äúcampo energetico‚Äù di un paziente. Nonostante la sua prevalenza nelle scuole di infermieristica e negli ospedali negli Stati Uniti, come riportato da {cite:t}rosa1998close, evidenze empiriche a supporto della sua efficacia sono scarse o assenti.\nIl focus dell‚Äôindagine di {cite:t}rosa1998close √® una delle asserzioni cardine degli operatori di terapia tattile: la presunta capacit√† di percepire i campi energetici senza contatto visivo. Per testare questa affermazione, √® stato progettato un esperimento in cui gli operatori ponevano le loro mani attraverso un pannello che bloccava la visione. In ciascuna prova, un esaminatore, seguendo l‚Äôesito di un lancio di moneta, posizionava la sua mano sopra una delle mani dell‚Äôoperatore. L‚Äôoperatore doveva quindi identificare quale delle sue mani era stata ‚Äúselezionata‚Äù dall‚Äôesaminatore. Ogni tentativo √® stato classificato come ‚Äúcorretto‚Äù o ‚Äúerrato‚Äù.\nL‚Äôunit√† di osservazione in questo esperimento √® costituita da un set di 10 prove per operatore. In totale, lo studio ha coinvolto 21 operatori, con sette di loro sottoposti a retest dopo circa un anno. I dati di retest sono stati trattati come entit√† indipendenti, portando a un campione effettivo di 28 osservazioni. La metrica di interesse √® la proporzione di risposte corrette per ciascun operatore, con una proporzione attesa di 0.50 sotto l‚Äôipotesi nulla di performance casuale.\nLa domanda della ricerca centrale √® se il campione nel suo complesso √® in grado di ottenere una prestazione superiore a quella attesa in base al caso soltanto e, inoltre, se vi sono variazioni nelle prestazioni individuali.\nInizieremo importando i dati forniti da {cite:t}doing_bayesian_data_an.\n\n# Define the URL of the CSV file on GitHub\nurl = \"https://raw.githubusercontent.com/boboppie/kruschke-doing_bayesian_data_analysis/master/2e/TherapeuticTouchData.csv\"\n# Download the content of the CSV file\nresponse = requests.get(url)\ntt_dat = pd.read_csv(StringIO(response.text))\nprint(tt_dat.head())\n\n   y    s\n0  1  S01\n1  0  S01\n2  0  S01\n3  0  S01\n4  0  S01\n\n\n\ntt_dat.shape\n\n(280, 2)\n\n\nNella colonna y, il valore 1 indica una risposta corretta, mentre 0 indica una risposta errata. La seconda colonna contiene il codice identificativo di ciascun operatore.\nCalcoliamo la proporzione di risposte corrette per ciascun operatore.\n\ntt_agg = tt_dat.groupby(\"s\").agg(proportion_correct=(\"y\", \"mean\")).reset_index()\ntt_agg\n\n\n\n\n\n\n\n\n\ns\nproportion_correct\n\n\n\n\n0\nS01\n0.1\n\n\n1\nS02\n0.2\n\n\n2\nS03\n0.3\n\n\n3\nS04\n0.3\n\n\n4\nS05\n0.3\n\n\n5\nS06\n0.3\n\n\n6\nS07\n0.3\n\n\n7\nS08\n0.3\n\n\n8\nS09\n0.3\n\n\n9\nS10\n0.3\n\n\n10\nS11\n0.4\n\n\n11\nS12\n0.4\n\n\n12\nS13\n0.4\n\n\n13\nS14\n0.4\n\n\n14\nS15\n0.4\n\n\n15\nS16\n0.5\n\n\n16\nS17\n0.5\n\n\n17\nS18\n0.5\n\n\n18\nS19\n0.5\n\n\n19\nS20\n0.5\n\n\n20\nS21\n0.5\n\n\n21\nS22\n0.5\n\n\n22\nS23\n0.6\n\n\n23\nS24\n0.6\n\n\n24\nS25\n0.7\n\n\n25\nS26\n0.7\n\n\n26\nS27\n0.7\n\n\n27\nS28\n0.8\n\n\n\n\n\n\n\n\nCostruiamo un modello gerarchico partendo dall‚Äôipotesi che il numero di risposte corrette di ciascun operatore sia modellato da una variabile casuale binomiale. Per ciascuno dei ventotto operatori, possiamo esprimere questo come segue:\n\\[\ny_i \\sim \\text{Binomial}(n_i, p_i),\n\\]\ndove \\(i = 0, \\dots, 27\\).\nPer modellare la distribuzione a priori del parametro sconosciuto \\(p_i\\), possiamo utilizzare una distribuzione Beta con parametri \\(a\\) e \\(b\\) ‚Äì si veda {cite:t}doingbayesian:\n\\[\np_i \\sim \\text{Beta}(a, b).\n\\]\n√à importante notare che gli iperparametri \\(a\\) e \\(b\\) sono condivisi tra tutti gli operatori, caratteristica che definisce un modello gerarchico.\nSe \\(a\\) e \\(b\\) sono noti, la distribuzione a posteriori del parametro \\(p\\) per ciascun operatore, dati i risultati osservati \\(y_i\\), √® anch‚Äôessa una distribuzione Beta:\n\\[\np_i \\mid y_i \\sim \\text{Beta}(a + y_i, b + n_i - y_i).\n\\]\nNel caso pi√π generale, dove gli iperparametri \\(a\\) e \\(b\\) sono incogniti, √® necessario stabilire una distribuzione a priori anche per questi. Nell‚Äôesempio seguente, useremo i seguenti prior:\n\\[\na \\sim \\text{Gamma}(8, 12)\\\\\nb \\sim \\text{Gamma}(27, 5)\n\\]\nPer applicare il modello gerarchico descritto sopra ai dati del therapeutic touch, iniziamo a calcolare il numero di risposte corrette di ciascun operatore.\n\nresult = tt_dat.groupby(\"s\")[\"y\"].sum().reset_index()\ny = result[\"y\"]\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreiamo il vettore N che fornisce il numero di prove per ciascun operatore.\n\nN = tt_dat.groupby(\"s\")[\"y\"].count()\n\nEsaminiamo dunque i dati a disposizione.\n\nprint(*N)\n\n10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n\n\n\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreaiamo un dizionario con i dati necessari per Stan.\n\ndata = {\n    \"N\": 28,\n    \"y\": y.tolist(),\n    \"n_trials\": N.tolist()\n}\n\nprint(data)\n\n{'N': 28, 'y': [1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 7, 8], 'n_trials': [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]}",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/24_stan_hier_beta_binom.html#modello-stan",
    "href": "chapters/chapter_4/24_stan_hier_beta_binom.html#modello-stan",
    "title": "49¬† Modello gerarchico beta-binomiale con Stan",
    "section": "49.2 Modello Stan",
    "text": "49.2 Modello Stan\nLeggiamo il codice Stan che implementa il modello descritto nel capitolo {ref}hier_beta_binom_model.\n\nstan_file = os.path.join(project_directory, \"stan\", \"h_beta_binom_model.stan\")\n\nwith open(stan_file, \"r\") as f:\n    print(f.read())\n\ndata {\n  int&lt;lower=0&gt; N;  // Number of participants\n  array[N] int&lt;lower=0&gt; y;  // Number of successes for each participant\n  array[N] int&lt;lower=0&gt; n_trials;  // Number of trials for each participant\n}\n\nparameters {\n  real&lt;lower=0&gt; alpha;  // Alpha parameter for the Beta distribution\n  real&lt;lower=0&gt; beta;   // Beta parameter for the Beta distribution\n  array[N] real&lt;lower=0, upper=1&gt; p;  // Success probability for each participant\n}\n\nmodel {\n  // Priors\n  alpha ~ gamma(8, 2);\n  beta ~ gamma(27, 5);\n  \n  // Each participant's success probability follows a Beta distribution\n  p ~ beta(alpha, beta);\n  \n  // Likelihood of the observed data\n  for (i in 1:N) {\n    y[i] ~ binomial(n_trials[i], p[i]);\n  }\n}\n\ngenerated quantities {\n  real overall_p = alpha / (alpha + beta);  // Calculate the mean success probability\n}\n\n\n\nNel nostro modello: - N √® il numero totale di partecipanti - y √® un array che contiene il numero di successi per ogni partecipante - n_trials √® un array che contiene il numero di prove per ogni partecipante\n\n49.2.1 Il concetto di gerarchia\nIl modello √® chiamato ‚Äúgerarchico‚Äù perch√© considera due livelli: 1. Il livello individuale: ogni partecipante ha la propria probabilit√† di successo 2. Il livello di gruppo: c‚Äô√® una distribuzione generale che descrive come variano le probabilit√† di successo tra i partecipanti\n\n\n49.2.2 Spiegazione del modello\n\n49.2.2.1 Parametri\n\np: √à un array che contiene la vera probabilit√† di successo per ogni partecipante.\nalpha e beta: Sono i parametri che definiscono la distribuzione Beta, che descrive come variano le probabilit√† di successo tra i partecipanti.\n\n\n\n49.2.2.2 Prior\nImpostiamo delle prior per alpha e beta:\nalpha ~ gamma(8, 2);\nbeta ~ gamma(27, 5);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri.\n\n\n49.2.2.3 Il cuore del modello\np ~ beta(alpha, beta);\nQuesta riga √® il cuore del modello gerarchico. Dice che la probabilit√† di successo di ogni partecipante (p) segue una distribuzione Beta, i cui parametri sono alpha e beta. Questo crea un legame tra tutti i partecipanti: le loro prestazioni individuali sono considerate come variazioni attorno a una tendenza generale del gruppo.\n\n\n49.2.2.4 Likelihood\nfor (i in 1:N) {\n  y[i] ~ binomial(n_trials[i], p[i]);\n}\nQuesta parte del modello descrive come i dati osservati (y) sono generati, dato il numero di prove (n_trials) e la vera probabilit√† di successo (p) per ogni partecipante.\n\n\n\n49.2.3 Quantit√† generate\nreal overall_p = alpha / (alpha + beta);\nQuesta riga calcola la probabilit√† di successo media per l‚Äôintero gruppo.\n\n\n49.2.4 Conclusione\nQuesto modello ci permette di: 1. Stimare la probabilit√† di successo individuale per ogni partecipante 2. Comprendere come queste probabilit√† variano nel gruppo 3. Ottenere una stima della probabilit√† di successo media per l‚Äôintero gruppo\nIl vantaggio principale di questo approccio gerarchico √® che combina informazioni a livello individuale e di gruppo, permettendo stime pi√π precise, specialmente per i partecipanti con pochi dati.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/24_stan_hier_beta_binom.html#compilazione-e-sampling",
    "href": "chapters/chapter_4/24_stan_hier_beta_binom.html#compilazione-e-sampling",
    "title": "49¬† Modello gerarchico beta-binomiale con Stan",
    "section": "49.3 Compilazione e sampling",
    "text": "49.3 Compilazione e sampling\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(\n    data=data,\n    iter_warmup=2000, \n    iter_sampling=4000,\n    seed=84735, \n    chains=4,\n    show_progress=False, \n    show_console=False\n)",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/24_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "href": "chapters/chapter_4/24_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "title": "49¬† Modello gerarchico beta-binomiale con Stan",
    "section": "49.4 Esame delle distribuzioni a posteriori",
    "text": "49.4 Esame delle distribuzioni a posteriori\nEsaminiamo le stime a posteriori dei parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"p\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n4.591\n0.866\n2.991\n6.359\n0.008\n0.006\n10600.0\n10141.0\n1.0\n\n\nbeta\n5.756\n0.932\n4.009\n7.623\n0.008\n0.006\n12032.0\n11787.0\n1.0\n\n\np[0]\n0.273\n0.100\n0.091\n0.469\n0.001\n0.000\n20279.0\n11628.0\n1.0\n\n\np[1]\n0.324\n0.103\n0.129\n0.524\n0.001\n0.001\n20614.0\n11911.0\n1.0\n\n\np[2]\n0.373\n0.107\n0.174\n0.588\n0.001\n0.001\n20791.0\n11355.0\n1.0\n\n\np[3]\n0.372\n0.106\n0.179\n0.590\n0.001\n0.001\n22416.0\n11620.0\n1.0\n\n\np[4]\n0.373\n0.107\n0.173\n0.582\n0.001\n0.001\n22260.0\n11753.0\n1.0\n\n\np[5]\n0.374\n0.106\n0.173\n0.583\n0.001\n0.001\n21443.0\n12716.0\n1.0\n\n\np[6]\n0.372\n0.106\n0.172\n0.580\n0.001\n0.001\n21992.0\n12317.0\n1.0\n\n\np[7]\n0.372\n0.106\n0.173\n0.582\n0.001\n0.001\n21133.0\n11017.0\n1.0\n\n\np[8]\n0.372\n0.105\n0.176\n0.583\n0.001\n0.001\n21459.0\n11369.0\n1.0\n\n\np[9]\n0.372\n0.108\n0.167\n0.580\n0.001\n0.001\n22007.0\n11102.0\n1.0\n\n\np[10]\n0.422\n0.108\n0.209\n0.627\n0.001\n0.001\n21331.0\n12556.0\n1.0\n\n\np[11]\n0.421\n0.109\n0.217\n0.634\n0.001\n0.001\n22045.0\n11591.0\n1.0\n\n\np[12]\n0.422\n0.108\n0.213\n0.632\n0.001\n0.001\n22874.0\n12190.0\n1.0\n\n\np[13]\n0.421\n0.110\n0.214\n0.637\n0.001\n0.001\n22807.0\n12055.0\n1.0\n\n\np[14]\n0.421\n0.109\n0.213\n0.634\n0.001\n0.001\n21851.0\n12199.0\n1.0\n\n\np[15]\n0.471\n0.112\n0.257\n0.689\n0.001\n0.001\n22072.0\n10892.0\n1.0\n\n\np[16]\n0.471\n0.111\n0.249\n0.680\n0.001\n0.001\n22559.0\n11739.0\n1.0\n\n\np[17]\n0.470\n0.111\n0.258\n0.683\n0.001\n0.001\n23384.0\n11679.0\n1.0\n\n\np[18]\n0.471\n0.111\n0.259\n0.688\n0.001\n0.001\n22495.0\n11479.0\n1.0\n\n\np[19]\n0.471\n0.111\n0.264\n0.691\n0.001\n0.001\n22949.0\n11720.0\n1.0\n\n\np[20]\n0.472\n0.110\n0.251\n0.680\n0.001\n0.001\n22288.0\n11847.0\n1.0\n\n\np[21]\n0.472\n0.109\n0.264\n0.685\n0.001\n0.001\n24414.0\n12216.0\n1.0\n\n\np[22]\n0.519\n0.109\n0.306\n0.728\n0.001\n0.001\n22363.0\n11502.0\n1.0\n\n\np[23]\n0.521\n0.111\n0.305\n0.732\n0.001\n0.001\n20720.0\n11618.0\n1.0\n\n\np[24]\n0.570\n0.109\n0.357\n0.780\n0.001\n0.001\n22438.0\n11048.0\n1.0\n\n\np[25]\n0.570\n0.109\n0.349\n0.772\n0.001\n0.001\n20850.0\n12520.0\n1.0\n\n\np[26]\n0.569\n0.110\n0.358\n0.786\n0.001\n0.001\n21973.0\n11715.0\n1.0\n\n\np[27]\n0.620\n0.107\n0.409\n0.821\n0.001\n0.001\n22119.0\n11629.0\n1.0\n\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilit√† di una risposta corretta per tutto il gruppo.\nConvertiamo l‚Äôoggetto fit creato da cmdstanpy in un oggetto InferenceData usando ArviZ:\n\nidata = az.from_cmdstanpy(posterior=fit)",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/24_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "href": "chapters/chapter_4/24_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "title": "49¬† Modello gerarchico beta-binomiale con Stan",
    "section": "49.5 Schrinkage bayesiano",
    "text": "49.5 Schrinkage bayesiano\nNel contesto dei modelli gerarchici bayesiani, il fenomeno dello ‚Äúshrinkage‚Äù (o riduzione) √® un aspetto fondamentale e desiderabile, specialmente quando si modellano dati provenienti da gruppi o sotto-popolazioni con campionature di dimensioni diverse o variazioni intrinseche. Questo fenomeno pu√≤ essere particolarmente rilevante e utile nel tuo modello gerarchico per il numero di risposte corrette di ciascun operatore, modello che utilizza una distribuzione binomiale per le osservazioni e una Beta per i priori dei parametri di successo $ p_i $.\n\n49.5.1 Cosa Significa Shrinkage in un Modello Gerarchico?\nLo ‚Äúshrinkage‚Äù in un modello bayesiano gerarchico si riferisce al processo per cui le stime dei parametri individuali (ad esempio, le probabilit√† di successo per ciascun operatore nel presente modello) sono ‚Äúspostate‚Äù verso una media di gruppo. Questo accade perch√© il modello considera sia i dati osservati per ciascun gruppo (o individuo) sia le informazioni aggiuntive fornite dalla struttura gerarchica e dai dati degli altri gruppi.\n\n\n49.5.2 Meccanismo dello Shrinkage\nNel presente modello: - Ogni operatore ha una probabilit√† di successo $ p_i $ che segue una distribuzione Beta $ (a, b) $, dove $ a $ e $ b $ sono iperparametri condivisi tra tutti gli operatori. - Gli iperparametri $ a $ e $ b $ sono stimati dai dati di tutti gli operatori, e quindi forniscono una base comune che riflette le caratteristiche medie di tutti gli operatori.\nSe un operatore ha pochi dati (ad esempio, pochi tentativi o risposte), la stima di $ p_i $ per quell‚Äôoperatore sar√† fortemente influenzata dai valori di $ a $ e $ b $, ‚Äúspostando‚Äù la stima di $ p_i $ verso la media di gruppo. Questo riduce l‚Äôimpatto delle fluttuazioni casuali nei dati di quell‚Äôoperatore, che potrebbero altrimenti portare a stime eccessivamente ottimistiche o pessimistiche.\n\n\n49.5.3 Benefici dello Shrinkage\n\nMigliore Stima per Gruppi con Pochi Dati: Operatori con meno dati beneficiano maggiormente dello shrinkage, in quanto le loro stime sono stabilizzate attraverso l‚Äôinformazione ‚Äúprestata‚Äù dagli altri operatori.\nRiduzione dell‚ÄôOverfitting: Il modello evita di adattarsi troppo ai dati di un singolo operatore, specialmente quando questi sono limitati o rumorosi, risultando in generalizzazioni pi√π robuste.\nIncorporazione della Struttura dei Dati: Lo shrinkage riflette l‚Äôassunzione che gli operatori siano simili ma non identici, permettendo una certa individualit√† ma entro un quadro comune che li lega.\n\nSupponiamo che alcuni operatori abbiano mostrato risultati estremamente buoni o cattivi, che potrebbero essere dovuti a varianze casuali. Lo shrinkage modera queste stime estreme, specialmente se non sono supportate da una grande quantit√† di dati, rendendo le previsioni finali pi√π credibili e meno soggette a errori casuali.\nIn conclusione, lo shrinkage in un modello gerarchico aiuta a ottenere stime pi√π accurate e credibili per tutti i membri del gruppo, sfruttando le informazioni collettive e limitando l‚Äôimpatto delle anomalie nei dati individuali.\nPer rappresentare visivamente questo fenomeno, iniziamo con il recuperare le stime a posteriori di alpha e beta.\n\nalphas = idata.posterior[\"alpha\"]\nbetas = idata.posterior[\"beta\"]\n\nCreiamo un array che contiene le stime bayesiane della probabilit√† di successo di ciascun operatore fornite sopra dalla funzione summary di ArviZ. Per fare questo usiamo le funzionalit√† di xarray.\n\n# Calcola la media lungo le dimensioni 'chain' e 'draw'\nbayesian_estimates = idata.posterior[\"p\"].mean(dim=(\"chain\", \"draw\"))\nprint(bayesian_estimates.values)\n\n[0.27273311 0.32377131 0.37344338 0.37214022 0.37257493 0.37351838\n 0.37219305 0.37214675 0.37185773 0.37173435 0.42165569 0.42127528\n 0.42172633 0.42118034 0.42149943 0.47116033 0.47087155 0.46970487\n 0.47107502 0.47138671 0.47205312 0.47221249 0.51906367 0.52052519\n 0.57032404 0.57017976 0.56928041 0.62016621]\n\n\nGeneriamo un array con le probabilit√† empiriche.\n\n# Empirical probabilities\nempirical_probs = y.values / N.values\nprint(empirical_probs)\n\n[0.1 0.2 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.5 0.5 0.5\n 0.5 0.5 0.5 0.5 0.6 0.6 0.7 0.7 0.7 0.8]\n\n\nIl grafico seguente confronta le probabilit√† empiriche con le stime Bayesiane per la probabilit√† di successo associata a ciascun operatore. Questa rappresentazione evidenzia il fenomeno di ‚Äúshrinkage‚Äù intrinseco ai modelli Bayesiani gerarchici. In particolare, il grafico illustra come le stime Bayesiane delle probabilit√† di successo per gli operatori tendono a convergere verso la media generale, in confronto alle probabilit√† empiriche.\n\n# Calcola la media generale delle probabilit√† empiriche\nmean_empirical_prob = np.mean(empirical_probs)\nmean_empirical_prob\n\n0.43928571428571417\n\n\n\n# Calcola la media generale delle stime Bayesiane\nmean_bayesian_estimate = np.mean(bayesian_estimates)\nmean_bayesian_estimate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'p' ()&gt; Size: 8B\narray(0.44112334)xarray.DataArray'p'0.4411array(0.44112334)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\n\n# Crea il grafico\nplt.figure()\n\n# Traccia le probabilit√† empiriche\nplt.scatter(range(1, 29), empirical_probs, label=\"Probabilit√† Empiriche\")\n\n# Traccia le stime Bayesiane\nplt.scatter(range(1, 29), bayesian_estimates, color=\"C1\", label=\"Stime Bayesiane\")\n\n# Aggiungi linee orizzontali per indicare le medie generali\nplt.axhline(\n    y=mean_empirical_prob,\n    linestyle=\"--\",\n    label=f\"Media Generale Empirica: {mean_empirical_prob:.2f}\",\n)\nplt.axhline(\n    y=mean_bayesian_estimate,\n    linestyle=\"--\",\n    label=f\"Media Generale Bayesiana: {mean_bayesian_estimate:.2f}\",\n)\n\n# Etichette e titolo\nplt.xlabel(\"Indice dell'Operatore\")\nplt.ylabel(\"Probabilit√† di Successo\")\nplt.title(\"Fenomeno dello Shrinkage in un Modello Bayesiano Gerarchico\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nEsaminiamo la distribuzione a posteriori dei parametri alpha e beta.\n\naz.plot_posterior(idata, var_names=[\"alpha\", \"beta\"], figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\n_ = az.plot_trace(idata, combined=True, figsize=(9, 6), kind=\"rank_bars\")\n\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilit√† di una risposta corretta per tutto il gruppo.\n\n# Function to calculate the mean of a Beta distribution\ndef beta_mean(alpha, beta):\n    return alpha / (alpha + beta)\n\n# Calculate the means for each pair of alpha and beta\nsample_posterior_x_means = np.array([beta_mean(a, b) for a, b in zip(alphas, betas)])\n\n\nsample_posterior_x_means.shape\n\n(4, 4000)\n\n\n\nsample_posterior_x_means\n\narray([[0.37604496, 0.41922669, 0.47345362, ..., 0.49569844, 0.47777766,\n        0.4247707 ],\n       [0.45096577, 0.41051049, 0.49462864, ..., 0.50996786, 0.53271226,\n        0.4371311 ],\n       [0.47134244, 0.47201767, 0.44473739, ..., 0.35595368, 0.41136842,\n        0.46184053],\n       [0.36027889, 0.42282699, 0.43706697, ..., 0.41162794, 0.43983373,\n        0.46031791]])\n\n\n\nprint(sample_posterior_x_means.mean())\n\n0.4428264916259948\n\n\n\n_ = az.plot_posterior(sample_posterior_x_means)\n\n\n\n\n\n\n\n\nL‚Äôintervallo [0.37, 0.51] rappresenta l‚Äôintervallo di credibilit√† al 94% per la probabilit√† di risposta corretta p, considerando l‚Äôinsieme del gruppo degli operatori. Questo intervallo ci fornisce un‚Äôindicazione sulla variabilit√† delle probabilit√† di successo tra gli operatori, considerando sia le differenze tra di loro che le somiglianze all‚Äôinterno del gruppo.\nPoich√© l‚Äôintervallo di credibilit√† include il valore 0.5, possiamo concludere che non ci sono evidenze credibili che gli operatori, considerati nel loro insieme, siano in grado di ‚Äúpercepire il campo energetico di una persona senza vedere le mani‚Äù ad un livello diverso rispetto a quello che ci si potrebbe aspettare dal caso soltanto.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/24_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/24_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "title": "49¬† Modello gerarchico beta-binomiale con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nrequests  : 2.32.3\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html",
    "href": "chapters/chapter_4/25_stan_poisson_model.html",
    "title": "50¬† Modello di Poisson",
    "section": "",
    "text": "Introduction\nNel capitolo precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo capitolo, useremo tale metodo per affrontare una questione relativa all‚Äôanalisi di un set di dati reali.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#domanda-della-ricerca",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#domanda-della-ricerca",
    "title": "50¬† Modello di Poisson",
    "section": "50.1 Domanda della ricerca",
    "text": "50.1 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1¬∞ gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nLo scopo della presente analisi dei dati √® determinare il tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, e fornire una stima dell‚Äôincertezza associata a questo valore.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "title": "50¬† Modello di Poisson",
    "section": "50.2 Importazione e pre-processing dei dati",
    "text": "50.2 Importazione e pre-processing dei dati\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1161\n2022    1095\n2021    1050\n2020    1020\n2019     996\n2015     995\n2018     992\n2017     984\n2016     959\nName: count, dtype: int64\n\n\nCreiamo un DataFrame con i dati necessari per PyMC.\n\nyear_counts.values\n\narray([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959])\n\n\n\n# Convert year_counts Series to a DataFrame\ndf = year_counts.reset_index()  # This converts the index (year) to a column and resets the index of the DataFrame\ndf.columns = ['year', 'events']  # Renaming the columns to 'year' and 'events'\n\n# Now, df is the DataFrame you wanted, with 'year' and 'events' columns\nprint(df)\n\n   year  events\n0  2023    1161\n1  2022    1095\n2  2021    1050\n3  2020    1020\n4  2019     996\n5  2015     995\n6  2018     992\n7  2017     984\n8  2016     959",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#modello-di-poisson",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#modello-di-poisson",
    "title": "50¬† Modello di Poisson",
    "section": "50.3 Modello di Poisson",
    "text": "50.3 Modello di Poisson\nIl nostro interesse riguarda il tasso di occorrenza di sparatorie fatali da parte della polizia per anno. Indicheremo questo tasso come \\(\\theta\\), e il suo intervallo di valori possibili √® \\([0, \\infty)\\). Un modello di Poisson rappresenta tipicamente il punto di partenza per l‚Äôanalisi di dati relativi alle frequenze assolute di un evento in un intervallo di tempo fissato. Il modello presuppone che i dati seguano una distribuzione di Poisson con un parametro di tasso \\(\\lambda\\):\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\]",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#distribuzione-a-priori",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#distribuzione-a-priori",
    "title": "50¬† Modello di Poisson",
    "section": "50.4 Distribuzione a priori",
    "text": "50.4 Distribuzione a priori\nCome distribuzione a priori per il parametro \\(\\lambda\\) nel modello di Poisson possiamo usare la distribuzione Gamma, poich√© √® una scelta coniugata. Ci√≤ significa che, quando viene combinata con la distribuzione di Poisson come verosimiglianza dei dati, la distribuzione Gamma produce una distribuzione a posteriori con una forma analitica semplice. Questa caratteristica semplifica il processo di inferenza bayesiana.\nNel nostro caso, il parametro \\(\\lambda\\) rappresenta il tasso di occorrenza di sparatorie fatali per anno negli Stati Uniti. Prima di osservare i dati effettivi riportati dal Washington Post, abbiamo una conoscenza limitata su tale fenomeno. Pertanto, dobbiamo specificare una distribuzione a priori per \\(\\lambda\\) che rifletta la nostra incertezza iniziale. As esempio, possiamo ipotizzare che ci sia, in media, una sparatoria mortale per stato al mese, quindi 12 sparatorie mortali all‚Äôanno per stato. Questo ci porta a una stima iniziale di 600 sparatorie fatali negli Stati Uniti ogni anno. Dato che non siamo molto sicuri di questa ipotesi, vogliamo specificare una distribuzione a priori con un certo grado di incertezza. Imponiamo dunque una deviazione standard pari a 200.\nPer visualizzare la distribuzione a priori per il parametro \\(\\lambda\\), creiamo un istogramma della distribuzione Gamma con i parametri specificati usando PyMC.\n\n# Parameters for the Gamma distribution\nmu = 600\nsigma = 200\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 600 e sigma = 200\")\nplt.show()",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#modello-di-poisson-con-pymc",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#modello-di-poisson-con-pymc",
    "title": "50¬† Modello di Poisson",
    "section": "50.5 Modello di Poisson con PyMC",
    "text": "50.5 Modello di Poisson con PyMC\nFormuliamo il modello di Poisson usando questi iper-parametri per la distribuzione a priori del parametro \\(\\lambda\\) (rate) della distribuzione di Poisson.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\n\n# Caricare i dati\nstan_data = {\n    \"y\": [1161, 1095, 1050, 1020, 996, 995, 992, 984, 959],\n    \"N\": 9,\n    \"mu\": 600,\n    \"sigma\": 200\n}\nprint(stan_data)\n\n{'y': [1161, 1095, 1050, 1020, 996, 995, 992, 984, 959], 'N': 9, 'mu': 600, 'sigma': 200}\n\n\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro rate.\n\naz.plot_trace(trace, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\nIl modello converge rapidamente e i grafici delle tracce sembrano ben mescolati.\nGeneriamo un sommario numerico della distribuzione a posteriori.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n1027.83\n10.819\n1007.71\n1048.01\n0.21\n0.149\n2650.0\n3735.0\n1.0\n\n\n\n\n\n\n\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\nUsiamo ArviZ per generare l‚Äôintervallo di credibilit√† al 94% per la distribuzione a posteriori del parametro rate.\n\naz.plot_posterior(trace, var_names=\"rate\")\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, analizzando i dati compresi tra il 2015 e il 2023 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 94% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all‚Äôanno, con un intervallo di credibilit√† compreso tra 1008 e 1048.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#derivazione-analitica",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#derivazione-analitica",
    "title": "50¬† Modello di Poisson",
    "section": "50.6 Derivazione analitica",
    "text": "50.6 Derivazione analitica\nPer derivare i parametri della distribuzione Gamma (\\(\\alpha\\) e \\(\\beta\\)) conoscendo la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), possiamo utilizzare le seguenti relazioni:\n\n\\(\\alpha = (\\frac{\\mu}{\\sigma})^2\\)\n\\(\\beta = \\frac{\\mu}{\\sigma^2}\\)\n\nQueste formule si basano sul fatto che la media della distribuzione Gamma √® data da \\(\\frac{\\alpha}{\\beta}\\), mentre la varianza √® \\(\\frac{\\alpha}{\\beta^2}\\). Inoltre, la deviazione standard √® la radice quadrata della varianza.\nLa distribuzione a posteriori per \\(\\lambda\\), data una verosimiglianza di Poisson e una distribuzione a priori gamma, √® ancora una distribuzione gamma con parametri aggiornati. Possiamo calcolare i parametri della distribuzione a posteriori nel modo seguente:\n\nParametro di forma a posteriori (Œ±_post) = Œ±_prior + Œ£(y_i), dove Œ£(y_i) rappresenta la somma dei dati osservati.\nParametro di tasso a posteriori (Œ≤_post) = Œ≤_prior + n, dove n √® il numero di punti dati.\n\nCon questi parametri aggiornati, possiamo poi calcolare la media a posteriori della distribuzione gamma e l‚Äôintervallo di credibilit√†.\n\ndata = df[\"events\"]\n\n# Prior hyperparameters\nalpha_prior = (mu / sigma)**2\nbeta_prior = mu / sigma**2\n\n# Data summary\nn = len(df[\"events\"])\nsum_y = np.sum(df[\"events\"])\n\n# Posterior hyperparameters\nalpha_post = alpha_prior + sum_y\nbeta_post = beta_prior + n\n\n# Posterior distribution (Gamma)\nposterior_gamma = stats.gamma(alpha_post, scale=1 / beta_post)\n\n# Calculate the mean and credibility interval (94%)\nposterior_mean = posterior_gamma.mean()\ncredible_interval = posterior_gamma.interval(0.94)\n\nprint(\"Estimated Rate (Posterior Mean):\", posterior_mean)\nprint(\"Credibility Interval (94%):\", credible_interval)\n\nEstimated Rate (Posterior Mean): 1027.287853577371\nCredibility Interval (94%): (1007.3046264976574, 1047.4587209661117)\n\n\nL‚Äôoutput delle istruzioni precedenti fornisce il tasso stimato a posteriori e l‚Äôintervallo di credibilit√† al 94%. A causa di approssimazioni numeriche, i valori non coincidono esattamente con i risultati ottenuti con PyMC, ma sono molto simili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#vittime-non-armate",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#vittime-non-armate",
    "title": "50¬† Modello di Poisson",
    "section": "50.7 Vittime non armate",
    "text": "50.7 Vittime non armate\nConsideriamo ora uno studio di {cite:t}ross2021racial. Nell‚Äôintroduzione allo studio, gli autori affermano che studi precedenti hanno dimostrato che la polizia negli Stati Uniti uccide cittadini neri rispetto a cittadini bianchi a tassi pi√π elevati di quanto ci si potrebbe aspettare secondo un modello generativo in cui la polizia incontra e uccide cittadini neri e bianchi in proporzione alle loro dimensioni relative della popolazione (ad esempio, Gabrielson et al., 2014; The Guardian, 2016; Takagi, 1981). Tuttavia, l‚Äôutilit√† di questi studi nel rilevare disparit√† razziali ingiustificabili nel comportamento della polizia √® stata messa in discussione (Cesario et al., 2019; Fryer, 2017; Selby et al., 2016; Tregle et al., 2019) perch√© la polizia uccide principalmente individui - neri o bianchi - che erano armati e impegnati in attivit√† criminali al momento dell‚Äôinterazione (Ross, 2015; Selby et al., 2016). Le differenze sottostanti nei tassi di attivit√† criminale armata specifici per la razza, piuttosto che - o oltre a - pregiudizi e/o bias stereotipati non intenzionali (Payne, 2006) da parte della polizia, sono state quindi citate come possibili cause dell‚Äôaumento dei tassi di sparatorie della polizia contro gli afroamericani. Tuttavia, {cite:t}ross2021racial fanno notare che le disparit√† a discapito degli individui afro-americani nell‚Äôuso della forza da parte della polizia statunitense persistono nel caso di individui disarmati sia a livello non letale (Fryer, 2016) che letale (Ross, 2015).\nPer verificare questa affermazione di {cite:t}ross2021racial, usiamo i dati forniti dal Washington Post. Iniziamo a considerare il numero di sparatorie fatali da parte delle polizia statunitense nei confronti di un individuo disarmato caucasico.\n\n# Filter the dataframe to include only rows where the individual was unarmed\nunarmed_events = fps[fps[\"armed_with\"] == \"unarmed\"]\n\n# Filter the dataframe to create two separate dataframes for white and non-white races\nwhite_df = unarmed_events[unarmed_events[\"race\"] == \"W\"]\nnon_white_df = unarmed_events[unarmed_events[\"race\"] != \"W\"]\n\nprint(\"\\nWhite Race DataFrame:\")\nprint(white_df.head())\n\n\nWhite Race DataFrame:\n      id       date threat_type flee_status armed_with         city  \\\n8     16 2015-01-06    accident         not    unarmed   Burlington   \n72   342 2015-01-29        move        foot    unarmed   Stillwater   \n76   114 2015-02-02        flee        foot    unarmed  Hummelstown   \n119  159 2015-02-17        flee        foot    unarmed  Springfield   \n136  371 2015-02-23        move         not    unarmed        Omaha   \n\n         county state   latitude  longitude location_precision  \\\n8    Des Moines    IA  40.809250 -91.118875      not_available   \n72        Payne    OK  36.121177 -97.050127      not_available   \n76      Dauphin    PA  40.273404 -76.712841      not_available   \n119      Greene    MO  37.225250 -93.319432      not_available   \n136     Douglas    NE  41.244051 -95.933308      not_available   \n\n                name   age  gender race    race_source  \\\n8      Autumn Steele  34.0  female    W  not_available   \n72      Ralph Willis  42.0    male    W  not_available   \n76     David Kassick  59.0    male    W  not_available   \n119  Michael Ireland  31.0    male    W  not_available   \n136     Daniel Elrod  39.0    male    W  not_available   \n\n     was_mental_illness_related  body_camera agency_ids  year  \n8                         False         True        287  2015  \n72                        False        False        164  2015  \n76                        False        False        303  2015  \n119                       False        False        350  2015  \n136                       False        False        158  2015  \n\n\n\nprint(\"\\nNon-White Race DataFrame:\")\nprint(non_white_df.head())\n\n\nNon-White Race DataFrame:\n     id       date threat_type flee_status armed_with         city    county  \\\n2     5 2015-01-03        move         not    unarmed      Wichita  Sedgwick   \n17   36 2015-01-08      attack         not    unarmed       Strong     Union   \n62  352 2015-01-26        flee         car    unarmed       Tahoka      Lynn   \n83  116 2015-02-04      attack         not    unarmed  Tallahassee      Leon   \n86  125 2015-02-04    accident         not    unarmed        Tempe  Maricopa   \n\n   state   latitude   longitude location_precision                 name   age  \\\n2     KS  37.694766  -97.280554      not_available   John Paul Quintero  23.0   \n17    AR  33.111333  -92.358981      not_available  Artago Damon Howard  36.0   \n62    TX  33.166180 -101.666311      not_available   Joshua Omar Garcia  24.0   \n83    FL  30.465764  -84.330427      not_available          Jeremy Lett  28.0   \n86    AZ  33.378178 -111.978345      not_available    Joaquin Hernandez  28.0   \n\n   gender race    race_source  was_mental_illness_related  body_camera  \\\n2    male    H  not_available                       False        False   \n17   male    B  not_available                       False        False   \n62   male    H  not_available                       False        False   \n83   male    B  not_available                       False        False   \n86   male    H  not_available                       False        False   \n\n          agency_ids  year  \n2                238  2015  \n17               249  2015  \n62               179  2015  \n83               311  2015  \n86  247;195;2267;319  2015  \n\n\nDi seguito sono riportate le frequenze assolute di vittime disarmate di razza caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as white\nunarmed_white_events = white_df[white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_white_race = unarmed_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_white_race)\n\n   year  event_count\n0  2015           31\n1  2016           29\n2  2017           29\n3  2018           26\n4  2019           26\n5  2020           27\n6  2021            7\n7  2022           23\n8  2023           17\n\n\nPer gli stessi anni, qui sotto sono riportate le frequenze assolute delle vittime di razza non caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as non-white\nunarmed_non_white_events = non_white_df[non_white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_non_white_race = unarmed_non_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_non_white_race)\n\n   year  event_count\n0  2015           63\n1  2016           35\n2  2017           40\n3  2018           33\n4  2019           28\n5  2020           34\n6  2021           26\n7  2022           29\n8  2023           34\n\n\nCome distribuzione a priori per il tasso di morti, usiamo la media dei due campioni.\n\n0.5 * (np.mean(events_by_year_non_white_race.event_count) + \nnp.mean(events_by_year_white_race.event_count))\n\n29.833333333333336\n\n\nUtilizziamo una deviazione standard piuttosto grande per esprimere la nostra incertezza.\n\n# Parameters for the Gamma distribution\nmu = 30\nsigma = 10\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 30 e sigma = 10\")\nplt.show()\n\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo caucasico\nstan_data_white = {\n    \"y\": events_by_year_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_white = model.sample(\n    data=stan_data_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza caucasica.\n\naz.plot_trace(trace_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_white)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n24.141\n1.583\n21.246\n27.201\n0.03\n0.021\n2864.0\n3732.0\n1.0\n\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo non caucasico\nstan_data_non_white = {\n    \"y\": events_by_year_non_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_non_white = model.sample(\n    data=stan_data_non_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza noln caucasica.\n\naz.plot_trace(trace_non_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_non_white)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n35.615\n1.954\n32.06\n39.396\n0.036\n0.026\n2920.0\n4095.0\n1.0\n\n\n\n\n\n\n\n\nIl confronto tra i due intervalli di credibilit√† suggerisce che le frequenze attese del modello di Poisson risultano maggiori nel gruppo non caucasico rispetto al gruppo caucasico. √à importante considerare anche che la popolazione caucasica negli Stati Uniti √® numericamente superiore rispetto agli individui non caucasici.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#modello-combinato-per-i-due-gruppi",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#modello-combinato-per-i-due-gruppi",
    "title": "50¬† Modello di Poisson",
    "section": "50.8 Modello combinato per i due gruppi",
    "text": "50.8 Modello combinato per i due gruppi\nIn alternativa, possiamo creare un modello Stan unico che valuti direttamente la differenza a posteriori delle frequenze attese dal modello di Poisson per i due gruppi. Per fare questo, possiamo estendere il modello per includere due rate, uno per ogni gruppo, e calcolare la differenza a posteriori delle frequenze attese.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_diff_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni per ogni gruppo\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y_white; // dati osservati per il gruppo caucasico\n  array[N] int&lt;lower=0&gt; y_non_white; // dati osservati per il gruppo non caucasico\n}\nparameters {\n  real&lt;lower=0&gt; rate_white; // parametro rate per la distribuzione Poisson per il gruppo caucasico\n  real&lt;lower=0&gt; rate_non_white; // parametro rate per la distribuzione Poisson per il gruppo non caucasico\n}\nmodel {\n  // Priori\n  rate_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  rate_non_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y_white ~ poisson(rate_white);\n  y_non_white ~ poisson(rate_non_white);\n}\ngenerated quantities {\n  real diff_rate = rate_non_white - rate_white; // differenza tra le frequenze attese\n}\n\n\n\nNel blocco generated quantities calcoliamo la distribuzione a posteriori della differenza tra i tassi di occorrenza stimati per i gruppi non caucasici e caucasici. Questa differenza permette di quantificare direttamente il confronto tra i tassi di incidenza dei due gruppi.\nGeneriamo il dizionario appropriato per il modello.\n\nstan_groups_data = {\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n    \"y_white\": events_by_year_white_race[\"event_count\"],\n    \"y_non_white\": events_by_year_non_white_race[\"event_count\"],\n}\nprint(stan_groups_data)\n\n{'N': 9, 'mu': 30, 'sigma': 10, 'y_white': 0    31\n1    29\n2    29\n3    26\n4    26\n5    27\n6     7\n7    23\n8    17\nName: event_count, dtype: int64, 'y_non_white': 0    63\n1    35\n2    40\n3    33\n4    28\n5    34\n6    26\n7    29\n8    34\nName: event_count, dtype: int64}\n\n\nEseguiamo il campionamento.\n\ntrace_groups = model.sample(\n    data=stan_groups_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro di interesse.\n\n_ = az.plot_trace(trace_groups, combined=True, var_names=[\"diff_rate\"], figsize= (9, 3))\n\n\n\n\n\n\n\n\n\naz.summary(trace_groups)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ndiff_rate\n11.508\n2.586\n6.792\n16.443\n0.033\n0.023\n6263.0\n5254.0\n1.0\n\n\nrate_non_white\n35.577\n1.946\n31.978\n39.260\n0.023\n0.016\n7282.0\n5576.0\n1.0\n\n\nrate_white\n24.069\n1.627\n21.098\n27.285\n0.021\n0.015\n5931.0\n4896.0\n1.0\n\n\n\n\n\n\n\n\nSulla base dei risultati ottenuti dal modello di Poisson, possiamo trarre le seguenti conclusioni:\nIl tasso stimato di incidenza delle vittime disarmate uccise dalla polizia negli Stati Uniti √® pi√π alto per il gruppo non caucasico rispetto al gruppo caucasico. La differenza media stimata tra i due tassi di incidenza √® di 11.508, con una deviazione standard di 2.586. Questo significa che, in media, il tasso per il gruppo non caucasico √® di circa 11.5 punti superiore rispetto al tasso per il gruppo caucasico.\nL‚Äôintervallo di credibilit√† al 94% per questa differenza va da 6.792 a 16.443, indicando che √® molto probabile che la vera differenza tra i tassi di incidenza dei due gruppi si trovi all‚Äôinterno di questo intervallo. Questo intervallo di credibilit√† non include lo zero, il che fornisce ulteriore evidenza che il tasso di incidenza per il gruppo non caucasico √® effettivamente pi√π alto rispetto al gruppo caucasico.\nInoltre, i tassi di incidenza stimati per ciascun gruppo sono i seguenti:\n\nGruppo non caucasico: tasso medio di 35.577 con un intervallo di credibilit√† al 94% tra 31.978 e 39.260.\nGruppo caucasico: tasso medio di 24.069 con un intervallo di credibilit√† al 94% tra 21.098 e 27.285.\n\nQuesti risultati indicano chiaramente che il gruppo non caucasico ha un tasso di incidenza pi√π alto di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico. L‚Äôintervallo di credibilit√† per ciascun tasso fornisce una stima robusta e credibile della variabilit√† di questi tassi.\nIn sintesi, il modello di Poisson fornisce una forte evidenza che esiste una differenza robusta tra i tassi di incidenza dei due gruppi, con il gruppo non caucasico che presenta un tasso pi√π elevato di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/25_stan_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/25_stan_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "50¬† Modello di Poisson",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\nlogging   : 0.5.1.2\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/introduction_chapter_5.html",
    "href": "chapters/chapter_5/introduction_chapter_5.html",
    "title": "51¬† Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo un approccio all‚Äôanalisi dei dati che si basa sull‚Äôutilizzo della regressione lineare, esaminandola dalla prospettiva dell‚Äôinferenza bayesiana. La regressione lineare, eseguita mediante l‚Äôuso del modello bayesiano, non solo ci consentir√† di analizzare le relazioni tra le variabili in modo pi√π profondo e flessibile, ma terr√† conto anche dell‚Äôincertezza e della variabilit√† presenti nelle stime.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "",
    "text": "Introduzione\nI modelli lineari sono stati utilizzati in varie forme per molto tempo. Stigler (1986) descrive come il metodo dei minimi quadrati, una tecnica per adattare una semplice regressione lineare, fosse associato a problemi fondamentali in astronomia nel 1700, come la determinazione del moto della luna e la riconciliazione del moto non periodico di Giove e Saturno. All‚Äôepoca, gli astronomi erano tra i primi a sentirsi a proprio agio nell‚Äôutilizzare questi metodi, poich√© raccoglievano personalmente le loro osservazioni e sapevano che le condizioni di raccolta dei dati erano simili, anche se i valori delle osservazioni differivano. Questo contrastava con l‚Äôapproccio pi√π cauto delle scienze sociali, dove la riluttanza a combinare dati eterogenei ritardava l‚Äôadozione dei modelli lineari (Stigler 1986).\nCome nota Alexander (2023), quando costruiamo modelli, non stiamo scoprendo ‚Äúla verit√†‚Äù. Un modello non pu√≤ essere una rappresentazione fedele della realt√†. Utilizziamo i modelli per esplorare e comprendere i nostri dati. Non esiste un modello migliore in assoluto, ma solo modelli utili che ci aiutano a imparare qualcosa sui dati che abbiamo e, si spera, qualcosa sul mondo da cui sono stati generati. Quando utilizziamo i modelli, cerchiamo di comprendere il mondo, ma ci sono limiti alla prospettiva che portiamo in questo. Non dovremmo semplicemente inserire dati in un modello sperando che risolva tutto. Non lo far√†.\nI modelli scientifici sono strumenti essenziali per comprendere la realt√† che ci circonda. Il processo di creazione, esplorazione e analisi di questi modelli √® fondamentale per approfondire la nostra conoscenza del mondo. Questo processo si pu√≤ suddividere in diverse fasi:\n√à importante sottolineare che il valore principale di questo processo non risiede nel risultato finale, cio√® nel modello stesso, ma nell‚Äôapprendimento e nella comprensione che otteniamo durante il percorso. Anche se a volte il modello finale pu√≤ effettivamente rappresentare accuratamente la realt√†, √® il processo di sviluppo e analisi che ci fornisce intuizioni preziose.\nQuando lavoriamo con i modelli, dobbiamo considerare due aspetti cruciali:\n√à fondamentale riconoscere che i dati su cui basiamo i nostri modelli spesso non sono perfettamente rappresentativi della realt√†. Questo pu√≤ essere dovuto a limitazioni nella raccolta dei dati, bias nei campioni o semplicemente alla complessit√† del mondo reale. Di conseguenza, i modelli addestrati su questi dati, sebbene utili, non sono infallibili.\nCome gi√† rilevato nel Capitolo 12, per utilizzare efficacemente i modelli, dobbiamo porci costantemente due domande chiave:\nMantenere queste domande in primo piano ci aiuta a utilizzare i modelli in modo critico e consapevole, riconoscendone sia il potenziale che i limiti. Questo approccio ci permette di sfruttare al meglio i modelli come strumenti per comprendere il mondo, pur rimanendo consapevoli delle loro imperfezioni e delle sfide nella rappresentazione della realt√† complessa.\nL‚Äôevoluzione e l‚Äôapplicazione dei metodi statistici moderni presentano un interessante caso di studio nell‚Äôadattamento degli strumenti scientifici a contesti in rapida evoluzione. Molti dei metodi statistici attualmente in uso trovano le loro radici in campi come l‚Äôastronomia e l‚Äôagricoltura. Un esempio emblematico √® rappresentato da Ronald Fisher, figura di spicco nello sviluppo della statistica moderna, le cui opere seminali furono concepite durante il suo periodo presso un istituto di ricerca agricola.\nTuttavia, il panorama scientifico e tecnologico ha subito profondi cambiamenti dall‚Äôepoca di Fisher. L‚Äôapplicazione di questi metodi statistici si √® estesa a contesti che i loro ideatori difficilmente avrebbero potuto prevedere. Questa espansione solleva interrogativi cruciali sulla validit√† delle assunzioni fondamentali di questi metodi quando applicati in ambiti cos√¨ diversi da quelli originari.\nIn conclusione, mentre la statistica rimane uno strumento di inestimabile valore, il suo utilizzo efficace richiede un equilibrio tra una solida conoscenza dei principi fondamentali e la flessibilit√† necessaria per adattarsi a scenari di ricerca in continua evoluzione. L‚Äôintegrazione di metodologie diverse √® essenziale per garantire l‚Äôaffidabilit√† e la robustezza dei modelli statistici. Solo attraverso questo approccio olistico e adattativo possiamo sperare di comprendere e interpretare adeguatamente la complessit√† del mondo contemporaneo.\nIn questo capitolo, esploreremo due modelli statistici fondamentali: la regressione lineare bivariata e la regressione lineare multipla. La prima considera una sola variabile esplicativa, mentre la seconda ne include diverse. Per ciascun modello, esamineremo due approcci distinti:\n√à importante sottolineare che i modelli statistici sono generalmente ottimizzati per uno di due scopi: l‚Äôinferenza o la previsione. La focalizzazione sulla previsione √® una caratteristica distintiva del machine learning, un campo tradizionalmente dominato da Python. Tuttavia, in R, il pacchetto tidymodels offre ora funzionalit√† simili.\nIndipendentemente dall‚Äôapproccio scelto, √® fondamentale tenere presente che l‚Äôanalisi di regressione √® essenzialmente una forma di media ponderata. Di conseguenza, i risultati ottenuti riflettono inevitabilmente i bias e le peculiarit√† del dataset utilizzato.\nInfine, una nota sulla terminologia e sulla notazione. Per ragioni storiche e specifiche del contesto, esistono vari termini usati per descrivere la stessa idea nella letteratura. Seguiamo Gelman, Hill, e Vehtari (2020) e utilizziamo i termini ‚Äúoutcome‚Äù e ‚Äúpredictor‚Äù, e la specificazione del modello bayesiano di McElreath (2020).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#introduzione",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#introduzione",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "",
    "text": "La regressione √® in effetti un oracolo, ma un oracolo crudele. Parla per enigmi e si diletta nel punirci per aver posto domande sbagliate.\nMcElreath (2020)\n\n\n\nCostruzione: Creiamo modelli basati sulle nostre attuali conoscenze e ipotesi.\nEsplorazione: Studiamo le caratteristiche e le implicazioni dei modelli creati.\nVerifica: Testiamo i modelli confrontandoli con dati reali e osservazioni.\nValutazione: Apprezziamo l‚Äôeleganza e l‚Äôefficacia dei modelli quando funzionano bene.\nAnalisi critica: Cerchiamo di comprendere i limiti e le debolezze dei nostri modelli.\nRevisione o sostituzione: Quando necessario, modifichiamo o abbandoniamo i modelli inadeguati.\n\n\n\n\nIl ‚Äúmondo del modello‚Äù: le assunzioni, le semplificazioni e le regole interne del modello stesso.\nIl ‚Äúmondo reale‚Äù: la realt√† pi√π ampia e complessa che stiamo cercando di comprendere e descrivere.\n\n\n\n\nIn che misura il modello ci insegna qualcosa sui dati che abbiamo a disposizione?\nQuanto accuratamente i dati che abbiamo riflettono il mondo reale su cui vogliamo trarre conclusioni?\n\n\n\n\n\n\n\nL‚Äôutilizzo di R base, concentrandoci sulle funzioni lm() e glm() (oppure le funzioni di pingouin in Python). Queste sono particolarmente utili per l‚Äôanalisi esplorativa dei dati (EDA) quando si necessita di risultati rapidi.\nL‚Äôapproccio bayesiano, ideale quando l‚Äôobiettivo principale √® l‚Äôinferenza statistica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "52.1 Modellare l‚Äôassociazione statistica tra variabili",
    "text": "52.1 Modellare l‚Äôassociazione statistica tra variabili\nPer introdurre l‚Äôapproccio bayesiano al modello di regressione, esamineremo un set di dati che riguarda la relazione tra la temperatura media e gli introiti (in dollari) di un particolare negozio di gelati. Sebbene questa possa non sembrare una questione scientifica particolarmente entusiasmante, √® un esempio semplice e intuitivo da analizzare. La relazione tra consumo di gelati e temperatura pu√≤ apparire banale, ma offre una chiara opportunit√† per comprendere i meccanismi alla base dell‚Äôassociazione tra due variabili. In questo momento, ci concentreremo esclusivamente sui metodi per stimare tale associazione.\nIn precedenza, abbiamo applicato il modello Normale ad una singola variabile. Tuttavia, di solito siamo interessati a modellare come una variabile di esito sia correlata a un‚Äôaltra variabile predittiva. Se la variabile predittiva ha una qualche associazione statistica con la variabile di esito, possiamo utilizzarla per predire il risultato. Quando la variabile predittiva √® integrata nel modello in un modo specifico, otteniamo una regressione lineare.\nI dati dell‚Äôesempio sono forniti di seguito.\n\ndata = {\n    \"temperature\": [\n        14.2,\n        16.4,\n        11.9,\n        15.2,\n        18.5,\n        22.1,\n        19.4,\n        25.1,\n        23.4,\n        18.1,\n        22.6,\n        17.2,\n    ],\n    \"icecream\": [215, 325, 185, 332, 406, 522, 412, 614, 544, 421, 445, 408],\n}\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n\n\n\n\ntemperature\nicecream\n\n\n\n\n0\n14.2\n215\n\n\n1\n16.4\n325\n\n\n2\n11.9\n185\n\n\n3\n15.2\n332\n\n\n4\n18.5\n406\n\n\n\n\n\n\n\n\nL‚Äôassociazione tra le due variabili (gli introiti derivanti dalla vendita di gelati e la temperatura) √® chiaramente visualizzata nel grafico seguente. Il grafico indica che l‚Äôassociazione tra le due variabili pu√≤ essere approssimata da una semplice funzione matematica, ovvero una retta. Tuttavia, √® evidente che una funzione lineare sia troppo semplice per rappresentare accuratamente questi dati: non √® possibile trovare una singola retta che passi per tutti i punti del diagramma di dispersione.\n\nplt.scatter(df[\"temperature\"], df[\"icecream\"], color=\"blue\")\nplt.xlabel(\"Temperature (¬∞C)\")\nplt.ylabel(\"Ice Cream Sales ($)\")\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-generativo-dei-dati",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-generativo-dei-dati",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "52.2 Modello Generativo dei Dati",
    "text": "52.2 Modello Generativo dei Dati\nPer descrivere la relazione tra introiti e temperatura, utilizzeremo un modello statistico lineare. Assumeremo che la relazione media tra \\(x\\) (temperatura) e \\(y\\) (introiti) possa essere rappresentata da una retta, ma influenzata da un certo grado di errore. Supponiamo che questo errore sia costante ai vari livelli di \\(x\\) e segua una distribuzione Normale. Inoltre, presupponiamo che gli errori attorno alla retta di regressione siano indipendenti tra loro.\nIn questo contesto, le nostre assunzioni delineano un modello statistico lineare, formalizzato come segue:\n\\[ y_i = \\alpha + \\beta x_i + \\epsilon_i \\]\ndove: - \\(\\alpha\\) √® l‚Äôintercetta, - \\(\\beta\\) √® il coefficiente angolare, - \\(\\epsilon_i \\sim \\text{Normale}(0, \\sigma^2)\\) rappresenta l‚Äôerrore, con media zero e varianza costante \\(\\sigma^2\\).\nQueste assunzioni ci permettono di applicare metodi di regressione lineare per stimare i parametri del modello (\\(\\alpha\\) e \\(\\beta\\)) e quantificare l‚Äôincertezza delle predizioni, considerando la variabilit√† nei dati.\nIl modello lineare descritto sopra costituisce il modello generativo dei dati (verosimiglianza):\n\\[ y_n = \\alpha + \\beta x_n + \\epsilon_n \\]\no equivalentemente\n\\[ \\epsilon_n \\sim \\text{Normale}(0, \\sigma) \\]\nQuesto modello descrive come i dati $ y_n $ sono generati. Ogni osservazione $ y_n $ √® una combinazione lineare di una costante \\(\\alpha\\) (intercetta), un coefficiente \\(\\beta\\) che moltiplica il valore della variabile $ x_n $ (temperatura), e un termine di errore \\(\\epsilon_n\\) che cattura la variabilit√† non spiegata dal modello lineare.\nIl termine di errore \\(\\epsilon_n\\) √® distribuito secondo una distribuzione normale con media 0 e deviazione standard \\(\\sigma\\). Questo implica che l‚Äôerrore √® simmetricamente distribuito attorno a zero e ha una variabilit√† definita da \\(\\sigma\\).\nL‚Äôequazione\n\\[ y_n \\sim \\text{Normale}(\\alpha + \\beta x_n, \\sigma) \\]\nmostra come il valore osservato $ y_n $ segue una distribuzione normale con media \\(\\alpha + \\beta x_n\\) e deviazione standard \\(\\sigma\\). Questo significa che, dato $ x_n $, i valori di $ y_n $ sono distribuiti normalmente attorno alla retta di regressione definita da \\(\\alpha + \\beta x_n\\).\nConsideriamo il caso in cui $ y_n $ rappresenta le vendite di gelati e $ x_n $ rappresenta la temperatura media. Secondo il nostro modello:\n\n\\(\\alpha\\) √® l‚Äôintercetta, ovvero le vendite di gelati previste quando la temperatura √® zero.\n\\(\\beta\\) √® il coefficiente che indica quanto aumentano (o diminuiscono) le vendite di gelati per ogni aumento di un grado della temperatura.\n\\(\\sigma\\) √® la deviazione standard che misura la variabilit√† delle vendite di gelati attorno alla media prevista dal modello.\n\nQuesto modello ci consente di stimare l‚Äôeffetto della temperatura sulle vendite di gelati e di quantificare l‚Äôincertezza associata a queste stime.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-bayesiano-della-regressione-bivariata",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-bayesiano-della-regressione-bivariata",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "52.3 Modello Bayesiano della Regressione Bivariata",
    "text": "52.3 Modello Bayesiano della Regressione Bivariata\n\n52.3.1 Verosimiglianza\nAssumiamo la verosimiglianza che abbiamo descritto in precedenza:\n\\[ y \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma) \\]\nQuesto significa che i dati \\(y\\) seguono una distribuzione normale con media \\(\\alpha + \\beta x\\) e deviazione standard \\(\\sigma\\). In altre parole, il valore osservato \\(y\\) √® generato come una combinazione lineare di \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente della variabile \\(x\\)), pi√π un errore che segue una distribuzione normale con deviazione standard \\(\\sigma\\).\n\n\n52.3.2 Distribuzioni a Priori\nIn una prima versione del modello, useremo delle distribuzioni a priori uniformi per i tre parametri.\n\n\n52.3.3 Distribuzioni a Posteriori\nLe distribuzioni a priori vengono combinate con i dati osservati attraverso il teorema di Bayes per aggiornare le nostre credenze sui parametri del modello. Il risultato √® una distribuzione a posteriori per ciascun parametro che riflette sia l‚Äôinformazione contenuta nei dati che le credenze iniziali incorporate nelle distribuzioni a priori. Questo processo permette di fare inferenze pi√π robuste, specialmente quando i dati sono limitati o rumorosi.\n\n\n52.3.4 Codice Stan\nIl codice Stan che implementa il modello precedente √® contenuto nel file icecream_model_1.stan. Compiliamo e stampiamo il modello.\n\nstan_file = os.path.join(project_directory, 'stan', 'icecream_model_1.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSi noti che, non avendo specificato le distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), Stan assume distribuzioni a priori uniformi.\n\n\n52.3.5 Dizionario con i dati\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\n    \"N\": len(df[\"temperature\"]),\n    \"x\": df[\"temperature\"],\n    \"y\": df[\"icecream\"]\n}\nprint(stan_data)\n\n{'N': 12, 'x': 0     14.2\n1     16.4\n2     11.9\n3     15.2\n4     18.5\n5     22.1\n6     19.4\n7     25.1\n8     23.4\n9     18.1\n10    22.6\n11    17.2\nName: temperature, dtype: float64, 'y': 0     215\n1     325\n2     185\n3     332\n4     406\n5     522\n6     412\n7     614\n8     544\n9     421\n10    445\n11    408\nName: icecream, dtype: int64}\n\n\n\n\n52.3.6 Campionamento MCMC\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n\n\n52.3.7 Distribuzioni a posteriori\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]))\n\n\n\n\n\n\n\n\nL‚Äôoggetto fit generato da cmdstanpy appartiene alla classe cmdstanpy.stanfit.mcmc.CmdStanMCMC. Questo oggetto √® funzionalmente equivalente a un oggetto della classe InferenceData, permettendo quindi la sua manipolazione tramite le funzioni fornite da ArviZ. Esaminiamo dunque un sommario delle distribuzioni a posteriori dei parametri del modello lineare.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-158.315\n64.516\n-271.588\n-28.269\n1.429\n1.010\n2051.0\n2311.0\n1.0\n\n\nbeta\n30.032\n3.372\n23.574\n36.268\n0.074\n0.053\n2065.0\n2329.0\n1.0\n\n\nsigma\n44.162\n12.121\n25.540\n66.813\n0.270\n0.195\n2120.0\n2226.0\n1.0\n\n\n\n\n\n\n\n\nAvendo definito nel modello il predittore lineare come \\(x - \\bar{x}\\), l‚Äôintercetta corrisponder√† alla media dei valori dell‚Äôaltezza. La pendenza \\(\\beta\\) ci informa sull‚Äôincremento atteso dell‚Äôaltezza quando il peso aumenta di un‚Äôunit√†. Il parametro \\(\\sigma\\) descrive la deviazione standard della dispersione dei dati attorno alla retta di regressione.\nConfrontiamo i valori ottenuti con l‚Äôapproccio bayesiano con quelli trovati usando la procedura di massima verosimiglianza.\n\nlm = pg.linear_regression(df[\"temperature\"], df[\"icecream\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-159.47\n54.64\n-2.92\n0.02\n0.92\n0.91\n-281.22\n-37.73\n\n\n1\ntemperature\n30.09\n2.87\n10.50\n0.00\n0.92\n0.91\n23.70\n36.47\n\n\n\n\n\n\n\n\nLa somiglianza tra le due soluzioni conferma che, nel caso di modelli semplici come questo, e quando vengono usati dei prior non informativi, i due approcci producono risultati sostanzialmente equivalenti.\n\n\n52.3.8 Interpretazione\nPossiamo interpretare i parametri come segue:\n\nLa media a posteriori di \\(\\alpha = -159.47\\) indica che il valore atteso degli introiti del negozio di gelati √® di -159.47 dollari quando la temperatura √® di 0 gradi centigradi.\nLa media a posteriori di \\(\\beta = 30.09\\) suggerisce che ci aspettiamo un aumento medio di 30.09 dollari negli introiti del negozio di gelati per ogni incremento di 1 grado centigrado nella temperatura.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#predizione",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#predizione",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "52.4 Predizione",
    "text": "52.4 Predizione\nLa distribuzione a posteriori non contiene solo informazioni su ciascun parametro singolarmente, ma anche sulle dipendenze tra i parametri. Queste dipendenze sono riflesse nei campioni a posteriori che possono essere trasformati arbitrariamente.\nAd esempio, supponiamo che alpha e beta siano vettori di campioni a posteriori.\nCon l‚Äôistruzione seguente nel blocco generated quantities, possiamo calcolare la predizione a posteriori per 30 gradi Celsius:\npred = alpha + beta * 30;\nModifichiamo il modello Stan per aggiungere il blocco generated quantities con questa istruzione e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_2.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  real pred; // predizione\n  \n  pred = alpha + beta * 30;\n}\n\n\n\nIn questo modello Stan aggiornato, il blocco generated quantities calcola la predizione a posteriori pred per una variabile predittore con valore 30. Questa aggiunta consente di ottenere la distribuzione a posteriori della predizione per un determinato valore del predittore.\nEseguiamo il campionamento.\n\nfit2 = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la stima a posteriori dell‚Äôintroito previsto per il negozio di gelati quando la temperatura raggiunge i 30 gradi Celsius. Questa analisi fornir√† sia una stima puntuale dell‚Äôintroito che una misura dell‚Äôincertezza associata, rappresentata dall‚Äôintervallo di credibilit√† al livello di confidenza prescelto.\n\naz.summary(fit2, var_names=([\"pred\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npred\n742.651\n40.123\n664.016\n816.924\n0.818\n0.579\n2409.0\n3196.0\n1.0\n\n\n\n\n\n\n\n\n\n52.4.1 Quantificazione dell‚Äôincertezza\nPer quantificare l‚Äôincertezza nelle predizioni del modello, possiamo estendere il metodo esaminato in precedenza per calcolare la distribuzione a posteriori delle predizioni per tutti i valori di \\(x\\) considerati. Questo ci permette di ottenere non solo le stime puntuali delle predizioni, ma anche una misura dell‚Äôincertezza associata a ciascuna predizione.\nPer fare ci√≤, modifichiamo il blocco generated quantities nel seguente modo:\ngenerated quantities {\n  vector[N] y_rep; // predizioni a posteriori per ciascun valore di x\n  \n  for (n in 1:N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\nEsaminiamo nei dettagli la modifica allo script Stan.\n\nDichiarazione del vettore y_rep:\n\nvector[N] y_rep;: Questa linea dichiara un vettore y_rep di lunghezza N che conterr√† le predizioni a posteriori per ciascun valore di x.\n\nCiclo for per generare le predizioni:\n\nfor (n in 1:N): Questo ciclo iterativo va da 1 a N, cio√® copre tutte le osservazioni.\ny_rep[n] = normal_rng(alpha + beta * x[n], sigma);: Per ogni valore di x[n], questa linea genera una predizione dalla distribuzione normale con media alpha + beta * x[n] e deviazione standard sigma. La funzione normal_rng √® utilizzata per generare numeri casuali dalla distribuzione normale specificata, rappresentando cos√¨ l‚Äôincertezza nelle predizioni.\n\n\n\nQuesto approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell‚Äôincertezza associata a ciascuna predizione.\nDalla distribuzione a posteriori di y_rep, possiamo calcolare sia la stima puntuale (ad esempio, la media o la mediana delle predizioni) sia gli intervalli di credibilit√† (ad esempio, l‚Äôintervallo al 95%) per ogni valore di x. Questo offre una misura dell‚Äôincertezza delle predizioni, riflettendo la variabilit√† e l‚Äôaffidabilit√† del modello.\n\nIn sintesi, questa modifica ci permette di valutare l‚Äôincertezza delle predizioni del modello in modo robusto e dettagliato, migliorando la comprensione della performance del modello e della sua capacit√† predittiva.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_3.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // variabili predette\n  \n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\n\nfit3 = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nCostruiamo ora un grafico che rappresenta i valori osservati insieme alla linea di regressione stimata tramite il modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ciascuna orientata in base ai valori campionati casualmente dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\n\n# Extract posterior samples\nalpha_samples = fit3.stan_variable(\"alpha\")\nbeta_samples = fit3.stan_variable(\"beta\")\n\n\n# Plot y vs x\nx = df[\"temperature\"] \nplt.scatter(x, df[\"icecream\"], color=\"blue\", label=\"Data\", s=10)  # s is the size of the point\n\n# Draw lines from posterior samples\nfor i in range(300):  # assuming you have at least 300 samples\n    plt.plot(\n        x,\n        alpha_samples[i] + beta_samples[i] * x,\n        color=\"gray\",\n        linestyle=\"-\",\n        linewidth=0.5,\n        alpha=0.05,\n    )\n\n# Line using the mean of posterior estimates\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\nplt.plot(\n    x,\n    mean_alpha + mean_beta * x,\n    color=\"red\",\n    linewidth=2,\n    label=\"Mean Posterior Prediction\",\n)\n\n# Additional plot formatting\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Regression with Posterior Samples\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLe numerose linee di regressione presenti nel grafico visualizzano la nostra incertezza riguardo l‚Äôinclinazione esatta della linea di regressione principale. Tuttavia, il grafico mostra chiaramente che questa incertezza √® minima.\nPossiamo procedere in un altro modo per descrivere l‚Äôincertezza della stima. Anzich√© utilizzare le distribuzioni a posteriori di alpha e beta, possiamo utilizzare la distribuzione a posteriori di y_rep. Procedendo in questo modo otteniamo il grafico mostrato qui sotto.\nIn questo plot, la linea rossa rappresenta la media delle predizioni a posteriori, mentre l‚Äôarea grigia rappresenta l‚Äôintervallo di credibilit√† al 95%, mostrando l‚Äôincertezza delle predizioni del modello. Questo approccio fornisce una visione pi√π completa e realistica dell‚Äôincertezza nelle predizioni rispetto all‚Äôapproccio che utilizza solo alpha e beta.\n\n# Estrai i campioni posteriori di y_rep\ny_rep_samples = fit3.stan_variable(\"y_rep\")\n\n# Calcola la media e l'intervallo di credibilit√† (ad esempio, 95%) per y_rep\ny_rep_mean = np.mean(y_rep_samples, axis=0)\ny_rep_lower = np.percentile(y_rep_samples, 2.5, axis=0)\ny_rep_upper = np.percentile(y_rep_samples, 97.5, axis=0)\n\n# Plot y vs x\nx = df[\"temperature\"]\ny = df[\"icecream\"]\nplt.scatter(x, y, color=\"blue\", label=\"Dati\", s=10)\n\n# Plot della media delle predizioni a posteriori\nplt.plot(x, y_rep_mean, color=\"red\", linewidth=2, label=\"Media delle predizioni\")\n\n# Plot dell'intervallo di credibilit√†\nplt.fill_between(\n    x,\n    y_rep_lower,\n    y_rep_upper,\n    color=\"gray\",\n    alpha=0.3,\n    label=\"Intervallo di credibilit√† 95%\",\n)\n\n# Formattazione del plot\nplt.xlabel(\"Temperatura (Celsius)\")\nplt.ylabel(\"Vendite di gelati\")\nplt.title(\"Incertezza delle predizioni del modello\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNel primo approccio, calcoliamo l‚Äôincertezza delle predizioni utilizzando le distribuzioni a posteriori di alpha e beta. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di alpha e beta, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri alpha e beta. Questo metodo visualizza come l‚Äôincertezza nei parametri del modello si traduce in incertezza nelle predizioni.\nNel secondo approccio, descriviamo l‚Äôincertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di y_rep. In questo caso, generiamo predizioni per ciascun valore osservato di x nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l‚Äôincertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.\nLe due descrizioni dell‚Äôincertezza delle predizioni del modello sono diverse perch√© riflettono aspetti differenti della distribuzione a posteriori:\n\nDistribuzione a posteriori di alpha e beta: Questo approccio considera solo l‚Äôincertezza nei parametri del modello (alpha e beta). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell‚Äôincertezza residua (sigma).\nDistribuzione a posteriori di y_rep: Questo approccio include non solo l‚Äôincertezza nei parametri alpha e beta, ma anche l‚Äôincertezza residua (sigma). La distribuzione di y_rep riflette la variabilit√† totale nel modello, inclusa la variabilit√† nei dati osservati. Pertanto, l‚Äôincertezza nelle predizioni √® maggiore perch√© tiene conto di tutte le fonti di variabilit√†.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#ricodifica-dei-dati",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#ricodifica-dei-dati",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "52.5 Ricodifica dei dati",
    "text": "52.5 Ricodifica dei dati\nL‚Äôintercetta (\\(\\alpha\\)) corrisponde al valore atteso degli introiti quando la temperatura √® di 0 gradi centigradi. Un valore negativo dell‚Äôintercetta indica che, in tali circostanze, ci aspettiamo una perdita. Tuttavia, possiamo ricodificare i dati in modo che l‚Äôintercetta abbia un‚Äôinterpretazione pi√π utile.\n\n52.5.1 Centratura della variabile $ x $\nCentriamo la variabile \\(x\\) (temperatura), sottraendo la media della temperatura (\\(\\bar{x}\\)) da ciascun valore di \\(x\\). In questo modo otteniamo la nuova variabile \\(xc\\) la cui media √® 0. La trasformazione √® definita come:\n\\[ xc_i = x_i - \\bar{x} \\]\nDove \\(\\bar{x}\\) √® la media della temperatura.\n\n\n52.5.2 Interpretazione della nuova intercetta\nIl valore 0 di \\(xc\\) corrisponde al valore medio di \\(x\\). Dato che la retta di regressione passa per il punto \\((\\bar{x}, \\bar{y})\\), se utilizziamo \\(xc\\) al posto di \\(x\\), la nuova intercetta (\\(\\alpha\\)) ci dir√† qual √® il valore atteso degli introiti (\\(y\\)) quando la temperatura assume il suo valore medio (\\(\\bar{x}\\)).\n\n# Calcolo della temperatura media\nmean_temp = df[\"temperature\"].mean()\n\n# Creazione della variabile centrata\ndf[\"temp_c\"] = df[\"temperature\"] - mean_temp\n\n\nstan_data2 = {\"N\": len(df[\"temp_c\"]), \"x\": df[\"temp_c\"], \"y\": df[\"icecream\"]}\nprint(stan_data2)\n\n{'N': 12, 'x': 0    -4.475\n1    -2.275\n2    -6.775\n3    -3.475\n4    -0.175\n5     3.425\n6     0.725\n7     6.425\n8     4.725\n9    -0.575\n10    3.925\n11   -1.475\nName: temp_c, dtype: float64, 'y': 0     215\n1     325\n2     185\n3     332\n4     406\n5     522\n6     412\n7     614\n8     544\n9     421\n10    445\n11    408\nName: icecream, dtype: int64}\n\n\n\nfit4 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\n\naz.summary(fit4, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n402.356\n13.079\n377.577\n426.508\n0.166\n0.117\n6454.0\n4831.0\n1.0\n\n\nbeta\n30.093\n3.398\n23.867\n36.725\n0.047\n0.033\n5538.0\n4353.0\n1.0\n\n\nsigma\n43.766\n11.651\n26.153\n66.129\n0.180\n0.128\n4437.0\n5027.0\n1.0\n\n\n\n\n\n\n\n\nNotiamo che la media a posteriori di \\(\\beta\\) √® rimasta invariata. Tuttavia, la media a posteriori di \\(\\alpha\\) √® ora pari a 402,4 dollari. Questo rappresenta il valore atteso degli introiti del negozio di gelati quando la temperatura √® al suo valore medio.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#distribizioni-a-priori-sui-parametri",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#distribizioni-a-priori-sui-parametri",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "52.6 Distribizioni a priori sui parametri",
    "text": "52.6 Distribizioni a priori sui parametri\nSpefichiamo ora le seguenti distribuzioni a priori debolmente informative sui parametri del modello.\n\nIntercetta (\\(\\alpha\\)):\n\n\\(\\alpha \\sim \\text{Normale}(0, 100)\\)\nLa scelta di una deviazione standard ampia (100) riflette l‚Äôincertezza riguardo al valore iniziale dell‚Äôintercetta. Si crede che l‚Äôintercetta possa essere qualsiasi valore vicino a 0, ma con una variazione significativa.\n\nCoefficiente Angolare (\\(\\beta\\)):\n\n\\(\\beta \\sim \\text{Normale}(0, 50)\\)\nUn‚Äôampia deviazione standard (50) per \\(\\beta\\) permette di incorporare l‚Äôincertezza riguardo all‚Äôinfluenza della temperatura sui ricavi del gelato. Questo prior permette che \\(\\beta\\) possa essere sia positivo che negativo con una vasta gamma di valori.\n\nDeviazione Standard Residua (\\(\\sigma\\)):\n\n\\(\\sigma \\sim \\text{Cauchy}^+(0, 5)\\)\nLa distribuzione Half-Cauchy √® scelta perch√© √® debolmente informativa e adatta per i parametri di scala come la deviazione standard residua. La scala di 5 consente a \\(\\sigma\\) di assumere una vasta gamma di valori positivi, riflettendo l‚Äôincertezza riguardo alla variabilit√† residua.\n\n\n\n52.6.1 Interpretazione delle Distribuzioni a Priori\nQueste distribuzioni a priori rappresentano le credenze iniziali riguardanti i parametri del modello prima di osservare i dati. Le distribuzioni normali per \\(\\alpha\\) e \\(\\beta\\) con deviazioni standard ampie permettono una grande flessibilit√†, mentre la distribuzione Half-Cauchy per \\(\\sigma\\) √® scelta per la sua capacit√† di gestire bene i parametri di scala. Queste scelte garantiscono che il modello sia debolmente informativo, permettendo ai dati osservati di avere un‚Äôinfluenza significativa sulle stime posteriori dei parametri.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_prior.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 100);\n  beta ~ normal(0, 50);\n  sigma ~ cauchy(0, 5);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nAdattiamo il nuovo modello ai dati.\n\nfit5 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit5, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n396.790\n12.114\n373.733\n419.045\n0.187\n0.132\n4518.0\n3481.0\n1.0\n\n\nbeta\n30.015\n2.996\n24.402\n35.673\n0.039\n0.028\n6018.0\n4754.0\n1.0\n\n\nsigma\n39.558\n9.771\n24.252\n57.630\n0.164\n0.120\n4130.0\n3957.0\n1.0\n\n\n\n\n\n\n\n\nSi noti che, utilizzando distribuzioni a priori debolmente informative, le distribuzioni a posteriori dei parametri risultano molto simili a quelle ottenute usando distribuzioni uniformi. Tuttavia, le distribuzioni a priori debolmente informative sono preferibili poich√© forniscono una maggiore stabilit√† numerica e sono generalmente pi√π affidabili e robuste, specialmente quando si lavora con dati reali. L‚Äôuso di distribuzioni uniformi √® sconsigliato per via delle possibili instabilit√† numeriche che possono introdurre nei modelli.\n\n\n52.6.2 Posterior-predictive check\nGeneriamo ora un PPC plot per confrontare le predizioni del modello con i dati osservati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_3.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nfit6 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nPer creare un PPC plot dobbiamo creare un oggetto InferenceData nel quale i dati sono strutturati come si aspetta ArviZ:\n\nidata = az.from_cmdstanpy(\n    posterior=fit6,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": df[\"icecream\"]},\n)\n\nAvendo generato l‚Äôoggetto idata, possiamo ora creare il pp-check plot.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"})\n\n/opt/anaconda3/envs/cmdstan_env/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  func(*args, **kwargs)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "52.7 Commenti e considerazioni finali",
    "text": "52.7 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato la stima dei parametri di un modello di regressione bivariato utilizzando l‚Äôapproccio bayesiano.\nPer fornire un confronto con un metodo alternativo, in appendice √® presentata un‚Äôintroduzione all‚Äôapproccio frequentista per il modello di regressione lineare bivariato. Questa sezione aggiuntiva offre una panoramica degli aspetti chiave dell‚Äôapproccio frequentista, consentendo di confrontare e comprendere le differenze tra i due approcci nella stima dei parametri e nell‚Äôinterpretazione dei risultati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "title": "52¬† Modello di regressione lineare bayesiano",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Jul 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\ncmdstanpy : 1.2.4\narviz     : 0.18.0\npingouin  : 0.5.4\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nFox, John. 2015. Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nStigler, Stephen. 1986. The History of Statistics. Massachusetts: Belknap Harvard.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_04_synt_sugar.html",
    "href": "chapters/chapter_5/05_04_synt_sugar.html",
    "title": "53¬† Zucchero sintattico",
    "section": "",
    "text": "53.1 Introduzione\nI modelli lineari sono cos√¨ ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie √® bambi (BAyesian Model-Building Interface). bambi √® un pacchetto Python progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato √® un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm o brms. bambi si basa su PyMC, ma offre un‚ÄôAPI di livello superiore.\nIn questo capitolo esploreremo come condurre un‚Äôanalisi di regressione utilizzando bambi invece di cmdstan.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_04_synt_sugar.html#bayesian-model-building-interface",
    "href": "chapters/chapter_5/05_04_synt_sugar.html#bayesian-model-building-interface",
    "title": "53¬† Zucchero sintattico",
    "section": "53.2 BAyesian Model-Building Interface",
    "text": "53.2 BAyesian Model-Building Interface\nLeggiamo i dati utilizzati nel capitolo precedente.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\n\nGeneriamo un diagramma a dispersione:\n\nplt.plot(df[\"weight\"], df[\"height\"], \"x\")\nplt.xlabel(\"Weight\")\nplt.ylabel(\"Height\")\n\nText(0, 0.5, 'Height')\n\n\n\n\n\n\n\n\n\nBambi si concentra sui modelli di regressione e questa restrizione porta a una sintassi pi√π semplice, ovvero la sintassi di Wilkinson {cite:p}wilkinson1973symbolic. Inoltre, bambi implementa delle distribuzioni a priori ottimizzate, eliminando cos√¨ la necessit√† di definirle esplicitamente. Tuttavia, se si preferisce un maggiore controllo sulle distribuzioni a priori, √® possibile specificarle manualmente.\nPer replicare il modello descritto nel capitolo precedente possiamo utilizzare la seguente istruzione.\n\ndf[\"weight_c\"] = df[\"weight\"] - np.mean(df[\"weight\"])\n\nmodel = bmb.Model(\"height ~ weight_c\", df)\n\nSul lato sinistro della tilde (‚àº), abbiamo la variabile dipendente, e sul lato destro, le variabili indipendenti. Con questa sintassi, stiamo semplicemente specificando la media (Œº nel modello lm di PyMC). Per impostazione predefinita, Bambi assume che la verosimiglianza sia gaussiana; √® possibile modificarla con l‚Äôargomento family. La sintassi della formula non specifica la distribuzione delle priors, ma solo come sono associate le variabili dipendenti e indipendenti. Bambi definir√† automaticamente delle priors (molto) debolmente informative per noi. Possiamo ottenere ulteriori informazioni stampando il modello Bambi.\n\nprint(model)\n\n       Formula: height ~ weight_c\n        Family: gaussian\n          Link: mu = identity\n  Observations: 352\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 154.5971, sigma: 19.3283)\n            weight_c ~ Normal(mu: 0.0, sigma: 2.9978)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 7.7313)\n\n\nLa descrizione inizia mostrando la formula utilizzata per definire il modello, y ~ x, che indica come la variabile dipendente y √® predetta dalla variabile indipendente x in una relazione lineare. La seconda riga specifica che si sta utilizzando una distribuzione gaussiana (normale) come funzione di verosimiglianza per il modello, il che implica l‚Äôassunzione che i residui del modello (le differenze tra i valori osservati e i valori predetti) seguano una distribuzione normale.\nLa terza riga menziona la funzione di collegamento, in questo caso l‚Äôidentit√†, che non applica alcuna trasformazione al valore atteso della variabile dipendente. Questo √® caratteristico dei modelli lineari, dove il valore atteso di y √® direttamente modellato come una combinazione lineare delle variabili indipendenti (E(Y) = \\alpha + \\beta x). √à importante notare che, nei modelli lineari generalizzati, la funzione di collegamento gioca un ruolo cruciale nel collegare il valore atteso della variabile risposta alla combinazione lineare delle variabili predittive.\nSegue il numero di osservazioni utilizzate per adattare il modello, indicando la dimensione del dataset su cui il modello √® stato allenato.\nLa parte successiva dell‚Äôoutput dettaglia i priors utilizzati per i parametri del modello. In Bambi, i priors sono assunzioni a priori sui valori dei parametri prima di osservare i dati. Questi priors aiutano a guidare l‚Äôinferenza, soprattutto in presenza di dati limitati o per regolarizzare il modello. L‚Äôintercetta (Intercept) ha un prior normale con media (mu) 2.0759 e deviazione standard (sigma) 3.9401, indicando la posizione iniziale attesa della linea di regressione e quanto ci si aspetta che vari. Il coefficiente della variabile x ha anch‚Äôesso un prior normale, centrato in zero con una deviazione standard ampia (6.8159), riflettendo incertezza su quale possa essere il vero effetto di x su y senza presupporre una direzione specifica dell‚Äôeffetto.\nLa sezione finale riguarda i parametri ausiliari del modello, in questo caso il parametro sigma della distribuzione gaussiana, che rappresenta la deviazione standard dei residui del modello. Questo ha un prior HalfStudentT, che √® una distribuzione che ammette solo valori positivi (essendo la deviazione standard sempre positiva), con un grado di libert√† (nu) 4.0 e una scala (sigma) 0.791. Questo prior √® scelto per la sua flessibilit√† e la capacit√† di gestire dati con potenziali outlier.\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nEseguiamo il campionamento MCMC.\n\nidata = model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\nLe distribuzioni a posteriori dei parametri e i trace plot si ottengono con la seguente istruzione.\n\n_ = az.plot_trace(idata)\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(idata, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n154.61\n0.27\n154.09\n155.09\n0.0\n0.0\n4300.59\n2955.37\n1.0\n\n\nsigma\n5.09\n0.19\n4.76\n5.45\n0.0\n0.0\n3966.32\n2953.56\n1.0\n\n\nweight_c\n0.90\n0.04\n0.82\n0.98\n0.0\n0.0\n4327.37\n3193.28\n1.0\n\n\n\n\n\n\n\n\nI dati replicano quelli ottenuti in precedenza.\nPossiamo anche generare un grafico che descrive l‚Äôincertezza a posteriori delle predizioni del modello.\nLa funzione plot_predictions del pacchetto Bambi serve per facilitare l‚Äôinterpretazione dei modelli di regressione attraverso la visualizzazione grafica. Il metodo appartiene al sottomodulo interpret di Bambi e si concentra sulla rappresentazione delle previsioni generate dal modello.\nQuando si esegue la funzione plot_predictions con i parametri specificati (model, idata, [\"weight_c\"]), essa produce un grafico che sintetizza le previsioni del modello in relazione a una o pi√π variabili indipendenti. In questo caso, il parametro model indica il modello di regressione Bayesiana costruito con Bambi, idata rappresenta i dati inferenziali (ottenuti tramite il fit del modello), e [\"weight_c\"] specifica la variabile indipendente da considerare per il grafico.\n\nbmb.interpret.plot_predictions(model, idata, [\"weight_c\"]);\n\nDefault computed for conditional variable: weight_c\n\n\n\n\n\n\n\n\n\nIl grafico generato da questa funzione illustra due aspetti principali:\n\nMedia Posteriore di y: Il grafico include una linea che rappresenta la media posteriore della variabile dipendente (height) rispetto alla variabile indipendente specificata (weight_c). La media posteriore √® una stima centrale delle previsioni del modello, che riflette la posizione pi√π probabile dei valori di height data l‚Äôevidenza fornita dai dati.\nIntervallo di Densit√† pi√π Alta del 94%: Attorno alla retta della media posteriore, il grafico mostra anche un‚Äôarea evidenziata che rappresenta l‚Äôintervallo di densit√† pi√π alta (HDI) del 94%. Questo intervallo √® un modo per quantificare l‚Äôincertezza delle previsioni del modello. L‚ÄôHDI del 94% significa che, data la distribuzione posteriore delle previsioni di height, c‚Äô√® il 94% di probabilit√† che il valore vero di height cada all‚Äôinterno di questo intervallo per un dato valore di weight_c. Questo fornisce una misura visiva dell‚Äôincertezza associata alle stime del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "53¬† Zucchero sintattico",
    "section": "53.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "53.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nbambi     : 0.14.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\narviz     : 0.18.0\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html",
    "href": "chapters/chapter_5/05_05_two_means.html",
    "title": "54¬† Confronto tra le medie di due gruppi",
    "section": "",
    "text": "54.1 Introduzione\nNel ?sec-two-groups-comparison, abbiamo discusso come eseguire l‚Äôinferenza sulla differenza tra le medie di due campioni indipendenti attraverso un approccio bayesiano. In quella analisi, i due gruppi sono stati trattati come entit√† distinte e abbiamo calcolato la differenza tra le loro medie.\nUn‚Äôalternativa consiste nell‚Äôuso di un modello di regressione. In questo caso, non si calcola direttamente la differenza tra le medie, ma si introduce una variabile ‚Äúdummy‚Äù nel modello di regressione. La variabile ‚Äúdummy‚Äù codifica l‚Äôappartenenza ai gruppi con valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto. Il modello di regressione stima poi un coefficiente per la variabile ‚Äúdummy‚Äù, che rappresenta la differenza tra le medie dei due gruppi. Cos√¨ facendo, la variabile ‚Äúdummy‚Äù agisce come un indicatore del gruppo, permettendoci di stimare in modo efficiente la differenza tra le medie.\nEntrambi i metodi sono validi per analizzare la differenza tra le medie di due gruppi indipendenti, tuttavia il modello di regressione offre maggiore flessibilit√† e potenzialit√† di espansione. Grazie a questo modello, √® possibile includere ulteriori variabili esplicative, ampliando la nostra capacit√† di comprendere i fattori che influenzano il risultato d‚Äôinteresse. Questa versatilit√† √® particolarmente vantaggiosa per esaminare come altre variabili possano influire sulla differenza tra le medie o per analizzare pi√π variabili contemporaneamente.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/chapter_5/05_05_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "54¬† Confronto tra le medie di due gruppi",
    "section": "54.2 Regressione bayesiana per due gruppi indipendenti",
    "text": "54.2 Regressione bayesiana per due gruppi indipendenti\nNel contesto bayesiano, il modello di regressione pu√≤ essere formulato nel modo seguente:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta x_i.\n\\end{align*}\n\\]\nIn questa rappresentazione:\n\n$ $ agisce come intercetta,\n$ $ √® il coefficiente angolare o la pendenza,\n$ $ √® l‚Äôerrore standard associato alle osservazioni.\n\nNel caso specifico, la variabile $ x $ √® una variabile indicatrice che assume i valori 0 o 1. Per il gruppo identificato da $ x = 0 $, il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nQuesto implica che $ $ rappresenta la media del gruppo codificato come $ x = 0 $.\nPer il gruppo contrassegnato da $ x = 1 $, il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta.\n\\end{align*}\n\\]\nIn termini dei parametri del modello, la media per il gruppo codificato con $ x = 1 $ √® rappresentata da $ + $. In questa configurazione, $ $ indica la differenza tra la media del gruppo con $ x = 1 $ e quella del gruppo con $ x = 0 $. Di conseguenza, l‚Äôanalisi della differenza tra le medie dei due gruppi pu√≤ essere effettuata attraverso l‚Äôinferenza sul parametro $ $. In sintesi, per confrontare le medie dei due gruppi indipendenti, si pu√≤ esaminare la distribuzione a posteriori di $ $.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#un-esempio-illustrativo",
    "href": "chapters/chapter_5/05_05_two_means.html#un-esempio-illustrativo",
    "title": "54¬† Confronto tra le medie di due gruppi",
    "section": "54.3 Un esempio illustrativo",
    "text": "54.3 Un esempio illustrativo\nEsaminiamo nuovamente i dati relativi al quoziente di intelligenza dei bambini le cui madri hanno completato oppure no la scuola superiore. Ci poniamo il problema di replicare i risultati ottenuti in precedenza usando l‚Äôanalisi di regressione.\nLeggiamo i dati:\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\n\nkidiq.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nCi sono 93 bambini la cui madre non ha completato le superiori e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\nsummary_stats = [st.mean, st.stdev]\nkidiq.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\n\naz.plot_violin(\n    {\n        \"mom_hs=0\": kidiq.loc[kidiq.mom_hs == 0, \"kid_score\"],\n        \"mom_hs=1\": kidiq.loc[kidiq.mom_hs == 1, \"kid_score\"],\n    }\n);\n\n\n\n\n\n\n\n\nIniziamo l‚Äôinferenza statistica sulla differenza tra le medie dei due gruppi utilizzando bambi. Questo pacchetto offre una sintassi semplice per formulare il modello bayesiano di interesse. Un altro vantaggio √® che bambi selezioner√† automaticamente le distribuzioni a priori appropriate per i parametri del modello, rendendo il processo pi√π intuitivo.\nIl modello di regressione sopra descritto si scrive nel modo seguente.\n\nmod = bmb.Model(\"kid_score ~ mom_hs\", kidiq)\n\nEffettuiamo il campionamento.\n\nresults = mod.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nPossiamo ispezionare le propriet√† del modello nel modo seguente.\n\nmod\n\n       Formula: kid_score ~ mom_hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 86.7972, sigma: 110.1032)\n            mom_hs ~ Normal(mu: 0.0, sigma: 124.2132)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nLe distribuzioni a priori utilizzate di default dal modello possono essere visualizzate nel modo seguente.\n\n_ = mod.plot_priors()\n\nSampling: [Intercept, kid_score_sigma, mom_hs]\n\n\n\n\n\n\n\n\n\nPer ispezionare il nostro posteriore e il processo di campionamento possiamo utilizzare az.plot_trace(). L‚Äôopzione kind='rank_vlines' ci fornisce una variante del grafico di rango che utilizza linee e punti e ci aiuta a ispezionare la stazionariet√† delle catene. Poich√© non c‚Äô√® un modello chiaro o deviazioni serie dalle linee orizzontali, possiamo concludere che le catene sono stazionarie.\n\n_ = az.plot_trace(results)\n\n\n\n\n\n\n\n\n\naz.summary(results, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n77.52\n2.04\n73.72\n81.48\n0.03\n0.02\n4640.52\n3274.01\n1.0\n\n\nkid_score_sigma\n19.91\n0.67\n18.68\n21.19\n0.01\n0.01\n4231.42\n3052.91\n1.0\n\n\nmom_hs\n11.78\n2.30\n7.23\n15.86\n0.03\n0.02\n4642.76\n3108.48\n1.0\n\n\n\n\n\n\n\n\nIl parametro ‚ÄúIntercept‚Äù rappresenta la stima a posteriori del punteggio del QI per il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. La media a posteriori di questo gruppo √® di 77.6, che √® praticamente identica al valore campionario corrispondente.\nIl parametro ‚Äúmom_hs‚Äù corrisponde alla stima a posteriori della differenza nei punteggi del QI tra il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 1 e il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. Anche in questo caso, la differenza a posteriori di 11.8 tra le medie dei due gruppi √® molto simile alla differenza campionaria tra le medie dei due gruppi. La parte importante della tabella riguarda l‚Äôintervallo di credibilit√† al 94%, che √® [7.5, 16.2], e che non include lo 0. Ci√≤ significa che, con un livello di certezza soggettiva del 94%, possiamo essere sicuri che il QI dei bambini le cui madri hanno il diploma superiore sar√† maggiore (in media) di almeno 7.5 punti, e tale differenza pu√≤ arrivare fino a 16.2 punti, rispetto al QI dei bambini le cui madri non hanno completato la scuola superiore.\nSe confrontiamo questi risultati con quelli ottenuti nel capitolo {ref}two_groups_comparison_notebook, notiamo che sono quasi identici. Le piccole differenze che si osservano possono essere attribuite sia all‚Äôapprossimazione numerica sia al fatto che nel modello precedente abbiamo consentito deviazioni standard diverse per i due gruppi, mentre nel caso attuale abbiamo assumo la stessa variabilit√† per entrambi i gruppi.\nUsiamo ora l‚Äôapproccio di massima verosimiglianza.\n\nlm = pg.linear_regression(kidiq[\"mom_hs\"], kidiq[\"kid_score\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n77.55\n2.06\n37.67\n0.0\n0.06\n0.05\n73.50\n81.59\n\n\n1\nmom_hs\n11.77\n2.32\n5.07\n0.0\n0.06\n0.05\n7.21\n16.34\n\n\n\n\n\n\n\n\nI risultati sono quasi identici a quelli trovati con l‚Äôapproccio bayesiano.\nIl test bayesiano di ipotesi pu√≤ essere svolto, per esempio, calcolando la probabilit√† che \\(\\beta_{mean\\_diff} &gt; 0\\). Questa probabilit√† √® 1, per cui concludiamo che la media del gruppo codificato con ‚Äúmom_hs = 1‚Äù √® maggiore della media del gruppo codificato con ‚Äúmom_hs = 0‚Äù.\n\naz.plot_posterior(results, var_names=\"mom_hs\", ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\nUn valore numerico si ottiene nel modo seguente.\n\nresults.posterior\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104kB\nDimensions:          (chain: 4, draw: 1000)\nCoordinates:\n  * chain            (chain) int64 32B 0 1 2 3\n  * draw             (draw) int64 8kB 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\nData variables:\n    Intercept        (chain, draw) float64 32kB 78.83 79.84 ... 73.83 79.82\n    kid_score_sigma  (chain, draw) float64 32kB 19.21 20.79 ... 20.87 19.45\n    mom_hs           (chain, draw) float64 32kB 11.97 8.374 ... 15.15 10.02\nAttributes:\n    created_at:                  2024-06-13T05:14:43.527326+00:00\n    arviz_version:               0.18.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (3)Intercept(chain, draw)float6478.83 79.84 73.54 ... 73.83 79.82array([[78.82644605, 79.84168005, 73.54424871, ..., 78.2407767 ,\n        79.65683325, 79.50875636],\n       [80.01627206, 78.71662919, 79.20643166, ..., 77.02806443,\n        79.29123634, 77.23338073],\n       [77.29254392, 77.44678841, 77.42416296, ..., 74.46900909,\n        80.21508608, 78.984981  ],\n       [75.11589965, 75.46194695, 76.33373715, ..., 75.60413192,\n        73.83124842, 79.81667588]])kid_score_sigma(chain, draw)float6419.21 20.79 20.36 ... 20.87 19.45array([[19.20601585, 20.79313289, 20.36108383, ..., 20.97965143,\n        20.94150175, 20.43169363],\n       [20.03731499, 19.08286456, 19.52683884, ..., 19.27515939,\n        19.94139224, 19.46453797],\n       [18.38282855, 19.29950429, 20.1234451 , ..., 19.13765117,\n        19.53346331, 18.6415884 ],\n       [20.69701767, 18.03001439, 19.71130165, ..., 21.17944029,\n        20.86573599, 19.45230071]])mom_hs(chain, draw)float6411.97 8.374 14.71 ... 15.15 10.02array([[11.96777777,  8.37382352, 14.70572866, ..., 12.14492642,\n        12.5707737 , 12.86370927],\n       [ 8.24668315, 12.34781247,  9.87043598, ..., 13.43240059,\n         9.11062374, 11.95853216],\n       [13.72195497, 12.79190398, 11.57487575, ..., 14.54096709,\n         9.29889013, 11.32656956],\n       [13.01259531, 12.49687999, 13.49840034, ..., 13.1175932 ,\n        15.14621113, 10.01597991]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (4)created_at :2024-06-13T05:14:43.527326+00:00arviz_version :0.18.0modeling_interface :bambimodeling_interface_version :0.13.0\n\n\n\n# Probabiliy that posterior is &gt; 0\n(results.posterior[\"mom_hs\"] &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#parametrizzazione-alternativa",
    "href": "chapters/chapter_5/05_05_two_means.html#parametrizzazione-alternativa",
    "title": "54¬† Confronto tra le medie di due gruppi",
    "section": "54.4 Parametrizzazione alternativa",
    "text": "54.4 Parametrizzazione alternativa\nConsideriamo adesso il caso in cui, per distinguere i gruppi, anzich√© una variabile dicotomica, con valori 0 e 1, usiamo una variabile qualitativa con i nomi dei due gruppi. Introduciamo questa nuova variabile nel data frame.\n\n# Add a new column 'hs' with the categories based on 'mom_hs'\nkidiq[\"hs\"] = kidiq[\"mom_hs\"].map({0: \"not_completed\", 1: \"completed\"})\nkidiq.tail()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\nhs\n\n\n\n\n429\n94\n0.0\n84.877412\n4\n21\nnot_completed\n\n\n430\n76\n1.0\n92.990392\n4\n23\ncompleted\n\n\n431\n50\n0.0\n94.859708\n2\n24\nnot_completed\n\n\n432\n88\n1.0\n96.856624\n2\n21\ncompleted\n\n\n433\n70\n1.0\n91.253336\n2\n25\ncompleted\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati, usando questa nuova variabile e forziamo a zero l‚Äôintercetta che Bambi aggiunge di default al modello.\n\nmod_2 = bmb.Model(\"kid_score ~ 0 + hs\", kidiq)\nresults_2 = mod_2.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nIspezionare il modello e le distribuzioni a priori.\n\nmod_2\n\n       Formula: kid_score ~ 0 + hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            hs ~ Normal(mu: [0. 0.], sigma: [124.2132 124.2132])\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\n_ = mod_2.plot_priors()\n\nSampling: [hs, kid_score_sigma]\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri del modello.\n\n_ = az.plot_trace(results_2)\n\n\n\n\n\n\n\n\n\naz.summary(results_2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nhs[completed]\n89.301\n1.059\n87.267\n91.258\n0.016\n0.012\n4147.0\n3064.0\n1.0\n\n\nhs[not_completed]\n77.473\n2.048\n73.722\n81.256\n0.031\n0.022\n4308.0\n3016.0\n1.0\n\n\nkid_score_sigma\n19.881\n0.680\n18.621\n21.181\n0.011\n0.008\n3982.0\n2995.0\n1.0\n\n\n\n\n\n\n\n\nIn questo caso, notiamo che abbiamo ottenuto le distribuzioni a posteriori per i parametri hs[completed] e hs[not_completed] che corrispondono alle medie dei due gruppi. Tali distribuzioni a posteriori illustrano direttamente l‚Äôincertezza sulla media dei due gruppi, alla luce della variabilit√† campionaria e delle nostre credenze a priori.\nPossiamo svolgere il test bayesiano di ipotesi sulla differenza tra le due medie a posteriori nel modo seguente.\n\npost_group = results_2.posterior[\"hs\"]\ndiff = post_group.sel(hs_dim=\"completed\") - post_group.sel(hs_dim=\"not_completed\")\naz.plot_posterior(diff, ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\n\n# Probabiliy that posterior is &gt; 0\n(post_group &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_05_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "54¬† Confronto tra le medie di due gruppi",
    "section": "54.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "54.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nnumpy     : 1.26.4\nbambi     : 0.14.0\npandas    : 2.2.2\npingouin  : 0.5.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html",
    "title": "55¬† Regressione multipla con Stan",
    "section": "",
    "text": "Introduzione\nIn questo capitolo introdurremo il modello di regressione multipla mostrando come possa essere implementato in Stan. Ci concentreremo sull‚Äôinterpretazione dei coefficienti parziali di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#regressione-multipla",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#regressione-multipla",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.1 Regressione multipla",
    "text": "55.1 Regressione multipla\nLa regressione multipla rappresenta un‚Äôestensione del modello di regressione semplice, e permette di esplorare e quantificare le relazioni tra una variabile dipendente e pi√π variabili indipendenti. Passando dal modello semplice \\(y = a + bx + \\text{errore}\\) al modello pi√π generale \\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\text{errore}\\), emergono nuove complessit√†. Queste includono le decisioni su quali predittori \\(x\\) includere nel modello, l‚Äôinterpretazione dei coefficienti e delle loro interazioni, e la costruzione di nuovi predittori a partire dalle variabili esistenti per catturare elementi di discrezionalit√† e non linearit√†.\nI coefficienti di regressione, in un contesto di regressione multipla, sono tipicamente pi√π complicati da interpretare rispetto a quelli di un modello con un solo predittore. L‚Äôinterpretazione di un dato coefficiente, infatti, √® parzialmente condizionata dalle altre variabili presenti nel modello. Il coefficiente \\(\\beta_k\\) rappresenta la differenza media o attesa nella variabile risposta \\(y\\), confrontando due individui che differiscono di un‚Äôunit√† nel predittore \\(x_k\\) ma sono identici per quanto riguarda gli altri predittori. Questo concetto √® talvolta sintetizzato con l‚Äôespressione ‚Äúconfrontare due osservazionni (o persone) che differiscono per \\(x_k\\) a parit√† delle altre variabili‚Äù.\nDal punto di vista dell‚Äôimplementazione con Stan, l‚Äôestensione del modello per includere molteplici predittori dell‚Äôintelligenza del bambino √® relativamente semplice. √à necessario costruire una matrice \\(X\\) contenente le colonne che rappresentano i vari predittori che intendiamo analizzare. Per l‚Äôesempio specifico in questione, i predittori selezionati per l‚Äôintelligenza del bambino includono: la scolarit√† della madre (codificata come 0 o 1 a seconda che la madre abbia completato o meno le scuole superiori), l‚Äôintelligenza della madre e l‚Äôet√† della madre. Prima di procedere con l‚Äôanalisi, √® importante standardizzare tutte queste variabili per facilitare l‚Äôinterpretazione dei risultati e migliorare la stabilit√† numerica del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#un-esempio-pratico",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#un-esempio-pratico",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.2 Un esempio pratico",
    "text": "55.2 Un esempio pratico\nPer fare un esempio pratico, analizzeremo nuovamente i dati sull‚Äôintelligenza di un gruppo di bambini. In questo caso, cercheremo di predire l‚Äôintelligenza media dei bambini considerando tre fattori: se le madri hanno completato la scuola superiore, l‚Äôintelligenza della madre e l‚Äôet√† della madre.\nImportiamo i dati:\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nCompiliamo e stampiamo il modello Stan di regressione multipla per questi dati. Il modello assume che i dati siano standardizzati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"mreg.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;   // Numero di osservazioni\n    int&lt;lower=1&gt; K;   // Numero di variabili indipendenti, intercetta inclusa\n    vector[N] x1;     // Prima variabile indipendente\n    vector[N] x2;     // Seconda variabile indipendente\n    vector[N] x3;     // Seconda variabile indipendente\n    // Aggiungi altri vettori se ci sono pi√π variabili indipendenti\n    vector[N] y;      // Vettore della variabile dipendente\n}\nparameters {\n    real alpha;           // Intercetta\n    real beta1;           // Coefficiente per la prima variabile indipendente\n    real beta2;           // Coefficiente per la seconda variabile indipendente\n    real beta3;           // Coefficiente per la terza variabile indipendente\n    // Definisci altri real per ulteriori coefficienti\n    real&lt;lower=0&gt; sigma;  // Errore del modello\n}\nmodel {\n    // Prior\n    alpha ~ student_t(3, 0, 2.5);\n    beta1 ~ student_t(3, 0, 2.5);\n    beta2 ~ student_t(3, 0, 2.5);\n    beta3 ~ student_t(3, 0, 2.5);\n    // Definisci prior per altri coefficienti\n    sigma ~ exponential(1);\n\n    // Likelihood\n    for (n in 1:N) {\n        y[n] ~ normal(alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\ngenerated quantities {\n    vector[N] log_lik; // Log-likelihood per ogni osservazione\n    vector[N] y_rep;  // Predizioni posteriori per ogni osservazione\n\n    for (n in 1:N) {\n        log_lik[n] = normal_lpdf(y[n] | alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n        y_rep[n] = normal_rng(alpha + beta1 * x1[n] + beta2 * x2[n] + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\n\n\n\nStandaridizziamo i predittori:\n\nx1 = stats.zscore(kidiq[\"mom_hs\"])\nx2 = stats.zscore(kidiq[\"mom_iq\"])\nx3 = stats.zscore(kidiq[\"mom_age\"])\n\n\ndf = pd.DataFrame({\n    \"one\": [1] * len(x1),  # Crea una lista di 1 della stessa lunghezza di x1\n    \"x1\": x1,\n    \"x2\": x2,\n    \"x3\": x3\n})\n\ndf.head()\n\n\n\n\n\n\n\n\n\none\nx1\nx2\nx3\n\n\n\n\n0\n1\n0.522233\n1.409460\n1.562029\n\n\n1\n1\n0.522233\n-0.710026\n0.820727\n\n\n2\n1\n0.522233\n1.030732\n1.562029\n\n\n3\n1\n0.522233\n-0.036733\n0.820727\n\n\n4\n1\n0.522233\n-0.484177\n1.562029\n\n\n\n\n\n\n\n\n\n# Convert scaled DataFrame to numpy matrix\nX = df.to_numpy()\n\n\n# Verificare le dimensioni di X\nprint(\"Dimensioni di X:\", X.shape)\n\nDimensioni di X: (434, 4)\n\n\nCreiamo un dizionario con i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\": X.shape[0],\n    \"K\": X.shape[1],  # Nota: questa include anche la colonna dell'intercetta\n    \"x1\": df[\"x1\"],\n    \"x2\": df[\"x2\"],\n    \"x3\": df[\"x3\"],\n    \"y\": stats.zscore(\n        kidiq[\"kid_score\"]\n    )\n}\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le tracce dei parametri:\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]))\n\n\n\n\n\n\n\n\nAnche nel caso della regressione multipla, i risultati ottenuti con l‚Äôapproccio bayesiano sono molto simili a quelli prodotti dall‚Äôapproccio basato sulla massima verosimiglianza.\nCalcoliamo una sintesi delle distribuzioni a posteriori dei parametri:\n\naz.summary(\n    fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]), hdi_prob=0.94\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.000\n0.043\n-0.082\n0.080\n0.0\n0.001\n9553.0\n5261.0\n1.0\n\n\nbeta1\n0.114\n0.045\n0.031\n0.201\n0.0\n0.000\n9409.0\n6308.0\n1.0\n\n\nbeta2\n0.414\n0.044\n0.330\n0.496\n0.0\n0.000\n9556.0\n6280.0\n1.0\n\n\nbeta3\n0.029\n0.043\n-0.050\n0.112\n0.0\n0.000\n9647.0\n6545.0\n1.0\n\n\nsigma\n0.891\n0.031\n0.835\n0.949\n0.0\n0.000\n9403.0\n5961.0\n1.0\n\n\n\n\n\n\n\n\nReplichiamo il risultato usando l‚Äôapproccio di massima verosimiglianza:\n\nlm = pg.linear_regression(X, stats.zscore(kidiq[\"kid_score\"]))\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-0.00\n0.04\n-0.00\n1.00\n0.21\n0.21\n-0.08\n0.08\n\n\n1\nx2\n0.11\n0.05\n2.50\n0.01\n0.21\n0.21\n0.02\n0.20\n\n\n2\nx3\n0.41\n0.04\n9.28\n0.00\n0.21\n0.21\n0.33\n0.50\n\n\n3\nx4\n0.03\n0.04\n0.68\n0.50\n0.21\n0.21\n-0.06\n0.12",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#interpretazione-dei-coefficienti",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#interpretazione-dei-coefficienti",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.3 Interpretazione dei coefficienti",
    "text": "55.3 Interpretazione dei coefficienti\nNel contesto della regressione multipla, l‚Äôinterpretazione dei coefficienti parziali differisce da quella della regressione bivariata. Una differenza chiave rispetto al modello di regressione bivariato √® nell‚Äôinterpretazione dei coefficienti. Nel caso bivariato, il coefficiente \\(\\beta_1\\) viene interpretato come il cambiamento atteso in \\(Y\\) al variare di una unit√† in \\(X_1\\). Tuttavia, nel modello di regressione multipla, l‚Äôinterpretazione di \\(\\beta_1\\) cambia. In questo caso, \\(\\beta_1\\) rappresenta il cambiamento atteso in \\(Y\\) al variare di una unit√† in \\(X_1\\), mantenendo costanti gli effetti di tutte le altre variabili \\(X_2, X_3, \\ldots, X_p\\). In altre parole, \\(\\beta_1\\) ci dice come varia in media \\(Y\\) quando \\(X_1\\) cambia, ma considera che altre variabili possono variare insieme a \\(X_1\\), e \\(\\beta_1\\) tiene conto di queste variazioni.\nNel nostro caso, il coefficiente associato all‚Äôintelligenza della madre, indicato come \\(\\beta\\) = 0.41, assume il seguente significato: prevediamo che l‚Äôintelligenza del bambino aumenti di 0.41 deviazioni standard in media per ogni deviazione standard aggiuntiva nell‚Äôintelligenza della madre, mantenendo costanti gli effetti del livello di istruzione e dell‚Äôet√† della madre. Questo implica che stiamo considerando l‚Äôimpatto dell‚Äôintelligenza della madre sull‚Äôintelligenza del bambino all‚Äôinterno di una popolazione di madri che sono omogenee per quanto riguarda il livello di istruzione e l‚Äôet√†.\nCosa significa mantenere costante l‚Äôeffetto di altre variabili? Consideriamo l‚Äôesempio della correlazione tra il numero di scarpe e le abilit√† matematiche. Esiste una marcata correlazione positiva tra queste due variabili. Tuttavia, √® evidente che i bambini, avendo in genere numeri di scarpe pi√π piccoli rispetto agli adulti, mostrano anche, presumibilmente, minori capacit√† matematiche. Questo esempio illustra che, se controlliamo per l‚Äôet√†, ossia se consideriamo solo soggetti della stessa et√†, la correlazione tra il numero di scarpe e le abilit√† matematiche scompare. Pertanto, nell‚Äôanalisi della relazione tra abilit√† matematiche (Y) e numero di scarpe (X), l‚Äôet√† (Z) agisce come variabile confondente. Controllare per Z significa esaminare la relazione tra Y e X limitandosi a individui della stessa et√†.\nMa ovviamente questo controllo empirico non √® sempre possibile. Nel modello di regressione, esso viene ‚Äúapprossimato‚Äù con una procedura statistica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.4 Distribuzione predittiva a posteriori",
    "text": "55.4 Distribuzione predittiva a posteriori\nCalcoliamo la distribuzione predittiva a posteriori e generiamo il PPC plot:\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_rep',\n    observed_data={'y': stats.zscore(kidiq[\"kid_score\"])},\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_rep'})\n\n/opt/anaconda3/envs/cmdstan_env/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  func(*args, **kwargs)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#il-controllo-statisico",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#il-controllo-statisico",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.5 Il Controllo Statisico",
    "text": "55.5 Il Controllo Statisico\nNella seguente simulazione illustreremo la procedura statistica utilizzata per isolare l‚Äôeffetto di una variabile controllando per un‚Äôaltra.\n\n# Creiamo dei dati di esempio\nnp.random.seed(0)\nN = 100\nX1 = np.random.normal(0, 1, N)\nX2 = X1 + np.random.normal(0, 0.5, N)\nY = 1 + 2 * X1 + 3 * X2 + np.random.normal(0, 1, N)\n\n# Modello completo Y ~ X1 + X2\nmodel_full = sm.OLS(Y, sm.add_constant(np.column_stack((X1, X2))))\nresults_full = model_full.fit()\n\n# Regressione di Y su X2\nmodel_Y_on_X2 = sm.OLS(Y, sm.add_constant(X2))\nresiduals_Y = model_Y_on_X2.fit().resid\n\n# Regressione di X1 su X2\nmodel_X1_on_X2 = sm.OLS(X1, sm.add_constant(X2))\nresiduals_X1 = model_X1_on_X2.fit().resid\n\n# Regressione dei residui di Y sui residui di X1\nmodel_residuals = sm.OLS(residuals_Y, sm.add_constant(residuals_X1))\nresults_residuals = model_residuals.fit()\n\n# Stampiamo i risultati\nprint(\"Coefficient from full model for X1: {:.4f}\".format(results_full.params[1]))\nprint(\n    \"Coefficient from regression of residuals: {:.4f}\".format(\n        results_residuals.params[1]\n    )\n)\n\nCoefficient from full model for X1: 1.9782\nCoefficient from regression of residuals: 1.9782\n\n\nQuesto esempio illustra il concetto di coefficiente parziale di regressione. Questo coefficiente quantifica l‚Äôeffetto della variabile esplicativa \\(X_j\\) sulla variabile dipendente \\(Y\\), depurando l‚Äôeffetto di \\(X_j\\) dall‚Äôinfluenza degli altri predittori nel modello. In sostanza, il coefficiente parziale di regressione valuta l‚Äôimpiego di \\(X_j\\) su \\(Y\\) quando \\(X_j\\) √® considerata linearmente indipendente rispetto agli altri predittori \\(X\\). L‚Äôeffetto misurato √® quindi quello della sola componente di \\(X_j\\) che non √® spiegata linearmente dai restanti predittori \\(X\\) sulla parte di \\(Y\\) che √® anch‚Äôessa indipendente dai medesimi predittori.\nPer chiarire ulteriormente, questo approccio statistico si focalizza sull‚Äôanalizzare l‚Äôeffetto di \\(X_j\\) eliminando l‚Äôinfluenza lineare degli altri predittori \\(X\\). √à simile a valutare la relazione tra \\(Y\\) e \\(X_j\\) in un contesto ideale dove tutti gli individui presentano livelli identici per le altre variabili \\(X\\). Tale metodo non eguaglia gli effetti non lineari che possono essere presenti tra le variabili, limitandosi a correggere solo per le associazioni lineari. In questo modo, il controllo statistico tenta di approssimare una condizione di omogeneit√† tra i soggetti rispetto alle altre variabili \\(X\\), consentendo di isolare e valutare pi√π precisamente l‚Äôeffetto puro di \\(X_j\\) su \\(Y\\).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#quali-predittori-includere-nel-modello",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#quali-predittori-includere-nel-modello",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.6 Quali predittori includere nel modello?",
    "text": "55.6 Quali predittori includere nel modello?\nL‚Äôutilizzo del modello di regressione multipla ha principalmente due scopi. In primo luogo, √® utilizzato per la predizione, cio√® per ottenere la migliore stima possibile di \\(Y\\) utilizzando una combinazione lineare delle variabili \\(X_1, X_2, \\ldots, X_p\\). In questo contesto, i coefficienti \\(\\beta_i\\) sono considerati come pesi che permettono di effettuare questa previsione.\nIn secondo luogo, il modello di regressione multipla viene spesso utilizzato per descrivere le relazioni causali tra le variabili. Tuttavia, √® importante sottolineare che questo modello non √® stato originariamente creato per stabilire relazioni causali, ed √® necessario essere cauti nell‚Äôattribuire interpretazioni causali dirette ai coefficienti \\(\\beta_i\\). Questo perch√© il modello stima correttamente i coefficienti parziali di regressione solo quando tutte le variabili che influenzano \\(Y\\) sono incluse nel modello. Nella pratica, spesso non conosciamo tutte le variabili causalmente rilevanti, il che pu√≤ portare a problemi di errore di specificazione.\nI modello di regressione multipla rappresenta uno strumento potente per predire e analizzare le relazioni tra variabili. Tuttavia, √® fondamentale riconoscerne le limitazioni, specialmente quando si tentano interpretazioni causali. In ambiti come la psicologia, dove √® cruciale comprendere le dinamiche causali, diventa essenziale una scelta accurata delle variabili da includere nel modello per prevenire distorsioni nelle stime dei coefficienti di regressione.\nTradizionalmente, si riteneva vantaggioso includere nel modello il maggior numero possibile di variabili per ottenere un livello di ‚Äúcontrollo‚Äù statistico pi√π elevato. Tuttavia, come sottolineato da McElreath (2020), questo metodo pu√≤ trasformarsi in una ‚Äúinsalata causale‚Äù. Questo termine descrive una situazione in cui la mancanza di attenzione alla struttura causale tra le variabili pu√≤ portare all‚Äôinclusione di variabili di controllo inappropriate, causando distorsioni nelle stime.\nIn alcuni casi, l‚Äôinserimento di determinate variabili di controllo nel modello √® indispensabile per evitare distorsioni, mentre in altri casi, l‚Äôinclusione di variabili non pertinenti pu√≤ portare a risultati fuorvianti. Questo enfatizza l‚Äôimportanza di formulare ipotesi chiare e ben ponderate sulla struttura causale che intercorre tra le variabili in esame.\nL‚Äôefficacia e la validit√† dei risultati ottenuti tramite regressione dipendono strettamente dalla correttezza delle ipotesi causali formulate, sia esplicitamente che implicitamente, dal ricercatore. Pertanto, per superare i limiti dell‚Äôapproccio dell‚Äô‚Äúinsalata causale‚Äù, √® cruciale che la formulazione del modello di regressione rifletta attentamente tali ipotesi causali.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#utilizzo-della-regressione-multipla",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#utilizzo-della-regressione-multipla",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.7 Utilizzo della Regressione Multipla",
    "text": "55.7 Utilizzo della Regressione Multipla\nLa regressione √® il metodo pi√π comune per adattare una linea (o un iper-piano) che spiega la variazione di una variabile dipendente rispetto a una o pi√π variabili indipendenti. Utilizzare una o pi√π variabili per spiegare la variazione in un‚Äôaltra √® un concetto chiave dei modelli lineari.\n\n55.7.1 Identificazione degli Effetti Causali\nQuando si tratta di identificare effetti causali, la regressione √® il metodo pi√π comune per stimare la relazione tra due variabili, controllando contemporaneamente per altre variabili. Questo processo permette di chiudere ‚Äúporte backdoor‚Äù con questi controlli. √à pi√π preciso parlare di ‚Äúaggiustare‚Äù per queste variabili piuttosto che ‚Äúcontrollarle‚Äù, poich√© non esercitiamo un vero controllo come faremmo in un esperimento controllato. Tuttavia, il termine ‚Äúcontrollo‚Äù rimane il pi√π comunemente usato.\nEcco alcuni punti chiave:\n\nPredire una Variabile con un‚ÄôAltra: Possiamo utilizzare i valori di una variabile \\(X\\) per predire i valori di un‚Äôaltra variabile \\(Y\\). Questo √® chiamato spiegare \\(Y\\) utilizzando \\(X\\). Si tratta di una spiegazione puramente statistica che non chiarisce il motivo per cui \\(Y\\) accade, a meno che non abbiamo identificato un effetto causale di \\(X\\) su \\(Y\\).\nAdattare una Linea o un Iperpiano: Esistono diversi modi per modellare la relazione tra variabili; uno comune √® adattare una linea o un iperpiano. Ad esempio, nella regressione lineare standard \\(Y = a + bX\\), i coefficienti vengono stimati minimizzando la somma dei residui quadrati, ovvero la somma degli errori di previsione elevati al quadrato. Oppure, i coefficienti possono essere stimati con un metodo bayesiano. La qualit√† dell‚Äôapprossimazione dipende dalla linearit√† del vero modello.\nPro e Contro:\n\nPro: Utilizza efficientemente la variazione nei dati.\nPro: Una retta o un iperpiano sono facili da interpretare.\nContro: Pu√≤ perdere variazioni interessanti nei dati.\nContro: Se la forma funzionale scelta √® errata, i risultati possono essere inaccurati.\n\nInterpretazione dei Coefficienti: Il coefficiente associato a una variabile \\(X\\) pu√≤ essere interpretato come la pendenza: un aumento di un‚Äôunit√† in \\(X\\) √® associato a un aumento di \\(b\\) unit√† in \\(Y\\).\nCon pi√π Predittori: Con un solo predittore, la stima della pendenza √® la covarianza di \\(X\\) e \\(Y\\) divisa per la varianza di \\(X\\). Con pi√π predittori, la stima tiene conto delle correlazioni tra i diversi predittori.\nPrevisioni e Residui: Inserendo i valori predittivi di un‚Äôosservazione in una regressione stimata, otteniamo una previsione \\(\\hat{Y}\\). La differenza tra \\(Y\\) e \\(\\hat{Y}\\) rappresenta la parte non spiegata, chiamata ‚Äúresiduo‚Äù.\nAggiunta di un‚ÄôAltra Variabile: Aggiungendo una variabile \\(Z\\) all‚Äôequazione di regressione, il coefficiente di ciascuna variabile viene stimato utilizzando la variazione residua dopo aver rimosso quella spiegata dall‚Äôaltra variabile. Questo processo ‚Äúaggiusta per \\(Z\\)‚Äù.\nModelli Non Lineari: Se la relazione tra \\(X\\) e \\(Y\\) non √® ben rappresentata da una linea retta, possiamo utilizzare modelli non lineari. I modelli lineari possono essere adattati per previsioni non lineari mediante combinazioni lineari di variabili (sono ‚Äúlineari nei parametri‚Äù). Alternativamente, possiamo utilizzare modelli di regressione non lineare come il probit, il logit, o altri modelli avanzati.\n\nQuesti sono i concetti fondamentali della regressione. √à importante ricordare che, se il modello di regressione scelto si avvicina al vero modello della popolazione, le sue stime saranno generalmente accurate. Tuttavia, dobbiamo sempre tenere presente che il modello di regressione √® stato ideato per descrivere le associazioni tra variabili e non necessariamente per identificare rapporti causali, anche se spesso viene usato in questo modo ‚Äì si vedano il Capitolo 58 e il Capitolo 59.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#considerazioni-conclusive",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#considerazioni-conclusive",
    "title": "55¬† Regressione multipla con Stan",
    "section": "55.8 Considerazioni conclusive",
    "text": "55.8 Considerazioni conclusive\nNel suo libro Statistical Rethinking, McElreath (2020) introduce l‚Äôidea di modelli statistici paragonandoli ai Golem, antiche creature della mitologia, prive di volont√† propria e animate solo dall‚Äôintento di chi le crea. Questi enti, pur essendo dotati di grande forza, possono diventare pericolosi se non guidati con saggezza.\nMcElreath (2020) sostiene che gli scienziati, nella creazione di modelli matematici e software, diano vita a moderni equivalenti di questi Golem. Questi modelli, sebbene influenzino il mondo reale tramite le loro previsioni e le intuizioni che generano, non dovrebbero essere considerati n√© completamente veritieri n√© falsi. Essi sono piuttosto strumenti sviluppati con uno scopo specifico, capaci di operare calcoli con estrema precisione, ma privi della capacit√† di comprendere o interpretare il contesto pi√π ampio in cui sono applicati.\nIn particolare, il modello di regressione viene esaminato come esempio di come tali strumenti possano produrre risultati concreti, ma manchino di adattabilit√† e giudizio autonomo, limitando la loro efficacia nel trattare questioni che richiedono un approccio pi√π creativo e comprensivo. McElreath (2020) enfatizza ulteriormente che nessun strumento statistico, da solo, √® sufficiente per affrontare adeguatamente il complesso problema dell‚Äôinferenza causale a partire da dati empirici. Questi modelli, privi di una reale comprensione delle dinamiche di causa ed effetto, si limitano a descrivere relazioni tra variabili. Senza un‚Äôinterpretazione critica e un orientamento consapevole da parte degli scienziati, questi strumenti, creati per fini ben definiti, possono rivelarsi non solo inefficaci, ma anche potenzialmente dannosi.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05a_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_05a_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "title": "55¬† Regressione multipla con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas     : 2.2.2\narviz      : 0.18.0\nmatplotlib : 3.9.1\ncmdstanpy  : 1.2.4\npingouin   : 0.5.4\nscipy      : 1.14.0\nstatsmodels: 0.14.2\nnumpy      : 1.26.4\nlogging    : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html",
    "href": "chapters/chapter_5/05_06_hier_regr.html",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo in dettaglio la metodologia della regressione lineare gerarchica Bayesiana, facendo uso delle API della libreria Bambi. Il nostro obiettivo principale √® quello di applicare questo metodo statistico a un dataset multilivello. Nello specifico, ci concentreremo su un dataset che comprende diverse unit√† di osservazione, rappresentate dai soggetti, ciascuna delle quali √® associata a pi√π misurazioni. Per avere una comprensione visiva pi√π chiara dei modelli gerarchici, possiamo consultare il demo di Michael Freeman disponibile su questo sito.\nNei vari ambiti disciplinari, come la sociologia, l‚Äôeconomia, la demografia e l‚Äôepidemiologia, si osserva sempre pi√π frequentemente l‚Äôanalisi di fenomeni con una struttura informativa gerarchica. In questi casi, i dati si riferiscono a pi√π livelli di osservazione o appartenenza, quali quello individuale, familiare, territoriale e sociale. In psicologia, questa struttura gerarchica si evidenzia nei disegni a misure ripetute, dove un singolo soggetto esegue un numero ( n ) di prove per ciascun compito. Specificatamente, lo studio delle interazioni tra l‚Äôindividuo e il suo contesto √® tipicamente analizzato attraverso fenomeni a struttura gerarchica. I modelli pi√π adatti per l‚Äôelaborazione di dati con questa complessit√† sono i cosiddetti modelli multilivello.\nI modelli gerarchici, conosciuti anche come modelli multilivello, modelli ad effetti misti, modelli ad effetti casuali o modelli nidificati, rappresentano un approccio efficace per l‚Äôanalisi di dati organizzati in gruppi o livelli. Tali modelli possono applicarsi a dati geograficamente nidificati (ad esempio, dati di citt√† all‚Äôinterno di province, province all‚Äôinterno di stati), dati organizzati gerarchicamente (come studenti all‚Äôinterno di scuole o pazienti in ospedali), o dati che implicano misurazioni ripetute sugli stessi individui. Questi modelli sono particolarmente utili per gestire le complessit√† intrinseche a tali dati, consentendo di tenere conto delle variazioni sia condivise che uniche tra i gruppi.\nI modelli gerarchici facilitano la condivisione di informazioni tra i gruppi mediante l‚Äôimpiego di distribuzioni priori per i parametri, che a loro volta sono influenzate da distribuzioni priori di livello superiore, comunemente chiamate iperpriori. Il prefisso ‚Äúiper‚Äù deriva dal termine greco per ‚Äúsopra‚Äù, indicando che queste distribuzioni priori operano a un livello superiore rispetto alle distribuzioni priori standard. Le distribuzioni degli iperparametri permettono al modello di equilibrare la descrizione delle caratteristiche specifiche dei gruppi con una descrizione delle tendenze comuni tra i gruppi. In definitiva, i parametri delle distribuzioni priori sono trattati come facenti parte di una popolazione di parametri pi√π ampia. Questo principio √® rappresentato graficamente nella figura di riferimento {numref}hierarchical-model-fig, che contrappone gli approcci dei modelli aggregati (dove i dati sono trattati come se provenissero da un unico gruppo), dei modelli non aggregati (dove ogni gruppo √® trattato separatamente) e dei modelli gerarchici (o parzialmente aggregati), dove le informazioni sono condivise tra i gruppi.\nNei capitoli precedenti, abbiamo introdotto il concetto di modellazione gerarchica bayesiana, focalizzandoci sulla stima dei parametri di distribuzioni di probabilit√†. Per ulteriori dettagli, si rimanda al capitolo {ref}hier_beta_binom_model. In questo capitolo, estenderemo tale concetto alla stima dei parametri in un modello di regressione lineare, prendendo in esame dati suddivisi in vari gruppi.\nAffrontando l‚Äôanalisi di dati provenienti da gruppi eterogenei, potrebbe emergere la tentazione di ignorare le differenze intergruppo, applicando un modello unico che non distingua i vari gruppi. Un tale approccio, pur potenziando la precisione delle stime aggregando tutti i dati, potrebbe comportare la perdita di informazioni preziose specifiche per ciascun gruppo. Al contrario, analizzando i gruppi separatamente, si otterrebbe una panoramica dettagliata ma potenzialmente meno accurata per carenza di dati condivisi.\nL‚Äôanalisi gerarchica offre un compromesso tra questi due estremi, sintetizzando i benefici di entrambe le metodologie. Nel dettaglio, confronteremo tre diversi approcci di modellazione nei paragrafi seguenti:\nIl modello di ‚Äúpartial pooling‚Äù si distingue per la sua capacit√† di bilanciare l‚Äôindipendenza dei gruppi con la necessit√† di un‚Äôanalisi aggregata. Facilita un adeguato ‚Äúshrinkage‚Äù dei parametri, mitigando l‚Äôeffetto di valori anomali o di gruppi con campioni limitati, e permettendo alle stime parametriche di ogni gruppo di essere influenzate sia dai dati specifici che dalla tendenza generale osservata nei dati aggregati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#introduzione",
    "href": "chapters/chapter_5/05_06_hier_regr.html#introduzione",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "",
    "text": "Le differenze tra un modello aggregato (pooled), un modello non aggregato (unpooled) e un modello gerarchico. (Figura tratta da Martin (2024)).\n\n\n\n\n\n\nComplete Pooling: Questo modello ignora la struttura gerarchica dei dati, trattando tutte le unit√† osservative come se appartenessero a una singola popolazione. Questo approccio pu√≤ essere eccessivamente generalizzante e rischia di mascherare le variazioni intergruppo.\nNo Pooling: In netto contrasto, questo modello tratta ogni gruppo come indipendente dagli altri, senza riconoscere alcuna struttura gerarchica. Sebbene questo metodo possa mettere in luce le specificit√† di ciascun gruppo, pu√≤ portare a conclusioni meno robuste per mancanza di un contesto pi√π ampio.\nPartial Pooling (o Modello Multi-Livello): Questo approccio √® il pi√π equilibrato tra i tre, presumendo che pendenze e intercette di ogni gruppo siano realizzazioni di variabili casuali, distribuite normalmente con parametri di media e varianza condivisi tra tutti i gruppi.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#eda",
    "href": "chapters/chapter_5/05_06_hier_regr.html#eda",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "56.1 EDA",
    "text": "56.1 EDA\nIniziamo importando i dati e ispezionando la struttura delle osservazioni suddivise nei diversi cluster.\n\ndata = bmb.load_data(\"sleepstudy\")\ndata.head()\n\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n0\n249.5600\n0\n308\n\n\n1\n258.7047\n1\n308\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n\n\n\n\n\n\nEliminiamo le righe in cui la colonna ‚ÄúDays‚Äù ha valore 0 o 1 dal dataset ‚Äúsleepstudy‚Äù utilizzando il seguente codice:\n\ndata = data[data['Days'].isin([0, 1]) == False]\ndata.head()\n\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n5\n414.6901\n5\n308\n\n\n6\n382.2038\n6\n308\n\n\n\n\n\n\n\n\nAnalizziamo il tempo di reazione medio in relazione ai giorni di deprivazione del sonno, osservando come questo varia per ciascun soggetto coinvolto nello studio.\n\ndef plot_data(data):\n    fig, axes = plt.subplots(3, 6, sharey=True, sharex=True, dpi=100, constrained_layout=True)\n    fig.subplots_adjust(left=0.075, right=0.975, bottom=0.075, top=0.925, wspace=0.03)\n\n    axes_flat = axes.ravel()\n\n    for i, subject in enumerate(data[\"Subject\"].unique()):\n        ax = axes_flat[i]\n        idx = data.index[data[\"Subject\"] == subject].tolist()\n        days = data.loc[idx, \"Days\"].values\n        reaction = data.loc[idx, \"Reaction\"].values\n\n        # Plot observed data points\n        ax.scatter(days, reaction, color=\"C0\", ec=\"black\", alpha=0.7)\n\n        # Add a title\n        ax.set_title(f\"Subject: {subject}\", fontsize=9)\n\n    # Remove axis labels for individual plots\n    for ax in axes_flat:\n        ax.set_xlabel('')\n        ax.set_ylabel('')\n\n    # Set x-axis ticks for the last row\n    for ax in axes[-1]:\n        ax.xaxis.set_ticks([0, 2, 4, 6, 8])\n\n    return axes\n\n\nplot_data(data)\nplt.tight_layout()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#modello-complete-pooling",
    "href": "chapters/chapter_5/05_06_hier_regr.html#modello-complete-pooling",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "56.2 Modello complete pooling",
    "text": "56.2 Modello complete pooling\nIl modello complete pooling tratta tutte le osservazioni come se fossero indipendenti, aggregandole in un unico gruppo. In questo modello, le rette di regressione lineare per tutti i soggetti hanno la stessa pendenza e la stessa intercetta. Il modello pu√≤ essere descritto esplicitamente come segue:\nSe disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello pu√≤ essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha + \\beta \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto $ i $ all‚Äôosservazione $ j $.\n\\(\\alpha\\) √® l‚Äôintercetta comune a tutti i soggetti.\n\\(\\beta\\) √® la pendenza comune a tutti i soggetti.\n\\(\\epsilon_{ij}\\) √® il termine di errore casuale per il soggetto $ i $ all‚Äôosservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non distingue tra i gruppi di osservazoni che appartengono a soggetti diversi e stima un‚Äôunica pendenza e un‚Äôunica intercetta dai dati di tutti i soggetti. In Bambi, questo modello pu√≤ essere specificato utilizzando solo la variabile Days come predittore, senza includere il Subject come fattore.\n\nmodel_pooling = bmb.Model(\"Reaction ~ 1 + Days\", data)\n\nProcediamo con l‚Äôesecuzione del campionamento MCMC, utilizzando il metodo NUTS specifico per il campionatore JAX. Questo pu√≤ essere fatto semplicemente passando l‚Äôopzione method=\"nuts_numpyro\" durante la chiamata al campionamento. In questo modo, stiamo invocando direttamente il campionatore JAX, sfruttando le sue caratteristiche avanzate.\n\nresults_pooling = model_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_pooling.build()\nmodel_pooling.graph()\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(results_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nDays\n11.47\n1.84\n8.04\n14.91\n0.03\n0.02\n3988.87\n2810.71\n1.0\n\n\nIntercept\n244.78\n10.92\n224.46\n264.45\n0.17\n0.12\n4041.97\n2658.41\n1.0\n\n\nsigma\n51.10\n2.98\n45.65\n56.55\n0.04\n0.03\n5329.35\n2790.09\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#modello-no-pooling",
    "href": "chapters/chapter_5/05_06_hier_regr.html#modello-no-pooling",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "56.3 Modello no-pooling",
    "text": "56.3 Modello no-pooling\nIl modello no-pooling tratta ogni soggetto come indipendente e adatta una retta di regressione separata per ciascun soggetto. Se disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello pu√≤ essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2), \\quad j = 1, \\ldots, n_i,\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto $ i $ all‚Äôosservazione $ j $.\n\\(\\alpha_i\\) √® l‚Äôintercetta per il soggetto $ i $.\n\\(\\beta_i\\) √® la pendenza per il soggetto $ i $.\n\\(\\epsilon_{ij}\\) √® il termine di errore casuale per il soggetto $ i $ all‚Äôosservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non fa alcuna ipotesi sulle relazioni tra diversi soggetti e stima la pendenza e l‚Äôintercetta di ciascun soggetto indipendentemente dagli altri soggetti. In Bambi, questo modello viene specificato con l‚Äôinterazione tra Days e Subject, come descritto in seguito.\n\nmodel_no_pooling = bmb.Model(\"Reaction ~ Days * C(Subject)\", data=data)\nresults_no_pooling = model_no_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_no_pooling.build()\nmodel_no_pooling.graph()\n\n\n\n\n\n\n\n\n\naz.summary(results_no_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nC(Subject)[309]\n-57.29\n32.32\n-119.91\n-0.59\n1.26\n0.89\n662.53\n1434.66\n1.00\n\n\nC(Subject)[310]\n-29.91\n32.67\n-90.85\n32.36\n1.29\n0.91\n648.02\n1215.34\n1.00\n\n\nC(Subject)[330]\n9.31\n32.28\n-51.03\n69.55\n1.29\n0.91\n623.35\n1415.59\n1.00\n\n\nC(Subject)[331]\n39.59\n32.86\n-22.53\n99.38\n1.22\n0.86\n726.64\n1777.99\n1.00\n\n\nC(Subject)[332]\n62.43\n33.19\n-0.00\n123.60\n1.32\n0.93\n635.82\n1623.17\n1.00\n\n\nC(Subject)[333]\n15.26\n32.99\n-46.96\n75.75\n1.31\n0.93\n633.21\n1420.10\n1.01\n\n\nC(Subject)[334]\n-46.36\n33.38\n-109.42\n18.03\n1.26\n0.89\n696.22\n1434.39\n1.00\n\n\nC(Subject)[335]\n22.36\n32.50\n-43.55\n80.35\n1.26\n0.89\n659.74\n1582.60\n1.01\n\n\nC(Subject)[337]\n19.29\n33.02\n-40.61\n82.56\n1.29\n0.91\n658.50\n1695.98\n1.00\n\n\nC(Subject)[349]\n-51.72\n32.23\n-118.13\n3.73\n1.26\n0.89\n654.21\n1426.79\n1.01\n\n\nC(Subject)[350]\n-47.43\n32.62\n-108.30\n13.58\n1.19\n0.84\n751.73\n1721.29\n1.00\n\n\nC(Subject)[351]\n-1.28\n32.99\n-63.34\n61.14\n1.31\n0.93\n634.10\n1422.43\n1.00\n\n\nC(Subject)[352]\n68.60\n33.01\n6.21\n131.53\n1.26\n0.89\n691.31\n1521.12\n1.00\n\n\nC(Subject)[369]\n-9.54\n32.80\n-72.64\n50.24\n1.30\n0.92\n635.85\n1376.31\n1.00\n\n\nC(Subject)[370]\n-55.22\n32.46\n-117.63\n3.85\n1.20\n0.85\n738.95\n1906.24\n1.00\n\n\nC(Subject)[371]\n-15.04\n33.29\n-76.39\n47.31\n1.29\n0.91\n664.32\n1407.51\n1.00\n\n\nC(Subject)[372]\n20.02\n33.39\n-43.71\n81.76\n1.34\n0.95\n622.00\n1289.03\n1.00\n\n\nDays\n21.05\n3.80\n13.56\n27.66\n0.20\n0.14\n374.59\n915.48\n1.01\n\n\nDays:C(Subject)[309]\n-16.64\n5.40\n-26.55\n-6.78\n0.21\n0.15\n669.58\n1435.91\n1.00\n\n\nDays:C(Subject)[310]\n-17.16\n5.47\n-27.42\n-6.93\n0.21\n0.15\n673.88\n1335.52\n1.00\n\n\nDays:C(Subject)[330]\n-13.11\n5.40\n-23.92\n-3.79\n0.21\n0.15\n636.31\n1462.66\n1.00\n\n\nDays:C(Subject)[331]\n-16.06\n5.49\n-26.63\n-6.24\n0.20\n0.14\n755.43\n1782.57\n1.00\n\n\nDays:C(Subject)[332]\n-18.55\n5.53\n-28.16\n-7.66\n0.22\n0.15\n650.04\n1629.90\n1.00\n\n\nDays:C(Subject)[333]\n-10.14\n5.49\n-20.40\n-0.26\n0.22\n0.15\n650.65\n1325.11\n1.00\n\n\nDays:C(Subject)[334]\n-2.96\n5.58\n-13.08\n7.98\n0.21\n0.15\n711.41\n1505.34\n1.00\n\n\nDays:C(Subject)[335]\n-25.15\n5.41\n-35.37\n-14.88\n0.21\n0.15\n672.31\n1594.75\n1.01\n\n\nDays:C(Subject)[337]\n1.47\n5.50\n-9.04\n11.35\n0.22\n0.15\n647.87\n1650.71\n1.00\n\n\nDays:C(Subject)[349]\n-4.65\n5.40\n-14.49\n5.76\n0.21\n0.15\n687.64\n1563.10\n1.01\n\n\nDays:C(Subject)[350]\n2.39\n5.46\n-7.64\n12.93\n0.20\n0.14\n742.08\n1511.57\n1.00\n\n\nDays:C(Subject)[351]\n-12.56\n5.51\n-24.47\n-3.13\n0.22\n0.15\n646.65\n1645.59\n1.00\n\n\nDays:C(Subject)[352]\n-13.79\n5.50\n-23.85\n-3.52\n0.21\n0.15\n712.39\n1694.37\n1.00\n\n\nDays:C(Subject)[369]\n-7.23\n5.45\n-17.20\n3.08\n0.21\n0.15\n647.46\n1631.52\n1.00\n\n\nDays:C(Subject)[370]\n-0.36\n5.44\n-10.58\n9.64\n0.20\n0.14\n763.49\n1403.81\n1.00\n\n\nDays:C(Subject)[371]\n-8.73\n5.48\n-19.12\n1.17\n0.21\n0.15\n657.08\n1425.90\n1.00\n\n\nDays:C(Subject)[372]\n-9.87\n5.60\n-20.45\n0.70\n0.22\n0.15\n658.55\n1577.27\n1.00\n\n\nIntercept\n248.27\n22.88\n205.30\n290.34\n1.20\n0.85\n368.87\n797.77\n1.01\n\n\nsigma\n25.77\n1.80\n22.42\n29.16\n0.03\n0.02\n3476.61\n2776.06\n1.00\n\n\n\n\n\n\n\n\nPer ricavare i coefficienti \\(\\alpha\\) delle regressioni individuali, dobbiamo sommare Intercept al valore del singolo soggetto. Per esempio, per il soggetto 309 abbiamo\n\n246.98 + -55.29\n\n191.69\n\n\nFacciamo lo stesso per la pendenza individuale delle rette di regressione. Per il soggetto 309 otteniamo\n\n21.30 + -16.97\n\n4.330000000000002\n\n\nQuesti valori sono identici a quelli che si otterrebbero se adattassimo il modello di regressione separatamente per ciascun soggetto. In effetti, abbiamo fatto proprio questo, utilizzando un modello unico. Per esempio, esaminiamo i singoli dati del soggetto 309.\n\ndata_subject_309 = data[data[\"Subject\"] == 309]\ndata_subject_309.shape\n\n(8, 3)\n\n\nStimiamo l‚Äôintercetta e la pendenza della retta di regressione usando l‚Äôapproccio frequentista mediante la funzione linear_regression del pacchetto pingouin.\n\nresult = pg.linear_regression(data_subject_309[\"Days\"], data_subject_309[\"Reaction\"])\nprint(result)\n\n       names        coef        se          T          pval        r2  \\\n0  Intercept  191.576970  3.723259  51.454104  3.615788e-09  0.890144   \n1       Days    4.357144  0.624898   6.972569  4.325982e-04  0.890144   \n\n     adj_r2    CI[2.5%]   CI[97.5%]  \n0  0.871834  182.466483  200.687458  \n1  0.871834    2.828074    5.886214  \n\n\nSi noti che i risultati ottenuti sono sostanzialmente gli stessi, con solo qualche minima differenza numerica. Questa discrepanza deriva dalla diversit√† degli approcci utilizzati: in un caso abbiamo applicato un metodo bayesiano, mentre nell‚Äôaltro abbiamo adottato una tecnica di stima frequentista.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#modello-partial-pooling",
    "href": "chapters/chapter_5/05_06_hier_regr.html#modello-partial-pooling",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "56.4 Modello partial pooling",
    "text": "56.4 Modello partial pooling\nIl modello gerarchico, conosciuto anche come modello di ‚Äúpartial pooling‚Äù, consente di gestire la complessit√† presente nei dati raggruppati o clusterizzati, come nel caso presente. La regressione lineare classica presume che ogni osservazione sia indipendente dalle altre, ma questa ipotesi viene meno quando i dati sono organizzati in gruppi. Le osservazioni all‚Äôinterno dello stesso gruppo tendono ad essere pi√π correlate tra loro rispetto a quelle in gruppi diversi. Trascurare questa struttura gerarchica potrebbe portare a stime errate e conclusioni fuorvianti.\nIl modello gerarchico affronta questo problema introducendo la nozione di effetti casuali, in contrapposizione agli effetti fissi del modello classico. Gli effetti fissi rappresentano l‚Äôeffetto medio di una variabile predittiva su tutti gli individui o gruppi, mentre gli effetti casuali considerano come l‚Äôeffetto di una variabile possa variare da un gruppo all‚Äôaltro. Mentre gli effetti fissi sono comuni a tutto il dataset, gli effetti casuali tengono conto delle differenze tra i gruppi.\nQuesto modello gerarchico unisce effetti fissi e casuali per fornire una rappresentazione pi√π accurata dei dati, quando questi mostrano relazioni gerarchiche o raggruppate. Il modello gerarchico di ‚Äúpartial pooling‚Äù considera le somiglianze tra i soggetti stimando un‚Äôintercetta e una pendenza comuni, ma consente anche variazioni individuali attorno a questi valori medi.\nPossiamo rappresentare matematicamente il modello come segue:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione del soggetto \\(i\\) al giorno \\(j\\).\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto \\(i\\) all‚Äôosservazione \\(j\\).\n\\(\\alpha_i\\) √® l‚Äôintercetta per il soggetto \\(i\\), che segue la distribuzione \\(\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2)\\).\n\\(\\beta_i\\) √® la pendenza per il soggetto \\(i\\), che segue la distribuzione \\(\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2)\\).\n\\(\\epsilon_{ij}\\) √® l‚Äôerrore casuale per il soggetto \\(i\\) all‚Äôosservazione \\(j\\), distribuito normalmente con media 0 e varianza costante \\(\\sigma^2\\).\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) rappresentano l‚Äôintercetta e la pendenza medie per tutti i soggetti, e le varianze \\(\\tau_\\alpha^2\\) e \\(\\tau_\\beta^2\\) quantificano le differenze tra gli individui.\nIn questo modo, il modello gerarchico riesce a rappresentare sia le informazioni comuni a tutti i soggetti, sia le differenze individuali, considerando sia gli effetti fissi che quelli casuali. Pu√≤ quindi offrire una visione pi√π completa e realistica dei dati, tenendo conto della loro struttura gerarchica. In Bambi, questo modello pu√≤ essere specificato utilizzando la variabile Days come predittore e includendo Subject come effetto casuale.\n\nmodel_partial_pooling = bmb.Model(\n    \"Reaction ~ 1 + Days + (Days | Subject)\", data, categorical=\"Subject\"\n)\n\nEseguiamo il campionamento.\n\nresults_partial_pooling = model_partial_pooling.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\n\nmodel_partial_pooling.build()\nmodel_partial_pooling.graph()\n\n\n\n\n\n\n\n\nEsaminiamo i risultati.\n\naz.summary(results_partial_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\n1|Subject[308]\n10.73\n18.79\n-24.56\n46.04\n0.33\n0.26\n3255.73\n2937.78\n1.0\n\n\n1|Subject[309]\n-42.84\n20.61\n-80.32\n-4.47\n0.33\n0.25\n3875.37\n3221.67\n1.0\n\n\n1|Subject[310]\n-25.54\n19.29\n-60.53\n13.25\n0.30\n0.23\n4138.84\n3018.13\n1.0\n\n\n1|Subject[330]\n4.47\n18.66\n-30.44\n39.57\n0.29\n0.28\n4114.34\n3137.90\n1.0\n\n\n1|Subject[331]\n22.25\n18.84\n-14.37\n56.09\n0.31\n0.24\n3647.27\n3190.14\n1.0\n\n\n1|Subject[332]\n35.47\n19.78\n-0.75\n72.90\n0.35\n0.27\n3136.07\n2682.60\n1.0\n\n\n1|Subject[333]\n12.45\n18.57\n-20.87\n48.62\n0.30\n0.24\n3864.22\n3219.57\n1.0\n\n\n1|Subject[334]\n-21.86\n19.05\n-57.62\n13.62\n0.32\n0.25\n3551.77\n3113.72\n1.0\n\n\n1|Subject[335]\n1.86\n19.13\n-36.87\n36.23\n0.31\n0.29\n3914.21\n3033.18\n1.0\n\n\n1|Subject[337]\n26.90\n19.72\n-9.49\n64.95\n0.31\n0.24\n4180.78\n3018.97\n1.0\n\n\n1|Subject[349]\n-27.34\n19.51\n-65.31\n8.17\n0.31\n0.24\n3972.05\n2986.81\n1.0\n\n\n1|Subject[350]\n-17.19\n18.91\n-51.29\n19.54\n0.32\n0.24\n3485.99\n2853.81\n1.0\n\n\n1|Subject[351]\n-1.03\n18.39\n-34.22\n35.64\n0.30\n0.28\n3653.60\n2564.84\n1.0\n\n\n1|Subject[352]\n43.42\n20.05\n5.56\n80.18\n0.34\n0.25\n3378.64\n2900.83\n1.0\n\n\n1|Subject[369]\n-1.29\n18.93\n-37.66\n32.85\n0.30\n0.28\n3884.22\n2969.10\n1.0\n\n\n1|Subject[370]\n-25.14\n19.29\n-60.79\n11.51\n0.31\n0.24\n3877.94\n3063.29\n1.0\n\n\n1|Subject[371]\n-7.30\n18.51\n-39.34\n29.39\n0.29\n0.26\n4032.75\n3045.50\n1.0\n\n\n1|Subject[372]\n15.07\n19.42\n-22.61\n49.98\n0.31\n0.25\n4032.08\n2887.51\n1.0\n\n\n1|Subject_sigma\n31.48\n8.82\n16.73\n48.74\n0.21\n0.15\n1782.73\n2284.94\n1.0\n\n\nDays\n11.37\n1.92\n7.83\n15.09\n0.05\n0.04\n1504.68\n2031.47\n1.0\n\n\nDays|Subject[308]\n8.15\n3.34\n2.37\n15.12\n0.07\n0.05\n2208.09\n2299.43\n1.0\n\n\nDays|Subject[309]\n-8.11\n3.50\n-14.30\n-1.30\n0.06\n0.05\n3145.27\n2942.98\n1.0\n\n\nDays|Subject[310]\n-7.27\n3.43\n-13.58\n-0.78\n0.06\n0.04\n3102.23\n2932.11\n1.0\n\n\nDays|Subject[330]\n-2.10\n3.30\n-8.62\n3.83\n0.06\n0.05\n2822.25\n3029.09\n1.0\n\n\nDays|Subject[331]\n-3.05\n3.42\n-9.04\n3.88\n0.06\n0.05\n2803.83\n2444.38\n1.0\n\n\nDays|Subject[332]\n-3.97\n3.45\n-10.17\n2.89\n0.07\n0.05\n2581.99\n2954.28\n1.0\n\n\nDays|Subject[333]\n0.45\n3.25\n-6.01\n6.29\n0.07\n0.05\n2399.69\n2255.14\n1.0\n\n\nDays|Subject[334]\n3.23\n3.31\n-2.61\n9.64\n0.07\n0.05\n2494.35\n2739.00\n1.0\n\n\nDays|Subject[335]\n-11.16\n3.42\n-17.82\n-4.83\n0.07\n0.05\n2765.99\n2593.76\n1.0\n\n\nDays|Subject[337]\n9.87\n3.59\n3.35\n16.88\n0.07\n0.05\n2994.53\n2701.91\n1.0\n\n\nDays|Subject[349]\n1.61\n3.46\n-5.02\n8.00\n0.07\n0.06\n2725.31\n2506.06\n1.0\n\n\nDays|Subject[350]\n7.40\n3.43\n1.15\n14.15\n0.07\n0.05\n2300.64\n2640.02\n1.0\n\n\nDays|Subject[351]\n-2.24\n3.27\n-8.15\n4.07\n0.06\n0.04\n2932.11\n2337.58\n1.0\n\n\nDays|Subject[352]\n0.27\n3.49\n-6.25\n6.74\n0.06\n0.05\n2991.34\n2788.30\n1.0\n\n\nDays|Subject[369]\n1.63\n3.40\n-4.75\n7.98\n0.07\n0.05\n2480.67\n2606.23\n1.0\n\n\nDays|Subject[370]\n4.96\n3.45\n-1.25\n11.48\n0.07\n0.05\n2484.65\n2426.40\n1.0\n\n\nDays|Subject[371]\n0.23\n3.34\n-5.78\n6.78\n0.06\n0.05\n2679.35\n2791.42\n1.0\n\n\nDays|Subject[372]\n1.01\n3.41\n-5.36\n7.32\n0.06\n0.05\n3482.98\n3000.94\n1.0\n\n\nDays|Subject_sigma\n6.79\n1.54\n4.13\n9.76\n0.04\n0.03\n1702.73\n2415.41\n1.0\n\n\nIntercept\n245.11\n9.81\n227.19\n263.98\n0.20\n0.14\n2510.76\n2918.52\n1.0\n\n\nsigma\n26.08\n1.79\n22.81\n29.56\n0.03\n0.02\n2791.82\n2675.76\n1.0\n\n\n\n\n\n\n\n\nConsideriamo il soggetto 309. Per questo soggetto l‚Äôintercetta √®\n\n245.24 + -42.22\n\n203.02\n\n\ne la pendenza della retta di regressione √®\n\n11.34 + -8.27\n\n3.0700000000000003\n\n\nSi noti che questi valori sono diversi da quelli ottenuti con la procedura di no-pooling. Entrambi i modelli di no pooling e il modello gerarchico di partial pooling riconoscono che ci possono essere differenze tra i diversi gruppi (o soggetti) nel dataset, ma gestiscono queste differenze in modi diversi.\nNel modello di no pooling, ogni gruppo viene trattato in modo completamente indipendente dagli altri. Ogni intercetta e pendenza viene stimata separatamente per ogni gruppo, senza fare riferimento agli altri gruppi. In altre parole, si adatta una regressione lineare separata per ciascun gruppo. Ci√≤ significa che se si hanno molti gruppi, ci saranno molti parametri da stimare.\nQuesto approccio pu√≤ catturare le differenze tra i gruppi molto accuratamente se ci sono molte osservazioni in ogni gruppo, ma pu√≤ essere problematico se ci sono poche osservazioni per gruppo. Inoltre, non sfrutta le informazioni comuni tra i gruppi e pu√≤ portare a stime molto variabili.\nIl modello gerarchico di partial pooling, invece, riconosce che, anche se ci sono differenze tra i gruppi, questi potrebbero condividere alcune caratteristiche comuni. Invece di stimare le intercette e pendenze completamente separatamente per ogni gruppo, il modello gerarchico stima una media comune e una varianza comune per l‚Äôintercetta e la pendenza, e poi consente a ciascun gruppo di variare attorno a questi valori comuni.\nQuesto porta al concetto di ‚Äúshrinkage‚Äù. Le stime delle intercette e pendenze per ciascun gruppo tendono a essere ‚Äúcompresse‚Äù verso i valori medi. Se un gruppo ha poche osservazioni, la sua stima sar√† pi√π fortemente influenzata dalla media comune. Se ha molte osservazioni, la sua stima sar√† meno influenzata dalla media comune. In questo modo, il modello riesce a bilanciare tra due tendenze opposte: rendere conto delle differenze tra i gruppi e sfruttare le informazioni comuni.\nIn sintesi, la differenza principale tra il modello no-pooling e il modello gerarchico partial-pooling sta nel modo in cui gestiscono le intercette e pendenze individuali:\n\nIl modello no-pooling tratta ogni gruppo separatamente, stimando le intercette e pendenze individuali senza considerare gli altri gruppi.\nIl modello gerarchico partial-pooling stima le intercette e pendenze comuni e consente a ciascun gruppo di variare attorno a questi valori comuni, dando luogo al fenomeno dello shrinkage.\n\nIl modello di no pooling pu√≤ essere pi√π adatto se i gruppi sono veramente indipendenti e molto diversi tra loro, mentre il modello gerarchico √® maggiormente appropriato quando ci sono somiglianze tra i gruppi che possono essere sfruttate per ottenere stime pi√π precise e robuste.\n\n56.4.1 Modello Gerarchico e Distribuzione dei Coefficienti\nIn un contesto di modello gerarchico con partial pooling, gli effetti casuali, inclusi intercette e pendenze specifiche per ciascun gruppo o individuo, vengono trattati come esiti di variabili aleatorie. Questo approccio si distingue nettamente da quello adottato nei modelli di no pooling, nei quali ciascun coefficiente viene considerato come un parametro statico e indipendente.\nAll‚Äôinterno di un modello gerarchico, l‚Äôassunzione di base √® che questi effetti casuali siano distribuiti normalmente. Ci√≤ implica che ogni coefficiente specifico di un gruppo o individuo (come l‚Äôintercetta per un dato soggetto) √® visto come una manifestazione di una variabile aleatoria che segue una distribuzione normale. La distribuzione di queste variabili aleatorie, che rappresenta la popolazione degli effetti casuali, √® caratterizzata da una media e una varianza condivise tra tutti i gruppi o soggetti, le quali vengono inferite direttamente dai dati raccolti. Questo permette di modellare la variabilit√† intra-gruppo e inter-gruppo in modo pi√π flessibile e informato, offrendo una rappresentazione pi√π accurata della struttura dei dati e delle relazioni sottostanti.\nAd esempio, le intercette individuali \\(\\alpha_i\\) possono essere modellate come:\n\\[\n\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2),\n\\]\ndove \\(\\alpha\\) √® l‚Äôintercetta media per tutti i soggetti e \\(\\tau_\\alpha^2\\) √® la varianza delle intercette tra i soggetti. Analogamente, le pendenze individuali \\(\\beta_i\\) possono essere modellate come:\n\\[\n\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2),\n\\]\ndove \\(\\beta\\) √® la pendenza media e \\(\\tau_\\beta^2\\) √® la varianza delle pendenze.\n\n\n56.4.2 Implicazioni\nQuesta struttura ha diverse implicazioni importanti:\n\nShrinkage: Come discusso in precedenza, le stime dei coefficienti individuali tendono a essere ‚Äúcompresse‚Äù verso i valori medi. Questo aiuta a stabilizzare le stime, specialmente quando ci sono poche osservazioni per gruppo.\nScambio di informazioni tra i gruppi: Poich√© i coefficienti individuali sono considerati come estratti dalla stessa distribuzione, ci√≤ permette uno scambio di informazioni tra i gruppi. Se un gruppo ha molte osservazioni, pu√≤ aiutare a informare le stime per un gruppo con poche osservazioni.\nInterpretazione gerarchica: Il modello riconosce una struttura gerarchica nei dati, con osservazioni raggruppate all‚Äôinterno di gruppi, e gruppi che condividono caratteristiche comuni. Questa struttura pu√≤ riflettere una realt√† sottostante nella quale gli individui o i gruppi non sono completamente indipendenti l‚Äôuno dall‚Äôaltro.\n\nIn conclusione, il modello gerarchico di partial-pooling offre un quadro flessibile e potente per analizzare dati raggruppati o clusterizzati, riconoscendo sia le somiglianze che le differenze tra i gruppi e utilizzando una struttura probabilistica per modellare le relazioni tra di loro.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#interpretazione",
    "href": "chapters/chapter_5/05_06_hier_regr.html#interpretazione",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "56.5 Interpretazione",
    "text": "56.5 Interpretazione\nIniziamo considerando le stime a posteriori degli effetti fissi.\n\naz.summary(results_partial_pooling, var_names=[\"Intercept\", \"Days\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n245.11\n9.81\n227.19\n263.98\n0.20\n0.14\n2510.76\n2918.52\n1.0\n\n\nDays\n11.37\n1.92\n7.83\n15.09\n0.05\n0.04\n1504.68\n2031.47\n1.0\n\n\n\n\n\n\n\n\nIn media, il tempo di reazione medio delle persone all‚Äôinizio dello studio √® compreso tra 227 e 264 millisecondi. Con ogni giorno aggiuntivo di privazione del sonno, i tempi di reazione medi aumentano, in media, tra 7.9 e 15.1 millisecondi.\nL‚Äôinterpretazione degli effetti fissi √® semplice. Ma quest‚Äôanalisi sarebbe incompleta e fuorviante se non valutiamo i termini specifici per i singoli soggetti che abbiamo aggiunto al modello. Questi termini ci dicono quanto i soggetti differiscono l‚Äôuno dall‚Äôaltro in termini di tempo di reazione iniziale e dell‚Äôassociazione tra giorni di privazione del sonno e tempi di reazione.\nDi seguito, utilizziamo ArviZ per ottenere un traceplot delle intercetti specifiche per i soggetti 1|Subject e delle pendenze Days|Subject. Questo traceplot contiene due colonne. A sinistra, abbiamo le distribuzioni posteriori e a destra abbiamo i trace-plots. L‚Äôaspetto casuale stazionario, o l‚Äôapparenza di rumore bianco, ci dice che il campionatore ha raggiunto la convergenza e le catene sono ben mescolate.\n\naz.plot_trace(\n    results_partial_pooling, combined=True, var_names=[\"1|Subject\", \"Days|Subject\"]\n)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nDall‚Äôampiezza delle distribuzioni a posteriori delle intercette per i singoli soggetti possiamo vedere che il tempo di reazione medio iniziale per un determinato soggetto pu√≤ differire notevolmente dalla media generale che abbiamo visto nella tabella precedente. C‚Äô√® anche una grande differenza nelle pendenze. Alcuni soggetti vedono aumentare rapidamente i loro tempi di reazione quando vengono deprivati del sonno, mentre altri hanno una tolleranza migliore e peggiorano pi√π lentamente.\nUna rappresentazione grafica della stima a posteriore dei parametri e dei dati si ottiene con az.plot_forest().\n\naz.plot_forest(data=results_partial_pooling, r_hat=False, combined=True, textsize=8);\n\n\n\n\n\n\n\n\nIn sintesi, il modello gerarchico cattura il comportamento che abbiamo visto nella fase di esplorazione dei dati. Le persone differiscono sia nei tempi di reazione iniziali che nel modo in cui questi tempi di reazione sono influenzati dai giorni di deprivazione del sonno. Possiamo dunque giungere alle seguenti conclusioni:\n\nIl tempo di reazione medio delle persone aumenta quando sono deprivate del sonno.\nI soggetti hanno tempi di reazione diversi all‚Äôinizio dello studio.\nAlcuni soggetti sono pi√π colpiti dalla privazione del sonno rispetto ad altri.\n\nMa c‚Äô√® un‚Äôaltra domanda a cui non abbiamo ancora risposto: I tempi di reazione iniziali sono associati a quanto la deprivazione del sonno influisce sull‚Äôevoluzione dei tempi di reazione?\nCreiamo un diagramma a dispersione per visualizzare le stime a posteriori congiunte delle intercette e delle pendenze specifiche per i soggetti. Questo grafico usa colori diversi per i soggetti. Se guardiamo il quadro generale, cio√® trascurando i ragruppamenti dei dati in base ai soggetti, possiamo concludere che non c‚Äô√® associazione tra l‚Äôintercetta e la pendenza. In altre parole, avere tempi di reazione iniziali pi√π bassi o pi√π alti non dice nulla su quanto la deprivazione del sonno influisca sul tempo di reazione medio di un determinato soggetto.\nD‚Äôaltra parte, se guardiamo la distribuzione a posteriori congiunta per un determinato individuo, possiamo vedere una correlazione negativa tra l‚Äôintercetta e la pendenza. Questo indica che, condizionalmente a un determinato soggetto, le stime a posteriori dell‚Äôintercetta e della pendenza non sono indipendenti.\n\n#  extract a subsample from the posterior and stack the chain and draw dims\nposterior = az.extract(results_partial_pooling, num_samples=500)\n\n_, ax = plt.subplots()\n\nresults_partial_pooling.posterior.plot.scatter(\n    x=\"1|Subject\", y=\"Days|Subject\",\n    hue=\"Subject__factor_dim\",\n    add_colorbar=False,\n    add_legend=False,\n    edgecolors=None,\n)\n\nax.axhline(c=\"0.25\", ls=\"--\")\nax.axvline(c=\"0.25\", ls=\"--\")\nax.set_xlabel(\"Subject-specific intercept\")\nax.set_ylabel(\"Subject-specific slope\");",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#confronto-dei-modelli",
    "href": "chapters/chapter_5/05_06_hier_regr.html#confronto-dei-modelli",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "56.6 Confronto dei modelli",
    "text": "56.6 Confronto dei modelli\nUn aspetto finale e cruciale del nostro studio riguarda il confronto tra i diversi modelli che abbiamo esaminato. La nostra intenzione √® determinare quale modello fornisce una rappresentazione migliore dei dati, trovando un equilibrio appropriato tra l‚Äôaccuratezza del modello e la sua complessit√†, cio√® la parsimonia.\nPer raggiungere questo scopo, faremo uso della metrica ELPD (Expected Log Predictive Density), che abbiamo introdotto in precedenza. ELPD ci consente di valutare un modello in termini di adattamento ai dati, considerando sia l‚Äôaccuratezza delle previsioni che la complessit√† del modello.\n\n56.6.1 Utilizzo di az.compare()\nIn Python, possiamo sfruttare la funzione az.compare() per confrontare direttamente modelli bayesiani. Questa funzione accetta un dizionario contenente gli oggetti InferenceData, risultanti dalla funzione Model.fit(), e restituisce un dataframe. I modelli vengono ordinati dal migliore al peggiore in base ai criteri selezionati, e di default, ArviZ usa il criterio di convalida incrociata ‚Äúleave one out‚Äù (LOO).\n\n56.6.1.1 Convalida Incrociata ‚ÄúLeave One Out‚Äù (LOO)\nLOO √® una tecnica di convalida che addestra il modello su tutti i dati disponibili tranne uno, utilizzando il singolo punto escluso come dati di test. Questo processo viene ripetuto per ogni punto dati nel set, e la media delle misure di errore fornisce una stima accurata dell‚Äôerrore di generalizzazione del modello. Anche se computazionalmente impegnativa, LOO fornisce una valutazione affidabile delle prestazioni del modello. In ArviZ, la funzione loo implementa questo metodo seguendo un approccio bayesiano.\n\n\n56.6.1.2 Widely Applicable Information Criterion (WAIC)\nOltre a LOO, possiamo anche utilizzare il criterio WAIC (Widely Applicable Information Criterion). Il WAIC √® uno strumento per la selezione del modello che mira a trovare il modello ottimale in un insieme di candidati, equilibrando l‚Äôadattamento ai dati e la complessit√† del modello, evitando cos√¨ il sovradattamento. WAIC √® particolarmente utile nel contesto bayesiano, poich√© tiene conto dell‚Äôincertezza associata ai parametri del modello.\nSia LOO che WAIC possono essere visti come stime empiriche dell‚ÄôELPD, fornendo un quadro comprensivo delle prestazioni dei modelli.\n\n\n\n56.6.2 Conclusione\nUtilizzando la funzione az.compare(), siamo in grado di effettuare una comparazione rapida ed efficace tra i diversi modelli, valutandoli secondo i criteri LOO e WAIC. Nel nostro caso specifico, il modello di ‚Äúpartial pooling‚Äù emerge come il migliore, presentando il valore ELPD stimato pi√π alto. Questo risultato conferma la validit√† del modello nel rappresentare la struttura dei dati, tenendo conto delle differenze individuali all‚Äôinterno dei cluster, e fornendo una stima coerente e informativa dell‚Äôeffetto della deprivazione del sonno sul tempo di reazione.\n\nmodels_dict = {\n    \"pooling\": results_pooling,\n    \"no_pooling\": results_no_pooling,\n    \"partial_pooling\": results_partial_pooling\n}\ndf_compare = az.compare(models_dict)\ndf_compare\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\npartial_pooling\n0\n-691.713947\n30.295799\n0.000000\n0.891306\n21.342364\n0.000000\nTrue\nlog\n\n\nno_pooling\n1\n-694.191320\n35.912449\n2.477372\n0.059001\n21.481324\n3.252636\nTrue\nlog\n\n\npooling\n2\n-772.071995\n2.953189\n80.358048\n0.049694\n9.029538\n19.939206\nFalse\nlog\n\n\n\n\n\n\n\n\n√à importante sottolineare che, per ottenere una stima dell‚ÄôELPD (Expected Log Predictive Density), √® necessario includere l‚Äôopzione idata_kwargs={\"log_likelihood\": True} all‚Äôinterno della funzione responsabile dell‚Äôesecuzione del campionamento MCMC.\nLa figura che segue illustra visivamente le informazioni rilevanti per il confronto tra i diversi modelli. In grigio √® indicata l‚Äôincertezza nella stima della differenza tra i valori ELPD dei diversi modelli.\n\n_ = az.plot_compare(df_compare, insample_dev=False)\n\n\n\n\n\n\n\n\nIl confronto tra i modelli guida il processo di selezione. In particolare, la comparazione tra il modello di partial-pooling e il modello completo di pooling √® resa chiara dall‚Äôelpd_diff di 80.17 e dal suo errore standard di 19.97. Questi valori indicano inequivocabilmente che il modello di partial-pooling √® superiore.\nLa situazione diventa pi√π sfumata quando confrontiamo il modello di partial-pooling con il modello di no-pooling. In questo caso, le stime dell‚ÄôELPD mostrano una grande sovrapposizione, suggerendo che non c‚Äô√® una differenza netta tra i due modelli in termini di adattamento ai dati.\nTuttavia, nonostante la vicinanza dei valori di ELPD, il modello di partial-pooling √® da preferire. La ragione risiede nelle sue propriet√†: esso fornisce stime pi√π robuste e conservative delle differenze individuali. A differenza del modello di no-pooling, che pu√≤ essere troppo sensibile alle variazioni all‚Äôinterno dei cluster, il modello di partial-pooling incorpora un equilibrio tra la condivisione delle informazioni all‚Äôinterno del gruppo e il riconoscimento delle differenze tra i gruppi. Questo lo rende pi√π resistente alle fluttuazioni nei dati e offre una rappresentazione pi√π affidabile delle relazioni sottostanti, rendendolo la scelta preferibile in questo contesto.\n\n56.6.2.1 PPC plots\nPer affrontare il tema della selezione di modelli, Johnson, Ott, e Dogucu (2022) usano anche il metodo dei posterior predictive checks. Creiamo dunque i PPC plots per i tre modelli.\n\nmodel_pooling_fitted = model_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_pooling.predict(model_pooling_fitted, kind=\"pps\")\n\n\n_ = az.plot_ppc(model_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_no_pooling_fitted = model_no_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_no_pooling.predict(model_no_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_no_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_partial_pooling_fitted = model_partial_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_partial_pooling.predict(model_partial_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_partial_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\nIn questo contesto specifico, l‚Äôanalisi tramite i PPC (Posterior Predictive Checks) plots non rivela differenze evidenti tra i tre modelli in esame: tutti sembrano egualmente adeguati nell‚Äôadattarsi ai dati. Di conseguenza, i PPC plots non forniscono ulteriori chiarimenti o conferme alle conclusioni gi√† raggiunte attraverso il confronto tra modelli basato sulla differenza ELPD (Expected Log Predictive Density). In altre parole, l‚Äôanalisi visiva tramite i PPC plots non aggiunge valore o informazioni supplementari a quanto gi√† dedotto dalle metriche di confronto.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#conclusioni",
    "href": "chapters/chapter_5/05_06_hier_regr.html#conclusioni",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "56.7 Conclusioni",
    "text": "56.7 Conclusioni\nIn questo capitolo, abbiamo esaminato e confrontato i modelli di pooling, no pooling e partial pooling utilizzando i dati provenienti dallo studio sul sonno di Belenky et al. (2003) (‚Äúsleepstudy‚Äù). Ciascun modello presenta caratteristiche distintive: il pooling per la sua struttura comune, il no pooling per la sua indipendenza tra i gruppi e il partial pooling come un compromesso equilibrato tra i due.\nL‚Äôanalisi basata sulla differenza della densit√† predittiva logaritmica attesa (ELPD) √® stata cruciale per selezionare il modello pi√π appropriato. Nonostante ciascun modello abbia vantaggi specifici, valutare l‚ÄôELPD ha fornito una misura obiettiva della qualit√† di adattamento, facilitando la scelta del modello che meglio rispecchia la struttura sottostante dei dati.\nIn conclusione, l‚Äôapproccio combinato di comprensione delle caratteristiche dei modelli e l‚Äôapplicazione di metodi quantitativi come l‚ÄôELPD ha permesso una selezione dei modelli informata ed efficace.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_06_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_06_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "56¬† Il modello lineare gerarchico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npingouin  : 0.5.4\nbambi     : 0.14.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBelenky, Gregory, Nancy J Wesensten, David R Thorne, Maria L Thomas, Helen C Sing, Daniel P Redmond, Michael B Russo, e Thomas J Balkin. 2003. ¬´Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: A sleep dose-response study¬ª. Journal of Sleep Research 12 (1): 1‚Äì12.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMartin, Osvaldo. 2024. Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html",
    "href": "chapters/chapter_5/05_07_robust_regr.html",
    "title": "57¬† Regressione robusta",
    "section": "",
    "text": "Introduzione\nNell‚Äôambito della psicologia, la gestione efficace dei dati anomali √® cruciale per garantire l‚Äôintegrit√† e l‚Äôaffidabilit√† delle inferenze statistiche. La regressione robusta bayesiana rappresenta un approccio metodologico avanzato, specificamente progettato per affrontare le sfide poste da distribuzioni dei dati caratterizzate da deviazioni significative dalla norma, comuni nei dataset psicologici. Questo capitolo si dedica all‚Äôesplorazione dettagliata della regressione robusta bayesiana, con un focus particolare sull‚Äôimpiego della distribuzione Student-t come modello di errore per accrescere la tolleranza ai dati anomali e sul Pareto Smoothed Importance Sampling (PSIS) per individuare la presenza di dati anomali.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "href": "chapters/chapter_5/05_07_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "title": "57¬† Regressione robusta",
    "section": "57.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati",
    "text": "57.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati\nLe osservazioni anomale, comunemente note come outlier, ovvero i valori che si situano ai margini della distribuzione complessiva dei dati, hanno un ruolo fondamentale nell‚Äôanalisi statistica. La loro presenza, infatti, pu√≤ seriamente compromettere l‚Äôintegrit√† e la validit√† predittiva di un modello statistico, evidenziando una potenziale inadeguatezza del modello stesso nel rappresentare con precisione l‚Äôeterogeneit√† intrinseca dei dati. Questi valori estremi sono indicativi di limitazioni nel modello, suggerendo che esso potrebbe non essere configurato correttamente o che possa non essere in grado di catturare tutte le dinamiche sottostanti i dati. Pertanto, l‚Äôidentificazione e l‚Äôanalisi approfondita degli outlier sono essenziali per garantire che le inferenze e le previsioni generate da un modello statistico siano robuste e affidabili.\nIgnorare o rimuovere gli outlier senza un‚Äôaccurata valutazione delle loro cause e caratteristiche pu√≤ portare a interpretazioni errate dei dati. Tale pratica pu√≤ essere paragonata a un tentativo di ‚Äúcorrezione‚Äù dei dati piuttosto che a un miglioramento del modello, nascondendo di fatto i veri problemi anzich√© risolverli. Di conseguenza, la sfida principale consiste nel comprendere l‚Äôimpatto degli outlier sul modello e nel trovare strategie per integrare queste informazioni anzich√© escluderle, considerandoli un elemento informativo cruciale nell‚Äôanalisi complessiva.\nPer affrontare gli outlier in modo efficace, √® essenziale adottare approcci statistici robusti. Questi possono includere la modifica della funzione di verosimiglianza per aumentare la tolleranza nei confronti di variazioni estreme dei dati, l‚Äôimpiego di distribuzioni a priori che ammettano esplicitamente la presenza di deviazioni significative, o l‚Äôutilizzo di metodi specifici per identificare e analizzare gli outlier.\nIn sintesi, gli outlier non dovrebbero essere visti come un problema da evitare, ma piuttosto come un‚Äôoccasione per affinare e perfezionare i modelli statistici. La rimozione degli outlier senza un‚Äôadeguata analisi pu√≤ condurre a conclusioni fuorvianti e a previsioni poco affidabili. Al contrario, un esame dettagliato e l‚Äôintegrazione consapevole degli outlier possono arricchire la nostra comprensione del fenomeno studiato, migliorando la precisione e l‚Äôaffidabilit√† delle previsioni del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html#mistura-di-gaussiane",
    "href": "chapters/chapter_5/05_07_robust_regr.html#mistura-di-gaussiane",
    "title": "57¬† Regressione robusta",
    "section": "57.2 Mistura di Gaussiane",
    "text": "57.2 Mistura di Gaussiane\nNel presente capitolo, esploreremo una metodologia avanzata per mitigare l‚Äôeffetto degli outlier attraverso l‚Äôottimizzazione della funzione di verosimiglianza, incrementando cos√¨ la sua robustezza nei confronti di deviazioni estreme nei dati. Una tattica particolarmente efficace per raggiungere tale obiettivo implica l‚Äôutilizzo della distribuzione t di Student nella modellazione dei dati. In particolare, nel contesto dell‚Äôanalisi di regressione, √® stato evidenziato come gli outlier possano influenzare negativamente la retta di regressione, facendola deviare dalle zone di maggiore densit√† dei dati. Attraverso l‚Äôutilizzo della distribuzione t di Student, la quale presenta code pi√π pesanti rispetto alla distribuzione Gaussiana (Normale), √® possibile ridurre l‚Äôimpatto distorsivo degli outlier sulla retta di regressione. Questo rappresenta un esempio classico di regressione robusta.\nLa distribuzione t di Student pu√≤ essere compresa concettualmente come una composizione di diverse distribuzioni gaussiane, ognuna con la propria varianza specifica. Questa caratteristica conferisce alla distribuzione una maggiore flessibilit√† nel trattare dati con varianze estreme, rendendola particolarmente adatta per l‚Äôuso in modelli statistici che richiedono una notevole resistenza agli outlier. Utilizzare questa distribuzione facilita l‚Äôesecuzione di analisi pi√π robuste e la generazione di previsioni pi√π accurate, migliorando il livello di inferenza in situazioni dove sono presenti dati anomali.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-6, 6, 100)\n\n# Inizializzazione dell'array per i PDF (Probability Density Function)\npdfs = []\n\n# Numero di gaussiane\nn_gaussians = 20\n\n# Ciclo per tracciare ogni gaussiana\nfor variance in np.linspace(.5, 5, n_gaussians):\n    label = \"Individual\\nGaussians\" if variance == .5 else None\n    pdf = stats.norm(0, variance).pdf(xs)\n    pdfs.append(pdf)\n    plt.plot(xs, pdf, color='k', label=label, alpha=.25)  # Usa matplotlib.pyplot.plot\n\n# Calcolo della somma dei PDFs\nsum_of_pdfs = np.array(pdfs).sum(axis=0)\nsum_of_pdfs /= sum_of_pdfs.max()\nsum_of_pdfs *= (1 - n_gaussians / 100)\n\n# Tracciare la somma dei PDFs\nplt.plot(xs, sum_of_pdfs, label='Mixture of\\nGaussian')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa natura della distribuzione t di Student come mistura di Gaussiane porta con s√© importanti conseguenze analitiche.\nLa caratteristica di essere una somma di distribuzioni gaussiane con varianze eterogenee si riflette nella presenza di code pi√π pesanti rispetto a una distribuzione gaussiana singola. Ci√≤ significa che la distribuzione t √® in grado di gestire pi√π efficacemente osservazioni estreme, rendendola una scelta preferenziale per dati che si discostano dalla normalit√†, soprattutto in presenza di outlier.\nIn numerosi ambiti si osserva frequentemente la presenza di dati provenienti da popolazioni con caratteristiche eterogenee, talvolta non immediatamente identificabili. Questa diversit√† pu√≤ essere il risultato di una variet√† di meccanismi sottostanti con varianze distinte. Essendo composta da diverse gaussiane, la distribuzione t di Student incorpora implicitamente l‚Äôeterogeneit√† non osservabile nei dati, che pu√≤ derivare da diverse fonti con varianze distinte.\nUn‚Äôaltra caratteristica distintiva della distribuzione t di Student √® la sua ridotta sensibilit√† agli outlier rispetto alla distribuzione gaussiana. Grazie alle sue code pi√π pesanti, la distribuzione t attribuisce una maggiore probabilit√† alle osservazioni estreme, riducendo l‚Äôeffetto distorsivo degli outlier sull‚Äôanalisi statistica.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-4, 4, 100)\n\n# Configurazione delle dimensioni del grafico\nplt.subplots(figsize=(6, 3))\n\n# Tracciare la distribuzione normale (Gaussiana)\nplt.plot(xs, stats.norm.pdf(xs), label='Gaussian')\n\n# Tracciare la distribuzione Student-t\nplt.plot(xs, stats.t(2).pdf(xs), color='C2', label='Student-t')\n\nplt.legend()\nplt.show()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html#un-esempio-concreto",
    "href": "chapters/chapter_5/05_07_robust_regr.html#un-esempio-concreto",
    "title": "57¬† Regressione robusta",
    "section": "57.3 Un esempio concreto",
    "text": "57.3 Un esempio concreto\nPer illustrare la capacit√† della distribuzione t di Student di mitigare l‚Äôeffetto degli outlier nell‚Äôanalisi di regressione, in questo capitolo considereremo un set di dati simulati, cos√¨ come illustrato nel tutorial fornito sul sito di Bambi.\n\nsize = 100\ntrue_intercept = 1\ntrue_slope = 2\n\nx = np.linspace(0, 1, size)\n# y = a + b*x\ntrue_regression_line = true_intercept + true_slope * x\n# add noise\ny = true_regression_line + np.random.normal(scale=0.5, size=size)\n\n# Add outliers\nx_out = np.append(x, [0.01, 0.1, 0.15])\ny_out = np.append(y, [12, 11, 13])\n\ndata = pd.DataFrame({\n    \"x\": x_out,\n    \"y\": y_out\n})\n\nSi noti che sono stati introdotti 3 valori anomali nel dataset, nonostante il vero meccanismo generativo dei dati implichi che la pendenza della retta di regressione sia pari a 2.\n\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(111, xlabel=\"x\", ylabel=\"y\", title=\"Generated data and underlying model\")\nax.plot(x_out, y_out, \"x\", label=\"sampled data\")\nax.plot(x, true_regression_line, label=\"true regression line\", lw=2.0)\nplt.legend(loc=0);\n\n\n\n\n\n\n\n\nQueste anomalie possono essere soggette ad un‚Äôanalisi rigorosa mediante l‚Äôapplicazione di metodi statistici avanzati. Un approccio per valutare l‚Äôimpatto di tali outlier sull‚Äôanalisi √® l‚Äôutilizzo della statistica PSIS \\(k\\), una tecnica che permette di quantificare l‚Äôinfluenza delle osservazioni estreme su una distribuzione.\nImplementiamo un modello di regressione lineare per analizzare la relazione tra y (variabile dipendente) e x. In questa analisi iniziale, l‚Äôipotesi sottostante √® che gli errori (o residui), seguano una distribuzione normale (gaussiana).\n\ngauss_model = bmb.Model(\"y ~ x\", data, family=\"gaussian\")\n\n\ngauss_model.build()\ngauss_model.graph()\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati. Si noti che l‚Äôargomento idata_kwargs={\"log_likelihood\": True} passato alla funzione fit √® usato per specificare le opzioni per la creazione dell‚Äôoggetto InferenceData che sar√† restituito. In questo caso, stiamo indicando che vogliamo che il logaritmo della verosimiglianza sia incluso nell‚Äôoggetto InferenceData. Il logaritmo della verosimiglianza pu√≤ essere utilizzato per ulteriori analisi e diagnostica, come il calcolo del LOO (Leave-One-Out Cross-Validation).\n\ngauss_fitted = gauss_model.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\nEsaminiamo visivamente i risultati dell‚Äôanalisi.\n\nax = bmb.interpret.plot_predictions(gauss_model, gauss_fitted, [\"x\"])\nplt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\nplt.show()\n\n\n\n\n\n\n\n\nIpotizzando una distribuzione normale degli errori, l‚Äôanalisi produce una stima fortemente distorta della pendenza della retta di regressione.\n\n_ = az.plot_trace(gauss_fitted)\n\n\n\n\n\n\n\n\n\naz.summary(gauss_fitted, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n2.01\n0.37\n1.34\n2.71\n0.01\n0.00\n3706.05\n2924.03\n1.0\n\n\nx\n0.70\n0.63\n-0.43\n1.91\n0.01\n0.01\n3728.06\n3011.37\n1.0\n\n\ny_sigma\n1.88\n0.13\n1.64\n2.12\n0.00\n0.00\n3760.28\n2821.34\n1.0\n\n\n\n\n\n\n\n\n\nposterior_predictive = gauss_model.predict(gauss_fitted, kind=\"pps\")\nax = az.plot_ppc(gauss_fitted, num_pp_samples=100)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nIn un secondo modello assumiamo che gli errori seguano una distribuzione t di Student.\n\nt_model = bmb.Model(\"y ~ x\", data, family=\"t\")\n\n\nt_model.build()\nt_model.graph()\n\n\n\n\n\n\n\n\n\nt_fitted = t_model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\n\nax = bmb.interpret.plot_predictions(t_model, t_fitted, [\"x\"])\n_ = plt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, la presenza degli outlier non ha distorto in alcun modo la stima della pendenza della retta di regressione. Nella regressione lineare gaussiana classica, i valori anomali hanno l‚Äôeffetto di ‚Äúspingere‚Äù la distribuzione a posteriori di \\(\\beta\\) verso lo zero. Invece, il modello student-t √® pi√π robusto e meno influenzato dai valori anomali.\n\naz.summary(t_fitted, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.04\n0.11\n0.85\n1.24\n0.00\n0.00\n4097.93\n3047.07\n1.0\n\n\nx\n2.05\n0.20\n1.69\n2.43\n0.00\n0.00\n3904.75\n2603.76\n1.0\n\n\ny_nu\n2.11\n0.43\n1.35\n2.89\n0.01\n0.01\n3372.83\n3184.83\n1.0\n\n\ny_sigma\n0.41\n0.05\n0.33\n0.50\n0.00\n0.00\n3528.66\n2898.77\n1.0\n\n\n\n\n\n\n\n\n\nposterior_predictive = t_model.predict(t_fitted, kind=\"pps\")\nax = az.plot_ppc(t_fitted, num_pp_samples=100)\nplt.xlim(-2, 5)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nNella figura successiva, esaminiamo la stima a posteriori della pendenza della retta di regressione per entrambi i modelli.\n\naz.plot_dist(t_fitted.posterior[\"x\"], color=\"C1\", label=\"Student-t Model\")\naz.plot_dist(gauss_fitted.posterior[\"x\"], label=\"Gaussian Model\");\n\n\n\n\n\n\n\n\nSi noti che, in presenza di outlier, l‚Äôimpiego della distribuzione t di Student ha portato a un adattamento del modello pi√π accurato, come evidenziato dai valori diagnostici Pareto \\(k\\).\n\naz.loo(gauss_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -218.88    29.25\np_loo       14.25        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100   97.1%\n (0.5, 0.7]   (ok)          1    1.0%\n   (0.7, 1]   (bad)         2    1.9%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\naz.loo(t_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -113.58    16.36\np_loo        5.55        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100   97.1%\n (0.5, 0.7]   (ok)          3    2.9%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html#waic-e-psis",
    "href": "chapters/chapter_5/05_07_robust_regr.html#waic-e-psis",
    "title": "57¬† Regressione robusta",
    "section": "57.4 WAIC e PSIS",
    "text": "57.4 WAIC e PSIS\nNella sezione seguente, approfondiremo il legame tra i valori diagnostici di Pareto \\(k\\) e il Watanabe-Akaike Information Criterion (WAIC), una metrica essenziale per valutare la qualit√† di un modello statistico. A differenza del pi√π tradizionale criterio di informazione di Akaike (AIC), impiegato nei contesti frequentisti, il WAIC estende il concetto di valutazione della qualit√† di un modello incorporando sia la sua capacit√† di adattamento ai dati sia la sua complessit√† intrinseca. Lo scopo √® prevenire l‚Äôeccesso di adattamento (overfitting), dove il modello √® troppo specifico ai dati di addestramento, e l‚Äôinsufficiente adattamento (underfitting), dove il modello √® troppo semplice per catturare la struttura sottostante dei dati. In termini pi√π accessibili, il WAIC stima l‚Äôefficacia con cui un modello pu√≤ prevedere dati non ancora osservati, basandosi sulla log-verosimiglianza dei dati e correggendo per la dimensione effettiva del modello. Un valore WAIC inferiore segnala una maggiore capacit√† previsionale del modello.\nPer calcolare il WAIC, si fa spesso ricorso all‚Äôimportance sampling, una tecnica per approssimare propriet√† di una distribuzione di probabilit√† campionando da una distribuzione alternativa. Il PSIS (Pareto Smoothed Importance Sampling), che migliora questo metodo, e i valori diagnostici di Pareto \\(k\\) giocano un ruolo cruciale nell‚Äôevaluazione della qualit√† dell‚Äôapproximation impiegata per il calcolo del WAIC. Il valore di Pareto \\(k\\) funge da termometro dell‚Äôefficacia dell‚Äôimportance sampling per un determinato modello e insieme di dati. Valori elevati di Pareto \\(k\\) (solitamente oltre 0.7) segnalano potenziali inaffidabilit√† nell‚Äôapprossimazione, il che pu√≤ tradursi in stime del WAIC distorte. Questo fenomeno suggerisce che il modello potrebbe non essere adeguatamente equipaggiato per prevedere specifiche osservazioni nei dati, spesso a causa della presenza di dati anomali o di una scarsa adattabilit√† del modello.\nStabilire un collegamento tra WAIC e i valori di Pareto \\(k\\) √® fondamentale, poich√© offre una panoramica pi√π dettagliata e affidabile della performance di un modello. Se da un lato il WAIC valuta l‚Äôadattabilit√† generale del modello ai dati e la sua gestione della complessit√†, dall‚Äôaltro, il valore di Pareto \\(k\\) fornisce insight preziosi sull‚Äôaffidabilit√† dell‚Äôapprossimazione usata per il suo calcolo. Insieme, queste metriche consentono una valutazione pi√π completa della qualit√† di un modello.\nQuando il calcolo del WAIC viene eseguito in modo puntiforme (pointwise=True), significa che la valutazione √® condotta separatamente per ciascuna osservazione all‚Äôinterno del dataset. Questa modalit√† di calcolo permette di identificare come ogni dato contribuisca al valore globale del WAIC, facilitando l‚Äôindividuazione di potenziali dati anomali o punti critici per il modello, diversamente da un calcolo aggregato che fornirebbe un unico valore di WAIC per tutto il modello. Questa analisi dettagliata √® particolarmente utile per affinare la comprensione della performance modello e per guidare eventuali miglioramenti.\n\ndef plot_loocv(inference, title=None, outliers_idx=[], divorce=None):\n    plt.subplots(figsize=(6, 3))\n    pareto_k = az.loo(inference, pointwise=True).pareto_k\n    waic = -az.waic(inference, pointwise=True).waic_i\n\n    plt.scatter(pareto_k, waic, color='C0', label=None)\n\n    # Assicurati che outliers_idx e divorce siano definiti\n    for oi in outliers_idx:\n        if divorce is not None and oi in divorce.index:\n            plt.annotate(divorce.loc[oi, \"Location\"], (pareto_k[oi] + .01, waic[oi]), fontsize=14)\n\n    plt.xlabel(\"PSIS Pareto K\")\n    plt.ylabel(\"WAIC\")\n    plt.title(title)\n    plt.show()\n\nCreiamo un grafico che mostra i valori di WAIC in funzione dei valori Pareto \\(k\\). Con questa rappresentazione possiamo esaminare come ogni osservazione influisca sulla performance del modello e sulla sua affidabilit√†. Se un punto ha un alto valore di Pareto \\(k\\) e un elevato impatto negativo sul WAIC (indicato da un alto valore negativo di WAIC), potrebbe essere un candidato per un‚Äôulteriore revisione o esclusione dal modello.\n\nplot_loocv(gauss_fitted, title=\"Gaussian Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\n\nplot_loocv(t_fitted, title=\"Student Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\n√à evidente che, per i dati in esame, quando si utilizza un modello di regressione lineare che assume una distribuzione degli errori t di Student, sia il WAIC che i valori diagnostici Pareto \\(k\\) risultano essere inferiori. Questa riduzione indica una maggiore efficienza del modello nella previsione dei dati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html#confronto-tra-modelli",
    "href": "chapters/chapter_5/05_07_robust_regr.html#confronto-tra-modelli",
    "title": "57¬† Regressione robusta",
    "section": "57.5 Confronto tra Modelli",
    "text": "57.5 Confronto tra Modelli\nEseguiamo ora un‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) per confrontare i due modelli statistici, il modello gaussiano e il modello basato sulla distribuzione t di Student. L‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) √® una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacit√† previsionale. Questo metodo √® particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento.\nL‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) √® una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacit√† previsionale. Questo metodo √® particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento. Ecco una spiegazione dettagliata del processo e di come viene applicato per confrontare un modello gaussiano con un modello basato sulla distribuzione t di Student.\nNello specifico, la validazione incrociata LOO √® un caso particolare di validazione incrociata k-fold, dove \\(k\\) √® uguale al numero di osservazioni nel dataset. In pratica, questo significa che per un dataset di \\(n\\) osservazioni, il modello viene addestrato \\(n\\) volte, ogni volta usando \\(n-1\\) osservazioni come dati di addestramento e la singola osservazione restante come dato di test. Questo processo viene ripetuto per ogni osservazione nel dataset, permettendo cos√¨ di valutare la performance del modello su ogni punto dati una volta.\nUtilizzando az.compare, √® possibile confrontare i due modelli sulla base della loro performance previsionale, quantificata attraverso metriche specifiche derivate dalla validazione incrociata LOO. Queste metriche aiutano a determinare quale modello ha una migliore capacit√† di generalizzazione, prendendo in considerazione sia la qualit√† dell‚Äôadattamento ai dati che la complessit√† del modello.\n\ndf_comp_loo = az.compare({\"Gaussian Model\": gauss_fitted, \"Student t Model\": t_fitted})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nStudent t Model\n0\n-113.577604\n5.549347\n0.000000\n1.000000e+00\n16.356973\n0.000000\nFalse\nlog\n\n\nGaussian Model\n1\n-218.877443\n14.247423\n105.299839\n8.894574e-11\n29.253584\n15.972113\nTrue\nlog\n\n\n\n\n\n\n\n\n\naz.plot_compare(df_comp_loo, insample_dev=False);\n\n\n\n\n\n\n\n\nCome abbiamo visto in precedenza, la ELPD (Expected Log Predictive Density) √® una misura della performance predittiva di un modello statistico. Rappresenta il logaritmo della densit√† predittiva media attesa, calcolata attraverso la validazione incrociata LOO. Un valore pi√π alto di ELPD indica una migliore capacit√† del modello di adattarsi ai dati e di fare previsioni accurate su nuovi dati non visti.\n\nrank: Posizione del modello basata sull‚Äôelpd_loo.\nelpd_loo: Stima dell‚ÄôExpected Log Pointwise Predictive Density per LOO-CV. Valori pi√π alti indicano migliori capacit√† predittive.\np_loo: Stima della complessit√† effettiva del modello, che riflette il numero di parametri ‚Äúeffettivi‚Äù.\nelpd_diff: Differenza di elpd_loo tra il modello corrente e il miglior modello. Per il miglior modello, questo valore √® 0.\nweight: Peso basato sull‚Äôelpd_loo, indicando l‚Äôimportanza relativa del modello nel contesto di un ensemble di modelli.\nse (Standard Error): Errore standard dell‚Äôelpd_loo.\ndse (Differenza di Standard Error): Errore standard della differenza di elpd_loo tra due modelli.\nwarning: Se vero, indica potenziali problemi con la stima elpd_loo per il modello.\nscale: La scala utilizzata per misurare l‚Äôelpd_loo; in questo caso, ‚Äúlog‚Äù.\n\nIl modello Student t ha un elpd_loo di -102.284333, il che lo rende il modello con le migliori capacit√† predittive tra i due, poich√© ha il valore elpd_loo pi√π alto (meno negativo). Questo modello ha anche un p_loo di 5.894299, indicando una complessit√† inferiore rispetto al Gaussian Model. Non ci sono avvertimenti, il che suggerisce che la stima elpd_loo √® considerata affidabile. Ha ricevuto un peso di 1.000000, indicando che √® il modello preferito per le previsioni.\nIl modello gaussiano mostra un elpd_loo di -219.324176 con una differenza di elpd_loo (elpd_diff) di 117.039843 rispetto al miglior modello. Questo indica che ha prestazioni significativamente peggiori in termini di adattamento predittivo rispetto allo Student t Model. Il suo p_loo pi√π alto di 15.391340 riflette una maggiore complessit√† del modello, che non sembra tradursi in migliori capacit√† predittive in questo contesto. Il modello presenta anche un avvertimento, il che potrebbe indicare problemi con la stima LOO, suggerendo cautela nell‚Äôinterpretazione dei suoi risultati.\nBasandosi sull‚Äôoutput fornito, il modello Student t √® considerato il modello migliore tra i due per questi dati, dato il suo elpd_loo pi√π alto (meno negativo), la minore complessit√† (p_loo inferiore), e l‚Äôassenza di avvertimenti. Il Gaussian Model, nonostante una maggiore complessit√†, mostra prestazioni inferiori e problemi potenziali (come indicato dall‚Äôavvertimento), rendendolo meno preferibile per la predizione su questo set di dati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/chapter_5/05_07_robust_regr.html#commenti-e-considerazioni-conclusive",
    "title": "57¬† Regressione robusta",
    "section": "57.6 Commenti e considerazioni conclusive",
    "text": "57.6 Commenti e considerazioni conclusive\nNella pratica statistica, si incontrano spesso situazioni in cui l‚Äôeterogeneit√† non osservata - variazioni o differenze tra osservazioni in un insieme di dati che non sono spiegabili attraverso le variabili misurabili nel contesto dello studio - svolge un ruolo significativo. Questa eterogeneit√† si manifesta quando le differenze osservate tra i dati non possono essere attribuite completamente alle variabili note e misurabili. Al contrario, esistono fattori ignoti o non misurati che influenzano le osservazioni, che possono essere intrinseci alle unit√† di osservazione o dipendere da condizioni ambientali o contestuali non contemplate durante la progettazione dello studio o la raccolta dei dati.\nPer modellare questa eterogeneit√†, spesso si utilizzano miscele di distribuzioni gaussiane o Student-t. La scelta della distribuzione Student-t in particolare implica un modello che √® meno sensibile agli effetti dei valori estremi, o ‚Äúoutliers‚Äù, grazie alle sue code pi√π pesanti. Tuttavia, una sfida nella modellazione statistica risiede nel corretto posizionamento dei parametri dei gradi di libert√† della distribuzione Student-t, specialmente perch√© gli outliers sono eventi rari e quindi difficili da stimare accuratamente.\nIn assenza di una teoria solida per guidare la scelta del modello statistico, la regressione robusta, basata su una distribuzione Student-t, emerge come una strategia prudente. Questo approccio si contrappone alla metodologia gaussiana standard, che pu√≤ risultare inadeguata nel gestire gli effetti dei valori estremi e dell‚Äôeterogeneit√† non osservata.\n√à fondamentale, inoltre, valutare accuratamente la bont√† di adattamento del modello ai dati. Strumenti come il Pareto Smoothed Importance Sampling (PSIS) e i valori diagnostici Pareto $ k $ si rivelano preziosi in questo contesto. Il PSIS utilizza la stima di $ k $ per perfezionare l‚Äôadattamento del modello, mentre i valori di $ k $ funzionano come indicatori diagnostici per valutare la qualit√† dell‚Äôimportance sampling e l‚Äôadeguatezza del modello stesso. Questi metodi aiutano a sviluppare modelli pi√π robusti e precisi, specialmente quando si trattano dati complessi con caratteristiche quali outliers e eterogeneit√† non osservata.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_07_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_07_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "57¬† Regressione robusta",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nbambi     : 0.13.0\npymc      : 5.15.1\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nseaborn   : 0.13.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_08_specification_error.html",
    "href": "chapters/chapter_5/05_08_specification_error.html",
    "title": "58¬† Errore di specificazione",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo l‚Äôerrore di specificazione nei modelli di regressione lineare. L‚Äôerrore di specificazione si verifica quando una variabile importante viene omessa dal modello, causando stime dei coefficienti che risultano sistematicamente distorte e inconsistenti.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_08_specification_error.html#dimostrazione",
    "href": "chapters/chapter_5/05_08_specification_error.html#dimostrazione",
    "title": "58¬† Errore di specificazione",
    "section": "58.1 Dimostrazione",
    "text": "58.1 Dimostrazione\nLa dimostrazione algebrica dell‚Äôerrore di specificazione nel modello di regressione, in caso di omissione di una variabile rilevante, coinvolge l‚Äôanalisi delle conseguenze che questa omissione ha sulla stima dei coefficienti di regressione.\nQuando un modello di regressione omette una variabile rilevante che √® correlata sia con la variabile dipendente \\(Y\\) sia con almeno una delle variabili indipendenti incluse nel modello, il coefficiente stimato per le variabili indipendenti incluse pu√≤ essere sistematicamente distorto.\nPer comprendere il bias causato dall‚Äôomissione di una variabile rilevante in un modello di regressione, √® essenziale analizzare dettagliatamente il calcolo delle covarianze e varianze coinvolte. Di seguito viene fornita una spiegazione dei passaggi algebrici che portano alla formulazione del bias di omissione variabile (Omitted Variable Bias, OVB).\n\n58.1.1 Modello Completo e Modello Ridotto\n\nModello Completo:\n\\[\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon\n\\]\nQui, \\(Y\\) √® la variabile dipendente, \\(X\\) e \\(Z\\) sono variabili indipendenti, \\(\\beta_0, \\beta_1, \\beta_2\\) sono i coefficienti, e \\(\\epsilon\\) √® il termine di errore.\nModello Ridotto (con omissione di \\(Z\\)):\n\\[\nY = \\alpha_0 + \\alpha_1 X + u\n\\]\ndove \\(u = \\beta_2 Z + \\epsilon\\) rappresenta il nuovo termine di errore che ora include l‚Äôeffetto non osservato di \\(Z\\).\n\n\n\n58.1.2 Decomposizione di \\(X\\)\nIpotesi:\n\\[ X = \\gamma_0 + \\gamma_1 Z + V \\]\ndove \\(V\\) √® una parte di \\(X\\) indipendente da \\(Z\\), quindi \\(\\text{Cov}(V, Z) = 0\\).\n\n\n58.1.3 Sostituzione nel Modello Ridotto\nSostituendo la decomposizione di \\(X\\) nel modello ridotto, otteniamo:\n\\[ Y = \\alpha_0 + \\alpha_1 (\\gamma_0 + \\gamma_1 Z + V) + u \\]\n\\[ Y = \\alpha_0 + \\alpha_1 \\gamma_0 + \\alpha_1 \\gamma_1 Z + \\alpha_1 V + \\beta_2 Z + \\epsilon \\]\n\\[ Y = (\\alpha_0 + \\alpha_1 \\gamma_0) + (\\alpha_1 \\gamma_1 + \\beta_2) Z + \\alpha_1 V + \\epsilon \\]\n\n\n58.1.4 Calcolo della Covarianza \\(\\text{Cov}(Y, X)\\)\n\\[ \\text{Cov}(Y, X) = \\text{Cov}(\\beta_1 X + \\beta_2 Z + \\epsilon, X) \\]\n\\[ \\text{Cov}(Y, X) = \\beta_1 \\text{Var}(X) + \\beta_2 \\text{Cov}(Z, X) \\]\ndove si usa che \\(\\text{Cov}(\\epsilon, X) = 0\\) poich√© \\(\\epsilon\\) √® indipendente da \\(X\\).\n\n\n58.1.5 Calcolo della Varianza di \\(X\\)\n\\[ \\text{Var}(X) = \\text{Var}(\\gamma_0 + \\gamma_1 Z + V) \\]\n\\[ \\text{Var}(X) = \\gamma_1^2 \\text{Var}(Z) + \\text{Var}(V) \\]\nAncora, \\(\\text{Cov}(Z, V) = 0\\) perch√© \\(V\\) √® definito come indipendente da \\(Z\\).\n\n\n58.1.6 Formula del Coefficiente Stimato \\(\\hat{\\alpha}_1\\)\n\\[ \\hat{\\alpha}_1 = \\frac{\\text{Cov}(Y, X)}{\\text{Var}(X)} \\]\n\\[ \\hat{\\alpha}_1 = \\beta_1 + \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\n\n\n58.1.7 Interpretazione del Bias\nIl bias nel coefficiente stimato \\(\\alpha_1\\), rispetto al vero coefficiente \\(\\beta_1\\), √® dato da:\n\\[ \\text{Bias}(\\hat{\\alpha}_1) = \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\nQuesto risultato dimostra che il bias √® direttamente proporzionale al coefficiente \\(\\beta_2\\) della variabile omessa \\(Z\\) e al rapporto di covarianza tra \\(Z\\) e \\(X\\) diviso per la varianza di \\(X\\). Questo bias pu√≤ essere positivo o negativo a seconda della direzione della correlazione tra \\(X\\) e \\(Z\\), e della grandezza di \\(\\beta_2\\).\n\n\n58.1.8 Conclusioni\nIn sintesi, l‚Äôomissione di \\(Z\\) introduce un bias nella stima di \\(\\alpha_1\\) che non riflette accuratamente \\(\\beta_1\\) se \\(Z\\) √® correlata sia con \\(Y\\) che con \\(X\\). Questo errore di specificazione pu√≤ portare a conclusioni errate sull‚Äôeffetto di \\(X\\) su \\(Y\\) e compromettere l‚Äôaccuratezza delle inferenze tratte dal modello di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_08_specification_error.html#un-esempio-numerico",
    "href": "chapters/chapter_5/05_08_specification_error.html#un-esempio-numerico",
    "title": "58¬† Errore di specificazione",
    "section": "58.2 Un esempio numerico",
    "text": "58.2 Un esempio numerico\nImmaginiamo di analizzare l‚Äôimpatto di due variabili indipendenti, la motivazione e l‚Äôansia, sulla prestazione in un compito specifico. Supponiamo che l‚Äôansia influenzi negativamente la prestazione, mentre la motivazione abbia un effetto positivo.\nLa nostra simulazione evidenzia due scenari distinti:\n\nModello Completo: Quando sia la motivazione che l‚Äôansia sono incluse nel modello di regressione, il coefficiente di regressione per l‚Äôansia viene stimato correttamente come negativo, riflettendo il suo impatto negativo sulla prestazione. Questo conferma che, quando tutte le variabili rilevanti sono presenti, la stima dei loro effetti √® accurata e non distorta.\nModello Ridotto (omissione della motivazione): Se la motivazione, che √® positivamente correlata alla prestazione e positivamente correlata all‚Äôansia, viene omessa dal modello, osserviamo un cambiamento notevole nel coefficiente di regressione per l‚Äôansia. In questo modello ridotto, il coefficiente per l‚Äôansia pu√≤ addirittura diventare positivo, suggerendo erroneamente che l‚Äôansia abbia un effetto benefico sulla prestazione. Questo fenomeno si verifica perch√© l‚Äôeffetto indiretto e non osservato della motivazione sull‚Äôansia porta a una stima distorta quando la motivazione non √® controllata nel modello.\n\n\n# Generiamo dati casuali\nnp.random.seed(42)\nn = 100  # Numero di osservazioni\n\n# Variabili indipendenti con correlazione negativa tra loro\nmotivazione = np.random.normal(100, 10, n)\nansia = 200 + 0.75 * motivazione + np.random.normal(0, 5, n)\n\n# Variabile dipendente, con peso maggiore sulla motivazione rispetto all'ansia\nprestazione = 5 * motivazione - 1 * ansia + np.random.normal(0, 50, n)\n\n# Creazione DataFrame\ndata = pd.DataFrame(\n    {\"Motivazione\": motivazione, \"Ansia\": ansia, \"Prestazione\": prestazione}\n)\n\n\nmodel_full = bmb.Model(\"Prestazione ~ Motivazione + Ansia\", data=data)\nresults_full = model_full.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_full, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n-1.12\n1.18\n-3.33\n1.01\n0.02\n0.02\n2347.49\n2341.41\n1.0\n\n\nIntercept\n-83.86\n250.01\n-521.27\n393.71\n4.87\n3.59\n2641.21\n2665.94\n1.0\n\n\nMotivazione\n6.21\n1.01\n4.38\n8.11\n0.02\n0.01\n2359.56\n2569.60\n1.0\n\n\nPrestazione_sigma\n54.19\n3.86\n47.05\n61.19\n0.06\n0.05\n3580.58\n2684.47\n1.0\n\n\n\n\n\n\n\n\n\n# Analisi di regressione con pingouin\nresults_full = pg.linear_regression(data[[\"Motivazione\", \"Ansia\"]], data[\"Prestazione\"])\nresults_full\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-84.058695\n244.261908\n-0.344133\n7.314908e-01\n0.467656\n0.456679\n-568.850966\n400.733576\n\n\n1\nMotivazione\n6.222523\n0.977770\n6.363994\n6.510176e-09\n0.467656\n0.456679\n4.281920\n8.163125\n\n\n2\nAnsia\n-1.122768\n1.143817\n-0.981597\n3.287403e-01\n0.467656\n0.456679\n-3.392928\n1.147393\n\n\n\n\n\n\n\n\n\nmodel_ansia_only = bmb.Model(\"Prestazione ~ Ansia\", data=data)\nresults_ansia_only = model_ansia_only.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_ansia_only, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n4.66\n0.84\n3.01\n6.13\n0.01\n0.01\n3797.94\n2688.34\n1.0\n\n\nIntercept\n-1055.09\n229.27\n-1470.97\n-615.01\n3.71\n2.65\n3810.32\n2766.51\n1.0\n\n\nPrestazione_sigma\n64.14\n4.66\n55.82\n73.16\n0.08\n0.06\n3209.37\n2678.96\n1.0\n\n\n\n\n\n\n\n\n\nresults_ansia_only = pg.linear_regression(data[[\"Ansia\"]], data[\"Prestazione\"])\nresults_ansia_only\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-1052.984249\n226.249178\n-4.654091\n1.020933e-05\n0.245386\n0.237686\n-1501.968379\n-604.000119\n\n\n1\nAnsia\n4.653853\n0.824399\n5.645148\n1.608208e-07\n0.245386\n0.237686\n3.017861\n6.289846\n\n\n\n\n\n\n\n\nQuesta dimostrazione mette in luce l‚Äôimportanza di includere tutte le variabili rilevanti in un modello di regressione per evitare conclusioni fuorvianti e garantire che le stime dei coefficienti riflettano veramente le relazioni causali tra le variabili.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_08_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_08_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "title": "58¬† Errore di specificazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.13.1\npymc      : 5.15.1\npingouin  : 0.5.4\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\narviz     : 0.18.0\nbambi     : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html",
    "href": "chapters/chapter_5/05_09_causal_inference.html",
    "title": "59¬† Inferenza causale",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo √® di introdurre il modello di regressione multipla e di discutere come esso si collega all‚Äôanalisi causale.\nIl modello di regressione offre indubitabili vantaggi: i coefficienti parziali di regressione consentono di isolare l‚Äôeffetto di una variabile, al netto dell‚Äôinfluenza delle altre variabili nel modello. Questo approccio permette di ottenere quello che viene chiamato ‚Äúcontrollo statistico‚Äù. Nel capitolo precedente, abbiamo introdotto il concetto di errore di specificazione: se escludiamo dal modello di regressione una variabile che ha un effetto causale su \\(Y\\) ed √® correlata con gli altri predittori, le stime degli effetti causali fornite dal modello di regressione saranno sistematicamente distorte. Questo potrebbe suggerire che sia meglio aggiungere al modello quanti pi√π predittori possibile, per massimizzare il controllo statistico e minimizzare la possibilit√† di un errore di specificazione.\nTuttavia, questo approccio, che McElreath (2020) chiama ‚Äúinsalata causale‚Äù, produce pi√π effetti negativi di quanti problemi risolva. In questo capitolo, esploreremo come la selezione delle variabili indipendenti da inserire nel modello di regressione richieda una conoscenza approfondita della struttura causale del fenomeno che si desidera descrivere. Senza una tale conoscenza, l‚Äôuso del modello di regressione pu√≤ risultare pi√π dannoso che utile.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html#confondimento",
    "href": "chapters/chapter_5/05_09_causal_inference.html#confondimento",
    "title": "59¬† Inferenza causale",
    "section": "59.1 Confondimento",
    "text": "59.1 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l‚Äôassociazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l‚Äôassociazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\n\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\n\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\n\nf\n\n\n\n\n\n\n\n\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un‚Äôassociazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale √® condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando cos√¨ l‚Äôinfluenza di \\(U\\) su \\(E\\). L‚Äôassegnazione casuale dell‚Äôistruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non pu√≤ essere eseguito. In assenza di esperimenti, √® necessaria una soluzione statistica che blocchi il percorso non causale. In assenza di esperimenti, si pu√≤ condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l‚Äôeffetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) √® la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l‚Äôinfluenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento pu√≤ distorcere l‚Äôassociazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili pu√≤ isolare il percorso causale, permettendo di misurare accuratamente l‚Äôeffetto di una variabile sull‚Äôaltra.\nQuesta discussione ha un‚Äôimplicazione importante per il modello di regressione. Nel caso dell‚Äôesempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata pu√≤ introdurre distorsioni nei risultati dell‚Äôanalisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non √® possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html#confondimento-1",
    "href": "chapters/chapter_5/05_09_causal_inference.html#confondimento-1",
    "title": "59¬† Inferenza causale",
    "section": "59.2 Confondimento",
    "text": "59.2 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l‚Äôassociazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l‚Äôassociazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\nimport graphviz\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\nf\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un‚Äôassociazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale √® condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando cos√¨ l‚Äôinfluenza di \\(U\\) su \\(E\\). L‚Äôassegnazione casuale dell‚Äôistruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non pu√≤ essere eseguito. In assenza di esperimenti, √® necessaria una soluzione statistica che blocchi il percorso non causale. Si pu√≤ condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l‚Äôeffetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) √® la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l‚Äôinfluenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento pu√≤ distorcere l‚Äôassociazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili pu√≤ isolare il percorso causale, permettendo di misurare accuratamente l‚Äôeffetto di una variabile sull‚Äôaltra.\nQuesta discussione ha un‚Äôimplicazione importante per il modello di regressione. Nel caso dell‚Äôesempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata pu√≤ introdurre distorsioni nei risultati dell‚Äôanalisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non √® possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html#bloccare-i-percorsi-backdoor",
    "href": "chapters/chapter_5/05_09_causal_inference.html#bloccare-i-percorsi-backdoor",
    "title": "59¬† Inferenza causale",
    "section": "59.3 Bloccare i percorsi backdoor",
    "text": "59.3 Bloccare i percorsi backdoor\nBloccare i percorsi di confondimento tra un predittore \\(X\\) e un risultato \\(Y\\) √® noto come ‚Äúchiudere un percorso backdoor‚Äù. Non vogliamo che nessuna associazione spuria entri attraverso un percorso non causale che coinvolge il predittore \\(X\\). Nell‚Äôesempio sopra, il percorso \\(E \\leftarrow U \\rightarrow W\\) √® un percorso di backdoor, poich√© entra in \\(E\\) con una freccia e collega \\(E\\) a \\(W\\). Questo percorso non √® causale: intervenire su \\(E\\) non provocher√† un cambiamento in \\(W\\) attraverso questo percorso, ma produrr√† comunque un‚Äôassociazione tra \\(E\\) e \\(W\\).\nLa buona notizia √® che, dato un grafo aciclico diretto (DAG) causale, √® sempre possibile determinare quali variabili controllare per chiudere tutti i percorsi di backdoor. √à anche possibile identificare quali variabili non controllare per evitare di creare nuovi confondimenti. Esistono quattro tipi fondamentali di relazioni causali che combinano tutti i possibili percorsi: la biforcazione, la catena, il collider e il discendente. Pertanto, √® necessario comprendere solo questi quattro concetti e come fluisce l‚Äôinformazione in ciascuno di essi.\n\nConfondente: Una variabile \\(U\\) che causa sia il predittore \\(X\\) sia il risultato \\(Y\\). Aggiustare per un confondente (fork) √® necessario per ottenere stime non distorte.\n\nEsempio: \\(X \\leftarrow U \\rightarrow Y\\).\n\nCatena: Una sequenza di variabili in cui una causa l‚Äôaltra, formando un percorso diretto. Non si dovrebbe aggiustare per le variabili lungo questo percorso, poich√© rappresenta il percorso causale.\n\nEsempio: \\(X \\rightarrow Z \\rightarrow Y\\).\n\nCollider: Una variabile che √® causata da due altre variabili. Aggiustare per un collider pu√≤ introdurre confondimento, poich√© si crea un‚Äôassociazione spuria tra i due predittori.\n\nEsempio: \\(X \\rightarrow Z \\leftarrow Y\\).\n\nDiscendente: Una variabile che √® causata sia dal predittore \\(X\\) sia dal risultato \\(Y\\). Condizionare su un discendente pu√≤ introdurre un bias, distorcendo l‚Äôassociazione tra \\(X\\) e \\(Y\\).\n\nEsempio: \\(X \\rightarrow W \\leftarrow Y\\) con \\(W\\) che ha un effetto su \\(Z\\) (discendente).\n\n\nComprendere queste relazioni e sapere come intervenire su di esse √® fondamentale per costruire modelli di regressione che riflettano accuratamente le relazioni causali tra le variabili. Questo approccio permette di isolare gli effetti causali e di evitare le distorsioni introdotte da percorsi di backdoor.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "href": "chapters/chapter_5/05_09_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "title": "59¬† Inferenza causale",
    "section": "59.4 Tipi di relazioni elementari nei DAG",
    "text": "59.4 Tipi di relazioni elementari nei DAG\nOgni DAG, per quanto grande e complicato, √® costruito sulle quattro relazioni elementari descritte in precedenza. Esaminiamole in dettaglio.\n\n59.4.1 Confondimento\nLa configurazione detta ‚Äúfork‚Äù rappresenta un classico caso di confondimento. Nel confondimento, una variabile \\(Z\\) √® una causa comune di due variabili \\(X\\) e \\(Y\\), generando una correlazione tra loro: \\(X \\leftarrow Z \\rightarrow Y\\). Se condiamo su \\(Z\\), allora \\(X\\) e \\(Y\\) diventano indipendenti.\n\nfork = Digraph(comment='Forchetta')\nfork.node('X', 'X', shape='plaintext')\nfork.node('Y', 'Y', shape='plaintext')\nfork.node('Z', 'Z', shape='plaintext')\nfork.edge('Z', 'X')\nfork.edge('Z', 'Y')\nfork\n\n\n\n\n\n\n\n\n\n59.4.1.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôistruzione (\\(X\\)) sul salario (\\(Y\\)) con \\(Z\\) che rappresenta lo status socioeconomico.\n\n\n59.4.1.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso non causale, isolando l‚Äôeffetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Introduce confondimento, portando a una stima distorta dell‚Äôeffetto di \\(X\\) su \\(Y\\).\n\n\nn = 1000\nZ = np.random.normal(0, 1, n)\nX = 0.5 * Z + np.random.normal(0, 1, n)\nY = 0.8 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.02\n0.04\n-0.09\n0.05\n0.0\n0.0\n6310.32\n3060.06\n1.0\n\n\nX\n0.30\n0.03\n0.23\n0.36\n0.0\n0.0\n5784.06\n2927.95\n1.0\n\n\nsigma\n1.23\n0.03\n1.18\n1.28\n0.0\n0.0\n6424.03\n3165.63\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.03\n0.03\n-0.08\n0.03\n0.0\n0.0\n5749.64\n3042.71\n1.0\n\n\nX\n-0.04\n0.03\n-0.10\n0.02\n0.0\n0.0\n3711.94\n3112.96\n1.0\n\n\nZ\n0.84\n0.04\n0.77\n0.90\n0.0\n0.0\n3850.83\n3388.92\n1.0\n\n\nsigma\n0.99\n0.02\n0.95\n1.03\n0.0\n0.0\n5593.71\n2941.94\n1.0\n\n\n\n\n\n\n\n\n\n\n\n59.4.2 Catena\nIn una catena, una variabile \\(X\\), influenza un mediatore \\(Z\\), che a sua volta influenza l‚Äôesito \\(Y\\): \\(X \\rightarrow Z \\rightarrow Y\\). Condizionare su \\(Z\\) blocca il percorso da \\(X\\) a \\(Y\\).\n\npipe = Digraph(comment='Tubo')\npipe.node('X', 'X', shape='plaintext')\npipe.node('Y', 'Y', shape='plaintext')\npipe.node('Z', 'Z', shape='plaintext')\npipe.edge('X', 'Z')\npipe.edge('Z', 'Y')\npipe\n\n\n\n\n\n\n\n\n\n59.4.2.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôapprendimento (\\(X\\)) sulla comprensione (\\(Y\\)) mediato dalla conoscenza (\\(Z\\)).\n\n\n59.4.2.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso causale, fornendo solo l‚Äôeffetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Misura l‚Äôeffetto totale di \\(X\\) su \\(Y\\).\n\n\nX = np.random.normal(0, 1, n)\nZ = 5 * X + np.random.normal(0, 1, n)\nY = 3 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Z': Z, 'Y': Y})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.10\n-0.15\n0.23\n0.0\n0.0\n6356.32\n2949.31\n1.0\n\n\nX\n14.95\n0.10\n14.77\n15.13\n0.0\n0.0\n6321.33\n3376.27\n1.0\n\n\nsigma\n3.20\n0.07\n3.06\n3.33\n0.0\n0.0\n6103.86\n2993.17\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.03\n-0.03\n0.10\n0.0\n0.0\n3132.72\n2315.01\n1.0\n\n\nX\n0.23\n0.16\n-0.09\n0.52\n0.0\n0.0\n1234.56\n1621.51\n1.0\n\n\nZ\n2.95\n0.03\n2.89\n3.01\n0.0\n0.0\n1231.93\n1656.26\n1.0\n\n\nsigma\n1.03\n0.02\n0.99\n1.07\n0.0\n0.0\n2903.70\n2513.20\n1.0\n\n\n\n\n\n\n\n\n\n\n\n59.4.3 Collider\nIn un collider, due variabili \\(X\\) e \\(Y\\) influenzano una terza variabile \\(Z\\): \\(X \\rightarrow Z \\leftarrow Y\\). Condizionare su \\(Z\\) pu√≤ indurre una correlazione spuria tra \\(X\\) e \\(Y\\).\n\ncollider = Digraph(comment='Collider')\ncollider.node('X', 'X', shape='plaintext')\ncollider.node('Y', 'Y', shape='plaintext')\ncollider.node('Z', 'Z', shape='plaintext')\ncollider.edge('X', 'Z')\ncollider.edge('Y', 'Z')\ncollider\n\n\n\n\n\n\n\n\nIl bias di selezione si verifica quando il campione che analizziamo non √® rappresentativo della popolazione a causa del processo di selezione. Questo pu√≤ portare a correlazioni spurie perch√© il processo di selezione pu√≤ favorire involontariamente alcune caratteristiche.\nIl bias del collider (o bias di stratificazione del collider) si verifica quando due variabili, \\(X\\) e \\(Y\\), influenzano una terza variabile \\(Z\\) (il collider). Se ci condiamo su \\(Z\\), possiamo indurre un‚Äôassociazione spuria tra \\(X\\) e \\(Y\\), anche se queste variabili sono scorrelate nella popolazione.\nNell‚Äôesempio tratto da McElreath (2020)`, si suggerisce che sembra che gli studi scientifici pi√π degni di nota siano i meno affidabili. Pi√π √® probabile che uno studio sia interessante, se vero, meno √® probabile che sia vero. Pi√π noioso √® il tema, pi√π rigorosi sono i risultati. Come pu√≤ esistere questa correlazione negativa, ampiamente creduta da molti?\nIn realt√†, tutto ci√≤ che √® necessario affinch√© emerga una tale correlazione negativa √® che ci si preoccupin sia della rilevanza che dell‚Äôaffidabilit√†. Che si tratti di revisione di sovvenzioni o di riviste, se editori e revisori si preoccupano di entrambi gli aspetti, allora l‚Äôatto stesso della selezione √® sufficiente a rendere gli studi pi√π rilevanti i meno affidabili. Infatti, √® difficile immaginare come il processo di peer review possa evitare di creare questa correlazione negativa.\nEcco una semplice simulazione per illustrare il concetto. Supponiamo che un pannello di revisione delle sovvenzioni riceva 200 proposte di ricerca. Tra queste proposte, non vi √® alcuna correlazione tra affidabilit√† (rigore, erudizione, plausibilit√† del successo) e rilevanza (valore per il benessere sociale, interesse pubblico). Il pannello pesa in ugual misura l‚Äôaffidabilit√† e la rilevanza. Successivamente, classificano le proposte in base ai loro punteggi combinati e selezionano il 10% migliore per il finanziamento.\n\n# Numero di proposte da finanziare\nN = 200\n# Proporzione da selezionare\np = 0.1\n# Rilevanza non correlata\nnw = np.random.randn(N)\n# Affidabilit√† non correlata\ntw = np.random.randn(N)\ncorrelation = np.corrcoef(tw, nw)[0, 1]\nprint(correlation)\n\n0.026051430796600182\n\n\nNello script, il processo di selezione basato sul punteggio combinato s induce una correlazione spuria tra nw e tw. Sebbene nw e tw siano non correlati nell‚Äôintero dataset, essi appaiono correlati nel sottoinsieme selezionato.\n\n# Punteggio totale\ns = nw + tw\n# Soglia per il 10% migliore\nq = np.quantile(s, 1 - p)\n# Selezionati\nselected = s &gt;= q\n# Correlazione tra affidabilit√† e rilevanza nei selezionati\ncorrelation = np.corrcoef(tw[selected], nw[selected])[0, 1]\nprint(correlation)\n\n-0.7082917138754293\n\n\nSi noti che:\n\nIl punteggio combinato s agisce come un collider perch√© √® influenzato sia da nw che da tw.\nQuando selezioniamo le proposte basandoci su s (condizioniamo su s), introduciamo involontariamente una correlazione tra nw e tw nel sottoinsieme selezionato.\n\nIn altre parole, condizionando su una variabile (s) che √® influenzata sia da nw che da tw, induciamo una correlazione spuria tra queste due variabili non correlate. Questo √® un esempio specifico di bias del collider, dove il processo di selezione agisce come il collider.\nPer riassumere:\n\nBias di selezione: in questo esempio si verifica perch√© analizziamo solo il 10% delle proposte migliori.\nBias del collider: √® introdotto perch√© la variabile di selezione s (punteggio totale) √® influenzata sia da nw che da tw, portando a una correlazione spuria quando condiamo su s.\n\nQuindi, la correlazione spuria osservata nel sottoinsieme selezionato √® il risultato del bias del collider introdotto dal processo di selezione basato sul punteggio combinato.\nPerch√© la correlazione √® negativa nel sottoinsieme di dati selezionato? Perch√©, ad esempio, se una proposta selezionata ha una bassa affidabilit√† (tw), deve avere un‚Äôalta rilevanza (nw). Altrimenti, non sarebbe stata finanziata. Lo stesso vale al contrario: se una proposta ha una bassa rilevanza (nw), possiamo dedurre che deve avere un‚Äôaffidabilit√† superiore alla media. Altrimenti, non sarebbe stata selezionata per il finanziamento. Questo √® il concetto chiave da comprendere: quando condiamo su un collider, si creano associazioni statistiche, ma non necessariamente causali, tra le sue cause.\n\n\n59.4.4 Discendente\nUn discendente √® una variabile influenzata da un‚Äôaltra variabile. Condizionare su un discendente significa parzialmente condizionare sul suo genitore. Nel DAG seguente, condizionare su \\(D\\) condizioner√† anche, in una certa misura, su \\(Z\\).\n\ndescendant = Digraph(comment='Discendente')\ndescendant.node('X', 'X', shape='plaintext')\ndescendant.node('Y', 'Y', shape='plaintext')\ndescendant.node('Z', 'Z', shape='plaintext')\ndescendant.node('D', 'D', shape='plaintext')\ndescendant.edge('X', 'Z')\ndescendant.edge('Y', 'Z')\ndescendant.edge('Z', 'D')\ndescendant\n\n\n\n\n\n\n\n\nQuesto perch√© \\(D\\) contiene informazioni su \\(Z\\), che a sua volta √® un collider tra \\(X\\) e \\(Y\\). Condizionare su \\(D\\) pu√≤ aprire parzialmente il percorso da \\(X\\) a \\(Y\\) attraverso \\(Z\\), creando un‚Äôassociazione spuria tra \\(X\\) e \\(Y\\). Tuttavia, l‚Äôeffetto di condizionare su un discendente dipende dalla relazione tra il discendente e il suo genitore. I discendenti sono comuni nei modelli causali perch√© spesso non possiamo misurare una variabile direttamente e dobbiamo utilizzare un proxy per essa.\n\n59.4.4.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôintelligenza (\\(X\\)) sul punteggio del test (\\(Y\\)) tramite il tempo di apprendimento (\\(Z\\)) e il punteggio in una simulazione (\\(D\\)).\n\n\n59.4.4.2 Conseguenze del Controllo\n\nControllare \\(D\\): Pu√≤ introdurre bias, creando un percorso non causale da \\(X\\) a \\(Y\\) attraverso \\(Z\\).\nNon controllare \\(D\\): Mantiene il percorso causale corretto da \\(X\\) a \\(Y\\).\n\n\nI = np.random.normal(100, 15, n)\nT = 200 - I + np.random.normal(0, 1, n)\nS = 0.5 * I + 0.1 * T + np.random.normal(0, 1, n)\nD = 0.7 * S + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'I': I, 'T': T, 'S': S, 'D': D})\n\n# Modello senza controllo per D\nmod1 = bmb.Model('S ~ T', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n99.39\n0.24\n98.92\n99.82\n0.0\n0.0\n5831.85\n3060.37\n1.0\n\n\nT\n-0.39\n0.00\n-0.40\n-0.39\n0.0\n0.0\n5879.01\n3269.97\n1.0\n\n\nsigma\n1.10\n0.02\n1.05\n1.14\n0.0\n0.0\n6041.49\n3081.54\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per D\nmod2 = bmb.Model('S ~ T + D', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nD\n0.50\n0.02\n0.45\n0.54\n0.00\n0.00\n2526.07\n2095.97\n1.0\n\n\nIntercept\n64.78\n1.58\n61.69\n67.64\n0.03\n0.02\n2486.35\n2167.12\n1.0\n\n\nT\n-0.26\n0.01\n-0.27\n-0.24\n0.00\n0.00\n2490.85\n2271.87\n1.0\n\n\nsigma\n0.90\n0.02\n0.86\n0.94\n0.00\n0.00\n3237.43\n2629.65\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "href": "chapters/chapter_5/05_09_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "title": "59¬† Inferenza causale",
    "section": "59.5 Come aprire o chiudere un percorso nei DAG",
    "text": "59.5 Come aprire o chiudere un percorso nei DAG\nPer determinare quali variabili includere o escludere nel modello di regressione, √® necessario seguire questa procedura:\n\nElencare tutti i percorsi che collegano \\(X\\) (la potenziale causa di interesse) e \\(Y\\) (il risultato).\nClassificare ciascun percorso come aperto o chiuso. Un percorso √® aperto a meno che non contenga un collider.\nIdentificare i percorsi di backdoor. Un percorso di backdoor ha una freccia che entra in \\(X\\).\nChiudere i percorsi di backdoor aperti: Se ci sono percorsi di backdoor aperti, decidere su quali variabili condizionare per chiuderli, se possibile.\n\nCondizionare su una variabile significa includerla nel modello di regressione. Per chiudere un percorso di backdoor, identifichiamo la variabile di confondimento che crea l‚Äôassociazione spuria e la includiamo nel modello. Questo bloccher√† il percorso, impedendo che l‚Äôassociazione spuria influenzi il risultato.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html#riflessioni-conclusive",
    "href": "chapters/chapter_5/05_09_causal_inference.html#riflessioni-conclusive",
    "title": "59¬† Inferenza causale",
    "section": "59.6 Riflessioni conclusive",
    "text": "59.6 Riflessioni conclusive\nIn conclusione, le osservazioni precedenti dimostrano che l‚Äôinferenza causale non pu√≤ essere affrontata semplicemente applicando meccanicamente il modello statistico della regressione lineare. Senza ulteriori conoscenze, che non possono essere derivate esclusivamente dai dati osservati, non √® possibile ottenere stime non distorte degli effetti causali. L‚Äôinferenza causale va oltre le tecniche statistiche: essa richiede informazioni supplementari sulle caratteristiche del fenomeno studiato.\nPer trarre conclusioni corrette sui meccanismi causali, √® essenziale disporre di informazioni dettagliate sul processo generativo dei dati. Bench√© spesso queste informazioni non siano direttamente disponibili, i ricercatori possono adottare strategie per minimizzare il rischio di errori interpretativi. Un passo fondamentale consiste nell‚Äôidentificare ipotetici meccanismi causali prima di procedere con le stime degli effetti, utilizzando diagrammi causali come i grafici aciclici diretti per mappare le relazioni tra le variabili. Questo processo aiuta a determinare quali fattori includere nell‚Äôanalisi, seguendo il ‚Äúbackdoor criterion‚Äù proposto da Judea Pearl, per chiudere i percorsi indiretti tra esposizione ed esito che potrebbero introdurre confondimenti.\nIn assenza di una comprensione del fenomeno in esame, √® cruciale che i ricercatori prestino attenzione all‚Äôordine temporale dei fattori. Questo approccio, fondamentale per l‚Äôinferenza causale, implica che l‚Äôesposizione avvenga prima dell‚Äôesito per stabilire una relazione causale plausibile. Inoltre, √® importante che tutte le covariate considerate nell‚Äôanalisi precedano temporalmente l‚Äôesposizione per evitare potenziali bias di specificazione, specialmente nei contesti di collider e mediazione. Seguendo questi principi, i ricercatori possono ridurre il rischio di stime errate degli effetti causali.\n\n\n\n\n\n\n\nTermine Tecnico\nSpiegazione\n\n\n\n\n(1) Collider\nLa variabile \\(X\\), causa \\(Z\\), e l‚Äôesito, \\(Y\\), causa \\(Z\\). Aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.45X + 0.77Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)\n\n\n(2) Confounder\nLa variabile \\(Z\\) causa sia la variabile indipendente \\(X\\), sia l‚Äôesito, \\(Y\\). Non aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(Z \\sim \\mathcal{N}(0,1)\\), \\(X = Z + \\varepsilon_x\\), \\(\\varepsilon_x \\sim \\mathcal{N}(0,1)\\); \\(Y = 0.5X + Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(3) Mediator\nLa variabile \\(X\\) causa \\(Z\\) che a sua volta causa l‚Äôesito \\(Y\\). Aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene l‚Äôeffetto diretto, non aggiustando per \\(Z\\) si ottiene l‚Äôeffetto totale di \\(X\\) su \\(Y\\). L‚Äôeffetto diretto rappresenta la relazione tra \\(X\\) e \\(Y\\) indipendentemente da qualsiasi mediatore, mentre l‚Äôeffetto totale include sia l‚Äôeffetto diretto sia qualsiasi effetto indiretto mediato dal mediatore potenziale. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Z = X + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\); \\(Y = Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(4) Discendente\nLa variabile \\(X\\) e l‚Äôesito \\(Y\\) hanno una variabile discendente comune \\(Z\\). Non aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene una stima non distorta. Tuttavia, aggiustando per \\(Z\\), si introduce un bias. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.5X + 0.5Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_09_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_09_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "59¬† Inferenza causale",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnetworkx   : 3.3\npandas     : 2.2.2\nbambi      : 0.14.0\nseaborn    : 0.13.2\ngraphviz   : 0.20.3\nnumpy      : 1.26.4\narviz      : 0.18.0\nmatplotlib : 3.9.1\nstatsmodels: 0.14.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_21_stan_binomial_regr.html",
    "href": "chapters/chapter_5/05_21_stan_binomial_regr.html",
    "title": "60¬† Regressione binomiale con Stan",
    "section": "",
    "text": "Introduzione\nIl presente capitolo approfondisce il concetto di regressione binomiale, una metodologia analitica specifica utilizzata per esaminare le variabili dipendenti che rappresentano le proporzioni di successi derivanti da un numero \\(n\\) di tentativi. A differenza della regressione logistica, dove la variabile dipendente segue una distribuzione di Bernoulli con esiti binari, la regressione binomiale si concentra sulle variabili dipendenti che esprimono proporzioni. Questo rende il modello binomiale la scelta pi√π appropriata per analizzare dati di questo tipo. Sia nella regressione logistica che in quella binomiale, √® cruciale rispettare il principio di indipendenza delle osservazioni. Questo requisito √® essenziale per garantire la validit√† e l‚Äôaffidabilit√† delle analisi condotte.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_21_stan_binomial_regr.html#regressione-binomiale",
    "href": "chapters/chapter_5/05_21_stan_binomial_regr.html#regressione-binomiale",
    "title": "60¬† Regressione binomiale con Stan",
    "section": "60.1 Regressione Binomiale",
    "text": "60.1 Regressione Binomiale\nNella regressione binomiale, l‚Äôattenzione √® focalizzata sui dati che si esprimono attraverso eventi dicotomici, ossia successi o insuccessi, in un determinato numero di prove. Un esempio classico √® il conteggio dei successi in una serie di tentativi, come ‚Äú3 successi su 7 tentativi‚Äù. Il modello matematico che descrive questo tipo di dati √®:\n\\[\ny_i \\sim \\text{Binomiale}(n_i, p_i)\n\\]\ndove: - \\(y_i\\) rappresenta il numero di successi osservati; - \\(n_i\\) √® il numero totale di tentativi per l‚Äôi-esima osservazione; - \\(p_i\\) indica la probabilit√† di successo in ogni tentativo per l‚Äôi-esima osservazione.\nNel contesto della regressione binomiale, l‚Äôobiettivo principale √® modellare e stimare la probabilit√† di successo \\(p_i\\) in funzione di una o pi√π variabili indipendenti (i predittori). Questo si realizza attraverso l‚Äôutilizzo di una funzione di collegamento che trasforma una combinazione lineare dei predittori in un valore che risiede nello spazio di probabilit√† \\([0,1]\\), rendendolo interpretabile come probabilit√† di successo.\nLa funzione logistica inversa, o logit inverso, √® la funzione di collegamento pi√π comunemente usata nella regressione binomiale. Questa trasforma la somma lineare dei predittori in una probabilit√†, usando la formula:\n\\[\np_i = \\text{InverseLogit}(\\beta_0 + \\beta_1 \\cdot x_{i1} + \\dots + \\beta_k \\cdot x_{ik})\n\\]\ndove: - \\(p_i\\) √® la probabilit√† stimata di successo per l‚Äôi-esima osservazione; - \\(x_{i1}, \\dots, x_{ik}\\) sono le variabili indipendenti; - \\(\\beta_0, \\beta_1, \\dots, \\beta_k\\) sono i parametri del modello da stimare, inclusa l‚Äôintercetta (\\(\\beta_0\\)) e i coefficienti per ciascun predittore (\\(\\beta_1, \\dots, \\beta_k\\)).\nLa funzione \\(\\text{InverseLogit}(\\eta) = \\frac{1}{1 + e^{-\\eta}}\\) assicura che il risultato sia sempre tra 0 e 1, permettendo di interpretarlo come probabilit√†. Questo √® cruciale perch√© ci consente di mantenere la coerenza interpretativa dei risultati nel contesto della probabilit√† di eventi dicotomici.\nIn conclusione, la regressione binomiale offre un framework robusto per analizzare e interpretare le relazioni tra variabili indipendenti e la probabilit√† di eventi binari, sfruttando la distribuzione binomiale e trasformazioni logistiche per collegare predittori lineari a probabilit√† comprese tra 0 e 1.\nAdottando un approccio bayesiano alla regressione binomiale, √® possibile incorporare le informazioni precedenti o le conoscenze priori sui parametri \\(\\beta\\), attraverso l‚Äôuso di distribuzioni a priori. Questo approccio permette di aggiornare le nostre credenze sui parametri del modello alla luce dei dati osservati, producendo una distribuzione a posteriori che riflette sia le informazioni apportate dai dati che le conoscenze pregresse.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_21_stan_binomial_regr.html#un-esempio-concreto",
    "href": "chapters/chapter_5/05_21_stan_binomial_regr.html#un-esempio-concreto",
    "title": "60¬† Regressione binomiale con Stan",
    "section": "60.2 Un esempio concreto",
    "text": "60.2 Un esempio concreto\nSeguiamo il tutorial fornito sul sito ufficiale di PyMC e generiamo dei dati sintetici dove \\(y\\) indica il numero di successi in \\(n = 20\\) prove e \\(x\\) √® un predittore.\n\n# true params\nbeta0_true = 0.7\nbeta1_true = 0.4\n# number of yes/no questions\nn = 20\n\nsample_size = 30\nx = np.linspace(-10, 20, sample_size)\n# Linear model\nmu_true = beta0_true + beta1_true * x\n# transformation (inverse logit function = expit)\np_true = expit(mu_true)\n# Generate data\ny = rng.binomial(n, p_true)\n# bundle data into dataframe\ndata = pd.DataFrame({\"x\": x, \"y\": y})\ndisplay(data)\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-10.000000\n1\n\n\n1\n-8.965517\n0\n\n\n2\n-7.931034\n1\n\n\n3\n-6.896552\n2\n\n\n4\n-5.862069\n6\n\n\n5\n-4.827586\n7\n\n\n6\n-3.793103\n4\n\n\n7\n-2.758621\n14\n\n\n8\n-1.724138\n14\n\n\n9\n-0.689655\n9\n\n\n10\n0.344828\n12\n\n\n11\n1.379310\n11\n\n\n12\n2.413793\n17\n\n\n13\n3.448276\n19\n\n\n14\n4.482759\n20\n\n\n15\n5.517241\n20\n\n\n16\n6.551724\n18\n\n\n17\n7.586207\n20\n\n\n18\n8.620690\n20\n\n\n19\n9.655172\n20\n\n\n20\n10.689655\n20\n\n\n21\n11.724138\n19\n\n\n22\n12.758621\n20\n\n\n23\n13.793103\n20\n\n\n24\n14.827586\n20\n\n\n25\n15.862069\n20\n\n\n26\n16.896552\n20\n\n\n27\n17.931034\n20\n\n\n28\n18.965517\n20\n\n\n29\n20.000000\n20\n\n\n\n\n\n\n\n\nPer questi dati, il modello di regressione binomiale pu√≤ essere descritto come segue:\n\nModello lineare: \\[\n\\eta_i = \\beta_0 + \\beta_1 x_i\n\\]\nProbabilit√† di successo: \\[\np_i = \\text{logit}^{-1}(\\eta_i) = \\frac{1}{1 + \\exp(-\\eta_i)}\n\\]\nLikelihood: \\[\ny_i \\mid p_i \\sim \\text{Binomiale}(n, p_i)\n\\]\nPriori: \\[\n\\beta_0 \\sim \\mathcal{N}(0, 1)\n\\] \\[\n\\beta_1 \\sim \\mathcal{N}(0, 1)\n\\]\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"binomial_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; sample_size;  // Numero totale di osservazioni\n  vector[sample_size] x;     // Variabile indipendente\n  array[sample_size] int&lt;lower=0&gt; y;  // Successi per ogni tentativo\n  int&lt;lower=0&gt; n;           // Numero di tentativi per osservazione\n}\nparameters {\n  real beta0;  // Intercetta\n  real beta1;  // Pendenza\n}\ntransformed parameters {\n  vector[sample_size] eta = beta0 + beta1 * x;  // Modello lineare\n  vector[sample_size] p = inv_logit(eta);       // Probabilit√† di successo\n}\nmodel {\n  // Priori\n  beta0 ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n\n  // Likelihood\n  y ~ binomial(n, p);\n}\n\n\n\nCreiamo un dizionario nel formato richiesto per l‚Äôinput a CmdStan:\n\nstan_data = {\n    \"sample_size\": data.shape[0],\n    \"x\": data[\"x\"],\n    \"y\": data[\"y\"],\n    \"n\": 20\n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nPer visualizzare e descrivere la distribuzione a posteriori dei parametri √® possibile utilizzare ArviZ dopo aver fittato il modello con cmdstanpy. ArviZ utilizza un formato di dati chiamato InferenceData, che √® un formato ad alto livello per la memorizzazione di risultati statistici. cmdstanpy restituisce un oggetto CmdStanMCMC, che pu√≤ essere convertito in InferenceData utilizzando la funzione az.from_cmdstanpy.\n\nidata = az.from_cmdstanpy(fit)\n\nOtteniamo un riassunto delle statistiche posteriori:\n\nsummary = az.summary(fit, var_names=([\"beta0\", \"beta1\"]), hdi_prob=0.94)\nprint(summary)\n\n        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nbeta0  0.934  0.174   0.603    1.257      0.003    0.002    4147.0    4717.0   \nbeta1  0.462  0.043   0.381    0.543      0.001    0.000    4247.0    4317.0   \n\n       r_hat  \nbeta0    1.0  \nbeta1    1.0  \n\n\nMostriamo le distribuzioni a posteriori e le tracce di campionamento per i parametri:\n\n_ = az.plot_trace(fit, var_names=([\"beta0\", \"beta1\"]))\n\n\n\n\n\n\n\n\nNel pannello superiore della figura seguente vediamo il modello lineare nella sua forma non trasformata. Come si pu√≤ osservare, questo modello lineare genera valori che escono dall‚Äôintervallo [0, 1], sottolineando quindi la necessit√† di una funzione di collegamento inversa. Questa funzione ha il compito di mappare i valori dal dominio dei numeri reali all‚Äôintervallo [0, 1]. Come abbiamo visto, questa trasformazione √® realizzata mediante la funzione logistica inversa.\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={\"width_ratios\": [2, 1]})\n\n# Data space plot ========================================================\naz.plot_hdi(\n    data[\"x\"],\n    idata.posterior.p,\n    hdi_prob=0.95,\n    fill_kwargs={\"alpha\": 0.25, \"linewidth\": 0},\n    ax=ax[0],\n    color=\"C1\",\n)\n# posterior mean\npost_mean = idata.posterior.p.mean((\"chain\", \"draw\"))\nax[0].plot(data[\"x\"], post_mean, label=\"posterior mean\", color=\"C1\")\n# plot truth\nax[0].plot(data[\"x\"], p_true, \"--\", label=\"true\", color=\"C2\")\n# formatting\nax[0].set(xlabel=\"x\", title=\"Data space\")\nax[0].set_ylabel(\"proportion successes\", color=\"C1\")\nax[0].tick_params(axis=\"y\", labelcolor=\"C1\")\nax[0].legend()\n# instantiate a second axes that shares the same x-axis\nfreq = ax[0].twinx()\nfreq.set_ylabel(\"number of successes\")\nfreq.scatter(data[\"x\"], data[\"y\"], color=\"k\", label=\"data\")\n# get y-axes to line up\ny_buffer = 1\nfreq.set(ylim=[-y_buffer, n + y_buffer])\nax[0].set(ylim=[-(y_buffer / n), 1 + (y_buffer / n)])\nfreq.grid(None)\n# set both y-axis to have 5 ticks\nax[0].set(yticks=np.linspace(0, 20, 5) / n)\nfreq.set(yticks=np.linspace(0, 20, 5))\n\n# Parameter space plot ===================================================\naz.plot_kde(\n    az.extract(idata, var_names=\"beta0\"),\n    az.extract(idata, var_names=\"beta1\"),\n    ax=ax[1],\n)\nax[1].plot(beta0_true, beta1_true, \"C2o\", label=\"true\")\nax[1].set(xlabel=r\"$\\beta_0$\", ylabel=r\"$\\beta_1$\", title=\"Parameter space\")\nax[1].legend(facecolor=\"white\", frameon=True)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61676/1160461270.py:44: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_21_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_21_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "60¬† Regressione binomiale con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html",
    "title": "61¬† Regressione logistica con Stan",
    "section": "",
    "text": "Introduzione\nLa regressione logistica √® un modello additivo utilizzato per dati binari, ossia dati \\(y\\) che assumono valori 0 o 1. Per modellare i dati binari, dobbiamo aggiungere due caratteristiche al modello base \\(y = a + bx\\): una trasformazione non lineare che vincola l‚Äôoutput tra 0 e 1 (a differenza di \\(a + bx\\), che √® illimitato), e un metodo per interpretare i numeri risultanti come probabilit√† che un evento si verifichi.\nIn questo capitolo, approfondiremo la regressione logistica bivariata, un modello statistico che ci consente di analizzare le relazioni tra una variabile di esito binaria e una singola variabile indipendente. Esploreremo il processo di stima dei coefficienti del modello attraverso un approccio bayesiano e forniremo un‚Äôinterpretazione dei risultati ottenuti. Mostreremo come i coefficienti influenzano la probabilit√† di successo della variabile binaria di esito, nonch√© come interpretare il loro segno e ampiezza.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.1 Modello di Regressione Logistica per Variabili Binarie",
    "text": "61.1 Modello di Regressione Logistica per Variabili Binarie\nIl modello di regressione logistica √® utilizzato per analizzare la relazione tra una variabile dipendente dicotomica, che assume i valori di ‚Äúsuccesso‚Äù e ‚Äúfallimento‚Äù, e una o pi√π variabili indipendenti, che possono essere sia quantitative che qualitative. Qui ci concentreremo sul caso di una sola variabile indipendente.\nConsideriamo \\(n\\) osservazioni i.i.d., dove \\(Y_i\\) indica l‚Äôosservazione \\(i\\)-esima della variabile risposta, per \\(i=1, \\dots, n\\). Ogni osservazione √® associata a un vettore di variabili esplicative \\((x_1, \\dots, x_p)\\). La relazione che vogliamo esaminare √® tra la probabilit√† di successo \\(\\pi_i\\) e la variabile esplicativa, espressa dalla formula:\n\\[\nP(Y=1 \\mid X=x_i) = \\pi_i.\n\\]\nIn questo contesto, la variabile dipendente \\(Y\\) segue una distribuzione di Bernoulli, con i seguenti possibili valori:\n\\[\ny_i =\n\\begin{cases}\n    1 & \\text{per un successo (per l'osservazione $i$-esima)},\\\\\n    0 & \\text{per un fallimento}.\n\\end{cases}\n\\]\nLe probabilit√† associate a questi valori sono rispettivamente \\(\\pi\\) per il successo e \\(1-\\pi\\) per il fallimento:\n\\[\n\\begin{aligned}\n    P(Y_i = 1) &= \\pi,\\\\\n    P(Y_i = 0) &= 1-\\pi.\n\\end{aligned}\n\\]\nQuesto modello permette di studiare come le variabili esplicative influenzino la probabilit√† di un evento binario, come il successo o il fallimento.\nLa media condizionata \\(\\mathbb{E}(Y \\mid X=x)\\) in una popolazione pu√≤ essere vista come la proporzione di valori 1 per un dato punteggio \\(x\\) sulla variabile esplicativa, ovvero la probabilit√† condizionata \\(\\pi_i\\) di osservare l‚Äôesito \\(Y = 1\\) in corrispondenza di un certo livello \\(X\\):\n\\[\n\\pi_i \\equiv P(Y = 1 \\mid X = x).\n\\]\nIl valore atteso diventa:\n\\[\n\\mathbb{E}(Y \\mid x) = \\pi_i.\n\\]\nSe \\(X\\) √® una variabile discreta, possiamo calcolare la proporzione di \\(Y=1\\) per ogni valore di \\(X=x\\) nel campione. Queste proporzioni rappresentano una stima non parametrica della funzione di regressione di \\(Y\\) su \\(X\\), e possono essere stimate tramite tecniche di smoothing.\nPer valori bassi della variabile \\(X\\), la proporzione condizionata di valori \\(Y=1\\) sar√† prossima allo 0. Per valori alti di \\(X\\), la proporzione di valori \\(Y=1\\) sar√† prossima a 1. A livelli intermedi di \\(X\\), la curva di regressione non parametrica gradualmente approssima i valori 0 e 1 seguendo un andamento sigmoidale.\nPer illustrare, generiamo dei dati simulati con una variabile dicotomica \\(Y\\) e una variabile discreta \\(X\\) nei quali la probabilit√† che \\(Y=1\\) aumenta con il valore di \\(X\\).\n\n# Simulate data\nnp.random.seed(42)  # For reproducibility\nn = 1000  # Number of samples\nX = np.random.randint(0, 10, size=n)  # Discrete independent variable with levels from 0 to 9\n\n# Define the logistic model\ndef logistic(x, beta0, beta1):\n    return expit(beta0 + beta1 * x)\n\nbeta0 = -2\nbeta1 = 1  # Increase the steepness of the curve\np = logistic(X, beta0, beta1)\n\n# Generate dichotomous outcome variable Y\nY = np.random.binomial(1, p, size=n)\n\n# Compute mean success rate and standard error for each level of X\ndf = pd.DataFrame({'X': X, 'Y': Y})\nmean_success_rate = df.groupby('X')['Y'].mean()\nstandard_error = df.groupby('X')['Y'].sem()\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit a non-parametric smoother (LOESS) and plot the curve\nlowess_smoothed = lowess(mean_success_rate.values, mean_success_rate.index, frac=0.3)\n\nplt.plot(lowess_smoothed[:, 0], lowess_smoothed[:, 1], color='red', label='Non-parametric Smoother')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.2 Modello Lineare nelle Probabilit√†",
    "text": "61.2 Modello Lineare nelle Probabilit√†\nPotremmo pensare di usare una funzione lineare per rappresentare la dipendenza di \\(Y\\) da \\(X\\). Introduciamo un modello lineare con le seguenti assunzioni standard:\n\\[\nY_i = \\alpha + \\beta X_i + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) segue una distribuzione normale con media 0 e varianza 1 (\\(\\varepsilon_i \\sim \\mathcal{N}(0, 1)\\)) e gli errori \\(\\varepsilon_i\\) e \\(\\varepsilon_j\\) sono indipendenti per ogni \\(i \\neq j\\). Il valore atteso di \\(Y_i\\) √® quindi \\(\\mathbb{E}(Y_i) = \\alpha + \\beta X_i\\), portando a:\n\\[\n\\pi_i = \\alpha + \\beta X_i.\n\\]\nQuesto √® noto come modello lineare nelle probabilit√† (linear probability model). Tuttavia, questo approccio presenta una limitazione significativa: non garantisce che i valori predetti di \\(\\pi_i\\) siano confinati nell‚Äôintervallo [0,1], come richiesto per le probabilit√†.\n\n61.2.1 Problemi di Normalit√†\nConsiderando che \\(Y_i\\) pu√≤ assumere solo i valori 0 o 1, i residui \\(\\varepsilon_i\\) risultano anch‚Äôessi dicotomici e quindi non possono seguire una distribuzione normale. Ad esempio, se \\(Y_i=1\\) con probabilit√† \\(\\pi_i\\), il residuo sar√†:\n\\[\n\\varepsilon_i = 1 - \\mathbb{E}(Y_i) = 1 - (\\alpha + \\beta X_i) = 1 - \\pi_i.\n\\]\nSe, invece, \\(Y_i=0\\) con probabilit√† \\(1-\\pi_i\\), il residuo sar√†:\n\\[\n\\varepsilon_i = 0 - \\mathbb{E}(Y_i) = 0 - (\\alpha + \\beta X_i) = - \\pi_i.\n\\]\nTuttavia, se la dimensione del campione √® grande, il teorema del limite centrale pu√≤ mitigare l‚Äôimportanza dell‚Äôassunzione di normalit√† per le stime dei minimi quadrati.\n\n\n61.2.2 Problematiche di Eteroschedasticit√†\nUtilizzare il metodo dei minimi quadrati pu√≤ essere inappropriato in questo contesto poich√© la varianza dei residui non √® costante ma dipende dalla media, e quindi dalla variabile \\(X\\). Assumendo che il modello sia lineare, abbiamo che \\(\\mathbb{E}(\\varepsilon_i)=0\\). Sfruttando le relazioni discusse in precedenza, la varianza dei residui si calcola come:\n\\[\n\\mathbb{V}(\\varepsilon_i) = (1-\\pi_i)\\pi_i.\n\\]\nConsideriamo che la varianza dei residui \\(\\varepsilon_i\\) pu√≤ essere espressa come:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2,\n\\]\ndove \\(\\mathbb{E}(\\varepsilon_i^2)\\) √® il valore atteso del quadrato dei residui e \\(\\mathbb{E}(\\varepsilon_i)^2\\) √® il quadrato del valore atteso dei residui.\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i^2) &= \\mathbb{E}[(Y_i - \\mathbb{E}(Y_i))^2] \\\\\n&= \\mathbb{E}[(Y_i - \\pi_i)^2] \\\\\n&= \\mathbb{E}[(Y_i^2 - 2Y_i\\pi_i + \\pi_i^2)] \\\\\n&= \\mathbb{E}(Y_i^2) - 2\\mathbb{E}(Y_i\\pi_i) + \\mathbb{E}(\\pi_i^2) \\\\\n&= \\mathbb{E}(Y_i) - 2\\mathbb{E}(Y_i\\pi_i) + \\pi_i^2 \\\\\n&= \\pi_i - 2\\pi_i^2 + \\pi_i^2 \\\\\n&= \\pi_i - \\pi_i^2 \\\\\n&= \\pi_i(1 - \\pi_i)\n\\end{align*}\n\\]\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i)^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i)^2 &= (\\mathbb{E}(Y_i - \\mathbb{E}(Y_i)))^2 \\\\\n&= (\\mathbb{E}(Y_i - \\pi_i))^2 \\\\\n&= (0)^2 \\\\\n&= 0\n\\end{align*}\n\\]\nQuindi, sostituendo questi risultati nella formula della varianza dei residui, otteniamo:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2 = \\pi_i(1 - \\pi_i)\n\\]\nQuindi, abbiamo dimostrato che la varianza dei residui nel modello lineare nelle probabilit√† pu√≤ essere espressa come \\((1-\\pi_i)\\pi_i\\).\nDato che \\(\\pi_i\\) dipende da \\(x\\), ci√≤ significa che la varianza non √® costante in funzione di \\(x\\). Questa eteroschedasticit√† dei residui rappresenta un problema per le stime dei minimi quadrati nel modello lineare, specialmente quando le probabilit√† \\(\\pi_i\\) sono vicine a 0 o 1.\n\n\n61.2.3 Linearit√†\nIl maggiore inconveniente connesso all‚Äôadozione del modello lineare nelle probabilit√† deriva dal fatto che la stima della probabilit√† di successo, \\(P(\\hat{Y}_i=1)=\\hat{\\pi}_i\\), non √® necessariamente compresa nell‚Äôintervallo \\((0,1)\\), ma pu√≤ essere sia negativa sia maggiore di 1. Nel caso dell‚Äôesempio in discussione, ci√≤ significa che la retta dei minimi quadrati produce valori attesi \\(\\hat{\\pi}\\) inferiori a 0 per bassi valori della variabile \\(X\\) e valori \\(\\hat{\\pi}\\) superiori a 1 per valori di \\(X\\) alti.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†-vincolato",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†-vincolato",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.3 Modello Lineare nelle Probabilit√† Vincolato",
    "text": "61.3 Modello Lineare nelle Probabilit√† Vincolato\nUna soluzione per mantenere \\(\\pi\\) all‚Äôinterno dell‚Äôintervallo (0, 1) √® la seguente specificazione del modello:\n\\[\n\\pi=\n\\begin{cases}\n  0                           &\\text{se $\\alpha + \\beta X &lt; 0$},\\\\\n  \\alpha + \\beta X           &\\text{se $0 \\leq \\alpha + \\beta X \\leq 1$},\\\\\n  1 &\\text{se $\\alpha + \\beta X &gt; 1$}.\n\\end{cases}\n\\]\nQuesto modello lineare nelle probabilit√† vincolato mostra alcune instabilit√†, soprattutto a causa della sua dipendenza critica dai valori estremi di \\(\\pi\\), dove assume i valori 0 o 1. La linearit√† di \\(\\pi = \\alpha + \\beta X\\) si basa fortemente sui punti in cui si verificano questi estremi. In particolare, la stima di \\(\\pi = 0\\) pu√≤ essere influenzata dal valore minimo di \\(X\\) associato a \\(Y=1\\), mentre la stima di \\(\\pi = 1\\) pu√≤ dipendere dal valore massimo di \\(X\\) per cui \\(Y=0\\). Questi valori estremi tendono a variare significativamente tra diversi campioni e possono diventare pi√π estremi all‚Äôaumentare della dimensione del campione.\nLa presenza di pi√π variabili esplicative (\\(k \\geq 2\\)) complica ulteriormente la stima dei parametri del modello. Inoltre, il modello mostra un cambiamento brusco nella pendenza della curva di regressione ai punti estremi (0 e 1 di \\(\\pi\\)), risultando poco realistico in molte situazioni pratiche. Questo rende il modello meno adatto a descrivere relazioni complesse e gradualmente variabili tra \\(\\pi\\) e \\(X\\).\nUna funzione che modella una relazione pi√π fluida e continua tra \\(\\pi\\) e \\(X\\) sarebbe pi√π realistica e rappresentativa delle dinamiche osservate. Questo motiva la preferenza per modelli alternativi, come il modello di regressione logistica, che tende a fornire una rappresentazione pi√π accurata e realistica delle interazioni tra variabili dicotomiche e esplicative.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#regressione-logistica",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#regressione-logistica",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.4 Regressione Logistica",
    "text": "61.4 Regressione Logistica\nUn metodo efficace per gestire il problema del vincolo sulle probabilit√† √® specificare modelli non direttamente per le probabilit√† stesse, ma per una loro trasformazione che elimina tale vincolo. Invece di definire un modello lineare per la probabilit√† condizionata \\(\\pi_i\\), si pu√≤ specificare un modello lineare per il logaritmo degli odds (logit):\n\\[\n\\eta_i = \\log_e \\frac{\\pi_i}{1-\\pi_i} = \\alpha + \\beta x_i,\n\\]\nQuesto approccio non presenta problemi poich√© il logit \\(\\eta_i\\) √® sempre un numero reale, permettendo di modellare una trasformazione lineare di \\(\\pi_i\\). La trasformazione inversa, che ci permette di ottenere \\(\\pi_i\\) da \\(\\eta_i\\), √® data dalla funzione logistica:\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n\\]\n\n61.4.1 Vantaggi della Regressione Logistica\nLa regressione logistica presenta diversi vantaggi rispetto al modello lineare delle probabilit√†:\n\nVincolo delle Probabilit√†: La trasformazione logistica assicura che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell‚Äôintervallo [0,1].\nInterpretabilit√† degli Odds Ratio: Il coefficiente \\(\\beta\\) pu√≤ essere interpretato come il cambiamento logaritmico negli odds di successo associato a un incremento unitario di \\(X\\). In altre parole, \\(e^\\beta\\) rappresenta il fattore di aumento (o diminuzione) degli odds per un incremento unitario della variabile indipendente.\nGestione dell‚ÄôEteroschedasticit√†: La forma funzionale della varianza del modello di regressione logistica \\(\\pi_i (1 - \\pi_i)\\) √® intrinsecamente considerata nel processo di stima tramite il metodo della massima verosimiglianza.\n\n\n\n61.4.2 Esempio Pratico\nPer illustrare l‚Äôapplicazione della regressione logistica, consideriamo nuovamente i dati simulati precedentemente. Applichiamo il modello di regressione logistica ai dati e tracciamo la curva logistica risultante:\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit logistic regression model and plot logistic curve\nX_design = sm.add_constant(X)\nlogit_model = sm.Logit(Y, X_design).fit()\nx_vals = np.linspace(X.min(), X.max(), 100)\ny_vals = logit_model.predict(sm.add_constant(x_vals))\n\nplt.plot(x_vals, y_vals, color='red', label='Logistic Regression Curve')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()\n\nOptimization terminated successfully.\n         Current function value: 0.289256\n         Iterations 8\n\n\n\n\n\n\n\n\n\nQuesto esempio dimostra come la regressione logistica possa essere utilizzata per modellare una variabile dicotomica in funzione di una variabile indipendente. La curva logistica risultante rappresenta adeguatamente la relazione tra \\(X\\) e la probabilit√† di successo \\(Y\\), garantendo che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell‚Äôintervallo [0,1].\nNelle sezioni seguenti, descriveremo in dettaglio il modello di regressione logistica utilizzato per generare la curva logistica mostrata nella figura precedente. Inizieremo chiarendo i concetti di odds e logit e la loro relazione con le probabilit√†.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#probabilit√†-odds-e-logit",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#probabilit√†-odds-e-logit",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.5 Probabilit√†, Odds e Logit",
    "text": "61.5 Probabilit√†, Odds e Logit\nLa relazione tra probabilit√†, odds e logit √® fondamentale per comprendere la regressione logistica. Questa relazione trasforma l‚Äôintervallo di probabilit√† (0, 1) in uno spettro pi√π ampio, rendendo possibile modellare le probabilit√† con un modello lineare.\nGli odds rappresentano il rapporto tra la probabilit√† di un evento e la probabilit√† del suo complemento. Il logit, invece, √® il logaritmo naturale degli odds, trasformando cos√¨ l‚Äôintervallo di probabilit√† in tutta la linea dei numeri reali. Quando la probabilit√† √® 0.5, gli odds sono 1 e il logit √® 0. Logit negativi indicano probabilit√† inferiori a 0.5, mentre logit positivi indicano probabilit√† superiori a 0.5.\n\n\n\n\n\n\n\n\nProbabilit√† (P)\nOdds (O)\nlogit (L)\n\n\n\n\n0.01\n0.01 / 0.99 = 0.0101\n\\(\\ln(\\frac{0.01}{0.99}) = -4.60\\)\n\n\n0.05\n0.05 / 0.95 = 0.0526\n\\(\\ln(\\frac{0.05}{0.95}) = -2.94\\)\n\n\n0.10\n0.10 / 90 = 0.1111\n\\(\\ln(\\frac{0.10}{0.90}) = -2.20\\)\n\n\n0.30\n0.30 / 0.70 = 0.4286\n\\(\\ln(\\frac{0.30}{0.70}) = -0.85\\)\n\n\n0.50\n0.50 / 0.50 = 1\n\\(\\ln(\\frac{0.50}{0.50}) = 0.00\\)\n\n\n0.70\n0.70 / 0.30 = 2.3333\n\\(\\ln(\\frac{0.70}{0.30}) = 0.85\\)\n\n\n0.90\n0.90 / 0.10 = 9\n\\(\\ln(\\frac{0.90}{0.10}) = 2.20\\)\n\n\n0.95\n0.95 / 0.05 = 19\n\\(\\ln(\\frac{0.95}{0.05}) = 2.94\\)\n\n\n0.99\n0.99 / 0.01 = 99\n\\(\\ln(\\frac{0.99}{0.01}) = 4.60\\)\n\n\n\n\n61.5.1 Trasformazione Inversa del Logit\nLa trasformazione inversa del logit, detta antilogit, consente di trasformare i logit in probabilit√†:\n\\[\n  \\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}}.\n\\]\nGrazie a questa trasformazione, possiamo passare dai logit alle probabilit√†. La trasformazione inversa del logit permette di specificare un modello non lineare per le probabilit√† \\(\\pi_i\\). Tale modello non lineare √® detto logit o modello di regressione logistica:\n\\[\n  \\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n\\]\nQuesto modello garantisce che le probabilit√† \\(\\pi_i\\) siano sempre comprese nell‚Äôintervallo [0,1], risolvendo i problemi del modello lineare nelle probabilit√† e fornendo una rappresentazione accurata della relazione tra la variabile indipendente \\(X\\) e la probabilit√† di successo \\(Y\\).\nLa funzione logistica ben rappresenta l‚Äôandamento sigmoidale delle proporzioni di casi \\(Y=1\\), ovvero \\(\\hat{\\pi}_i = E(Y \\mid x_i)\\) in funzione di livelli crescenti della variabile \\(X\\).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#modelli-lineari-generalizzati",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#modelli-lineari-generalizzati",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.6 Modelli Lineari Generalizzati",
    "text": "61.6 Modelli Lineari Generalizzati\nNel caso di una variabile risposta binaria, il modello classico di regressione lineare si scontra con sfide specifiche:\n\nDistribuzione Binomiale: \\(Y_i\\) segue una distribuzione binomiale (con indice \\(n_i\\), potenzialmente uguale a uno nel caso individuale), rendendo non applicabile l‚Äôipotesi di normalit√†.\nLimiti delle Probabilit√†: Utilizzando una specificazione lineare come \\(\\pi_i= \\beta_0 + \\beta_1 x_i\\), si possono ottenere stime di probabilit√† esterne all‚Äôintervallo 0-1.\nVarianze Non Costanti: La varianza di \\(\\varepsilon\\) varia in base alla specificazione del modello di probabilit√†, seguendo la formula \\(V(\\varepsilon_i)=\\pi_i(1-\\pi_i)\\).\n\nPer superare queste sfide, si utilizzano i Modelli Lineari Generalizzati (GLM). Questi modelli consentono l‚Äôuso di variabili risposta di diversa natura e includono:\n\nRegressione Lineare: Per variabili dipendenti continue e variabili esplicative continue o qualitative.\nRegressione Logistica: Per variabili risposta binarie.\nModello Loglineare di Poisson: Per modellare frequenze in tabelle di contingenza.\n\nI GLM allentano alcune ipotesi fondamentali del modello lineare classico, come linearit√†, normalit√† della componente erratica, e omoschedasticit√† delle osservazioni. Sono strutturati in tre componenti principali:\n\nComponente Aleatoria: Definisce la distribuzione di probabilit√† della variabile risposta \\(Y\\).\nComponente Sistematica: Specifica la relazione lineare tra le variabili esplicative e una trasformazione della variabile risposta.\nFunzione Legame: Trasforma la media attesa \\(\\mathbb{E}(Y)\\) in un formato che possa essere modellato linearmente rispetto alle variabili esplicative. Non √® la variabile risposta stessa ad essere modellizzata direttamente, ma una sua trasformazione, come il logit nel caso della regressione logistica.\n\nEsempi di combinazioni di componenti aleatorie, funzioni di legame e sistematiche nei GLM includono:\n\n\n\n\n\n\n\n\n\nComponente Aleatoria\nFunzione Legame\nComponente Sistematica\nModello\n\n\n\n\nGaussiana\nIdentit√†\nContinua\nRegressione\n\n\nGaussiana\nIdentit√†\nCategoriale\nAnalisi della varianza\n\n\nGaussiana\nIdentit√†\nMista\nAnalisi della covarianza\n\n\nBinomiale\nLogit\nMista\nRegressione logistica\n\n\nPoisson\nLogaritmo\nMista\nModello Loglineare\n\n\n\nQuesta struttura rende i GLM particolarmente flessibili e adatti a una vasta gamma di situazioni statistiche, superando i limiti del modello lineare classico.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-sistematica",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-sistematica",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.7 Componente Sistematica",
    "text": "61.7 Componente Sistematica\nLa componente sistematica mette in relazione un vettore (\\(\\eta_1, \\eta_2, \\dots, \\eta_k\\)) con le variabili esplicative mediante un modello lineare. Sia \\(X_{ij}\\) il valore della \\(j\\)-esima variabile esplicativa (\\(j=1, 2, \\dots, p\\)) per l‚Äô\\(i\\)-esima osservazione (\\(i=1, \\dots, k\\)). Allora\n\\[\n\\eta_i = \\sum_j \\beta_j X_{ij}.\n\\]\nQuesta combinazione lineare di variabili esplicative √® chiamata il predittore lineare. Un \\(X_{ij}=1, \\forall i\\) viene utilizzato per il coefficiente dell‚Äôintercetta del modello (talvolta denotata da \\(\\alpha\\)).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-aleatoria",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-aleatoria",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.8 Componente Aleatoria",
    "text": "61.8 Componente Aleatoria\nLa componente aleatoria del modello suppone l‚Äôesistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Si assume che \\(Y_i\\) abbia una distribuzione binomiale:\n\\[\nY_i \\sim Bin(n_i, \\pi_i)\n\\]\ncon parametri \\(n_i\\) e \\(\\pi_i\\). Per dati individuali (uno per ciascun valore \\(x_i\\)), \\(n_i=1,\n    \\forall i\\).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#funzione-legame",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#funzione-legame",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.9 Funzione Legame",
    "text": "61.9 Funzione Legame\nLa funzione legame \\(g(\\cdot)\\) mette in relazione il valore atteso della variabile risposta \\(Y_i\\) con la componente sistematica \\(\\eta_i\\) del modello. Abbiamo visto che \\(\\mathbb{E}(Y_i)=\\pi_i\\). Che relazione c‚Äô√® tra \\(\\pi_i\\) e il predittore lineare \\(\\eta_i= \\alpha + \\sum_j  \\beta_j X_{ij}\\)? La risposta a questa domanda √® data dalla funzione legame:\n\\[\n\\eta_i = g(\\pi_i) = \\ln{\\frac{\\pi_i}{1-\\pi_i}}\n\\]\nSi noti che la funzione legame non trasforma la variabile risposta \\(Y_i\\) ma bens√¨ il suo valore atteso \\(\\pi_i\\).\nLa funzione legame √® invertibile: anzich√© trasformare il valore atteso nel predittore lineare si pu√≤ trasformare il predittore lineare nel valore atteso \\(\\pi_i\\):\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} =  \\frac{e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}{1+e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}.\n\\]\nSi ottiene cos√¨ un modello non lineare per le probabilit√† \\(\\pi_i\\).\nIn conclusione, la regressione logistica estende il concetto di regressione lineare per modellare le probabilit√† condizionate di esiti Bernoulliani $ Y \\(, adoperando la funzione logistica come collegamento per trasformare relazioni lineari tra predittori (\\) _i = _0 + 1 X{i} $) in probabilit√† nell‚Äôintervallo [0,1]. Questo metodo permette di passare dalla modellazione diretta della probabilit√† $ p $ alla modellazione di una funzione di tale probabilit√† attraverso una relazione lineare, impiegando la funzione logit come funzione di collegamento.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#modelli-lineari-generalizzati-1",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#modelli-lineari-generalizzati-1",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.10 Modelli Lineari Generalizzati",
    "text": "61.10 Modelli Lineari Generalizzati\nNel caso di una variabile risposta binaria, il modello classico di regressione lineare incontra alcune difficolt√† specifiche:\n\nDistribuzione Binomiale: \\(Y_i\\) segue una distribuzione binomiale, rendendo inapplicabile l‚Äôipotesi di normalit√†.\nLimiti delle Probabilit√†: Utilizzando una specificazione lineare come \\(\\pi_i = \\beta_0 + \\beta_1 x_i\\), si possono ottenere stime di probabilit√† al di fuori dell‚Äôintervallo 0-1.\nVarianze Non Costanti: La varianza dei residui \\(\\varepsilon_i\\) varia in base alla specificazione del modello di probabilit√†, seguendo la formula \\(V(\\varepsilon_i) = \\pi_i(1 - \\pi_i)\\).\n\nPer superare queste sfide, si utilizzano i Modelli Lineari Generalizzati (GLM). Questi modelli consentono l‚Äôuso di variabili risposta di diversa natura e includono:\n\nRegressione Lineare: Per variabili dipendenti continue.\nRegressione Logistica: Per variabili risposta binarie.\nModello Loglineare di Poisson: Per modellare frequenze in tabelle di contingenza.\n\nI GLM allentano alcune ipotesi fondamentali del modello lineare classico, come linearit√†, normalit√† della componente erratica e omoschedasticit√† delle osservazioni. Sono strutturati in tre componenti principali:\n\nComponente Aleatoria: Definisce la distribuzione di probabilit√† della variabile risposta \\(Y\\).\nComponente Sistematica: Specifica la relazione lineare tra le variabili esplicative e una trasformazione della variabile risposta.\nFunzione Legame: Trasforma la media attesa \\(\\mathbb{E}(Y)\\) in un formato che possa essere modellato linearmente rispetto alle variabili esplicative. Non √® la variabile risposta stessa ad essere modellata direttamente, ma una sua trasformazione, come il logit nel caso della regressione logistica.\n\n\n61.10.1 Combinazioni di Componenti nei GLM\nEsempi di combinazioni di componenti aleatorie, funzioni di legame e sistematiche nei GLM includono:\n\n\n\n\n\n\n\n\n\nComponente Aleatoria\nFunzione Legame\nComponente Sistematica\nModello\n\n\n\n\nGaussiana\nIdentit√†\nContinua\nRegressione\n\n\nBinomiale\nLogit\nContinua\nRegressione logistica\n\n\nPoisson\nLogaritmo\nContinua\nModello Loglineare\n\n\n\nQuesta struttura rende i GLM particolarmente flessibili e adatti a una vasta gamma di situazioni statistiche, superando i limiti del modello lineare classico.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-sistematica-1",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-sistematica-1",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.11 Componente Sistematica",
    "text": "61.11 Componente Sistematica\nLa componente sistematica mette in relazione un vettore \\((\\eta_1, \\eta_2, \\dots, \\eta_k)\\) con le variabili esplicative mediante un modello lineare. Sia \\(X_{i}\\) il valore della variabile esplicativa continua per l‚Äô\\(i\\)-esima osservazione (\\(i=1, \\dots, k\\)). Allora:\n\\[\n\\eta_i = \\beta_0 + \\beta_1 X_i.\n\\]\nQuesta combinazione lineare di variabili esplicative √® chiamata il predittore lineare.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-aleatoria-1",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#componente-aleatoria-1",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.12 Componente Aleatoria",
    "text": "61.12 Componente Aleatoria\nLa componente aleatoria del modello suppone l‚Äôesistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Si assume che \\(Y_i\\) abbia una distribuzione binomiale:\n\\[\nY_i \\sim \\text{Bin}(1, \\pi_i),\n\\]\ncon parametro \\(\\pi_i\\). Per dati individuali, \\(n_i=1\\) per tutti \\(i\\).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#funzione-legame-1",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#funzione-legame-1",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.13 Funzione Legame",
    "text": "61.13 Funzione Legame\nLa funzione legame \\(g(\\cdot)\\) mette in relazione il valore atteso della variabile risposta \\(Y_i\\) con la componente sistematica \\(\\eta_i\\) del modello. Abbiamo visto che \\(\\mathbb{E}(Y_i) = \\pi_i\\). La relazione tra \\(\\pi_i\\) e il predittore lineare \\(\\eta_i = \\beta_0 + \\beta_1 X_i\\) √® data dalla funzione legame:\n\\[\n\\eta_i = g(\\pi_i) = \\ln{\\frac{\\pi_i}{1 - \\pi_i}}.\n\\]\nSi noti che la funzione legame non trasforma la variabile risposta \\(Y_i\\) ma il suo valore atteso \\(\\pi_i\\).\nLa funzione legame √® invertibile: anzich√© trasformare il valore atteso nel predittore lineare, si pu√≤ trasformare il predittore lineare nel valore atteso \\(\\pi_i\\):\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\beta_0 + \\beta_1 X_i}}{1 + e^{\\beta_0 + \\beta_1 X_i}}.\n\\]\nSi ottiene cos√¨ un modello non lineare per le probabilit√† \\(\\pi_i\\).\n\n61.13.1 Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione\nUn aspetto cruciale per comprendere la relazione tra le variabili predittive e una variabile di risposta binaria √® l‚Äôinterpretazione dei coefficienti del modello.\n\n61.13.1.1 Interpretazione sui Logit\nNella regressione logistica, ogni coefficiente \\(\\beta_j\\) del modello pu√≤ essere interpretato direttamente in termini di log-odds, che sono i logaritmi delle probabilit√† di ottenere un evento con esito positivo (\\(y=1\\)). Quando interpretiamo i coefficienti:\n\nCoefficienti Positivi (\\(\\beta_j &gt; 0\\)): Un coefficiente positivo indica che c‚Äô√® una relazione diretta tra il predittore e l‚Äôaumento dei log-odds di osservare l‚Äôevento di interesse. Questo significa che all‚Äôaumentare del valore del predittore, la probabilit√† dell‚Äôevento di interesse aumenta.\nCoefficienti Negativi (\\(\\beta_j &lt; 0\\)): Al contrario, un coefficiente negativo indica una relazione inversa tra il predittore e la probabilit√† logistica dell‚Äôevento. Con l‚Äôaumentare del predittore, i log-odds e quindi la probabilit√† dell‚Äôevento diminuiscono.\n\n\n\n61.13.1.2 Interpretazione sugli Odds Ratio (OR)\nL‚Äôinterpretazione dei coefficienti nella regressione logistica pu√≤ estendersi agli odds ratio (OR), che forniscono informazioni sulla relazione tra i predittori e la probabilit√† dell‚Äôevento di interesse. Per esempio, consideriamo un modello con un predittore continuo \\(X\\) e un coefficiente \\(\\beta_1 = 0.50\\). Il logaritmo naturale dell‚Äôodds ratio, \\(\\log(OR) = 0.50\\), viene esponenziato per ottenere:\n\\[\nOR = e^{0.50} \\approx 1.65.\n\\]\nQuesto risultato indica che per un‚Äôunit√† di incremento in \\(X\\), l‚Äôodds di sperimentare l‚Äôevento di interesse √® circa 1.65 volte maggiore. In altre parole, l‚Äôincremento di una unit√† nel predittore \\(X\\) aumenta l‚Äôodds di sperimentare l‚Äôevento di interesse di circa il 65%. Viceversa, un coefficiente negativo indicherebbe una diminuzione dell‚Äôodds per un incremento di una unit√† in \\(X\\).\n\n\n61.13.1.3 Interpretazione sulla Scala delle Probabilit√†\nLa regressione logistica consente di interpretare i coefficienti non solo in termini di log-odds, ma anche relativamente alle variazioni di probabilit√†. Consideriamo un modello che predice la probabilit√† di superare un esame basandosi sul numero di ore di studio (\\(X\\)).\nSupponiamo che il coefficiente associato alle ore di studio sia \\(\\beta_1 = 0.5\\). Questo valore indica che ogni ora aggiuntiva di studio incrementa i log-odds di successo nell‚Äôesame. Per comprendere l‚Äôimpatto di un‚Äôora in pi√π di studio sulla probabilit√† di successo, possiamo utilizzare la seguente formula:\n\\[\n\\Delta p = \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot (X_1 + 1))}} - \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot X_1)}}.\n\\]\nQuesta formula calcola la differenza tra la probabilit√† di successo dopo aver aggiunto un‚Äôora di studio e la probabilit√† di successo prima di tale aggiunta. In termini pratici, \\(\\Delta p\\) rappresenta l‚Äôincremento della probabilit√† di superare l‚Äôesame attribuibile a un‚Äôora supplementare di studio. Questa interpretazione √® cruciale per valutare quantitativamente l‚Äôeffetto delle ore di studio sulla probabilit√† di superare l‚Äôesame.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#un-esempio-concreto",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#un-esempio-concreto",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.14 Un esempio concreto",
    "text": "61.14 Un esempio concreto\nConsideriamo nuovamente i dati simulati in precedenza\n\ndf.head()\n\n\n\n\n\n\n\n\n\nX\nY\n\n\n\n\n0\n6\n1\n\n\n1\n3\n1\n\n\n2\n7\n1\n\n\n3\n4\n1\n\n\n4\n6\n1\n\n\n\n\n\n\n\n\nStimeremo ora i coefficienti del modello di regressione logistica usando Stan. Definiamo i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\" : df.shape[0],\n    \"y\" : df[\"Y\"],\n    \"x\" : df[\"X\"] \n}\n\nCompiliamo il modello di regressione logistica e stampiamo lo script Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"logistic_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:47:02 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n12:47:13 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  real alpha;\n  real beta;\n}\nmodel {\n  y ~ bernoulli_logit(alpha + beta * x);\n}\n\n\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n12:47:36 - cmdstanpy - INFO - CmdStan start processing\n12:47:36 - cmdstanpy - INFO - Chain [1] start processing\n12:47:36 - cmdstanpy - INFO - Chain [2] start processing\n12:47:36 - cmdstanpy - INFO - Chain [3] start processing\n12:47:36 - cmdstanpy - INFO - Chain [4] start processing\n12:47:37 - cmdstanpy - INFO - Chain [3] done processing\n12:47:37 - cmdstanpy - INFO - Chain [2] done processing\n12:47:37 - cmdstanpy - INFO - Chain [4] done processing\n12:47:37 - cmdstanpy - INFO - Chain [1] done processing\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(fit)\n\n\n\n\n\n\n\n\nOtteniamo le stime a posteriori dei parametri:\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-1.778\n0.18\n-2.132\n-1.436\n0.004\n0.003\n2261.0\n2634.0\n1.0\n\n\nbeta\n1.004\n0.07\n0.869\n1.144\n0.001\n0.001\n2305.0\n2682.0\n1.0\n\n\n\n\n\n\n\n\nCreiamo un nuovo DataFrame con 100 valori \\(x\\) nell‚Äôintervallo [0, 9]:\n\nnew_data = pd.DataFrame({\n    \"x\": np.linspace(0, 9, 100)\n})\nnew_data\n\n\n\n\n\n\n\n\n\nx\n\n\n\n\n0\n0.000000\n\n\n1\n0.090909\n\n\n2\n0.181818\n\n\n3\n0.272727\n\n\n4\n0.363636\n\n\n...\n...\n\n\n95\n8.636364\n\n\n96\n8.727273\n\n\n97\n8.818182\n\n\n98\n8.909091\n\n\n99\n9.000000\n\n\n\n\n100 rows √ó 1 columns\n\n\n\n\nOtteniamo le medie a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\nalpha = fit.stan_variable('alpha').mean()\nbeta = fit.stan_variable('beta').mean() \nprint(alpha, beta)\n\n-1.7784477 1.003503126\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilit√† √® una funzione lineare di $ x $:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\n\nlogit_p = alpha + new_data['x'] * beta\nlogit_p\n\n0    -1.778448\n1    -1.687220\n2    -1.595993\n3    -1.504765\n4    -1.413537\n        ...   \n95    6.888170\n96    6.979398\n97    7.070625\n98    7.161853\n99    7.253080\nName: x, Length: 100, dtype: float64\n\n\nEsaminiamo graficamente la relazione tra il logit \\(\\log \\left( \\frac{p}{1-p} \\right)\\) e \\(x\\):\n\nnew_data['logit_p'] = logit_p\n\nplt.plot(new_data['x'], new_data['logit_p'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Logit Predetti in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Logit')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilit√† √® una funzione lineare di $ x $. Per ottenere la probabilit√† $ p $ dalla trasformazione del logit, possiamo utilizzare la funzione logistica inversa. Svolgiamo la conversione:\n\nCalcoliamo il logit per ogni valore di $ x $:\n\\[\n\\text{logit}_p = \\alpha + \\beta x\n\\]\nApplichiamo la funzione logistica inversa (antilogit) per ottenere la probabilit√† $ p $:\n\\[\np = \\frac{e^{\\text{logit}_p}}{1 + e^{\\text{logit}_p}} = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}\n\\]\n\nQuesta formula ci permette di trasformare il logit in una probabilit√† compresa tra 0 e 1 per ogni valore di $ x $ nel dataset new_data.\n\nprob = np.exp(logit_p) / (1 + np.exp(logit_p))\n# Aggiungi le probabilit√† calcolate a `new_data`\nnew_data['prob'] = prob\nnew_data.head()\n\n\n\n\n\n\n\n\n\nx\nlogit_p\nprob\n\n\n\n\n0\n0.000000\n-1.778448\n0.144495\n\n\n1\n0.090909\n-1.687220\n0.156142\n\n\n2\n0.181818\n-1.595993\n0.168542\n\n\n3\n0.272727\n-1.504765\n0.181716\n\n\n4\n0.363636\n-1.413537\n0.195677\n\n\n\n\n\n\n\n\n\nplt.plot(new_data['x'], new_data['prob'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Probabilit√† Predetta in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Probabilit√† Predetta')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\n\n61.14.1 Interpretazione dei Coefficienti nella Regressione Logistica\nAbbiamo stimato i coefficienti \\(\\alpha\\) e \\(\\beta\\) dal modello di regressione logistica con i seguenti valori: - \\(\\alpha = -1.7784477\\) - \\(\\beta = 1.003503126\\)\nEsamineremo ora l‚Äôinterpretazione di questi coefficienti sulla scala dei logit, dell‚Äôodds ratio e delle probabilit√†.\n\n61.14.1.1 La regola del dividere per 4\nLa regola del dividere per 4 √® un metodo utile per interpretare i coefficienti della regressione logistica. Dividendo il coefficiente \\(\\beta\\) per 4, si ottiene un‚Äôapprossimazione della massima variazione nella probabilit√† \\(\\Pr(y = 1)\\) per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nLa curva logistica √® pi√π ripida al centro, dove $ + x = 0 $ e quindi $ ^{-1}(+ x) = 0.5 $. In questo punto, la pendenza della curva, ovvero la derivata della funzione logistica, √® massima e raggiunge il valore $ / 4 $.\nPer esempio, nel modello con $ = -1.778 $ e $ = 1.003 $, dividendo \\(\\beta\\) per 4 otteniamo circa 0.25. Questo valore rappresenta l‚Äôaumento massimo, in termini di probabilit√†, che possiamo aspettarci per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nIn sintesi, la regola del dividere per 4 semplifica l‚Äôinterpretazione dei coefficienti della regressione logistica, fornendo un‚Äôindicazione intuitiva di come la variabile indipendente influisce sulla probabilit√† dell‚Äôevento di interesse.\n\n\n61.14.1.2 Scala dei Logit\nNella regressione logistica, la funzione logit rappresenta una relazione lineare tra il logit della probabilit√† di successo e la variabile indipendente \\(X\\):\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\nCon i coefficienti stimati, la funzione logit diventa:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot x\n\\]\n\n\\(\\alpha = -1.7784477\\): Questo √® l‚Äôintercetta del modello, il valore del logit quando \\(x = 0\\). Indica che, quando \\(x\\) √® 0, il logit della probabilit√† di successo √® \\(-1.7784477\\).\n\\(\\beta = 1.003503126\\): Questo √® il coefficiente di \\(x\\) e rappresenta il cambiamento nel logit per ogni incremento unitario in \\(x\\). In altre parole, per ogni incremento di 1 unit√† in \\(x\\), il logit della probabilit√† di successo aumenta di circa \\(1.003503126\\).\n\n\n\n61.14.1.3 Odds Ratio\nL‚Äôodds ratio (OR) misura il cambiamento relativo nelle odds di successo per un incremento unitario in \\(x\\). √à ottenuto esponenziando il coefficiente \\(\\beta\\):\n\\[\n\\text{OR} = e^{\\beta} = e^{1.003503126} \\approx 2.728\n\\]\nUn odds ratio di circa \\(2.728\\) indica che, per ogni incremento unitario in \\(x\\), le odds di successo aumentano di circa \\(172.8\\%\\). In altre parole, l‚Äôodds di successo √® circa \\(2.728\\) volte maggiore per ogni unit√† aggiuntiva di \\(x\\).\n\n\n61.14.1.4 Scala delle Probabilit√†\nPer interpretare l‚Äôeffetto di \\(\\beta\\) sulla scala delle probabilit√†, possiamo considerare come la probabilit√† \\(p\\) cambia in corrispondenza di specifici valori di \\(x\\).\n\nQuando \\(x = 0\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-1.7784477}}{1 + e^{-1.7784477}} \\approx \\frac{0.169} {1 + 0.169} \\approx 0.144\n\\]\nQuindi, la probabilit√† di successo quando \\(x = 0\\) √® circa \\(14.4\\%\\).\n\nPer un incremento unitario in \\(x\\), diciamo \\(x = 1\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot 1 \\approx -0.774944574\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-0.774944574}}{1 + e^{-0.774944574}} \\approx \\frac{0.461} {1 + 0.461} \\approx 0.316\n\\]\nQuindi, la probabilit√† di successo quando \\(x = 1\\) √® circa \\(31.6\\%\\). Tuttavia questo incremento non √® costante per i diversi livelli \\(x\\) e il modo pi√π semplice per mostrare la relazione tra probabilit√† di successo e la variabile \\(X\\) √® quella di generare un grafico come quello che abbimo prodotto in precedenza.\n\n\n\n61.14.2 Riassunto\n\nScala dei Logit: Un incremento unitario in \\(x\\) aumenta il logit della probabilit√† di successo di \\(1.003503126\\).\nOdds Ratio: Le odds di successo aumentano di circa \\(2.728\\) volte per ogni incremento unitario in \\(x\\).\nScala delle Probabilit√†: Quando \\(x\\) passa da 0 a 1, la probabilit√† di successo aumenta da circa \\(14.4\\%\\) a \\(31.6\\%\\). Per la relazione tra ciascun livello \\(x\\) e la probabilit√† di successo √® necessario generare un grafico.\n\nQuesta analisi dimostra come i coefficienti del modello di regressione logistica possono essere interpretati su diverse scale, fornendo un quadro completo della relazione tra la variabile indipendente e la probabilit√† di successo.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.15 Regressione logistica con solo l‚Äôintercetta",
    "text": "61.15 Regressione logistica con solo l‚Äôintercetta\nLa regressione lineare con solo l‚Äôintercetta √® equivalente a stimare una media e la regressione lineare con un singolo predittore binario √® equivalente a stimare una differenza tra medie. Allo stesso modo, la regressione logistica con solo l‚Äôintercetta √® equivalente alla stima di una proporzione.\nEcco un esempio. Un campione casuale di 50 persone viene testato e 10 di loro manifestano una certa caratteristica psicologica. La proporzione √® 0.20 con errore standard $ = 0.06 $. In alternativa, possiamo impostare questo come regressione logistica usando Bambi in Python:\n\n# Dati\ny = [0]*40 + [1]*10\ndf = pd.DataFrame({'y': y})\n\n# Modello\nmodel = bmb.Model('y ~ 1', data=df, family='bernoulli')\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.39\n0.35\n-2.05\n-0.73\n0.01\n0.01\n1524.26\n1636.18\n1.0\n\n\n\n\n\n\n\n\nPossiamo trasformare la previsione nella scala delle probabilit√† e ottenere un risultato che √® essenzialmente lo stesso della stima classica con incertezza di 0.20 ¬± 0.06.\n\n# Given values\nintercept = -1.4\nerror = 0.35\n\n# Calculate logit^-1(-1.41)\np_hat = expit(intercept)\n\n# Calculate logit^-1(-1.41 ¬± 0.36)\nlower_bound = expit(intercept - error)\nupper_bound = expit(intercept + error)\n\nprint(f'p_hat: {p_hat:.3f}, Lower bound: {lower_bound:.3f}, Upper bound: {upper_bound:.3f}')\n\np_hat: 0.198, Lower bound: 0.148, Upper bound: 0.259\n\n\nLe stime classiche e quelle della regressione logistica differiscono leggermente, in parte perch√© Bambi usa una distribuzione a priori e in parte perch√© l‚Äôerrore standard classico √® solo un‚Äôapprossimazione all‚Äôincertezza inferenziale derivante dai dati discreti.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "title": "61¬† Regressione logistica con Stan",
    "section": "61.16 Regressione logistica con un singolo predittore binario",
    "text": "61.16 Regressione logistica con un singolo predittore binario\nLa regressione logistica su una variabile indicatrice √® equivalente a un confronto di proporzioni. Per un esempio semplice, consideriamo i test per una malattia su campioni provenienti da due popolazioni diverse, dove 10 su 50 individui della popolazione A risultano positivi, rispetto a 20 su 60 della popolazione B. La stima classica √® 0.13 con errore standard di 0.08. Ecco come impostare questo caso come regressione logistica utilizzando Bambi in Python:\n\n# Dati\nx = [0] * 50 + [1] * 60\ny = [0] * 40 + [1] * 10 + [0] * 40 + [1] * 20\ndf = pd.DataFrame({'x': x, 'y': y})\n\n# Definire il modello\nmodel = bmb.Model('y ~ x', data=df, family='bernoulli')\n\n# Adattare il modello con un seed\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Visualizzare i risultati del fit\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.41\n0.36\n-2.07\n-0.74\n0.01\n0.01\n2661.46\n2476.84\n1.0\n\n\nx\n0.71\n0.45\n-0.09\n1.60\n0.01\n0.01\n3115.18\n2554.46\n1.0\n\n\n\n\n\n\n\n\nPer ottenere l‚Äôinferenza per la differenza di probabilit√†, confrontiamo le previsioni sulla scala delle probabilit√† per $ x = 0 $ e $ x = 1 $:\n\n# Given values\nintercept = -1.41\nslope = 0.71\n\n# Calculate probabilities for x = 0 and x = 1\nlogit_0 = intercept\nlogit_1 = intercept + slope\n\nprob_0 = expit(logit_0)\nprob_1 = expit(logit_1)\n\n# Calculate the difference in probabilities\ndiff = prob_1 - prob_0\n\nprob_0, prob_1, diff\nprint(f'prob_0: {prob_0:.3f}, prob_1: {prob_1:.3f}, difference: {diff:.3f}')\n\nprob_0: 0.196, prob_1: 0.332, difference: 0.136\n\n\nPer l‚Äôerrore standard possiamo eseguire la seguente simulazione:\n\n# Given values\nintercept_mean = -1.41\nslope_mean = 0.71\nintercept_sd = 0.36\nslope_sd = 0.45\n\n# Number of simulations\nnum_simulations = 10000\n\n# Generate samples of the coefficients\nintercept_samples = np.random.normal(intercept_mean, intercept_sd, num_simulations)\nslope_samples = np.random.normal(slope_mean, slope_sd, num_simulations)\n\n# Calculate the corresponding probabilities\nprob_0_samples = expit(intercept_samples)\nprob_1_samples = expit(intercept_samples + slope_samples)\n\n# Calculate the difference in probabilities for each sample\ndiff_samples = prob_1_samples - prob_0_samples\n\n# Calculate the mean and standard deviation of the differences\nmean_diff = np.mean(diff_samples)\nstd_diff = np.std(diff_samples)\n\nmean_diff, std_diff\nprint(f'difference: {mean_diff:.3f}, standard error: {std_diff:.3f}')\n\ndifference: 0.140, standard error: 0.096\n\n\nSebbene abbiamo ottenuto un errore standard di circa 0.095, che √® leggermente diverso dall‚Äôerrore standard di 0.08 menzionato inizialmente, questo valore riflette l‚Äôincertezza nelle stime dei coefficienti fornite. Potrebbero esserci delle variazioni dovute al metodo di campionamento utilizzato. Tuttavia, questi calcoli dimostrano l‚Äôapproccio corretto per stimare l‚Äôerrore standard utilizzando la simulazione Monte Carlo con le deviazioni standard dei coefficienti stimati. ‚Äã",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_22_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_22_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "61¬† Regressione logistica con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz      : 0.18.0\nseaborn    : 0.13.2\nmatplotlib : 3.9.1\nscipy      : 1.14.0\nstatsmodels: 0.14.2\npandas     : 2.2.2\nnumpy      : 1.26.4\nbambi      : 0.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_23_stan_poisson_regr.html",
    "href": "chapters/chapter_5/05_23_stan_poisson_regr.html",
    "title": "62¬† Regressione di Poisson con Stan",
    "section": "",
    "text": "Introduzione\nIn questo tutorial, approfondiremo l‚Äôutilizzo di CmdStanPy per condurre un‚Äôanalisi di regressione di Poisson. La regressione di Poisson rappresenta una forma di modello lineare generalizzato impiegato nell‚Äôanalisi di regressione per modellare dati di conteggio. Essa si basa sull‚Äôassunzione che la variabile di risposta Y segua una distribuzione di Poisson, con il logaritmo del suo valore atteso modellabile attraverso una combinazione lineare di parametri sconosciuti.\nIn questo capitolo, dopo aver investigato il calcolo della media a posteriori e dell‚Äôincertezza correlata al tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, ci interrogheremo se vi siano evidenze di una tendenza all‚Äôaumento di tale tasso nel corso del tempo.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_23_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "href": "chapters/chapter_5/05_23_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "title": "62¬† Regressione di Poisson con Stan",
    "section": "62.1 Introduzione alla Regressione di Poisson",
    "text": "62.1 Introduzione alla Regressione di Poisson\nUna variabile casuale di Poisson viene utilizzata per modellare conteggi. Poich√© una variabile casuale di Poisson √® un conteggio, il suo valore minimo √® zero e, in teoria, il massimo √® illimitato. L‚Äôobiettivo √® modellare il parametro principale, Œª, il numero medio di occorrenze per unit√† di tempo o spazio, come funzione di una o pi√π covariate.\nIl modello di regressione di Poisson si basa sulla distribuzione di Poisson, una distribuzione probabilistica che descrive eventi con una probabilit√† costante di occorrenza in un intervallo di tempo o spazio definito. La funzione di probabilit√† della distribuzione di Poisson √® definita come:\n\\[ Pr(Y = y) = \\frac{\\mu^y e^{-\\mu}}{y!}, \\]\ndove \\(\\mu\\) rappresenta il numero atteso di eventi nell‚Äôintervallo considerato e \\(y\\) i possibili conteggi di eventi, assumendo valori interi non negativi (0, 1, 2, ‚Ä¶). √à importante notare che in questa distribuzione, il valore atteso \\(\\mu\\) coincide anche con la varianza.\nNel modello di regressione di Poisson, si cerca di collegare il valore atteso di un conteggio, \\(\\mu_i\\), a un insieme di variabili esplicative (come et√†, sesso, sintomi di depressione, ecc.) tramite una relazione funzionale. A differenza dei modelli lineari tradizionali, che possono produrre stime di conteggi negative e quindi non sensate, la regressione di Poisson utilizza una funzione di legame esponenziale per garantire che le stime dei conteggi siano sempre non negative. La relazione √® espressa come segue:\n\\[ \\mu_i = e^{\\beta_0 + \\beta_1 x_i}, \\]\ndove \\(\\beta_0\\) e \\(\\beta_1\\) sono i parametri del modello che devono essere stimati. Questi parametri quantificano l‚Äôeffetto delle variabili esplicative sui conteggi previsti. L‚Äôutilizzo della funzione esponenziale come legame assicura che il valore atteso \\(\\mu_i\\) sia sempre positivo.\nPer costruire il modello di regressione di Poisson:\n\nSi assume che il conteggio degli eventi per un dato livello della variabile esplicativa segua una distribuzione di Poisson, con un parametro di tasso (\\(\\mu_i\\)) specifico per ciascuna osservazione.\nSi definisce un predittore lineare, \\(\\eta_i\\), come una combinazione lineare dei coefficienti del modello (\\(\\beta\\)) e delle variabili esplicative (\\(x_i\\)).\nSi applica la funzione di legame esponenziale per stabilire che il tasso medio di eventi, \\(\\mu_i\\), sia determinato dal predittore lineare, cos√¨ che \\(\\mu_i = e^{\\eta_i} = e^{\\alpha + \\beta x_i}\\).\n\nQuesti passaggi consentono di costruire un modello che non solo predice accuratamente i conteggi, ma offre anche insight significativi sull‚Äôeffetto delle variabili esplicative studiate.\nConsideriamo il seguente esempio. Supponiamo di voler studiare il numero medio di episodi di comportamento aggressivo tra adolescenti in una scuola. In questo caso, il parametro \\(\\lambda_i\\) rappresenta il numero medio di episodi di comportamento aggressivo per lo studente \\(i\\), e ci aspettiamo di mostrare che la variabilit√† tra gli studenti di \\(\\lambda_i\\) pu√≤ essere spiegata da variabili come il livello di stress, il supporto familiare, o la presenza di sintomi depressivi. Utilizzando la regressione di Poisson, possiamo modellare il numero medio di episodi di comportamento aggressivo come:\n\\[ \\lambda_i = e^{\\beta_0 + \\beta_1 \\text{Stress}_i + \\beta_2 \\text{SupportoFamiliare}_i + \\beta_3 \\text{Depressione}_i}, \\]\ndove \\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\) e \\(\\beta_3\\) sono i parametri del modello che quantificano l‚Äôeffetto delle rispettive variabili esplicative sui conteggi di comportamenti aggressivi previsti.\n\n62.1.1 Assunzioni della Regressione di Poisson\nAnalogamente alla regressione lineare, l‚Äôuso della regressione di Poisson per fare inferenze richiede delle assunzioni sul modello:\n\nRisposta di Poisson: La variabile di risposta √® un conteggio per unit√† di tempo o spazio, descritta da una distribuzione di Poisson.\nIndipendenza: Le osservazioni devono essere indipendenti l‚Äôuna dall‚Äôaltra.\nMedia = Varianza: Per definizione, la media di una variabile casuale di Poisson deve essere uguale alla sua varianza.\nLinearit√†: Il logaritmo del tasso medio, log(Œª), deve essere una funzione lineare di \\(x\\).\n\n\n\n62.1.2 Un Esempio con Stan\nPer fare un esempio, consideriamo nuovamente i dati corrispondenti alle sparatorie mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1¬∞ gennaio 2015.\nImportiamo i dati.\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n\n\n\n\n\n\n\nid\ndate\nthreat_type\nflee_status\narmed_with\ncity\ncounty\nstate\nlatitude\nlongitude\nlocation_precision\nname\nage\ngender\nrace\nrace_source\nwas_mental_illness_related\nbody_camera\nagency_ids\n\n\n\n\n0\n3\n2015-01-02\npoint\nnot\ngun\nShelton\nMason\nWA\n47.246826\n-123.121592\nnot_available\nTim Elliot\n53.0\nmale\nA\nnot_available\nTrue\nFalse\n73\n\n\n1\n4\n2015-01-02\npoint\nnot\ngun\nAloha\nWashington\nOR\n45.487421\n-122.891696\nnot_available\nLewis Lee Lembke\n47.0\nmale\nW\nnot_available\nFalse\nFalse\n70\n\n\n2\n5\n2015-01-03\nmove\nnot\nunarmed\nWichita\nSedgwick\nKS\n37.694766\n-97.280554\nnot_available\nJohn Paul Quintero\n23.0\nmale\nH\nnot_available\nFalse\nFalse\n238\n\n\n3\n8\n2015-01-04\npoint\nnot\nreplica\nSan Francisco\nSan Francisco\nCA\n37.762910\n-122.422001\nnot_available\nMatthew Hoffman\n32.0\nmale\nW\nnot_available\nTrue\nFalse\n196\n\n\n4\n9\n2015-01-04\npoint\nnot\nother\nEvans\nWeld\nCO\n40.383937\n-104.692261\nnot_available\nMichael Rodriguez\n39.0\nmale\nH\nnot_available\nFalse\nFalse\n473\n\n\n\n\n\n\n\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1161\n2022    1095\n2021    1050\n2020    1020\n2019     996\n2015     995\n2018     992\n2017     984\n2016     959\nName: count, dtype: int64\n\n\n\nyears = year_counts.index.to_numpy()\nyear = years - 2019\nyear\n\narray([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)\n\n\n\ncounts = year_counts.values\ncounts\n\narray([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959])\n\n\nCreiamo un dizionario con i dati nel formato richiesto per CmdStan.\n\nstan_data = {\n    \"N\" : len(year),\n    \"y\" : counts,\n    \"x\" : year \n}\nstan_data\n\n{'N': 9,\n 'y': array([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959]),\n 'x': array([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)}\n\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:07:11 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/poisson_regression.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/poisson_regression\n12:07:21 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/poisson_regression\n\n\ndata {\n  int&lt;lower=0&gt; N;  // Numero di osservazioni\n  array[N] int&lt;lower=0&gt; y;  // Dati di conteggio (frequenze)\n  vector[N] x;  // Variabile predittore (anni, gi√† standardizzata)\n}\n\nparameters {\n  real alpha;  // Intercetta\n  real beta;  // Pendenza\n}\n\nmodel {\n  // Priors debolmente informativi\n  alpha ~ normal(0, 10);\n  beta ~ normal(0, 10);\n\n  // Modello di regressione di Poisson\n  y ~ poisson_log(alpha + beta * x);\n}\n\ngenerated quantities {\n  array[N] int&lt;lower=0&gt; y_pred = poisson_log_rng(alpha + beta * x);\n}\n\n\n\nQuesto modello Stan specifica una regressione di Poisson per dati di conteggio, dove l‚Äôobiettivo √® modellare il numero di eventi (espressi dalla variabile y) in funzione di una variabile predittiva x (in questo caso, anni standardizzati). Il modello √® strutturato in quattro blocchi principali: data, parameters, model, e generated quantities. Ecco una panoramica dettagliata di ciascuna sezione e il suo ruolo nel contesto del modello:\n\n\n62.1.3 Blocco data\n\nN: Un intero che specifica il numero totale di osservazioni nel dataset. Serve a definire le dimensioni degli array e dei vettori utilizzati nel modello.\ny: Un array di interi che rappresenta i dati di conteggio osservati. Ogni elemento in y corrisponde al numero di eventi registrati in ciascuna delle N unit√† di osservazione.\nx: Un vettore di lunghezza N che contiene i valori della variabile predittiva (ad esempio, anni).\n\n\n\n62.1.4 Blocco parameters\n\nalpha: Un parametro reale che rappresenta l‚Äôintercetta del modello. In un contesto di regressione di Poisson, alpha corrisponde al logaritmo del tasso atteso di eventi quando la variabile predittiva x √® zero.\nbeta: Un parametro reale che rappresenta la pendenza o il coefficiente della variabile predittiva x. Questo parametro indica come il logaritmo del tasso atteso di eventi cambia in risposta a variazioni di una unit√† in x.\n\n\n\n62.1.5 Blocco model\nI priors per alpha e beta sono definiti come distribuzioni normali con media 0 e deviazione standard 10, rappresentando priors debolmente informativi che permettono ai dati di guidare principalmente l‚Äôinferenza sui parametri.\nNella tradizionale regressione di Poisson, il parametro \\(\\mu_i\\) (il tasso medio di eventi per l‚Äôunit√† osservata) √® collegato alle variabili esplicative tramite una funzione esponenziale: \\(\\mu_i = e^{\\eta_i} = e^{\\beta_0 + \\beta_1 x_i}\\). Questa trasformazione assicura che il valore predetto di \\(\\mu_i\\) sia sempre positivo, indipendentemente dai valori assunti dalle variabili esplicative, una necessit√† quando si modellano conteggi che non possono essere negativi.\nLa funzione poisson_log, invece di lavorare direttamente con \\(\\mu_i\\) come nella forma esponenziale \\(e^{\\eta_i}\\), opera sul logaritmo di \\(\\mu_i\\). Questo significa che la funzione specifica il logaritmo del tasso medio di eventi come lineare rispetto ai predittori. In altre parole, anzich√© modellare \\(\\mu_i\\) direttamente e poi trasformarlo, si modella il logaritmo di \\(\\mu_i\\) (che √® \\(\\log(\\mu_i)\\)) come funzione lineare delle variabili esplicative: \\(\\log(\\mu_i) = \\eta_i = \\beta_0 + \\beta_1 x_i\\).\nQuesta specificazione ha diversi vantaggi:\n\nStabilit√† numerica: Lavorare con il logaritmo di \\(\\mu_i\\) pu√≤ ridurre i problemi di stabilit√† numerica che talvolta emergono quando si lavora con valori estremamente grandi o piccoli di \\(\\mu_i\\).\nInterpretazione diretta dei parametri: Poich√© si modella il logaritmo di \\(\\mu_i\\), i coefficienti (come \\(\\beta_1\\)) possono essere interpretati in termini di variazione percentuale. Un incremento di una unit√† in \\(x_i\\) √® associato a un moltiplicatore esponenziale di \\(e^{\\beta_1}\\) sul tasso medio di eventi.\n\nNel codice Stan, la linea y ~ poisson_log(alpha + beta * x); specifica quindi che i dati di conteggio y seguono una distribuzione di Poisson, con il logaritmo del parametro di tasso (\\(\\log(\\mu_i)\\)) modellato come una funzione lineare di x attraverso alpha + beta * x.\n\n\n62.1.6 Blocco generated quantities\n\ny_pred: Un array di interi che contiene valori predetti generati dalla distribuzione di Poisson. Per ogni osservazione, poisson_log_rng genera un valore di conteggio casuale basato sul tasso atteso calcolato come alpha + beta * x. Questi valori predetti possono essere utilizzati per verifiche predittive posteriori o per ottenere una distribuzione predittiva degli eventi.\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo un sommario della distribuzione a posteriori per i parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n6.934\n0.011\n6.915\n6.955\n0.0\n0.0\n2669.0\n2192.0\n1.0\n\n\nbeta\n0.020\n0.004\n0.012\n0.028\n0.0\n0.0\n4415.0\n2727.0\n1.0\n\n\n\n\n\n\n\n\nL‚Äôess_bulk (Effective Sample Size per il bulk dell‚Äôestimatore) e ess_tail (Effective Sample Size per la coda dell‚Äôestimatore) sono relativamente alti per entrambi i parametri, indicando che il campionamento ha fornito una buona approssimazione della distribuzione a posteriori. Inoltre, il valore di r_hat vicino a 1.0 per entrambi i parametri suggerisce che il campionamento ha raggiunto la convergenza, indicando che i risultati sono affidabili.\n\n\n62.1.7 Interpretazione del Parametro alpha\nIl parametro alpha √® una stima del logaritmo del tasso atteso di eventi (frequenze) quando il valore della variabile esplicativa x √® zero, ossia quando si trova nella sua media, che in questo contesto √® stata standardizzata e centrata sull‚Äôanno 2019. Il valore medio di alpha √® 6.934, indicando che il logaritmo naturale del tasso atteso di eventi quando x = 0 √® circa 6.934.\nL‚Äôintervallo di alta densit√† (HDI) del 95% per alpha va da 6.912 a 6.954, fornendo un intervallo di stime plausibili per il valore di alpha con un alto grado di certezza statistica.\nPer interpretare alpha in termini di tasso atteso di eventi, usiamo exp(alpha). Questo trasforma il logaritmo del tasso di eventi nel tasso effettivo. Ad esempio, exp(6.934) d√† il tasso atteso di eventi per l‚Äôanno di riferimento 2019.\n\nnp.exp(6.934)\n\n1026.5921464104808\n\n\n\n\n62.1.8 Interpretazione del Parametro beta\nIl parametro beta rappresenta la variazione logaritmica attesa nelle frequenze per ogni incremento unitario in x (l‚Äôanno, in questo caso). Un valore medio di beta pari a 0.020, con un HDI del 95% che va da 0.012 a 0.028, suggerisce una tendenza positiva: all‚Äôaumentare degli anni, ci si aspetta un incremento nelle frequenze degli eventi.\nUtilizzando il link logaritmico del modello, l‚Äôeffetto di un incremento di un anno su x si traduce in una moltiplicazione del tasso di frequenza per exp(beta). Quindi, un aumento di un anno implica che il tasso di frequenza sar√† moltiplicato per exp(0.020), che √® approssimativamente 1.02, indicando un aumento previsto del 2% nelle frequenze per ogni anno successivo.\n\nnp.exp([0.020, 0.012, 0.028])\n\narray([1.02020134, 1.01207229, 1.02839568])\n\n\n\n\n62.1.9 Calcolo dell‚ÄôAumento Effettivo in Frequenza\nPer calcolare l‚Äôaumento effettivo in frequenza per ogni anno, utilizziamo la seguente formula:\n\\[ \\text{Aumento atteso} = \\exp(\\alpha) \\times (\\exp(\\beta) - 1) \\]\n\nCalcolo del Fattore di Moltiplicazione: exp(beta) √® il fattore di moltiplicazione che descrive come cambia il tasso di frequenza con un incremento di un anno. Con beta = 0.020, exp(beta) √® circa 1.0202.\nDeterminazione dell‚ÄôAumento Attuale in Frequenza: exp(alpha) fornisce il tasso di base delle frequenze quando x = 0. Moltiplicando questo tasso di base per (\\exp(\\beta) - 1), otteniamo l‚Äôaumento effettivo in frequenza per ogni anno aggiuntivo. Sottraendo 1 a exp(beta), otteniamo l‚Äôincremento percentuale dovuto solamente all‚Äôaumento di un anno.\n\nQuesta metodologia fornisce un modo intuitivo e statistico per quantificare come le variabili nel tempo influenzano la frequenza degli eventi, permettendo di fare previsioni basate su modelli storici e tendenze osservate.\n\n# Parametri del modello\nalpha_mean = 6.934\nbeta_mean = 0.020\n\n# Calcolo del tasso di frequenza base per l'anno centrato (exp(alpha))\ntasso_base = np.exp(alpha_mean)\n\n# Calcolo del fattore di moltiplicazione per l'aumento (exp(beta))\nfattore_moltiplicazione = np.exp(beta_mean)\n\n# Aumento atteso in frequenza per un anno\naumento_atteso = tasso_base * (fattore_moltiplicazione - 1)\naumento_atteso\n\n20.738537018435174\n\n\nBasandosi sul modello di regressione di Poisson, si stima un incremento medio di circa 20.74 nel numero di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno aggiuntivo. In altre parole, il modello prevede che, anno dopo anno, il numero di tali incidenti potrebbe crescere di circa 21 casi. Questa previsione riflette una dinamica esponenziale tra il passare degli anni e l‚Äôaumento della frequenza assoluta di sparatorie fatali, come evidenziato dai dati analizzati.\n\n\n62.1.10 Posterior-Predictive Check\nEsaminiamo il posterior-predictive check per il modello esaminato:\n\ny_observed = stan_data[\"y\"]\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_pred',\n    observed_data={'y': y_observed}\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_pred'}, kind='cumulative')",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_23_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_23_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "62¬† Regressione di Poisson con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.14.0\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\npandas    : 2.2.2\narviz     : 0.18.0\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html",
    "title": "63¬† Modelli misti con Stan",
    "section": "",
    "text": "Introduzione\nIl presente capitolo fornisce un riassunto della trattazione dei modelli misti fornita da Sorensen e Vasishth (2015), a cui si rimanda per gli approfondimenti.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html#domanda-della-ricerca",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html#domanda-della-ricerca",
    "title": "63¬† Modelli misti con Stan",
    "section": "63.1 Domanda della Ricerca",
    "text": "63.1 Domanda della Ricerca\nLa questione scientifica riguarda la comprensione delle frasi nel caso di proposizioni relative di soggetto e di oggetto. Una proposizione relativa di soggetto √® una frase in cui un sostantivo (ad esempio, ‚Äúsenatore‚Äù) viene modificato da una proposizione relativa (ad esempio, ‚Äúche ha interrogato il giornalista‚Äù), e il sostantivo modificato √® il soggetto grammaticale della proposizione relativa. In una proposizione relativa di oggetto, il sostantivo modificato dalla proposizione relativa √® l‚Äôoggetto grammaticale della proposizione (per esempio, ‚ÄúIl senatore che il giornalista ha interrogato si √® dimesso‚Äù). In entrambi i casi, il sostantivo modificato (‚Äúsenatore‚Äù) √® chiamato il sostantivo principale.\nUn risultato comune per l‚Äôinglese √® che le proposizioni relative di soggetto sono pi√π facili da elaborare rispetto a quelle di oggetto. Le lingue naturali in generale includono proposizioni relative, e fino a poco tempo fa il vantaggio delle proposizioni di soggetto √® stato considerato valido a livello cross-linguistico. Tuttavia, le proposizioni relative in cinese rappresentano un interessante controesempio a questa generalizzazione; ricerche recenti condotte da Hsiao e Gibson (2003) hanno suggerito che in cinese, le proposizioni relative di oggetto sono pi√π facili da elaborare rispetto a quelle di soggetto in un punto specifico della frase (il sostantivo principale della proposizione relativa). Viene presentata un‚Äôanalisi di un insieme di dati successivamente pubblicata (Gibson e Wu 2013) che valuta questa affermazione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html#i-dati",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html#i-dati",
    "title": "63¬† Modelli misti con Stan",
    "section": "63.2 I Dati",
    "text": "63.2 I Dati\nLa variabile dipendente dell‚Äôesperimento di Gibson e Wu (2013) era il tempo di lettura (rt) in millisecondi del sostantivo principale della proposizione relativa. Questo √® stato registrato in due condizioni (proposizione relativa di soggetto e proposizione relativa di oggetto), con 37 soggetti e 15 item, presentati in un disegno standard a quadrato latino. Originariamente c‚Äôerano 16 item, ma uno √® stato rimosso, risultando in 37 √ó 15 = 555 punti dati. Tuttavia, otto punti dati da un soggetto (id 27) erano mancanti. Di conseguenza, abbiamo un totale di 555 - 8 = 547 punti dati. La condizione (object relative / subject relative) √® codificata dalla variabile so.\n\ngibson_data = pd.read_csv(\"../../data/gibson_wu_2013.csv\")\ngibson_data.head()\n\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n0\n1\n13\nobj-ext\n8\nÁî∑‰∫∫\n-\n1561\nheadnoun\nobject relative\n1\n\n\n1\n1\n6\nsubj-ext\n8\nÂ•≥Â≠©\n-\n959\nheadnoun\nsubject relative\n-1\n\n\n2\n1\n5\nobj-ext\n8\nËΩéËªä\n-\n582\nheadnoun\nobject relative\n1\n\n\n3\n1\n9\nobj-ext\n8\nÊé¢Âì°\n-\n294\nheadnoun\nobject relative\n1\n\n\n4\n1\n14\nsubj-ext\n8\nÁ©∫ÊúçÂì°\n-\n438\nheadnoun\nsubject relative\n-1\n\n\n\n\n\n\n\n\n\ngibson_data.tail()\n\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n542\n9\n15\nobj-ext\n8\nÊºîÂì°\n-\n406\nheadnoun\nobject relative\n1\n\n\n543\n9\n16\nsubj-ext\n8\nË®òËÄÖ\n-\n342\nheadnoun\nsubject relative\n-1\n\n\n544\n9\n7\nobj-ext\n8\nÁãó\n-\n478\nheadnoun\nobject relative\n1\n\n\n545\n9\n8\nsubj-ext\n8\nÊ•≠È§òÈÅ∏Êâã\n-\n510\nheadnoun\nsubject relative\n-1\n\n\n546\n9\n11\nobj-ext\n8\nÁêÉÂì°\n-\n350\nheadnoun\nobject relative\n1\n\n\n\n\n\n\n\n\n\ngibson_data.shape\n\n(547, 10)\n\n\n\ngibson_data[\"RT\"] = gibson_data[\"rt\"] / 1000\n\n\n_ = sns.kdeplot(data=gibson_data, x='RT', hue='so', fill=True, common_norm=False, alpha=0.5)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html#modello-ad-effetti-fissi",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html#modello-ad-effetti-fissi",
    "title": "63¬† Modelli misti con Stan",
    "section": "63.3 Modello ad effetti fissi",
    "text": "63.3 Modello ad effetti fissi\nIniziamo facendo l‚Äôassunzione che la variabile dipendente del tempo di lettura (rt) sul sostantivo principale sia distribuita approssimativamente in modo log-normale (Rouder, 2005). Questo presuppone che il logaritmo di rt sia distribuito approssimativamente in modo normale. Il logaritmo dei tempi di lettura, logrt, ha una media Œ≤0 sconosciuta. La media della distribuzione log-normale di rt √® la somma di Œ≤0 e di uno scarto Œ≤1so il cui valore dipende dal predittore categoriale so, che assume il valore di -1 quando rt proviene dalla condizione di proposizione relativa di soggetto, e 1 quando rt proviene dalla condizione di proposizione relativa di oggetto.\nIl modello del logaritmo dei tempi di lettura √® dunque il seguente:\n\\[\nlogrt_i = \\beta_0 + \\beta_1 so_i + \\epsilon_i.\n\\]\nQuesto √® un modello a effetti fissi. L‚Äôindice i rappresenta la i-esima riga nel frame dati (in questo caso, i ‚àà {1, . . . , 547}); il termine Œµi rappresenta l‚Äôerrore nella i-esima riga. Con la variabile so codificata come indicato sopra indicato, Œ≤0 rappresenta la media di log rt, indipendentemente dal tipo di proposizione relativa. Il parametro Œ≤1 √® lo scarto rispetto a Œ≤0 in modo che la media di log rt sia Œ≤0 + 1Œ≤1 quando log rt proviene dalla condizione di proposizione relativa di oggetto, e Œ≤0 - 1Œ≤1 quando log rt proviene dalla condizione di proposizione relativa di soggetto. In tali circostanze, 2Œ≤1 corrisponde alla differenza tra le medie nelle condizioni di proposizione relativa di oggetto e di soggetto. Insieme, Œ≤0 e Œ≤1 costituiscono le componenti del modello che caratterizzano l‚Äôeffetto della manipolazione sperimentale (il tipo di proposizione relativa) sulla variabile dipendente rt. Questo √® un modello ad effetti fissi perch√© i parametri Œ≤0 e Œ≤1 non variano da soggetto a soggetto o da item a item.\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"fixed_effects.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:32:16 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/fixed_effects.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/fixed_effects\n12:32:29 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/fixed_effects\n\n\ndata {\n  int&lt;lower=1&gt; N;                // Number of data points\n  vector[N] rt;                  // Reading time\n  vector[N] so;                  // Predictor, constrained between -1 and 1\n}\nparameters {\n  vector[2] beta;                // Intercept and slope\n  real&lt;lower=0&gt; sigma_e;         // Error standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Define the model for mu using vectorized operations\n  mu = beta[1] + beta[2] * so;\n\n  // Vectorized likelihood\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\nCreiamo un dizionario che include i dati nel formato atteso dal precedente codice Stan.\n\nstan_data = {\n    \"N\" : gibson_data.shape[0],\n    \"rt\" : gibson_data[\"RT\"],\n    \"so\" : gibson_data[\"so\"] \n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo le tracce.\n\n_ = az.plot_trace(fit, var_names=([\"beta\", \"sigma_e\"]), compact=False)\n\n\n\n\n\n\n\n\nEsaminiamo le medie a posteriori e gli intervalli di credibilit√† dei parametri.\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.03\n-0.90\n-0.80\n0.0\n0.0\n3535.32\n2985.81\n1.0\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.01\n0.0\n0.0\n4901.41\n3327.06\n1.0\n\n\nsigma_e\n0.60\n0.02\n0.56\n0.63\n0.0\n0.0\n4436.39\n2709.09\n1.0\n\n\n\n\n\n\n\n\nL‚Äôanalisi della distribuzione di Œ≤1 indica che approssimativamente il 94% della densit√† di probabilit√† a posteriori √® al di sotto dello zero, suggerendo che, in cinese, ci sia qualche evidenza che le proposizioni relative oggetto siano pi√π facili da elaborare rispetto alle proposizioni relative soggetto, dati i dati di Gibson e Wu (2013). Tuttavia, poich√© l‚Äôintervallo di credibilit√† al 95% include lo zero, potremmo essere riluttanti a trarre questa conclusione, se vogliamo adottare un approccio ‚Äúquasi frequentista‚Äù di test di ipotesi.\nTuttavia, √® importante notare che il modello ad effetti fissi presentato qui non √® comunque appropriato per i dati attuali. L‚Äôassunzione di indipendenza degli errori viene violata, perch√© abbiamo misure ripetute per ciascun soggetto e per ciascun item. I modelli lineari misti estendono il modello lineare per risolvere precisamente questo problema.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html#modello-ad-intercette-casuali",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html#modello-ad-intercette-casuali",
    "title": "63¬† Modelli misti con Stan",
    "section": "63.4 Modello ad Intercette Casuali",
    "text": "63.4 Modello ad Intercette Casuali\nIl modello degli effetti fissi non √® adatto per i dati di Gibson e Wu (2013) poich√© non tiene conto del fatto che abbiamo misurazioni multiple per ciascun soggetto e item. Come gi√† accennato, queste misurazioni multiple portano a una violazione dell‚Äôassunzione di indipendenza degli errori. Inoltre, i coefficienti degli effetti fissi Œ≤0 e Œ≤1 rappresentano medie su tutti i soggetti e gli item, ignorando il fatto che alcuni soggetti saranno pi√π veloci e alcuni pi√π lenti della media; allo stesso modo, alcuni item saranno letti pi√π rapidamente della media e altri pi√π lentamente.\nNei modelli lineari misti, prendiamo in considerazione questa variabilit√† per soggetto e per item aggiungendo i termini di correzione u0j e w0k, che aggiustano Œ≤0 per il soggetto j e l‚Äôitem k. Questo scompone parzialmente Œµi in una somma di termini u0j e w0k, che sono gli aggiustamenti dell‚Äôintercetta Œ≤0 per il soggetto j e l‚Äôitem k associato a rt_i. Se il soggetto j √® pi√π lento della media di tutti i soggetti, uj sar√† un numero positivo, e se l‚Äôitem k viene letto pi√π velocemente della durata media di tutti gli item, allora wk sar√† un numero negativo. Ogni soggetto j ha il proprio aggiustamento u0j, e ogni item ha il proprio aggiustamento w0k. Questi aggiustamenti u0j e w0k sono chiamati intercette casuali (random intercepts) da Pinheiro e Bates (2000) e intercette variabili (varying intercepts) da Gelman e Hill (2007), e aggiustando Œ≤0 con questi termini miglioriamo la nostra capacit√† di tener conto della variabilit√† per i soggetti e per gli item.\nIl modello statistico ad intercette casuali assume che questi aggiustamenti sono distribuiti normalmente intorno allo zero con deviazione standard sconosciuta:\n\\[\nu_0 \\sim N(0, \\sigma_u),\n\\]\n\\[\nw_0 ‚àº N(0, \\sigma_w).\n\\]\nAvendo specificato il modello in questo modo, ci sono tre fonti di varianza: la deviazione standard degli errori œÉe, la deviazione standard delle intercette casuali per i soggetti, œÉu, e la deviazione standard delle intercette casuali per gli item, œÉw. Ci riferiamo a questi valori come alle componenti della varianza.\nEsprimiamo ora il logaritmo del tempo di lettura, prodotto dai soggetti j ‚àà {1, . . . , 37} che leggono gli item k ‚àà {1,‚Ä¶, 15}, nelle condizioni i ‚àà {1, 2} (1 si riferisce alle proposizioni soggetto, 2 alle proposizioni oggetto), come la seguente somma.\n\\[\n\\log rt_{ijk} = \\beta_0 + \\beta_{1i} + u_{0j} + w_{0k} + \\varepsilon_{ijk}.\n\\]\nNotiamo che stiamo utilizzando un modo leggermente diverso per descrivere il modello, rispetto al modello degli effetti fissi. Stiamo utilizzando indici per soggetto, item e condizione per identificare ciascuna riga del data frame. Inoltre, anzich√© scrivere \\(\\beta_1 so_i\\), indicizziamo direttamente Œ≤1 in funzione della condizione i (essendo so \\(\\in \\{-1, 1\\}\\)).\nQuesto √® un modello √® un modello ad effetti misti, e pi√π specificamente un modello ad intercette casuali. Il coefficiente \\(\\beta_{1i}\\) √® quello di maggior interesse; avr√† un valore medio ‚àíŒ≤1 per le proposizioni soggetto e Œ≤1 per le proposizioni oggetto a causa della codifica del contrasto. Quindi, se la nostra media a posteriori per Œ≤1 √® negativa, ci√≤ suggerirebbe che le proposizioni oggetto vengono lette pi√π velocemente delle proposizioni soggetto.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_intercepts.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:33:49 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n12:34:01 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  vector[J] u;                     // Subject intercepts\n  vector[K] w;                     // Item intercepts\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  real&lt;lower=0&gt; sigma_u;           // Subject standard deviation\n  real&lt;lower=0&gt; sigma_w;           // Item standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Priors\n  beta ~ normal(0, 5);             // Assuming a weakly informative prior for beta\n  u ~ normal(0, sigma_u);\n  w ~ normal(0, sigma_w);\n  sigma_e ~ exponential(1);\n  sigma_u ~ exponential(1);\n  sigma_w ~ exponential(1);\n\n  // Likelihood\n  mu = beta[1] + beta[2] * so + u[subj] + w[item];  // Vectorized computation of mu\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\n\nstan_data = {\n    'subj': pd.factorize(gibson_data['subj'])[0] + 1,\n    'item': pd.factorize(gibson_data['item'])[0] + 1,\n    'rt': gibson_data['RT'].values,\n    'so': gibson_data['so'].values,\n    'N': len(gibson_data),\n    'J': gibson_data['subj'].nunique(),\n    'K': gibson_data['item'].nunique()\n}\n\n\nfit = model.sample(data=stan_data)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.97\n-0.70\n0.0\n0.0\n1101.73\n1576.57\n1.0\n\n\nbeta[1]\n-0.04\n0.02\n-0.08\n0.01\n0.0\n0.0\n9851.81\n3141.84\n1.0\n\n\nsigma_e\n0.52\n0.02\n0.49\n0.55\n0.0\n0.0\n7247.72\n2689.88\n1.0\n\n\nsigma_u\n0.25\n0.04\n0.17\n0.33\n0.0\n0.0\n3714.95\n2902.11\n1.0\n\n\nsigma_w\n0.20\n0.05\n0.11\n0.30\n0.0\n0.0\n3978.74\n2983.07\n1.0\n\n\n\n\n\n\n\n\nSi noti che rispetto al Modello ad effetti fissi, la stima di œÉe √® pi√π piccola; questo perch√© ora vengono stimate due componenti di varianza aggiuntive. Si noti inoltre che l‚Äôintervallo di credibilit√† al 95% per la stima di Œ≤1 include lo zero; quindi, c‚Äô√® ancora qualche evidenza che le proposizioni oggetto siano pi√π facili delle proposizioni soggetto, ma non possiamo escludere la possibilit√† che non ci sia una differenza credibile nei tempi di lettura tra i due tipi di proposizioni relative.\nIl presente modello con intercette casuali assume che l‚Äôeffetto della variabile so sia lo stesso per ciascun soggetto.Ma questo non √® necessariamente vero. Per consentire al modello di tenere conto che l‚Äôeffetto della variabile so possa variare tra i soggetti, dobbiamo estendere il presente modello e trasformarlo in un modello che include sia intercette sia pendenze casuali.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "title": "63¬† Modelli misti con Stan",
    "section": "63.5 Random Intercepts, Random Slopes Model",
    "text": "63.5 Random Intercepts, Random Slopes Model\nPer esprimere la struttura descritta sopra nel modello lineare misto, dobbiamo specificare le pendenze casuali. Il primo cambiamento consiste nel permettere che la dimensione dell‚Äôeffetto per so varii per soggetto e per item. Consentiamo che la dimensione dell‚Äôeffetto vari per soggetto e per item includendo nel modello pendenze variabili per soggetto e per item, che costituiscono degli scarti rispetto alla pendenza fissa Œ≤1, allo stesso modo in cui le intercette variabili per soggetto e per item aggiustano l‚Äôintercetta fissa Œ≤0. Questo aggiustamento della pendenza per soggetto e per item √® espresso aggiustando Œ≤1 tramite due termini u1j e w1k. Questi termini rappresentano le pendenze casuali. Aggiungendo al modello tali termini aggiuntivi possiamo rendere conto del fatto che l‚Äôeffetto del tipo di proposizione relativa varia per soggetto j e per item k.\nEsprimiamo il logaritmo del tempo di lettura, prodotto dal soggetto j che legge l‚Äôitem k, come la seguente somma.\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_{1i} + u_{1ij} + w_{1ik} + \\epsilon_{ijk},\n\\]\ndove il pedice \\(i\\) indica le condizioni. Questo √® un modello di intercette variabili e pendenze variabili.\nIl modello √® specificato in linguaggio Stan come indicato nel file random_slopes.stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_slopes.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:35:00 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n12:35:11 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  matrix[2,J] u;                   // Subject intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_u;      // Subject standard deviations\n  matrix[2,K] w;                   // Item intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_w;      // Item standard deviations\n}\nmodel {\n  // Priors\n  for (j in 1:J) {\n    u[1,j] ~ normal(0, sigma_u[1]); // Prior for subject intercepts\n    u[2,j] ~ normal(0, sigma_u[2]); // Prior for subject slopes\n  }\n  \n  for (k in 1:K) {\n    w[1,k] ~ normal(0, sigma_w[1]); // Prior for item intercepts\n    w[2,k] ~ normal(0, sigma_w[2]); // Prior for item slopes\n  }\n  \n  // Likelihood\n  for (i in 1:N) {\n    real mu = beta[1] + u[1, subj[i]] + w[1, item[i]]\n              + (beta[2] + u[2, subj[i]] + w[2, item[i]]) * so[i];\n    rt[i] ~ lognormal(mu, sigma_e);\n  }\n}\n\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    iter_sampling = 2000,\n    iter_warmup = 1000,\n)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.98\n-0.71\n0.00\n0.0\n706.84\n302.85\n1.01\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.02\n0.00\n0.0\n1982.52\n4756.68\n1.00\n\n\nsigma_e\n0.52\n0.02\n0.48\n0.55\n0.00\n0.0\n2288.99\n5672.93\n1.00\n\n\nsigma_u[0]\n0.25\n0.04\n0.18\n0.34\n0.00\n0.0\n712.02\n275.18\n1.01\n\n\nsigma_u[1]\n0.06\n0.04\n0.01\n0.12\n0.01\n0.0\n39.10\n29.54\n1.09\n\n\nsigma_w[0]\n0.20\n0.05\n0.11\n0.30\n0.00\n0.0\n4099.46\n5332.27\n1.00\n\n\nsigma_w[1]\n0.04\n0.03\n0.00\n0.11\n0.00\n0.0\n114.76\n68.32\n1.03\n\n\n\n\n\n\n\n\nAnche in questo caso, Sorensen e Vasishth (2015) commentano che l‚Äôintervallo di credibilit√† al 95% per \\(\\beta_1\\) include lo zero.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "title": "63¬† Modelli misti con Stan",
    "section": "63.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate",
    "text": "63.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate\nSorensen e Vasishth (2015), nell‚Äôapprofondire l‚Äôanalisi dei dati presentati da Gibson e Wu (2013), propongono un avanzamento metodologico nel modello preso in considerazione, introducendo un modello a effetti misti che incorpora intercette e pendenze casuali correlate. La logica dietro questo approccio consiste nell‚Äôesaminare la possibilit√† che vi sia una relazione tra la velocit√† di lettura dei soggetti (espressa attraverso intercette casuali) e la loro reazione alle diverse tipologie di proposizioni (oggetto vs.¬†soggetto), ipotizzando che soggetti con una velocit√† di lettura superiore alla media possano esperire un rallentamento maggiore nel leggere proposizioni oggetto rispetto alle proposizioni soggetto, e viceversa. Questa ipotesi suggerisce l‚Äôesistenza di correlazioni tra le intercette casuali (che rappresentano variazioni individuali nella velocit√† di base di lettura) e le pendenze casuali (che rappresentano la variazione nella risposta al tipo di proposizione).\nPer integrare questa struttura nel modello lineare misto (LMM), √® essenziale modellare la correlazione tra intercette casuali e pendenze casuali. La formula del modello, la quale rimane inalterata rispetto alla versione precedente, √® rappresentata come segue:\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_1 + u_{1ij} + w_{1ik} + \\epsilon_{ijk}.\n\\]\nL‚Äôintroduzione di correlazioni tra intercette e pendenze casuali trasforma il modello in un approccio di intercette e pendenze correlate, richiedendo la definizione di una matrice di varianza-covarianza per gli effetti casuali. Questo implica la necessit√† di stabilire una relazione di covarianza tra le intercette casuali (per soggetto e per item) e le pendenze casuali (per soggetto e per item), suggerendo che le pendenze per soggetto (u1) potrebbero correlare con le intercette per soggetto (u0), cos√¨ come le pendenze per item (w1) potrebbero correlare con le intercette per item (w0). Questo approccio offre una visione pi√π dettagliata e accurata della dinamica tra velocit√† di lettura individuale e reazione alle differenti strutture sintattiche, arricchendo significativamente l‚Äôanalisi statistica dei dati comportamentali.\nNel contesto di questo insegnamento, non approfondiremo la formulazione del modello Stan che include la correlazione tra pendenze e intercette, data la sua complessit√† tecnica. Tuttavia, √® importante sottolineare che √® possibile ottenere risultati analoghi con un approccio pi√π accessibile utilizzando il pacchetto Bambi per Python. Questo strumento consente di specificare modelli statistici in maniera intuitiva e diretta. Per esempio, per incorporare la correlazione tra pendenze e intercette nel nostro modello, possiamo utilizzare la seguente sintassi con Bambi:\nmodel = bmb.Model(\"rt ~ so + (so | subject) + (so | item)\", data)\nQuesta espressione crea un modello in cui rt (il tempo di risposta) √® modellato come una funzione del tipo di proposizione so, con pendenze e intercette casuali correlate sia per subject che per item. L‚Äôuso di (so | subject) e (so | item) permette di modellare specificamente le variazioni nelle risposte attribuibili a differenze individuali tra i soggetti e caratteristiche uniche degli item, rispettivamente. Questa sintassi semplifica notevolmente l‚Äôimplementazione di modelli complessi, rendendo l‚Äôanalisi accessibile anche a chi possiede una conoscenza di base della statistica bayesiana e della modellazione statistica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_24_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_24_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "63¬† Modelli misti con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGibson, Edward, e H-H Iris Wu. 2013. ¬´Processing Chinese relative clauses in context¬ª. Language and Cognitive Processes 28 (1-2): 125‚Äì55.\n\n\nSorensen, Tanner, e Shravan Vasishth. 2015. ¬´Bayesian linear mixed models using Stan: A tutorial for psychologists, linguists, and cognitive scientists¬ª. arXiv preprint arXiv:1506.06201.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_30_entropy.html",
    "href": "chapters/chapter_5/05_30_entropy.html",
    "title": "64¬† Entropia",
    "section": "",
    "text": "Introduzione\nNel contesto della statistica bayesiana, √® cruciale confrontare diversi modelli predittivi per identificare quello che meglio si adatta ai dati disponibili. Una metrica essenziale in questo confronto √® la Expected Log Predictive Density (ELPD), che misura l‚Äôaccuratezza con cui un modello pu√≤ prevedere nuovi dati. Non essendo possibile calcolare direttamente l‚ÄôELPD, a causa della necessit√† di conoscere il meccanismo generatore dei dati \\(p_t(y)\\), ci affidiamo a una stima approssimativa fornita dalla distribuzione predittiva a posteriori del modello, \\(p(\\tilde{y} | y)\\).\nPer ottenere una stima pi√π accurata della capacit√† di generalizzazione di un modello su futuri set di dati, utilizziamo metodi di stima dell‚ÄôELPD basati sulla validazione incrociata. Questa tecnica consiste nell‚Äôaddestrare il modello su un sottoinsieme di dati e testarlo su un altro, isolando cos√¨ le prestazioni del modello dalle variazioni casuali presenti nei dati. Il risultato di questo processo √® l‚Äôindice di Leave-One-Out Cross-Validation (LOO-CV), fondamentale per comparare diversi modelli.\nLa differenza nei valori di Leave-One-Out Cross-Validation (LOO-CV) tra due modelli, accompagnata dal calcolo dell‚Äôerrore standard associato a questa differenza, ci consente di determinare se esiste una differenza robusta nelle prestazioni tra i due modelli. Se il rapporto tra questa differenza di LOO-CV e il relativo errore standard supera il valore di 2, possiamo concludere che i modelli mostrano differenze sostanziali. Questo indica che le variazioni osservate non sono casuali ma riflettono una superiorit√† effettiva di un modello rispetto all‚Äôaltro.\nIn questo capitolo, esploreremo il concetto di entropia, essenziale per quantificare l‚Äôincertezza nelle distribuzioni di probabilit√†. L‚Äôentropia di una variabile casuale rappresenta la media della sua imprevedibilit√†. Approfondiremo anche il modo in cui l‚Äôentropia pu√≤ essere impiegata per misurare la ‚Äúdistanza‚Äù tra un modello teorico e i dati osservati, introducendo il concetto di divergenza di Kullback-Leibler (\\(\\mathbb{KL}\\)). Questa metrica quantifica le discrepanze tra due distribuzioni probabilistiche, fornendo una misura di quanto efficacemente un modello rappresenti le osservazioni empiriche. Il capitolo successivo presenter√† un‚Äôanalisi della tecnica di Validazione Incrociata Leave-One-Out, impiegata per calcolare un‚Äôapprossimazione della divergenza \\(\\mathbb{KL}\\), nota come LOO-CV.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_30_entropy.html#la-generalizzabilit√†-dei-modelli-e-il-metodo-scientifico",
    "href": "chapters/chapter_5/05_30_entropy.html#la-generalizzabilit√†-dei-modelli-e-il-metodo-scientifico",
    "title": "64¬† Entropia",
    "section": "64.1 La Generalizzabilit√† dei Modelli e il Metodo Scientifico",
    "text": "64.1 La Generalizzabilit√† dei Modelli e il Metodo Scientifico\nLa generalizzabilit√† dei modelli √® un concetto chiave nella scienza, essendo uno dei fondamenti del metodo scientifico. Questo principio si riferisce alla capacit√† di un modello di applicarsi e produrre risultati validi oltre il contesto specifico o il set di dati in cui √® stato originariamente sviluppato o testato. Il valore scientifico di un modello √® quindi fortemente influenzato dalla sua capacit√† di generalizzarsi a nuovi dati.\nNella pratica, la generalizzabilit√† di un modello pu√≤ essere minacciata da due problemi principali: il sotto-adattamento e il sovra-adattamento. Il sotto-adattamento si verifica quando un modello √® troppo semplice per catturare adeguatamente la complessit√† dei dati, portando a prestazioni insoddisfacenti sia sui dati di addestramento che su nuovi insiemi di dati. Questo limita gravemente la sua utilit√† in applicazioni pratiche. Al contrario, il sovra-adattamento si manifesta quando un modello √® eccessivamente complesso, adattandosi troppo fedelmente al rumore o alle peculiarit√† specifiche del set di dati di addestramento a discapito della capacit√† di generalizzare a nuovi dati.\nL‚Äôapproccio bayesiano alla modellazione consente di gestire in modo efficace la necessit√† di un compromesso tra complessit√† del modello e adattamento ai dati. La selezione di modelli, come descritto da McElreath (2020), √® un processo che richiede di mediare tra la semplicit√† del modello e la sua capacit√† di rappresentare fedelmente la realt√† dei dati.\nUna pratica comune nella scelta tra modelli alternativi si basa sul principio del rasoio di Ockham, che predilige le spiegazioni pi√π semplici in presenza di multiple teorie equivalenti per un fenomeno. Tuttavia, questo principio da solo non √® sufficiente: √® essenziale che il modello scelto descriva accuratamente i dati.\nLa metodologia prevalente nella selezione dei modelli √® spesso centrata sull‚Äôuso dei valori-p, ma come evidenziato da McElreath (2020), questo approccio √® problematico e privo di una solida giustificazione teorica.\nUn metodo pi√π robusto e fondato scientificamente impiega invece la divergenza di Kullback-Leibler, una misura che valuta quanto un modello approssimi efficacemente la distribuzione reale dei dati, offrendo una stima quantitativa della sua aderenza al processo generativo sottostante. Questo capitolo pone le basi per comprendere il concetto di entropia, essenziale per affrontare nel prossimo capitolo la divergenza di Kullback-Leibler e le sue implicazioni nella selezione di modelli.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_30_entropy.html#cos√®-lentropia-dellinformazione",
    "href": "chapters/chapter_5/05_30_entropy.html#cos√®-lentropia-dellinformazione",
    "title": "64¬† Entropia",
    "section": "64.2 Cos‚Äô√® l‚ÄôEntropia dell‚ÄôInformazione?",
    "text": "64.2 Cos‚Äô√® l‚ÄôEntropia dell‚ÄôInformazione?\nL‚Äôentropia dell‚Äôinformazione, un concetto introdotto da Claude Shannon, rappresenta uno dei fondamenti della teoria dell‚Äôinformazione. Questa grandezza matematica quantifica l‚Äôincertezza o la sorpresa associata alla ricezione di un messaggio, misurando quanto sia sorprendente un evento in base alla sua probabilit√†. Gli eventi che si verificano con alta probabilit√† sono considerati meno sorprendenti perch√© prevedibili; al contrario, quelli meno probabili, essendo inaspettati, trasmettono pi√π sorpresa.\nLa sorpresa di un evento, determinata dalla sua probabilit√† \\(p\\), si calcola con la formula:\n\\[ H(p) = -\\log_2(p) = \\log_2 \\left(\\frac{1}{p}\\right). \\]\nL‚Äôuso del logaritmo in questa formula ha diverse giustificazioni:\n\nIl logaritmo converte la moltiplicazione delle probabilit√† in una somma. Questo semplifica l‚Äôanalisi di eventi complessi formati da pi√π eventi indipendenti.\nLa base del logaritmo (in questo caso, 2) corrisponde all‚Äôunit√† di misura dell‚Äôinformazione. La base 2 √® utilizzata perch√© l‚Äôinformazione viene misurata in bit, che rappresentano decisioni binarie.\nLa scala logaritmica riflette meglio la percezione umana dell‚Äôinformazione e della sorpresa. Eventi con probabilit√† molto basse hanno un impatto informativo molto maggiore rispetto a variazioni di probabilit√† in range pi√π alti.\n\n√à importante notare che la base del logaritmo pu√≤ variare: non ci sono unit√† intrinseche per misurare la sorpresa. Ad esempio, l‚Äôuso della base 2, comune nelle telecomunicazioni, porta a misurare l‚Äôinformazione in ‚Äúbit‚Äù. Al contrario, l‚Äôadozione della base \\(e\\), tipica nella fisica statistica, porta a misurazioni in ‚Äúnats‚Äù, o ‚Äúcifre naturali‚Äù.\nPer illustrare, consideriamo alcuni esempi pratici.\n\ndef calcola_entropia(p):\n    if p == 0 or p == 1:\n        return 0  # Non c'√® incertezza se l'evento √® certo o impossibile\n    else:\n        return -p * math.log2(p)\n\n# Esempi di probabilit√†\nprobabilit√† = [0.0, 0.1, 0.5, 0.9, 1.0]\n\n# Calcolo dell'entropia per ciascuna probabilit√†\nentropie = {p: calcola_entropia(p) for p in probabilit√†}\n\nprint(entropie)\n\n{0.0: 0, 0.1: 0.33219280948873625, 0.5: 0.5, 0.9: 0.13680278410054494, 1.0: 0}\n\n\nL‚Äôoutput di questo script mostra che l‚Äôentropia √® massima per eventi con probabilit√† intermedia (0.5) e minima (zero) per eventi certi o impossibili.\nIn generale, possiamo dunque dire che l‚Äôentropia raggiunge il suo valore massimo in condizioni di completa equiprobabilit√†, ovvero quando ogni esito possibile di un evento ha esattamente la stessa probabilit√† di verificarsi. Questa condizione rappresenta il massimo grado di imprevedibilit√†, poich√© non esistono indizi che possano aiutare a prevedere quale esito si verificher√†.\nAl contrario, l‚Äôentropia √® minima, assumendo un valore di zero, quando l‚Äôesito di un evento √® completamente certo. Questo avviene quando uno degli esiti possibili ha una probabilit√† di 1, eliminando qualsiasi forma di incertezza o sorpresa. In pratica, ci√≤ significa che non c‚Äô√® alcuna informazione da guadagnare nell‚Äôosservare l‚Äôevento, poich√© l‚Äôesito √® gi√† noto in anticipo.\n\n64.2.1 Additivit√† dell‚ÄôEntropia per Eventi Indipendenti\nL‚Äôentropia mostra una propriet√† di additivit√† nel caso di eventi indipendenti. Questo significa che, se due o pi√π eventi indipendenti si verificano, l‚Äôentropia totale associata alla loro combinazione √® uguale alla somma delle entropie di ciascun evento preso singolarmente. Questa caratteristica deriva dalla propriet√† additiva dei logaritmi, che permette di sommare le entropie individuali per ottenere l‚Äôentropia complessiva.\n\n\n64.2.2 Entropia di Variabili Casuali\nL‚Äôinformazione di Shannon misura la sorpresa di un singolo evento, ma √® possibile estendere questo concetto al caso di una distribuzione di probabilit√†, ovvero al caso di una variabile casuale discreta o continua. L‚Äôentropia fornisce una misura complessiva dell‚Äôincertezza o della sorpresa associata a una variabile casuale.\n\n64.2.2.1 Entropia di una Variabile Casuale Discreta\nConsideriamo una variabile casuale discreta \\(X\\) che pu√≤ assumere i valori \\(a_1, a_2, \\ldots, a_n\\) con le relative probabilit√† \\(p_1, p_2, \\ldots, p_n\\), dove la somma totale delle probabilit√† √® 1. L‚Äôentropia di $ X $ √® calcolata come la somma pesata delle entropie di ciascun possibile esito:\n\\[ H(X) = -\\sum_{i=1}^{n} p_i \\log_2(p_i). \\]\nLa formula somma le informazioni di tutti i possibili esiti, pesando ciascun termine con la probabilit√† \\(p_i\\) dell‚Äôesito stesso. Questo significa che gli esiti pi√π probabili influenzano maggiormente l‚Äôentropia totale rispetto a quelli meno probabili.\nIl logaritmo converte la moltiplicazione delle probabilit√† in una somma, semplificando i calcoli per eventi indipendenti.\nIl segno negativo √® necessario perch√© i logaritmi delle probabilit√†, essendo numeri minori di 1, sono negativi. Il segno negativo inverte questi valori, trasformandoli in quantit√† positive che rappresentano correttamente l‚Äôinformazione o la sorpresa. Inoltre, esiti pi√π probabili, avendo \\(p_i\\) maggiori, producono logaritmi negativi meno estremi, riflettendo la loro minore sorpresa.\nIn sintesi, l‚Äôentropia \\(H(X)\\) misura l‚Äôincertezza complessiva di una variabile casuale discreta, tenendo conto delle probabilit√† di tutti i suoi possibili esiti. Ogni termine della somma \\(-p_i \\log_2(p_i)\\) rappresenta la quantit√† di sorpresa o informazione associata a ciascun esito, ponderata dalla probabilit√† di quell‚Äôesito.\n\n\n64.2.2.2 Entropia di una Variabile Casuale Continua\nNel caso delle variabili casuali continue, il concetto di entropia viene generalizzato sostituendo la somma con un integrale. Questo √® necessario perch√© le variabili continue possono assumere un numero infinito di valori all‚Äôinterno di un intervallo.\nPer una variabile casuale continua \\(X\\) con una funzione di densit√† di probabilit√† \\(p(x)\\), l‚Äôentropia (nota anche come entropia differenziale) √® definita dalla seguente formula:\n\\[ H(X) = -\\int p(x) \\log_2(p(x)) \\, dx, \\]\ndove:\n\n\\(p(x)\\) √® la funzione di densit√† di probabilit√† di \\(X\\),\nl‚Äôintegrale √® calcolato su tutto il dominio di \\(X\\).\n\nL‚Äôentropia di una variabile casuale continua fornisce una misura dell‚Äôincertezza o della sorpresa associata alla distribuzione della variabile. Come nel caso discreto, l‚Äôentropia continua quantifica l‚Äôincertezza associata a \\(X\\). Una PDF molto concentrata (ad esempio, una distribuzione con picchi stretti) implica bassa entropia, poich√© l‚Äôevento √® pi√π prevedibile. Una PDF distribuita uniformemente implica alta entropia, poich√© l‚Äôevento √® meno prevedibile.\nIl segno negativo assicura che l‚Äôentropia sia una quantit√† positiva, in quanto \\(\\log_2(p(x))\\) √® negativo per \\(p(x)\\) compreso tra 0 e 1.\n\n\n\n64.2.3 Applicazioni Psicologiche\nL‚Äôentropia dell‚Äôinformazione trova applicazioni anche in psicologia, per esempio nello studio dell‚Äôeffetto della sorpresa sull‚Äôumore. La sorpresa, o entropia, √® stata documentata sia in laboratorio che in contesti naturali come un fattore significativo che influenza le emozioni.\nAd esempio, Spector (1956) osserv√≤ l‚Äôeffetto della probabilit√† a priori sulla soddisfazione dei soggetti in risposta a una promozione lavorativa. I risultati indicano che gli esiti meno probabili a priori (e quindi pi√π sorprendenti quando si verificano) hanno un impatto maggiore sull‚Äôumore. In altre parole, quando un evento inatteso e sorprendente si verifica, esso tende a influenzare l‚Äôumore in modo pi√π forte rispetto a eventi previsti e probabili.\n\n\n64.2.4 Divergenza di Kullback-Leibler: Uno Strumento per Confrontare Distribuzioni Probabilistiche\nLa divergenza \\(\\mathbb{KL}\\), introdotta da Kullback e Leibler nel 1951, estende il concetto di entropia di Shannon. Mentre l‚Äôentropia misura l‚Äôincertezza di una singola distribuzione di probabilit√†, la divergenza \\(\\mathbb{KL}\\) valuta quanto una distribuzione di probabilit√† \\(Q\\) differisca da un‚Äôaltra distribuzione di riferimento \\(P\\). Entrambe le distribuzioni devono descrivere la stessa variabile aleatoria \\(X\\).\n\n64.2.4.1 Calcolo della Divergenza \\(\\mathbb{KL}\\)\nSupponiamo che la variabile casuale \\(X\\) segua la distribuzione \\(P\\). L‚Äôentropia di Shannon, che quantifica la sorpresa media risultante dall‚Äôosservazione di esiti distribuiti secondo \\(P\\), si calcola come:\n\\[\nH(P) = -\\sum_x p(x) \\log(p(x)).\n\\]\nPer valutare quanto sarebbe sorprendente osservare \\(P\\) attraverso la lente di una distribuzione diversa \\(Q\\), calcoliamo l‚Äôentropia incrociata, definita come:\n\\[\nH(P, Q) = -\\sum_x p(x) \\log(q(x)).\n\\]\nQuesta misura rappresenta la sorpresa attesa se utilizzassimo \\(Q\\) anzich√© \\(P\\) per descrivere la variabile aleatoria \\(X\\).\nLa divergenza \\(\\mathbb{KL}\\), che √® la differenza tra l‚Äôentropia di \\(P\\) e l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\), si esprime come:\n\\[\nD_{\\mathbb{KL}}(P \\parallel Q) = \\sum_x p(x) \\big(\\log(p(x)) - \\log(q(x))\\big).\n\\]\nAlternativamente, la formula precedente pu√≤ essere riscritta utilizzando il rapporto tra i logaritmi:\n\\[\nD_{\\mathbb{KL}}(P \\parallel Q) = \\sum_x p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right).\n\\]\nIn queste formule\n\\[\\log(p(x)) - \\log(q(x))\\]\nrappresenta il ‚Äúcosto‚Äù di sorpresa per ciascun esito \\(x\\), ponderato dalla probabilit√† \\(p(x)\\) di tale esito secondo la distribuzione originale \\(P\\). Questo costo quantifica quanto \\(Q\\) sia inadeguata a modellare o descrivere \\(P\\).\nLa divergenza \\(\\mathbb{KL}\\) quantifica ‚Äúquanto siamo sorpresi‚Äù nell‚Äôutilizzare \\(Q\\) per prevedere eventi distribuiti secondo \\(P\\) e riflette l‚Äôinformazione che viene ‚Äúpersa‚Äù quando \\(Q\\) √® usata al posto di \\(P\\).\nIn conclusione, la divergenza \\(\\mathbb{KL}\\) si basa su due misure fondamentali:\n\nEntropia di \\(P\\): Misura l‚Äôincertezza interna di \\(P\\).\nEntropia incrociata tra \\(P\\) e \\(Q\\): Quantifica l‚Äôincertezza quando \\(Q\\) √® utilizzata per stimare \\(P\\).\n\nCos√¨, la divergenza \\(\\mathbb{KL}\\) rappresenta la differenza tra l‚Äôentropia di \\(P\\) e l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\), e mette in evidenza quanto l‚Äôuso di \\(Q\\) al posto di \\(P\\) incrementi l‚Äôincertezza o la sorpresa.\n\nEsempio 64.1 Per fare un esempio, supponiamo che \\(P\\) e \\(Q\\) siano due distribuzioni di probabilit√† su un insieme finito di possibili esiti, ad esempio {0, 1, 2}. Per semplicit√†, consideriamo che \\(P\\) e \\(Q\\) siano definite come segue:\n\n\\(P\\) √® la distribuzione ‚Äúvera‚Äù: \\(P = [0.1, 0.6, 0.3]\\);\n\\(Q\\) √® una distribuzione alternativa che usiamo per la stima: \\(Q = [0.2, 0.5, 0.3]\\).\n\n\n# Definizione delle distribuzioni\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.2, 0.5, 0.3])\n\n# Calcolo della divergenza KL da P a Q\nKL_divergence = np.sum(kl_div(P, Q))\n\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.0401\n\n\nNel codice precedente, kl_div(P, Q) calcola la divergenza \\(\\mathbb{KL}\\) elemento per elemento dell‚Äôarray. Essa calcola \\(\\sum_x p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) per ogni esito \\(x\\), che √® esattamente il termine \\(p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) descritto nella formula della divergenza \\(\\mathbb{KL}\\). Utilizziamo poi np.sum per sommare tutti i contributi individuali e ottenere il valore totale della divergenza \\(\\mathbb{KL}\\).\nQuesto esempio fornisce un calcolo diretto della divergenza \\(\\mathbb{KL}\\) tra due distribuzioni, mostrando come una distribuzione \\(Q\\) possa essere inadeguata nel modellare una distribuzione \\(P\\), con un focus sul ‚Äúcosto‚Äù di sorpresa per ogni esito.\n\n\nEsempio 64.2 In un due altri esempi, rendiamo via via \\(Q\\) pi√π diverso da \\(P\\). Notiamo come la divergenza \\(\\mathbb{KL}\\) aumenta.\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.35, 0.3, 0.35])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.2444\n\n\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.6, 0.3, 0.1])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.5663\n\n\n\n\n\n\n64.2.5 Applicazione della Divergenza \\(\\mathbb{KL}\\) nella Selezione di Modelli\nLa divergenza \\(\\mathbb{KL}\\) √® un indice fondamentale nella selezione di modelli statistici. L‚Äôobiettivo √® identificare il modello \\(Q\\) che minimizza \\(D_{\\mathbb{KL}}(P \\parallel Q)\\), ovvero ridurre al minimo la differenza \\(H(P) - H(P, Q)\\). Questo significa minimizzare l‚Äôerrore introdotto nell‚Äôapprossimare la distribuzione vera \\(P\\) con il modello \\(Q\\).\n\n64.2.5.1 Propriet√† Importanti\n\nNon-negativit√†: \\(D_{\\mathbb{KL}}(P \\parallel Q) \\geq 0\\). Il valore √® zero solamente quando \\(P\\) e \\(Q\\) sono identiche, indicando una perfetta corrispondenza.\nAsimmetria: \\(D_{\\mathbb{KL}}(P \\parallel Q) \\neq D_{\\mathbb{KL}}(Q \\parallel P)\\). Questa propriet√† evidenzia che la ‚Äúdistanza‚Äù percepita dal modello \\(Q\\) verso \\(P\\) non √® equivalente se misurata nella direzione inversa.\n\n\n\n64.2.5.2 Selezione dei Modelli Statistici\nNella selezione dei modelli statistici, l‚Äôobiettivo principale √® scegliere il modello \\(Q\\) che minimizzi la divergenza \\(\\mathbb{KL}\\) rispetto alla distribuzione ‚Äúvera‚Äù \\(P\\) dei dati. Tuttavia, \\(P\\) √® spesso sconosciuta o non direttamente osservabile.\nA causa di questa incertezza, i ricercatori e gli statistici utilizzano criteri approssimativi per stimare indirettamente la divergenza \\(\\mathbb{KL}\\). Nel capitolo successivo, esploreremo come questi criteri valutano sia la bont√† di adattamento del modello che la sua complessit√†.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_30_entropy.html#riflessioni-conclusive",
    "href": "chapters/chapter_5/05_30_entropy.html#riflessioni-conclusive",
    "title": "64¬† Entropia",
    "section": "64.3 Riflessioni Conclusive",
    "text": "64.3 Riflessioni Conclusive\nIn questo capitolo, abbiamo esaminato il concetto di entropia, evidenziando il suo ruolo fondamentale nel quantificare l‚Äôincertezza all‚Äôinterno delle distribuzioni di probabilit√†. Abbiamo anche affrontato la questione di come l‚Äôentropia possa essere impiegata per valutare la ‚Äúdistanza‚Äù tra un modello teorico e i dati reali. A tale scopo, abbiamo introdotto la divergenza \\(\\mathbb{KL}\\), una misura che quantifica le discrepanze tra due distribuzioni di probabilit√†.\nNel capitolo successivo, approfondiremo ulteriormente il tema della divergenza \\(\\mathbb{KL}\\). Esploreremo come questo strumento possa essere utilizzato per confrontare modelli teorici con dati empirici e ci concentreremo su come possa fornirci una comprensione pi√π dettagliata dell‚Äôadattamento di un modello alla realt√† che intende rappresentare. Questa esplorazione ci permetter√† di valutare pi√π accuratamente la validit√† e la generalizzabilit√† dei modelli scientifici nel loro tentativo di catturare e interpretare la complessit√† dei fenomeni oggetto di studio.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_30_entropy.html#esercizi",
    "href": "chapters/chapter_5/05_30_entropy.html#esercizi",
    "title": "64¬† Entropia",
    "section": "64.4 Esercizi",
    "text": "64.4 Esercizi\n\nEsercizio 64.1 Cosideriamo due distribuzioni di probabilit√† discrete, \\(p\\) e \\(q\\):\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\nSi calcoli l‚Äôentropia di \\(p\\), l‚Äôentropia incrociata tra \\(p\\) e \\(q\\), la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).\nSi consideri q = np.array([0.2, 0.55, 0.25]) e si calcoli di nuovo a divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). Si confronti con il risultato precedente e si interpreti.\n\n\nEsercizio 64.2 Sia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\). Sia \\(q_1\\) una approssimazione a \\(p\\): q1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01]). Sia \\(q_2\\) una distribuzione uniforme: q2 = [0.2] * 5. Si calcoli la divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) e da \\(q_2\\) da \\(p\\) e si interpretino i risultati.\n\n\nEsercizio 64.3 La Divergenza \\(\\mathbb{KL}\\) √® spesso paragonata a una ‚Äúdistanza‚Äù tra due distribuzioni di probabilit√†, ma √® fondamentale capire che non √® simmetrica. Questo significa che la misura di quanto \\(p\\) √® diversa da \\(q\\) non √® la stessa di quanto \\(q\\) √® diversa da \\(p\\). Questa asimmetria riflette la differenza nella perdita di informazione quando si sostituisce una distribuzione con l‚Äôaltra.\nPer le seguenti distribuzioni\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\nsi calcoli l‚Äôentropia di p, l‚Äôentropia incrociata da p a q, la divergenza KL da p a q, l‚Äôentropia di q, l‚Äôentropia incrociata da q a p, e la divergenza KL da q a p.¬†Si commenti.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_30_entropy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_30_entropy.html#informazioni-sullambiente-di-sviluppo",
    "title": "64¬† Entropia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nscipy     : 1.14.0\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nSpector, Aaron J. 1956. ¬´Expectations, fulfillment, and morale¬ª. The Journal of Abnormal and Social Psychology 52 (1): 51‚Äì56.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_31_kl.html",
    "href": "chapters/chapter_5/05_31_kl.html",
    "title": "65¬† Divergenza KL e ELPD",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo in dettaglio due concetti fondamentali per la valutazione e il confronto di modelli statistici nel contesto bayesiano: la Divergenza di Kullback-Leibler (\\(\\mathbb{KL}\\)) e la Densit√† Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD). Questi strumenti ci permettono di quantificare l‚Äôadattamento dei modelli ai dati e la loro capacit√† predittiva.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_31_kl.html#confronto-di-modelli-utilizzando-la-divergenza-mathbbkl",
    "href": "chapters/chapter_5/05_31_kl.html#confronto-di-modelli-utilizzando-la-divergenza-mathbbkl",
    "title": "65¬† Divergenza KL e ELPD",
    "section": "65.1 Confronto di Modelli Utilizzando la Divergenza \\(\\mathbb{KL}\\)",
    "text": "65.1 Confronto di Modelli Utilizzando la Divergenza \\(\\mathbb{KL}\\)\n\n65.1.1 La Distribuzione Predittiva Posteriori\nLa distribuzione predittiva posteriori, indicata come \\(Q(\\tilde{y} \\mid y)\\), rappresenta le previsioni su nuovi dati \\(\\tilde{y}\\) basate su un modello statistico \\(Q\\) e i dati osservati \\(y\\). Questa distribuzione combina:\n\nLe previsioni del modello per un dato set di parametri \\(\\theta\\), ovvero \\(Q(\\tilde{y} \\mid \\theta)\\).\nLa distribuzione posteriore di questi parametri dati i dati osservati, cio√® \\(P(\\theta \\mid y)\\).\n\nQuesta combinazione permette di fare previsioni che tengono conto sia dell‚Äôincertezza nei parametri che della struttura del modello.\n\n\n65.1.2 Misurazione della Divergenza \\(\\mathbb{KL}\\)\nLa divergenza \\(\\mathbb{KL}\\) quantifica quanto bene la distribuzione predittiva del modello \\(Q\\) si avvicina alla distribuzione vera \\(P\\) che ha generato i dati. Matematicamente, questo √® espresso come \\(\\mathbb{KL}(P \\parallel Q)\\).\nInterpretazione:\n\nUn valore basso di \\(\\mathbb{KL}\\) indica che \\(Q\\) √® una buona approssimazione di \\(P\\).\nUn valore alto indica una maggiore discrepanza tra le due distribuzioni.\n\n\n\n65.1.3 Confronto Pratico tra Modelli\nPoich√© non conosciamo direttamente \\(P\\), la vera distribuzione che ha generato i dati, utilizziamo la divergenza \\(\\mathbb{KL}\\) per confrontare diversi modelli. La formula generale per la divergenza \\(\\mathbb{KL}\\) tra due distribuzioni \\(P\\) e \\(Q\\) √®:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\mathbb{E}_P[\\log P] - \\mathbb{E}_P[\\log Q],\n\\]\ndove \\(\\mathbb{E}_P\\) indica il valore atteso calcolato sotto la distribuzione \\(P\\).\nPer distribuzioni discrete, questa si esprime come:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\sum_{i=1}^n p_i (\\log p_i - \\log q_i),\n\\]\ndove \\(p_i\\) e \\(q_i\\) rappresentano le probabilit√† degli eventi \\(i\\) per le distribuzioni \\(P\\) e \\(Q\\) rispettivamente.\nLa divergenza \\(\\mathbb{KL}\\) pu√≤ essere riformulata in termini di valore atteso come segue:\n\nTermine \\(\\log P\\): \\[\n\\mathbb{E}_P[\\log P(X)] = \\sum_{i=1}^n p_i \\log p_i\n\\] Questo termine rappresenta l‚Äôentropia negativa di \\(P\\).\nTermine \\(\\log Q\\): \\[\n\\mathbb{E}_P[\\log Q(X)] = \\sum_{i=1}^n p_i \\log q_i\n\\] Questo termine rappresenta l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\).\n\nQuindi, la divergenza \\(\\mathbb{KL}\\) si riduce a:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\mathbb{E}_P[\\log P(X)] - \\mathbb{E}_P[\\log Q(X)]\n\\]\nPer variabili continue, la formula diventa:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\int p(x) (\\log p(x) - \\log q(x)) \\, dx.\n\\]\nNella pratica del confronto tra modelli, il termine \\(\\mathbb{E}_P[\\log P]\\) rimane costante per tutti i modelli confrontati e pu√≤ quindi essere omesso. Ci concentriamo dunque sul termine:\n\\[\n-\\mathbb{E}_P[\\log Q(y)]\n\\]\nche misura l‚Äôadattabilit√† del modello ai dati osservati. Questo si calcola come:\n\\[\n-\\int p(y) \\log Q(y) \\, dy,\n\\]\nindicando quale modello \\(Q\\) rappresenti meglio la distribuzione \\(P\\) secondo la quantit√† di informazione che si perderebbe utilizzandolo per descrivere i dati osservati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_31_kl.html#expected-log-predictive-density-elpd",
    "href": "chapters/chapter_5/05_31_kl.html#expected-log-predictive-density-elpd",
    "title": "65¬† Divergenza KL e ELPD",
    "section": "65.2 Expected Log Predictive Density (ELPD)",
    "text": "65.2 Expected Log Predictive Density (ELPD)\nL‚ÄôELPD √® una misura avanzata usata nei metodi bayesiani per valutare quanto bene un modello pu√≤ prevedere nuovi dati. √à come se stessimo chiedendo al modello: ‚ÄúQuanto sei sicuro delle tue previsioni per dati che non hai mai visto?‚Äù\nLa formula dell‚ÄôELPD √®:\n\\[ \\text{ELPD} = \\sum_{i=1}^n \\log p(y_i | \\mathbf{y}_{-i}), \\]\ndove:\n\n\\(y_i\\) √® l‚Äôi-esima osservazione,\n\\(\\mathbf{y}_{-i}\\) rappresenta tutte le osservazioni eccetto \\(y_i\\).\n\nInterpretazione:\n\nL‚ÄôELPD misura quanto bene il modello pu√≤ prevedere ogni singola osservazione basandosi su tutte le altre.\nUn ELPD pi√π alto indica un modello con migliori capacit√† predittive.\n\n\n65.2.1 Collegamento con la Divergenza \\(\\mathbb{KL}\\)\nIl collegamento tra \\(-\\mathbb{E}_P[\\log Q(y)]\\) e l‚ÄôELPD √® che entrambi misurano la capacit√† predittiva di un modello, ma in modi leggermente diversi:\n\n\\(-\\mathbb{E}_P[\\log Q(y)]\\) misura la divergenza tra la vera distribuzione \\(P\\) e la distribuzione del modello \\(Q\\), indicando quanto bene \\(Q\\) approssima \\(P\\).\nL‚ÄôELPD, d‚Äôaltra parte, misura direttamente la capacit√† del modello di prevedere nuove osservazioni, utilizzando un approccio di convalida incrociata leave-one-out.\n\nL‚ÄôELPD si focalizza sulla capacit√† di un modello di predire nuovi dati, offrendo una misura della sua capacit√† di generalizzazione. Matematicamente, l‚ÄôELPD √® definito come il valore atteso del logaritmo della densit√† predittiva di un modello, calcolato sotto la vera distribuzione dei dati futuri:\n\\[\n\\text{ELPD} = \\mathbb{E}_{y \\sim p(y)} [\\log p(y \\mid \\theta)]\n\\]\nMentre \\(-\\int p(y) \\log Q(y) \\, dy\\) quantifica quanto bene un modello descrive la distribuzione attuale dei dati, l‚ÄôELPD stima quanto efficacemente il modello pu√≤ essere utilizzato per prevedere nuovi dati. Questo rende l‚ÄôELPD una misura complementare alla \\(\\mathbb{KL}\\), enfatizzando non solo l‚Äôadattabilit√† ma anche la predittivit√† di un modello.\nIn conclusione, utilizzare l‚ÄôELPD come criterio di valutazione tende a favorire modelli che non solo si adattano bene ai dati esistenti ma sono anche robusti contro l‚Äôoverfitting. La combinazione di Divergenza \\(\\mathbb{KL}\\) ed ELPD fornisce una valutazione completa dei modelli, considerando sia la loro capacit√† di adattarsi ai dati osservati che la loro abilit√† nel fare previsioni accurate su nuovi dati.\n\nEsempio 65.1 Consideriamo un esempio utilizzando la distribuzione binomiale per illustrare il concetto di ELPD. Immaginiamo un esperimento in cui lanciamo una moneta 10 volte e contiamo il numero di teste. Supponiamo che la vera probabilit√† di ottenere testa sia 0.6 (anche se nella realt√† non la conosceremmo).\n\nLa vera distribuzione dei dati segue una Binomiale(n=10, p=0.6): \\(y \\sim \\text{Binomiale}(10, 0.6)\\)\nIl nostro modello stima \\(p=0.5\\) (ipotizziamo una moneta equa): \\(p(y|\\theta) = \\text{Binomiale}(10, 0.5)\\)\n\nCalcoliamo l‚ÄôELPD:\n\n# Parametri\nn = 10  # numero di lanci\np_true = 0.6  # vera probabilit√† di testa\np_model = 0.5  # probabilit√† stimata dal modello\n\n# Calcolo ELPD\nelpd = 0\nfor y in range(n + 1):\n    # Probabilit√† di y secondo la vera distribuzione\n    p_true_y = binom.pmf(y, n, p_true)\n\n    # Log della densit√† predittiva del modello\n    log_p_model_y = binom.logpmf(y, n, p_model)\n\n    # Somma pesata\n    elpd += p_true_y * log_p_model_y\n\nprint(f\"ELPD del modello che stima p=0.5: {elpd:.4f}\")\n\n# Per confronto, calcoliamo l'ELPD per il modello \"vero\"\nelpd_true = 0\nfor y in range(n + 1):\n    p_true_y = binom.pmf(y, n, p_true)\n    log_p_true_y = binom.logpmf(y, n, p_true)\n    elpd_true += p_true_y * log_p_true_y\n\nprint(f\"ELPD del modello vero (con p=0.6): {elpd_true:.4f}\")\n\nELPD del modello che stima p=0.5: -2.0549\nELPD del modello vero (con p=0.6): -1.8536\n\n\nL‚ÄôELPD del modello vero √® maggiore (meno negativo) di quello del nostro modello stimato, indicando una migliore capacit√† predittiva.\nQuesto esempio illustra come l‚ÄôELPD quantifica la capacit√† predittiva di un modello:\n\nConsidera tutti i possibili risultati (da 0 a 10 teste).\nPer ogni risultato, calcola:\n\nLa probabilit√† di quel risultato secondo la vera distribuzione.\nIl logaritmo della densit√† predittiva del nostro modello per quel risultato.\n\nMoltiplica questi due valori e somma su tutti i possibili risultati.\n\nIn conclusione, l‚ÄôELPD ci permette di confrontare modelli diversi: un valore pi√π alto (meno negativo) indica una migliore capacit√† predittiva. Nel nostro caso, il vero modello (p=0.6) ha un ELPD maggiore del modello stimato (p=0.5).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_31_kl.html#metodi-di-approssimazione-per-la-stima-dellelpd",
    "href": "chapters/chapter_5/05_31_kl.html#metodi-di-approssimazione-per-la-stima-dellelpd",
    "title": "65¬† Divergenza KL e ELPD",
    "section": "65.3 Metodi di Approssimazione per la Stima dell‚ÄôELPD",
    "text": "65.3 Metodi di Approssimazione per la Stima dell‚ÄôELPD\nL‚ÄôELPD √® un importante indicatore della qualit√† di un modello statistico. Tuttavia, poich√© la vera distribuzione dei dati √® sconosciuta, non possiamo calcolare direttamente l‚ÄôELPD. Per superare questa limitazione, utilizziamo metodi di approssimazione noti come ‚Äúcriteri di informazione‚Äù.\n\n65.3.1 Obiettivo dei Criteri di Informazione\nI criteri di informazione ci aiutano a bilanciare due aspetti cruciali nella valutazione di un modello:\n\nL‚Äôadattamento del modello ai dati osservati\nLa complessit√† del modello\n\nEsaminiamo alcuni dei criteri pi√π comuni utilizzati per approssimare l‚ÄôELPD.\n\n\n65.3.2 Errore Quadratico Medio (MSE)\nL‚ÄôErrore Quadratico Medio (Mean Squared Error o MSE) misura la discrepanza media tra le previsioni del modello e i valori reali.\nFormula:\n\\[ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2, \\]\ndove:\n\n\\(n\\) √® il numero totale di osservazioni,\n\\(y_i\\) sono i valori reali,\n\\(\\hat{y}_i\\) sono i valori previsti dal modello.\n\nUn MSE inferiore indica un migliore adattamento del modello ai dati.\n\n\n65.3.3 Criterio di Informazione di Akaike (AIC)\nIl Criterio di Informazione di Akaike (AIC) va oltre l‚ÄôMSE, considerando sia l‚Äôadattamento del modello che la sua complessit√†.\nFormula:\n\\[ AIC = -2 \\sum \\log p(y_i \\mid \\hat{\\theta}_{\\text{mle}}) + 2k, \\]\ndove:\n\n\\(\\hat{\\theta}_{\\text{mle}}\\) sono i parametri stimati del modello,\n\\(k\\) √® il numero di parametri del modello.\n\nL‚ÄôAIC bilancia la bont√† di adattamento (primo termine) con la complessit√† del modello (secondo termine). Un valore pi√π basso di AIC indica una minor perdita di informazione, suggerendo un modello preferibile.\nVantaggi e Limitazioni:\n\nFacile e veloce da calcolare.\nPu√≤ essere meno accurato per campioni piccoli o modelli complessi.\nFornisce un‚Äôapprossimazione asintoticamente corretta dell‚ÄôELPD per modelli regolari e campioni grandi.\n\n\n\n65.3.4 Criterio di Informazione Bayesiano (BIC)\nIl Criterio di Informazione Bayesiano (BIC) √® definito come:\n\\[\nBIC = \\ln(n)k - 2\\ln(L),\n\\]\ndove \\(n\\) √® il numero di osservazioni.\nIl BIC impone una penalit√† maggiore per l‚Äôincremento dei parametri, rendendolo particolarmente adeguato per dataset di grandi dimensioni.\n\n\n65.3.5 Widely Applicable Information Criterion (WAIC)\nIl WAIC √® una versione avanzata dell‚ÄôAIC, particolarmente utile nel contesto bayesiano. Considera l‚Äôintera distribuzione a posteriori dei parametri anzich√© solo la stima puntuale.\nFormula:\n\\[ WAIC = -2\\left[ \\sum_{i=1}^{n} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i|\\theta^{(s)}) \\right) - \\sum_{i=1}^{n} \\text{Var}_{\\theta^{(s)}} \\left( \\log p(y_i|\\theta^{(s)}) \\right) \\right], \\]\ndove:\n\n\\(S\\) √® il numero di campioni dalla distribuzione a posteriori,\n\\(\\text{Var}_{\\theta^{(s)}}\\) √® la varianza della log-verosimiglianza.\n\nCaratteristiche del WAIC:\n\nCalcola il logaritmo della densit√† predittiva per ogni punto dati.\nPenalizza la complessit√† del modello basandosi sulla variabilit√† delle sue predizioni.\nLa somma delle varianze a posteriori del logaritmo della densit√† predittiva converge al numero effettivo di parametri del modello.\n\n\n\n65.3.6 Leave-One-Out Cross-Validation (LOO-CV)\nIl LOO-CV √® un metodo robusto che massimizza l‚Äôutilizzo dei dati disponibili, rendendolo ideale per modelli complessi e campioni di dimensioni ridotte.\nProcedura:\n\nRimuove un‚Äôosservazione alla volta.\nAdatta il modello sui dati rimanenti.\nValuta la densit√† predittiva per l‚Äôosservazione esclusa.\n\nFormula:\n\\[ \\text{Stima dell'ELPD} = \\sum_{i=1}^N \\log p(y_i \\mid y_{-i}), \\]\ndove:\n\n\\(y_i\\) √® il dato escluso,\n\\(y_{-i}\\) rappresenta tutti gli altri dati.\n\nVantaggi e Limitazioni:\n\nFornisce una stima robusta dell‚ÄôELPD.\nParticolarmente utile per set di dati non molto ampi.\nComputazionalmente intensivo.\n\n\n\n65.3.7 Valutazione Comparativa e Applicazioni Pratiche\nQuesti metodi forniscono diverse prospettive sulla stima dell‚ÄôELPD. Il LOO-CV √® particolarmente prezioso per modelli complessi o set di dati limitati, mentre AIC e WAIC offrono approcci pi√π rapidi e meno computazionalmente intensivi, adatti per valutazioni preliminari o quando si dispone di grandi set di dati.\nIn conclusione, la selezione del modello ottimale richiede un equilibrio tra adattamento ai dati e semplicit√†. L‚Äôutilizzo combinato di tecniche di validazione incrociata e criteri di informazione permette di costruire modelli che:\n\nsi adattano bene ai dati attuali,\nsono in grado di fare previsioni affidabili su nuovi dati,\ncatturano le tendenze importanti senza perdersi nel rumore.\n\nL‚Äôobiettivo finale non √® creare il modello pi√π complesso o quello che si adatta perfettamente ai dati di addestramento, ma trovare un equilibrio ottimale tra semplicit√† e accuratezza.\n\nEsempio 65.2 Il seguente script Python dimostra come calcolare l‚ÄôAIC per un modello binomiale. Ecco una breve spiegazione del codice:\n\nDefiniamo una funzione per la log-verosimiglianza negativa del modello binomiale.\nImplementiamo una funzione per calcolare l‚ÄôAIC dato il valore di log-verosimiglianza e il numero di parametri.\nUtilizziamo scipy.optimize.minimize per trovare il parametro che massimizza la verosimiglianza.\nCalcoliamo l‚ÄôAIC per il modello binomiale.\n\n\n# Dati di esempio \nn_trials = 100\ntrue_p = 0.7\ndata = np.random.binomial(n_trials, true_p, size=50)\n\n# Funzione di log-verosimiglianza negativa\ndef neg_log_likelihood(p, data, n):\n    return -np.sum(binom.logpmf(data, n, p))\n\n# Funzione per calcolare l'AIC\ndef calculate_aic(log_likelihood, k):\n    return 2 * k - 2 * log_likelihood\n\n# Ottimizzazione per trovare la massima verosimiglianza\nresult = minimize(\n    neg_log_likelihood,\n    x0=[0.5],\n    args=(data, n_trials),\n    method=\"L-BFGS-B\",\n    bounds=[(0, 1)],\n)\n\n# Estrai il parametro ottimale e la log-verosimiglianza\np_mle = result.x[0]\nmax_log_likelihood = -result.fun\n\n# Calcola l'AIC\nk = 1  # numero di parametri (solo p in questo caso)\naic = calculate_aic(max_log_likelihood, k)\n\nprint(f\"Parametro stimato (p): {p_mle:.4f}\")\nprint(f\"Log-verosimiglianza massimizzata: {max_log_likelihood:.4f}\")\nprint(f\"AIC: {aic:.4f}\")\n\nParametro stimato (p): 0.5000\nLog-verosimiglianza massimizzata: -567.8227\nAIC: 1137.6453\n\n\nQuesto esempio mostra come calcolare l‚ÄôAIC. Questo indice pu√≤ essere utilizzato per confrontare modelli con diversi livelli di complessit√†. Il modello con l‚ÄôAIC pi√π basso √® generalmente considerato il migliore in termini di compromesso tra adattamento ai dati e complessit√† del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_31_kl.html#considerazioni-conclusive",
    "href": "chapters/chapter_5/05_31_kl.html#considerazioni-conclusive",
    "title": "65¬† Divergenza KL e ELPD",
    "section": "65.4 Considerazioni Conclusive",
    "text": "65.4 Considerazioni Conclusive\nL‚ÄôELPD e la divergenza \\(\\mathbb{KL}\\) sono strumenti complementari per la valutazione dei modelli statistici:\n\nELPD: Misura la capacit√† predittiva su nuovi dati. Pi√π alto √® l‚ÄôELPD, migliori sono le previsioni.\nDivergenza \\(\\mathbb{KL}\\): Quantifica la differenza tra la distribuzione vera dei dati e quella del modello. Una divergenza KL minore indica una migliore approssimazione.\n\nRelazione tra ELPD e divergenza \\(\\mathbb{KL}\\):\n\nUn alto ELPD generalmente corrisponde a una bassa divergenza \\(\\mathbb{KL}\\).\nMassimizzare l‚ÄôELPD equivale a minimizzare la divergenza \\(\\mathbb{KL}\\).\nEntrambi guidano verso modelli che catturano meglio la realt√† dei dati.\n\nNella pratica:\n\nLa divergenza \\(\\mathbb{KL}\\) valuta l‚Äôadattamento ai dati osservati.\nL‚ÄôELPD e i suoi metodi di approssimazione (LOO-CV, AIC, WAIC) misurano la capacit√† di generalizzazione a dati futuri.\n\nIn conclusione, l‚ÄôELPD, la divergenza \\(\\mathbb{KL}\\) e i relativi metodi di approssimazione forniscono un framework essenziale per la valutazione e la selezione di modelli statistici, bilanciando efficacemente l‚Äôadattamento ai dati con la capacit√† predittiva su nuove osservazioni.\n\nEsempio 65.3 Consideriamo un esempio numerico per confrontare AIC con la divergenza \\(\\mathbb{KL}\\). Supponiamo di avere un set di dati e due modelli statistici: il primo modello si adatta bene ai dati (modello vero), mentre il secondo √® un po‚Äô pi√π distante dalla realt√† (modello alternativo, ne considereremo 5). Calcoleremo la divergenza \\(\\mathbb{KL}\\) tra le distribuzioni previste da questi modelli e il Criterio di Informazione di Akaike per valutare la qualit√† di adattamento dei modelli.\nPer questo esempio, supponiamo di avere un set di dati e due modelli statistici: il primo modello si adatta bene ai dati (modello vero), mentre il secondo √® un po‚Äô pi√π distante dalla realt√† (modello alternativo). Calcoleremo la divergenza \\(\\mathbb{KL}\\) tra le distribuzioni previste da questi modelli e il Criterio di Informazione di Akaike per valutare la qualit√† di adattamento dei modelli.\n\nSupponiamo che i dati siano generati da una distribuzione normale con media vera \\(\\mu = 0\\) e deviazione standard \\(\\sigma = 1\\).\nAssumiamo che il modello vero conosca i parametri della distribuzione.\nAssumiamo che questo modello abbia una deviazione standard leggermente diversa (considereremo 5 modelli diversi: \\(\\sigma\\) = 1.5 fino a 5.0).\n\n\n# Generazione dei dati simulati\nnp.random.seed(42)\ndata = np.random.normal(loc=0, scale=1, size=1000)\n\n# Parametri del modello vero\nmu_true, sigma_true = 0, 1\n\n# Variazione di sigma_alt\nsigma_alts = np.linspace(1.5, 5.0, 5)\nKL_divergences = []\nAIC_values = []\n\n# Calcolo della divergenza KL e AIC per ogni sigma_alt\nfor sigma_alt in sigma_alts:\n    p_true = stats.norm.pdf(data, mu_true, sigma_true)\n    p_alt = stats.norm.pdf(data, mu_true, sigma_alt)\n    KL_divergence = np.sum(p_true * np.log(p_true / p_alt))\n    KL_divergences.append(KL_divergence)\n\n    log_likelihood_alt = np.sum(np.log(stats.norm.pdf(data, mu_true, sigma_alt)))\n    AIC_alt = (\n        2 * 2 - 2 * log_likelihood_alt\n    )  # 2 parametri (mu e sigma), nessuna esponenziale\n    AIC_values.append(AIC_alt)\n\n# Creazione del grafico\nplt.plot(sigma_alts, KL_divergences, label=\"Divergenza KL\", marker=\"o\")\nplt.plot(sigma_alts, AIC_values, label=\"AIC\", marker=\"x\")\nplt.xlabel(\"Sigma Alternativo\")\nplt.ylabel(\"Valore\")\nplt.title(\"Divergenza KL e AIC al variare di Sigma Alternativo\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi vede che, anche se la scala di misura √® diversa tra la divergenza \\(\\mathbb{KL}\\) e il criterio AIC, all‚Äôaumentare della differenza tra la distribuzione vera \\(P\\) e la distribuzione alternativa \\(Q\\), entrambi aumentano.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_31_kl.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_31_kl.html#informazioni-sullambiente-di-sviluppo",
    "title": "65¬† Divergenza KL e ELPD",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_32_stan_loo.html",
    "href": "chapters/chapter_5/05_32_stan_loo.html",
    "title": "66¬† Validazione Incrociata Leave-One-Out",
    "section": "",
    "text": "Introduzione\nCome evidenziato nel precedente capitolo, uno dei metodi pi√π efficaci e ampiamente utilizzati per stimare la Densit√† Predittiva Logaritmica Attesa (ELPD) √® la validazione incrociata Leave-One-Out (LOO-CV). Rispetto ad altri approcci che utilizzano l‚Äôintero set di dati per valutare le performance del modello, il metodo LOO-CV esclude una singola osservazione alla volta dal dataset, addestra il modello sui dati rimanenti e successivamente valuta la sua capacit√† di predire l‚Äôosservazione esclusa. Questo procedimento viene ripetuto per ogni osservazione presente nel dataset, fornendo cos√¨ un‚Äôanalisi dettagliata e approfondita della capacit√† del modello di generalizzare al di fuori dei dati osservati. Nel presente capitolo, esamineremo attentamente la metodologia LOO-CV e illustreremo come essa possa essere utilizzata per calcolare l‚ÄôELPD.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_32_stan_loo.html#il-problema-del-sovra-adattamento",
    "href": "chapters/chapter_5/05_32_stan_loo.html#il-problema-del-sovra-adattamento",
    "title": "66¬† Validazione Incrociata Leave-One-Out",
    "section": "66.1 Il Problema del Sovra-adattamento",
    "text": "66.1 Il Problema del Sovra-adattamento\nQuando costruiamo un modello statistico, uno dei problemi pi√π comuni che possiamo incontrare √® il sovra-adattamento (in inglese, ‚Äúoverfitting‚Äù). Ma cosa significa esattamente?\nImmaginate di provare a disegnare una linea che passi attraverso un gruppo di punti su un grafico. Se la linea passa esattamente per ogni singolo punto, potrebbe sembrare perfetta, vero? In realt√†, questo potrebbe essere un esempio di sovra-adattamento.\nIl sovra-adattamento si verifica quando un modello si adatta troppo bene ai dati che abbiamo usato per crearlo (chiamati ‚Äúdati di addestramento‚Äù). In questo processo, il modello inizia a catturare non solo le tendenze generali nei dati (il ‚Äúsegnale‚Äù), ma anche le fluttuazioni casuali o gli errori (il ‚Äúrumore‚Äù).\n\n66.1.1 Perch√© il sovra-adattamento √® un problema?\nUn modello sovra-adattato funzioner√† benissimo con i dati di addestramento, ma avr√† prestazioni scarse quando lo useremo con nuovi dati. √à come se il modello avesse ‚Äúimparato a memoria‚Äù i dati di addestramento invece di capire le regole generali che li governano.\nPer evitare il sovra-adattamento, dobbiamo trovare un equilibrio tra la capacit√† del modello di adattarsi ai dati di addestramento e la sua capacit√† di generalizzare a nuovi dati. Questo √® ci√≤ che chiamiamo il ‚Äútrade-off‚Äù tra bias e varianza.\n\n\n66.1.2 Tecniche di Validazione\nPer assicurarci che il nostro modello non stia sovra-adattandosi, usiamo delle tecniche chiamate ‚Äútecniche di validazione‚Äù. Una delle pi√π importanti √® la validazione incrociata (cross-validation).\n\n\n66.1.3 Validazione Incrociata (Cross-Validation)\nLa validazione incrociata √® come fare un ‚Äútest di realt√†‚Äù per il nostro modello. Invece di usare tutti i dati per addestrare il modello e poi testarlo, dividiamo i dati in parti e usiamo alcune parti per l‚Äôaddestramento e altre per il test, in modo ripetuto.\nCi sono diversi tipi di validazione incrociata, ma vediamo due dei pi√π comuni:\n\nK-fold cross-validation:\n\nImmaginate di avere un mazzo di carte. Le mescolate e le dividete in K gruppi (chiamate ‚Äúfold‚Äù).\nPrendete K-1 gruppi per addestrare il modello e usate il gruppo rimanente per testarlo.\nRipetete questo processo K volte, ogni volta usando un gruppo diverso per il test.\nAlla fine, fate la media dei risultati di tutti i test.\n\nPer esempio, se K = 5, dividerete i dati in 5 parti, addestrerete il modello su 4 parti e lo testerete sulla quinta, ripetendo questo processo 5 volte.\nLeave-one-out cross-validation (LOO-CV):\n\nQuesta √® una versione estrema della K-fold, dove K √® uguale al numero totale di osservazioni.\nPrendete tutti i dati tranne uno per addestrare il modello, e usate quello lasciato fuori per testarlo.\nRipetete questo processo per ogni singola osservazione nel dataset.\n\n√à come se steste giocando a ‚Äúindovina chi‚Äù con i vostri dati, cercando di prevedere ogni singola osservazione basandovi su tutte le altre.\n\nQueste tecniche ci aiutano a capire quanto bene il nostro modello si comporter√† con dati nuovi, che non ha mai visto prima.\n\n\n66.1.4 Criteri di Informazione\nOltre alla validazione incrociata, usiamo anche i ‚Äúcriteri di informazione‚Äù per valutare i nostri modelli. Questi criteri ci aiutano a bilanciare due aspetti importanti:\n\nquanto bene il modello si adatta ai dati;\nquanto √® complesso il modello.\n\nNel capitolo precedente abbiamo visto alcuni dei criteri pi√π comuni: il MSE, AIC, WAIC e LOO-CV.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_32_stan_loo.html#applicazioni-pratiche",
    "href": "chapters/chapter_5/05_32_stan_loo.html#applicazioni-pratiche",
    "title": "66¬† Validazione Incrociata Leave-One-Out",
    "section": "66.2 Applicazioni Pratiche",
    "text": "66.2 Applicazioni Pratiche\nNel contesto dell‚Äôinferenza bayesiana, la selezione del modello si basa principalmente sul confronto delle stime dell‚ÄôExpected Log Predictive Density (ELPD) ottenute attraverso la Cross-Validazione Leave-One-Out (LOO-CV). Questo processo pu√≤ essere efficacemente implementato utilizzando le funzioni fornite dal pacchetto ArviZ.\nPunti Chiave:\n\nConfronto dei Modelli:\n\nSi utilizzano le stime ELPD calcolate tramite LOO-CV.\nIl pacchetto ArviZ fornisce gli strumenti necessari per questi confronti.\n\nValidit√† dei Confronti:\n\nL‚Äôaffidabilit√† di questi confronti dipende dall‚Äôadeguatezza dei dati.\n√à cruciale che i modelli forniscano un adattamento sufficiente ai dati del campione.\n\nValutazione dell‚ÄôAdattamento:\n\nUn aspetto fondamentale √® il calcolo dei valori diagnostici Pareto \\(k\\).\nQuesti valori aiutano a valutare la qualit√† dell‚Äôadattamento del modello ai dati.\n\n\nNell‚Äôesempio successivo, vedremo come applicare questi concetti utilizzando cmdstan. Questo approccio pratico illustrer√† l‚Äôintero processo di selezione e valutazione del modello. Questo framework fornisce un metodo robusto per selezionare il modello pi√π appropriato, considerando sia la sua capacit√† predittiva che la sua adeguatezza ai dati osservati.\n\nEsempio 66.1 Generiamo un set di dati artificiali seguendo una distribuzione normale con una media (loc) di 5 e una deviazione standard (scale) di 2. Scegliamo una dimensione (size) del campione di 100.\n\ny = np.random.normal(loc=5, scale=2, size=100)\nprint(y[0:10])\n\n[4.4683817  6.45280554 8.60973205 5.47134851 7.02579291 5.90298401\n 5.43248972 5.47579654 5.03030772 3.19422982]\n\n\nUtilizziamo cmdstan per adattare un modello normale ai dati. Stimiamo la media (mu) e la deviazione standard (sigma) del modello attraverso il campionamento MCMC.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian-mod-log-lik.stan')\n\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Priors\n  mu ~ normal(5, 2);         // Prior for mu, centered around the known mean with some uncertainty\n  sigma ~ normal(0, 2);      // Half-normal prior for sigma (implying positive values)\n  \n  // Likelihood\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  for (n in 1:N)\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n}\n\n\n\n\nstan_data = {\n    'N': len(y), \n    'y': y\n}\n\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n5.22\n0.20\n4.84\n5.6\n0.0\n0.0\n6710.00\n5164.47\n1.0\n\n\nsigma\n2.01\n0.15\n1.75\n2.3\n0.0\n0.0\n7198.11\n5271.80\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_32_stan_loo.html#valori-diagnostici-pareto-k",
    "href": "chapters/chapter_5/05_32_stan_loo.html#valori-diagnostici-pareto-k",
    "title": "66¬† Validazione Incrociata Leave-One-Out",
    "section": "66.3 Valori Diagnostici Pareto \\(k\\)",
    "text": "66.3 Valori Diagnostici Pareto \\(k\\)\nI valori diagnostici Pareto \\(k\\) sono essenziali nell‚Äôanalizzare l‚Äôaffidabilit√† delle stime dell‚ÄôELPD ottenute tramite la validazione incrociata Leave-One-Out (LOO-CV). Questi valori indicano la precisione con cui la LOO-CV approssima l‚ÄôELPD, fornendo una misura di quanto ci possiamo fidare della stima rispetto a quella che otterremmo con un calcolo diretto e completo.\nLa LOO-CV √® una tecnica che stima come un modello statistico si comporterebbe nel prevedere nuovi dati basandosi su quelli esistenti. Il valore Pareto \\(k\\) ci dice quanto affidabile sia questa stima:\n\n\\(k &lt; 0.5\\): Mostra che l‚Äôapprossimazione √® eccellente e l‚Äôerrore nella stima dell‚ÄôELPD √® trascurabile.\n\\(0.5 \\leq k &lt; 0.7\\): Indica che l‚Äôapprossimazione √® accettabile, ma potrebbe essere opportuno esaminare pi√π a fondo il modello e i dati.\n\\(0.7 \\leq k &lt; 1\\): Suggerisce che l‚Äôapprossimazione sta diventando mediocre, rendendo i risultati della LOO-CV meno affidabili e potenzialmente inadeguati.\n\\(k \\geq 1\\): Un valore cos√¨ alto segnala un‚Äôapprossimazione inadeguata e suggerisce che i risultati ottenuti potrebbero essere molto lontani dalla realt√†, indicando la presenza di problemi nel modello o nella metodologia.\n\nIl valore di Pareto \\(k\\) si basa sulla distribuzione di Pareto per valutare le discrepanze nelle log-verosimiglianze, ovvero le differenze tra la log-verosimiglianza calcolata eliminando un dato e quella ottenuta sull‚Äôintero dataset. Valori elevati di \\(k\\) indicano che ci sono code pi√π pesanti del previsto nella distribuzione delle discrepanze, suggerendo che l‚Äôapprossimazione potrebbe non essere precisa.\nIn sintesi, i valori di Pareto \\(k\\) offrono un indicatore affidabile dell‚Äôaccuratezza dell‚Äôapprossimazione fornita dalla LOO-CV e sono utili per identificare eventuali problemi nel modello statistico o nella metodologia impiegata.\nConvertiamo l‚Äôoggetto creato da cmdstanpy nella classe InferenceData richiesta da ArviZ:\n\nfit_az = az.from_cmdstanpy(posterior=fit)\n\nEseguiamo LOO-CV usando ArviZ:\n\nloo_result = az.loo(fit_az)\nprint(loo_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -212.67     6.84\np_loo        1.90        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_32_stan_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "href": "chapters/chapter_5/05_32_stan_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "title": "66¬† Validazione Incrociata Leave-One-Out",
    "section": "66.4 Il Ruolo dell‚ÄôELPD nella Valutazione Comparativa dei Modelli",
    "text": "66.4 Il Ruolo dell‚ÄôELPD nella Valutazione Comparativa dei Modelli\nL‚ÄôELPD √® fondamentale per il confronto di diversi modelli statistici. Utilizzando metodologie come la LOO-CV per stimare l‚ÄôELPD, possiamo ottenere una valutazione oggettiva dell‚Äôadeguatezza di ciascun modello rispetto ai dati. Questo √® cruciale nella scelta del modello pi√π adatto tra diverse alternative o nel decidere se un modello pi√π complesso offre un miglior adattamento rispetto a uno pi√π semplice.\nIn conclusione, l‚ÄôELPD agisce come un indicatore affidabile della capacit√† predittiva di un modello. La LOO-CV, a sua volta, fornisce un modo efficace per stimare questa metrica, permettendo analisi precise e robuste delle prestazioni di diversi modelli. L‚Äôautomazione di queste procedure di valutazione attraverso software come PyMC e Arviz rende l‚Äôapproccio ancora pi√π pratico e accessibile, consolidandone il ruolo come strumento essenziale per la selezione e la validazione di modelli statistici.\n\n66.4.1 Simulazione\nPer illustrare il confronto tra modelli utilizzando la LOO-CV, procediamo con una simulazione. Genereremo dati sintetici in cui esiste una relazione lineare tra le variabili \\(x\\) e \\(y\\). In questo scenario, potremmo essere interessati a confrontare un modello lineare con un modello pi√π semplice, che considera solo il termine di intercetta. Utilizzeremo la LOO-CV per stabilire quale dei due modelli si adatta meglio ai dati in questione. La stima dell‚ÄôELPD servir√† come criterio quantitativo per orientare questa scelta di modello.\n\n# Generate synthetic data\nnp.random.seed(42)\nx = np.linspace(0, 10, 100)\ny_true = 3 + 2 * x\ny_obs = y_true + np.random.normal(scale=3, size=100)\nzx = stats.zscore(x)\nzy = stats.zscore(y_obs)\nprint(np.mean(zy), np.std(zy))\n\n-2.19824158875781e-16 1.0\n\n\nAdattiamo ai dati un modello che rispecchia il vero meccanismo generativo dei dati.\nSi noti che, per calcolare LOO e WAIC, ArviZ ha bisogno di accedere alla log-likelihood per ogni campione posteriore. Possiamo trovarla tramite compute_log_likelihood(). In alternativa, possiamo passare idata_kwargs={\"log_likelihood\": True} a sample() per farla calcolare automaticamente alla fine del campionamento.\n\nstan_lin_reg_file = os.path.join(\n    project_directory, 'stan', 'linear-regression.stan')\n\nmodel_lin_reg = CmdStanModel(stan_file=stan_lin_reg_file)\nprint(model_lin_reg.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha + beta * x[n], sigma);\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\n\n# Prepare the stan_data dictionary\nstan_data = {\n    'N': len(zx),\n    'x': zx,\n    'y': zy\n}\nprint(stan_data)\n\n{'N': 100, 'x': array([-1.71481604, -1.68017329, -1.64553055, -1.6108878 , -1.57624505,\n       -1.5416023 , -1.50695955, -1.4723168 , -1.43767406, -1.40303131,\n       -1.36838856, -1.33374581, -1.29910306, -1.26446031, -1.22981757,\n       -1.19517482, -1.16053207, -1.12588932, -1.09124657, -1.05660382,\n       -1.02196108, -0.98731833, -0.95267558, -0.91803283, -0.88339008,\n       -0.84874733, -0.81410459, -0.77946184, -0.74481909, -0.71017634,\n       -0.67553359, -0.64089084, -0.6062481 , -0.57160535, -0.5369626 ,\n       -0.50231985, -0.4676771 , -0.43303435, -0.39839161, -0.36374886,\n       -0.32910611, -0.29446336, -0.25982061, -0.22517786, -0.19053512,\n       -0.15589237, -0.12124962, -0.08660687, -0.05196412, -0.01732137,\n        0.01732137,  0.05196412,  0.08660687,  0.12124962,  0.15589237,\n        0.19053512,  0.22517786,  0.25982061,  0.29446336,  0.32910611,\n        0.36374886,  0.39839161,  0.43303435,  0.4676771 ,  0.50231985,\n        0.5369626 ,  0.57160535,  0.6062481 ,  0.64089084,  0.67553359,\n        0.71017634,  0.74481909,  0.77946184,  0.81410459,  0.84874733,\n        0.88339008,  0.91803283,  0.95267558,  0.98731833,  1.02196108,\n        1.05660382,  1.09124657,  1.12588932,  1.16053207,  1.19517482,\n        1.22981757,  1.26446031,  1.29910306,  1.33374581,  1.36838856,\n        1.40303131,  1.43767406,  1.4723168 ,  1.50695955,  1.5416023 ,\n        1.57624505,  1.6108878 ,  1.64553055,  1.68017329,  1.71481604]), 'y': array([-1.25369697, -1.51410888, -1.12264904, -0.69018101, -1.46541976,\n       -1.43451905, -0.57172677, -0.91324793, -1.44980379, -0.95462592,\n       -1.38523884, -1.35540634, -0.99984973, -1.95770364, -1.84039662,\n       -1.27613083, -1.45193071, -0.81222207, -1.34206267, -1.54251469,\n       -0.19132131, -0.9363926 , -0.77094195, -1.42465105, -0.98987813,\n       -0.65835464, -1.20638283, -0.47509892, -0.89211361, -0.71948769,\n       -0.83081717,  0.32587522, -0.49918168, -0.94733587, -0.05384951,\n       -0.96038888, -0.27359788, -1.23754931, -0.91695414, -0.18642458,\n        0.09293748, -0.13633347, -0.23711307, -0.29130011, -0.80056374,\n       -0.42161671, -0.27180948,  0.4553774 ,  0.15894085, -0.77662445,\n        0.21176558, -0.082681  , -0.18567329,  0.43638204,  0.65964551,\n        0.64479105, -0.13655587,  0.13748445,  0.46220469,  0.78867095,\n        0.15219165,  0.31773898, -0.07374059, -0.08407726,  0.86834951,\n        1.14867904,  0.52434286,  1.04865616,  0.78507034,  0.35410049,\n        0.84674641,  1.41743978,  0.72630189,  1.49143251, -0.3973201 ,\n        1.21247617,  0.90624433,  0.76002975,  0.97019317,  0.04716531,\n        0.88910552,  1.18460649,  1.72967356,  0.84479898,  0.7425482 ,\n        0.91416098,  1.59519538,  1.35695436,  0.99399369,  1.50339012,\n        1.34335048,  1.77408719,  1.03852468,  1.24117485,  1.24250254,\n        0.78187315,  1.62002314,  1.63482977,  1.54830613,  1.46923337])}\n\n\n\nfit2 = model_lin_reg.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit2, var_names=['beta', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta\n0.91\n0.04\n0.82\n0.99\n0.0\n0.0\n7552.03\n5699.11\n1.0\n\n\nsigma\n0.42\n0.03\n0.37\n0.48\n0.0\n0.0\n7001.46\n5200.57\n1.0\n\n\n\n\n\n\n\n\nReplichiamo i risultati usando le funzioni di pingouin:\n\n# Create a DataFrame\ndf = pd.DataFrame({\n    \"x\": zx,\n    \"y\": zy\n})\n\n# Perform linear regression using pingouin\nregression_results = pg.linear_regression(df[['x']], df['y'])\n\n# Print the regression results\nprint(regression_results)\n\n       names          coef        se             T          pval        r2  \\\n0  Intercept -2.220446e-16  0.041834 -5.307754e-15  1.000000e+00  0.828492   \n1          x  9.102152e-01  0.041834  2.175778e+01  2.661609e-39  0.828492   \n\n     adj_r2  CI[2.5%]  CI[97.5%]  \n0  0.826742 -0.083018   0.083018  \n1  0.826742  0.827197   0.993233  \n\n\nTroviamo ELPD con il metodo LOO-CV per il modello lineare.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit2_az = az.from_cmdstanpy(posterior=fit2)\n# Perform LOO-CV using ArviZ\nloo2_result = az.loo(fit2_az)\nprint(loo2_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -56.81     6.89\np_loo        2.87        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nAdattiamo ora un secondo modello che non tiene conto della relazione lineare tra \\(x\\) e \\(y\\).\n\nstan_lin_reg_file_only_alpha = os.path.join(\n    project_directory, 'stan', 'linear-regression-only-alpha.stan')\n\nmodel_lin_reg_only_alpha = CmdStanModel(stan_file=stan_lin_reg_file_only_alpha)\nprint(model_lin_reg_only_alpha.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha, sigma);\n  alpha ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha, sigma);\n    y_rep[n] = normal_rng(alpha, sigma);\n  }\n}\n\n\n\n\nfit3 = model_lin_reg_only_alpha.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit3, var_names=['alpha', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.00\n0.10\n-0.19\n0.20\n0.0\n0.0\n6612.61\n5300.73\n1.0\n\n\nsigma\n1.02\n0.07\n0.88\n1.15\n0.0\n0.0\n6998.01\n5550.97\n1.0\n\n\n\n\n\n\n\n\nTroviamo ora ELPD con il metodo LOO-CV per il modello che ignora la relazione lineare.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit3_az = az.from_cmdstanpy(posterior=fit3)\n# Perform LOO-CV using ArviZ\nloo3_result = az.loo(fit3_az)\nprint(loo3_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -143.63     4.52\np_loo        1.40        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nInfine, calcoliamo eldp_diff. L‚Äôincertezza di questa quantit√† √® espressa dall‚Äôerrore standard. Se il rapporto tra eldp_diff e il suo errore standard √® almeno uguale a 2, allora possiamo concludere che vi √® una differenza credibile tra di due modelli.\n\ndf_comp_loo = az.compare({\"linear_model\": loo2_result, \"intercept_model\": loo3_result})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nlinear_model\n0\n-56.814716\n2.873961\n0.000000\n1.000000e+00\n6.890641\n0.000000\nFalse\nlog\n\n\nintercept_model\n1\n-143.633507\n1.403145\n86.818792\n2.428635e-11\n4.516124\n7.956892\nFalse\nlog\n\n\n\n\n\n\n\n\nNel caso presente, sappiamo che il modello che include una relazione lineare tra le due variabili √® quello che rispecchia il modo in cui i dati sono stati generati. Infatti, troviamo che il rapporto tra eldp_diff e il suo errore standard √® molto maggiore di 2, il che conferma che, per questi dati, il modello lineare √® da preferire al modello che include solo l‚Äôintercetta.\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_32_stan_loo.html#riflessioni-conclusive",
    "href": "chapters/chapter_5/05_32_stan_loo.html#riflessioni-conclusive",
    "title": "66¬† Validazione Incrociata Leave-One-Out",
    "section": "66.5 Riflessioni Conclusive",
    "text": "66.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il metodo della Validazione Incrociata LOO-CV come strumento efficace per stimare l‚ÄôELPD. Abbiamo illustrato in dettaglio come la LOO-CV possa essere applicata utilizzando il framework cmdstan, evidenziando il suo ruolo cruciale nella pratica della modellazione statistica.\nUn aspetto centrale che abbiamo esaminato √® l‚Äôimportanza della LOO-CV nel contesto del confronto tra diversi modelli statistici. Questo metodo non solo aiuta a valutare la capacit√† predittiva di un singolo modello, ma si rivela anche essenziale quando si tratta di selezionare il modello pi√π adatto tra un insieme di alternative, fornendo una base di confronto oggettiva e affidabile.\nInoltre, abbiamo discusso il ruolo significativo dei valori diagnostici Pareto \\(k\\) nell‚Äôinterpretazione delle stime ottenute tramite LOO-CV. Abbiamo sottolineato come questi valori siano fondamentali per valutare l‚Äôaffidabilit√† delle stime di ELPD derivate dalla LOO-CV, offrendo una misura della precisione e della robustezza di queste stime.\nNel complesso, attraverso questo capitolo, abbiamo mirato a fornire una comprensione completa di come la LOO-CV e i valori diagnostici Pareto \\(k\\) siano impiegati per migliorare la precisione e l‚Äôaffidabilit√† delle stime di ELPD, migliorando cos√¨ la qualit√† e l‚Äôefficacia dei modelli statistici in vari contesti di ricerca e applicazione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_32_stan_loo.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_32_stan_loo.html#informazioni-sullambiente-di-sviluppo",
    "title": "66¬† Validazione Incrociata Leave-One-Out",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_35_missing.html",
    "href": "chapters/chapter_5/05_35_missing.html",
    "title": "67¬† Dati mancanti",
    "section": "",
    "text": "Introduzione\nNel campo della data science, la gestione dei dati mancanti rappresenta una sfida cruciale e una competenza fondamentale per gli analisti e i ricercatori. I dati mancanti non sono solo una comune occorrenza nei dataset reali, ma possono anche avere un impatto significativo sulla qualit√† delle analisi, sulle inferenze tratte e sulle decisioni basate su tali dati. L‚Äôimportanza di affrontare correttamente i dati mancanti risiede nella necessit√† di mantenere l‚Äôintegrit√† delle analisi statistiche e di evitare conclusioni errate o distorte. Una gestione appropriata dei dati mancanti permette di migliorare l‚Äôaccuratezza dei modelli predittivi, di aumentare la robustezza delle analisi e di garantire che le decisioni basate sui dati siano informate e affidabili. Pertanto, comprendere le cause dei dati mancanti, conoscere le diverse tipologie di assenza dei dati, come classificato nella tassonomia di Rubin, e applicare le tecniche di trattamento pi√π adeguate sono competenze essenziali nella data science per massimizzare il valore estratto dai dati disponibili.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_35_missing.html#la-tassonomia-di-rubin",
    "href": "chapters/chapter_5/05_35_missing.html#la-tassonomia-di-rubin",
    "title": "67¬† Dati mancanti",
    "section": "67.1 La tassonomia di Rubin",
    "text": "67.1 La tassonomia di Rubin\nLa tassonomia dei dati mancanti di Rubin introduce una classificazione che aiuta a comprendere e gestire le situazioni in cui i dati non sono completamente disponibili. Questa classificazione √® particolarmente rilevante in ambiti come la statistica, la ricerca scientifica e l‚Äôanalisi dei dati, dove la presenza di dati mancanti pu√≤ influenzare significativamente i risultati degli studi. La tassonomia identifica tre categorie principali: Dati Mancanti Completamente a Caso (MCAR), Dati Mancanti a Caso (MAR) e Dati Mancanti Non a Caso (MNAR). Ognuna di queste categorie si basa su specifiche assunzioni relative alla probabilit√† condizionata che un dato sia mancante. Vediamo nel dettaglio:\n\nDati Mancanti Completamente a Caso (MCAR): Questa categoria rappresenta la situazione meno problematica tra le tre. L‚Äôassunzione MCAR suggerisce che la mancanza di dati avviene in modo completamente casuale, senza alcuna relazione sia con i dati osservati che con quelli non osservati. La mancanza √® attribuibile a circostanze casuali e non legate alle caratteristiche dei dati stessi. In pratica, questo significa che la probabilit√† che un dato sia mancante √® la stessa per tutte le osservazioni. Quando i dati sono MCAR, le tecniche di analisi possono procedere senza introdurre distorsioni significative nei risultati.\nDati Mancanti a Caso (MAR): In questa categoria, la probabilit√† che un dato sia mancante pu√≤ dipendere dai dati osservati, ma non da quelli non osservati. Questo tipo di mancanza viene considerato ‚Äúignorabile‚Äù perch√©, conoscendo i dati osservati, √® possibile procedere con l‚Äôanalisi senza compromettere l‚Äôaffidabilit√† delle inferenze, sebbene possa esserci una perdita di precisione. Questa situazione si verifica quando la ragione della mancanza di dati √® correlata a qualche caratteristica osservabile nel dataset, permettendo di gestire la mancanza attraverso l‚Äôanalisi dei dati disponibili.\nDati Mancanti Non a Caso (MNAR): Questa √® la situazione pi√π complessa e potenzialmente problematica. I dati sono considerati MNAR quando la probabilit√† che un dato sia mancante dipende dalle informazioni non osservate. Ci√≤ significa che la mancanza di dati √® correlata a valori che non sono noti o osservabili, rendendo pi√π difficile l‚Äôimputazione e l‚Äôanalisi. Le tecniche standard di gestione dei dati mancanti potrebbero introdurre distorsioni significative nei risultati a causa del rischio di confondimento. La gestione dei dati MNAR richiede metodi avanzati e cautela nell‚Äôinterpretazione dei risultati.\n\nLe assunzioni su cui si basa questa tassonomia sono fondamentali per scegliere il metodo di trattamento dei dati mancanti pi√π appropriato. Tuttavia, √® importante notare che queste assunzioni sono intrinsecamente non verificabili. L‚Äôanalisi e le conclusioni di uno studio dipenderanno dalla plausibilit√† di queste assunzioni nel contesto specifico in cui vengono applicate. La scelta di come trattare i dati mancanti dovrebbe quindi essere attentamente considerata e giustificata nel contesto della ricerca.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_35_missing.html#un-esempio-empirico",
    "href": "chapters/chapter_5/05_35_missing.html#un-esempio-empirico",
    "title": "67¬† Dati mancanti",
    "section": "67.2 Un Esempio Empirico",
    "text": "67.2 Un Esempio Empirico\nL‚Äôanalisi e il trattamento dei dati mancanti rivestono un ruolo cruciale nell‚Äôinterpretazione dei risultati di uno studio. Esaminiamo i diversi scenari di dati mancanti che hai delineato, prendendo spunto dall‚Äôesempio metaforico del ‚Äúcane che mangia i compiti‚Äù, presentato nel tutorial di Dustin Stansbury.\n\n67.2.1 1. Perdita di Dati Casuale e Indipendente dalle Cause\n\nEsempio: Il fenomeno del ‚Äúcane che mangia i compiti‚Äù avviene in maniera casuale.\nConseguenze: In questa situazione, la perdita di dati √® classificata come ‚ÄúMissing Completely At Random‚Äù (MCAR), ovvero l‚Äôassenza di dati non √® in alcun modo correlata n√© alle variabili osservate n√© a quelle non osservate.\nGestione: √à possibile eliminare i casi con dati mancanti senza introdurre distorsioni, bench√© ci√≤ possa ridurre l‚Äôefficienza dello studio a causa della diminuzione della dimensione del campione.\n\n\n# Helper function to plot regression line\ndef plot_regression_line(x, y, color, label, **plot_kwargs):\n    valid_idx = ~np.isnan(y)\n    \n    X = np.vstack((np.ones_like(x[valid_idx]), x[valid_idx])).T\n    intercept, slope = np.linalg.lstsq(X, y[valid_idx], rcond=None)[0]\n    \n    xs = np.linspace(x.min(), x.max(), 10)\n    ys = xs * slope + intercept\n    plt.plot(xs, ys, color=color, label=label, **plot_kwargs)\n\n# Function to plot dog homework data\ndef plot_dog_homework(S, H, Hstar, title=None):\n    \n    # Plot S vs H\n    plt.scatter(S, H, color='k', alpha=1, label='total', s=10)\n    plot_regression_line(S, H, label='total trend', color='k', alpha=.5)\n    \n    # Plot S vs Hstar\n    plt.scatter(S, Hstar, color='C0', alpha=.8, label='incomplete')\n    plot_regression_line(S, Hstar, label='incomplete trend', color='C0', alpha=.5)\n    \n    # Set labels and title\n    plt.xlabel(\"S\")\n    plt.ylabel(\"H\")\n    if title is not None:\n        plt.title(title)\n    plt.legend()\n\n    plt.show()  # Display the plot\n\n\nnp.random.seed(123)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 50% of of homework _at random_\nD = stats.bernoulli(0.5).rvs(size=n_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Random missing data\\ncauses loss of precision; little/no bias\")\n\n\n\n\n\n\n\n\nIn scenari di dati mancanti completamente a caso, si verifica una perdita di precisione, ma, mediamente, l‚Äôanalisi non risulta distorta.\n\n\n67.2.2 2. Perdita di Dati Condizionata dalle Cause\n\nEsempio: Il cane mangia i compiti in base alle abitudini di studio dello studente, ad esempio se lo studente trascura di nutrire il cane dopo aver studiato intensamente.\nConseguenze: Questo caso √® definito come ‚ÄúMissing At Random‚Äù (MAR), in cui la probabilit√† di perdita di dati √® correlata a variabili osservabili.\nGestione: √à necessario adeguare l‚Äôanalisi in base alla causa per prevenire distorsioni. L‚Äôimpiego di modelli statistici che considerano le variabili legate alla mancanza di dati pu√≤ risultare efficace.\n\nIn una prima simulazione, il trattamento (competenza dello studente) e l‚Äôeffetto (qualit√† del compito) hanno una relazione lineare. Questo scenario √® molto raro.\n\nnp.random.seed(12)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between student ability and homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats based on the student's ability\np_dog_eats_homework = np.where(S &gt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on common cause\\nmay work for linear relationships (rare) \")\n\n\n\n\n\n\n\n\nQuando l‚Äôassociazione tra abilit√† degli studenti e punteggio dei compiti √® lineare, l‚Äôadattamento dal campione completo e da quello incompleto pu√≤ risultare simile, con una perdita di precisione solo agli estremi del campione.\nConsideriamo ora il caso in cui il trattamento (capacit√† dello studente) e l‚Äôeffetto (caratteristiche del compito) non sono associati linearmente. Questo scenario √® molto pi√π comune.\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Nonlinear association between student ability and homework score\nmu_score = 1 - np.exp(-0.7 * S)\nH = stats.norm.rvs(mu_score)\n\n# Dog eats all the homework of above-average students\np_dog_eats_homework = np.where(S &gt; 0, 1, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data based on common cause\\nvery bady for non-linear relationships (common)\")\n\n\n\n\n\n\n\n\nIn un tale scenario, l‚Äôadattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l‚Äôanalisi del campione incompleto produce un risultato distorto.\n\n\n67.2.3 3. Perdita di Dati Condizionata dal Risultato\n\nEsempio: Il cane mangia i compiti in base al punteggio ottenuto.\nConseguenze: Questo scenario √® classificato come ‚ÄúMissing Not At Random‚Äù (MNAR), in cui la perdita di dati √® direttamente correlata al risultato mancante, complicando significativamente la gestione.\nGestione: Spesso, affrontare questa situazione richiede di modellare il processo causale alla base della perdita di dati, utilizzando tecniche come l‚Äôanalisi di sopravvivenza o l‚Äôimpiego di dati censurati.\n\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between ability and score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 90% of homework that is below average\np_dog_eats_homework = np.where(H &lt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on outcome state\\nusually not benign\")\n\n\n\n\n\n\n\n\nl‚Äôadattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l‚Äôanalisi del campione incompleto produce un risultato distorto. La situazione √® simile a quella precedene in cui la relazione tra cause e risultati non era lineare.\nSenza conoscere la relazione causale tra il risultato e la perdita di dati, e le forme funzionali di come X √® associato con Y, √® difficile tenere conto di questo scenario.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_35_missing.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/chapter_5/05_35_missing.html#commenti-e-considerazioni-conclusive",
    "title": "67¬† Dati mancanti",
    "section": "67.3 Commenti e considerazioni conclusive",
    "text": "67.3 Commenti e considerazioni conclusive\nIn conclusione, la strategia di gestione dei dati mancanti varia a seconda della loro relazione con le variabili nel modello causale. Comprendere la natura della perdita di dati √® vitale per scegliere l‚Äôapproccio analitico corretto e per interpretare con precisione i risultati dello studio. Solo nel caso di dati mancanti completamente a caso, l‚Äôanalisi che ignora la mancanza di dati produce risultati affidabili.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_35_missing.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_35_missing.html#informazioni-sullambiente-di-sviluppo",
    "title": "67¬† Dati mancanti",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib : 3.8.4\npandas     : 2.2.2\nstatsmodels: 0.14.2\narviz      : 0.18.0\nnumpy      : 1.26.4\nseaborn    : 0.13.2\nxarray     : 2024.5.0\nscipy      : 1.13.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "",
    "text": "Introduzione\nIn questa sezione delle dispense abbiamo esaminato il modello di regressione. Sebbene il modello di regressione sia estremamente popolare in psicologia e nelle scienze sociali, presenta dei limiti sostanziali. √à utile per descrivere le associazioni tra variabili, ma non √® adatto per scoprire nessi causali, che rappresentano l‚Äôobiettivo principale delle teorie scientifiche. Come afferma Richard McElreath:\nTrovare associazioni nei dati osservazionali non √® un buon metodo per costruire teorie. Abbiamo bisogno di una motivazione per esaminare determinate variabili, poich√© le associazioni tra variabili non sono rare, ma raramente sono causali. Il fatto che nessuno abbia esaminato l‚Äôassociazione tra certe variabili in precedenza non √® un buon motivo per farlo in un nuovo progetto di ricerca.\nUn approccio preferibile, che una volta era comune, √® utilizzare una teoria formale per sviluppare aspettative sui dati osservati, misurare le variabili corrette e utilizzare modelli statistici specifici per testare la teoria, non solo regressioni.\nIn questo capitolo, forniremo un esempio di questo approccio implementando un modello che rappresenta un processo cognitivo sottostante, piuttosto che limitarsi a descrivere le associazioni tra variabili. Nello specifico, esamineremo uno dei modelli psicologici pi√π influenti: il modello di apprendimento di Rescorla-Wagner. Analizzeremo la definizione del modello, il significato dei suoi parametri e i metodi per stimarli dai dati osservati, con particolare attenzione all‚Äôuso della massima verosimiglianza e del software Stan.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#introduzione",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#introduzione",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "",
    "text": "Le persone una volta facevano teoria. Ora fanno solo regressioni.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#lapprendimento-per-rinforzo-imparare-dallesperienza",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#lapprendimento-per-rinforzo-imparare-dallesperienza",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.1 L‚Äôapprendimento per rinforzo: imparare dall‚Äôesperienza",
    "text": "68.1 L‚Äôapprendimento per rinforzo: imparare dall‚Äôesperienza\nImmagina un robot alle prese con un videogioco, privo di istruzioni precise ma con un obiettivo ben chiaro: ottenere il punteggio pi√π alto. Attraverso tentativi ed errori, il robot sperimenta diverse azioni, scoprendo quali lo avvicinano al successo e quali no. Questo √® il principio fondamentale dell‚Äôapprendimento per rinforzo (RL), un metodo di intelligenza artificiale ispirato al modo in cui gli esseri viventi imparano.\n\n68.1.1 Il meccanismo alla base dell‚Äôapprendimento per rinforzo\nNell‚Äôapprendimento per rinforzo, un ‚Äúagente‚Äù (che sia un robot, un modello matematico o una persona) interagisce con un ‚Äúambiente‚Äù. L‚Äôagente compie azioni e riceve in cambio ‚Äúricompense‚Äù positive o negative, a seconda di quanto le sue azioni sono vicine al raggiungimento del suo obiettivo. L‚Äôobiettivo dell‚Äôagente √® imparare a scegliere le azioni che gli permetteranno di ottenere il maggior numero di ricompense positive nel tempo.\n\n\n68.1.2 Esplorazione e sfruttamento\nUno dei dilemmi principali che gli agenti di apprendimento per rinforzo si trovano ad affrontare √® il bilanciamento tra esplorazione e sfruttamento. Da un lato, l‚Äôagente ha bisogno di esplorare l‚Äôambiente, provare nuove azioni e scoprire nuove strategie per ottenere ricompense. Dall‚Äôaltro lato, desidera anche sfruttare la conoscenza gi√† acquisita, scegliendo le azioni che ha gi√† scoperto essere efficaci in passato.\n\n\n68.1.3 L‚Äôapprendimento per rinforzo nella ricerca sull‚Äôintelligenza artificiale\nDalla fine degli anni ‚Äô60, molti ricercatori nel campo dell‚Äôintelligenza artificiale hanno ipotizzato che non esistano principi generali da scoprire, e che l‚Äôintelligenza derivi piuttosto dalla conoscenza di un vasto numero di trucchi, procedure ed euristiche specializzati. L‚Äôintelligenza artificiale moderna dedica invece molta attenzione alla ricerca di principi generali di apprendimento e processo decisionale. In questo senso, la ricerca sull‚Äôapprendimento per rinforzo rappresenta sicuramente un ritorno verso principi di intelligenza artificiale pi√π semplici e universali.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#un-esempio-pratico-il-problema-dei-two-armed-bandits",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#un-esempio-pratico-il-problema-dei-two-armed-bandits",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.2 Un esempio pratico: il problema dei two-armed bandits",
    "text": "68.2 Un esempio pratico: il problema dei two-armed bandits\nImmaginiamo un giocatore di fronte a due slot machine. Ogni volta che sceglie una slot, pu√≤ vincere (ottenendo un premio) o perdere (non ottenendo nulla). La probabilit√† di vincita varia tra le due slot machine, ma il giocatore non le conosce all‚Äôinizio. Il suo obiettivo √® massimizzare le vincite scegliendo la slot machine con la maggiore probabilit√† di vincita il pi√π spesso possibile.\nQuesto semplice problema illustra il dilemma fondamentale dell‚Äôapprendimento per rinforzo: esplorare entrambe le slot machine per scoprire quale √® la migliore (esplorazione) o sfruttare la slot machine che ha gi√† scoperto essere la pi√π vincente (sfruttamento)?\nIl modello di apprendimento di Rescorla-Wagner affronta proprio questo problema del ‚Äútwo-armed bandits‚Äù. In questo scenario, un partecipante deve compiere ripetutamente delle scelte tra due opzioni o azioni. Dopo ogni scelta, riceve una ricompensa numerica estratta da una distribuzione di probabilit√† che dipende dall‚Äôazione selezionata. L‚Äôobiettivo del partecipante √® massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte.\nUna metafora comune per descrivere questa situazione √® quella di un giocatore che deve fare una serie di scelte tra due slot machine (‚Äútwo-armed bandits‚Äù) per massimizzare le sue vincite. Se nella scelta \\(t\\) viene selezionata la slot machine \\(k\\), il partecipante ottiene una ricompensa \\(r_t\\). Questa ricompensa ha valore 1 con una probabilit√† di successo \\(\\mu^k_t\\) specifica per quella slot machine, altrimenti ha valore 0.\nIn altre parole:\n\nOgni volta che il partecipante sceglie una slot machine, pu√≤ vincere (ottenendo una ricompensa di 1) o perdere (ottenendo una ricompensa di 0).\nLa probabilit√† di vincita varia tra le due diverse slot machine.\nQueste probabilit√† di successo sono inizialmente sconosciute al partecipante.\n\nNella versione pi√π semplice di questo problema, le probabilit√† di successo \\(\\mu^k_t\\) rimangono costanti nel tempo. Questo significa che la probabilit√† di vincere su una determinata slot machine non cambia durante il periodo di osservazione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#simulare-lapprendimento",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#simulare-lapprendimento",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.3 Simulare l‚ÄôApprendimento",
    "text": "68.3 Simulare l‚ÄôApprendimento\nNel problema del two-armed bandit, ogni azione (cio√® la scelta di una specifica slot machine) ha un valore associato che rappresenta la ricompensa attesa quando quella specifica azione viene selezionata. Questo valore √® chiamato ‚Äúvalore dell‚Äôazione‚Äù. Conoscendo il valore di ogni azione, il problema di apprendimento si riduce a scegliere sempre l‚Äôazione con il valore pi√π alto per massimizzare la ricompensa totale.\n\n68.3.1 Parametri del Problema\nPer simulare il problema, dobbiamo considerare tre parametri principali:\n\nIl numero di tentativi, \\(T\\): Questo rappresenta quante volte il partecipante far√† una scelta. Ad esempio, se \\(T = 100\\), il partecipante far√† 100 scelte.\nIl numero di slot machine, \\(K\\): Questo indica quante opzioni di scelta sono disponibili. Ad esempio, se \\(K = 2\\), ci sono due slot machine tra cui scegliere.\nLe probabilit√† di ricompensa delle diverse opzioni, \\(\\mu^k_t\\): Queste sono le probabilit√† che ogni slot machine offra una ricompensa. Queste probabilit√† possono variare nel tempo, ma nella versione pi√π semplice del problema, rimangono costanti.\n\n\n\n68.3.2 Esempio Pratico\nIn questo tutorial, simuleremo il comportamento di un partecipante che sceglie tra due slot machine, utilizzando il modello di apprendimento di Rescorla-Wagner. Ecco come configureremo la simulazione:\n\nImposteremo il numero di tentativi a \\(T = 100\\). Questo significa che il partecipante far√† 100 scelte.\nImposteremo il numero di slot machine a \\(K = 2\\). Ci saranno quindi due slot machine tra cui scegliere.\nImposteremo le probabilit√† di ricompensa delle slot machine a \\(\\mu = [0.2, 0.8]\\). Questo significa che la slot machine 1 ha una probabilit√† del 20% di offrire una ricompensa, mentre la slot machine 2 ha una probabilit√† dell‚Äô80% di offrire una ricompensa.\n\nOgni azione ha un valore che rappresenta la ricompensa attesa. In altre parole, il valore dell‚Äôazione √® la media delle ricompense che ci si aspetta di ottenere scegliendo quella particolare azione. Se si conosce questo valore per ogni azione, il partecipante dovrebbe sempre scegliere l‚Äôazione con il valore pi√π alto per massimizzare le sue ricompense.\nL‚Äôobiettivo di questo tutorial √® mostrare come si pu√≤ simulare il processo di apprendimento e come si possono usare modelli come quello di Rescorla-Wagner per capire meglio come le persone prendono decisioni in situazioni di incertezza. Attraverso la simulazione, vedremo come il partecipante pu√≤ apprendere e adattarsi alle probabilit√† di ricompensa delle slot machine per massimizzare le sue vincite nel corso del tempo.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#imparare-il-rinforzo-i-componenti-chiave",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#imparare-il-rinforzo-i-componenti-chiave",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.4 Imparare il rinforzo: i componenti chiave",
    "text": "68.4 Imparare il rinforzo: i componenti chiave\nL‚Äôapprendimento per rinforzo √® simile a come gli esseri viventi imparano attraverso l‚Äôesperienza: provando e sbagliando, imparano ad associare le loro azioni a conseguenze positive o negative.\nPer comprendere meglio il funzionamento dell‚Äôapprendimento per rinforzo, √® fondamentale analizzare i suoi quattro componenti chiave.\n1. La politica (o strategia) Il robot non agisce a caso. Ha una strategia, un piano d‚Äôazione che cambia nel tempo in base ai risultati ottenuti. Inizialmente, potrebbe scegliere le slot casualmente (50% leva A, 50% leva B). Ma con l‚Äôesperienza, impara a preferire la leva che gli ha dato pi√π vincite. In termini tecnici, la strategia √® rappresentata dalla funzione œÄ (pi), che associa le azioni possibili (tirare la leva A o B) ai diversi stati del gioco (vincita, perdita). All‚Äôinizio, œÄ potrebbe essere casuale. Ma con il tempo, si aggiorna in base alle ricompense ricevute, aumentando la probabilit√† di scegliere la leva vincente.\n2. La ricompensa La ricompensa √® un segnale che indica all‚Äôagente la bont√† o meno delle sue azioni. La ricompensa pu√≤ essere positiva (rinforzo) se l‚Äôazione √® stata vantaggiosa, o negativa (punizione) se l‚Äôazione √® stata dannosa. L‚Äôobiettivo dell‚Äôagente √® massimizzare la ricompensa cumulativa nel lungo periodo. In termini tecnici, la funzione di ricompensa R assegna un valore numerico a ogni stato del gioco: 1 per la vincita e 0 per la perdita. Il robot √® ‚Äúmotivato‚Äù a massimizzare la ricompensa cumulativa, ovvero la somma totale delle vincite ottenute nel tempo.\n3. La funzione di valore Per ogni leva, il robot calcola la ricompensa media che si aspetta di ricevere in futuro. In altre parole, cerca di capire quale slot √® pi√π ‚Äúgenerosa‚Äù nel lungo periodo. In termini tecnici, la funzione di valore Q stima la ricompensa media attesa per ogni stato del gioco. Il robot utilizza questa stima per scegliere l‚Äôazione che lo porter√† nello stato con il valore Q pi√π alto, ovvero la slot machine che ha maggiori probabilit√† di fargli ottenere una vincita nel lungo periodo.\n4. Il modello dell‚Äôambiente In alcuni casi, il robot pu√≤ avere un asso nella manica: un modello dell‚Äôambiente, ovvero una simulazione dell‚Äôambiente che permette all‚Äôagente di prevedere le conseguenze delle sue azioni prima di compierle. In termini tecnici, il modello dell‚Äôambiente M √® una simulazione delle slot machine che permette al robot di prevedere la probabilit√† di vincita per ogni leva. Il robot pu√≤ utilizzare questa informazione per aggiornare la sua funzione di valore e scegliere l‚Äôazione che massimizza la ricompensa attesa.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#modello-di-apprenimento-di-rescorla-wagner",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#modello-di-apprenimento-di-rescorla-wagner",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.5 Modello di Apprenimento di Rescorla-Wagner",
    "text": "68.5 Modello di Apprenimento di Rescorla-Wagner\nIl modello di apprendimento di Rescorla-Wagner, sviluppato per comprendere come gli esseri viventi apprendono le associazioni tra eventi, √® particolarmente utile nel descrivere l‚Äôapprendimento associativo, come il condizionamento classico. Il modello si basa sull‚Äôidea che l‚Äôapprendimento avvenga attraverso l‚Äôaggiornamento continuo delle aspettative sulla base degli errori di previsione. In altre parole, la differenza tra ci√≤ che ci si aspetta di ricevere e ci√≤ che viene effettivamente osservato determina come modifichiamo le nostre aspettative per il futuro.\n\n68.5.1 Aspettativa di Valore\nImmaginiamo un problema con due bandit a due braccia: ogni braccio rappresenta un‚Äôazione con una specifica ricompensa media associata. Il valore di un‚Äôazione corrisponde alla sua ricompensa media attesa.\nIndichiamo con:\n\n\\(A_t\\): l‚Äôazione scelta al tempo \\(t\\);\n\\(R_t\\): la ricompensa ottenuta dopo aver scelto l‚Äôazione \\(A_t\\);\n\\(q^{*}(a)\\): il valore atteso dell‚Äôazione \\(a\\) (ovvero la ricompensa media attesa se scegliamo \\(a\\)).\n\nSe conoscessimo il valore esatto di ogni azione, il problema del bandit a due braccia sarebbe banale: basterebbe scegliere sempre l‚Äôazione con il valore pi√π alto. Tuttavia, in realt√†, non conosciamo con certezza i valori delle azioni, ma possiamo solo stimarli.\nIndichiamo con \\(Q_t(a)\\) la stima del valore dell‚Äôazione \\(a\\) al tempo t. L‚Äôobiettivo √® far s√¨ che \\(Q_t(a)\\) si avvicini il pi√π possibile al valore reale \\(q^{*}(a)\\).\n\n\n68.5.2 La Regola di Apprendimento\nSecondo il modello Rescorla-Wagner, il valore atteso di un‚Äôazione viene aggiornato dopo ogni tentativo usando la seguente regola:\n\\[Q_k(t + 1) = Q_k(t) + \\alpha (R_k - Q_k(t))\\]\ndove:\n\n\\(Q_k(t)\\): valore atteso dell‚Äôazione k al tempo t\n\\(\\alpha\\): tasso di apprendimento, un valore compreso tra 0 e 1 che determina la velocit√† di aggiornamento delle aspettative. Un valore pi√π alto di Œ± implica un apprendimento pi√π rapido, mentre uno pi√π basso implica un apprendimento pi√π lento.\n\\(R_k\\): ricompensa ottenuta dopo aver scelto l‚Äôazione k al tempo t\n\\(R_k - Q_k(t)\\): errore di previsione, la differenza tra la ricompensa ottenuta e quella attesa\n\nIn parole semplici, l‚Äôerrore di previsione guida l‚Äôaggiornamento delle nostre aspettative: se la ricompensa √® maggiore del previsto, il valore dell‚Äôazione viene aumentato; se la ricompensa √® minore del previsto, il valore dell‚Äôazione viene diminuito.\n\n\n68.5.3 La Regola Decisionale\nPer decidere quale azione intraprendere, utilizziamo la regola softmax, che bilancia l‚Äôesplorazione di nuove opzioni con la scelta dell‚Äôazione con il valore atteso pi√π alto. La regola softmax trasforma i valori attesi Q in probabilit√† di scelta:\n\\[p_k(t) = \\frac{exp(\\theta Q_k(t))}{\\sum_{i=1}^K exp(\\theta Q_i(t))}\\]\ndove:\n\n\\(p_k(t)\\): probabilit√† di scegliere l‚Äôazione k al tempo t\n\\(\\theta\\): parametro temperatura che controlla il livello di esplorazione. Valori alti di \\(\\theta\\) portano a scelte pi√π deterministiche (quasi sempre l‚Äôazione con il valore pi√π alto), mentre valori bassi portano a scelte pi√π casuali.\n\n\n68.5.3.1 Esempio di Calcolo della Softmax\nPer capire come funziona la softmax, consideriamo alcuni valori di \\(Q\\) e \\(\\theta\\).\n\ndef softmax(Q, theta):\n    p = np.exp(theta * Q) / np.sum(np.exp(theta * Q))\n    return p\n\nQ = np.array([0.25, 0.75])\ntheta = 3.5\nprint(softmax(Q, theta))\n\n[0.1480472 0.8519528]\n\n\n\ntheta = 0.5\nprint(softmax(Q, theta))\n\n[0.4378235 0.5621765]\n\n\nLa funzione softmax trasforma i valori \\(Q\\) e \\(\\theta\\) in una distribuzione di probabilit√†, mostrando come la probabilit√† di scelta cambia al variare di \\(\\theta\\).\n\n\n\n68.5.4 Variazione di \\(\\theta\\) con Valori Fissi di \\(Q\\)\nManteniamo fissi i valori di \\(Q\\) e facciamo variare \\(\\theta\\):\n\nQ = np.array([0.1, 0.75])\ntheta_values = np.linspace(0, 5, 100)\n\nprobabilities_list = []\nfor theta in theta_values:\n    probabilities = softmax(Q, theta)\n    probabilities_list.append(probabilities)\n    \nprobabilities_array = np.array(probabilities_list).T\n\noption_labels = ['Opzione 1', 'Opzione 2']\n\nplt.figure()\nfor i in range(len(option_labels)):\n    plt.plot(theta_values, probabilities_array[i], label=option_labels[i])\n\nplt.xlabel('Theta')\nplt.ylabel('Probabilit√†')\nplt.title('Funzione Softmax - Modello Rescorla-Wagner')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico risultante mostra come le probabilit√† di scelta cambiano al variare del parametro \\(\\theta\\). Quando \\(\\theta\\) √® vicino a zero, la scelta √® quasi casuale. Quando \\(\\theta\\) √® molto grande, la scelta √® quasi sempre l‚Äôopzione con il valore pi√π alto.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.6 Simulazione del Modello di Rescorla-Wagner",
    "text": "68.6 Simulazione del Modello di Rescorla-Wagner\nCombiniamo la regola di apprendimento e la regola decisionale per simulare il comportamento del partecipante:\n\ndef simulate_RescorlaWagner(params, T, mu, noisy_choice=True):\n\n    alpha, theta = params\n    \n    # Un array di zeri di lunghezza T\n    c = np.zeros((T), dtype=int)\n    r = np.zeros((T), dtype=int)\n\n    # Un array multidimensionale di zeri di dimensione 2xT\n    Q_stored = np.zeros((2, T), dtype=float)\n    \n    # Inizializza Q per t == 0\n    Q = [0.5, 0.5]\n\n    for t in range(T):\n\n        # Salva i valori Q per Q_{t+1}\n        Q_stored[:, t] = Q\n\n        # Calcola le probabilit√† di scelta\n        p0 = np.exp(theta*Q[0]) / (np.exp(theta*Q[0]) + np.exp(theta*Q[1]))\n        p1 = 1 - p0\n        \n        # Se noisy_choice √® vero, viene simulato un comportamento di scelta rumoroso in \n        # cui l'opzione 0 √® scelta con probabilit√† p0, mentre l'opzione 1 √® scelta con \n        # probabilit√† 1-p0.\n        if noisy_choice:\n            if np.random.random_sample(1) &lt; p0:\n                c[t] = 0\n            else:\n                c[t] = 1\n        else:  # la scelta viene effettuata senza rumore\n            c[t] = np.argmax([p0, p1])\n\n        # Genera la ricompensa sulla base delle probabilit√† di ricompensa\n        r[t] = np.random.rand() &lt; mu[c[t]]\n\n        # Aggiorna le aspettative di valore\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    return c, r, Q_stored\n\nSimuliamo T = 100 prove utilizzando il modello generativo dei dati definito in precedenza.\n\nT = 100\nK = 2\nmu = [0.2, 0.8]\n\n\nc, r, Q = simulate_RescorlaWagner([.1, 2.5], T=T, mu=mu)\n\nRappresentiamo graficamente i risultati ottenuti dalla simulazione.\n\nplt.plot(range(T), r, 'r--', alpha=.6)\nplt.plot(range(T), c, '+', label='scelta')\nplt.xlabel('Prove')\nplt.ylabel('Feedback (1=Ricompensa,\\n 0=Nessuna ricompensa)')\nplt.title(f'Apprendimento di Rescorla-Wagner')\nplt.show()\n\n\n\n\n\n\n\n\nCome possiamo osservare, le scelte per la slot machine che produce meno ricompense diventano meno frequenti nel corso delle prove.\nPossiamo anche rappresentare graficamente le aspettative di valore \\(Q\\) delle due slot machine nel corso delle prove.\n\nplt.plot(range(T), Q[1, :], 'r--', alpha=.6, label='80% machine')\nplt.plot(range(T), Q[0, :], 'm-', alpha=.6, label='20% machine')\nplt.plot(range(T), c, 'b+', label='choice')\nplt.xlabel('trials')\nplt.ylabel('value')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi noti come nel corso delle prove i valori delle slot macchine convergano lentamente verso le probabilit√† di ricompensa (20% e 80%).\nIn sintesi, il modello di Rescorla-Wagner ci permette di simulare come le persone apprendono e prendono decisioni basate su ricompense. Utilizzando la regola di apprendimento (\\(\\delta\\)-rule) e la regola decisionale softmax, possiamo vedere come le aspettative di valore e le scelte cambiano nel tempo in risposta alle ricompense ottenute.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#adattamento-del-modello",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#adattamento-del-modello",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.7 Adattamento del Modello",
    "text": "68.7 Adattamento del Modello\nDopo aver visto come funziona il modello di Rescorla-Wagner, il passo successivo √® stimare i parametri del modello a partire dai dati osservati. Questo processo √® fondamentale nella modellazione computazionale perch√© ci permette di capire quali valori dei parametri descrivono meglio il comportamento osservato. Esistono diversi metodi per stimare i parametri, ma ci concentreremo sull‚Äôapproccio della Massima Verosimiglianza.\n\n68.7.1 La Massima Verosimiglianza\nL‚Äôapproccio della massima verosimiglianza cerca di trovare i valori dei parametri del modello che massimizzano la probabilit√† dei dati osservati. In altre parole, vogliamo trovare i parametri \\((\\alpha, \\theta)\\) che rendono i dati osservati \\(d_{1:T}\\) pi√π probabili secondo il modello Rescorla-Wagner.\n\n\n68.7.2 Calcolo del Logaritmo della Verosimiglianza\nMassimizzare la verosimiglianza √® spesso pi√π facile se si lavora con il logaritmo della verosimiglianza, perch√© le moltiplicazioni di probabilit√† diventano somme. La log-verosimiglianza pu√≤ essere espressa come:\n\\[\n\\log \\mathcal{L} = \\log p(d_{1:T} | (\\alpha, \\theta)_m, m) = \\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nIn questa equazione:\n\n\\(\\log \\mathcal{L}\\) √® il logaritmo della verosimiglianza.\n\\(p(d_{1:T} | (\\alpha, \\theta)_m, m)\\) √® la probabilit√† dei dati osservati dato il modello e i parametri.\n\\(p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\\) √® la probabilit√† di ogni singola scelta \\(c_t\\) data la storia delle scelte e dei feedback fino al tempo \\(t\\) e i parametri del modello.\n\n\n\n68.7.3 Minimizzazione del Logaritmo Negativo della Verosimiglianza\nIn pratica, massimizzare la log-verosimiglianza √® equivalente a minimizzare il logaritmo negativo della verosimiglianza. Questo ci porta alla seguente equazione:\n\\[\n-\\log \\mathcal{L} = -\\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nPer applicare questa procedura al modello di Rescorla-Wagner, dobbiamo definire la funzione di log-verosimiglianza negativa specifica per il nostro modello. Questa funzione ci permette di calcolare quanto bene i parametri \\(\\alpha\\) e \\(\\theta\\) spiegano i dati osservati. Durante il processo di stima, l‚Äôobiettivo √® minimizzare questa funzione per trovare i valori ottimali dei parametri.\n\n\n68.7.4 Esempio Pratico\nImmaginiamo di avere dati osservati da un esperimento in cui un partecipante ha fatto 100 scelte tra due slot machine. Il nostro obiettivo √® stimare i parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura) che meglio spiegano queste scelte. Per fare ci√≤, utilizziamo il metodo della massima verosimiglianza.\nLa seguente funzione negll_RescorlaWagner calcola il negativo della log-verosimiglianza per il modello di apprendimento di Rescorla-Wagner. Questo ci permette di capire quanto bene i parametri del modello (\\(\\alpha\\) e \\(\\theta\\)) spiegano le scelte osservate. Ecco una spiegazione passo passo per capire come funziona questa funzione.\nI parametri della Funzione sono:\n\nparams: una lista che contiene i valori dei parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura).\nc: un array che contiene le scelte effettuate dal partecipante (0 o 1).\nr: un array che contiene le ricompense ricevute dopo ogni scelta (1 per ricompensa, 0 per nessuna ricompensa).\n\nEsaminiamo ora il corpo della funzione.\n\nInizializzazione dei Parametri\nalpha, theta = params\nQ = [0.5, 0.5]\nT = len(c)\nchoiceProb = np.zeros((T), dtype=float)\n\nalpha e theta sono estratti dalla lista params.\nQ √® una lista che tiene traccia delle aspettative di valore per le due slot machine, inizializzate a 0.5.\nT √® il numero di scelte effettuate.\nchoiceProb √® un array che memorizza la probabilit√† di ogni scelta effettuata.\n\nCalcolo delle Probabilit√† di Scelta e Aggiornamento dei Valori\nfor t in range(T):\n    p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n    p = [p0, 1 - p0]\n    choiceProb[t] = p[c[t]]\n    delta = r[t] - Q[c[t]]\n    Q[c[t]] = Q[c[t]] + alpha * delta\n\nCalcolo delle Probabilit√† di Scelta:\n\np0 √® la probabilit√† di scegliere la prima slot machine.\np √® una lista delle probabilit√† di scegliere ciascuna delle due slot machine.\nchoiceProb[t] memorizza la probabilit√† della scelta effettivamente fatta al tempo \\(t\\).\n\nAggiornamento delle Aspettative di Valore:\n\ndelta √® la differenza tra la ricompensa effettiva r[t] e l‚Äôaspettativa di valore Q[c[t]] per la scelta fatta.\nQ[c[t]] viene aggiornata secondo la regola di Rescorla-Wagner: il nuovo valore atteso √® il vecchio valore atteso pi√π una frazione (determinata da \\(\\alpha\\)) dell‚Äôerrore di previsione.\n\n\nCalcolo del Negativo della Log-Verosimiglianza\nnegLL = -np.sum(np.log(choiceProb))\nreturn negLL\n\nLog-Verosimiglianza:\n\nnp.log(choiceProb) calcola il logaritmo delle probabilit√† di scelta.\nnp.sum(np.log(choiceProb)) somma questi logaritmi.\n\nNegativo della Log-Verosimiglianza:\n\nIl risultato √® moltiplicato per -1 per ottenere il negativo della log-verosimiglianza, poich√© nella stima dei parametri cerchiamo di minimizzare questa funzione.\n\n\n\nIn sintesi, la funzione negll_RescorlaWagner:\n\nCalcola le probabilit√† di scelta basate sui parametri \\(\\alpha\\) e \\(\\theta\\).\nAggiorna le aspettative di valore in base alle scelte e alle ricompense osservate.\nCalcola il negativo della log-verosimiglianza per valutare quanto bene i parametri spiegano i dati osservati.\n\nEcco la funzione completa con commenti per facilitarne la comprensione:\n\ndef negll_RescorlaWagner(params, c, r):\n    alpha, theta = params\n    Q = [0.5, 0.5]\n    T = len(c)\n    choiceProb = np.zeros((T), dtype=float)\n\n    for t in range(T):\n        # Calcola le probabilit√† di scelta per k = 2\n        p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n        # \"p\" √® una lista di probabilit√† di scelta per le due opzioni disponibili\n        p = [p0, 1 - p0]\n\n        # Memorizza la probabilit√† della scelta effettuata\n        choiceProb[t] = p[c[t]]\n\n        # Aggiorna le aspettative di valore secondo la regola di Rescorla-Wagner\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    # Calcola il negativo della log-verosimiglianza\n    negLL = -np.sum(np.log(choiceProb))\n\n    return negLL\n\nSimuliamo ora un set di dati.\n\n# simulate choices from RW Model\nalpha = .2\ntheta = 1.5\nc, r, Q2 = simulate_RescorlaWagner([alpha, theta], T=T, mu=[.2, .8])\n\nPer fare un esempio, valutiamo la log-verosimiglianza negativa per i dati simulati in corrispondenza dei valori alpha e theta indicati di seguito.\n\nalpha_hat = 0.3\ntheta_hat = 2.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.3 2.5 67.02432583559954\n\n\n\nalpha_hat = 0.2\ntheta_hat = 1.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.2 1.5 62.40238018291291\n\n\nUn metodo per trovare i parametri di massima verosimiglianza √® effettuare una ricerca esaustiva su tutto lo spazio dei parametri. Questo significa selezionare i valori di alpha e theta per i quali la funzione negLL assume il valore pi√π basso.\nPer illustrare questo metodo, applichiamolo a un set di dati simulato. Per semplicit√†, assumiamo di conoscere il valore di \\(\\theta\\) e di dover trovare solo il valore di \\(\\alpha\\).\n\nnLL = []\nalpha_vals = np.linspace(0, 0.5, 1000)\nfor alpha_val in alpha_vals:\n    nLL.append(negll_RescorlaWagner([alpha_val, theta], c, r))\n\nplt.figure()\nplt.plot(alpha_vals, nLL, '-')\nplt.plot(\n    alpha_vals[np.argmin(nLL)], nLL[np.argmin(nLL)],\n    'X', label=r'optimal $\\hat \\alpha$'\n)\nplt.ylabel('negative log likelihood')\nplt.xlabel(fr'learning rate, $\\hat \\alpha$')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n68.7.5 Validazione\nUna volta stabilito un metodo per stimare i parametri del modello dai dati, dobbiamo valutare quanto accuratamente queste stime riflettano i veri valori dei parametri del modello. Per rispondere a questa domanda, possiamo condurre uno studio di simulazione.\nI parametri della simulazione sono i seguenti.\n\nT = 250\nmu = [0.2, 0.8]\nnum_subjects = 20\n\nCalcolimo i valori di massima verosimiglianza dei parametri alpha e theta usando la funzione minimize per minimizzare la funzione di log-verosimiglianza. Simuliamo i dati di un soggetto.\nSpecifichiamo poi le stime iniziali per i valori dei parametri e i valori margine delle possibili soluzioni. I risultati saranno salvati nell‚Äôoggetto result. Le stime dei due parametri si estraggono con result.x.\n\nc, r, Q = simulate_RescorlaWagner([0.15, 1.5], T=T, mu=mu)\n\ninit_guess = (0.1, 0.1)\n\n# minimize neg LL\nresult = minimize(\n    negll_RescorlaWagner,\n    init_guess,\n    (c, r),\n    bounds=((0, 1), (0, 10)),\n)\nprint(result.x)\n\n[0.1093135  1.27704408]\n\n\nSimuliamo i dati per 500 soggetti, con 250 osservazioni ciascuno, utilizzando valori casuali di alpha e theta. Successivamente, eseguiamo la stima di massima verosimiglianza per i dati di ogni soggetto, inizializzando casualmente i parametri per ciascuno di essi. Infine, salviamo i risultati ottenuti nel DataFrame df. Ecco il codice corrispondente:\n\nNREP = 500\ndf = pd.DataFrame(\n    index=range(0, NREP), columns=[\"true_alpha\", \"alpha\", \"true_theta\", \"theta\"]\n)\n\n# loop through subjects\nfor index in range(NREP):\n\n    true_alpha = 0.95 * np.random.random()\n    true_theta = 4.0 * np.random.random()\n\n    c, r, Q = simulate_RescorlaWagner([true_alpha, true_theta], T=250, mu=mu)\n\n    init_guess = (0.2 * np.random.random(), 1.0 * np.random.random())\n    # minimize neg LL\n    param_fits = minimize(\n        negll_RescorlaWagner,\n        init_guess,\n        (c, r),\n        bounds=((0, 1), (0, 10)),\n    )\n\n    # store in dataframe\n    df.at[index, \"true_alpha\"] = true_alpha\n    df.at[index, \"true_theta\"] = true_theta\n    df.at[index, \"alpha\"] = param_fits.x[0]\n    df.at[index, \"theta\"] = param_fits.x[1]\n\nLa figura successiva mostra una corrispondenza tra i valori stimati di alpha e i valori veri. √à importante notare che la corrispondenza non √® perfetta a causa della presenza di una componente di casualit√† nei dati. Inoltre, in alcuni casi si possono osservare valori stimati di alpha pari a 0 o 1, che corrispondono a risultati spurii dell‚Äôalgoritmo. Il numero di risultati spurii aumenta con il diminuire del numero di osservazioni per ciascun soggetto.\n\nplt.plot(df.true_alpha, df.alpha, 'ob', alpha=.4)\nplt.xlabel('True alpha')\nplt.ylabel('Estimated alpha')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nUn discorso analogo si pu√≤ fare per theta, anche se in questo caso vi √® una migliore corrispondenza tra i valori stimati e i valori veri.\n\nplt.plot(df.true_theta, df.theta, 'or', alpha=.4)\nplt.xlabel('True theta')\nplt.ylabel('Estimated theta')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, possiamo affermare che il metodo della massima verosimiglianza √® in grado di recuperare i valori simulati dei parametri \\(\\alpha\\) e \\(\\theta\\) del modello di Rescorla-Wagner, ma solo quando il numero di osservazioni per soggetto √® considerevole. Tuttavia, √® importante notare che questo metodo pu√≤ produrre risultati imprecisi in determinate circostanze.\nEsistono altri metodi di stima che offrono risultati migliori anche con un numero inferiore di osservazioni per soggetto. Tra questi, il metodo gerarchico bayesiano √® ampiamente utilizzato nella pratica. Va precisato che l‚Äôobiettivo di questo tutorial era principalmente illustrare in modo semplice come sia possibile ottenere con buona accuratezza i parametri del modello di Rescorla-Wagner dai dati generati da una simulazione, considerando condizioni ottimali in cui i valori dei parametri del modello sono noti.\n√à importante sottolineare che, nella pratica, la stima dei parametri pu√≤ essere un processo complesso e che l‚Äôaccuratezza delle stime dipende da molteplici fattori, come la dimensione del campione e la natura dei dati osservati. Pertanto, √® sempre consigliabile valutare attentamente i risultati e considerare l‚Äôutilizzo di approcci pi√π sofisticati, come il metodo gerarchico bayesiano, per ottenere stime pi√π affidabili dei parametri del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#stima-con-stan",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#stima-con-stan",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "68.8 Stima con Stan",
    "text": "68.8 Stima con Stan\nConsideriamo ora la stima dei parametri del modello Rescorla-Wagner usando un metodo bayesiano, ovvero mediante Stan. Compiliamo il modello e stampiamo il codice Stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"rescorla_wagner.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:57:16 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/rescorla_wagner.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/rescorla_wagner\n12:57:27 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/rescorla_wagner\n\n\ndata {\n  int&lt;lower=1&gt; nTrials; // numero di tentativi\n  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)\n  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)\n}\ntransformed data {\n  vector[2] initV; // valori iniziali per V\n  initV = rep_vector(0.5, 2); // inizializzati a 0.5\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento\n  real&lt;lower=0&gt; theta; // temperatura\n}\nmodel {\n  vector[2] v; // valori attesi\n  real delta; // errore di previsione\n  \n  // Priori\n  alpha ~ beta(1, 1); // prior uniforme su [0, 1]\n  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10\n  \n  v = initV;\n  \n  for (t in 1 : nTrials) {\n    // Calcolo delle probabilit√† di scelta usando la funzione softmax con limitazione\n    vector[2] logits;\n    logits = theta * v;\n    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow\n    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow\n    \n    choice[t] ~ categorical_logit(logits);\n    \n    // Errore di previsione\n    delta = reward[t] - v[choice[t]];\n    \n    // Aggiornamento dei valori attesi (apprendimento)\n    v[choice[t]] = v[choice[t]] + alpha * delta;\n  }\n}\n\n\n\n\n68.8.1 Sezione data\nQuesta sezione definisce i dati che vengono forniti al modello:\ndata {\n  int&lt;lower=1&gt; nTrials; // numero di tentativi\n  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)\n  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)\n}\n\nnTrials: Il numero totale di tentativi o scelte effettuate dal partecipante.\nchoice: Un array che contiene le scelte effettuate dal partecipante in ciascun tentativo (1 o 2).\nreward: Un array che contiene le ricompense ricevute per ciascun tentativo (0 o 1).\n\n\n\n68.8.2 Sezione transformed data\nQuesta sezione prepara alcuni dati iniziali trasformati per il modello:\ntransformed data {\n  vector[2] initV; // valori iniziali per V\n  initV = rep_vector(0.5, 2); // inizializzati a 0.5\n}\n\ninitV: Un vettore di lunghezza 2 che rappresenta i valori iniziali delle aspettative di ricompensa per le due opzioni, entrambi inizializzati a 0.5.\n\n\n\n68.8.3 Sezione parameters\nQuesta sezione definisce i parametri del modello che Stan cercher√† di stimare:\nparameters {\n  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento\n  real&lt;lower=0&gt; theta; // temperatura\n}\n\nalpha: Il tasso di apprendimento, che determina quanto rapidamente il partecipante aggiorna le proprie aspettative. Questo valore √® compreso tra 0 e 1.\ntheta: La temperatura, che controlla il livello di esplorazione (quanto spesso il partecipante sceglie l‚Äôopzione con il valore atteso pi√π alto rispetto a esplorare altre opzioni). Questo valore √® positivo.\n\n\n\n68.8.4 Sezione model\nQuesta √® la sezione principale che definisce come il modello effettua le stime e aggiorna i valori:\nmodel {\n  vector[2] v; // valori attesi\n  real delta; // errore di previsione\n  \n  // Priori\n  alpha ~ beta(1, 1); // prior uniforme su [0, 1]\n  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10\n  \n  v = initV;\n  \n  for (t in 1 : nTrials) {\n    // Calcolo delle probabilit√† di scelta usando la funzione softmax con limitazione\n    vector[2] logits;\n    logits = theta * v;\n    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow\n    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow\n    \n    choice[t] ~ categorical_logit(logits);\n    \n    // Errore di previsione\n    delta = reward[t] - v[choice[t]];\n    \n    // Aggiornamento dei valori attesi (apprendimento)\n    v[choice[t]] = v[choice[t]] + alpha * delta;\n  }\n}\n\nv: Un vettore che contiene i valori attesi delle ricompense per le due opzioni.\ndelta: La differenza tra la ricompensa ricevuta e il valore atteso (errore di previsione).\n\n\n68.8.4.1 Priori\nLe distribuzioni prior definiscono le nostre convinzioni iniziali sui parametri prima di vedere i dati:\n\nalpha ~ beta(1, 1): Una distribuzione beta uniforme per alpha, che assegna uguale probabilit√† a tutti i valori tra 0 e 1.\ntheta ~ normal(0, 10): Una distribuzione normale per theta con media 0 e deviazione standard 10.\n\n\n\n68.8.4.2 Ciclo sui Tentativi\nPer ogni tentativo, il modello:\n\nCalcola le probabilit√† di scelta utilizzando la funzione softmax, limitando i valori per evitare overflow numerici:\nlogits = theta * v;\nlogits = fmin(logits, 20);\nlogits = fmax(logits, -20);\nchoice[t] ~ categorical_logit(logits);\n\nlogits = theta * v;: logits √® un vettore che contiene i valori trasformati theta * v.\ntheta √® la temperatura, che controlla quanto il partecipante esplora rispetto a sfruttare (scegliere l‚Äôopzione con il valore atteso pi√π alto).\nv sono i valori attesi delle ricompense per le due opzioni.\nlogits = fmin(logits, 20);: Questa funzione assicura che nessun valore in logits sia maggiore di 20. Se un valore √® maggiore di 20, viene impostato a 20.\nlogits = fmax(logits, -20);: Questa funzione assicura che nessun valore in logits sia minore di -20. Se un valore √® minore di -20, viene impostato a -20.\nchoice[t] ~ categorical_logit(logits);: categorical_logit(logits) √® una distribuzione che assegna probabilit√† alle scelte (1 o 2) in base ai valori logits.\n\nMotivazione: Limitare i valori dei logits √® importante per evitare problemi numerici (overflow) quando si calcolano le probabilit√†. Valori estremi di theta * v possono causare risultati non definiti o infiniti, quindi li limitiamo a un intervallo ragionevole (-20 a 20).\nFunzionamento della Funzione categorical_logit:\n\ncategorical_logit(logits) utilizza la funzione softmax per convertire i logits in probabilit√†.\nLa funzione softmax √® definita come:\n\\[\n\\text{softmax}(z_i) = \\frac{\\exp(z_i)}{\\sum_{j=1}^{K} \\exp(z_j)},\n\\]\ndove z_i sono i logits per ciascuna opzione.\nQuesta funzione garantisce che le probabilit√† siano comprese tra 0 e 1 e che la loro somma sia 1.\n\nEsempio Pratico:\nSupponiamo che theta = 1 e i valori attesi siano v = [0.3, 0.7]. I logits sarebbero calcolati come:\nlogits = theta * v; // logits = [1 * 0.3, 1 * 0.7] = [0.3, 0.7]\nlogits = fmin(logits, 20); // nessun valore √® maggiore di 20, quindi rimane [0.3, 0.7]\nlogits = fmax(logits, -20); // nessun valore √® minore di -20, quindi rimane [0.3, 0.7]\nApplicando la funzione softmax:\n\\[\n\\text{softmax}(0.3, 0.7) = \\left( \\frac{\\exp(0.3)}{\\exp(0.3) + \\exp(0.7)}, \\frac{\\exp(0.7)}{\\exp(0.3) + \\exp(0.7)} \\right)\n\\]\nCalcolando le esponenziali e le probabilit√†:\n\\[\n\\exp(0.3) \\approx 1.35, \\quad \\exp(0.7) \\approx 2.01\n\\]\n\\[\n\\text{softmax}(0.3, 0.7) \\approx \\left( \\frac{1.35}{1.35 + 2.01}, \\frac{2.01}{1.35 + 2.01} \\right) = \\left( 0.40, 0.60 \\right)\n\\]\nQuindi, le probabilit√† di scegliere l‚Äôopzione 1 e l‚Äôopzione 2 sono circa 0.40 e 0.60, rispettivamente. Il modello usa queste probabilit√† per determinare quale scelta viene effettivamente fatta al tempo t.\nCalcola l‚Äôerrore di previsione come la differenza tra la ricompensa ricevuta e il valore atteso:\ndelta = reward[t] - v[choice[t]];\nAggiorna i valori attesi utilizzando l‚Äôerrore di previsione e il tasso di apprendimento alpha:\nv[choice[t]] = v[choice[t]] + alpha * delta;\n\nIn sintesi,\n\nI logits sono valori calcolati come theta * v e limitati tra -20 e 20 per evitare problemi numerici.\ncategorical_logit(logits) converte questi logits in probabilit√† utilizzando la funzione softmax.\nLa scelta al tempo t (choice[t]) √® modellata come una variabile categoriale con queste probabilit√†, riflettendo la probabilit√† che il partecipante scelga ciascuna delle opzioni.\nL‚Äôerrore di previsione (delta) √® calcolato come la differenza tra la ricompensa ricevuta e il valore atteso.\nI valori attesi (v) vengono aggiornati utilizzando l‚Äôerrore di previsione e il tasso di apprendimento (alpha).\n\nQuesto modello Stan implementa il processo di apprendimento del modello di Rescorla-Wagner. Utilizza le scelte e le ricompense osservate per stimare i parametri alpha e theta, aggiornando le aspettative di ricompensa in base ai risultati di ogni tentativo.\n\n\n\n68.8.5 Inferenza\nCompiliamo il modello Stan:\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nDefiniamo i parametri della simulazione:\n\nparams = [0.1, 2.5]  # alpha, theta\nT = 300  # numero di tentativi\nmu = [0.2, 0.8]  # probabilit√† di ricompensa per le due opzioni\n\nSimuliamo i dati:\n\nchoices, rewards, Q_stored = simulate_RescorlaWagner(params, T, mu)\n\nPrepariamo i dati per Stan. Si noti che abbiamo sommato 1 a choices per adattarsi agli indici di Stan che partono da 1.\n\nc = choices + 1\n\nstan_data = {\n    'nTrials': T,\n    'choice': c.tolist(),\n    'reward': rewards.tolist()\n}\nprint(stan_data)\n\n{'nTrials': 300, 'choice': [1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2], 'reward': [1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n12:58:12 - cmdstanpy - INFO - CmdStan start processing\n12:58:12 - cmdstanpy - INFO - Chain [1] start processing\n12:58:12 - cmdstanpy - INFO - Chain [2] start processing\n12:58:12 - cmdstanpy - INFO - Chain [3] start processing\n12:58:12 - cmdstanpy - INFO - Chain [4] start processing\n12:58:14 - cmdstanpy - INFO - Chain [3] done processing\n12:58:14 - cmdstanpy - INFO - Chain [1] done processing\n12:58:15 - cmdstanpy - INFO - Chain [2] done processing\n12:58:15 - cmdstanpy - INFO - Chain [4] done processing\n\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\alpha\\) e \\(\\theta\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\n\n\n68.8.6 Interpretazione delle Stime dei Parametri\nUtilizzando az.summary(trace, hdi_prob=0.94, round_to=2), otteniamo un riassunto delle stime dei parametri del modello, che include la media, la deviazione standard, gli intervalli di credibilit√† (HDI) e altre statistiche diagnostiche:\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.12\n0.06\n0.02\n0.24\n0.00\n0.00\n2582.93\n2151.18\n1.0\n\n\ntheta\n2.36\n0.35\n1.77\n2.96\n0.01\n0.01\n2578.16\n1868.05\n1.0\n\n\n\n\n\n\n\n\nCon 300 prove, le stime dei parametri fornite dal modello sono adeguate:\n\nL‚Äôintervallo di credibilit√† al 94% (hdi_3% - hdi_97%) include il valore simulato del parametro. Questo significa che le stime del modello sono coerenti con i parametri originali usati nella simulazione.\nLa deviazione standard della stima a posteriori √® relativamente piccola, indicando che le stime sono precise.\nI valori di r_hat sono vicini a 1, indicando che le catene di campionamento sono ben mescolate e hanno ottenuto la convergenza.\n\nQuesti risultati suggeriscono che il modello di apprendimento di Rescorla-Wagner ha stimato correttamente i parametri \\(\\alpha\\) e \\(\\theta\\) dai dati simulati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_40_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_40_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "title": "68¬† Apprendimento per rinforzo",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/introduction_chapter_6.html",
    "href": "chapters/chapter_6/introduction_chapter_6.html",
    "title": "69¬† Introduzione",
    "section": "",
    "text": "Nell‚Äôinferenza statistica, esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati. Sebbene entrambi siano utilizzati per stimare quantit√† sconosciute, fare previsioni e testare ipotesi, differiscono nella loro interpretazione della probabilit√† e nell‚Äôintegrazione di conoscenze precedenti ed evidenze.\nCome visto precedentemente, la statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica utilizzando il teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione √® trattato come una variabile casuale ed √® costantemente aggiornato man mano che nuovi dati vengono raccolti. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che pu√≤ essere utilizzata per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nD‚Äôaltra parte, la statistica frequentista interpreta la probabilit√† come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa, esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi. Metteremo in evidenza i limiti dell‚Äôinferenza frequentista, riconosciuti negli ultimi decenni come una delle principali cause della crisi della riproducibilit√† dei risultati della ricerca Baker (2016). Infine, discuteremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman e Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista.\n\n\n\n\nBaker, Monya. 2016. ¬´Reproducibility Crisis¬ª. Nature 533 (7604): 452‚Äì54.\n\n\nGelman, Andrew, e John Carlin. 2014. ¬´Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors¬ª. Perspectives on Psychological Science 9 (6): 641‚Äì51.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian\nModeling. Boca Raton, Florida: CRC Press.\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications\nin r. Chapman; Hall/CRC.\n\n\nBaker, Monya. 2016a. ‚Äú1,500 Scientists Lift the Lid on\nReproducibility.‚Äù Nature 533 (7604).\n\n\n‚Äî‚Äî‚Äî. 2016b. ‚ÄúReproducibility Crisis.‚Äù Nature 533\n(7604): 452‚Äì54.\n\n\nBaribault, Beth, and Anne GE Collins. 2023. ‚ÄúTroubleshooting\nBayesian Cognitive Models.‚Äù Psychological Methods.\n\n\nBelenky, Gregory, Nancy J Wesensten, David R Thorne, Maria L Thomas,\nHelen C Sing, Daniel P Redmond, Michael B Russo, and Thomas J Balkin.\n2003. ‚ÄúPatterns of Performance Degradation and Restoration During\nSleep Restriction and Subsequent Recovery: A Sleep Dose-Response\nStudy.‚Äù Journal of Sleep Research 12 (1): 1‚Äì12.\n\n\nBetancourt, Michael. 2016. ‚ÄúDiagnosing Suboptimal Cotangent\nDisintegrations in Hamiltonian Monte Carlo.‚Äù arXiv Preprint\narXiv:1604.00695.\n\n\nBland, J Martin, and Douglas G Altman. 2011. ‚ÄúComparisons Within\nRandomised Groups Can Be Very Misleading.‚Äù Bmj 342.\n\n\nBox, G. E., A. Luceno, and M. del Carmen Paniagua-Quinones. 2011.\nStatistical Control by Monitoring and Adjustment. John Wiley;\nSons.\n\n\nBrownstein, Naomi C, Thomas A Louis, Anthony O‚ÄôHagan, and Jane\nPendergast. 2019. ‚ÄúThe Role of Expert Judgment in Statistical\nInference and Evidence-Based Decision-Making.‚Äù The American\nStatistician 73 (sup1): 56‚Äì68.\n\n\nChivers, Tom. 2024. Everything Is Predictable: How Bayesian\nStatistics Explain Our World. Simon; Schuster.\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and\nthe Crisis of Modern Science. Columbia University Press.\n\n\nCollaboration, Open Science. 2015. ‚ÄúEstimating the Reproducibility\nof Psychological Science.‚Äù Science 349 (6251): aac4716.\n\n\nComtois, Katherine Anne, Karin E Hendricks, Christopher R DeCou,\nSamantha A Chalker, Amanda H Kerbrat, Jennifer Crumlish, Tierney K\nHuppert, and David Jobes. 2023. ‚ÄúReducing Short Term Suicide Risk\nAfter Hospitalization: A Randomized Controlled Trial of the\nCollaborative Assessment and Management of Suicidality.‚Äù\nJournal of Affective Disorders 320: 656‚Äì66.\n\n\nDagan, Noa, Noam Barda, Eldad Kepten, Oren Miron, Shay Perchik, Mark\nKatz, Miguel Hern√°n, Marc Lipsitch, Ben Reis, and Ran Balicer. 2021.\n‚ÄúBNT162b2 mRNA Covid-19 Vaccine in a Nationwide Mass Vaccination\nSetting.‚Äù New England Journal of Medicine 384 (15):\n1412‚Äì23. https://doi.org/10.1056/NEJMoa2101765.\n\n\nDe Finetti, Bruno. 2017. Theory of Probability: A Critical\nIntroductory Treatment. Vol. 6. John Wiley & Sons.\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth.\n1987. ‚ÄúHybrid Monte Carlo.‚Äù Physics Letters B 195\n(2): 216‚Äì22.\n\n\nFishburn, Peter C. 1986. ‚ÄúThe Axioms of Subjective\nProbability.‚Äù Statistical Science 1 (3): 335‚Äì45.\n\n\nFox, John. 2015. Applied Regression Analysis and Generalized Linear\nModels. Sage publications.\n\n\nGelman, Andrew, and John Carlin. 2014. ‚ÄúBeyond Power Calculations:\nAssessing Type s (Sign) and Type m (Magnitude) Errors.‚Äù\nPerspectives on Psychological Science 9 (6): 641‚Äì51.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and\nOther Stories. Cambridge University Press.\n\n\nGelman, Andrew, and Eric Loken. 2013. ‚ÄúThe Garden of Forking\nPaths: Why Multiple Comparisons Can Be a Problem, Even When There Is No\n‚ÄòFishing Expedition‚Äô or ‚Äòp-Hacking‚Äô and the\nResearch Hypothesis Was Posited Ahead of Time.‚Äù Department of\nStatistics, Columbia University 348 (1-17): 3.\n\n\nGelman, Andrew, and Cosma Rohilla Shalizi. 2013. ‚ÄúPhilosophy and\nthe Practice of Bayesian Statistics.‚Äù British Journal of\nMathematical and Statistical Psychology 66 (1): 8‚Äì38.\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob\nCarpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian\nB√ºrkner, and Martin Modr√°k. 2020. ‚ÄúBayesian Workflow.‚Äù\narXiv Preprint arXiv:2011.01808.\n\n\nGeman, Stuart, and Donald Geman. 1984. ‚ÄúStochastic Relaxation,\nGibbs Distributions, and the Bayesian\nRestoration of Images.‚Äù IEEE Transactions on Pattern Analysis\nand Machine Intelligence 6: 721‚Äì41.\n\n\nGibson, Edward, and H-H Iris Wu. 2013. ‚ÄúProcessing Chinese\nRelative Clauses in Context.‚Äù Language and Cognitive\nProcesses 28 (1-2): 125‚Äì55.\n\n\nGill, Jeff. 2015. Bayesian Methods: A Social and Behavioral Sciences\nApproach. 3rd Edition. Chapman; Hall/CRC.\n\n\nHastings, W. Keith. 1970. ‚ÄúMonte Carlo\nSampling Methods Using Markov Chains and Their\nApplications.‚Äù Biometrika 57 (1): 97‚Äì109.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ‚ÄúThe No-u-Turn\nSampler: Adaptively Setting Path Lengths in Hamiltonian Monte\nCarlo.‚Äù Journal of Machine Learning Research 15 (1):\n1593‚Äì623.\n\n\nHoffmann, Tabea, Abe Hofman, and Eric-Jan Wagenmakers. 2022.\n‚ÄúBayesian Tests of Two Proportions: A Tutorial with r and\nJASP.‚Äù Methodology 18 (4): 239‚Äì77.\n\n\nHowson, Colin, and Peter Urbach. 2006. Scientific Reasoning: The\nBayesian Approach. Open Court Publishing.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC.\n\n\nIoannidis, John PA. 2005. ‚ÄúWhy Most Published Research Findings\nAre False.‚Äù PLoS Medicine 2 (8): e124.\n\n\nJaynes, Edwin T. 2003. Probability Theory: The Logic of\nScience. Cambridge University Press.\n\n\nJohnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with\nR. CRC Press.\n\n\nJohnson, Kaneesha R. 2021. ‚ÄúTwo Regimes of Prison Data\nCollection.‚Äù Harvard Data Science Review 3 (3): 10‚Äì1162.\n\n\nKaplan, David. 2023. Bayesian Statistics for the Social\nSciences. Guilford Publications.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A\nTutorial with R, JAGS, and Stan. Academic\nPress.\n\n\nLabatut, Benjamƒ±ÃÅn. 2021. Quando Abbiamo Smesso Di Capire Il\nMondo. Adelphi Edizioni spa.\n\n\nLakens, Dani√´l. 2015. ‚ÄúOn the Challenges of Drawing Conclusions\nfrom p-Values Just Below 0.05.‚Äù PeerJ 3: e1142.\n\n\nLilienfeld, Scott O, and Adele N Strother. 2020. ‚ÄúPsychological\nMeasurement and the Replication Crisis: Four Sacred Cows.‚Äù\nCanadian Psychology/Psychologie Canadienne 61 (4): 281‚Äì288.\n\n\nLindley, Dennis V. 2013. Understanding Uncertainty. John Wiley\n& Sons.\n\n\nMartin, Osvaldo. 2024. Bayesian Analysis with Python. Packt\nPublishing Ltd.\n\n\nMartin, Osvaldo A, Ravin Kumar, and Junpeng Lao. 2022. Bayesian\nModeling and Computation in Python. CRC Press.\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and\nR. 1st Edition. New York, NY: Manning Publications.\n\n\nMaul, Andrew, David Torres Irribarra, and Mark Wilson. 2016. ‚ÄúOn\nthe Philosophical Foundations of Psychological Measurement.‚Äù\nMeasurement 79: 311‚Äì20.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. \" O‚ÄôReilly\nMedia, Inc.\".\n\n\nMcShane, Blakeley B, Jennifer L Tackett, Ulf B√∂ckenholt, and Andrew\nGelman. 2019. ‚ÄúLarge-Scale Replication Projects in Contemporary\nPsychological Research.‚Äù The American Statistician 73\n(sup1): 99‚Äì105.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth,\nAugusta H. Teller, and Edward Teller. 1953. ‚ÄúEquation of State\nCalculations by Fast Computing Machines.‚Äù The Journal of\nChemical Physics 21 (6): 1087‚Äì92.\n\n\nNobles, Melissa. 2000. Shades of Citizenship: Race and the Census in\nModern Politics. Stanford University Press.\n\n\nNuzzo, Regina. 2014. ‚ÄúScientific Method: Statistical\nErrors.‚Äù Nature 506 (7487).\n\n\nO‚ÄôHagan, Anthony. 2019. ‚ÄúExpert Knowledge Elicitation: Subjective\nbut Scientific.‚Äù The American Statistician 73 (sup1):\n69‚Äì81.\n\n\nPearl, Judea. 2009. Causality. Cambridge University Press.\n\n\nPress, S James. 2009. Subjective and Objective Bayesian Statistics:\nPrinciples, Models, and Applications. John Wiley & Sons.\n\n\nRamsey, Frank P. 1926. ‚ÄúTruth and Probability.‚Äù In\nReadings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.\n\n\nRiederer, Emily. 2021. ‚ÄúCausal Design Patterns for Data\nAnalysts,‚Äù January. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nRohrer, Julia M. 2018. ‚ÄúThinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational Data.‚Äù\nAdvances in Methods and Practices in Psychological Science 1\n(1): 27‚Äì42.\n\n\nSchoot, Van Rens de, Duco Veen, Laurent Smeets, and Sonja Winter. 2020.\n‚ÄúA Tutorial on Using the WAMBS Checklist to Avoid the Misuse of\nBayesian Statistics.‚Äù Routledge.\n\n\nSorensen, Tanner, and Shravan Vasishth. 2015. ‚ÄúBayesian Linear\nMixed Models Using Stan: A Tutorial for Psychologists, Linguists, and\nCognitive Scientists.‚Äù arXiv Preprint arXiv:1506.06201.\n\n\nSpector, Aaron J. 1956. ‚ÄúExpectations, Fulfillment, and\nMorale.‚Äù The Journal of Abnormal and Social Psychology\n52 (1): 51‚Äì56.\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, and Marek McGann.\n2024. ‚ÄúMost Psychological Researchers Assume Their Samples Are\nErgodic: Evidence from a Year of Articles in Three Major\nJournals.‚Äù Collabra: Psychology 10 (1).\n\n\nStevens, Stanley Smith. 1946. ‚ÄúOn the Theory of Scales of\nMeasurement.‚Äù Science 103 (2684): 677‚Äì80.\n\n\nStigler, Stephen. 1986. The History of Statistics.\nMassachusetts: Belknap Harvard.\n\n\nTukey, John W. 1962. ‚ÄúThe Future of Data\nAnalysis.‚Äù The Annals of Mathematical Statistics\n33 (1): 1‚Äì67. https://doi.org/10.1214/aoms/1177704711.\n\n\nVan Dongen, Noah, Riet van Bork, Adam Finnemann, Jonas Haslbeck, Han LJ\nvan der Maas, Donald J Robinaugh, Jill de Ron, Jan Sprenger, and Denny\nBorsboom. 2024. ‚ÄúProductive Explanation: A Framework for\nEvaluating Explanations in Psychological Science.‚Äù\nPsychological Review.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and\nPaul-Christian B√ºrkner. 2021. ‚ÄúRank-Normalization, Folding, and\nLocalization: An Improved r ÃÇ for Assessing Convergence of MCMC (with\nDiscussion).‚Äù Bayesian Analysis 16 (2): 667‚Äì718.\n\n\nWard, Andrew, and Traci Mann. 2022. ‚ÄúControl Yourself: Broad\nImplications of Narrowed Attention.‚Äù Perspectives on\nPsychological Science 17 (6): 1692‚Äì1703.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, and Babette Renneberg. 2019.\n‚ÄúFuture Expectations in Clinical Depression: Biased or\nRealistic?‚Äù Journal of Abnormal Psychology 128 (7): 678.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon\nSchwab, and Steven N Goodman. 2023. ‚ÄúA New Look at p Values for\nRandomized Clinical Trials.‚Äù NEJM Evidence 3 (1):\nEVIDoa2300003.",
    "crumbs": [
      "Bibliografia"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html",
    "href": "chapters/chapter_7/a00_installation.html",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1 Guida all‚ÄôInstallazione Locale dei Jupyter Notebook\nPer facilitare l‚Äôapprendimento e l‚Äôapplicazione delle tecniche di analisi dei dati discusse in questo corso, utilizzeremo i Jupyter Notebook come strumento principale. I Jupyter Notebook sono documenti interattivi che consentono di combinare codice, testo narrativo, visualizzazioni grafiche e altri elementi multimediali, rendendoli ideali per documentare e condividere analisi di dati in modo trasparente e riproducibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "href": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1.1 Prerequisiti per l‚ÄôUso dei Jupyter Notebook\nPer utilizzare i Jupyter Notebook, √® necessario soddisfare alcuni prerequisiti:\n\nInstallare Python: √à il linguaggio di programmazione fondamentale per il nostro corso e deve essere installato sul vostro computer.\nGestione degli Ambienti Virtuali con conda: Utilizzeremo conda per creare e gestire ambienti virtuali, che permettono di isolare e gestire le dipendenze del progetto.\nInstallazione dei Pacchetti Python Necessari: Dovrete installare specifici pacchetti Python, inclusi PyMC per l‚Äôanalisi bayesiana, e altri pacchetti utili, all‚Äôinterno dell‚Äôambiente virtuale creato per questo corso.\nInterfaccia per l‚ÄôUso dei Jupyter Notebook: Avrete bisogno di un IDE (Integrated Development Environment) che supporti i Jupyter Notebook, come Visual Studio Code, per scrivere e eseguire i vostri notebook.\n\n\n\nA.1.2 Installazione di Anaconda\nLa maggior parte dei requisiti elencati pu√≤ essere agevolmente soddisfatta tramite l‚Äôinstallazione di Anaconda, una distribuzione di Python che include conda e facilita la gestione degli ambienti virtuali e l‚Äôinstallazione dei pacchetti.\n\n\n\n\n\n\nSe Anaconda √® gi√† stata installata, potrebbero sorgere problemi dopo l‚Äôaggiornamento del sistema operativo. In tal caso, sar√† indispensabile procedere con una nuova installazione di Anaconda.\n\n\n\n\nA.1.2.1 Per Utenti macOS\nSe lavorate su macOS, potreste trovare pi√π pratico utilizzare conda direttamente dal Terminale o da un‚Äôapplicazione terminale moderna come Warp, piuttosto che attraverso Anaconda Navigator. In questo caso, potete optare per installare una versione di Visual Studio Code indipendente da quella fornita con Anaconda, per un maggiore controllo e flessibilit√†.\n\n\nA.1.2.2 Per Utenti Windows\nPer coloro che utilizzano Windows, l‚Äôuso di Jupyter Notebook tramite Anaconda Navigator potrebbe risultare la scelta pi√π semplice e diretta, grazie all‚Äôintegrazione e alla facilit√† d‚Äôuso fornite da Anaconda in ambienti Windows.\n\n\n\nA.1.3 Creazione e Configurazione dell‚ÄôAmbiente Virtuale\nIndipendentemente dal sistema operativo, √® fondamentale installare e configurare conda, che vi permetter√† di creare {ref}appendix-virtual-env dedicati. All‚Äôinterno di questi ambienti, installerete cmdstanpy (o PyMC) e gli altri pacchetti richiesti per il corso. La strada pi√π semplice per soddisfare questi requisiti √® attraverso l‚Äôinstallazione di Anaconda, che semplifica notevolmente il processo di configurazione iniziale e gestione degli ambienti virtuali.\nQuesta guida all‚Äôinstallazione locale mira a fornirvi tutti gli strumenti necessari per iniziare a utilizzare i Jupyter Notebook nel contesto del nostro corso, facilitando un apprendimento efficiente e la condivisione dei risultati delle vostre analisi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-di-anaconda",
    "href": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-di-anaconda",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.2 Guida all‚ÄôInstallazione di Anaconda",
    "text": "A.2 Guida all‚ÄôInstallazione di Anaconda\nAnaconda √® una distribuzione popolare per la programmazione in Python. Ecco una guida passo-passo per l‚Äôinstallazione:\n\nScaricare Anaconda:\n\nVisitate il sito ufficiale di Anaconda: https://www.anaconda.com/.\nScegliete la versione adatta al vostro sistema operativo (Windows, macOS o Linux).\nOptate per il download dell‚Äôultima versione disponibile, che include l‚Äôultima versione di Python.\n\nInstallare Anaconda:\n\nEseguite il file di installazione scaricato.\nSeguite le istruzioni visualizzate, mantenendo le impostazioni predefinite, a meno che non abbiate esigenze specifiche.\n\nAggiungere Anaconda al ‚ÄòPATH‚Äô del Sistema:\n\nDurante l‚Äôinstallazione, vi sar√† chiesto se desiderate aggiungere Anaconda al ‚ÄòPATH‚Äô del sistema. Questo passaggio √® cruciale poich√© consente di utilizzare Python da qualunque parte del computer.\nVi consiglio di selezionare questa opzione (altri metodi sono possibili, ma questo ha dimostrato di funzionare senza problemi).\n\nConfermare l‚ÄôInstallazione:\n\nAl termine dell‚Äôinstallazione, aprite PowerShell all‚Äôinterno di Anaconda Navigagor (Windows) o il terminale (macOS/Linux) e digitate python --version per verificare se l‚Äôinstallazione √® riuscita. Se compare la versione di Python, tutto √® andato a buon fine.\n\n\nAnaconda include il Navigator, un‚Äôinterfaccia utente grafica per gestire ambienti di sviluppo, installare librerie aggiuntive e lanciare strumenti come Jupyter Notebook, che consente (in alternativa a VS Code) di scrivere ed eseguire codice Python.\n\n\n\n\n\n\nIstruzioni Specifiche per Utenti Windows:\n\nScaricare Anaconda:\n\nScaricate la versione ‚Äú64-Bit Graphical Installer‚Äù dal sito di Anaconda.\n\nInstallare Anaconda:\n\nAvviate l‚Äôinstaller scaricato e seguite le istruzioni visualizzate.\nDurante l‚Äôinstallazione, selezionate ‚ÄúJust Me‚Äù (solo per l‚Äôutente corrente).\nMantenete il percorso di installazione predefinito.\n\nIncludere Anaconda nel ‚ÄòPATH‚Äô:\n\nIMPORTANTE: Selezionate l‚Äôopzione per aggiungere Anaconda al PATH e impostarlo come installazione di Python di default. Di default, questa opzione √® deselezionata.\n\nVerifica dell‚ÄôInstallazione:\n\nCercate ‚ÄúAnaconda Navigator‚Äù nel menu Start. Se si apre correttamente, l‚Äôinstallazione √® riuscita.\nAprite ‚ÄúAnaconda Prompt‚Äù (o ‚ÄúPowerShell‚Äù) dal menu Start di Anaconda Navigator e digitate conda --version per confermare l‚Äôinstallazione di conda.\n\n\nSeguite attentamente queste istruzioni per garantire un‚Äôinstallazione senza problemi.\nPer maggiori dettagli, consultate il tutorial su come installare Anaconda su Windows: Tutorial Installazione di Anaconda su Windows. Questo tutorial offre spiegazioni dettagliate e una guida passo-passo.\n\n\n\nUna volta installato Anaconda, potrete utilizzare Anaconda Navigator per gestire progetti Python, installare librerie necessarie e avviare strumenti come Jupyter Notebook.\n\n\n\n\n\n\n√à necessario comprendere la differenza tra applicazione (App) e installer.\nCos‚Äô√® un‚ÄôApplicazione (App)\nUn‚Äôapplicazione, comunemente chiamata ‚Äúapp‚Äù, √® un software che funziona sul vostro computer o dispositivo mobile per uno scopo specifico, come navigare in internet, inviare messaggi, elaborare testi o fare calcoli. Esempi includono browser web come Google Chrome, programmi di elaborazione testi come Microsoft Word, o sistemi come Anaconda Navigator.\nCos‚Äô√® un Installer\nUn installer √® un software che installa un‚Äôapplicazione sul vostro computer. Tipicamente, quando scaricate un‚Äôapplicazione da internet, scaricate in realt√† l‚Äôinstaller. L‚Äôinstaller ha il compito di: - Copiare i file dell‚Äôapp nella corretta cartella del computer. - Creare scorciatoie per l‚Äôapp, come icone sul desktop o voci nel menu Start. - Configurare impostazioni iniziali per il corretto funzionamento dell‚Äôapp.\nDopo l‚ÄôInstallazione\nDopo che l‚Äôinstaller ha completato il suo lavoro, l‚Äôapplicazione sar√† pronta all‚Äôuso e l‚Äôinstaller pu√≤ essere eliminato.\nIn sintesi, l‚Äôapplicazione √® il software che userete per svolgere compiti specifici, mentre l‚Äôinstaller √® lo strumento temporaneo per installare l‚Äôapplicazione sul vostro computer. Capire questa distinzione √® fondamentale nel mondo dell‚Äôinformatica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#sec-virtual-environment",
    "href": "chapters/chapter_7/a00_installation.html#sec-virtual-environment",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.3 L‚ÄôAmbiente Virtuale in Python",
    "text": "A.3 L‚ÄôAmbiente Virtuale in Python\nDopo aver installato Python tramite Anaconda, un aspetto fondamentale da considerare √® la creazione di un ambiente virtuale. Un ambiente virtuale rappresenta uno spazio dedicato sul vostro computer, dove √® possibile installare e gestire le librerie Python necessarie per il corso, inclusi quelle per l‚Äôanalisi statistica. La creazione di un ambiente virtuale √® estremamente vantaggiosa poich√© contribuisce all‚Äôorganizzazione del lavoro e previene possibili conflitti tra diverse librerie. Le istruzioni dettagliate per la configurazione di un ambiente virtuale sono disponibili nel Appendice E`.\nL‚Äôesecuzione delle fasi precedentemente delineate, ossia l‚Äôinstallazione di Anaconda, la configurazione di Visual Studio Code e la creazione di un ambiente virtuale, assicurer√† la completa preparazione di un ambiente di sviluppo locale ottimizzato per l‚Äôutilizzo dei Jupyter Notebook nelle vostre attivit√† legate alla data science all‚Äôinterno di questo corso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#la-shell",
    "href": "chapters/chapter_7/a00_installation.html#la-shell",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.4 La Shell",
    "text": "A.4 La Shell\nPer la creazione e la gestione dell‚Äôambiente di calcolo, l‚Äôuso di una shell √® indispensabile. Questa pu√≤ essere approfondita nella sezione {ref}appendix-shell. La shell permette di interagire con il sistema operativo attraverso l‚Äôuso di comandi in un terminale. Diverse soluzioni software sono disponibili per facilitare questa interazione.\n\nA.4.1 Unix (MacOS, Linux)\nIn ambienti Unix come MacOS e Linux, ci sono diverse shell tra cui scegliere. Una scelta popolare √® Bash, che √® comunemente preinstallata su molti sistemi Unix. Un‚Äôaltra opzione moderna √® Zsh, nota per la sua facilit√† di personalizzazione e funzionalit√† avanzate. Per un‚Äôesperienza di terminale migliorata, warp √® un‚Äôopzione innovativa che offre un‚Äôinterfaccia utente ricca di funzionalit√† e supporto per i comandi intelligenti.\n\n\nA.4.2 Windows\nSu Windows, la shell predefinita √® il Prompt dei Comandi, ma non √® cos√¨ potente o flessibile come le shell disponibili su Unix. PowerShell √® un‚Äôopzione pi√π avanzata disponibile su Windows, che combina la gestione della configurazione e l‚Äôautomazione delle attivit√† con un linguaggio di scripting.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#lavorare-con-visual-studio-code",
    "href": "chapters/chapter_7/a00_installation.html#lavorare-con-visual-studio-code",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.5 Lavorare con Visual Studio Code",
    "text": "A.5 Lavorare con Visual Studio Code\nPer utilizzare Visual Studio Code con Python e Jupyter Notebook, √® essenziale installare le relative estensioni. Per fare ci√≤, √® sufficiente seguire alcuni semplici passaggi:\n\nAvvia Visual Studio Code sul tuo computer.\nNella barra laterale sinistra, trova e clicca sull‚Äôicona con quattro quadrati, di cui uno disallineato. Questo √® il menu delle estensioni.\nNella barra di ricerca all‚Äôinterno del menu delle estensioni, digita ‚ÄúPython‚Äù e premi Invio. Troverai diverse estensioni relative a Python.\nTrova l‚Äôestensione ufficiale di Python sviluppata da Microsoft e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\nSuccessivamente, cerca ‚ÄúJupyter‚Äù nella barra di ricerca delle estensioni e premi Invio.\nTrova l‚Äôestensione ‚ÄúJupyter‚Äù nell‚Äôelenco dei risultati e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\n\nUna volta completati questi passaggi, avrai installato con successo le componenti aggiuntive necessarie per lavorare con Python e Jupyter Notebook all‚Äôinterno di Visual Studio Code. Potrai quindi iniziare a scrivere, eseguire e testare il tuo codice Python e i tuoi notebook Jupyter direttamente nell‚Äôambiente di sviluppo di Visual Studio Code.\nQuando apri un file con estensione .ipynb in Visual Studio Code ricorda di selezionare l‚Äôambiente virtuale che desiderate utilizzare. Puoi farlo tramite la ‚ÄúCommand Palette‚Äù (‚áß‚åòP), utilizzando l‚Äôistruzione Python: Select Interpreter. In alternativa, puoi fare clic sull‚Äôicona Select kernel di Visual Studio Code, che si trova nell‚Äôangolo in alto a destra, sotto l‚Äôicona degli ingranaggi (‚öôÔ∏è).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#google-colab",
    "href": "chapters/chapter_7/a00_installation.html#google-colab",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.6 Google Colab",
    "text": "A.6 Google Colab\nUtilizzando il link √® possibile accedere a Google Colab e iniziare a scrivere codice Python direttamente dal proprio browser, senza dover effettuare alcuna installazione. Basta selezionare l‚Äôopzione ‚ÄúNuovo notebook‚Äù per creare un nuovo ambiente di lavoro. Per avere un‚Äôintroduzione completa sulle funzionalit√† di Colab, si pu√≤ consultare la guida disponibile al seguente link. √à possibile salvare ogni notebook nella propria cartella di Google Drive per una facile gestione e condivisione dei file.\n\nA.6.1 Uso dei Comandi Speciali in Colab\nNell‚Äôambiente Google Colab, √® possibile utilizzare il comando\n!pip list -v\nper visualizzare un elenco dettagliato di tutte le librerie preinstallate. Questo comando fornisce informazioni utili per comprendere quali strumenti sono immediatamente disponibili per l‚Äôuso, comprese le versioni delle librerie e i percorsi di installazione.\nIl prefisso ! indica un comando speciale, noto anche come comando ‚Äúshell‚Äù, che consente di interagire con il sistema sottostante di Colab direttamente dalla cella del notebook, eseguendo operazioni al di fuori dell‚Äôambiente Python standard.\n\n\nA.6.2 Installazione di Librerie Supplementari\nSe necessario aggiungere ulteriori librerie all‚Äôambiente Colab, come pymc, bambi, e arviz, √® possibile farlo facilmente mediante l‚Äôuso dei comandi pip. Ad esempio, per installare queste tre librerie, si possono eseguire i seguenti comandi uno dopo l‚Äôaltro:\n!pip install bambi\n!pip install pymc\n!pip install arviz\nQuesti comandi non solo installeranno le librerie specificate ma gestiranno anche automaticamente l‚Äôinstallazione delle dipendenze necessarie, tra cui numpy, pandas, matplotlib, seaborn, scipy, e statsmodels, assicurando cos√¨ che tutto l‚Äôambiente di lavoro sia pronto per l‚Äôuso.\n\n\nA.6.3 Google Drive\n\nA.6.3.1 Collegare Google Drive a Colab\nPer accedere alla propria cartella di Google Drive durante l‚Äôutilizzo di Colab, √® possibile seguire i seguenti passaggi:\n\nDalla pagina iniziale, fare clic sull‚Äôicona a forma di cartella (Files) situata nel menu in alto a sinistra.\n\n\n\nSi aprir√† un menu con diverse opzioni.\n\n\n\nSelezionare la terza icona tra le quattro disposte orizzontalmente. Apparir√† l‚Äôistruzione ‚ÄúRun this cell to mount your Google Drive‚Äù. Fare clic sull‚Äôicona del triangolo contenuta in un cerchio grigio.\nA questo punto, fare clic sull‚Äôicona ‚Äúdrive‚Äù e successivamente su ‚ÄúMyDrive‚Äù per accedere alle cartelle e ai file salvati sul proprio Google Drive.\n\n√à importante tenere presente che la versione gratuita del runtime di Google Colaboratory non salva le informazioni in modo permanente, il che significa che tutto il lavoro svolto verr√† eliminato una volta terminata la sessione. Pertanto, √® necessario reinstallare le librerie utilizzate in precedenza ogni volta che ci si connette a Colab. Al contrario, i Jupyter Notebook possono essere salvati nella propria cartella di Google Drive.\nPer salvare un Jupyter Notebook su Google Drive utilizzando Colab, √® possibile seguire i seguenti passaggi:\n\nFare clic su File nella barra del menu di Colab.\nSelezionare Save a copy in Drive. Di default, Colab salver√† il Notebook nella cartella Colab Notebooks/.ipynb_checkpoints con un nome simile a Untitled7.ipynb.\nDopo aver salvato il Notebook, √® consigliabile rinominarlo facendo clic con il pulsante destro del mouse sul file nella cartella di Google Drive e selezionando Rename. In questo modo sar√† possibile assegnare un nome pi√π significativo al Notebook.\nPer organizzare i file, √® possibile trascinare il Notebook nella cartella desiderata all‚Äôinterno di Google Drive.\n\nSeguendo questi passaggi, sar√† possibile salvare e organizzare i Jupyter Notebook nella propria cartella di Google Drive, consentendo di accedervi facilmente e mantenerli in modo permanente anche dopo la sessione di Colab.\n\n\n\n\n\n\n√à possibile accedere a un breve tutorial video su come utilizzare Colab e come leggere i dati da un file esterno in un Notebook di Jupyter in Colab. Il video tutorial pu√≤ essere trovato seguendo il link fornito.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html",
    "href": "chapters/chapter_7/a01_markdown.html",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "B.1 Configurazione Locale per Jupyter Notebook\nPer iniziare a lavorare con i Jupyter Notebook nel proprio ambiente di sviluppo locale, √® necessario completare alcuni passaggi preliminari che assicurano una configurazione ottimale:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "href": "chapters/chapter_7/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "Installazione di Python tramite Anaconda: Anaconda √® una distribuzione di Python che include gi√† Jupyter e altre librerie utili per la data science e l‚Äôanalisi di dati. Seguendo le istruzioni dettagliate disponibili sul sito di Anaconda (e fornite in precedenza in questa dispensa), si pu√≤ facilmente installare Python e Jupyter sul proprio sistema.\nSelezione di un Ambiente di Sviluppo Integrato (IDE): Visual Studio Code (VS Code) rappresenta una scelta eccellente per chi cerca un IDE versatile e gratuito. Disponibile al download dal sito ufficiale, VS Code supporta Python tramite l‚Äôinstallazione di una specifica estensione. Dopo aver installato VS Code, √® possibile aggiungere il supporto per Python e per i Jupyter Notebook installando l‚Äôestensione ‚ÄúPython‚Äù disponibile nella sezione ‚ÄúExtensions‚Äù, identificabile dall‚Äôicona dei quattro quadrati. Per una completa integrazione dei notebook Jupyter, potrebbe essere necessario installare anche la libreria ipykernel.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#celle",
    "href": "chapters/chapter_7/a01_markdown.html#celle",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.2 Celle",
    "text": "B.2 Celle\nI Jupyter Notebook sono organizzati in celle, elementi discreti che possono contenere codice o testo (markdown). La possibilit√† di cambiare il tipo di una cella tramite il menu ‚ÄúCell‚Äù o la barra degli strumenti, selezionando ‚ÄúCode‚Äù per codice Python o ‚ÄúMarkdown‚Äù per annotazioni testuali, rende i notebook estremamente versatili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#formattazione-del-testo-con-markdown",
    "href": "chapters/chapter_7/a01_markdown.html#formattazione-del-testo-con-markdown",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.3 Formattazione del Testo con Markdown",
    "text": "B.3 Formattazione del Testo con Markdown\nMarkdown permette di arricchire le celle di testo con formattazioni varie, creando un documento strutturato e leggibile. Ecco alcuni esempi:\n\nTitoli: # Titolo per un titolo di primo livello, ## Sottotitolo per un secondo livello, e cos√¨ via.\nElenchi: - Elemento per elenchi puntati, 1. Elemento per elenchi numerati.\nCollegamenti: [Testo del link](URL) per inserire un link.\nEnfasi: **grassetto** per il testo in grassetto, *corsivo* per il corsivo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "href": "chapters/chapter_7/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.4 Comandi Magici in Jupyter Notebook",
    "text": "B.4 Comandi Magici in Jupyter Notebook\nI Jupyter Notebook supportano i ‚Äúcomandi magici‚Äù, comandi speciali che iniziano con % (per comandi su una singola riga) o %% (per comandi che occupano un‚Äôintera cella). Questi comandi offrono funzionalit√† avanzate come:\n\n%run: esegue un file Python esterno.\n%timeit: valuta il tempo di esecuzione di una singola riga di codice.\n%matplotlib inline: integra grafici Matplotlib direttamente nel notebook.\n%load: carica il codice da un file esterno in una cella.\n%reset: cancella tutte le variabili definite nel notebook.\n%pwd e %cd: gestiscono il percorso della directory di lavoro.\n\nDigitando %lsmagic in una cella, si pu√≤ accedere all‚Äôelenco completo dei comandi magici disponibili, esplorando cos√¨ ulteriori strumenti e funzionalit√† offerte da Jupyter Notebook.\nIn conclusione, i Jupyter Notebook rappresentano uno strumento indispensabile per chi lavora nel campo della programmazione e dell‚Äôanalisi dati, grazie alla loro capacit√† di unire codice, visualizzazione dei dati, e annotazioni testuali in un unico documento interattivo e facilmente condivisibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a02_shell.html",
    "href": "chapters/chapter_7/a02_shell.html",
    "title": "Appendice C ‚Äî La Shell",
    "section": "",
    "text": "C.1 Che cos‚Äô√® una Shell?\nUna shell √® un programma che riceve comandi dall‚Äôutente tramite tastiera (o da file) e li passa al sistema operativo per l‚Äôesecuzione. Pu√≤ essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a02_shell.html#che-cos√®-una-shell",
    "href": "chapters/chapter_7/a02_shell.html#che-cos√®-una-shell",
    "title": "Appendice C ‚Äî La Shell",
    "section": "",
    "text": "C.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nC.1.2 Windows vs macOS/Linux\n\nWindows 10: √à possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l‚Äôambiente preferito √® solitamente PowerShell.\nmacOS/Linux: Zsh √® la shell predefinita in entrambi i sistemi. √à consigliabile sfruttare l‚Äôapplicazione warp per un‚Äôesperienza utente moderna e ottimizzata.\n\n\n\nC.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nC.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nC.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless/more: Visualizza il contenuto dei file con possibilit√† di navigazione.\ncat: Mostra l‚Äôintero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nC.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l‚Äôutilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilit√† nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma pi√π potente perch√© pu√≤ rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nC.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nC.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilit√† di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l‚Äôintero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nSuggerimenti per una Gestione Ottimale dei File e delle Cartelle\n\n\n\n√à cruciale familiarizzarsi con l‚Äôutilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L‚Äôimpiego dei percorsi relativi rende il processo di navigazione pi√π intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l‚Äôutilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: √à importante evitare l‚Äôinserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, ), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l‚Äôuso del trattino (-) pu√≤ causare problemi; quindi √® consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilit√† con alcuni sistemi operativi o applicazioni, rendendo pi√π complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, √® consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, √® possibile ottimizzare notevolmente l‚Äôorganizzazione e la gestione dei propri file, migliorando l‚Äôefficienza del lavoro e riducendo il rischio di errori.\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarit√† con la shell √® fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a03_colab_tutorial.html",
    "href": "chapters/chapter_7/a03_colab_tutorial.html",
    "title": "Appendice D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "D.1 Preparazione su Google Drive\nPer iniziare, √® necessario effettuare alcune operazioni preliminari su Google Drive:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a03_colab_tutorial.html#preparazione-su-google-drive",
    "href": "chapters/chapter_7/a03_colab_tutorial.html#preparazione-su-google-drive",
    "title": "Appendice D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "Salvataggio dei file necessari: Accedi al tuo account Google Drive e salva i file di interesse, come un dataset e un Jupyter Notebook. Per esempio, potresti creare un Jupyter Notebook con Visual Studio Code e salvarlo con l‚Äôestensione .ipynb. In questo esempio, il file STAR.csv √® stato salvato nella cartella drive/MyDrive/teaching/psicometria/2024.\nPosizionamento dei file: Assicurati di conoscere con precisione il percorso della cartella in cui hai salvato i tuoi file. √à possibile salvare il notebook in qualsiasi cartella, ma √® importante ricordare dove si trova. Nel nostro esempio, anche il notebook import_data.ipynb √® stato salvato nella stessa cartella del dataset.\n\n\nD.1.1 Collegamento a Google Colab\nPer collegare il tuo Google Drive a Colab, inserisci il seguente codice nella prima cella del tuo Jupyter Notebook su Colab:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nEsegui questa cella per iniziare il processo di autenticazione. Ti verr√† richiesto di inserire le tue credenziali (si consiglia di utilizzare l‚Äôaccount istituzionale) e di concedere i permessi necessari a Colab per accedere al tuo Drive.\n\n\nD.1.2 Verifica del file\nPrima di procedere, √® utile verificare che il file desiderato si trovi effettivamente nel percorso specificato. Usa un comando simile al seguente per elencare i file presenti nella cartella:\n!ls drive/MyDrive/teaching/psicometria/2024\nSe il comando mostra il file STAR.csv, significa che √® presente nella cartella e pronto per essere utilizzato.\n\n\nD.1.3 Importazione dei pacchetti e del dataset\nPrima di importare i dati, importa i pacchetti Python necessari per la tua analisi:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSuccessivamente, puoi importare i dati direttamente dal file CSV specificando il percorso completo:\ndf = pd.read_csv(\"drive/MyDrive/teaching/psicometria/2024/STAR.csv\")\n√à fondamentale usare il percorso completo dal punto di montaggio drive fino al nome del file. Il percorso varier√† a seconda dell‚Äôutente e della struttura del suo Drive.\n\n\nD.1.4 Visualizzazione dei dati\nCon i dati ora disponibili in df, puoi procedere con l‚Äôanalisi. Per esempio, per creare un istogramma della variabile reading, puoi usare il seguente codice:\n_ = sns.histplot(data=df, x=\"reading\", stat='density')\nQuesto ti permetter√† di visualizzare la distribuzione dei dati relativi alla lettura nel dataset STAR.csv.\nSeguendo questi passaggi, puoi facilmente lavorare con i file salvati su Google Drive direttamente all‚Äôinterno di un Jupyter Notebook su Google Colab.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html",
    "href": "chapters/chapter_7/a04_virtual_env.html",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "",
    "text": "E.1 Concetto di Ambiente Virtuale\nUn ambiente virtuale √® uno spazio di lavoro isolato sul vostro computer, dove potete installare e utilizzare librerie Python senza interferire con il sistema principale. Questo isolamento consente di gestire le versioni delle librerie in modo efficiente, mantenendo il sistema organizzato e sicuro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "href": "chapters/chapter_7/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali",
    "text": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali\n\nIsolamento: Permette di selezionare e mantenere versioni specifiche di Python e delle librerie, garantendo la compatibilit√† e la stabilit√† del progetto.\nOrdine e Sicurezza: Mantiene separato l‚Äôambiente virtuale dal sistema principale, evitando conflitti e assicurando che le modifiche non influenzino altri programmi.\nRiproducibilit√† del Codice: Consente di condividere il codice in modo che funzioni correttamente su altri computer, garantendo coerenza e riproducibilit√† del lavoro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "href": "chapters/chapter_7/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda",
    "text": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda\nPer creare e gestire ambienti virtuali, √® possibile utilizzare conda, uno strumento incluso in Anaconda. Seguire i seguenti passaggi:\n\nAssicurarsi di avere Anaconda correttamente installato sul sistema.\nUtilizzare il terminale su macOS/Linux o PowerShell su Windows.\nEvitare di installare pacchetti direttamente nell‚Äôambiente base di Conda.\nCreare un nuovo ambiente virtuale usando il comando conda create.\nAttivare l‚Äôambiente virtuale appena creato utilizzando conda activate.\nInstallare i pacchetti necessari all‚Äôinterno dell‚Äôambiente virtuale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "href": "chapters/chapter_7/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.4 Gestione dell‚ÄôAmbiente Virtuale",
    "text": "E.4 Gestione dell‚ÄôAmbiente Virtuale\nPer una gestione pi√π efficiente degli ambienti virtuali, √® consigliabile utilizzare la linea di comando anzich√© l‚Äôinterfaccia grafica di Anaconda. Questo offre maggiore controllo e flessibilit√† nel processo di creazione e gestione degli ambienti.\nSeguendo correttamente questi passaggi, √® possibile sfruttare appieno i vantaggi degli ambienti virtuali, garantendo un ambiente di sviluppo Python pulito e ben organizzato.\n\n\n\n\n\n\n√à fondamentale evitare l‚Äôinstallazione diretta di pacchetti nell‚Äôambiente base di Conda. Assicuratevi sempre di seguire attentamente i seguenti passaggi:\n\nDisattivate l‚Äôambiente base.\nCreate un nuovo ambiente virtuale.\nAttivate il nuovo ambiente appena creato.\n\nSolo dopo aver completato questi passaggi, √® sicuro procedere con l‚Äôinstallazione dei pacchetti necessari. √à possibile verificare l‚Äôambiente attivo osservando il nome visualizzato all‚Äôinizio del prompt nel terminale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "href": "chapters/chapter_7/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali",
    "text": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali\n\nDisattivare l‚ÄôAmbiente Virtuale Corrente: Se siete in un ambiente virtuale e desiderate uscirne, utilizzate il comando:\nconda deactivate\nSe non siete in un ambiente virtuale, potete procedere al passaggio successivo.\nCreare un Nuovo Ambiente Virtuale: Per utilizzare il campionatore CmdStan e il linguaggio di programmazione probabilistica Stan, adottate l‚Äôambiente virtuale cmdstan_env. Se si utilizza conda, √® possibile installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge tramite la seguente procedura:\nconda create -n cmdstan_env -c conda-forge cmdstanpy\nConda richieder√† la conferma digitando y. Questo passaggio crea l‚Äôambiente e installa cmdstanpy insieme alle dipendenze necessarie.\nAttivare il Nuovo Ambiente: Per utilizzare l‚Äôambiente appena creato, attivatelo tramite:\nconda activate cmdstan_env\nInstallare le Librerie Richieste: All‚Äôinterno dell‚Äôambiente, installate altre librerie necessarie. Ecco come installare le librerie che utilizzeremo:\nconda install -c conda-forge jax numpyro bambi arviz seaborn jupyter-book ipywidgets watermark pingouin networkx -y \nNota: Gli utenti Windows potrebbero dover utilizzare nutpie come alternativa a jax.\nComandi Utili per Gestire Ambienti e Librerie:\n\nElencare gli ambienti virtuali disponibili e verificare quello attivo:\nconda env list\nRimuovere un ambiente virtuale specifico, ad esempio my_env:\nconda env remove -n my_env\nRimuovere una libreria da un ambiente specifico, ad esempio package_name:\nconda remove -n nome_ambiente package_name\n\n\nSeguendo attentamente questi passaggi e utilizzando i comandi di gestione, sarete in grado di creare e gestire efficacemente gli ambienti virtuali con Conda, garantendo una gestione pulita e ordinata delle dipendenze dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#conda-forge",
    "href": "chapters/chapter_7/a04_virtual_env.html#conda-forge",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.6 Conda Forge",
    "text": "E.6 Conda Forge\n√à consigliato aggiungere Conda Forge come canale aggiuntivo da cui Conda pu√≤ cercare e installare i pacchetti. Conda Forge √® una collezione di pacchetti gestita dalla community.\n\nE.6.1 Aggiungere Conda Forge\nPer aggiungere Conda Forge come canale, eseguire i seguenti comandi:\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\nconda config --add channels conda-forge: Aggiunge Conda Forge come canale aggiuntivo per la ricerca e l‚Äôinstallazione dei pacchetti.\nconda config --set channel_priority strict: Imposta la priorit√† dei canali su ‚Äústrict‚Äù, dando priorit√† ai pacchetti trovati nei canali elencati per primi nel file di configurazione .condarc.\n\n\n\nE.6.2 Vantaggi dell‚ÄôUso di Conda Forge\n\nAmpia Disponibilit√† di Pacchetti: Conda Forge offre un numero maggiore di pacchetti rispetto al canale predefinito di Conda, aumentando le possibilit√† di trovare il pacchetto necessario senza ricorrere ad altre soluzioni.\nAggiornamenti Frequenti: I pacchetti su Conda Forge vengono aggiornati pi√π frequentemente, rendendo pi√π probabile trovare le versioni pi√π recenti.\nCoerenza e Compatibilit√†: Utilizzando la priorit√† ‚Äústrict‚Äù e Conda Forge, si aumenta la coerenza e la compatibilit√† tra i pacchetti, riducendo il rischio di conflitti tra dipendenze.\n\nAggiungere Conda Forge come canale e impostare la priorit√† dei canali su ‚Äústrict‚Äù sono pratiche consigliate per migliorare la gestione dei pacchetti con Conda. Questo approccio aiuta a mantenere l‚Äôambiente stabile, aggiornato e compatibile con le ultime versioni dei pacchetti disponibili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "href": "chapters/chapter_7/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.7 Utilizzo di Graphviz (Opzionale)",
    "text": "E.7 Utilizzo di Graphviz (Opzionale)\nPer utilizzare il pacchetto Python graphviz, √® necessario installare prima Graphviz sul vostro computer. Le istruzioni specifiche per l‚Äôinstallazione variano a seconda del sistema operativo e sono disponibili sul sito ufficiale di Graphviz.\n\nE.7.1 Installazione di Graphviz\n\nInstallazione di Graphviz: Seguire le istruzioni sul sito di Graphviz per installare il software sul vostro sistema operativo (Windows, macOS, Linux).\nVerifica dell‚ÄôInstallazione: Dopo l‚Äôinstallazione, assicuratevi che Graphviz sia correttamente installato eseguendo il seguente comando nel terminale:\ndot -V\nQuesto comando dovrebbe restituire la versione di Graphviz installata.\n\n\n\nE.7.2 Installazione del Pacchetto Python graphviz\nDopo aver installato Graphviz, potete procedere con l‚Äôinstallazione del pacchetto Python graphviz nel vostro ambiente virtuale. Seguite questi passaggi:\n\nAttivare l‚ÄôAmbiente Virtuale: Attivate l‚Äôambiente virtuale in cui avete installato pymc (ad esempio, pymc_env) nella vostra console:\nconda activate pymc_env\nInstallare il Pacchetto Python graphviz: Eseguite il seguente comando per installare il pacchetto graphviz tramite Conda Forge:\nconda install -c conda-forge graphviz\n\n\n\nE.7.3 Vantaggi dell‚ÄôUtilizzo di Graphviz\nL‚Äôinstallazione di Graphviz e del relativo pacchetto Python consente di creare e visualizzare grafici e diagrammi all‚Äôinterno del vostro ambiente Python. Questo pu√≤ essere particolarmente utile per visualizzare strutture di dati complesse, flussi di lavoro o grafi probabilistici.\nSeguendo questi passaggi, sarete in grado di utilizzare le funzionalit√† di Graphviz nel vostro ambiente Python, migliorando le capacit√† di visualizzazione e analisi dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a10_math_symbols.html",
    "href": "chapters/chapter_7/a10_math_symbols.html",
    "title": "Appendice F ‚Äî Simbologia di base",
    "section": "",
    "text": "Per una scrittura pi√π sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL‚Äôoperatore logico booleano \\(\\land\\) significa ‚Äúe‚Äù (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa ‚Äúo‚Äù (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire ‚Äúesiste almeno un‚Äù e indica l‚Äôesistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicit√† \\(\\exists!\\) (‚Äúesiste soltanto un‚Äù) indica l‚Äôesistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l‚Äôesistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire ‚Äúper ogni.‚Äù\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) √® un elemento dell‚Äôinsieme \\(A\\).\nL‚Äôimplicazione logica ‚Äú\\(\\Rightarrow\\)‚Äù significa ‚Äúimplica‚Äù (se ‚Ä¶allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) √® condizione sufficiente per la verit√† di \\(Q\\) e che \\(Q\\) √® condizione necessaria per la verit√† di \\(P\\).\nL‚Äôequivalenza matematica ‚Äú\\(\\iff\\)‚Äù significa ‚Äúse e solo se‚Äù e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge ‚Äútale che.‚Äù\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge ‚Äúuguale per definizione.‚Äù\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge ‚Äúproporzionale a.‚Äù\nIl simbolo \\(\\approx\\) si legge ‚Äúcirca.‚Äù\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire ‚Äúappartiene‚Äù e indica l‚Äôappartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire ‚Äúnon appartiene.‚Äù\nIl simbolo \\(\\subseteq\\) si legge ‚Äú√® un sottoinsieme di‚Äù (pu√≤ coincidere con l‚Äôinsieme stesso). Il simbolo \\(\\subset\\) si legge ‚Äú√® un sottoinsieme proprio di.‚Äù\nIl simbolo \\(\\#\\) indica la cardinalit√† di un insieme.\nIl simbolo \\(\\cap\\) indica l‚Äôintersezione di due insiemi. Il simbolo \\(\\cup\\) indica l‚Äôunione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l‚Äôinsieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l‚Äôinsieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) √® l‚Äôinsieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore pi√π alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densit√† di probabilit√†.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilit√† o densit√† di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) √® una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilit√† di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilit√† di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html",
    "href": "chapters/chapter_7/a11_numbers.html",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "",
    "text": "G.1 Numeri binari\nI numeri binari costituiscono la forma pi√π fondamentale di sistema numerico in informatica, essendo composto esclusivamente da due simboli, ovvero 0 e 1. Questo sistema √® frequentemente impiegato per rappresentare dualit√† logiche, come vero/falso o presenza/assenza, in virt√π della sua innata semplicit√† binaria. La sua applicazione √® particolarmente efficace nell‚Äôelaborazione di dati per generare statistiche sintetiche in modo efficiente e rapido.\nImmaginiamo di porre la seguente domanda a 10 studenti: ‚ÄúTi piacciono i mirtilli?‚Äù Le risposte potrebbero essere le seguenti:\nopinion = (True, False, True, True, True, False, True, True, True, False)\nopinion\n\n(True, False, True, True, True, False, True, True, True, False)\nIn questo caso, abbiamo utilizzato i numeri binari 0 e 1 per rappresentare risposte diverse, dove False indica ‚ÄúNo‚Äù e True indica ‚ÄúSi‚Äù. Questa rappresentazione binaria ci consente di ottenere facilmente una panoramica delle preferenze degli studenti riguardo i mirtilli.\nIn Python True equivale a 1 e False a zero. Possiamo dunque calcolare la proporzione di risposte positive nel modo seguente:\nsum(opinion) / len(opinion)\n\n0.7",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-interi",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-interi",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.2 Numeri interi",
    "text": "G.2 Numeri interi\nI numeri interi sono numeri privi di decimali e comprendono sia i numeri naturali utilizzati per il conteggio, come 1, 2, ‚Ä¶, sia i numeri con il segno, necessari per rappresentare grandezze negative. L‚Äôinsieme dei numeri naturali √® indicato con il simbolo \\(\\mathbb{N}\\). L‚Äôinsieme numerico dei numeri interi relativi si rappresenta come \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-razionali",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-razionali",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.3 Numeri razionali",
    "text": "G.3 Numeri razionali\nI numeri razionali sono numeri frazionari rappresentabili come \\(m/n\\), dove \\(m\\) e \\(n\\) sono numeri interi e \\(n\\) √® diverso da zero. Gli elementi dell‚Äôinsieme dei numeri razionali sono quindi dati da \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). √à importante notare che l‚Äôinsieme dei numeri naturali √® incluso in quello dei numeri interi, che a sua volta √® incluso in quello dei numeri razionali, ovvero \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Per rappresentare solo i numeri razionali non negativi, utilizziamo il simbolo \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.4 Numeri irrazionali",
    "text": "G.4 Numeri irrazionali\nTuttavia, alcune grandezze non possono essere esprimibili come numeri interi o razionali. Questi numeri sono noti come numeri irrazionali e sono rappresentati dall‚Äôinsieme \\(\\mathbb{R}\\). Essi comprendono numeri illimitati e non periodici, che non possono essere scritti come frazioni. Ad esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\(\\pi = 3.141592\\ldots\\) sono esempi di numeri irrazionali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-reali",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-reali",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.5 Numeri reali",
    "text": "G.5 Numeri reali\nI numeri razionali rappresentano solo una parte dei punti sulla retta \\(r\\). Per rappresentare ogni possibile punto sulla retta, √® necessario introdurre i numeri reali. L‚Äôinsieme dei numeri reali comprende numeri positivi, negativi e nulli, e contiene come casi particolari i numeri interi, razionali e irrazionali. In statistica, il numero di decimali spesso indica il grado di precisione della misurazione.\n\nG.5.1 Intervalli\nQuesto ci porta a esplorare gli intervalli, una struttura matematica che ci aiuta a definire sottoinsiemi specifici sulla retta numerica. Gli intervalli aperti, che escludono i punti di inizio e fine. D‚Äôaltro canto, gli intervalli chiusi includono sia il punto di inizio che quello di fine, fornendo una copertura di valori senza tralasciare i confini. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\n\nIntervallo\n\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a12_sum_notation.html",
    "href": "chapters/chapter_7/a12_sum_notation.html",
    "title": "Appendice H ‚Äî Simbolo di somma (sommatorie)",
    "section": "",
    "text": "H.1 Manipolazione di somme\n√à conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l‚Äôoperatore della sommatoria.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Simbolo di somma (sommatorie)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/chapter_7/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice H ‚Äî Simbolo di somma (sommatorie)",
    "section": "",
    "text": "H.1.1 Propriet√† 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) √® pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\nH.1.2 Propriet√† 2 (propriet√† distributiva)\nNel caso in cui l‚Äôargomento contenga una costante, √® possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\n√® possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nH.1.3 Propriet√† 3 (propriet√† associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\n√à dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nH.1.4 Propriet√† 4\nSe deve essere eseguita un‚Äôoperazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull‚Äôargomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nH.1.5 Propriet√† 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Simbolo di somma (sommatorie)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/chapter_7/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice H ‚Äî Simbolo di somma (sommatorie)",
    "section": "H.2 Doppia sommatoria",
    "text": "H.2 Doppia sommatoria\n√à possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell‚Äôindice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria √® il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi pu√≤ osservare che nella sommatoria interna (quella che dipende dall‚Äôindice \\(j\\)), la quantit√† \\(x_i\\) √® costante, ovvero non dipende dall‚Äôindice (che √® \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall‚Äôoperatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si pu√≤ osservare che nell‚Äôargomento della sommatoria esterna la quantit√† costituita dalla sommatoria in \\(j\\) non dipende dall‚Äôindice \\(i\\) e quindi questa quantit√† pu√≤ essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n}¬†x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto cos√¨ ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Simbolo di somma (sommatorie)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html",
    "href": "chapters/chapter_7/a13_sets.html",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "",
    "text": "I.1 Diagrammi di Eulero-Venn\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le propriet√† delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19¬∞ secolo John Venn, anche se rappresentazioni simili erano gi√† state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, √® possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le propriet√† degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all‚Äôinterno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/chapter_7/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.2 Appartenenza ad un insieme",
    "text": "I.2 Appartenenza ad un insieme\nUsiamo ora Python.\n\nSet1 = {1, 2}\nprint(Set1)\nprint(type(Set1))\n\n{1, 2}\n&lt;class 'set'&gt;\n\n\n\nmy_list = [1, 2, 3, 4]\nmy_set_from_list = set(my_list)\nprint(my_set_from_list)\n\n{1, 2, 3, 4}\n\n\nL‚Äôappartenenza ad un insieme si verifica con in e not in.\n\nmy_set = set([1, 3, 5])\nprint(\"Ecco il mio insieme:\", my_set)\nprint(\"1 appartiene all'insieme:\", 1 in my_set)\nprint(\"2 non appartiene all'insieme:\", 2 in my_set)\nprint(\"4 NON appartiene all'insieme:\", 4 not in my_set)\n\nEcco il mio insieme: {1, 3, 5}\n1 appartiene all'insieme: True\n2 non appartiene all'insieme: False\n4 NON appartiene all'insieme: True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/chapter_7/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.3 Relazioni tra insiemi",
    "text": "I.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l‚Äôinsieme universo e l‚Äôinsieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv = set([x for x in range(11)])\nSuper = set([x for x in range(11) if x % 2 == 0])\nDisj = set([x for x in range(11) if x % 2 == 1])\nSub = set([4, 6])\nNull = set([x for x in range(11) if x &gt; 10])\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\", Univ)\nprint(\"Tutti gli interi positivi pari fino a 10:\", Super)\nprint(\"Tutti gli interi positivi dispari fino a 10:\", Disj)\nprint(\"Insieme di due elementi, 4 e 6:\", Sub)\nprint(\"Un isieme vuoto:\", Null)\n\nInsieme Universo (tutti gli interi positivi fino a 10): {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nTutti gli interi positivi pari fino a 10: {0, 2, 4, 6, 8, 10}\nTutti gli interi positivi dispari fino a 10: {1, 3, 5, 7, 9}\nInsieme di due elementi, 4 e 6: {4, 6}\nUn isieme vuoto: set()\n\n\n\nprint('√à \"Super\" un sovrainsieme di \"Sub\"?', Super.issuperset(Sub))\nprint('√à \"Super\" un sottoinsieme di \"Univ\"?', Super.issubset(Univ))\nprint('√à \"Sub\" un sovrainsieme di \"Super\"?', Sub.issuperset(Super))\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?', Sub.isdisjoint(Disj))\n\n√à \"Super\" un sovrainsieme di \"Sub\"? True\n√à \"Super\" un sottoinsieme di \"Univ\"? True\n√à \"Sub\" un sovrainsieme di \"Super\"? False\nSono \"Super\" e \"Disj\" insiemi disgiunti? True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/chapter_7/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.4 Operazioni tra insiemi",
    "text": "I.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cio√®\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l‚Äôinsieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l‚Äôinsieme differenza \\(A \\setminus B\\) √® detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) √® una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare √® data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) √® la regione delimitata dal rettangolo, \\(L\\) √® la regione all‚Äôinterno del cerchio di sinistra e \\(R\\) √® la regione all‚Äôinterno del cerchio di destra. La regione evidenziata mostra l‚Äôinsieme indicato sotto ciascuna figura.\n\n\n\nDiagrammi di Venn\n\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\n\nLeggi di DeMorgan\n\n\nVediamo ora come si eseguono le operazioni tra insiemi con Python.\nEguaglianza e differenza.\n\nS1 = {1, 2}\nS2 = {2, 2, 1, 1, 2}\nprint(\n    \"S1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\nS1==S2: True\n\n\n\nS1 = {1, 2, 3, 4, 5, 6}\nS2 = {1, 2, 3, 4, 0, 6}\nprint(\n    \"S1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\nS1==S2: False\n\n\nIntersezione. Si noti che il connettivo logico & corrisponde all‚Äôintersezione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\n\nS1: {9, 3, 6}\n\n\n\nS2 = set([x for x in range(1, 7)])\nprint(\"S2:\", S2)\n\nS2: {1, 2, 3, 4, 5, 6}\n\n\n\nS_intersection = S1.intersection(S2)\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nS_intersection = S1 & S2\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\n\n\n\nS3 = set([x for x in range(6, 10)])\nprint(\"S3:\", S3)\nS1_S2_S3 = S1.intersection(S2).intersection(S3)\nprint(\"Intersection of S1, S2, and S3:\", S1_S2_S3)\n\nS3: {8, 9, 6, 7}\nIntersection of S1, S2, and S3: {6}\n\n\nUnione. Si noti che il connettivo logico | corrisponde all‚Äôunione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\nS2 = set([x for x in range(1, 5)])\nprint(\"S2:\", S2)\n\nS_union = S1.union(S2)\nprint(\"Unione di S1 e S2:\", S_union)\nS_union = S1 | S2\nprint(\"Unione di S1 e S2:\", S_union)\n\nS1: {9, 3, 6}\nS2: {1, 2, 3, 4}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\n\n\nInsieme complementare.\n\nS = set([x for x in range(21) if x % 2 == 0])\nprint(\"S √® l'insieme dei numeri interi pari tra 0 e 20:\", S)\n\nS √® l'insieme dei numeri interi pari tra 0 e 20: {0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20}\n\n\n\nS_complement = set([x for x in range(21) if x % 2 != 0])\nprint(\"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\", S_complement)\n\nS_complement √® l'insieme dei numeri interi dispari tra 0 e 20: {1, 3, 5, 7, 9, 11, 13, 15, 17, 19}\n\n\n\nprint(\n    \"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\",\n    S.union(S_complement) == set([x for x in range(21)]),\n)\n\n√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20? True\n\n\nDifferenza tra insiemi.\n\nS1 = set([x for x in range(31) if x % 3 == 0])\nprint(\"Set S1:\", S1)\n\nSet S1: {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\n\n\n\nS2 = set([x for x in range(31) if x % 5 == 0])\nprint(\"Set S2:\", S2)\n\nSet S2: {0, 5, 10, 15, 20, 25, 30}\n\n\n\nS_difference = S2 - S1\nprint(\"Differenza tra S2 e S1, i.e. S2\\S1:\", S_difference)\n\nS_difference = S1.difference(S2)\nprint(\"Differenza tra S1 e S2, i.e. S1\\S2:\", S_difference)\n\nDifferenza tra S1 e S2 i.e. S2\\S1: {25, 10, 20, 5}\nDifferenza tra S2 e S1 i.e. S1\\S2: {3, 6, 9, 12, 18, 21, 24, 27}\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Œî, √® un‚Äôoperazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all‚Äôunione tra i due insiemi meno la loro intersezione.\n\nprint(\"S1\", S1)\nprint(\"S2\", S2)\nprint(\"Differenza simmetrica\", S1 ^ S2)\nprint(\"Differenza simmetrica\", S2.symmetric_difference(S1))\n\nS1 {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\nS2 {0, 5, 10, 15, 20, 25, 30}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/chapter_7/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.5 Coppie ordinate e prodotto cartesiano",
    "text": "I.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) √® l‚Äôinsieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) √® la prima componente (o prima coordinata) e \\(y\\) la seconda. L‚Äôinsieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPi√π in generale, un prodotto cartesiano di \\(n\\) insiemi pu√≤ essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento √® una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non √® dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento √® possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all‚Äôn-esimo. Il prodotto cartesiano prende il nome da Ren√© Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA = set([\"a\", \"b\", \"c\"])\nS = {1, 2, 3}\n\n\ndef cartesian_product(S1, S2):\n    result = set()\n    for i in S1:\n        for j in S2:\n            result.add(tuple([i, j]))\n    return result\n\n\nC = cartesian_product(A, S)\nprint(f\"Prodotto cartesiano di A e S\\n{A} x {S} = {C}\")\n\nProdotto cartesiano di A e S\n{'Head', 'Tail'} x {1, 2, 3} = {('Tail', 1), ('Head', 2), ('Head', 1), ('Tail', 3), ('Tail', 2), ('Head', 3)}\n\n\nSi definisce cardinalit√† (o potenza) di un insieme finito il numero degli elementi dell‚Äôinsieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalit√† dell'insieme prodotto cartesiano √®:\", len(C))\n\nLa cardinalit√† dell'insieme prodotto cartesiano √®: 9\n\n\nInvece di scrivere funzioni noi stessi, √® possibile usare la libreria itertools di Python. Si ricordi di trasformare l‚Äôoggetto risultante in una lista per la visualizzazione e la successiva elaborazione.\n\nfrom itertools import product as prod\n\n\nA = set([x for x in range(1, 7)])\nB = set([x for x in range(1, 7)])\np = list(prod(A, B))\n\nprint(\"A √® l'insieme di tutti i possibili lanci di un dado:\", A)\nprint(\"B √® l'insieme di tutti i possibili lanci di un dado:\", B)\nprint(\n    \"\\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\\n\",\n    p,\n)\n\nA √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\nB √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\n\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\n [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLa cardinalit√† (cio√® il numero di elementi) del prodotto cartesiano tra due o pi√π insiemi √® uguale al prodotto delle cardinalit√† degli insiemi considerati: card(A √ó B) = card(A) ¬∑ card(B).\nUsando itertools √® facile calcolare la cardinalit√† del prodotto cartesiano di un insieme per se stesso. Consideriamo il quadrato dell‚Äôinsieme costituito dai risultati del lancio di una moneta. L‚Äôinsieme risultante avr√† cardinalit√† \\(2 \\cdot 2 = 4\\).\n\nA = {\"Head\", \"Tail\"} \np2 = list(prod(A, repeat=2))  \nprint(f\"Il quadrato dell'insieme A √® un insieme che contiene {len(p2)} elementi: {p2}\")\n\nIl quadrato dell'insieme A √® un insieme che contiene 4 elementi: [('Head', 'Head'), ('Head', 'Tail'), ('Tail', 'Head'), ('Tail', 'Tail')]\n\n\nL‚Äôinsieme \\(A\\) elevato alla terza potenza produce un insieme la cui cardinalit√† √®\n\np3 = list(prod(A, repeat=3))  \nprint(f\"L'insieme A elevato alla terza potenza √® costituito da {len(p3)} elementi: {p3}\")\n\nL'insieme A elevato alla terza potenza √® costituito da 8 elementi: [('Head', 'Head', 'Head'), ('Head', 'Head', 'Tail'), ('Head', 'Tail', 'Head'), ('Head', 'Tail', 'Tail'), ('Tail', 'Head', 'Head'), ('Tail', 'Head', 'Tail'), ('Tail', 'Tail', 'Head'), ('Tail', 'Tail', 'Tail')]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html",
    "href": "chapters/chapter_7/a13a_probability.html",
    "title": "Appendice J ‚Äî Sigma algebra",
    "section": "",
    "text": "J.1 Spiegazione\nUna \\(\\sigma\\)-algebra (o \\(\\sigma\\)-campo) √® un insieme di sottoinsiemi di uno spazio campionario \\(\\Omega\\) che soddisfa specifiche propriet√†. Queste propriet√† permettono di definire una struttura matematica per assegnare e calcolare le probabilit√† in modo consistente. Le propriet√† fondamentali di una \\(\\sigma\\)-algebra sono:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html#spiegazione",
    "href": "chapters/chapter_7/a13a_probability.html#spiegazione",
    "title": "Appendice J ‚Äî Sigma algebra",
    "section": "",
    "text": "Insieme Vuoto: L‚Äôinsieme vuoto \\(\\varnothing\\) deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{A}\\). Questo garantisce che anche l‚Äôassenza di qualsiasi evento sia considerata.\nChiusura rispetto all‚ÄôUnione: Se una sequenza infinita di insiemi \\(A_1, A_2, \\dots\\) appartiene a \\(\\mathcal{A}\\), allora anche la loro unione \\(\\cup_{i=1}^\\infty A_i\\) deve appartenere a \\(\\mathcal{A}\\). Questa propriet√† permette di costruire nuovi eventi a partire da unione di eventi gi√† considerati misurabili.\nChiusura rispetto al Complemento: Se un insieme \\(A\\) appartiene a \\(\\mathcal{A}\\), allora anche il suo complemento \\(A^c\\) deve appartenere a \\(\\mathcal{A}\\). Questa propriet√† assicura che, se possiamo misurare un evento, possiamo anche misurare l‚Äôevento opposto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html#spazi-misurabili-e-di-probabilit√†",
    "href": "chapters/chapter_7/a13a_probability.html#spazi-misurabili-e-di-probabilit√†",
    "title": "Appendice J ‚Äî Sigma algebra",
    "section": "J.2 Spazi Misurabili e di Probabilit√†",
    "text": "J.2 Spazi Misurabili e di Probabilit√†\n\nSpazio Misurabile: Una coppia \\((\\Omega, \\mathcal{A})\\), dove \\(\\Omega\\) √® lo spazio campionario e \\(\\mathcal{A}\\) √® una \\(\\sigma\\)-algebra su \\(\\Omega\\), √® chiamata spazio misurabile. In questo contesto, gli insiemi misurabili sono quelli a cui possiamo assegnare una misura, come la probabilit√†.\nSpazio di Probabilit√†: Se aggiungiamo una misura di probabilit√† \\(\\mathbb{P}\\) a uno spazio misurabile \\((\\Omega, \\mathcal{A})\\), otteniamo uno spazio di probabilit√† \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\). La misura di probabilit√† \\(\\mathbb{P}\\) assegna valori di probabilit√† a ciascuno degli insiemi in \\(\\mathcal{A}\\) in modo che le propriet√† assiomatiche della probabilit√† siano soddisfatte.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html#sigma-campo-di-borel",
    "href": "chapters/chapter_7/a13a_probability.html#sigma-campo-di-borel",
    "title": "Appendice J ‚Äî Sigma algebra",
    "section": "J.3 \\(\\sigma\\)-campo di Borel",
    "text": "J.3 \\(\\sigma\\)-campo di Borel\nQuando lo spazio campionario \\(\\Omega\\) √® la retta reale, si usa spesso il \\(\\sigma\\)-campo di Borel. Questo √® il pi√π piccolo \\(\\sigma\\)-campo che contiene tutti gli insiemi aperti della retta reale. √à fondamentale per definire la misurabilit√† e le probabilit√† su \\(\\mathbb{R}\\), poich√© contiene tutti gli insiemi che possiamo considerare ‚Äúmisurabili‚Äù nella pratica.\n\nJ.3.1 Conclusione\nLe \\(\\sigma\\)-algebre permettono di gestire insiemi e misure in modo strutturato e coerente, formando la base matematica per la teoria della probabilit√† e altre aree dell‚Äôanalisi matematica. Utilizzando \\(\\sigma\\)-algebre, possiamo definire spazi di probabilit√† che sono essenziali per modellare e analizzare fenomeni aleatori in maniera rigorosa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html",
    "href": "chapters/chapter_7/a14_combinatorics.html",
    "title": "Appendice K ‚Äî Calcolo combinatorio",
    "section": "",
    "text": "K.1 Principio del prodotto\nI metodi di base del calcolo combinatorio applicano due principi: la regola del prodotto e la regola della somma. Consideriamo il principio del prodotto.\nIn generale, una scelta pu√≤ essere effettuata in pi√π fasi, ad esempio \\(k\\). Supponiamo che per ogni \\(i = 1, \\dots, k\\) la scelta da compiere al \\(i\\)-esimo stadio possa essere effettuata in \\(n_i\\) modi. Secondo il principio del prodotto, il numero totale di possibili scelte √® dato dal prodotto dei singoli numeri, ovvero:\n\\[\nn_{\\text{tot}} = n_1 \\cdot  n_2 \\cdots n_{k-1} \\cdot n_k.\n\\]\nEsempio 1. Ho a disposizione 2 paia di scarpe, 3 paia di pantaloni e 5 magliette. In quanti modi diversi mi posso vestire?\n\\[\n2 \\cdot 3 \\cdot 5 = 30\n\\]\nEsempio 2. In Minnesota le targhe delle automobili sono costituite da tre lettere (da A a Z) seguite da tre numeri (da 0 a 9). Qual √® la proporzione di targhe che iniziano con GZN?\nLa soluzione √® data dal numero di targhe che iniziano con GZN diviso per il numero totale di targhe possibili.\nIl numero totale di targe √® \\(26 \\cdot 26 \\cdot 26 \\cdot 10 \\cdot 10 \\cdot 10 = 17,576,000\\). Per calcolare il numero di targhe che iniziano con GZN, consideriamo le targhe che hanno la forma GZN _ _ _. Per i tre simboli mancanti ci sono \\(10 \\cdot 10 \\cdot 10\\) possibilit√†. Dunque la proporzione cercata √®\n\\[\n10^3/(26^3 \\cdot 10^3) = 1/26^3 = 0.0000569.\n\\]\n10**3 / (26**3 * 10**3)\n\n5.689576695493855e-05",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/chapter_7/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice K ‚Äî Calcolo combinatorio",
    "section": "K.2 Principio della somma",
    "text": "K.2 Principio della somma\nIl principio della somma afferma che se un insieme pu√≤ essere suddiviso in due o pi√π sottoinsiemi disgiunti, allora il numero totale di elementi nell‚Äôinsieme √® dato dalla somma dei numeri di elementi in ciascun sottoinsieme.\nIn altre parole, se si vuole determinare il numero totale di modi in cui √® possibile realizzare un certo evento, e questo evento pu√≤ essere realizzato in modo esclusivo in modo A oppure B, allora il numero totale di modi in cui √® possibile realizzare l‚Äôevento √® dato dalla somma dei modi in cui pu√≤ essere realizzato in modo A e dei modi in cui pu√≤ essere realizzato in modo B.\nAd esempio, se si vuole determinare il numero totale di modi in cui √® possibile scegliere un dolce da una tavola con due tipi di dolci (ad esempio torta e biscotti), il principio della somma afferma che il numero totale di modi √® dato dalla somma del numero di modi in cui √® possibile scegliere la torta e del numero di modi in cui √® possibile scegliere i biscotti.\nEsempio 3. L‚Äôurna \\(A\\) contiene \\(5\\) palline numerate da \\(1\\) a \\(5\\), l‚Äôurna \\(B\\) contiene \\(6\\) palline numerate da \\(6\\) a \\(11\\), l‚Äôurna \\(C\\) contiene \\(3\\) palline numerate da \\(12\\) a \\(14\\) e l‚Äôurna \\(D\\) contiene \\(2\\) palline numerate \\(15\\) e \\(16\\). Quanti insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, si possono formare?\nIl numero di insiemi di tipo \\(AB\\) √® dato dal prodotto delle palline che possono essere estratte dall‚Äôurna \\(A\\) (5) e da quelle che possono essere estratte dall‚Äôurna \\(B\\) (6), ovvero \\(5 \\cdot 6 = 30\\). In modo analogo, si ottengono 15 insiemi di tipo \\(AC\\), 10 di tipo \\(AD\\), 18 di tipo \\(BC\\), 12 di tipo \\(BD\\), 6 di tipo \\(CD\\). Quindi, per la regola della somma, il numero totale di insiemi distinti che si possono formare con due palline provenienti dalle quattro urne √® dato dalla somma di questi valori, ovvero \\(30 + 15 + 10 + 18 + 12 + 6 = 91\\). Pertanto, ci sono 91 insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, che si possono formare.\nIn conclusione, il principio del prodotto e il principio della somma sono due concetti fondamentali del calcolo combinatorio. In generale, il principio del prodotto si applica quando si tratta di eventi indipendenti che si verificano in successione, mentre il principio della somma si applica quando si tratta di eventi mutuamente esclusivi (cio√® non possono accadere contemporaneamente) e si cerca di calcolare il numero totale di possibili risultati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#il-modello-dellurna",
    "href": "chapters/chapter_7/a14_combinatorics.html#il-modello-dellurna",
    "title": "Appendice K ‚Äî Calcolo combinatorio",
    "section": "K.3 Il modello dell‚Äôurna",
    "text": "K.3 Il modello dell‚Äôurna\nI problemi di combinatoria spesso coinvolgono l‚Äôestrazione di palline da urne, le quali rappresentano dei modelli delle corrispondenti situazioni considerate. Una procedura comune per rappresentare queste situazioni √® il modello dell‚Äôurna, che consiste nell‚Äôestrazione di \\(k\\) palline da un‚Äôurna contenente \\(n\\) palline. Le palline possono essere tutte diverse, oppure alcune palline possono essere indistinguibili tra loro. Tra le possibili modalit√† di estrazione, sono particolarmente importanti:\n\nL‚Äôestrazione Bernoulliana di \\(k\\) palline, che si ottiene estraendo una pallina alla volta e rimettendola nell‚Äôurna dopo ogni estrazione;\nL‚Äôestrazione senza ripetizione di \\(k\\) palline, che si ottiene estraendo una pallina alla volta senza rimetterla nell‚Äôurna dopo l‚Äôestrazione;\nL‚Äôestrazione in blocco di \\(k\\) palline, che si ottiene estraendo \\(k\\) palline contemporaneamente.\n\nPer esempio, nel caso di campioni di ampiezza 2 estratti da un‚Äôurna con tre elementi \\(\\{1, 2, 3\\}\\), abbiamo i seguenti quattro casi:\n\ncampionamento con reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{2,  1\\}, \\{3,  1\\}, \\{1,  2\\}, \\{2,  2\\}, \\{3,  2\\}, \\{1,  3\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento con reimmissione senza tenere conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{1,  2\\}, \\{1,  3\\}, \\{2,  2\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento senza reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  2\\}, \\{2,  1\\}, \\{1,  3\\}, \\{3,  1\\}, \\{2,  3\\}, \\{3,  2\\}\\);\ncampionamento senza reimmissione e senza tenere conto dell‚Äôordine di estrazione: \\(\\{1 , 2\\}, \\{1,  3\\}, \\{2, 3\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#permutazioni-semplici",
    "href": "chapters/chapter_7/a14_combinatorics.html#permutazioni-semplici",
    "title": "Appendice K ‚Äî Calcolo combinatorio",
    "section": "K.4 Permutazioni semplici",
    "text": "K.4 Permutazioni semplici\nLe permutazioni semplici sono il risultato di uno scambio dell‚Äôordine degli elementi di un insieme che contiene elementi distinti tra loro. Queste permutazioni sono indicate con il simbolo \\(P_n\\), e il numero di permutazioni semplici di \\(n\\) elementi distinti √® pari al fattoriale di \\(n\\), cio√® \\(n!\\), come espresso dall‚Äôeq. {eq}eq-permsem:\n\\[\nP_n = n!\n\\] (eq-permsem)\ndove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed √® uguale al prodotto di \\(n\\) numeri interi decrescenti da \\(n\\) fino a 1. Per definizione, il fattoriale di 0 √® 1.\nIl numero di permutazioni di \\(n\\) elementi distinti pu√≤ essere visto come l‚Äôestrazione senza rimessa di \\(n\\) elementi diversi da un‚Äôurna contenente gli \\(n\\) oggetti. Questo ci consente di applicare il principio del prodotto, il quale afferma che il numero di modi in cui √® possibile combinare o disporre un insieme di oggetti √® dato dal prodotto del numero di scelte possibili per ciascuna categoria di oggetti. Nel caso delle permutazioni, il principio del prodotto si applica nel seguente modo: se abbiamo \\(n\\) oggetti distinti da disporre in un ordine particolare, il numero di permutazioni possibili √® dato dal prodotto del numero di scelte possibili per la prima posizione, per la seconda posizione, per la terza posizione, e cos√¨ via, fino alla \\(n\\)-esima posizione.\nPer esempio, consideriamo il caso di disporre tre oggetti, A, B e C. Ci sono tre modi per scegliere il primo oggetto: A, B o C. Una volta scelto il primo oggetto, ci sono due modi per scegliere il secondo oggetto. Infine, rimane un solo modo per scegliere l‚Äôultimo oggetto. Possiamo concettualizzare questo processo come un albero, dove il numero totale di foglie √® uguale al numero di permutazioni. Per calcolare il numero di foglie, basta moltiplicare sequenzialmente il numero di rami a ogni livello, cio√® \\(3 \\times 2 \\times 1\\).\nEsempio 4. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Calcoliamo il numero di permutazioni semplici.\nLe permutazioni semplici di \\(A\\) sono: \\(\\{a, b, c\\}\\), \\(\\{a, c, b\\}\\), \\(\\{b, c, a\\}\\), \\(\\{b, a, c\\}\\), \\(\\{c, a, b\\}\\), \\(\\{c, b, a\\}\\), ovvero 6. Applichiamo l‚Äôeq. {ref}eq-permsem:\n\\[\nP_n = P_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6.\n\\]\nLo strumento principale che usiamo in Python per trovare le permutazioni di un insieme √® una libreria specificamente progettata per iterare sugli oggetti in modi diversi, ovvero itertools. Con itertools.permutations() generiamo le permutazioni.\n\nA = {\"A\", \"B\", \"C\"}\nprint(A)\n\n{'A', 'B', 'C'}\n\n\n\npermutations = it.permutations(A)\n\nPer visualizzare il risultato dobbiamo trasformarlo in una tupla:\n\ntuple(permutations)\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nLo stesso risultato si ottiene con\n\npermutations = it.permutations(\"ABC\")\npermutations = tuple(permutations)\npermutations\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nPossiamo ora contare quanti elementi ci sono nella tupla usando la funzione len():\n\nlen(permutations)\n\n6\n\n\nOppure, possiamo appliare la formula {eq}eq-permsem mediante la funzione factorial() contenuta nella libreria math di Numpy:\n\nmath.factorial(3)\n\n6\n\n\nEsempio 5. Gli anagrammi sono le permutazioni che si ottengono da una parola variando l‚Äôordine delle lettere. Le permutazioni semplici si applicano al caso di parole costituite da lettere tutte diverse tra loro. Ad esempio, con la parola NUMERO si ottengono \\(P_6 = 6! = 6\\cdot5\\cdot4\\cdot3\\cdot2\\cdot1 = 720\\) anagrammi.\n\npermutations = it.permutations(\"NUMERO\")\npermutations = tuple(permutations)\npermutations[1:10]\n\n(('N', 'U', 'M', 'E', 'O', 'R'),\n ('N', 'U', 'M', 'R', 'E', 'O'),\n ('N', 'U', 'M', 'R', 'O', 'E'),\n ('N', 'U', 'M', 'O', 'E', 'R'),\n ('N', 'U', 'M', 'O', 'R', 'E'),\n ('N', 'U', 'E', 'M', 'R', 'O'),\n ('N', 'U', 'E', 'M', 'O', 'R'),\n ('N', 'U', 'E', 'R', 'M', 'O'),\n ('N', 'U', 'E', 'R', 'O', 'M'))\n\n\n\nlen(permutations)\n\n720\n\n\n\nmath.factorial(6)\n\n720\n\n\nEsempio 6. Un altro esempio riguarda i giochi di carte. Ci sono 52! \\(\\approx 8 \\times 10^{67}\\) modi di ordinare un mazzo di carte da poker; questo numero √® ‚Äúquasi‚Äù grande come il numero di atomi dell‚Äôuniverso che si stima essere uguale a circa \\(10^{80}\\).\n\nmath.factorial(52)\n\n80658175170943878571660636856403766975289505440883277824000000000000\n\n\n\nprint(\"{:.2e}\".format(math.factorial(52)))\n\n8.07e+67\n\n\nEsempio 7. Le cifre 1, 2, 3, 4 e 5 sono disposte in ordine casuale per formare un numero di cinque cifre.\n\nQuanti diversi numeri di cinque cifre possono essere formati?\nQuanti diversi numeri di cinque cifre sono dispari?\n\nIniziamo a creare una tupla con le cinque cifre:\n\ntuple(range(1, 6))\n\n(1, 2, 3, 4, 5)\n\n\nCome in precedenza, possiamo usare it.permutations():\n\npermutations = it.permutations(range(1, 6))\npermutations = tuple(permutations)\npermutations[1:10]\n\n((1, 2, 3, 5, 4),\n (1, 2, 4, 3, 5),\n (1, 2, 4, 5, 3),\n (1, 2, 5, 3, 4),\n (1, 2, 5, 4, 3),\n (1, 3, 2, 4, 5),\n (1, 3, 2, 5, 4),\n (1, 3, 4, 2, 5),\n (1, 3, 4, 5, 2))\n\n\nCi sono 120 permutazioni.\n\nlen(permutations)\n\n120\n\n\nPer trovare i numeri dispari tra queste 120 permutazioni utilizziamo la funzione sum() in Python abbinato alle espressioni for e in. Accediamo al quinto elemento di una permutazione utilizzando la notazione [4] (il primo elemento √® indicato con 0, quindi il quinto √® 4):\n\nsum(permutation[4] % 2 for permutation in permutations)\n\n72\n\n\nPossiamo controllare questo teoricamente: nel caso presente, ci sono tre possibili cifre dispari per l‚Äôultima posizione di un numero di cinque cifre: 1, 3 e 5. Dopo aver scelto una di queste, le cifre rimanenti nelle prime quattro posizioni possono essere formate in 4! modi. Pertanto:\n\nmath.factorial(4) * 3\n\n72",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#disposizioni-semplici",
    "href": "chapters/chapter_7/a14_combinatorics.html#disposizioni-semplici",
    "title": "Appendice K ‚Äî Calcolo combinatorio",
    "section": "K.5 Disposizioni semplici",
    "text": "K.5 Disposizioni semplici\nLe disposizioni semplici rappresentano tutti i modi in cui un insieme di oggetti pu√≤ essere disposto in sequenza, tenendo conto dell‚Äôordine in cui gli oggetti vengono scelti e senza permettere la scelta di un oggetto pi√π di una volta.\nQuindi, se abbiamo un insieme di \\(n\\) oggetti distinti e vogliamo selezionarne \\(k\\) per formare una sequenza, le disposizioni semplici rappresentano tutti i sottoinsiemi di \\(k\\) oggetti distinti che possono essere selezionati dall‚Äôinsieme di \\(n\\) oggetti distinti in modo tale che l‚Äôordine in cui vengono selezionati sia importante.\nAd esempio, se abbiamo l‚Äôinsieme di oggetti \\({a,b,c}\\) e vogliamo selezionare due oggetti per formare una sequenza, le disposizioni semplici sarebbero: \\(ab\\), \\(ba\\), \\(ac\\), \\(ca\\), \\(bc\\), \\(cb\\). Nota che, in questo caso, l‚Äôordine in cui gli oggetti vengono scelti √® importante e ogni oggetto viene scelto una sola volta.\nIl numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® indicato con \\(D_{n,k}\\) e pu√≤ essere calcolato dividendo il numero di permutazioni di \\(n\\) oggetti distinti per il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti, poich√© ogni disposizione semplice pu√≤ essere ottenuta come una permutazione di un sottoinsieme di \\(k\\) oggetti distinti.\nQuindi, il numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® dato da\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!},\n\\] (eq_disp_simple)\ndove \\(n!\\) rappresenta il numero di permutazioni di \\(n\\) oggetti distinti e \\((n-k)!\\) rappresenta il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti.\nEsempio 8. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Qual √® il numero di disposizioni semplici di classe 2? Come abbiamo visto sopra, le disposizioni semplici di classe 2 sono \\(\\{a, b\\}\\), \\(\\{b, a\\}\\), \\(\\{a, c\\}\\), \\(\\{c, a\\}\\), \\(\\{b, c\\}\\), \\(\\{c, b\\}\\), ovvero 6.\nApplichiamo l‚Äôeq. {eq}eq_disp_simple:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} = 3 \\cdot 2 = 6.\n\\]\nIn maniera equivalente possiamo trovare il risultato usando itertools.permutations(iterable, k). Tale istruzione ci consente di trovare il numero di permutazioni possibili di tutti i sottoinsiemi di \\(k\\) elementi distinti, ovvero il numero di diverse sequenze ordinate che possiamo ottenere scegliendo \\(k\\) oggetti dall‚Äôinsieme.\n\ntuple(it.permutations(\"ABC\", 2))\n\n(('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B'))\n\n\n\nres = tuple(it.permutations(\"ABC\", 2))\nlen(res)\n\n6\n\n\nOppure possiamo implementare l‚Äôeq. {eq}eq_disp_simple:\n\ndef simple_disp(n, k):\n    return math.factorial(n) / math.factorial(n - k)\n\n\nsimple_disp(3, 2)\n\n6.0",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#sec-combinazione-semplice",
    "href": "chapters/chapter_7/a14_combinatorics.html#sec-combinazione-semplice",
    "title": "Appendice K ‚Äî Calcolo combinatorio",
    "section": "K.6 Combinazioni semplici",
    "text": "K.6 Combinazioni semplici\nLe combinazioni sono simili alle permutazioni, ma ignorano l‚Äôordine degli elementi. In altre parole, le combinazioni rappresentano i modi di scegliere \\(k\\) elementi distinti da\\(n\\)elementi senza considerare l‚Äôordine. Ad esempio, scegliendo 2 elementi da 3 (A, B e C), le permutazioni sono 6 (AB, BA, AC, CA, BC, CB), mentre le combinazioni sono 3 (AB, AC, BC).\nPer calcolare le combinazioni, prima calcoliamo le permutazioni \\(D_{n,k}\\) e poi dividiamo per \\(k!\\). Questo perch√© ci sono \\(k!\\) modi per disporre \\(k\\) elementi in ordine diverso, ma tutte queste disposizioni contano come una singola combinazione. La formula generale per le combinazioni √®:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{D_{n,k}}{P_k} = \\frac{n!}{k!(n-k)!},\n\\] (eq_combsemp)\nche √® spesso indicata con il simbolo \\(\\binom{n}{k}\\) e viene chiamato ‚Äúcoefficiente binomiale‚Äù. In sintesi, le combinazioni semplici rappresentano il numero di sottoinsiemi di \\(k\\) elementi distinti scelti da un insieme di \\(n\\) elementi distinti senza considerare l‚Äôordine di estrazione.\nEsempio 9. Per l‚Äôinsieme \\(A = \\{a, b, c\\}\\) si trovino le combinazioni semplici di classe 2.\nLe combinazioni semplici dell‚Äôinsieme \\(A\\) sono \\(\\{a, b\\}\\), \\(\\{a, c\\}\\), \\(\\{b, c\\}\\), ovvero 3. Applichiamo l‚Äôeq. {eq}eq_combsemp:\n\\[\nC_{n,k} = \\binom{n}{k} = \\binom{3}{2} = 3.\n\\]\nUsiamo itertools:\n\nc_nk = tuple(it.combinations(\"ABC\", 2))\nc_nk\n\n(('A', 'B'), ('A', 'C'), ('B', 'C'))\n\n\n\nlen(c_nk)\n\n3\n\n\nLa soluzione si trova anche usando la funzione comb() della libreria math.\n\nmath.comb(3, 2)\n\n3\n\n\nOppure usando la funzione comb() della libreria scipy.special.\n\nimport scipy.special as sp\n\nsp.comb(3, 2)\n\n3.0\n\n\nEsempio 10. Quanti gruppi di 2 si possono formare con 5 individui?\n\nc_nk = tuple(it.combinations(range(5), 2))\nc_nk\n\n((0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (1, 2),\n (1, 3),\n (1, 4),\n (2, 3),\n (2, 4),\n (3, 4))\n\n\n\nlen(c_nk)\n\n10\n\n\novvero\n\nmath.comb(5, 2)\n\n10\n\n\nEsempio 11. Ho un‚Äôassociazione con 50 soci. Devo scegliere 5 membri che compongano il comitato direttivo. Quante possibili scelte?\n\nmath.comb(50, 5)\n\n2118760\n\n\nEsempio 12. Una gelateria offre 15 gusti di gelato differenti. Quante coppe diverse posso formare se ognuna contiene 3 gusti di gelato differenti tra loro?\n\nmath.comb(15, 3)\n\n455\n\n\nEsempio 13. Uno studente deve rispondere a 5 domande su 10. Solo 5 su 10. Quante possibili scelte ha?\n\nmath.comb(10, 5)\n\n252\n\n\nEsempio 14. Consideriamo un incidente del 2009 quando il Governatore della California Arnold Schwarzenegger invi√≤ un messaggio all‚Äôassemblea statale riguardo il veto al disegno di legge 1176. Questo messaggio formava un acrostico volgare con le prime lettere di ogni riga.\n\n\n\n\n\n\nFigura¬†K.1\n\n\n\nCi possiamo chiedere quale sia la probabilit√† che questo acrostico sia stato casuale. Per rispondere a questa domanda, calcoliamo le combinazioni di due diversi eventi.\nIl messaggio di Arnold Schwarzenegger √® composto da 85 parole. Supponiamo che il messaggio sia stato diviso in 7 righe in modo casuale. Per creare 7 righe, dobbiamo inserire 6 interruzioni di riga. Queste interruzioni di riga possono essere inserite in qualsiasi posizione tra le parole.\nPoich√© ci sono 85 parole, ci sono 84 spazi tra le parole (prima della seconda parola, terza parola, e cos√¨ via). Il numero di modi in cui possiamo inserire 6 interruzioni di riga in 84 spazi √® dato dalla combinazione:\n\\[\n\\binom{84}{6} = \\frac{84!}{6!(78!)} \\approx 406,481,544.\n\\]\nCalcoliamo ora il numero di modi in cui questo particolare acrostico pu√≤ essere ottenuto.\nSupponiamo che l‚Äôacrostico ‚ÄúFUCKYOU‚Äù possa essere formato solo in un numero limitato di combinazioni specifiche. Per calcolare queste combinazioni, dobbiamo considerare le parole che iniziano con ciascuna delle lettere dell‚Äôacrostico e le posizioni in cui possono essere inserite le interruzioni di riga.\n\nIdentificazione delle parole chiave:\n\nF: ‚ÄúFor‚Äù\nU: ‚Äúunnecessary‚Äù\nC: ‚Äúconversation‚Äù\nK: ‚Äúkeeping‚Äù\nY: ‚Äúyou‚Äù\nO: ‚Äúover‚Äù\nU: ‚Äúuntil‚Äù\n\nDeterminazione delle possibili interruzioni di riga: Per formare l‚Äôacrostico, dobbiamo posizionare le interruzioni di riga in modo che le parole chiave siano all‚Äôinizio delle righe. Le interruzioni possono essere inserite tra le parole chiave, con un certo numero di parole tra di esse.\nConteggio delle combinazioni:\n\nTra ‚ÄúFor‚Äù e ‚Äúunnecessary‚Äù: 11 possibilit√†\nTra ‚Äúunnecessary‚Äù e ‚Äúconversation‚Äù: 3 possibilit√†\nTra ‚Äúconversation‚Äù e ‚Äúkeeping‚Äù: 9 possibilit√†\nTra ‚Äúkeeping‚Äù e ‚Äúyou‚Äù: 2 possibilit√†\nTra ‚Äúyou‚Äù e ‚Äúover‚Äù: 2 possibilit√†\nTra ‚Äúover‚Äù e ‚Äúuntil‚Äù: 1 possibilit√†\n\nQuindi, il numero totale di combinazioni √®:\n\\[\n11 \\times 3 \\times 9 \\times 2 \\times 2 \\times 1 = 1,188.\n\\]\n\nIn conclusione, la probabilit√† che l‚Äôacrostico volgare si verifichi casualmente √® data dal rapporto tra il numero di combinazioni specifiche che formano l‚Äôacrostico (1,188) e il numero totale di modi per inserire 6 interruzioni di riga in 84 spazi (406,481,544):\n\\[\n\\frac{1,188}{406,481,544} \\approx 2.92 \\times 10^{-6} \\approx 1 \\text{ su } 342,000.\n\\]\nQuesta analisi ci mostra che √® estremamente improbabile che l‚Äôacrostico volgare sia stato il risultato di una divisione casuale delle righe del messaggio. In altre parole, la probabilit√† che questo acrostico sia stato generato casualmente √® trascurabile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a15_calculus.html",
    "href": "chapters/chapter_7/a15_calculus.html",
    "title": "Appendice L ‚Äî Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "L.1 Introduzione ai logaritmi\nIl logaritmo √® una funzione matematica che risponde alla domanda: ‚Äúquante volte devo moltiplicare un certo numero (chiamato‚Äùbase‚Äù) per ottenere un altro numero?‚Äù Matematicamente, questo √® espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perch√© \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano pi√π grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo √® utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio: - \\(\\log(1) = 0\\) - \\(\\log(0.1) = -1\\) - \\(\\log(0.01) = -2\\) - \\(\\log(0.001) = -3\\)\nCome si pu√≤ vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle propriet√† pi√π utili dei logaritmi √® che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta propriet√† √® estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilit√† potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn‚Äôaltra propriet√† utile dei logaritmi √® che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa propriet√† √® molto utilizzata in matematica, specialmente in situazioni in cui √® necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare pi√π agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli pi√π gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a15_calculus.html#watermark",
    "href": "chapters/chapter_7/a15_calculus.html#watermark",
    "title": "Appendice L ‚Äî Per liberarvi dai terrori preliminari",
    "section": "L.2 Watermark",
    "text": "L.2 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Feb 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\nnumpy     : 1.26.4\narviz     : 0.17.0\nscipy     : 1.12.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a20_kde_plot.html",
    "href": "chapters/chapter_7/a20_kde_plot.html",
    "title": "Appendice M ‚Äî Kernel Density Estimation",
    "section": "",
    "text": "M.1 Watermark\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Oct 27 2023\n\nPython implementation: CPython\nPython version       : 3.11.6\nIPython version      : 8.16.1\n\nnumpy     : 1.25.2\nmatplotlib: 3.8.0\nseaborn   : 0.13.0\nscipy     : 1.11.3\narviz     : 0.16.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>¬† <span class='chapter-title'>Kernel Density Estimation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a30_prob_tutorial.html",
    "href": "chapters/chapter_7/a30_prob_tutorial.html",
    "title": "Appendice N ‚Äî Esercizi di probabilit√† discreta",
    "section": "",
    "text": "N.1 Watermark\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Oct 27 2023\n\nPython implementation: CPython\nPython version       : 3.11.6\nIPython version      : 8.16.1\n\nmatplotlib: 3.8.0\narviz     : 0.16.1\nseaborn   : 0.13.0\nnumpy     : 1.25.2\npandas    : 2.1.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Esercizi di probabilit√† discreta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html",
    "href": "chapters/chapter_7/a40_rng.html",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "",
    "text": "O.1 Distribuzione uniforme\nConsideriamo la distribuzione uniforme: rng.uniform([low, high, size]). Genero un singolo valore:\nLo genero una seconda volta:\nrng.uniform(0, 1, size=1)\n\narray([0.77395605])\nGenero 20 valori:\nrng.uniform(0, 1, size=20)\n\narray([0.43887844, 0.85859792, 0.69736803, 0.09417735, 0.97562235,\n       0.7611397 , 0.78606431, 0.12811363, 0.45038594, 0.37079802,\n       0.92676499, 0.64386512, 0.82276161, 0.4434142 , 0.22723872,\n       0.55458479, 0.06381726, 0.82763117, 0.6316644 , 0.75808774])\nCreo un istogramma.\nn_samples = 1000000\n_ = plt.hist(rng.uniform(0, 1, size=n_samples), bins=50, density=True)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html#distribuzione-normale",
    "href": "chapters/chapter_7/a40_rng.html#distribuzione-normale",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "O.2 Distribuzione normale",
    "text": "O.2 Distribuzione normale\nEstraiamo ora dei campioni casuali dalla distribuzione Gaussiana, rng.normal([loc, scale, size]). Per esempio, generiamo 10 valori dalla distribuzione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\):\n\nx = rng.normal(loc=100, scale=15, size=10)\nprint(x)\n\n[ 88.39130723 106.85972149 112.68284617  98.40757644  59.28402571\n  83.63194152 127.29102032  91.32585446 109.21359401 103.23261596]\n\n\nOra generiamo un grande numero (1000000) di valori casuali dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). Con questi valori creiamo un istogramma e a tale istogramma sovrapponiamo la funzione di densit√† \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). In questo modo possiamo accertarci che i numeri casuali che abbiamo ottenuto si riferiscano veramente alla densit√† desiderata. Per trovare la densit√† della distribuzione normale, uso norm.pdf da scipy.stats.\n\nn_samples = 1000000\nmu = 100\nsigma = 15\n# create x's\nxs = np.linspace(55, 145, n_samples)\ny_pdf = stats.norm.pdf(xs, mu, sigma)\n# create random samples\nsamps = rng.normal(loc=mu, scale=sigma, size=n_samples)\n# plot them\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=50, density=True)\nplt.title(\"Distribuzione Normale $\\mathcal{N}(\\mu=100, \\sigma=15)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(40, 160);\n\n\n\n\n\n\n\n\nLa stessa procedura pu√≤ essere usata per tutte le distribuzioni implementate da NumPy. Esaminiamo alcuni esempi qui sotto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html#distribuzione-beta",
    "href": "chapters/chapter_7/a40_rng.html#distribuzione-beta",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "O.3 Distribuzione Beta",
    "text": "O.3 Distribuzione Beta\nPer estrarre dei campioni casuali dalla distribuzione Beta usiamo il generatore rng.beta(a, b[, size]); per la densit√† Beta usiamo stats.beta.pdf(x, a, b).\n\n# Definisci il numero di campioni\nn_samples = 1000000\na = 3\nb = 9\n\n# Crea un array di valori x\nxs = np.linspace(0, 1, n_samples)\n\n# Calcola la densit√† di probabilit√† (PDF) della distribuzione Beta\ny_pdf = stats.beta.pdf(xs, a, b)\n\n# Genera i campioni casuali\nsamps = rng.beta(a, b, size=n_samples)\n\n# Traccia il grafico\nplt.plot(xs, y_pdf, label=\"Densit√† Beta(3,9)\")\nplt.hist(samps, bins=50, density=True, label=\"Campioni\")\nplt.title(\"Confronto tra la Distribuzione Beta(3,9) e Campioni Casuali\")\nplt.ylabel(\"Densit√†\")\nplt.xlabel(\"Valore\")\n_ = plt.legend()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html#distribuzione-binomiale",
    "href": "chapters/chapter_7/a40_rng.html#distribuzione-binomiale",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "O.4 Distribuzione binomiale",
    "text": "O.4 Distribuzione binomiale\nPer estrarre dei campioni casuali dalla distribuzione Binomiale usiamo rng.binomial(n, p[, size]); per la distribuzione di massa Binomiale usiamo stats.binom.pmf(r, n, p).\n\nn_samples = 1000000\n\nn = 10\np = 0.3\n# create r values\nr_values = list(range(n + 1))\n# pmf\ny_pmf = [stats.binom.pmf(r, n, p) for r in r_values]\n# create random samples\nr_samps = rng.binomial(n=n, p=p, size=n_samples)\nplt.plot(r_values, y_pmf, \"x\")\nplt.hist(r_samps, bins=np.arange(-0.5, 11.5, 1), density=True)\nplt.title(\"Distribuzione Binomiale($n$=10, $p$=0.3)\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\");",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html#distribuzione-t-di-student",
    "href": "chapters/chapter_7/a40_rng.html#distribuzione-t-di-student",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "O.5 Distribuzione \\(t\\) di Student",
    "text": "O.5 Distribuzione \\(t\\) di Student\nPer estrarre dei campioni casuali dalla distribuzione \\(t\\) di Student uso il generatore rng con standard_t(df, size=None); per la densit√† \\(t\\) di Student uso t.pdf da scipy.stats.\n\nn_samples = 100000\ndf = 4\n# create x's\nxs = np.linspace(-4, 4, n_samples)\ny_pdf = stats.t.pdf(xs, df=df)\n# create random samples\nsamps = rng.standard_t(df=df, size=n_samples)\n# plot them\nfig, ax = plt.subplots()\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=400, density=True)\nplt.title(\"Distribuzione $t(\\\\nu=4)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(-4, 4);",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "href": "chapters/chapter_7/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "O.6 Distribuzione arbitraria di una variabile casuale distreta",
    "text": "O.6 Distribuzione arbitraria di una variabile casuale distreta\nCon la funzione random.choices √® possible specificare i valori di una variabile casuale discreta con una distribuzione di massa di probabilit√† arbitraria.\n\n# Define the set of values\nx_rv = [1, 2, 3, 4]\n# Define the weights for each value\nweights = [0.1, 0.1, 0.3, 0.5]\n\nx_sample = rng.choice(x_rv, size=100, p=weights)\nprint(f\"Random Sample: {x_sample}\")\n\nRandom Sample: [1 1 4 3 1 4 1 4 3 3 4 4 1 4 4 4 4 2 4 2 1 4 4 2 1 3 2 4 1 4 4 3 4 2 4 4 1\n 4 3 4 4 4 4 3 1 4 3 3 2 4 3 4 4 3 3 4 4 1 3 4 4 4 3 2 1 4 4 4 4 4 3 4 3 2\n 3 4 4 3 3 4 4 3 4 2 4 3 4 3 1 2 4 4 1 1 4 3 1 4 4 4]\n\n\nNell‚Äôesempio, i pesi weights indicano che, nella distribuzione, il valore 4 √® presente con una frequenza di cinque volte maggiore dei valori 1 e 2.\nSe aggiungiamo l‚Äôargomento k possiamo definire i pesi (indirettamente, le probabilit√†) dei diversi valori della variabile casuale che sono stati specificati. Nell‚Äôesempio, i pesi [1, 1, 3, 6] indicano che, nella distribuzione, il valore 4 √® presente con una frequenza di sei volte maggiore dei valori 1 e 2.\n\nn_samples = 100000\nx = rng.choice(x_rv, size=n_samples, p=weights)\nbins = plt.hist(x, density=True)\nplt.title(\"Distribuzione arbitraria di massa di probabilit√†\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xticks(x_rv);\n\n\n\n\n\n\n\n\n\nrng.binomial(10, .1, size=4)\n\narray([3, 0, 3, 1])",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_7/a40_rng.html#commenti-e-considerazioni-finali",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "O.7 Commenti e Considerazioni Finali",
    "text": "O.7 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esaminato l‚Äôutilizzo della funzione rng = np.random.default_rng() per generare un campione di numeri pseudo-casuali da una distribuzione. Dopo aver inizializzato rng con rng = np.random.default_rng(RANDOM_SEED), possiamo generare campioni casuali da diverse distribuzioni di massa e di densit√† di probabilit√†:\n\nDistribuzione uniforme: rng.uniform(min, max, size)\nDistribuzione normale: rng.normal(loc, scale, size)\nDistribuzione t di Student: rng.standard_t(df, size)\nDistribuzione beta: rng.beta(alpha, beta, size)\nDistribuzione binomiale: rng.binomial(n, p, size)\n\nNei capitoli precedenti, nello specifico nei notebook {ref}discr_distr_notebook e {ref}cont-rv-distr-notebook, abbiamo invece approfondito l‚Äôutilizzo di varie funzioni della libreria scipy.stats per manipolare le distribuzioni di probabilit√†. In particolare, abbiamo illustrato come sia possibile utilizzare:\n\n.pdf per ottenere i valori della funzione di densit√† di probabilit√† o .pmf per ottenere i valori della distribuzione di massa di probabilit√†.\n.ppf per calcolare i quantili della distribuzione.\n.cdf per calcolare la probabilit√† associata a un valore specifico. Nel caso di una variabile casuale continua, questo corrisponde al valore della funzione di ripartizione, che rappresenta l‚Äôarea sotto la curva di densit√† nella coda sinistra. Nel caso di una variabile casuale discreta, corrisponde alla somma delle probabilit√† dalla distribuzione di massa di probabilit√† dal valore minimo fino al valore specificato (incluso).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a40_rng.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_7/a40_rng.html#informazioni-sullambiente-di-sviluppo",
    "title": "Appendice O ‚Äî Generazione di numeri casuali",
    "section": "O.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "O.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Mar 22 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.1\nseaborn   : 0.13.2\narviz     : 0.17.1\nscipy     : 1.12.0\nnumpy     : 1.26.4\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a44_montecarlo.html",
    "href": "chapters/chapter_7/a44_montecarlo.html",
    "title": "Appendice P ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "P.1 Stima dell‚Äôintegrale di un cerchio\nImmaginiamo un quadrato di lato 2 centrato sull‚Äôorigine. Genereremo punti casuali uniformemente distribuiti all‚Äôinterno di questo quadrato. Per ogni punto \\((x, y)\\), verificheremo se cade all‚Äôinterno del cerchio di raggio unitario inscritto nel quadrato, cio√® se la distanza dall‚Äôorigine √® minore di 1:\n\\[\n\\sqrt{x^2 + y^2} &lt; 1,\n\\]\nche si semplifica a:\n\\[\nx^2 + y^2 &lt; 1.\n\\]\nLa proporzione di tali punti rappresenta la proporzione dell‚Äôarea del quadrato occupata dal cerchio. Poich√© il quadrato ha un‚Äôarea di 4, l‚Äôarea del cerchio √® pari a 4 volte la proporzione dei punti che cadono all‚Äôinterno del cerchio.\nQuindi, se generiamo un numero sufficiente di punti casuali e contiamo quanti di essi cadono all‚Äôinterno del cerchio, possiamo stimare \\(\\pi\\) come:\n\\[\n\\pi \\approx 4 \\times \\frac{\\text{numero di punti dentro il cerchio}}{\\text{numero totale di punti}}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "href": "chapters/chapter_7/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "title": "Appendice P ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "P.1.1 Codice Stan\nEsaminiamo il corrispondente codice Stan.\ngenerated quantities {\n  real&lt;lower=-1, upper=1&gt; x = uniform_rng(-1, 1);\n  real&lt;lower=-1, upper=1&gt; y = uniform_rng(-1, 1);\n  int&lt;lower=0, upper=1&gt; inside = x^2 + y^2 &lt; 1;\n  real&lt;lower=0, upper=4&gt; pi = 4 * inside;\n}\n\nVariabili x e y:\n\nVengono generate casualmente e uniformemente nell‚Äôintervallo \\((-1, 1)\\). Questo significa che stiamo campionando punti all‚Äôinterno di un quadrato di lato 2 centrato sull‚Äôorigine.\n\nVariabile inside:\n\n√à un indicatore che verifica se il punto \\((x, y)\\) cade all‚Äôinterno del cerchio unitario. La condizione \\(x^2 + y^2 &lt; 1\\) √® vera se il punto \\((x, y)\\) √® all‚Äôinterno del cerchio di raggio 1 centrato sull‚Äôorigine, e falsa altrimenti.\nSe la condizione √® vera, inside √® impostato a 1, altrimenti a 0.\n\nVariabile pi:\n\npi viene calcolata come 4 volte il valore di inside.\n\n\nIl programma Stan genera punti casuali, verifica se cadono all‚Äôinterno del cerchio e usa la proporzione di punti che cadono all‚Äôinterno del cerchio per stimare \\(\\pi\\). Moltiplicando il valore indicatore per 4, otteniamo una stima di \\(\\pi\\) basata su ciascun punto generato. La stima finale di \\(\\pi\\) sar√† la media di queste stime su molti punti campionati.\n\n\nP.1.2 Media Campionaria dell‚ÄôIndicatore\nDopo aver generato un numero sufficiente di punti casuali e aver verificato quanti di essi cadono all‚Äôinterno del cerchio, calcoliamo la media campionaria dell‚Äôindicatore inside. Questo indicatore √® uguale a 1 se il punto √® dentro il cerchio e a 0 se √® fuori. La media di questi valori ci d√† la proporzione dei punti che cadono dentro il cerchio.\nQuesta proporzione √® una stima della probabilit√† che un punto casuale sia all‚Äôinterno del cerchio. Moltiplicando questa proporzione per 4, otteniamo una stima di \\(\\pi\\).\nMatematicamente, possiamo scrivere questo processo come segue:\n\\[\n\\mathbb{E}[4 \\cdot \\textrm{I}(\\sqrt{X^2 + Y^2} \\leq 1)] = \\int_{-1}^1 \\int_{-1}^1 4 \\cdot \\textrm{I}(x^2 + y^2 &lt; 1) \\, \\textrm{d}x \\, \\textrm{d}y = \\pi,\n\\]\ndove \\(\\textrm{I}()\\) √® l‚Äôindicatore che ritorna 1 se il suo argomento √® vero e 0 altrimenti.\nIn altre parole, stiamo calcolando l‚Äôaspettativa di 4 volte l‚Äôindicatore che un punto casuale \\((x, y)\\) cade dentro il cerchio unitario. Questo valore atteso √® uguale a \\(\\pi\\), il che ci permette di stimare \\(\\pi\\) usando i metodi Monte Carlo.\n\n\nP.1.3 Compilazione e Campionamento\nCompiliamo e poi campioniamo dal modello, prendendo un campione di dimensione \\(M = 10,000\\) estrazioni.\n\nM = 10_000\nmodel = CmdStanModel(stan_file=\"../../stan/monte-carlo-pi.stan\")\n\nsample = model.sample(\n    chains=1,\n    iter_warmup=1,\n    iter_sampling=M,\n    show_progress=False,\n    show_console=False,\n    seed=123,\n)\n\nx_draws = sample.stan_variable(\"x\")\ny_draws = sample.stan_variable(\"y\")\ninside_draws = sample.stan_variable(\"inside\")\npi_draws = sample.stan_variable(\"pi\")\n\ndf = pd.DataFrame({\"N\": 1000, \"x\": x_draws, \"y\": y_draws, \"inside\": inside_draws})\n\nplt.figure(figsize=(5, 5))\nplt.scatter(df[\"x\"], df[\"y\"], c=df[\"inside\"], cmap=\"coolwarm\", s=1)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Monte Carlo Simulation of Pi Estimation\")\nplt.gca().set_aspect(\"equal\", adjustable=\"box\")\nplt.show()\n\n\n\n\n\n\n\n\nSuccessivamente, calcoliamo la media campionaria dell‚Äôindicatore dentro-il-cerchio, che produce una stima della probabilit√† che un punto sia dentro il cerchio:\n\nPr_is_inside = np.mean(inside_draws)\npi_hat = np.mean(pi_draws)\nprint(f\"Pr[Y is inside circle] = {Pr_is_inside:.3f};\")\nprint(f\"estimate for pi = {pi_hat:.3f}\")\n\nPr[Y is inside circle] = 0.786;\nestimate for pi = 3.144\n\n\nIl valore esatto di \\(\\pi\\) fino a tre cifre decimali √® \\(3.142\\). Con il nostro metodo, ci avviciniamo a questo valore, ma non lo raggiungiamo esattamente, il che √® tipico dei metodi Monte Carlo. Aumentando il numero di estrazioni, l‚Äôerrore diminuisce. Teoricamente, con un numero sufficiente di estrazioni, possiamo ottenere qualsiasi precisione desiderata; tuttavia, in pratica, dobbiamo accontentarci di pochi decimali di accuratezza nelle nostre stime Monte Carlo. Questo di solito non √® un problema, poich√© l‚Äôincertezza statistica tende a dominare rispetto all‚Äôimprecisione numerica nella maggior parte delle applicazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a45_mcmc.html",
    "href": "chapters/chapter_7/a45_mcmc.html",
    "title": "Appendice Q ‚Äî Catene di Markov",
    "section": "",
    "text": "Q.1 Struttura e Dinamica delle Catene di Markov\nNelle catene di Markov, le variabili casuali si muovono all‚Äôinterno di uno ‚Äúspazio degli stati‚Äù, che pu√≤ essere discreto o continuo. In questo contesto, ci focalizziamo su spazi degli stati discreti e finiti, generalmente rappresentati come \\(\\{1, 2, \\ldots, M\\}\\).\nLa dinamica interna delle catene di Markov √® governata dalle ‚Äúprobabilit√† di transizione‚Äù tra gli stati, riassunte in una ‚Äúmatrice di transizione‚Äù. Ogni elemento $ (i, j) $ di questa matrice indica la probabilit√† di passare dallo stato $ i $ allo stato $ j $ in un singolo passo della catena.\nIn sintesi, le catene di Markov offrono un framework robusto e versatile per la modellazione di dipendenze tra variabili casuali, rivelandosi essenziali in molti settori della statistica e della scienza dei dati, inclusa la metodologia MCMC, che √® centrale in algoritmi come quello di Metropolis.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a45_mcmc.html#terminologia",
    "href": "chapters/chapter_7/a45_mcmc.html#terminologia",
    "title": "Appendice Q ‚Äî Catene di Markov",
    "section": "Q.2 Terminologia",
    "text": "Q.2 Terminologia\nCatene di Markov omogenee\nUna catena di Markov √® detta ‚Äúomogenea‚Äù quando le probabilit√† di transizione tra gli stati sono indipendenti dal tempo. In termini pi√π semplici, la dinamica della catena √® regolata da una matrice di transizione fissa che rimane costante nel tempo. Ci√≤ significa che la probabilit√† di passare da uno stato all‚Äôaltro √® sempre la stessa, indipendentemente dal momento in cui avviene questa transizione.\nCatene di Markov irriducibili\nUna catena di Markov √® ‚Äúirriducibile‚Äù quando √® possibile raggiungere qualsiasi stato partendo da qualsiasi altro stato in un numero finito di passaggi. In altre parole, non esistono stati isolati che intrappolano la catena indefinitamente.\nStati ricorrenti\nIn una catena di Markov, uno stato √® considerato ‚Äúricorrente‚Äù se viene rivisitato ripetutamente. Gli stati possono ulteriormente essere classificati come ‚Äúpositivamente ricorrenti‚Äù se esiste un tempo limitato per tornare allo stato, e ‚Äúnullamente ricorrenti‚Äù in caso contrario. Gli stati ‚Äúricorrenti di Harris‚Äù sono quelli che vengono visitati infinite volte mentre il tempo tende all‚Äôinfinito.\nAperiodicit√†\nGli stati ‚Äúaperiodici‚Äù in una catena di Markov sono quelli senza cicli deterministici, il che significa che la catena non rimane bloccata in un ciclo fisso di stati.\nStazionariet√†\nNella teoria delle catene di Markov, la ‚Äúdistribuzione marginale‚Äù √® semplicemente la distribuzione delle probabilit√† degli stati della catena in un certo momento. In altre parole, √® una descrizione delle probabilit√† di trovarsi in ciascuno degli stati possibili in un determinato istante di tempo. Se stiamo parlando, ad esempio, di una catena di Markov con tre stati (A, B, C), una possibile distribuzione marginale potrebbe essere \\([0.4, 0.5, 0.1]\\), indicando che la probabilit√† di trovarsi nello stato A √® del 40%, nello stato B del 50% e nello stato C del 10%.\nUna catena di Markov √® definita come ‚Äústazionaria‚Äù quando questa distribuzione marginale rimane invariata nel tempo. In altre parole, le probabilit√† di essere in ogni stato possibile non cambiano, anche se la catena passa da uno stato all‚Äôaltro seguendo le probabilit√† di transizione.\nLa stazionariet√† √® un concetto cruciale perch√© rende possibile analizzare il comportamento a lungo termine della catena senza dover tener conto di tutti i dettagli delle transizioni individuali. In pratica, una volta che la catena √® stazionaria, sappiamo che la sua distribuzione marginale non cambier√† pi√π, e questo √® spesso ci√≤ che ci interessa nelle applicazioni reali.\nErgodicit√†\nL‚Äôergodicit√† √® un‚Äôaltra propriet√† fondamentale che descrive come una catena di Markov si comporta nel limite quando il numero di passaggi tende all‚Äôinfinito. Una catena ergodica √® una catena che √® sia aperiodica (non ha cicli fissi) sia irriducibile (ogni stato √® raggiungibile da ogni altro stato) e positivamente ricorrente secondo Harris (ogni stato viene visitato infinite volte in un tempo finito). Ci√≤ significa che mentre il numero di passaggi tende all‚Äôinfinito, la distribuzione marginale della catena rimane stabile. Pertanto, se campioniamo da una catena di Markov stazionaria a intervalli ampiamente distanziati, questi campioni possono essere considerati indipendenti.\nNella teoria ergodica, si discute spesso di ‚Äúburn-in‚Äù, che √® il periodo di tempo necessario perch√© la catena si avvicini alla distribuzione stazionaria, e di ‚Äúthinning‚Äù, che √® la pratica di prendere campioni a intervalli ampiamente distanziati per minimizzare la correlazione tra i campioni.\nConvergenza\nNel contesto della convergenza, le propriet√† di irriducibilit√† e aperiodicit√† garantiscono che la catena di Markov si stabilizzer√† in un equilibrio a lungo termine, specificamente convergendo verso una distribuzione stazionaria $ s $. In questo scenario, ‚Äúconvergenza‚Äù implica che con l‚Äôincrementare indefinito del numero di passaggi $ n $, la distribuzione marginale della catena tende sempre pi√π verso la distribuzione stazionaria $ s $.\nTale convergenza √® di natura probabilistica e avviene a prescindere dalle condizioni iniziali, cio√® dall‚Äôeffettivo stato da cui la catena √® partita. Detto in modo pi√π semplice, con un tempo sufficientemente lungo, il comportamento della catena di Markov diventa prevedibile e stabile, in accordo con la distribuzione stazionaria $ s $.\nQuindi, i concetti di convergenza e stazionariet√† sono strettamente correlati: la convergenza rappresenta il percorso che la catena percorre per raggiungere uno stato di equilibrio, mentre la stazionariet√† fornisce una descrizione formale di questo stato di equilibrio al quale la catena tender√† nel lungo periodo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html",
    "href": "chapters/chapter_7/a46_stan.html",
    "title": "Appendice R ‚Äî Linguaggio Stan",
    "section": "",
    "text": "R.1 Interfacce e pacchetti\n√à possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html#interfacce-e-pacchetti",
    "href": "chapters/chapter_7/a46_stan.html#interfacce-e-pacchetti",
    "title": "Appendice R ‚Äî Linguaggio Stan",
    "section": "",
    "text": "CmdStanPy - integrazione con il linguaggio di programmazione Python;\nPyStan - integrazione con il linguaggio di programmazione Python;\nCmdStan - eseguibile da riga di comando,\nRStan - integrazione con il linguaggio \\(\\mathsf{R}\\);\nMatlabStan - integrazione con MATLAB;\nStan.jl - integrazione con il linguaggio di programmazione Julia;\nStataStan - integrazione con Stata.\nScalaStan - integrazione con Scala.\n\n\n\nArviz - ArviZ √® una libreria Python per l‚Äôanalisi esplorativa dei modelli bayesiani. Essa funge da strumento indipendente dal backend per diagnosticare e visualizzare l‚Äôinferenza bayesiana.\nshinystan - interfaccia grafica interattiva per l‚Äôanalisi della distribuzione a posteriori e le diagnostiche MCMC in \\(\\mathsf{R}\\);\nbayesplot - insieme di funzioni utilizzabili per creare grafici relativi all‚Äôanalisi della distribuzione a posteriori, ai test del modello e alle diagnostiche MCMC in \\(\\mathsf{R}\\);\nbrms - fornisce un‚Äôampia gamma di modelli lineari e non lineari specificando i modelli statistici mediante la sintassi usata in \\(\\mathsf{R}\\);\nrstanarm - fornisce un sostituto per i modelli frequentisti forniti da base \\(\\mathsf{R}\\) e lme4 utilizzando la sintassi usata in \\(\\mathsf{R}\\) per la specificazione dei modelli statistici;\ncmdstanr - un‚Äôinterfaccia \\(\\mathsf{R}\\) per CmdStan.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html#interfaccia-cmdstanpy",
    "href": "chapters/chapter_7/a46_stan.html#interfaccia-cmdstanpy",
    "title": "Appendice R ‚Äî Linguaggio Stan",
    "section": "R.2 Interfaccia cmdstanpy",
    "text": "R.2 Interfaccia cmdstanpy\nNegli esempi di questa dispensa verr√† utilizzata l‚Äôinterfaccia cmdstanpy. CmdStanPy √® una interfaccia di Stan per gli utenti Python, che fornisce gli oggetti e le funzioni necessarie per condurre l‚Äôinferenza bayesiana su un modello di probabilit√† e dei dati. Essa racchiude l‚Äôinterfaccia a riga di comando di CmdStan in un piccolo insieme di classi Python, le quali offrono metodi per analizzare e gestire l‚Äôinsieme risultante di modello, dati e stime a posteriori.\nPer l‚Äôinstallazione di CmdStanPy, si segua il link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html#codice-stan",
    "href": "chapters/chapter_7/a46_stan.html#codice-stan",
    "title": "Appendice R ‚Äî Linguaggio Stan",
    "section": "R.3 Codice Stan",
    "text": "R.3 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina √® stato generato), l‚Äôutente pu√≤ utilizzare l‚Äôinterfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan √® costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono: data, transformed data, parameters, transformed parameters, model, e generated quantities.\n\nR.3.1 Blocco data\nNel blocco data vengono specificate le variabili di input che saranno utilizzate nel modello Stan. Per ciascuna variabile, √® necessario definire il tipo di dato e le dimensioni, oltre a eventuali vincoli sui valori che le variabili possono assumere.\nPer esempio\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y; // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior; // Parametro beta per il prior Beta\n}\nEcco una sintesi dei tipi di dati e delle specifiche che possono essere dichiarate:\n\nint: rappresenta numeri interi.\nreal: designa numeri reali, inclusi quelli con parte decimale.\nvector: si riferisce a un vettore unidimensionale di numeri reali.\nmatrix: indica una matrice bidimensionale di numeri reali.\narray: descrive una sequenza ordinata di elementi che possono essere di qualsiasi tipo specificato, e pu√≤ avere pi√π di una dimensione.\n\n√à importante dichiarare le dimensioni di ciascuna variabile e, se necessario, applicare vincoli sui valori che queste possono assumere (ad esempio, specificando lower=0 e upper=1 per vincolare i valori tra 0 e 1). Questi vincoli sono utili per ottimizzare la stima dei parametri e garantire che il modello sia ben definito.\n\nR.3.1.1 Interi\nGli interi non vincolati vengono dichiarati utilizzando la parola chiave int. Ad esempio, la variabile N viene dichiarata come un intero nel seguente modo.\nint N;\nI tipi di dati interi possono essere vincolati per consentire valori solo in un intervallo specificato fornendo un limite inferiore, un limite superiore o entrambi. Ad esempio, per dichiarare N come un intero positivo, si utilizza quanto segue.\nint&lt;lower=1&gt; N;\n\n\nR.3.1.2 Reali\nLe variabili reali non vincolate vengono dichiarate utilizzando la parola chiave real. Ad esempio,\nreal theta;\nLe variabili reali possono essere limitate utilizzando la stessa sintassi degli interi. Per esempio, la variabile sigma pu√≤ essere dichiarata come non negativa come segue.\nreal&lt;lower=0&gt; sigma;\n\n\nR.3.1.3 Tipi di dati vettoriali e matriciali\nStan fornisce tre tipi di oggetti contenitore: array, vettori e matrici. I vettori e le matrici sono tipi di strutture dati pi√π limitati rispetto agli array. I vettori sono collezioni intrinsecamente unidimensionali di valori reali o complessi, mentre le matrici sono intrinsecamente bidimensionali. I vettori, le matrici e gli array non sono assegnabili tra loro, anche se le loro dimensioni sono identiche. Una matrice 3√ó4 √® un tipo di oggetto diverso in Stan rispetto a un array 3√ó4.\nI vettori e le matrici non possono essere tipizzati per restituire valori interi. Sono limitati a valori reali e complessi.\n\n\nR.3.1.4 Indicizzazione da 1\nVettori e matrici, cos√¨ come gli array, sono indicizzati a partire da uno (1) in Stan.\n\n\nR.3.1.5 Tipi di dati array\nStan supporta array di dimensioni arbitrarie. I valori in un array possono essere di qualsiasi tipo, in modo che gli array possano contenere valori che sono semplici reali o interi, vettori, matrici o altri array. Gli array sono l‚Äôunico modo per memorizzare sequenze di interi, e alcune funzioni in Stan, come le distribuzioni discrete, richiedono argomenti interi.\nUn array bidimensionale √® semplicemente un array di array. Quando viene fornito un indice a un array, restituisce il valore in quell‚Äôindice. Quando vengono forniti pi√π di un indice, questa operazione di indicizzazione √® concatenata. Ad esempio, se a √® un array bidimensionale, allora a[m, n] √® solo una abbreviazione per a[m][n].\n\n\nR.3.1.6 Dichiarazione di variabili array\nGli array sono dichiarati con la parola chiave array seguita dalle dimensioni racchiuse tra parentesi quadre, il tipo di elemento e il nome della variabile.\nPer esempio, la variabile n viene dichiarata come un array di cinque interi come segue.\narray[5] int n;\nUn array bidimensionale di valori interi con tre righe e quattro colonne viene dichiarato come segue.\narray[3, 4] int a;\nUn array di N numeri reali vincolati tra 0 e 1 viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] real&lt;lower=0, upper=1&gt; y;\nUn array di N interi positivi viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] int&lt;lower=0&gt; x;\n\n\nR.3.1.7 Vettori\nI vettori in Stan sono vettori colonna. I vettori sono dichiarati con una dimensione (cio√®, una dimensionalit√†). Ad esempio, un vettore reale tridimensionale di dimensione 3 viene dichiarato con la parola chiave vector, come segue.\nvector[3] u;\n\nR.3.1.7.1 Matrici\nLe matrici sono dichiarate con la parola chiave matrix insieme a un numero di righe e un numero di colonne. Ad esempio,\nmatrix[3, 3] A;\nmatrix[M, N] B;\ndichiara A come una matrice 3√ó3 e B come una matrice M√óN. Perch√© la seconda dichiarazione sia ben formata, le variabili M e N devono essere dichiarate come interi nel blocco dati o dati trasformati e prima della dichiarazione della matrice.\n\n\nR.3.1.7.2 Miscelazione di tipi di array, vettore e matrice\nArray, vettori riga, vettori colonna e matrici non sono interscambiabili in Stan. Quindi una variabile di uno qualsiasi di questi tipi fondamentali non √® assegnabile a nessuno degli altri, anche se le loro dimensioni sono identiche, n√© pu√≤ essere utilizzata come argomento dove √® richiesto l‚Äôaltro.\n\n\nR.3.1.7.3 Dizionari\n√à fondamentale che i dati forniti a Stan tramite CmdStanPy siano organizzati in un oggetto di tipo dizionario. In Python, un dizionario √® una collezione di coppie chiave-valore che permette di associare a ogni chiave (unica) un valore specifico. Quando si preparano i dati per un modello Stan utilizzando CmdStanPy, si crea un dizionario dove:\n\nOgni chiave corrisponde al nome di una variabile dichiarata nel blocco data del modello Stan.\nIl valore associato a ciascuna chiave rappresenta i dati effettivi da passare al modello per quella variabile.\n\nQuesta struttura consente di mappare direttamente le variabili definite nel modello Stan ai dati che si desidera analizzare, facilitando il processo di assegnazione dei dati e assicurando che ogni variabile riceva i dati corretti.\n\n\n\n\nR.3.2 Blocco parameters\nI parametri da stimare sono definiti all‚Äôinterno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilit√†. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell‚Äôintervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\nCerto, ecco il testo corretto e migliorato:\n\n\nR.3.3 Sezione model\nNella sezione model, vengono definite le relazioni tra i dati osservati e i parametri del modello, insieme alle distribuzioni a priori di tali parametri.\nA titolo di esempio, il seguente codice assegna una distribuzione a priori Beta ai parametri alpha_prior e beta_prior per il parametro theta. La verosimiglianza specifica che il meccanismo generatore dei dati osservati y √® binomiale, con parametri ntrials e theta.\nmodel {\n  // Prior\n  theta ~ beta(alpha_prior, beta_prior);\n  \n  // Likelihood\n  y ~ binomial(ntrials, theta);\n}\nIl simbolo ~ √® chiamato tilde. In generale, possiamo leggerlo come ‚Äú√® distribuito come‚Äù, e questa notazione viene utilizzata come abbreviazione per definire distribuzioni. Pertanto, l‚Äôesempio sopra pu√≤ essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta)\n\\]\nQuesta notazione compatta facilita la definizione delle relazioni probabilistiche nel modello.\nSe non specificata, Stan utilizza una distribuzione a priori uniforme tra meno infinito e pi√π infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, √® possibile consultare questo link.\n\n\nR.3.4 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. √à possibile trasformare i parametri del modello; solitamente ci√≤ viene fatto nel caso dei modelli pi√π avanzati per consentire un campionamento MCMC pi√π efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantit√† che non fa parte del modello ma pu√≤ essere calcolata a partire dai parametri del modello, per ogni iterazione dell‚Äôalgoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\nR.3.5 Sintassi\nSi noti che il codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos‚Äôaltro. I punti e virgola non sono invece richiesti all‚Äôinizio di un ciclo o di un‚Äôistruzione condizionale, dove non viene assegnato nulla.\nIn STAN, qualsiasi stringa che segue // denota un commento e viene ignorata dal programma.\nUna descrizione dettagliata della sintassi del linguaggio Stan √® disponibile al seguente link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_lin_fun.html",
    "href": "chapters/chapter_7/a50_lin_fun.html",
    "title": "Appendice S ‚Äî La funzione lineare",
    "section": "",
    "text": "La funzione lineare √® definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di questa funzione √® una retta, dove il parametro \\(b\\) rappresenta il coefficiente angolare e il parametro \\(a\\) rappresenta l‚Äôintercetta con l‚Äôasse delle \\(y\\). In altre parole, la retta interseca l‚Äôasse \\(y\\) nel punto \\((0,a)\\) se \\(b \\neq 0\\).\nPossiamo dare un‚Äôinterpretazione geometrica alle costanti \\(a\\) e \\(b\\) considerando la funzione:\n\\[\ny = b x.\n\\]\nQuesta funzione rappresenta un caso speciale, la proporzionalit√† diretta tra \\(x\\) e \\(y\\). Nel caso generale della funzione lineare:\n\\[\ny = a + b x,\n\\]\naggiungiamo una costante \\(a\\) a ciascun valore \\(y = b x\\). Nella funzione lineare, se il coefficiente \\(b\\) √® positivo, il valore di \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) √® negativo, il valore di \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\), la retta √® orizzontale e il valore di \\(y\\) non varia al variare di \\(x\\).\nConsideriamo ora il coefficiente \\(b\\) in modo pi√π dettagliato. Prendiamo un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\), come mostrato nella figura. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono chiamate ‚Äúincrementi‚Äù di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) √® definito come il rapporto\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Per dare un‚Äôinterpretazione geometrica al coefficiente angolare (o pendenza) della retta, possiamo semplificare assumendo \\(\\Delta x = 1\\). In questo caso, \\(b\\) √® uguale a \\(\\Delta y\\).\n\n\n\n\n\n\nFigura¬†S.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nPossiamo dunque dire che la pendenza \\(b\\) di un retta √® uguale all‚Äôincremento \\(\\Delta y\\) associato ad un incremento unitario nella \\(x\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>¬† <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html",
    "href": "chapters/chapter_7/a50_reglin_ml.html",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "",
    "text": "T.1 Preparazione del Notebook\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sc\nimport statistics as st\nimport arviz as az\nimport pingouin as pg\nimport warnings\nfrom sklearn.linear_model import LinearRegression\n\nwarnings.filterwarnings(\"ignore\")\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"regression_ml\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html#stima-dei-coefficienti-del-modello-di-regressione",
    "href": "chapters/chapter_7/a50_reglin_ml.html#stima-dei-coefficienti-del-modello-di-regressione",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "T.2 Stima dei Coefficienti del Modello di Regressione",
    "text": "T.2 Stima dei Coefficienti del Modello di Regressione\nConsideriamo i dati forniti dal dataset kidiq.\n\nkidiq = pd.read_stata(\"../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nCi concentreremo sulla relazione lineare tra l‚Äôintelligenza del bambino e l‚Äôintelligenza della madre.\nIniziamo rinominando le due variabili di interesse.\n\nx = kidiq[\"mom_iq\"]\ny = kidiq[\"kid_score\"]\n\nUn diagramma a dispersione evidenzia un‚Äôassociazione tra le due variabili in esame, che pu√≤ essere ragionevolmente approssimata da una retta. Tuttavia, il grafico suggerisce anche che la relazione tra le variabili non sia particolarmente forte.\nIn questo contesto, ci poniamo il duplice obiettivo di individuare la retta che meglio si adatta ai dati del diagramma e di quantificare la bont√† di questo adattamento. In altre parole, vogliamo valutare quanto, in media, i punti del diagramma si discostano dalla retta individuata.\n\nplt.plot(x, y, \"x\")\nplt.xlabel(\"Intelligenza della madre\")\n_ = plt.ylabel(\"Intelligenza del bambino\")\n\n\n\n\n\n\n\n\nCalcoliamo i coefficienti del modello\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i\n\\]\ncon il metodo della massima verosimiglianza. A questo scopo usiamo la funzione linear_regression() del pacchetto pingouin.\n\nlm = pg.linear_regression(x, y)\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n25.80\n5.92\n4.36\n0.0\n0.2\n0.2\n14.17\n37.43\n\n\n1\nmom_iq\n0.61\n0.06\n10.42\n0.0\n0.2\n0.2\n0.49\n0.72\n\n\n\n\n\n\n\n\nRecuperiamo i coefficienti b0 e b1 dall‚Äôoggetto lm creato da linear_regression().\n\nbeta = lm[\"coef\"]  # Coefficienti\nbeta\n\n0    25.799778\n1     0.609975\nName: coef, dtype: float64\n\n\n\nb0 = beta[0]\nb1 = beta[1]\n\nCalcoliamo i valori predetti dal modello di regressione:\n\\[\n\\hat{y}_i = \\beta_0 + \\beta_1 x_i\n\\]\n\nyhat = b0 + b1 * x\nyhat\n\n0      99.678390\n1      80.308253\n2      96.217173\n3      86.461529\n4      82.372303\n         ...    \n429    77.572841\n430    82.521552\n431    83.661788\n432    84.879856\n433    81.461993\nName: mom_iq, Length: 434, dtype: float64\n\n\nI modelli predetti \\(\\yhat\\) corrispondono alla retta di regressione.\n\nplt.plot(x, yhat)\nplt.xlabel(\"Intelligenza della madre\")\nplt.ylabel(\"Intelligenza predetta del bambino, $\\hat{y}$\")\n_ = plt.title(\"Retta di regressione\")\n\n\n\n\n\n\n\n\nAggiungiamo i dati osservati al grafico.\n\nplt.plot(x, yhat)\nplt.plot(x, y, \"x\")\nplt.xlabel(\"Intelligenza della madre\")\nplt.ylabel(\"Intelligenza predetta del bambino, $\\hat{y}$\")\n_ = plt.title(\"Retta di regressione\")\n\n\n\n\n\n\n\n\n\nT.2.1 Interpretazione\nIl coefficiente \\(\\beta_0\\) indica il valore atteso della distribuzione condizionata \\(p(y_i \\mid x_i = 0)\\). Nel caso presente, indica la media del quoziente d‚Äôintelligenza del bambino quando la madre ha un quoziente di intelligenza uguale a 0. Ovviamente questa non √® un‚Äôinformazione di una qualche importanza pratica. Vedremo come migliorare l‚Äôinterpretabilit√† dell‚Äôintercetta usando una parametrizzazione alternativa dei dati.\nIl coefficiente \\(\\beta_1\\) indica il cambiamento del valore atteso della variabile dipendente quando la variabile indipendente aumenta di un‚Äôunit√†. Nel caso presente abbiamo che il punteggio del quoziente di intelligenza del bambino aumenta in media di 0.61 punti quando il quoziente di intelligenza della madre aumenta di un punto. In una parametrizzazione alternativa, standardizzando la variabile indipendente, \\(\\beta_1\\) indicherebbe di quanto varia in media il quoziente di intelligenza del bambino quando il quoziente di intelligenza della madre aumenta di una deviazione standard.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html#residui",
    "href": "chapters/chapter_7/a50_reglin_ml.html#residui",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "T.3 Residui",
    "text": "T.3 Residui\nCalcoliamo i residui\n\\[\ne_i = y_i - \\hat{y}_i\n\\]\n\ne = y - yhat\n\nLa retta di regressine calcolata con il metodo della massima verosimiglianza ha le seguenti propriet√†:\n\nil valore atteso dei residui √® zero,\ni residui sono incorrelati con i valori predetti.\n\nValutiamo la media dei residui:\n\nnp.mean(e)\n\n-1.5455123100404022e-14\n\n\nCalcoliamo la correlazione tra i residui \\(e\\) e i valori predetti \\(\\hat{y}\\):\n\nnp.corrcoef(e, yhat)[0, 1]\n\n1.6170164072555654e-16\n\n\nIl modello di regressione bivariato\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i\n\\]\nscompone la variabile dipendente \\(y_i\\) in due componenti tra loro incorrelate, una componente deterministica\n\\[\n\\hat{y}_i = \\beta_0 + \\beta_1 x_i\n\\]\ne una componente aleatoria\n\\[\ne_i = y_i - \\hat{y}_i.\n\\]\n\ndf = pd.DataFrame()\ndf[\"x\"] = x\ndf[\"y\"] = y\ndf[\"yhat\"] = yhat\ndf[\"e\"] = e\ndf[\"sum\"] = df[\"yhat\"] + df[\"e\"]\ndf\n\n\n\n\n\n\n\n\n\nx\ny\nyhat\ne\nsum\n\n\n\n\n0\n121.117529\n65\n99.678390\n-34.678390\n65.0\n\n\n1\n89.361882\n98\n80.308253\n17.691747\n98.0\n\n\n2\n115.443165\n85\n96.217173\n-11.217173\n85.0\n\n\n3\n99.449639\n83\n86.461529\n-3.461529\n83.0\n\n\n4\n92.745710\n115\n82.372303\n32.627697\n115.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n429\n84.877412\n94\n77.572841\n16.427159\n94.0\n\n\n430\n92.990392\n76\n82.521552\n-6.521552\n76.0\n\n\n431\n94.859708\n50\n83.661788\n-33.661788\n50.0\n\n\n432\n96.856624\n88\n84.879856\n3.120144\n88.0\n\n\n433\n91.253336\n70\n81.461993\n-11.461993\n70.0\n\n\n\n\n434 rows √ó 5 columns",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html#errore-standard-della-regressione",
    "href": "chapters/chapter_7/a50_reglin_ml.html#errore-standard-della-regressione",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "T.4 Errore Standard della Regressione",
    "text": "T.4 Errore Standard della Regressione\nL‚Äôerrore standard della regressione rappresenta la stima della deviazione standard dei residui nell‚Äôintera popolazione. Questo parametro pu√≤ essere calcolato attraverso la formula:\n\\[\n\\hat{\\sigma}_e = \\sqrt{\\frac{\\sum_i (e_i - \\bar{e})^2}{n-2}},\n\\]\ndove $ {e} $ indica la media dei residui, che teoricamente √® zero dato che si assume che la media degli errori sia zero.\nIl denominatore ‚Äún-2‚Äù deriva dalla perdita di due gradi di libert√†, necessaria per la stima dei due coefficienti, $ _0 $ (intercetta) e $ _1 $ (pendenza), che sono utilizzati per calcolare le stime previste $ _i = _0 + _1 x_i $. Questi gradi di libert√† vengono sottratti perch√© ciascun parametro stimato consuma un grado di libert√† dal totale disponibile.\nNel caso dell‚Äôesempio, la numerosit√† campionaria √®\n\nn = len(x)\nn\n\n434\n\n\nL‚Äôerrore standard della regressione diventa\n\nnp.sqrt(np.sum(e**2) / (n-2))\n\n18.266122792299274\n\n\nQuesto valore indica che, in media, nella popolazione la distanza tra i valori osservati e la retta di regressione √® di 18.3 punti.\nCome discusso da {cite}gelman2020regression, la radice quadrata media dei residui, $ _{i=1}^n (y_i - ( + x_i))^2 $, tende a sottostimare la deviazione standard \\(\\sigma\\) dell‚Äôerrore nel modello di regressione. Questa sottostima √® spesso il risultato di un sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati usati anche per calcolare i residui.\nLa validazione incrociata rappresenta un approccio alternativo per valutare l‚Äôerrore predittivo che evita alcuni dei problemi legati al sovradimensionamento. La versione pi√π semplice della validazione incrociata √® l‚Äôapproccio leave-one-out, in cui il modello √® adattato \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti dati, e utilizzando questo modello adattato per predire l‚Äôosservazione esclusa: - Per \\(i = 1, \\ldots, n\\): - Adatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x,y)_j, j \\neq i\\). Denomina i coefficienti di regressione stimati come \\(\\hat{a}_{-i}, \\hat{b}_{-i}\\). - Calcola il residuo validato incrociato, $ r_{} = y_i - ({-i} + {-i} x_i) $. - Calcola la stima di \\(\\sigma_{\\text{CV}} = \\frac{1}{n} \\sum_{i=1}^n r_{\\text{CV}}^2\\).\nPer fare un esempio, eseguiamo i passaggi sopra descritti per il modello dell‚Äôintelligenza del bambino predetta dall‚Äôintelligenza della madre.\n\n# Inizializzazione di un modello di regressione lineare\nmodel = LinearRegression()\n\n# Array per salvare i residui cross-validated\nresiduals_cv = []\n\n# Loop per la validazione incrociata leave-one-out\nfor i in range(len(df)):\n    # Dati di training escludendo l'i-esimo punto\n    X_train = df.loc[df.index != i, [\"x\"]]\n    y_train = df.loc[df.index != i, \"y\"]\n\n    # Dati di test\n    X_test = df.loc[[i], [\"x\"]]\n    y_test = df.loc[i, \"y\"]\n\n    # Addestramento del modello\n    model.fit(X_train, y_train)\n\n    # Predizione sull'i-esimo punto\n    y_pred = model.predict(X_test)\n\n    # Calcolo del residuo validato incrociato\n    residual_cv = y_test - y_pred[0]\n    residuals_cv.append(residual_cv**2)\n\n# Calcolo di sigma_cv\nsigma_cv = np.sqrt(np.mean(residuals_cv))\n\nprint(\"Stima di œÉ_CV:\", sigma_cv)\n\nStima di œÉ_CV: 18.306662828465665\n\n\nNel caso dei dati analizzati, si osserva che la stima ottenuta attraverso la validazione incrociata √® leggermente superiore rispetto a quella calcolata usando la formula $ _e = $. Questo incremento, sebbene minimo, riflette le differenze metodologiche tra i due approcci di stima dell‚Äôerrore standard.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html#parametrizzazione-alternativa",
    "href": "chapters/chapter_7/a50_reglin_ml.html#parametrizzazione-alternativa",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "T.5 Parametrizzazione Alternativa",
    "text": "T.5 Parametrizzazione Alternativa\nPer consentire una migliore interpretazione dell‚Äôintercetta, centriamo i valori della variabile indipendente.\n\nxc = x - np.mean(x)\nnp.mean(xc)\n\n7.858537169696961e-16\n\n\nEseguiamo l‚Äôanalisi di regressione.\n\nlm2 = pg.linear_regression(xc, y)\nlm2.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n86.80\n0.88\n98.99\n0.0\n0.2\n0.2\n85.07\n88.52\n\n\n1\nmom_iq\n0.61\n0.06\n10.42\n0.0\n0.2\n0.2\n0.49\n0.72\n\n\n\n\n\n\n\n\nNotiamo che la stima della pendenza della retta di regressione √® rimasta immutata, mentre cambia il coefficiente \\(\\beta_0\\). Nel caso in cui la variabile indipendente sia centrata, il coefficiente \\(\\beta_0\\) rappresenta il valore atteso della variabile dipendente quando la variabile indipendente assume il suo valore medio.\nNel caso presente, il valore 86.80 indica la media del quoziente di intelligenza del bambino quando il quoziente di intelligenza della madre assume il valore medio nel campione.\nAdesso standardizziamo sia la variabile dipendente che la variabile indipendente.\n\nx_mean = np.mean(x)\nx_std = np.std(x, ddof=0)\n\n# Standardizzazione\nzx = (x - x_mean) / x_std\n\nprint(np.mean(zx), np.std(zx))\n\n4.9115857310606007e-17 0.9999999999999999\n\n\n\ny_mean = np.mean(y)\ny_std = np.std(y, ddof=0)\n\n# Standardizzazione\nzy = (y - y_mean) / y_std\n\n\nlm3 = pg.linear_regression(zx, zy)\nlm3.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-0.00\n0.04\n-0.00\n1.0\n0.2\n0.2\n-0.08\n0.08\n\n\n1\nmom_iq\n0.45\n0.04\n10.42\n0.0\n0.2\n0.2\n0.36\n0.53\n\n\n\n\n\n\n\n\nDopo aver standardizzato entrambe le variabili, i coefficienti di regressione possono essere interpretati nel seguente modo:\n\n\\(\\beta_0\\) = 0: Questo si verifica perch√© la retta di regressione, calcolata attraverso il metodo dei minimi quadrati (ML), interseca il punto delle medie delle variabili standardizzate, ovvero \\((\\bar{X}, \\bar{Y})\\).\n\\(\\beta_1\\): Rappresenta la variazione media della variabile dipendente, espressa in termini di deviazioni standard, per ogni aumento di una deviazione standard nella variabile indipendente.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html#teorema-della-scomposizione-della-devianza",
    "href": "chapters/chapter_7/a50_reglin_ml.html#teorema-della-scomposizione-della-devianza",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "T.6 Teorema della scomposizione della devianza",
    "text": "T.6 Teorema della scomposizione della devianza\nIl teorema della scomposizione della devianza nel modello di regressione lineare ci aiuta a comprendere quanto bene il modello si adatta ai dati. Esso scompone la variazione totale dei dati in componenti attribuibili all‚Äôeffetto del modello e alla variazione residua non spiegata dal modello.\n\nT.6.1 Formulazione del Teorema\nDato un set di dati $ y_1, y_2, , y_n $, dove $ y_i $ rappresenta l‚Äôi-esimo valore della variabile dipendente, e $ {y} $ √® la media campionaria di $ y $, la devianza totale (o variazione totale) dei dati pu√≤ essere scomposta nel seguente modo:\n\nDevianza Totale (VT): Misura la dispersione totale dei dati intorno alla loro media. \\[\nDT = \\sum_{i=1}^n (y_i - \\bar{y})^2\n\\]\nDevianza Spiegata (VS): Misura quanto della variazione totale √® spiegata dal modello di regressione. \\[\nDS = \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2\n\\] dove $ _i $ √® il valore predetto dalla regressione per l‚Äôi-esimo osservazione.\nDevianza Residua (VR): Misura la variazione dei dati che il modello non riesce a spiegare. \\[\nDR = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n\\]\n\n\n\nT.6.2 Teorema di Scomposizione della Devianza\nIl teorema afferma che la variazione totale $ DT $ √® uguale alla somma della variazione spiegata $ DS $ e della variazione residua $ DR $:\n\\[\nDT = DS + DR\n\\]\n\n\nT.6.3 Dimostrazione\nLa dimostrazione di questa identit√† si basa sul principio di ortogonalit√† dei residui e delle stime. I residui $ y_i - _i $ sono ortogonali alle predizioni $ _i - {y} $ nel contesto della regressione lineare. Matematicamente, ci√≤ √® espresso da:\n\\[\n\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})(y_i - \\hat{y}_i) = 0\n\\]\nUtilizzando l‚Äôortogonalit√†, possiamo scrivere la variazione totale come segue:\n\\[\n\\begin{align*}\nDT &= \\sum_{i=1}^n (y_i - \\bar{y})^2 \\\\\n   &= \\sum_{i=1}^n [(y_i - \\hat{y}_i) + (\\hat{y}_i - \\bar{y})]^2 \\\\\n   &= \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + 2\\sum_{i=1}^n (y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) + \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2 \\\\\n   &= DR + 2 \\cdot 0 + DS \\\\\n   &= DR + DS\n\\end{align*}\n\\]\nQuesta dimostrazione chiarisce che la variazione totale √® esattamente uguale alla somma della devianza spiegata dal modello e quella non spiegata (residua). Il coefficiente di determinazione $ R^2 $, che √® definito come $ R^2 = $, offre una misura della proporzione della variazione totale spiegata dal modello.\nApplichiamo ora il teorema di scomposizione della devianza ai dati in esame. Usando pg.linear_regression(x, y) calcoliamo il coefficiente di determinazione.\n\nr_squared = lm[\"r2\"][0] # R-squared del modello\nprint(r_squared)\n\n0.20095123075855126\n\n\nCalcoliamo la devianza totale.\n\nDT = np.sum((y - np.mean(y))**2)\nprint(DT)\n\n180386.15668202768\n\n\nCalcoliamo la devianza spiegata.\n\nDS = np.sum((yhat - np.mean(y)) ** 2)\nprint(DS)\n\n36248.82019705826\n\n\nCalcoliamo la devianza residua.\n\nDR = np.sum((y - yhat) ** 2)\nprint(DR)\n\n144137.33648496936\n\n\nLa devianza totale √® la somma della devianza spiegata e della devianza residua.\n\nDS + DR\n\n180386.15668202762\n\n\nIl coefficiente di determinazione √® il rapporto tra la devianza spiegata e la devianza totale.\n\nRsq = DS / DT\nprint(Rsq)\n\n0.2009512307585509",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html#inferenza",
    "href": "chapters/chapter_7/a50_reglin_ml.html#inferenza",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "T.7 Inferenza",
    "text": "T.7 Inferenza\nEsistono due principali approcci di inferenza statistica applicabili ai modelli di regressione: l‚Äôinferenza frequentista e l‚Äôinferenza bayesiana.\n\nT.7.1 Inferenza Frequentista\nL‚Äôinferenza frequentista stabilisce le sue basi analizzando la distribuzione campionaria delle stime dei coefficienti di regressione e calcolando l‚Äôerrore standard associato. Questo metodo si focalizza prevalentemente sul test delle ipotesi e sulla costruzione degli intervalli di fiducia. Tuttavia, il test dell‚Äôipotesi nulla √® spesso criticato nel dibattito metodologico contemporaneo per la sua rigidezza e limitazioni interpretative. Analogamente, gli intervalli di fiducia possono risultare contro-intuitivi e di limitata utilit√† pratica, dato che richiedono un‚Äôinterpretazione che non riflette direttamente la probabilit√† che il parametro si trovi all‚Äôinterno dell‚Äôintervallo specificato.\n\n\nT.7.2 Inferenza Bayesiana\nContrariamente all‚Äôapproccio frequentista, l‚Äôinferenza bayesiana offre un quadro pi√π flessibile e intuitivo per l‚Äôanalisi statistica. Attraverso l‚Äôutilizzo degli intervalli di credibilit√†, l‚Äôinferenza bayesiana permette di incorporare conoscenze pregresse e aggiornarle alla luce di nuovi dati. Gli intervalli di credibilit√† forniscono una stima diretta della probabilit√† che un parametro si trovi all‚Äôinterno di un certo intervallo, basata sulla distribuzione a posteriori. Questo rende l‚Äôinterpretazione pi√π diretta e gli intervalli di credibilit√† risultano essere strumenti praticamente pi√π utili nell‚Äôinferenza statistica.\nPer queste ragioni, molti ricercatori e analisti preferiscono sviluppare inferenze tramite l‚Äôapproccio bayesiano, specialmente quando le situazioni richiedono una maggiore flessibilit√† interpretativa e l‚Äôintegrazione di informazioni pregresse nel modello analitico.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a50_reglin_ml.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_7/a50_reglin_ml.html#informazioni-sullambiente-di-sviluppo",
    "title": "Appendice T ‚Äî Modello di Regressione Bivariato e ML",
    "section": "T.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "T.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed May 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.8.4\narviz     : 0.18.0\npingouin  : 0.5.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Modello di Regressione Bivariato e ML</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a51_reglin_1.html",
    "href": "chapters/chapter_7/a51_reglin_1.html",
    "title": "Appendice U ‚Äî Regressione lineare bivariata",
    "section": "",
    "text": "U.1 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di trovare una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L‚Äôequazione lineare che descrive la relazione tra le due variabili √® della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) √® il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo √® che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo √® che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo √® quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) √® piatto, cio√® le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ci√≤ significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) √®\n\\[\na = \\bar{y} - b \\bar{x}.\n\\]\nLa formula per il coefficiente \\(b\\) √®\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) √® la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) √® la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\nNel caso dell‚Äôesempio presente, tali coefficienti sono uguali a:\ncov_xy = np.cov(kidiq[\"kid_score\"], kidiq[\"mom_iq\"], ddof=1)[0][1]\nvar_x = np.var(kidiq[\"mom_iq\"], ddof=1)\nb = cov_xy / var_x\nb\n\n0.6099745717307855\na = np.mean(kidiq[\"kid_score\"]) - b * np.mean(kidiq[\"mom_iq\"])\na\n\n25.79977784996293\nVerifichiamo i risultati trovati usando funzione optimize.curve_fit. Questa √® una funzione molto potente, in quanto pu√≤ adattarsi non solo alle funzioni lineari, ma anche alle funzioni non lineari. Qui la usiamo per la retta di regressione.\ndef func(x, a, b):\n    y = a + b*x\n    return y\n  \noptimize.curve_fit(func, xdata = kidiq.mom_iq, ydata = kidiq.kid_score)[0]\n\narray([25.7997779 ,  0.60997457])",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a51_reglin_1.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/chapter_7/a51_reglin_1.html#stima-dei-coefficienti-di-regressione",
    "title": "Appendice U ‚Äî Regressione lineare bivariata",
    "section": "",
    "text": "U.1.1 Interpretazione\nIl coefficiente \\(a\\) indica l‚Äôintercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l‚Äôasse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non √® di particolare interesse poich√© corrisponde al valore della retta di regressione quando l‚Äôintelligenza della madre √® pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come √® possibile trasformare i dati per fornire un‚Äôinterpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) √® positivo) o diminuisce (se \\(b\\) √® negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri √® associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ci√≤ significa che non √® in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unit√† di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\n√à importante comprendere che il modello statistico di regressione lineare non √® in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima √® basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\), per tutte le osservazioni del campione √® fornito dalla figura seguente.\n\n_, ax = plt.subplots()\n_ = ax.plot(kidiq[\"mom_iq\"], a + b * kidiq[\"mom_iq\"], \"o\", alpha=0.4)\n\n\n\n\n\n\n\n\nIl diagramma precedente presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). Si vede che i valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nprint(kidiq[\"kid_score\"][0])\n\n65\n\n\nIl QI della madre √®\n\nkidiq[\"mom_iq\"][0]\n\n121.11752860260343\n\n\nPer questo bambino, il valore predetto dal modello di regressione √®\n\na + b * kidiq[\"mom_iq\"][0]\n\n99.67839048842711\n\n\nL‚Äôerrore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) √®\n\nkidiq[\"kid_score\"][0] - (a + b * kidiq[\"mom_iq\"][0])\n\n-34.67839048842711\n\n\nPer tutte le osservazioni abbiamo\n\nres = kidiq[\"kid_score\"] - (a + b * kidiq[\"mom_iq\"])\nres\n\n0     -34.678390\n1      17.691747\n2     -11.217173\n3      -3.461529\n4      32.627697\n         ...    \n429    16.427159\n430    -6.521552\n431   -33.661788\n432     3.120144\n433   -11.461993\nLength: 434, dtype: float64\n\n\n√à una propriet√† del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nnp.sum(res)\n\n-2.7284841053187847e-12\n\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che √® predicibile da \\(x_i\\), √® data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, √® dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\npd.DataFrame(\n    {\n        \"kid_score\": kidiq[\"kid_score\"],\n        \"mom_iq\": kidiq[\"mom_iq\"],\n        \"y_hat\": a + b * kidiq[\"mom_iq\"],\n        \"e\": kidiq[\"kid_score\"] - (a + b * kidiq[\"mom_iq\"]),\n        \"y_hat + e\": (a + b * kidiq[\"mom_iq\"])\n        + (kidiq[\"kid_score\"] - (a + b * kidiq[\"mom_iq\"])),\n    }\n).head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\ny_hat\ne\ny_hat + e\n\n\n\n\n0\n65\n121.117529\n99.678390\n-34.678390\n65.0\n\n\n1\n98\n89.361882\n80.308253\n17.691747\n98.0\n\n\n2\n85\n115.443165\n96.217173\n-11.217173\n85.0\n\n\n3\n83\n99.449639\n86.461529\n-3.461529\n83.0\n\n\n4\n115\n92.745710\n82.372303\n32.627697\n115.0\n\n\n\n\n\n\n\n\n\n\nU.1.2 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l‚Äôintercetta del modello di regressione lineare non ha un‚Äôinterpretazione utile. Questo perch√© l‚Äôintercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore ‚Äú0‚Äù di \\(x\\) √® arbitrario e non corrisponde ad un ‚Äúassenza‚Äù della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un‚Äôassenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre √® 0 non √® di alcun interesse.\nPer fornire all‚Äôintercetta del modello di regressione un‚Äôinterpretazione pi√π utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq[\"xd\"] = kidiq[\"mom_iq\"] - np.mean(kidiq[\"mom_iq\"])\nkidiq\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\nxd\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n21.117529\n\n\n1\n98\n1.0\n89.361882\n4\n25\n-10.638118\n\n\n2\n85\n1.0\n115.443165\n4\n27\n15.443165\n\n\n3\n83\n1.0\n99.449639\n3\n25\n-0.550361\n\n\n4\n115\n1.0\n92.745710\n4\n27\n-7.254290\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n429\n94\n0.0\n84.877412\n4\n21\n-15.122588\n\n\n430\n76\n1.0\n92.990392\n4\n23\n-7.009608\n\n\n431\n50\n0.0\n94.859708\n2\n24\n-5.140292\n\n\n432\n88\n1.0\n96.856624\n2\n21\n-3.143376\n\n\n433\n70\n1.0\n91.253336\n2\n25\n-8.746664\n\n\n\n\n434 rows √ó 6 columns\n\n\n\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n_, ax = plt.subplots()\nax.plot(kidiq[\"xd\"], kidiq[\"kid_score\"], \"o\", alpha=0.4)\nb, a = np.polyfit(kidiq[\"xd\"], kidiq[\"kid_score\"], 1)\nplt.plot(kidiq[\"xd\"], a + b * kidiq[\"xd\"])\nax.set_xlabel(\"QI della madre (scarti dalla media)\")\n_ = ax.set_ylabel(\"QI del bambino\")\n\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l‚Äôasse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l‚Äôorigine dell‚Äôasse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L‚Äôunica cosa che cambia √® il valore dell‚Äôintercetta della linea di regressione, che ora ha un‚Äôinterpretazione pi√π significativa.\n\nresult = stats.linregress(kidiq.xd, kidiq.kid_score)\nresult.intercept, result.slope\n\n(86.79723502304148, 0.6099745717307856)\n\n\nL‚Äôintercetta rappresenta il punto in cui la retta di regressione incontra l‚Äôasse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l‚Äôasse \\(x\\) di una quantit√† pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell‚Äôintercetta viene influenzato dalla trasformazione. In particolare, poich√© \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l‚Äôintercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l‚Äôintercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.\n\n\nU.1.3 Il metodo dei minimi quadrati\nPer calcolare i coefficienti di regressione \\(a\\) e \\(b\\), si deve minimizzare la somma dei quadrati degli scarti tra i valori osservati \\(y_i\\) e quelli previsti dal modello \\(a + bx_i\\) per ogni osservazione \\(i\\). In altre parole, si vuole trovare i valori di \\(a\\) e \\(b\\) che permettono di ottenere la retta di regressione che si avvicina il pi√π possibile ai dati osservati.\nPer calcolare i coefficienti di regressione tramite una simulazione, supponiamo che uno dei due parametri sia noto, ad esempio \\(a\\), cos√¨ da avere una sola incognita. Creiamo una griglia di valori b_grid possibili, ad esempio:\n\nb_grid = np.linspace(0, 1, 1001)\n\nDefiniamo una funzione che calcola la somma dei quadrati dei residui \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\):\n\ndef sse(a, b, x, y):\n    return np.sum((y - (a + b * x)) ** 2)\n\nCalcoliamo la somma degli errori quadratici per ciascun possibile valore b_grid. Per semplificaer il problema, considerato noto \\(a = 25.79978\\).\n\na = 25.79978\nsse_vals = [sse(a, b, kidiq[\"mom_iq\"], kidiq[\"kid_score\"]) for b in b_grid]\n\nEsaminiamo il risultato ottenuto.\n\nplt.plot(b_grid, sse_vals, '-')\nplt.plot(\n    b_grid[np.argmin(sse_vals)], sse_vals[np.argmin(sse_vals)],\n    'X', label=r'Stima dei minimi quadrati, $\\hat \\beta$'\n)\nplt.ylabel('SSE')\nplt.xlabel(fr'Possibili valori $\\hat \\beta$')\nplt.title(f'Minimizzazione dei residui quadratici')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIl risultato ottenuto con la simulazione riproduce quello ottenuto per via analitica.\n\nb_grid[np.argmin(sse_vals)]\n\n0.61\n\n\nAbbiamo mostrato un esempio di simulazione per stimare uno dei coefficienti del modello lineare. Tuttavia, una simulazione pi√π complessa, ma computazionalmente pi√π costosa, pu√≤ essere utilizzata per stimare simultaneamente entrambi i coefficienti del modello lineare. Ci√≤ che abbiamo fatto qui √® solo una dimostrazione del concetto di base, ovvero il metodo di minimizzazione dei residui quadrati, che viene utilizzato per stimare i coefficienti del modello lineare.\n\n\nU.1.4 L‚Äôerrore standard della regressione\nIl secondo obiettivo del modello di regressione lineare √® quello di misurare quanto della variabilit√† di \\(y\\) possa essere spiegata dalla variabilit√† di \\(x\\) per ogni osservazione. L‚Äôindice di bont√† di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche ‚Äúerrore standard della stima‚Äù, \\(s_e\\). Per calcolare \\(s_e\\), si utilizza una formula che prevede di sommare i quadrati dei residui \\(e_i\\) per ogni osservazione e di dividere per \\(n-2\\), dove \\(n\\) rappresenta la numerosit√† del campione e \\(2\\) rappresenta il numero di coefficienti stimati nel modello di regressione. L‚Äôerrore standard della stima \\(s_e\\) possiede la stessa unit√† di misura di \\(y\\) ed √® una stima della deviazione standard dei residui nella popolazione di cui il campione √® stato estratto. In altre parole, l‚Äôerrore standard della stima rappresenta una stima della media dei residui, che indica quanto lontane le previsioni del modello di regressione lineare possono essere dalle osservazioni effettive.\nVerifichiamo quanto detto con i dati a disposizione. I residui possono essere trovati nel modo seguente.\n\ne = kidiq.kid_score - (a + b * kidiq.mom_iq)\ne[0:10]\n\n0   -34.678393\n1    17.691744\n2   -11.217175\n3    -3.461531\n4    32.627695\n5     6.382843\n6   -41.521043\n7     3.864879\n8    26.414384\n9    11.208066\ndtype: float64\n\n\nCalcoliamo il residuo medio, prendendo il valore assoluto.\n\nnp.mean(np.abs(e))\n\n14.46860267547228\n\n\nL‚Äôerrore standard della regressione √®\n\nnp.sqrt(sum(e**2) / (len(e) - 2))\n\n18.2661227922994\n\n\nSi noti che i due valori non sono uguali, ma hanno lo stesso ordine di grandezza.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a51_reglin_1.html#indice-di-determinazione",
    "href": "chapters/chapter_7/a51_reglin_1.html#indice-di-determinazione",
    "title": "Appendice U ‚Äî Regressione lineare bivariata",
    "section": "U.2 Indice di determinazione",
    "text": "U.2 Indice di determinazione\nUn importante risultato dell‚Äôanalisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione √® descritta mediante l‚Äôindice di determinazione \\(R^2\\), che fornisce una misura della bont√† di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) pu√≤ essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) pu√≤ quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. L‚Äôindice di determinazione \\(R^2\\) √® definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) √® spiegata dalla variabile indipendente \\(x\\).\nPer l‚Äôesempio in discussione abbiamo quanto segue. La devianza totale √®\n\ndev_t = np.sum((kidiq.kid_score - np.mean(kidiq.kid_score)) ** 2)\ndev_t\n\n180386.15668202768\n\n\nLa devianza spiegata √®\n\ndev_r = np.sum(((a + b * kidiq.mom_iq) - np.mean(kidiq.kid_score)) ** 2)\ndev_r\n\n36248.820197060355\n\n\nL‚Äôindice di determinazione √®\n\nR2 = dev_r / dev_t\nround(R2, 3)\n\n0.201\n\n\nVerifichiamo.\n\nX = sm.add_constant(kidiq[\"mom_iq\"])\nmod = sm.OLS(kidiq[\"kid_score\"], X)\nres = mod.fit()\nprint(res.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              kid_score   R-squared:                       0.201\nModel:                            OLS   Adj. R-squared:                  0.199\nMethod:                 Least Squares   F-statistic:                     108.6\nDate:                Thu, 29 Feb 2024   Prob (F-statistic):           7.66e-23\nTime:                        08:43:14   Log-Likelihood:                -1875.6\nNo. Observations:                 434   AIC:                             3755.\nDf Residuals:                     432   BIC:                             3763.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         25.7998      5.917      4.360      0.000      14.169      37.430\nmom_iq         0.6100      0.059     10.423      0.000       0.495       0.725\n==============================================================================\nOmnibus:                        7.545   Durbin-Watson:                   1.645\nProb(Omnibus):                  0.023   Jarque-Bera (JB):                7.735\nSkew:                          -0.324   Prob(JB):                       0.0209\nKurtosis:                       2.919   Cond. No.                         682.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nIl risultato ottenuto si pu√≤ interpretare dicendo che circa il 20% della variabilit√† dei punteggi del QI dei bambini pu√≤ essere predetto conoscendo il QI delle madri.\n\nU.2.1 Inferenza sul modello di regressione\nIl paragrafo precedente discute l‚Äôapproccio ‚Äúclassico‚Äù al modello di regressione lineare, che si basa sulle stime dei minimi quadrati. Questo approccio non tiene conto delle distribuzioni a priori dei parametri \\(\\alpha\\) e \\(\\beta\\). Se imponiamo distribuzioni a priori uniformi (non informative) sui parametri, le stime di massima verosimiglianza coincidono con il massimo a posteriori bayesiano. Tuttavia, in un contesto bayesiano, √® possibile imporre distribuzioni a priori debolmente o informativamente. In questo caso, la scelta della distribuzione a priori ha un effetto sulla regolarizzazione dei dati.\nNell‚Äôapproccio frequentista, l‚Äôinferenza viene effettuata calcolando la distribuzione campionaria dei parametri e gli intervalli di fiducia per i parametri. Ad esempio, se si vuole determinare se la pendenza della retta di regressione √® maggiore di zero, si calcola l‚Äôintervallo di fiducia al 95% per il parametro \\(\\beta\\). Se l‚Äôintervallo non include lo zero e se il limite inferiore dell‚Äôintervallo √® maggiore di zero, si conclude che c‚Äô√® evidenza di un‚Äôassociazione lineare positiva tra \\(x\\) e \\(y\\) con un grado di confidenza del 95%.\nIn un‚Äôottica bayesiana, l‚Äôintervallo di credibilit√† al 95% per il parametro \\(\\beta\\) pu√≤ essere calcolato. Se usiamo una distribuzione a priori uniforme, gli intervalli di credibilit√† e di fiducia sono identici. Tuttavia, se usiamo una distribuzione a priori debolmente o informativamente, i due intervalli possono differire. Solitamente si usa una distribuzione a priori debolmente informativa centrata sullo zero, che ha l‚Äôeffetto di regolarizzare i dati. Il prossimo capitolo spiegher√† come effettuare l‚Äôinferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a51_reglin_1.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_7/a51_reglin_1.html#commenti-e-considerazioni-finali",
    "title": "Appendice U ‚Äî Regressione lineare bivariata",
    "section": "U.3 Commenti e considerazioni finali",
    "text": "U.3 Commenti e considerazioni finali\nIl modello lineare bivariato √® uno strumento fondamentale per analizzare la relazione tra due variabili. Non solo ci permette di capire se esiste una correlazione tra le due variabili, ma ci permette anche di determinare il grado di intensit√† di tale correlazione e di fare previsioni sull‚Äôandamento futuro.\nIn pratica, il modello lineare ci consente di rispondere a domande del tipo: se il valore della variabile indipendente aumenta di una certa quantit√†, di quanto aumenter√† il valore della variabile dipendente? Oppure, se il valore della variabile indipendente diminuisce, di quanto diminuir√† il valore della variabile dipendente?\nQuesti sono solo alcuni esempi di come il modello lineare bivariato possa essere utilizzato per fare previsioni. La bellezza di questo modello sta nella sua semplicit√†: si tratta di una formula matematica che ci permette di descrivere la relazione tra le due variabili in modo chiaro e preciso. Inoltre, il modello lineare pu√≤ essere utilizzato anche in contesti pi√π complessi, ad esempio quando ci sono pi√π variabili indipendenti che influenzano la variabile dipendente.\nInsomma, il modello lineare bivariato √® uno strumento fondamentale per analizzare e comprendere le relazioni tra le variabili, e ci permette di fare previsioni utili per prendere decisioni informate e ottimizzare i nostri risultati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a51_reglin_1.html#watermark",
    "href": "chapters/chapter_7/a51_reglin_1.html#watermark",
    "title": "Appendice U ‚Äî Regressione lineare bivariata",
    "section": "U.4 Watermark",
    "text": "U.4 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -m\n\nLast updated: Thu Feb 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib : 3.8.3\nseaborn    : 0.13.2\nscipy      : 1.12.0\narviz      : 0.17.0\nnumpy      : 1.26.4\nstatsmodels: 0.14.1\npandas     : 2.2.1",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a60_ttest_exercises.html",
    "href": "chapters/chapter_7/a60_ttest_exercises.html",
    "title": "Appendice V ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "",
    "text": "V.1 Inferenza statistica su una singola media",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "href": "chapters/chapter_7/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "title": "Appendice V ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "",
    "text": "V.1.1 Test \\(t\\) di Student a un campione\nPer descrivere l‚Äôinferenza su una singola media consideriamo il seguente esempio. √à stato condotto uno studio di ricerca al fine di esaminare le differenze tra gli adulti anziani e quelli giovani sulla percezione della soddisfazione nella vita. Per testare questa ipotesi, √® stato effettuato uno studio pilota su dati ipotetici. Il test √® stato somministrato a dieci adulti anziani (oltre i 70 anni) e dieci adulti giovani (tra i 20 e i 30 anni). La scala di valutazione utilizzata ha un range di punteggi da 0 a 60, dove punteggi elevati indicano una maggiore soddisfazione nella vita e punteggi bassi indicano una minore soddisfazione. √à stata scelta una scala con elevata affidabilit√† e validit√†. I dati (fittizi) raccolti sono riportati di seguito.\n\nyounger = np.array([45, 38, 52, 48, 25, 39, 51, 46, 55, 46])\nolder = np.array([34, 33, 36, 38, 37, 40, 42, 43, 32, 36])\n\nPer ora, esaminiamo soltanto il gruppo degli adulti pi√π anziani. Si suppponga che studi precedenti indichino che, per questo gruppo d‚Äôet√†, la soddisfazione della vita misurata con questo test sia pari a 60. Svolgiamo il test t di Student usando l‚Äôipotesi nulla che nella popolazione la media sia effettivamente uguale a 40.\nInziamo a svolgere l‚Äôesercizio applicando la funzione ttest del modulo pingouin. Per l‚Äôesempio presente, poniamo \\(\\mu_0\\), la media dell‚Äôipotesi nulla, uguale a 40. Svolgiamo l‚Äôesercizio con ttest.\n\nres = pg.ttest(older, 40)\n\nEsaminiamo il risultato.\n\nprint(res)\n\n               T  dof alternative     p-val           CI95%   cohen-d   BF10  \\\nT-test -2.481666    9   two-sided  0.034896  [34.46, 39.74]  0.784772  2.319   \n\n           power  \nT-test  0.599895  \n\n\nInterpretazione. Dato che il valore-p √® minore di \\(\\alpha\\) = 0.05, ovvero in modo equivalente, dato che la statistica test cade nella regione di rifiuto, rifiutiamo \\(H_0: \\mu = 40\\).\nProcediamo ora con i calcoli passo-passo utilizzando la formula del test t di Student. La statistica \\(T\\) calcolata dal test √® definita come:\n\\[\nT = \\frac{\\bar{X} - \\mathbb{E}(\\bar{X})}{s / \\sqrt{n}} = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) √® la media campionaria, \\(\\mu_0\\) √® l‚Äôipotesi nulla sulla media della popolazione, \\(s\\) √® la deviazione standard campionaria e \\(n\\) √® la dimensione del campione. Tale statistica ha una semplice interpretazione: essa corrisponde alla standardizzazione della media del campione all‚Äôinterno della distribuzione campionaria delle medie di ampiezza \\(n\\) = 10. La distribuzione campionaria delle medie di ampiezza \\(n\\) = 10 ha media \\(\\mu_{\\bar{X}} = \\mu\\) e varianza \\(\\sigma^2_{\\bar{X}} = \\frac{\\sigma^2}{n}\\), dove \\(\\mu\\) √® la media della popolazione e \\(\\sigma^2\\) √® la varianza della popolazione da cui il campione √® stato estratto. Tuttavia, poich√© i parametri della popolazione sono sconosciuti, l‚Äôapproccio frequentista utilizza la media \\(\\mu_0\\) ipotizzata dall‚Äôipotesi nulla \\(H_0\\) al posto della media sconosciuta della popolazione e stima il parametro sconosciuto \\(\\sigma\\) con la deviazione standard \\(s\\) del campione. In queste circostanze, la statistica \\(T\\) segue la distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† se il campione √® stato estratto da una popolazione normale.\nSvolgiamo i calcoli con Python.\n\nT = (np.mean(older) - 40) / (np.std(older, ddof=1) / np.sqrt(len(older)))\nT\n\n-2.481665888425312\n\n\nI gradi di libert√† sono \\(n-1\\).\n\ndf = len(older) - 1\nprint(df)\n\n9\n\n\nTroviamo il valore-p, ovvero l‚Äôarea sottesa alla distribuzione t di Student con 9 gradi di libert√† nei due intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\).\n\n# Set up the x-axis values for the t-distribution plot\nx = np.linspace(st.t.ppf(0.001, df), st.t.ppf(0.999, df), 1000)\n\n# Set up the y-axis values for the t-distribution plot\ny = st.t.pdf(x, df)\n\n# Create the t-distribution plot\nplt.plot(x, y, label=\"t-distribution\")\n\n# Shade the areas [-infinity, -T] and [T, +infinity]\nplt.fill_between(x[x &lt;= -T], y[x &lt;= -T], color=\"red\", alpha=0.2)\nplt.fill_between(x[x &gt;= T], y[x &gt;= T], color=\"red\", alpha=0.2)\n\n# Add vertical lines for T and -T\nplt.axvline(x=T, color=\"black\", linestyle=\"--\")\nplt.axvline(x=-T, color=\"black\", linestyle=\"--\")\n\n\n# Set the plot title and axis labels\nplt.title(f\"Distribuzione t di Student con {df} gradi di libert√†\")\nplt.xlabel(\"Valore t\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.show()\n\n\n\n\n\n\n\n\n\nst.t.cdf(T, df=len(older) - 1) * 2\n\n0.03489593108658913\n\n\n\n\nV.1.2 Intervallo di confidenza per una media\nCalcoliamo ora l‚Äôintervallo di confidenza al livello di fiducia del 95%. Come visto in precedenza, la procedura ttest ha calcolato l‚Äôintervallo di confidenza del 95% per la media della popolazione che va da 34.46 a 39.74. Questo intervallo pu√≤ essere interpretato come segue: se la stessa procedura venisse applicata molte volte, in circa il 95% dei casi l‚Äôintervallo ottenuto conterr√† il vero valore della media della popolazione.\nIniziamo a trovare il valore critico della distribuzione \\(t\\) di Student che lascia \\(\\alpha/2\\) in ciascuna coda.\n\nalpha = 0.05\ndf # 9\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.262157162854099\n\n\nL‚Äôintervallo di confidenza √® dato da\n\\[\n\\bar{X} \\pm t_{n-1} \\frac{s}{\\sqrt{n}}.\n\\]\nSvolgiamo i calcoli.\n\nci_lower = np.mean(older) - t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nci_upper = np.mean(older) + t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nprint(\"L'intervallo di confidenza al 95% per la media della popolazione √®: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la media della popolazione √®: [34.46, 39.74].",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "href": "chapters/chapter_7/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "title": "Appendice V ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "V.2 Confronto tra medie per campioni indipendenti",
    "text": "V.2 Confronto tra medie per campioni indipendenti\n\nV.2.1 Test \\(t\\) di Student per campioni indipendenti\nPer eseguire il test t di Student per due campioni indipendenti, iniziamo svolgendo i calcoli con la funzione ttest del modulo pingouin. L‚Äôipotesi nulla √® che la differenza tra le medie delle due popolazioni sia uguale a 0: \\(\\mu_1 - \\mu_2 = 0\\). La funzione ttest implementa la seguente formula:\n\\[\nT = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\n    \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}.\n}},\n\\]\n\nres = pg.ttest(younger, older, paired=False)\nprint(res)\n\n               T  dof alternative    p-val          CI95%  cohen-d   BF10  \\\nT-test  2.479867   18   two-sided  0.02326  [1.13, 13.67]  1.10903  2.849   \n\n           power  \nT-test  0.650317  \n\n\nSvolgiamo i calcoli passo-passo.\n\nt_num = np.mean(younger) - np.mean(older)\nt_denom = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nT = np.divide(t_num, t_denom)\nT\n\n2.479866520313643\n\n\nLa statistica \\(T\\) calcolata sopra si distribuisce con \\((n_1 - 1) + (n_2 - 1)\\), ovvero \\(n_1 + n_2 - 2\\), gradi di libert√†.\n\ndf = len(younger) + len(older) - 2\nprint(df)\n\n18\n\n\nIl valore-p √® uguale all‚Äôarea sottesa alla funzione t di Student con \\(n_1 + n_2 - 2\\) negli intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\). Nel caso presente abbiamo\n\n(1 - st.t.cdf(T, df=df)) * 2\n\n0.023260241301116924\n\n\n\n\nV.2.2 Intervallo di confidenza per la differenza tra due medie\nCalcoliamo ora l‚Äôintervallo di confidenza al livello di fiducia del 95% per la differenza tra le due medie. Iniziamo a calcolare il valore critico \\(t\\).\n\nalpha = 0.05\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.10092204024096\n\n\nTroviamo l‚Äôerrore standard della differenza tra le due medie.\n\nse_diff = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nse_diff\n\n2.9840315756446754\n\n\nTroviamo i limiti inferiore e superiore dell‚Äôintervallo di confidenza al 95%.\n\nci_lower = (np.mean(younger) - np.mean(older)) - (t_c * se_diff)\nci_upper = (np.mean(younger) - np.mean(older)) + (t_c * se_diff)\nprint(\"L'intervallo di confidenza al 95% per la differenza tra le due medie √®: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la differenza tra le due medie √®: [1.13, 13.67].\n\n\nSi noti che i gradi di libert√† sono \\(n_1+n_2-2\\) quando le varianze delle due popolazioni sono uguali. La formula di Welch-Satterthwaite viene usata per approssimare i gradi di libert√† quando le due varianze non sono uguali:\n\\[\n\\nu \\approx \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1 - 1} + \\frac{(s_2^2/n_2)^2}{n_2 - 1}}\n\\]\ndove \\(\\nu\\) rappresenta i gradi di libert√† approssimati, \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie delle due popolazioni, \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\nNel caso di varianze diverse, l‚Äôargomento correction=True produce una correzione dei gradi di liberta con l‚Äôapprossimazione di Welch-Satterthwaite e il corrispondente valore-p.\n\nres1 = pg.ttest(younger, older, paired=False, correction=True)\nprint(res1)\n\n               T        dof alternative     p-val          CI95%  cohen-d  \\\nT-test  2.479867  12.156852   two-sided  0.028738  [0.91, 13.89]  1.10903   \n\n         BF10     power  \nT-test  2.849  0.650317  \n\n\nConsideriamo ora la statistica \\(d\\) di Cohen. Il \\(d\\) di Cohen √® una misura di effetto comunemente utilizzata per valutare la differenza tra le medie di due gruppi indipendenti. La formula del \\(d\\) di Cohen per la differenza di due medie indipendenti √® la seguente:\n\\[\nd = \\frac{\\bar{X}_1 - \\bar{X}_2}{s},\n\\]\ndove \\(\\bar{X}_1\\) e \\(\\bar{X}_2\\) sono le medie dei due gruppi, e \\(s\\) √® la deviazione standard raggruppata (pooled standard deviation), definita come:\n\\[\ns = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi e \\(s_1\\) e \\(s_2\\) sono le deviazioni standard dei due gruppi. Il \\(d\\) di Cohen pu√≤ essere interpretato come la differenza tra le medie dei due gruppi in unit√† di deviazioni standard raggruppate. Un valore di \\(d\\) di Cohen di 0.2 √® considerato un effetto piccolo, un valore di 0.5 √® considerato un effetto medio e un valore di 0.8 o superiore √® considerato un effetto grande.\nLa funzione ttest ha trovato un valore di 1.10903. Svolgiamo i calcoli passo-passo.\nIniziamo a calcolare la deviazione standard raggruppata (pooled standard deviation).\n\ns_pool_num = np.sum(\n    [\n        (len(younger) - 1) * np.std(younger, ddof=1) ** 2,\n        (len(older) - 1) * np.std(older, ddof=1) ** 2,\n    ]\n)\ns_pool_denom = len(younger) + len(older) - 2\n\ns_pool = np.sqrt(np.divide(s_pool_num, s_pool_denom))\ns_pool\n\n6.672497450147301\n\n\nTroviamo ora il \\(d\\) di Cohen.\n\nd = (np.mean(younger) - np.mean(older)) / s_pool\nprint(d)\n\n1.1090300229094336\n\n\nInterpretazione. Il risultato dell‚Äôanalisi suggerisce che la differenza nella soddisfazione nella vita tra i due gruppi di et√†, misurata tramite l‚Äôindice \\(d\\) di Cohen, √® considerevole in termini di dimensione dell‚Äôeffetto.\n\n\nV.2.3 PyMC\nSvolgiamo ora lo stesso esercizio usando l‚Äôinferenza Bayesiana. Utilizzeremo distribuzioni a priori ampie per garantire un risultato simile all‚Äôanalisi frequentista. Inseriamo i dati in un DataFrame.\n\ny = np.concatenate((younger, older))\nx = np.concatenate((np.repeat(1, len(younger)), np.repeat(0, len(older))))\ndf = pd.DataFrame({\"y\": y, \"x\": x})\ndf.head()\n\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n0\n45\n1\n\n\n1\n38\n1\n\n\n2\n52\n1\n\n\n3\n48\n1\n\n\n4\n25\n1\n\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n15\n40\n0\n\n\n16\n42\n0\n\n\n17\n43\n0\n\n\n18\n32\n0\n\n\n19\n36\n0\n\n\n\n\n\n\n\n\n\nsns.scatterplot(x=df[\"x\"], y=df[\"y\"])\nsns.regplot(x=df[\"x\"], y=df[\"y\"], ci=False)\n\n\n\n\n\n\n\n\nCreaimo il modello statistico corrispondente ad un modello di regressione con un predittore dicotomico codificato con 0 per il primo gruppo e con 1 per il secondo gruppo. Iniziamo con l‚Äôanalisi predittiva a priori per determinare se le distribuzioni a priori sono adeguate.\n\nwith Model() as model_p:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=100)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata_p = pm.sample_prior_predictive(samples=50)\n\nSampling: [Y_obs, alpha, beta, sigma]\n\n\nUtilizzo lo script fornito dal sito di PyMC per generare casualmente un campione di rette di regressione dal modello utilizzando le distribuzioni a priori specificate.\n\n_, ax = plt.subplots()\n\nxp = xr.DataArray(np.linspace(0, 1, 11), dims=[\"plot_dim\"])\nprior = idata_p.prior\nyp = prior[\"alpha\"] + prior[\"beta\"] * xp\n\nax.plot(xp, yp.stack(sample=(\"chain\", \"draw\")), c=\"k\", alpha=0.4)\n\nax.set_ylabel(\"Soddisfazione della vita\")\nax.set_xlabel(\"Gruppo (codificato con 0 e 1)\")\nax.set_title(\"Distribuzione predittiva a priori\");\n\n\n\n\n\n\n\n\nSi noti che prior[\"alpha\"] √® un array che contiene 50 valori generati casualmente dal modello per il parametro alpha.\n\nprior[\"alpha\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'alpha' (chain: 1, draw: 50)&gt; Size: 400B\narray([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'alpha'chain: 1draw: 5027.91 -9.761 21.89 -14.57 68.4 ... -74.84 -16.03 -8.952 -12.09 0.6241array([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nLo stesso si pu√≤ dire per beta.\n\nprior[\"beta\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'beta' (chain: 1, draw: 50)&gt; Size: 400B\narray([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'beta'chain: 1draw: 5036.25 -7.924 78.12 -77.3 -2.919 ... -61.35 -116.8 -28.46 82.94 6.628array([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL‚Äôarray xp √® un vettore unidimensionale di 11 elementi compresi tra 0 e 1.\n\nxp.shape\n\n(11,)\n\n\n\nxp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (plot_dim: 11)&gt; Size: 88B\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])\nDimensions without coordinates: plot_dimxarray.DataArrayplot_dim: 110.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nSi noti che l‚Äôxarray yp ha coordinate chain e draw.\n\nyp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (chain: 1, draw: 50, plot_dim: 11)&gt; Size: 4kB\narray([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49\nDimensions without coordinates: plot_dimxarray.DataArraychain: 1draw: 50plot_dim: 1127.91 31.54 35.16 38.79 42.41 46.04 ... 4.601 5.264 5.927 6.59 7.252array([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL‚Äôistruzione yp = prior[\"alpha\"] + prior[\"beta\"] * xp genera i valori y per una serie di rette con coefficienti prior[\"alpha\"] e prior[\"beta\"]. Nel nostro caso, stiamo generando 50 rette perch√© abbiamo selezionato 50 valori di alpha e 50 valori di beta dalle distribuzioni a posteriori.\nNel contesto della modellazione bayesiana, il termine ‚Äúchain‚Äù si riferisce alla catena di campionamento di Markov Monte Carlo (MCMC). Durante il processo di campionamento, vengono eseguiti diversi passaggi successivi per ottenere campioni indipendenti dalla distribuzione a posteriori. Ogni passaggio viene chiamato ‚Äúdraw‚Äù o ‚Äúsample‚Äù. Pertanto, ‚Äúchain‚Äù rappresenta le catene di campionamento e ‚Äúdraw‚Äù rappresenta i singoli campioni all‚Äôinterno di ciascuna catena.\nL‚Äôistruzione yp.stack(sample=(\"chain\", \"draw\")) viene utilizzata per combinare le dimensioni ‚Äúchain‚Äù e ‚Äúdraw‚Äù al fine di ottenere un array multidimensionale che rappresenta i campioni di parametri estratti dalla distribuzione a posteriori. Ci√≤ facilita la visualizzazione e l‚Äôanalisi dei campioni.\nNotiamo che le pendenze delle rette di regressione generate casualmente dal modello, utilizzando le distribuzioni a priori specificate, presentano un intervallo pi√π ampio rispetto alle pendenze trovate nel campione osservato. Inoltre, il valore medio della variabile dipendente \\(y\\) nel campione √® incluso nella distribuzione a priori. Questo suggerisce che le scelte delle distribuzioni a priori siano appropriate per il modello.\nAvendo determinato le distribuzioni a priori, eseguiamo il campionamento MCMC.\n\nwith Model() as model:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=50)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, beta, sigma]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 16 seconds.\n\n\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(idata, combined=True)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nNel contesto di un modello di regressione in cui i gruppi ‚Äúolder‚Äù e ‚Äúyounger‚Äù sono codificati rispettivamente come 0 e 1, la media del gruppo ‚Äúolder‚Äù pu√≤ essere interpretata come il valore di riferimento o l‚Äôintercetta del modello. In termini matematici, la media del gruppo ‚Äúolder‚Äù corrisponde al coefficiente Œ± (alpha) del modello di regressione. La differenza tra le medie dei due gruppi √® invece uguale al coefficiente beta.\nPer verificare, troviamo la media del gruppo ‚Äúolder‚Äù (codificato con x = 0).\n\nnp.mean(older)\n\n37.1\n\n\nCalcoliamo la differenza tra le medie dei due campioni.\n\nnp.mean(younger) - np.mean(older)\n\n7.399999999999999\n\n\nEsaminiamo ora le stime a posteriori dei due coefficienti del modello e gli intervalli di credibilit√† al 95%.\n\naz.summary(idata, hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n37.067\n2.260\n32.572\n41.284\n0.048\n0.034\n2210.0\n2191.0\n1.0\n\n\nbeta\n7.406\n3.250\n1.230\n14.012\n0.070\n0.050\n2142.0\n2151.0\n1.0\n\n\nsigma\n7.178\n1.278\n4.916\n9.771\n0.028\n0.020\n2183.0\n2007.0\n1.0\n\n\n\n\n\n\n\n\nI coefficienti alpha e beta nel modello di regressione assumono i valori previsti. L‚Äôintervallo di credibilit√† per il coefficiente beta pu√≤ essere interpretato nel seguente modo: si pu√≤ affermare con una certezza soggettiva del 95% che il gruppo ‚Äúyounger‚Äù tende ad avere una soddisfazione della vita che √® almeno 1.1 punti superiore e non pi√π di 14.1 punti superiore rispetto al gruppo ‚Äúolder‚Äù.\nUsiamo ora la funzione dedicata di PyMC per campionare le distribuzioni a posteriori per generare il posterior predictive check. La funzione sample_posterior_predictive estrarr√† casualmente 40000 campioni dei parametri del modello dalla traccia MCMC. Successivamente, per ogni campione, verranno estratti 100 numeri casuali da una distribuzione normale specificata dai valori di mu e sigma in quel campione:\n\nwith model:\n    pm.sample_posterior_predictive(idata, extend_inferencedata=True, random_seed=rng)\n\nSampling: [Y_obs]\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôoggetto xarray ‚Äúposterior_predictive‚Äù in ‚Äúidata‚Äù conterr√† ora 40000 insiemi di dati (ciascuno contenente 100 valori), i quali sono stati generati utilizzando una diversa configurazione dei parametri dalle distribuzioni a posteriori di alpha e beta:\n\nidata.posterior_predictive\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 648kB\nDimensions:      (chain: 4, draw: 1000, Y_obs_dim_2: 20)\nCoordinates:\n  * chain        (chain) int64 32B 0 1 2 3\n  * draw         (draw) int64 8kB 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999\n  * Y_obs_dim_2  (Y_obs_dim_2) int64 160B 0 1 2 3 4 5 6 ... 13 14 15 16 17 18 19\nData variables:\n    Y_obs        (chain, draw, Y_obs_dim_2) float64 640kB 56.93 45.38 ... 29.89\nAttributes:\n    created_at:                 2024-05-07T04:19:22.885544+00:00\n    arviz_version:              0.18.0\n    inference_library:          pymc\n    inference_library_version:  5.14.0xarray.DatasetDimensions:chain: 4draw: 1000Y_obs_dim_2: 20Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Y_obs_dim_2(Y_obs_dim_2)int640 1 2 3 4 5 6 ... 14 15 16 17 18 19array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19])Data variables: (1)Y_obs(chain, draw, Y_obs_dim_2)float6456.93 45.38 44.72 ... 47.46 29.89array([[[56.93119105, 45.38112552, 44.71705033, ..., 36.6533742 ,\n         26.7945236 , 43.70073916],\n        [48.59795404, 49.14921972, 36.26414691, ..., 33.9800401 ,\n         43.64123915, 27.04789784],\n        [46.20305509, 37.31314497, 24.9156855 , ..., 34.63748569,\n         43.68189988, 25.00128306],\n        ...,\n        [41.88456655, 46.6706999 , 42.15297999, ..., 33.78602401,\n         45.84205574, 30.18639455],\n        [42.50078136, 51.06733118, 58.90315575, ..., 25.58896962,\n         23.22293853, 36.39028755],\n        [37.25135731, 33.72155053, 49.35109368, ..., 38.50069572,\n         43.37827239, 40.12896516]],\n\n       [[69.89704936, 44.89150638, 35.56737805, ..., 40.56827667,\n         24.40992124, 38.77930154],\n        [41.05292868, 34.71488032, 44.81629245, ..., 42.46278301,\n         44.84971018, 50.22855624],\n        [47.57661051, 44.39864842, 34.75311598, ..., 37.36811349,\n         52.05518433, 60.44519465],\n...\n        [46.36530415, 46.82141194, 43.99908701, ..., 33.36542914,\n         38.30912878, 24.24702688],\n        [58.0412549 , 40.54760807, 44.01622446, ..., 17.3388618 ,\n         29.39961152, 36.3022488 ],\n        [45.5066708 , 40.26978451, 45.96019551, ..., 27.45048685,\n         31.34425973, 27.56274796]],\n\n       [[49.10864016, 50.6347884 , 33.25334531, ..., 41.79996363,\n         56.15275593, 32.58161595],\n        [61.01484177, 45.19326455, 47.63829417, ..., 48.95528758,\n         33.60197361, 36.22097782],\n        [46.69327667, 52.18230406, 43.11523761, ..., 27.3596807 ,\n         41.88385917, 38.33724321],\n        ...,\n        [44.95070411, 36.79029201, 46.02741174, ..., 24.30896316,\n         21.17478346, 30.58681844],\n        [44.15401203, 43.59896216, 50.40780036, ..., 45.82617659,\n         29.65260042, 20.27135168],\n        [40.78029668, 41.79302778, 37.94651275, ..., 30.31091397,\n         47.45717734, 29.89154143]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Y_obs_dim_2PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64', name='Y_obs_dim_2'))Attributes: (4)created_at :2024-05-07T04:19:22.885544+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.14.0\n\n\nPossiamo utilizzare questi dati per verificare se il modello √® in grado di riprodurre le caratteristiche osservate nel campione. Per fare ci√≤, possiamo utilizzare la funzione plot_ppc fornita da ArviZ:\n\naz.plot_ppc(idata, num_pp_samples=200);\n\n\n\n\n\n\n\n\nOsserviamo che i dati generati dal modello seguono l‚Äôandamento dei dati osservati, indicando che il modello √® adeguato per i dati considerati. Inoltre, notiamo che il modello produce campioni di dati molto diversi tra loro. Questa variazione √® coerente considerando che il campione osservato era di dimensioni ridotte e quindi vi √® un‚Äôampia incertezza associata alle caratteristiche dei campioni futuri.\nEseguiamo ora l‚Äôanalisi di regressione sugli stessi dati usando il metodo dei minimi quadrati. A questo fine usiamo la funzione linear_regression del modulo pingouin.\n\npg.linear_regression(df['x'], df['y'])\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n37.1\n2.110029\n17.582697\n8.790692e-13\n0.25465\n0.213242\n32.666994\n41.533006\n\n\n1\nx\n7.4\n2.984032\n2.479867\n2.326024e-02\n0.25465\n0.213242\n1.130782\n13.669218\n\n\n\n\n\n\n\n\nLa stima dei coefficienti √® altamente coerente con quella ottenuta utilizzando PyMC. L‚Äôintervallo di fiducia per il coefficiente b, che rappresenta la differenza tra le medie dei due gruppi, presenta una somiglianza notevole con l‚Äôintervallo di credibilit√† bayesiano.\nTuttavia, √® importante sottolineare che, anche se in questo caso specifico l‚Äôapproccio frequentista produce risultati simili all‚Äôapproccio bayesiano, non √® possibile generalizzare questa conclusione a tutti i casi. Le differenze tra i due approcci possono emergere in scenari diversi e richiedono un‚Äôanalisi caso per caso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a60_ttest_exercises.html#project-star",
    "href": "chapters/chapter_7/a60_ttest_exercises.html#project-star",
    "title": "Appendice V ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "V.3 Project Star",
    "text": "V.3 Project Star\nSvolgiamo ora un altro esercizio usando dei dati reali relativi al progetto Star. Il Project STAR (Student-Teacher Achievement Ratio) √® stato un grande esperimento educativo condotto negli Stati Uniti tra il 1985 e il 1990. L‚Äôobiettivo era quello di esaminare l‚Äôeffetto della dimensione delle classi sulla performance degli studenti. In particolare, gli studenti venivano assegnati in modo casuale a classi di piccole dimensioni (13-17 studenti) o grandi dimensioni (22-25 studenti).\nIl progetto coinvolse pi√π di 6.000 studenti e 1.000 insegnanti in 79 scuole elementari in Tennessee. I risultati dello studio indicarono che gli studenti assegnati a classi pi√π piccole hanno ottenuto risultati migliori in termini di performance accademica, partecipazione in classe, comportamento e assenze rispetto agli studenti assegnati a classi pi√π grandi.\nIn questo capitolo, analizziamo una parte dei dati del Project STAR. Come variabili abbiamo i punteggi ottenuti dagli studenti ai test standardizzati di lettura e matematica alla fine del terzo anno, insieme alla percentuale di studenti che hanno completato gli studi superiori.\nL‚Äôobiettivo dell‚Äôesercizio √® calcolare la media dell‚Äôeffetto causale della frequenza delle classi piccole rispetto alle classi di dimensioni standard sui punteggi dei test di lettura di terza elementare per tutta la popolazione target di studenti.\nLeggiamo i dati dal file STAR.csv.\n\ndf_star = pd.read_csv(\"../data/STAR.csv\")\ndf_star.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nLe medie dei due gruppi sono le seguenti.\n\ngroup_means = df_star.groupby('classtype')[\"reading\"].mean()\nprint(group_means)\n\nclasstype\nregular    625.492017\nsmall      632.702564\nName: reading, dtype: float64\n\n\nGeneriamo un violin plot per i punteggi nel test di lettura di terza elementare per i due gruppi.\n\nsns.violinplot(x=\"classtype\", y=\"reading\", data=df_star)\n\n\n\n\n\n\n\n\nL‚Äôipotesi nulla √® che i dati provengono da due popolazioni aventi la stessa media: \\(H_0: \\mu_1 - \\mu_2 = 0\\). Useremo un test bilaterale, ovvero rifiuteremo \\(H_0\\) sia quando il valore \\(T\\) cade nella regione di rifiuto perch√© \\(\\mu_1 &gt; \\mu_2 = 0\\), sia quando cade nella regione di rifiuto perch√© \\(\\mu_1 &lt; \\mu_2 = 0\\).\nPer semplicit√†, credo due DataFrame, uno per ciascun gruppo.\n\ndf_small = df_star[df_star['classtype'] == 'small']\ndf_regular = df_star[df_star['classtype'] == 'regular']\n\nSvolgo il test \\(t\\) di Student per due gruppi indipendenti con la funzione ttest.\n\nres = pg.ttest(df_small[\"reading\"], df_regular[\"reading\"], paired=False)\nprint(res)\n\n               T          dof alternative    p-val          CI95%   cohen-d  \\\nT-test  3.495654  1220.993525   two-sided  0.00049  [3.16, 11.26]  0.197183   \n\n          BF10     power  \nT-test  25.771  0.938789  \n\n\nInterpretazione. Avendo ottenuto un valore-p minore di \\(\\alpha\\), si conclude rifiutando l‚Äôipotesi nulla di uguaglianza delle due medie. Si presti per√≤ attenzione al \\(d\\) di Cohen: \\(d\\) = 0.20. Ci√≤ significa che la dimensione dell‚Äôeffetto √® piccola.\nSvolgiamo ora i calcoli passo-passo. Calcoliamo la differenza tra le medie dei due gruppi.\n\nmean_diff = np.mean(df_small[\"reading\"]) - np.mean(df_regular[\"reading\"])\nmean_diff\n\n7.210546686018347\n\n\nTroviamo i gradi di libert√† per la differenza tra due medie indipendenti.\n\nnum_rows = df_star.shape[0]\nnum_rows\n\n1274\n\n\n\ndof = 2 * num_rows - 2\ndof\n\n2546\n\n\nTroviamo il valore critico per un test bilaterale.\n\nt_c = st.t.ppf(0.975, dof)\nt_c\n\n1.9608961841574426\n\n\nSe non assumiamo che le due varianze siano uguali, allora l‚Äôerrore standard per la differenza tra le medie di due gruppi indipendenti √®\n\\[\n\\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\nse_diff = np.sqrt(\n    np.var(df_small[\"reading\"], ddof=1) / len(df_small[\"reading\"]) +\n    np.var(df_regular[\"reading\"], ddof=1) / len(df_regular[\"reading\"])\n    )\nse_diff\n\n2.0627173626882493\n\n\nTroviamo il valore della statistica \\(T\\).\n\nT = mean_diff / se_diff\nprint(T)\n\n3.4956542357413216\n\n\nTroviamo il valore-p.\n\n(1 - st.t.cdf(T, df=dof)) * 2\n\n0.0004809856733483109\n\n\nCalcoliamo ora l‚Äôintervallo di fiducia al 95% per la differenza tra le medie dei due gruppi:\n\\[\n(\\bar{X}_1 - \\bar{X}_2) \\pm t_{n_1 + n_2 - 2} \\cdot \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\npm = np.array([-1, +1])\nci = mean_diff + pm * (t_c * se_diff)\nprint(ci)\n\n[ 3.16577208 11.25532129]\n\n\nInterpretazione. Dai risultati ottenuti, si pu√≤ concludere che l‚Äôeffetto causale medio di frequentare una classe piccola sui punteggi dei test di lettura di terza elementare, per tutti gli studenti della popolazione target, √® probabilmente un aumento compreso tra 3.17 e 11.25 punti.\n\nV.3.1 Margine d‚Äôerrore\nEsiste un modo alternativo di esprimere gli intervalli di confidenza, che √® popolare nel mondo dei sondaggi. Coinvolge l‚Äôuso di ci√≤ che √® noto come ‚Äúmargine di errore‚Äù, definito come la met√† della larghezza dell‚Äôintervallo di confidenza. Utilizzando questo termine, possiamo esprimere l‚Äôintervallo di confidenza come:\n\\[\n\\text{stimatore} \\pm \\text{margine di errore.}\n\\]\nPer i dati presenti, possiamo dire che frequentare una classe piccola produce un incremento atteso di 7.21 ¬± 4.04 punti sui punteggi dei test di lettura di terza elementare. L‚Äôampiezza dell‚Äôintervallo di confidenza √® qui di 8.08 punti, quindi il margine di errore √® di 4.04 punti.\nSi deve notare la differenza concettuale tra il risultato espresso in termini di intervallo di confidenza o margine d‚Äôerrore, che rappresenta una differenza assoluta tra le medie dei due gruppi, e l‚Äôindice \\(d\\) di Cohen, il quale rappresenta una differenza relativa tra le medie dei due gruppi, ponderata in base all‚Äôincertezza della stima. In altre parole, mentre il margine d‚Äôerrore esprime la precisione della stima assoluta della differenza tra le medie, l‚Äôindice \\(d\\) di Cohen esprime la dimensione dell‚Äôeffetto relativo tra i due gruppi, tenendo conto della variazione naturale dei dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "href": "chapters/chapter_7/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "title": "Appendice V ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "V.4 Inferenza su una proporzione",
    "text": "V.4 Inferenza su una proporzione\nOccupiamoci ora dell‚Äôinferenza sulla proporzione di una popolazione. La teoria delle probabilit√† ci dice che il valore atteso della proporzione campionaria \\(\\hat{p}\\) √® la proporzione \\(p\\) della popolazione e che la deviazione standard della proporzione campionaria √® la deviazione standard della variabile casuale binomiale \\(Y\\) divisa per \\(n\\):\n\\[\\begin{align}\n\\mu_{\\hat p}&=\\frac{\\mu_Y}{n} = p \\\\\n\\sigma_{\\hat p} &=\\frac{\\sigma_Y}{n} = \\frac{\\sqrt{n \\cdot p \\cdot (1-p)}}{n} = \\sqrt{\\frac{p \\cdot (1-p)}{n}}\n\\end{align}\\]\nQuesto punto pu√≤ essere chiarito da una simulazione. Supponiamo di esaminare 10000 campioni casuali di ampiezza 10 estratti da una popolazione nella quale la probabilit√† di ‚Äúsuccesso‚Äù √® 0.6.\n\np = 0.6\nn = 10\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\nI primi 5 campioni sono i seguenti.\n\nY[0:5]\n\n[array([0, 0, 1, 1, 0, 1, 0, 1, 0, 1]),\n array([0, 0, 0, 1, 1, 1, 1, 0, 0, 1]),\n array([0, 1, 1, 1, 0, 1, 1, 0, 0, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0])]\n\n\n\n_ = plt.hist(np.sum(Y, axis=1), density=True)\n\n\n\n\n\n\n\n\nL‚Äôistogramma precedente √® un‚Äôapprossimazione empirica della distribuzione delle proporzioni campionarie di ampiezza 10 estratte da una popolazione con probabilit√† di successo uguale a 0.6.\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.5986799999999999\nValore teorico atteso: 0.6\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.154939528849161\nDeviazione standard teorica: 0.15491933384829668\n\n\nMan mano che aumenta il numero di campioni estratti dalla popolazione, i due valori diventano sempre pi√π simili.\nPer quel che riguarda la forma della distribuzione, come conseguenza del TLC possiamo dire che la distribuzione delle proporzioni campionarie tende sempre pi√π ad assumere una forma normale all‚Äôaumentare della dimensione dei campioni.\nPer mettere alla prova il TLC, consideriamo un caso estremo, ovvero una popolazione nella quale la probabilit√† di successo √® 0.03. Supponiamo che la numerosit√† campionaria sia uguale a 400.\n\np = 0.03\nn = 400\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.029917250000000003\nValore teorico atteso: 0.03\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.008587201373992577\nDeviazione standard teorica: 0.00852936105461599\n\n\n\nnp.mean(Y, axis=1)\n\narray([0.03  , 0.04  , 0.0275, ..., 0.045 , 0.0325, 0.035 ])\n\n\n\ny = np.mean(Y, axis=1)\nsns.distplot(y, bins=10, hist=True, kde=False, norm_hist=True, hist_kws={'edgecolor':'black'})\nx = np.linspace(0, 0.1, 1000)\ny = st.norm.pdf(x, np.mean(y), np.std(y))  # Normal density values\nplt.plot(x, y, 'r-', label='Normal Density')\n\n\n\n\n\n\n\n\n\nV.4.1 Brexit\nPrendiamo in considerazione un ulteriore relativo all‚Äôindagine BES condotta prima del referendum sulla Brexit del 2016 al fine di valutare l‚Äôopinione pubblica dell‚Äôintera popolazione del Regno Unito. Importiamo i dati.\n\nbes = pd.read_csv(\"../data/BES.csv\")\nbes.head()\n\n\n\n\n\n\n\n\n\nvote\nleave\neducation\nage\n\n\n\n\n0\nleave\n1.0\n3.0\n60\n\n\n1\nleave\n1.0\nNaN\n56\n\n\n2\nstay\n0.0\n5.0\n73\n\n\n3\nleave\n1.0\n4.0\n64\n\n\n4\ndon't know\nNaN\n2.0\n68\n\n\n\n\n\n\n\n\n\nbes.shape\n\n(30895, 4)\n\n\nEliminiamo le righe del DataFrame che contengono dati mancanti.\n\nbes_cleaned = bes.dropna()\nbes_cleaned.shape\n\n(25097, 4)\n\n\nCalcoliamo la proporzione di risposte ‚Äúleave‚Äù.\n\nbes_cleaned[\"leave\"].mean()\n\n0.47188907040682154\n\n\nL‚Äôoutput del sondaggio BES indica che il 47.19% dei partecipanti era a favore della Brexit. Tuttavia, non possiamo inferire da questo risultato che circa il 47% di tutti gli elettori del Regno Unito era a favore della Brexit, poich√© si tratta di un risultato a livello di campione. Per generalizzare a livello di popolazione, dobbiamo considerare la variabilit√† campionaria che introduce rumore nei nostri risultati.\nAbbiamo visto sopra che la distribuzione campionaria di una proporzione presenta le seguenti caratteristiche:\n\nLa media della distribuzione campionaria di una proporzione √® uguale alla proporzione della popolazione. Ci√≤ significa che in media, la proporzione dei valori del campione √® uguale alla proporzione della popolazione.\nLa deviazione standard della distribuzione campionaria di una proporzione √® calcolata come \\(\\sqrt{\\pi (1-\\pi) / n}\\), dove \\(\\pi\\) rappresenta la proporzione della popolazione e \\(n\\) √® la dimensione del campione. La deviazione standard rappresenta la dispersione dei valori del campione intorno alla proporzione della popolazione. Possiamo stimare l‚Äôerrore standard sostituendo \\(\\pi\\) con \\(p\\), la proporzione campionaria.\nLa distribuzione campionaria di una proporzione tende alla normale se la dimensione del campione √® grande.\n\nPer fare inferenze sul parametro \\(\\pi\\) della popolazione (la proporzione di elettori del Regno Unito a favore della Brexit nel 2016), possiamo costruire un intervallo di confidenza al 95% per la proporzione nella popolazione.\nPer iniziare il calcolo dell‚Äôintervallo di confidenza, dobbiamo prima determinare la dimensione del campione.\n\nn = bes_cleaned.shape[0]\nn\n\n25097\n\n\nPossiamo stimare l‚Äôerrore standard di una proporzione con la formula $ SE = . $\n\np = bes_cleaned[\"leave\"].mean()\nse = np.sqrt(p * (1 - p) / n)\nprint(se)\n\n0.0031511685382488307\n\n\nTroviamo il limite inferiore e il limite superiore dell‚Äôintervallo di fiducia al 95%.\n\npm = np.array([-1, +1])\nci = np.mean(bes_cleaned[\"leave\"]) + pm * st.norm.ppf(0.975) * se\nprint(f\"L'intervallo di fiducia al 95% √® [{ci[0]:.4f}, {ci[1]:.4f}].\")\n\nL'intervallo di fiducia al 95% √® [0.4657, 0.4781].\n\n\nSecondo l‚Äôapproccio frequentista, √® possibile affermare che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era compresa con una probabilit√† del 95% tra il 46.57% e il 47.81%. Questo intervallo di confidenza √® stato ottenuto mediante una procedura di stima con un livello di confidenza del 95%, il quale indica la probabilit√† che l‚Äôintervallo contenga il vero valore del parametro.\nInoltre, il margine di errore, che rappresenta la met√† della larghezza dell‚Äôintervallo di confidenza, √® di 0.62 punti percentuali. Ci√≤ significa che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era probabilmente del 47.19%, con un margine di errore di 0.62 punti percentuali.\nSi noti che il margine di errore dipende dalla dimensione del campione. Nel caso del sondaggio BES, che ha una grande dimensione del campione di 25097 osservazioni, il margine di errore √® relativamente piccolo. Tuttavia, per la maggior parte dei sondaggi che hanno una dimensione del campione molto pi√π piccola, di circa 1000 osservazioni, il margine di errore sar√† molto pi√π grande. In generale, all‚Äôaumentare della dimensione del campione, la larghezza dell‚Äôintervallo di confidenza diminuisce, e viceversa.\n\n\nV.4.2 Supporto per la Brexit ed et√†\nCon i dati del sondaggio BES facciamo un altro esempio relativo al confronto tra due medie indipendenti. Nello specifico, esamineremo la differenza d‚Äôet√† tra gli elettori che hanno espresso supporto per la Brexit e quelli che invece hanno sostenuto la posizione ‚Äústay‚Äù.\n\nsns.violinplot(x=\"leave\", y=\"age\", data=bes)\n\n\n\n\n\n\n\n\nIl violin plot rivela che l‚Äôet√† media dei sostenitory della posizione ‚Äúleave‚Äù √® pi√π alta dell‚Äôet√† media del gruppo ‚Äústay‚Äù. Si noti per√≤ che le due distribuzioni non sembrano gaussiane.\nPer verificare l‚Äôipotesi di gaussianit√† dei dati, usiamo un QQ-plot (Quantile-Quantile plot). Un QQ-plot √® uno strumento grafico utilizzato per verificare se una distribuzione di dati segue o meno una distribuzione teorica, come ad esempio una distribuzione normale. In pratica, un QQ-plot confronta i quantili di una distribuzione di dati con quelli di una distribuzione teorica, disegnando un grafico dei quantili teorici lungo l‚Äôasse x e dei quantili dei dati lungo l‚Äôasse y. Se i dati seguono la distribuzione teorica, allora i punti nel QQ-plot si distribuiranno lungo una linea retta. Se invece ci sono deviazioni dalla distribuzione teorica, i punti nel QQ-plot si discosteranno dalla retta e si potr√† individuare in che punto si verificano le maggiori deviazioni.\n\nax = pg.qqplot(bes[\"age\"], dist=\"norm\")\n\n\n\n\n\n\n\n\nSi pu√≤ osservare dal QQ-plot che i valori di et√† estremi della distribuzione differiscono marcatamente dalle corrispondenti aspettative teoriche. Solo per fare un esecizio, proseguiamo comunque con l‚Äôanalisi dei dati e applichiamo il test t di Student ai due gruppi d‚Äôet√†. Si noti per√≤ che, per dati non normali, una tale procedura di analisi statistica √® inappropriata.\nPossiamo anche visualizzare i dati dei due gruppi tramite un KDE plot (da notare che questa rappresentazione √® gi√† inclusa nel violin plot precedente).\n\nsns.kdeplot(data=bes, x=\"age\", hue=\"leave\")\n\n\n\n\n\n\n\n\nPer agevolare il test t di Student, dividiamo il DataFrame originale in due DataFrame distinti.\n\nleave_df = bes[bes[\"leave\"] == 1]\nstay_df = bes[bes[\"leave\"] == 0]\n\nL‚Äôipotesi nulla che viene sottoposta a verifica con il test t di Student √® l‚Äôuguaglianza delle medie dei valori dell‚Äôet√† nelle due popolazioni da cui i campioni sono stati estratti: \\(H_0: \\mu_{\\text{leave}} = \\mu_{\\text{stay}}\\). Il test t di Student pu√≤ essere facilmente eseguito utilizzando la funzione ttest del pacchetto pingouin.\n\nres = pg.ttest(leave_df[\"age\"], stay_df[\"age\"], paired=False)\nprint(res)\n\n                T           dof alternative  p-val         CI95%   cohen-d  \\\nT-test  41.588603  27738.840259   two-sided    0.0  [7.63, 8.38]  0.495062   \n\n       BF10  power  \nT-test  inf    1.0  \n\n\nSvolgiamo ora i calcoli applicando la formula del test t di Student. La statistica \\(t\\) di Student per la differenza tra le medie di due campioni indipendenti √®\n\\[T = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}},\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}2\\) sono le medie dei due campioni, \\(s^2_1\\) e \\(s^2_2\\) sono le varianze dei due campioni e \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\n\nn_l = leave_df.shape[0]\nn_l\n\n13692\n\n\n\nn_s = stay_df.shape[0]\nn_s\n\n14352\n\n\n\nn_l + n_s - 2\n\n28042\n\n\nCalcoliamo l‚Äôerrore standard della differenza delle medie di due campioni indipendenti.\n\nse = np.sqrt(\n    (np.var(leave_df[\"age\"], ddof=1) / n_l) + \n    (np.var(stay_df[\"age\"], ddof=1) / n_s)\n) \nse\n\n0.19250126816432642\n\n\nTroviamo la statistica t di Student.\n\nT = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) / se\n\nTroviamo il valore-p con la funzione t.sf che calcola l‚Äôarea sottesa alla funzione \\(t\\) nella coda di destra. √à importante notare che le funzioni Python che abbiamo utilizzato in precedenza calcolano i gradi di libert√† in modo diverso rispetto alla formula \\(n_1+n_2-2\\). Infatti, il numero di gradi di libert√† calcolato come \\(n_1+n_2-2\\) √® appropriato solo quando le varianze delle due popolazioni sono uguali. Se le varianze sono diverse, √® necessario introdurre un fattore di correzione, che viene calcolato mediante software. Tuttavia, per questo esercizio, procederemo con \\(n_1+n_2-2\\), poich√© per un valore \\(t\\) cos√¨ estremo non fa alcuna differenza.\n\n2 * st.t.sf(T, df = n_l + n_s - 2)\n\n0.0\n\n\nPoniamoci ora l‚Äôobiettivo di trovare l‚Äôintervallo di fiducia per la differenza tra le due medie. Iniziamo a trovare il valore critico della distribuzione \\(t\\) corrispondente al livello di significativit√† scelto.\n\nt_c = st.t.ppf(0.975, df=n_l + n_s - 2)\nt_c\n\n1.9600485852064147\n\n\nPossiamo ora trovare l‚Äôintervallo di fiducia.\n\npm = np.array([-1, +1])\nci = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) + pm * t_c * se\nprint(f\"L'intervallo di fiducia al 95% √® [{ci[0]:.2f}, {ci[1]:.2f}].\")\n\nL'intervallo di fiducia al 95% √® [7.63, 8.38].\n\n\nIn conclusione, l‚Äôintervallo di confidenza al 95% per la differenza di et√† media tra i sostenitori della Brexit e coloro che sostenevano la posizione ‚Äòstay‚Äô √® [7.63, 8.38]. Ci√≤ significa che, utilizzando una procedura di stima corretta nel 95% dei casi, ci si aspetta che l‚Äôet√† media dei sostenitori della Brexit sia 8 anni superiore a quella dei sostenitori della posizione ‚Äòstay‚Äô, con un‚Äôincertezza di +/- 0.375 anni.\n\nnp.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])\n\n8.00585876624487\n\n\n\n(8.38 - 7.63) / 2\n\n0.37500000000000044",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a60_ttest_exercises.html#watermark",
    "href": "chapters/chapter_7/a60_ttest_exercises.html#watermark",
    "title": "Appendice V ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "V.5 Watermark",
    "text": "V.5 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv \n\nLast updated: Tue May 07 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nxarray    : 2024.3.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\npingouin  : 0.5.4\nscipy     : 1.13.0\npandas    : 2.2.2\narviz     : 0.18.0",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a70_predict_counts.html",
    "href": "chapters/chapter_7/a70_predict_counts.html",
    "title": "Appendice W ‚Äî La predizione delle frequenze",
    "section": "",
    "text": "W.1 La ricerca sul trauma\nPer fare un esempio di questo approccio, in questo capitolo faremo riferimento alla ricerca sul trauma. In questo campo di ricerca, come in altri, il risultato di interesse pu√≤ essere rappresentato dalla frequenza del numero di episodi che si verificano in un dato periodo di tempo. Nel caso della ricerca sulla violenza domestica, ad esempio, potremmo esaminare il tasso di atti aggressivi durante l‚Äôintervallo tra un momento temporale di baseline e un‚Äôintervista di follow-up. Altri esempi di risultati esprimibili in termini di frequenze nalla ricerca post-traumatica includono la frequenza dell‚Äôabuso di sostanze durante un periodo di osservazione o il numero di interventi della polizia durante un dato periodo.\nNell‚Äôesempio seguente esamineremo l‚Äôuso della predizione bayesiana per predire il numero di aggressioni nei confronti del partner nelle relazioni di coppia. I dati presentati sono tratti da uno studio che esamina la frequenza di episodi di aggressione messi in atto da pazienti di sesso maschile che avevano recentemente iniziato un programma di trattamento dell‚Äôalcol nei confronti del loro partner di sesso femminile.\nLa frequenza degli episodi di violenza, cos√¨ come altri fenomeni quantificabili in termini di frequenze assolute, pu√≤ essere modellata da un processo di Poisson, che si basa sul presupposto che gli eventi siano casuali e abbiano la stessa probabilit√† di verificarsi in qualsiasi momento. Naturalmente, questa ipotesi non √® sempre valida, ma spesso √® sufficiente per la modellazione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a70_predict_counts.html#la-distribuzione-a-priori",
    "href": "chapters/chapter_7/a70_predict_counts.html#la-distribuzione-a-priori",
    "title": "Appendice W ‚Äî La predizione delle frequenze",
    "section": "W.2 La distribuzione a priori",
    "text": "W.2 La distribuzione a priori\nIn una ricerca sui pazienti che avevano recentemente iniziato un programma di trattamento per l‚Äôabuso o la dipendenza da alcol, {cite:t}gagnon2008poisson hanno trovato che, in un periodo di 6 mesi, il numero di assalti fisici da parte dei pazienti di genere maschile nei confronti del loro partner femminile √® uguale, in media, a 11.46 (\\(SD\\) = 25.79; \\(n\\) = 114).\nPer questi dati, √® dunque sensato pensare che la distribuzione del numero di episodi di aggressione fisica pu√≤ essere rappresentata dalla distribuzione esponenziale.\nDal punto di vista statistico, ricordiamo che la distribuzione esponenziale modella il numero di eventi che si verificano in un intervallo di tempo quando questi eventi si verificano raramente e indipendentemente l‚Äôuno dall‚Äôaltro.\nLa funzione di densit√† di probabilit√† della distribuzione esponenziale √® data da:\n\\[\nf(x) = Œªe^{(-Œªx)}\n\\]\ndove Œª √® il parametro della distribuzione e rappresenta il tasso medio di occorrenza degli eventi. La media e la varianza della distribuzione esponenziale sono entrambe uguali a 1/Œª.\nPoniamoci dunque il problema di rappresentare le nostre credenze a priori relative al numero di episodi di aggressione fisica mediante una distribuzione esponenziale.\nDalla ricerca di {cite:t}gagnon2008poisson sappiamo che, in un periodo di 6 mesi, il numero di assalti fisici nei confronti del partner femminile, in questa popolazione, √® uguale a 11.46.\nConsidereremo una distribuzione esponenziale per rappresentare le nostre credenze a priori circa la frequenza media \\(\\mu\\) degli episodi di aggressione nei confronti del partner per questa popolazione, in un periodo di 6 mesi. In Python, scipy.stats.expon √® un modulo che fornisce funzioni per lavorare con la distribuzione esponenziale. In particolare, la funzione pdf (probability density function) calcola la funzione di densit√† di probabilit√† della distribuzione esponenziale per un dato valore di x.\nLa sintassi per utilizzare questa funzione √® la seguente:\nscipy.stats.expon.pdf(x, loc=0, scale=1)\ndove x √® il valore per il quale si vuole calcolare la funzione di densit√† di probabilit√†. Il parametro loc(opzionale) e scale specificano rispettivamente la posizione e la scala della distribuzione. La posizione (loc) di solito √® impostata a 0, mentre la scala (scale) √® l‚Äôinverso del parametro Œª della distribuzione esponenziale. In altre parole, la scala √® uguale alla media della distribuzione esponenziale.\nPer il caso presente, dunque, se vogliamo che la distribuzione esponenziale abbia una media di 11.46, procediamo come indicato sotto\n\nx = np.linspace (0, 50, 100) \ny = st.expon.pdf(x, 0, 11.46)\nplt.plot(x, y);\n\n\n\n\n\n\n\n\nPer verificare che abbiamo implementato correttamente la funzione esponenziale con il parametro voluto, estraiamo un grande numero di realizzazioni della v.c. e calcoliamo la media.\n\nr = st.expon.rvs(0, 11.46, size=100000)\nr.mean()\n\n11.438957034038369",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a70_predict_counts.html#inferenza-bayesiana",
    "href": "chapters/chapter_7/a70_predict_counts.html#inferenza-bayesiana",
    "title": "Appendice W ‚Äî La predizione delle frequenze",
    "section": "W.3 Inferenza bayesiana",
    "text": "W.3 Inferenza bayesiana\nUna volta capito come descrivere le nostre credenze a priori, poniamoci il problema di usare PyMC per l‚Äôinferenza Bayesiana.\nConsideriamo un singlo individuo di genere maschile appartenente a questa popolazione. Se, in media, in 6 mesi ci aspettiamo un numero di episodi di violenza pari a 11.46, possiamo descrivere il numero di episodi di violenza per un singolo individuo con la seguente distribuzione esponenziale. Si noti che, in questo caso, la funzione pm.Exponential √® parametrizzata usando il parametro l che √® uguale a \\(\\lambda = 1/ \\mu\\).\n\nl = 1/11.46\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    idata = pm.sample_prior_predictive(samples=10000, random_seed=rng)\n\nSampling: [mu]\n\n\nEsaminiamo 10000 campioni casuali estratti dalla distribuzione a priori. Il risultato √® simile alla distribuzione di densit√† teorica rappresentata nel grafico precedente.\n\n_ = az.plot_posterior(idata.prior.mu);\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, stiamo usando una distribuzione a priori informativa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a70_predict_counts.html#la-verosimiglianza",
    "href": "chapters/chapter_7/a70_predict_counts.html#la-verosimiglianza",
    "title": "Appendice W ‚Äî La predizione delle frequenze",
    "section": "W.4 La verosimiglianza",
    "text": "W.4 La verosimiglianza\nAdesso inseriamo nel modello PyMC la verosimiglianza.\nIn questo caso, usiamo quale modello generativo dei dati una distribuzione di Poisson.\nLe distribuzioni di Poisson sono usate per modellare il numero di eventi rari che si verificano in un intervallo di tempo fisso. Ad esempio, il numero di episodi di comportamento inappropriato per settimana in individui con disturbi alimentari, nascite in un giorno o incidenti in una settimana.\nLa verosimiglianza di Poisson √® simile a quella binomiale, ma non ha un limite superiore al numero di successi.\nPer esempio, consideriamo un paziente chiamato Mario. Usando gli item della sottoscala relativa agli episodi di violenza fisica della Conflict Tactics Scales-2, troviamo che Mario ha avuto 8 episodi violenti nei confronti del partner negli ultimi 6 mesi.\nInseriamo questa informazione nel modello bayesiano usando 8 come dato che specifica una verosimiglianza di Poisson con parametro sconosciuto mu, a cui abbiamo attribuito una distribuzione a priori esponenziale ed eseguiamo il campionamento.\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    episodes = pm.Poisson(\"episodes\", mu, observed=8)\n    idata2 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 11 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "href": "chapters/chapter_7/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "title": "Appendice W ‚Äî La predizione delle frequenze",
    "section": "W.5 La distribuzione a posteriori",
    "text": "W.5 La distribuzione a posteriori\nEstraiamo dall‚Äôoggetto idata2 i campioni della distribuzione a posteriori del parametro mu (media del numero di episodi di violenza negli ultimi 6 mesi).\n\nsample_posterior = idata2.posterior['mu']\n\nGeneriamo un grafico della distribuzione a posteriori del parametro mu.\n\naz.plot_posterior(sample_posterior)\n\n\n\n\n\n\n\n\nPossiamo dunque concludere, con un livello di certezza soggettiva del 94%, che per Mario, il numero di episodi di violenza nei confronti del partner varier√† da un minimo di 3.5 ad un massimo di 13, in un periodo di 6 mesi, con una media di 8.2.\nSupponiamo ora di volere confrontare due individui, Mario e Paolo. Di Mario abbiamo osservato 8 episodi di violenza in 6 mesi; di Paolo abbiamo osservato 12 episodi di violenza negli ultimi 6 mesi. Possiamo dire che Paolo √® pi√π violento di Mario? Oppure dobbiamo pensare che la differenza tra i due sia solo una fluttuazione casuale?\nScriviamo il modello bayesiano nel modo seguente, usando sempre la distribuzione a priori che abbiamo definito in precedenza.\n\nwith pm.Model() as model3:\n    mu_A = pm.Exponential(\"mu_A\", l)\n    mu_B = pm.Exponential(\"mu_B\", l)\n    episodes_A = pm.Poisson(\"episodes_A\", mu_A, observed=[8])\n    episodes_B = pm.Poisson(\"episodes_B\", mu_B, observed=[12])\n    idata3 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu_A, mu_B]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 36 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nEsaminiamo le distribuzioni a posteriori dei parametri mu_A e mu_B che rappresentano la media del numero di episodi di violenza per i due individui.\n\nwith model3:\n    az.plot_trace(idata3, kind=\"rank_bars\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nEstraiamo le distribuzioni a posteriori dei due parametri da idata3.\n\nmu_A = idata3.posterior['mu_A']\nmu_B = idata3.posterior['mu_B']\nmu_B.mean(), mu_A.mean()\n\n(&lt;xarray.DataArray 'mu_B' ()&gt;\n array(11.98949309),\n &lt;xarray.DataArray 'mu_A' ()&gt;\n array(8.26997179))\n\n\nRappresentiamo graficamente le due distribuzioni a posteriori.\n\naz.plot_posterior(mu_A)\naz.plot_posterior(mu_B);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVogliamo eseguire un test di ipotesi bayesiano per determinare la probabilit√† che la media del numero di episodi di violenza di Mario sia maggiore di quella di Paolo. Per fare ci√≤, calcoliamo quante volte mu_B √® maggiore di mu_A nelle due distribuzioni a posteriori.\n\n(mu_B &gt; mu_A).mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0.808)xarray.DataArray0.808array(0.808)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nPossiamo dunque dire che, se confrontiamo i valori dei parametri delle due distribuzioni a posteriori, nell‚Äô81% di casi risulta che Paolo √® pi√π violento di Mario.\nIl grafico seguente mostra le stime degli intervalli di credibilit√† del 94% per ciascuna delle 4 catene, pe i due parametri.\n\n_ = az.plot_forest(idata3, var_names=[\"mu_A\", \"mu_B\"])\n\n\n\n\n\n\n\n\nDato che gli intervalli di credibilit√† sono sovrapposti, concludiamo che non ci sono evidenze credibili di una differenza. Ovvero, sulla base delle nostre credenze a priori e sulla base dei dati osservati, ad un livello di certezza soggettiva del 94%, non possiamo concludere che Paolo sia pi√π violento di Mario.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "href": "chapters/chapter_7/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "title": "Appendice W ‚Äî La predizione delle frequenze",
    "section": "W.6 La predizione di episodi di violenza futuri",
    "text": "W.6 La predizione di episodi di violenza futuri\nConsideriamo ora il problema della predizione di dati futuri. Utilizziamo nuovamente il modello che abbiamo gi√† usato in precedenza, ovvero model3.\nCreiamo la distribuzione predittiva a posteriori per il parametro mu_A, ovvero la media del numero di eventi di violenza attesi in futuro per Mario.\n\nwith model3:\n    post_pred = pm.sample_posterior_predictive(idata3)\n\nSampling: [episodes_A, episodes_B]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n\npost_pred\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (chain: 4, draw: 2000, episodes_A_dim_2: 1,\n                       episodes_B_dim_2: 1)\nCoordinates:\n  * chain             (chain) int64 0 1 2 3\n  * draw              (draw) int64 0 1 2 3 4 5 ... 1994 1995 1996 1997 1998 1999\n  * episodes_A_dim_2  (episodes_A_dim_2) int64 0\n  * episodes_B_dim_2  (episodes_B_dim_2) int64 0\nData variables:\n    episodes_A        (chain, draw, episodes_A_dim_2) int64 1 4 12 ... 6 10 11\n    episodes_B        (chain, draw, episodes_B_dim_2) int64 18 13 4 ... 14 14 17\nAttributes:\n    created_at:                 2023-10-27T04:56:02.607337\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:chain: 4draw: 2000episodes_A_dim_2: 1episodes_B_dim_2: 1Coordinates: (4)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([   0,    1,    2, ..., 1997, 1998, 1999])episodes_A_dim_2(episodes_A_dim_2)int640array([0])episodes_B_dim_2(episodes_B_dim_2)int640array([0])Data variables: (2)episodes_A(chain, draw, episodes_A_dim_2)int641 4 12 14 7 4 1 ... 9 13 11 6 10 11array([[[ 1],\n        [ 4],\n        [12],\n        ...,\n        [ 6],\n        [13],\n        [ 7]],\n\n       [[12],\n        [12],\n        [ 4],\n        ...,\n        [ 4],\n        [ 6],\n        [15]],\n\n       [[ 9],\n        [ 4],\n        [ 8],\n        ...,\n        [ 9],\n        [ 5],\n        [12]],\n\n       [[22],\n        [ 3],\n        [ 7],\n        ...,\n        [ 6],\n        [10],\n        [11]]])episodes_B(chain, draw, episodes_B_dim_2)int6418 13 4 6 10 8 ... 9 22 7 14 14 17array([[[18],\n        [13],\n        [ 4],\n        ...,\n        [13],\n        [10],\n        [18]],\n\n       [[ 7],\n        [11],\n        [ 6],\n        ...,\n        [ 5],\n        [13],\n        [ 4]],\n\n       [[ 8],\n        [ 5],\n        [22],\n        ...,\n        [16],\n        [11],\n        [14]],\n\n       [[20],\n        [10],\n        [12],\n        ...,\n        [14],\n        [14],\n        [17]]])Indexes: (4)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='draw', length=2000))episodes_A_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_2'))episodes_B_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_2'))Attributes: (4)created_at :2023-10-27T04:56:02.607337arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (episodes_A_dim_0: 1, episodes_B_dim_0: 1)\nCoordinates:\n  * episodes_A_dim_0  (episodes_A_dim_0) int64 0\n  * episodes_B_dim_0  (episodes_B_dim_0) int64 0\nData variables:\n    episodes_A        (episodes_A_dim_0) int64 8\n    episodes_B        (episodes_B_dim_0) int64 12\nAttributes:\n    created_at:                 2023-10-27T04:56:02.610237\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:episodes_A_dim_0: 1episodes_B_dim_0: 1Coordinates: (2)episodes_A_dim_0(episodes_A_dim_0)int640array([0])episodes_B_dim_0(episodes_B_dim_0)int640array([0])Data variables: (2)episodes_A(episodes_A_dim_0)int648array([8])episodes_B(episodes_B_dim_0)int6412array([12])Indexes: (2)episodes_A_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_0'))episodes_B_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_0'))Attributes: (4)created_at :2023-10-27T04:56:02.610237arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n              \n            \n            \n\n\nRappresentiamo la distribuzione predittiva a posteriori di mu_A con un istogramma.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_A, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per Paolo.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_B, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nIn base alle nostre credenze precedenti e ai dati osservati negli ultimi 6 mesi, possiamo aspettarci con una certezza soggettiva del 94% che nei prossimi 6 mesi Mario avr√† tra 1 e 15 episodi di violenza, mentre Paolo ne avr√† tra 3 e 20.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a70_predict_counts.html#watermark",
    "href": "chapters/chapter_7/a70_predict_counts.html#watermark",
    "title": "Appendice W ‚Äî La predizione delle frequenze",
    "section": "W.7 Watermark",
    "text": "W.7 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Oct 27 2023\n\nPython implementation: CPython\nPython version       : 3.11.6\nIPython version      : 8.16.1\n\nseaborn   : 0.13.0\narviz     : 0.16.1\nmatplotlib: 3.8.0\npymc      : 5.9.1\nscipy     : 1.11.3\nxarray    : 2023.10.1\nnumpy     : 1.25.2\npandas    : 2.1.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a100_solutions.html",
    "href": "chapters/chapter_7/a100_solutions.html",
    "title": "Appendice X ‚Äî Soluzioni degli Esercizi",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 64\nEsercizio¬†64.1\n\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\n\n\n# Calcoliamo l'entropia di $p$.\nh_p = -np.sum(p * np.log(p))\nprint(\"Entropia di p: \", h_p)\n\nEntropia di p:  1.0296530140645737\n\n\n\n# Calcoliamo l'entropia incrociata tra $p$ e $q$.\nh_pq = -np.sum(p * np.log(q))\nprint(\"Entropia incrociata tra p e q: \", h_pq)\n\nEntropia incrociata tra p e q:  1.372238457997479\n\n\n\n# Calcoliamo la divergenza di Kullback-Leibler da $p$ a $q$.\nkl_pq = h_pq - h_p\nprint(\"Divergenza KL da p a q: \", kl_pq)\n\nDivergenza KL da p a q:  0.34258544393290524\n\n\n\n# Lo stesso risultato si ottiene applicando la formula della Divergenza $\\mathbb{KL}$.\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.3425854439329054\n\n\n\n# Se invece $q$ √® molto simile a $p$, la differenza $\\mathbb{KL}$ √® molto minore.\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.2, 0.55, 0.25])\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.007041377136023895\n\n\nEsercizio¬†64.2\n\n# Define the parameters\nn = 4\np = 0.2\n\n# Compute the probability mass function\ntrue_py = stats.binom.pmf(range(n + 1), n, p)\nprint(true_py)\n\n[0.4096 0.4096 0.1536 0.0256 0.0016]\n\n\n\nq1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01])\nprint(q1)\n\n[0.46 0.42 0.1  0.01 0.01]\n\n\n\nq2 = [0.2] * 5\nprint(q2)\n\n[0.2, 0.2, 0.2, 0.2, 0.2]\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_1$ da $p$ √®\nkl_pq1 = np.sum(true_py * (np.log(true_py) - np.log(q1)))\nprint(\"Divergenza KL di q1 da p: \", kl_pq1)\n\nDivergenza KL di q1 da p:  0.02925199033345882\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_2$ da $p$ √®:\nkl_pq2 = np.sum(true_py * (np.log(true_py) - np.log(q2)))\nprint(\"Divergenza KL di q2 da p: \", kl_pq2)\n\nDivergenza KL di q2 da p:  0.48635777871415425\n\n\n√à chiaro che perdiamo una quantit√† maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anzich√© \\(q_1\\).\nEsercizio¬†64.3\n\n# Definire le distribuzioni p e q\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\n\n# Calcolo dell'entropia di p\nh_p = -np.sum(p * np.log(p))\n\n# Calcolo dell'entropia incrociata da p a q\nh_pq = -np.sum(p * np.log(q))\n\n# Calcolo della divergenza KL da p a q\nkl_pq = h_pq - h_p\n\n# Calcolo dell'entropia di q\nh_q = -np.sum(q * np.log(q))\n\n# Calcolo dell'entropia incrociata da q a p\nh_qp = -np.sum(q * np.log(p))\n\n# Calcolo della divergenza KL da q a p\nkl_qp = h_qp - h_q\n\nprint(f\"Entropia di p: {h_p}\")\nprint(f\"Entropia incrociata da p a q: {h_pq}\")\nprint(f\"Divergenza KL da p a q: {kl_pq}\")\n\nprint(f\"\\nEntropia di q: {h_q}\")\nprint(f\"Entropia incrociata da q a p: {h_qp}\")\nprint(f\"Divergenza KL da q a p: {kl_qp}\")\n\nEntropia di p: 0.056001534354847345\nEntropia incrociata da p a q: 1.1954998257220641\nDivergenza KL da p a q: 1.1394982913672167\n\nEntropia di q: 0.6108643020548935\nEntropia incrociata da q a p: 3.226634230947714\nDivergenza KL da q a p: 2.6157699288928207",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>X</span>¬† <span class='chapter-title'>Soluzioni degli Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#probabilit√†-inversa",
    "href": "chapters/chapter_3/03_bayes_theorem.html#probabilit√†-inversa",
    "title": "24¬† Il teorema di Bayes",
    "section": "25.3 Probabilit√† Inversa",
    "text": "25.3 Probabilit√† Inversa\nGli esempi precedenti mettono in luce che possiamo distinguere due domande diverse. La prima domanda √®: ‚ÄúQual √® la probabilit√† dell‚Äôevidenza, data l‚Äôipotesi?‚Äù La seconda domanda √®: ‚ÄúQual √® la probabilit√† che l‚Äôipotesi sia vera, data l‚Äôevidenza?‚Äù\nUn esempio per rispondere alla prima domanda √® il seguente: Supponiamo che la probabilit√† di ottenere testa nel lancio di una moneta sia 0.5 (questa √® l‚Äôipotesi). Qual √® la probabilit√† di ottenere 0 volte testa in cinque lanci?\nUn esempio per rispondere alla seconda domanda √® il seguente: Supponiamo di avere ottenuto 0 volte testa in 5 lanci di una moneta (questa √® l‚Äôevidenza). Ci chiediamo: qual √® la probabilit√† che la moneta sia bilanciata, alla luce delle nostre osservazioni?\nPer molto tempo, la storia della probabilit√† si √® concentrata sulla prima domanda. Ma dopo che il reverendo Thomas Bayes ha iniziato a porsi la seconda domanda nel XVIII secolo, questa √® diventata nota come probabilit√† inversa.\nQuesto modo di pensare ha suscitato molte controversie nel corso della storia della statistica, forse perch√© influisce su tutto. In particolare, ci si pu√≤ chiedere la seguente domanda: quanto √® probabile che un‚Äôipotesi scientifica sia vera, dato il risultato di uno studio? Per stimare questa probabilit√†, e un numero crescente di scienziati sostiene che √® esattamente ci√≤ che dovrebbero fare le statistiche, abbiamo bisogno di Bayes e delle probabilit√† a priori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html",
    "href": "chapters/chapter_6/01_intro_frequentist.html",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "",
    "text": "Introduzione\nCi sono due approcci principali per l‚Äôinferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l‚Äôanalisi dei dati. Entrambi gli approcci sono usati per stimare quantit√† sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilit√† e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilit√† viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l‚Äôutilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD‚Äôaltra parte, la statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica attraverso l‚Äôuso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione √® trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che pu√≤ essere utilizzata per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell‚Äôinferenza statistica frequentista.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#storia-i-frequentisti-sono-razzisti",
    "href": "chapters/chapter_6/01_intro_frequentist.html#storia-i-frequentisti-sono-razzisti",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.1 Storia: I Frequentisti sono Razzisti?",
    "text": "70.1 Storia: I Frequentisti sono Razzisti?\nNel Capitolo 24, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all‚Äôinterpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il ‚Äúlato luminoso‚Äù del liberalismo moderno.\nLe origini culturali dell‚Äôapproccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la ‚Äúparte oscura‚Äù della modernit√†. Si potrebbe dire che l‚Äôavversione per la soggettivit√† abbia guidato l‚Äôascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, eredit√≤ una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplor√≤ l‚ÄôAfrica, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli ‚Äúanticicloni‚Äù. Tuttavia, il suo contributo pi√π significativo riguard√≤ l‚Äôuso della statistica nello studio degli esseri umani, in particolare nell‚Äôanalisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all‚ÄôUniversity College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come ‚Äúregressione verso la media‚Äù, da lui chiamato ‚Äúregressione verso la mediocrit√†‚Äù.\nIl suo interesse per l‚Äôereditariet√† del talento lo port√≤ a scrivere il libro ‚ÄúHereditary Genius‚Äù, in cui esaminava come i pensatori brillanti spesso si concentrassero in determinate famiglie. Coni√≤ l‚Äôespressione ‚Äúnatura e cultura‚Äù per riferirsi ai due fattori che influenzano lo sviluppo umano: l‚Äôereditariet√† (quello che oggi chiamiamo genetica) e l‚Äôambiente.\nTuttavia, Galton non si limit√≤ a osservare e documentare fatti sulla distribuzione dell‚Äôintelligenza. Il suo obiettivo era creare una scienza dell‚Äôallevamento umano, che egli denomin√≤ ‚Äúeugenetica‚Äù. Egli sosteneva l‚Äôincoraggiamento della riproduzione tra le famiglie di maggior successo e lo scoraggiamento tra quelle meno fortunate.\nGalton era anche estremamente razzista. In una lettera al Times di Londra, defin√¨ gli africani ‚Äúinferiori‚Äù e ‚Äúselvaggi pigri e chiacchieroni‚Äù, descrisse gli arabi come ‚Äúpoco pi√π che consumatori della produzione altrui‚Äù e sostenne che l‚ÄôAfrica orientale dovesse essere consegnata ai cinesi, poich√© questi, nonostante fossero ‚Äúinclini alla menzogna e alla servilit√†‚Äù, erano per natura ‚Äúindustriosi e amanti dell‚Äôordine‚Äù. Per Galton, gli anglosassoni erano la migliore razza esistente, sebbene ritenesse che gli antichi ateniesi fossero stati i migliori di tutti i tempi.\nIl lavoro di Galton ispir√≤ una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, un poliedrico studioso, divenne professore di matematica applicata all‚ÄôUCL nel 1885, seguendo le orme di Galton. Alla morte di quest‚Äôultimo, eredit√≤ la cattedra di eugenismo finanziata da Galton stesso. Pearson fond√≤ la rivista di statistica ‚ÄúBiometrika‚Äù e svilupp√≤ il test del chi quadrato, oltre a coniare il termine ‚Äúdeviazione standard‚Äù.\nRonald Fisher, pi√π giovane, succedette a Pearson come professore di eugenismo all‚ÄôUCL. Fisher √® considerato un gigante della teoria statistica, avendo inventato o esteso numerosi strumenti statistici moderni, tra cui l‚Äôanalisi della varianza (ANOVA), il concetto di ‚Äúsignificativit√† statistica‚Äù e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall‚Äôapproccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell‚Äôeugenismo.\n√à interessante chiedersi se le idee di Galton, Pearson e Fisher sull‚Äôeugenismo abbiano influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e dell‚Äôeugenismo sono strettamente intrecciate. Fisher e, in misura minore, Pearson respingevano l‚Äôidea del bayesianesimo perch√© cercavano di assegnare un fondamento ‚Äúoggettivo‚Äù alle loro idee eugenetiche. Se fosse stata la scienza a stabilire che alcune razze erano inferiori e altre superiori, o che si dovesse scoraggiare la riproduzione tra i poveri, allora queste idee sarebbero state incontestabili. Il bayesianesimo, con la sua intrinseca soggettivit√†, minava questa pretesa di oggettivit√†.\nQuanto di tutto ci√≤ dobbiamo tenere a mente quando esaminiamo la statistica frequentista? Chivers (2024) risponde in questo modo. √à certo che parte dell‚Äôideologia razziale nazista pu√≤ essere ricondotta senza troppe difficolt√† a Galton. Tuttavia, questa considerazione, per quanto estremamente importante dal punto di vista storico ed etico, non √® direttamente rilevante in ambito statistico. La domanda cruciale in termini statistici rimane: ‚ÄúQuale approccio √® corretto?‚Äù o, pi√π accuratamente, ‚ÄúQuale √® pi√π utile?‚Äù, piuttosto che ‚ÄúQuale ha avuto i sostenitori pi√π disgustosi?‚Äù.\nD‚Äôaltra parte, personalmente ritengo che la risposta di Chivers (2024) sia fondamentalmente inadeguata. Consideriamo uno scenario ipotetico: all‚Äôinterno di una ‚Äútorre d‚Äôavorio‚Äù - che sia la statistica, l‚Äôaccademia o la scienza in generale - la teoria A si dimostra pi√π efficace della teoria B. Tuttavia, al di fuori di questo ambito ristretto, la teoria A, a differenza della B, comporta implicazioni etiche inaccettabili.\nDobbiamo davvero accettare A solo perch√© funziona meglio all‚Äôinterno di questo microcosmo artificiale? Assolutamente no.\nInnanzitutto, le cosiddette ‚Äútorri d‚Äôavorio‚Äù sono mere costruzioni ideologiche. Non esiste una vera demarcazione tra ‚Äúdentro‚Äù e ‚Äúfuori‚Äù questi ambiti. La scienza e l‚Äôetica non operano in compartimenti stagni, ma si influenzano reciprocamente in un continuo dialogo.\nInoltre, nel caso specifico del frequentismo, √® evidente - come dimostreremo in seguito - che questo metodo √® intrinsecamente fallace, indipendentemente dal contesto in cui lo si applichi. La sua presunta efficacia all‚Äôinterno di un ambito ristretto √® illusoria e non giustifica in alcun modo le sue implicazioni problematiche. Non possiamo e non dobbiamo separare l‚Äôefficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce non solo sul piano morale, ma anche su quello scientifico, rendendo la sua difesa insostenibile su tutti i fronti.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#storia-i-frequentisti-sono-razzisti-1",
    "href": "chapters/chapter_6/01_intro_frequentist.html#storia-i-frequentisti-sono-razzisti-1",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.2 Storia: I Frequentisti Sono Razzisti?",
    "text": "70.2 Storia: I Frequentisti Sono Razzisti?\nNel Capitolo 24 abbiamo presentato le origini storiche del teorema di Bayes e abbiamo messo in evidenza il background culturale che ha contribuito alle origini dell‚Äôinterpretazione applicativa del teorema di Bayes fornita da Richard Price, ovvero le idee che stavano alla base della rivoluzione americana, quello che potremmo chiamare il ‚Äúlato luminoso‚Äù del liberalismo moderno.\nLe origini culturali dell‚Äôapproccio frequentista hanno caratteristiche diametralmente opposte e sono strettamente in relazione con quello che potremmo chiamare la ‚Äúparte oscura‚Äù della modernit√†.\nA distaste for subjectivity is what it seems to have driven the rise of frequentism.\nFrancis Galton (1822‚Äì1911), for instance, was in many ways an extraordinary man. The cousin of Charles Darwin and a qualified doctor who inherited a fortune, he quit medicine and went off to do whatever took his fancy. He explored Africa and was awarded a medal for doing so by the Royal Geographical Society; he got meteorological stations to fill out surveys about the weather and, using the data, became the first to notice ‚Äúanticyclones,‚Äù; and, crucially, he pushed forward the use of statistics in studying humans and, specifically, how things like talent are passed on through families. Galton spent most of his career at University College London, where he made various huge breakthroughs. Un importante contributo riguardava la distribuzione Normale.\nGalton was also the first to explain what we now know as regression to the mean, or as he called it, regression to mediocrity. Looking at sweet peas, but thinking about humans, he noticed that the offspring of very tall parents tend not to be as tall as their parents, compared to an average of the two parents‚Äô height; and the offspring of very short parents tend to be rather taller. This was confusing, because you might expect the offspring‚Äôs heights to be normally distributed around their parents. Galton showed that this was a general finding: any two variables that correlated somewhat but imperfectly would demonstrate the same phenomenon.\nGalton was also very interested in the inheritance of talent. He wrote a book called Hereditary Genius, looking at how brilliant thinkers often clustered in families (his own family, with Erasmus Darwin and Charles Darwin as close relatives, may have been an inspiration). He coined the phrase ‚Äúnature and nurture‚Äù to refer to the twin inputs of heredity (what we‚Äôd now call genetics) and environment. But what he really wanted to do was to create a science of human breeding‚Äîeugenics, another phrase which he came up with.\nBut Galton didn‚Äôt just want to observe and document facts about how intelligence is distributed. He wanted to breed humans. He was in favor of encouraging breeding among highly successful families, and discouraging it among less successful ones. And he was extremely racist. He wrote a letter to the London Times calling African people ‚Äúinferior‚Äù and ‚Äúlazy, palavering savages,‚Äù saying that ‚Äúthe Arab‚Äù is ‚Äúlittle more than an eater up of other men‚Äôs produce; he is a destroyer rather than a creator,‚Äù and ‚Äúthat East Africa should be handed over to the Chinese because, while they are given to ‚Äúlying and servility,‚Äù that is the product of their education, and ‚ÄúChinamen‚Äù are by nature ‚Äúindustrious [and] order loving.‚Äù (Anglo-Saxons were, for Galton, the best extant race, although the best of all time were the ancient Athenians: ‚ÄúThe average ability of the Athenian race is, on the lowest possible estimate, very nearly two grades [standard deviations] higher than our own‚Äù). He was obsessed with cataloguing and comparing the races, with the tools of science that he himself helped to create.\nGalton‚Äôs work inspired a later generation of statisticians‚Äînotably Karl Pearson (1857‚Äì1936), and after him Ronald Fisher (1890‚Äì1962). Like Galton, Fisher and Pearson were brilliant, and like Galton they were, certainly by the standards of our day and arguably by the standards of their own, unpleasantly race-obsessed. Also, they hated each other.\nPearson was a polymath, a historian, philosopher, physicist, lawyer, and politician before he was a mathematician. In 1885 he became a professor of applied mathematics at UCL, following in Galton‚Äôs footsteps. Galton, upon his death, left money to UCL to found a chair of eugenics, and Pearson was the first appointee.\nAlong with Galton and a third man, Raphael Weldon, Pearson founded a journal of statistics, Biometrika. He came up with the ‚Äúchi-square test,‚Äù which allowed mathematicians to check whether a sample of data really was normally distributed, or whether it best fit some other curve. He also was the first to coin the term ‚Äústandard deviation.\nFisher was younger; he was appointed the University College of London professor of eugenics after Pearson retired. Fisher is a titan of statistical theory. The list of modern statistical tools he invented or extended is remarkable. He was responsible for the various models used in ‚Äúanalysis of variance‚Äù (ANOVA), for the concept of ‚Äústatistical significance,‚Äù for the ‚Äúmaximum likelihood estimation‚Äù (MLE) method for establishing which hypothesis about the distribution of data would best explain some given data, and for a host of other things. Fisher was also a pioneering geneticist. All these men tried to move statistics away from where Laplace and Bayes had left it, relying on subjective priors.\nLike Galton, both Pearson and Fisher had what we would now consider pretty unpleasant views. Specifically, they both were big fans of eugenics. What‚Äôs a bit more interesting, though, is whether Galton, Pearson, and Fisher‚Äôs views on eugenics affected their views on science. Clayton argues forcefully that they did. ‚ÄúAs far as the history of statistics and eugenics go,‚Äù he told me, ‚Äúthey‚Äôre intertwined. It‚Äôs a necessary part of the story.‚Äù At heart, he said, Fisher and to some extent Pearson hated the idea of Bayesianism because they wanted a veneer of objectivity for their eugenic views. If it was science that some races were inferior and others superior, if it was objective truth that we ought to discourage breeding among the poor, then we couldn‚Äôt argue with it. Bayesianism and its inherent subjectivity, its squishy ‚ÄúWhat do I think?‚Äù nature, undermined ‚Äúthat, Clayton said. ‚ÄúThey sought out a kind of scientific authority,‚Äù he told me, ‚Äúbecause they knew they‚Äôd encounter resistance for this quite radical upheaval. They wanted that backed by the most unassailable authority possible.\nQuanto di questo dobbiamo tenere a mente quando esaminiamo la statistica frequentista? √à certo che some of the Nazi race ideology can be traced back without too much difficulty to Galton. Ma questa considerazione, per quanto estremamente importante, non √® rilevante in ambito statistico. The crucial question in statistical terms is ‚ÄòWhich is correct?‚Äô or, perhaps more accurately, ‚ÄòWhich is more useful?‚Äô rather than ‚ÄòWhich had the more unpleasant adherents?‚Äô",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/chapter_6/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.2 Stime, stimatori e parametri",
    "text": "70.2 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si √® interessati a una quantit√† a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantit√† sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore √® una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune propriet√† della popolazione di cui il campione √® rappresentativo. Il parametro rappresenta la misura di tali propriet√†, ma spesso non √® possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima √® quindi l‚Äôapprossimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore √® la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilit√† del campionamento. In questo capitolo esamineremo come l‚Äôapproccio frequentista quantifica l‚Äôincertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/chapter_6/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.3 Distribuzione campionaria",
    "text": "70.3 Distribuzione campionaria\nIn questo capitolo, affronteremo il problema dell‚Äôutilizzo della media di un campione casuale per stimare il parametro \\(\\mu\\) corrispondente alla media della popolazione da cui √® stato estratto il campione. Per caratterizzare l‚Äôincertezza della stima di un parametro, l‚Äôapproccio frequentista utilizza lo strumento statistico della distribuzione campionaria.\nPer comprendere il concetto di distribuzione campionaria, considereremo il caso di una popolazione finita di dimensioni ridotte. Tuttavia, le stesse propriet√† che esamineremo si applicano alle popolazioni di qualsiasi dimensione.\nIn questa simulazione, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL‚Äôistogramma sottostante descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nPrendiamo ora in considerazione l‚Äôestrazione di tutti i campioni possibili di dimensione \\(n\\) = 2 dalla popolazione.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nPer ottenere un array con tutte le possibili coppie di valori estratti dall‚Äôarray x, possiamo utilizzare la funzione product del modulo itertools. Impostiamo l‚Äôargomento repeat a 2 per indicare che vogliamo coppie di valori. Successivamente, convertiamo la lista di tuple risultante in un array NumPy utilizzando la funzione np.array, e infine stampiamo il risultato. L‚Äôoutput ottenuto sar√† un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie di valori che possono essere estratti dall‚Äôarray x.\nCalcoliamo il numero totale di campioni di ampiezza \\(n\\) = 2.\n\nlen(list(itertools.product(x, x)))\n\n16\n\n\nOra procediamo al calcolo della media per ciascun campione. Questo insieme di valori rappresenta la distribuzione campionaria delle medie dei campioni con dimensione \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), utilizziamo la funzione mean del modulo NumPy e la applichiamo lungo l‚Äôasse delle colonne dell‚Äôarray di coppie di valori. In questo modo otteniamo un array unidimensionale contenente la media di ciascuna coppia di valori.\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x. Sappiamo che, se la variabile aleatoria \\(X\\) √® distribuita con media \\(\\mu\\) e varianza \\(\\sigma^2\\), allora la media della distribuzione dei campioni casuali indipendenti di ampiezza \\(n\\) = 2 sar√†:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu.\n\\]\nVerifichiamo che ci√≤ sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\nVerifichiamo che la varianza della distribuzione dei campioni casuali indipendenti di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione \\(X\\) con varianza \\(\\sigma^2\\) sia \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\).\nConsiderando la definizione di varianza, possiamo scrivere:\n\\[\n\\begin{aligned}\n\\mathbb{V}(\\bar{X}) &= \\mathbb{E}[(\\bar{X}-\\mu_{\\bar{X}})^2] \\\\\n&= \\mathbb{E}[(\\bar{X} - \\mu)^2] \\\\\n&= \\mathbb{E}[(X_1+X_2)/2 - \\mu)^2] \\\\\n&= \\mathbb{E}[((X_1 - \\mu) + (X_2 - \\mu))/2)^2] \\\\\n&= \\mathbb{E}[(X_1 - \\mu)^2/4 + (X_2 - \\mu)^2/4 + (X_1 - \\mu)(X_2 - \\mu)/2)] \\\\\n&= \\frac{1}{4}\\mathbb{E}[(X_1 - \\mu)^2] + \\frac{1}{4}\\mathbb{E}[(X_2 - \\mu)^2] + \\frac{1}{2}\\mathbb{E}[(X_1 - \\mu)(X_2 - \\mu)] \\\\\n&= \\frac{1}{4}\\mathbb{V}(X_1) + \\frac{1}{4}\\mathbb{V}(X_2) + \\frac{1}{2}\\mathbb{C}(X_1,X_2) \\\\\n&= \\frac{\\sigma^2}{4} + \\frac{\\sigma^2}{4} + 0 \\\\\n&= \\frac{\\sigma^2}{2}\n\\end{aligned}\n\\]\nDove \\(\\mu_{\\bar{X}}\\) √® la media della distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) e \\(\\mathbb{C}(X_1,X_2)\\) √® la covarianza tra \\(X_1\\) e \\(X_2\\). In questo caso, dato che i campioni sono estratti in modo casuale e indipendente, la covarianza tra \\(X_1\\) e \\(X_2\\) √® 0. Pertanto, abbiamo dimostrato che \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\) per \\(n=2\\).\nIl valore teorico della varianza delle medie dei campioni √® dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione √® diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, si presti attenzione a due aspetti importanti:\n\nla media della distribuzione delle medie campionarie √® uguale alla media della popolazione,\nla varianza della distribuzione delle medie campionarie √® minore della varianza della popolazione, ovvero √® pari alla varianza della popolazione divisa per l‚Äôampiezza campionaria.\n\nQuesti due risultati che abbiamo ottenuto empiricamente nella simulazione possono essere espressi in maniera formale dicendo che la media di campioni casuali estratti con ripetizione da una popolazione finita (oppure da una popolazione infinita) di media \\(\\mu\\) e varianza \\(\\sigma^2\\) ha valore atteso $ ({X}_n) = $ e varianza $ ({X}_n) = . $\nInoltre, se la popolazione segue una distribuzione normale, allora per le propriet√† della distribuzione normale, anche la distribuzione delle medie dei campioni seguir√† una distribuzione normale. Al contrario, se la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all‚Äôaumentare delle dimensioni del campione, la distribuzione delle medie dei campioni tender√† a una distribuzione normale.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/chapter_6/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.4 Teorema del Limite Centrale",
    "text": "70.4 Teorema del Limite Centrale\nEsaminiamo ora pi√π in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostr√≤ il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 70.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tender√† a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC pu√≤ essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l‚Äôaltezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalit√† della distribuzione risultante. Questa √® la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\nPer illustrare il TLC, utilizziamo una simulazione. Consideriamo una popolazione iniziale fortemente asimmetrica, come una distribuzione Beta(2, 1). Estraiamo da questa popolazione 50,000 campioni di ampiezza \\(n\\) e costruiamo la distribuzione campionaria di tali campioni.\n\n# parameters of the beta\na=2\nb=1\n\ndef plotSamples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n          v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together \n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(sample_means)\n    ax2 = ax.twinx()\n    sns.lineplot(x=x,y=y, ax=ax2, color='black')\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l‚Äôampiezza campionaria √® 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplotSamples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non √® certamente Normale, inizia ad avvicinarsi alla gaussianit√†.\n\nplotSamples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c‚Äô√® ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l‚Äôapprossimazione migliora.\n\nplotSamples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplotSamples(30)\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) mostra che, salvo per campioni molto piccoli, la distribuzione campionaria della media dei campioni pu√≤ essere ben approssimata dalla Normale, indipendentemente dalla forma della distribuzione della popolazione. Ci√≤ significa che, per campioni sufficientemente grandi, il TLC ci fornisce una formula esplicita per la forma della distribuzione campionaria della media dei campioni, anche in assenza di conoscenze sulla popolazione di media \\(\\mu\\) e deviazione standard \\(\\sigma\\): \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).\nIl risultato del TLC ha una grande utilit√† in molti ambiti. Infatti, ci aiuta a comprendere perch√© i risultati degli esperimenti con un grande numero di osservazioni sono pi√π affidabili rispetto a quelli con un numero ridotto di osservazioni. Inoltre, il TLC ci fornisce una formula esplicita per l‚Äôerrore standard (\\(\\sigma/\\sqrt{n}\\)), che ci consente di valutare l‚Äôaffidabilit√† degli esperimenti al variare della dimensione del campione.\nNegli esperimenti psicologici, molti dei fenomeni che vogliamo misurare sono in realt√† medie di molteplici variabili (ad esempio, l‚Äôintelligenza ‚Äúgenerale‚Äù misurata dal QI √® una media di un gran numero di abilit√† specifiche), e in questi casi la quantit√† media segue una distribuzione normale. Questa legge matematica ci permette di osservare spesso la distribuzione normale nei dati degli esperimenti psicologici e in molte altre discipline scientifiche.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/chapter_6/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.5 Distribuzioni campionarie di altre statistiche",
    "text": "70.5 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax)\nax2 = ax.twinx()\n_ = sns.lineplot(x=x, y=y, ax=ax2, color=\"black\")\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Per calcolare la varianza, iniziamo usando la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCreiamo ora un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza, usando la procedura descritta in precedenza.\nSappiamo che la varianza della popolazione √® uguale a \\(15^2 = 225\\). Tuttavia, calcolando la varianza con la formula della statistica descrittiva otteniamo, in media, un valore minore. Dunque, l‚Äôutilizzo della formula precedente conduce a una stima troppo piccola della varianza della popolazione. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n176.76365773544788\n\n\n\n\n\n\n\n\n\nQuesta dimostrazione ci fa dunque capire come\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nnon sia uno stimatore adeguato per la varianza della popolazione.\nAbbiamo gi√† visto per√≤ che questo problema trova una semplice soluzione nel momento in cui usiamo usiamo il seguente stimatore per la varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\nVerifichiamo.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n224.19924816630638\n\n\n\n\n\n\n\n\n\nLa discrepanza tra la stima di un parametro e il suo vero valore √® definita come errore di stima. Uno stimatore √® considerato non distorto (unbiased) se, in media, le sue stime su diversi campioni ipotetici coincidono con il valore del parametro che si intende stimare, ossia se l‚Äôerrore medio di stima √® nullo.\nNel corso di questo capitolo, abbiamo osservato che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) costituisce uno stimatore non distorto di \\(\\mu\\), mentre \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo implica che lo stimatore \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) presenta una distribuzione campionaria centrata sul vero valore del parametro \\(\\sigma^2\\).",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#considerazioni-conclusive",
    "href": "chapters/chapter_6/01_intro_frequentist.html#considerazioni-conclusive",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.6 Considerazioni conclusive",
    "text": "70.6 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_6/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nseaborn   : 0.13.2\narviz     : 0.18.0\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\n\n\n\n\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, Edwin T. 2003. Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#introduzione",
    "href": "chapters/chapter_6/01_intro_frequentist.html#introduzione",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "Introduzione",
    "text": "Introduzione\nCi sono due approcci principali per l‚Äôinferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l‚Äôanalisi dei dati. Entrambi gli approcci sono usati per stimare quantit√† sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilit√† e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilit√† viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l‚Äôutilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD‚Äôaltra parte, la statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento {cite:p}jaynes2003probability. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica attraverso l‚Äôuso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione √® trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che pu√≤ essere utilizzata per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell‚Äôinferenza statistica frequentista.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/chapter_6/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "70¬† Introduzione all‚Äôinferenza frequentista",
    "section": "70.1 I Frequentisti sono Razzisti?",
    "text": "70.1 I Frequentisti sono Razzisti?\nNel Capitolo 24, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all‚Äôinterpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il ‚Äúlato luminoso‚Äù del liberalismo moderno.\nLe origini culturali dell‚Äôapproccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la ‚Äúparte oscura‚Äù della modernit√†. Si potrebbe dire che l‚Äôavversione per la soggettivit√† abbia guidato l‚Äôascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, eredit√≤ una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplor√≤ l‚ÄôAfrica, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli ‚Äúanticicloni‚Äù. Tuttavia, il suo contributo pi√π significativo riguard√≤ l‚Äôuso della statistica nello studio degli esseri umani, in particolare nell‚Äôanalisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all‚ÄôUniversity College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come ‚Äúregressione verso la media‚Äù, da lui chiamato ‚Äúregressione verso la mediocrit√†‚Äù.\nIl suo interesse per l‚Äôereditariet√† del talento lo port√≤ a scrivere il libro ‚ÄúHereditary Genius‚Äù, in cui esaminava come i pensatori brillanti spesso si concentrassero in determinate famiglie. Coni√≤ l‚Äôespressione ‚Äúnature and nurture‚Äù per riferirsi ai due fattori che influenzano lo sviluppo umano: l‚Äôereditariet√† (quello che oggi chiamiamo genetica) e l‚Äôambiente.\nTuttavia, Galton non si limit√≤ a osservare e documentare fatti sulla distribuzione dell‚Äôintelligenza. Il suo obiettivo era creare una scienza dell‚Äôallevamento umano, che egli denomin√≤ ‚Äúeugenetica‚Äù. Egli sosteneva l‚Äôincoraggiamento della riproduzione tra le famiglie di maggior successo e lo scoraggiamento tra quelle meno fortunate.\nGalton era anche estremamente razzista. In una lettera al Times di Londra, defin√¨ gli africani ‚Äúinferiori‚Äù e ‚Äúselvaggi pigri e chiacchieroni‚Äù, descrisse gli arabi come ‚Äúpoco pi√π che consumatori della produzione altrui‚Äù e sostenne che l‚ÄôAfrica orientale dovesse essere consegnata ai cinesi, poich√© questi, nonostante fossero ‚Äúinclini alla menzogna e alla servilit√†‚Äù, erano per natura ‚Äúindustriosi e amanti dell‚Äôordine‚Äù. Per Galton, gli anglosassoni erano la migliore razza esistente, sebbene ritenesse che gli antichi ateniesi fossero stati i migliori di tutti i tempi.\nIl lavoro di Galton ispir√≤ una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, un poliedrico studioso, divenne professore di matematica applicata all‚ÄôUCL nel 1885, seguendo le orme di Galton. Alla morte di quest‚Äôultimo, eredit√≤ la cattedra di eugenismo finanziata da Galton stesso. Pearson fond√≤ la rivista di statistica ‚ÄúBiometrika‚Äù e svilupp√≤ il test del chi quadrato, oltre a coniare il termine ‚Äúdeviazione standard‚Äù.\nRonald Fisher, pi√π giovane, succedette a Pearson come professore di eugenismo all‚ÄôUCL. Fisher √® considerato un gigante della teoria statistica, avendo inventato o esteso numerosi strumenti statistici moderni, tra cui l‚Äôanalisi della varianza (ANOVA), il concetto di ‚Äúsignificativit√† statistica‚Äù e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall‚Äôapproccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell‚Äôeugenismo.\n√à interessante chiedersi se le idee di Galton, Pearson e Fisher sull‚Äôeugenismo abbiano influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e dell‚Äôeugenismo sono strettamente intrecciate. Fisher e, in misura minore, Pearson respingevano l‚Äôidea del bayesianesimo perch√© cercavano di assegnare un fondamento ‚Äúoggettivo‚Äù alle loro idee eugenetiche. Se fosse stata la scienza a stabilire che alcune razze erano inferiori e altre superiori, o che si dovesse scoraggiare la riproduzione tra i poveri, allora queste idee sarebbero state incontestabili. Il bayesianesimo, con la sua intrinseca soggettivit√†, minava questa pretesa di oggettivit√†.\nQuanto di tutto ci√≤ dobbiamo tenere a mente quando esaminiamo la statistica frequentista? Chivers (2024) risponde in questo modo. √à certo che parte dell‚Äôideologia razziale nazista pu√≤ essere ricondotta senza troppe difficolt√† a Galton. Tuttavia, questa considerazione, per quanto estremamente importante dal punto di vista storico ed etico, non √® direttamente rilevante in ambito statistico. La domanda cruciale in termini statistici rimane: ‚ÄúQuale approccio √® corretto?‚Äù o, pi√π accuratamente, ‚ÄúQuale √® pi√π utile?‚Äù, piuttosto che ‚ÄúQuale ha avuto i sostenitori pi√π disgustosi?‚Äù.\nD‚Äôaltra parte, personalmente ritengo che la risposta di Chivers (2024) sia fondamentalmente inadeguata. Consideriamo uno scenario ipotetico: all‚Äôinterno di una ‚Äútorre d‚Äôavorio‚Äù - che sia la statistica, l‚Äôaccademia o la scienza in generale - la teoria A si dimostra pi√π efficace della teoria B. Tuttavia, al di fuori di questo ambito ristretto, la teoria A, a differenza della B, comporta implicazioni etiche inaccettabili.\nDobbiamo davvero accettare A solo perch√© funziona meglio all‚Äôinterno di questo microcosmo artificiale? Assolutamente no.\nInnanzitutto, le cosiddette ‚Äútorri d‚Äôavorio‚Äù sono mere costruzioni ideologiche. Non esiste una vera demarcazione tra ‚Äúdentro‚Äù e ‚Äúfuori‚Äù questi ambiti. La scienza e l‚Äôetica non operano in compartimenti stagni, ma si influenzano reciprocamente in un continuo dialogo.\nInoltre, nel caso specifico del frequentismo, √® evidente - come dimostreremo in seguito - che questo metodo √® intrinsecamente fallace, indipendentemente dal contesto in cui lo si applichi. La sua presunta efficacia all‚Äôinterno di un ambito ristretto √® illusoria e non giustifica in alcun modo le sue implicazioni problematiche. Non possiamo e non dobbiamo separare l‚Äôefficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce non solo sul piano morale, ma anche su quello scientifico, rendendo la sua difesa insostenibile su tutti i fronti.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html",
    "href": "chapters/chapter_6/05_crisis.html",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#pratiche-di-ricerca-discutibili",
    "href": "chapters/chapter_6/05_crisis.html#pratiche-di-ricerca-discutibili",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.2 Pratiche di Ricerca Discutibili",
    "text": "71.2 Pratiche di Ricerca Discutibili\nLo studio di Bem, che portava a conclusioni insensate, si rivel√≤ un catalizzatore per un esame critico delle pratiche di ricerca in psicologia, innescando un dibattito che avrebbe avuto profonde ripercussioni sull‚Äôintera disciplina.\nGi√† nel 2005, alcuni ricercatori lungimiranti avevano previsto l‚Äôimminente crisi nella metodologia scientifica. Tra questi, John Ioannidis dell‚ÄôUniversit√† di Stanford si distingueva per la sua analisi acuta e provocatoria. Nel suo articolo seminale intitolato ‚ÄúWhy Most Published Research Findings Are False‚Äù, Ioannidis metteva in luce le carenze delle pratiche statistiche diffuse in gran parte della comunit√† scientifica. Il nucleo della critica di Ioannidis riguardava l‚Äôapproccio interpretativo dei dati sperimentali. Secondo la sua analisi, il problema fondamentale risiedeva nel fatto che molti scienziati non valutavano correttamente la probabilit√† che la loro ipotesi fosse vera alla luce dei dati raccolti. Al contrario, seguendo l‚Äôapproccio tradizionale ispirato ai lavori di Bernoulli e Fisher, si concentravano sulla probabilit√† di ottenere i dati osservati nell‚Äôipotesi che la loro teoria fosse falsa.\nLa psicologia, come molte altre discipline scientifiche, si trova spesso a fare i conti con le insidie dei campioni di piccole dimensioni, che possono facilmente portare a falsi positivi. La pressione per ottenere risultati ‚Äústatisticamente significativi‚Äù spinge talvolta i ricercatori ad adottare pratiche discutibili, come l‚Äôinterruzione prematura della raccolta dati non appena il p-value scende sotto la soglia convenzionale dello 0.05.\nSimmons, Nelson e Simonsohn hanno dimostrato quanto sia semplice ottenere risultati statisticamente significativi attraverso l‚Äôimpiego di tali espedienti. Queste pratiche, note come ‚ÄúHARKing‚Äù (Hypothesizing After Results are Known) o ‚Äúp-hacking‚Äù, sono molto diffuse nelle ricerche che adottano l‚Äôapproccio frequentista, talvolta inconsapevolmente.\nIl sistema accademico stesso, con i suoi incentivi alla pubblicazione e al finanziamento, incoraggia indirettamente queste pratiche. Un caso emblematico √® quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l‚Äôamministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di pi√π in presenza di donne o sull‚Äôeffetto dei nomi ‚Äúattraenti‚Äù dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero ‚Äúespressioni di preoccupazione‚Äù, e quindici furono corretti. Nel 2019, Wansink si dimise da Cornell dopo essere stato giudicato colpevole di cattiva condotta scientifica.\nTuttavia, sarebbe un errore considerare Wansink come un caso isolato. Il suo √® piuttosto un esempio estremo di pratiche che, in forme meno evidenti, continuano ad essere diffuse nel mondo della ricerca. Molti scienziati, infatti, adottano inconsapevolmente metodi di p-hacking, ritenendoli parte normale del processo di ricerca.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#il-progetto-di-riproducibilit√†",
    "href": "chapters/chapter_6/05_crisis.html#il-progetto-di-riproducibilit√†",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.3 Il Progetto di Riproducibilit√†",
    "text": "71.3 Il Progetto di Riproducibilit√†\nNel 2011, in risposta alle crescenti preoccupazioni emerse nel mondo scientifico, Brian Nosek, psicologo dell‚ÄôUniversit√† della Virginia, diede avvio al Progetto di Riproducibilit√†. Questa iniziativa coinvolse 270 ricercatori in uno sforzo collettivo per replicare cento studi di psicologia. L‚Äôobiettivo era ripetere gli esperimenti originali, utilizzando gli stessi metodi ma con nuovi campioni, per verificare la solidit√† e la replicabilit√† dei risultati precedentemente pubblicati.\nI risultati di questo imponente lavoro, pubblicati nel 2015, furono a dir poco sconvolgenti. Dei cento studi esaminati, ben novantasette avevano inizialmente riportato risultati statisticamente significativi. Tuttavia, il team di Nosek riusc√¨ a replicare questi risultati solo in trentasei casi. Non solo: le dimensioni degli effetti nelle replicazioni risultarono, in media, dimezzate rispetto agli studi originali. Inoltre, pi√π della met√† di queste dimensioni degli effetti cadeva al di fuori degli intervalli di confidenza al 95% riportati nei lavori originali.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilit√† che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilit√† di Nosek rappresent√≤ un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, pi√π in generale, nelle scienze sociali e biomediche. Mise in luce non solo la fragilit√† di molti risultati considerati consolidati, ma anche la necessit√† di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle pratiche scientifiche √® tuttora in corso.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#la-probabilit√†-inversa",
    "href": "chapters/chapter_6/05_crisis.html#la-probabilit√†-inversa",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.4 La Probabilit√† Inversa",
    "text": "71.4 La Probabilit√† Inversa\nLa crisi della replicazione in psicologia e in altre scienze ha radici profonde, che vanno oltre le pratiche di ricerca individuali. Sebbene si possano identificare cause immediate come la pressione a pubblicare (‚Äúpublish or perish‚Äù), la ricerca della novit√† a tutti i costi, e incentivi accademici distorti, il problema fondamentale risiede nell‚Äôapproccio statistico stesso utilizzato dalla maggior parte degli scienziati.\nPer comprendere meglio, dobbiamo tornare alle basi della statistica inferenziale. L‚Äôapproccio frequentista, dominante nella ricerca scientifica, si basa su probabilit√† di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilit√† di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso ‚Äúp-value‚Äù √® un esempio di questa logica: esso indica la probabilit√† di ottenere risultati estremi quanto o pi√π estremi di quelli osservati, supponendo che l‚Äôipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto √® probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una ‚Äúprobabilit√† inferenziale‚Äù, cio√® la probabilit√† che l‚Äôipotesi sia corretta dati i risultati ottenuti.\nQui entra in gioco l‚Äôapproccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilit√† inferenziale. L‚Äôapproccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le ‚Äúprior‚Äù) relative all‚Äôipotesi in esame.\nLa differenza tra questi due approcci √® cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l‚Äôipotesi nulla √® vera, l‚Äôapproccio bayesiano ci fornisce la probabilit√† che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L‚Äôuso esclusivo dell‚Äôapproccio frequentista pu√≤ portare a sovrastimare la forza delle evidenze a favore di un‚Äôipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significativit√† statistica, rendendo pi√π difficile dichiarare un risultato ‚Äúsignificativo‚Äù.\nRichiedere la preregistrazione delle ipotesi per prevenire l‚ÄôHARKing (Hypothesizing After Results are Known).\nFar s√¨ che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo ‚Äúpositivi‚Äù o ‚Äúnuovi‚Äù.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell‚Äôinterpretazione delle evidenze statistiche. L‚Äôadozione di un approccio bayesiano offre una soluzione pi√π radicale, fornendo un quadro pi√π completo e realistico della forza delle evidenze a favore o contro un‚Äôipotesi scientifica.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#guardare-i-dati",
    "href": "chapters/chapter_6/05_crisis.html#guardare-i-dati",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.5 Guardare i Dati",
    "text": "71.5 Guardare i Dati\nApparentemente, l‚Äôinnocua pratica di dare un‚Äôocchiata ai risultati mentre vengono raccolti pu√≤ cambiare enormemente la probabilit√† di ottenere un risultato statisticamente significativo. Nella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione Normale di partenza. Di conseguenza, l‚Äô‚Äúipotesi nulla‚Äù √® vera: non c‚Äô√® differenza tra le medie delle popolazioni di partenza. Tuttavia, a causa della variabilit√† campionaria, il p-valore √® fortemente influenzato da ogni singola osservazione che viene aggiunta al campione.\n\ndef simulate_t_tests(seed, max_sample_size, mu=0, sigma=1):\n    # Imposta il seme per la riproducibilit√†\n    np.random.seed(seed)\n\n    # Intervallo di grandezza campionaria\n    sample_sizes = range(2, max_sample_size + 1, 2)\n    p_values = []\n\n    # Genera due campioni grandi iniziali da una distribuzione normale\n    full_sample1 = np.random.normal(mu, sigma, max_sample_size)\n    full_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n    # Simulazione\n    for n in sample_sizes:\n        # Estrai sottoinsiemi incrementali dai campioni completi\n        sample1 = full_sample1[:n]\n        sample2 = full_sample2[:n]\n\n        # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n        t_stat, p_value = ttest_ind(sample1, sample2)\n        p_values.append(p_value)\n\n    color_fill = \"#b97c7c\"\n    color_edge = \"#8f2727\"\n\n    # Crea il grafico del p-valore in funzione della grandezza campionaria\n    plt.plot(sample_sizes, p_values, marker=\"\", linestyle=\"-\", color=color_fill)\n    plt.axhline(y=0.05, color=color_edge, linestyle=\"--\", label=\"Significativit√† a 0.05\")\n    plt.xlabel(\"Grandezza Campionaria\")\n    plt.ylabel(\"P-valore\")\n    plt.title(\"P-valore in funzione della grandezza campionaria\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nNelle due simulazioni seguenti (si veda Lakens 2015), osserviamo come il p-valore cambia progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). √à evidente come il p-valore vari drasticamente quando nuove osservazoni vengono aggiunte ai campioni. Si noti inoltre che, per alcune configurazioni dei due campioni, il p-valore scende al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato ‚Äústatisticamente significativo‚Äù. Tuttavia, questa simulazione non mostra altro che rumore: i due campioni sono stati estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed=12, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\n\nsimulate_t_tests(seed=42, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\nL‚Äôapproccio frequentista presenta una limitazione fondamentale: ogni test statistico considera esclusivamente i dati osservati nell‚Äôesperimento in corso, ignorando le conoscenze accumulate in precedenza. Questa pratica rende il processo decisionale estremamente volatile, poich√©, teoricamente, ad ogni nuovo studio si ‚Äúdimentica‚Äù tutta l‚Äôinformazione derivante dagli studi precedenti.\n\n71.5.1 Analisi Bayesiana\nL‚Äôapproccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cio√®, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l‚Äôinformazione a priori (ci√≤ che sapevamo prima dell‚Äôesperimento) con la verosimiglianza (ci√≤ che i dati ci dicono). Questo equilibrio √® particolarmente prezioso quando i dati sono deboli o contengono molto rumore. In tali situazioni, l‚Äôinformazione a priori assume un ruolo pi√π rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l‚Äôanalisi bayesiana dei dati simulati in precedenza. Come indicato dalla figura sopra, utilizzando un generatore di numeri casuali con un ‚Äúseed‚Äù pari a 12 per simulare i dati e una numerosit√† campionaria di 50 si ottengono due campioni di dati che, se vengono analizzati con l‚Äôapproccio frequentista forniscono un risultato ‚Äústatisticamente significativo‚Äù, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilit√† al 95% compreso tra -0.52 e 1.12. Poich√© questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c‚Äô√® una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l‚Äôapproccio bayesiano √® pi√π resistente a falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l‚Äôanalisi bayesiana fornisce una rappresentazione pi√π sfumata e realistica dell‚Äôincertezza associata alle nostre conclusioni.\nInoltre, l‚Äôapproccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\nnp.random.seed(12)\nmu=0\nsigma=2\nmax_sample_size=50\nfull_sample1 = np.random.normal(mu, sigma, max_sample_size)\nfull_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n\nstan_data = {\n    \"N1\": len(full_sample1),\n    \"N2\": len(full_sample2),\n    \"y1\": full_sample1,\n    \"y2\": full_sample2,\n}\nstan_data\n\n{'N1': 50,\n 'N2': 50,\n 'y1': array([ 0.94597166, -1.36285176,  0.48487899, -3.40147127,  1.50628567,\n        -3.06944268,  0.01025416, -0.24045534, -1.61396376,  5.74363879,\n        -1.19564584,  0.94491399,  2.19191224, -2.4303376 ,  2.68471274,\n        -0.24429958,  2.02503095, -1.82773829, -2.05906041,  2.4195929 ,\n         1.00374461,  0.27769235,  1.28152223,  1.05466533, -2.30872047,\n        -4.42666696, -3.36351302, -3.5761885 , -4.43706989, -1.29486156,\n        -1.05680864, -0.07841835,  0.4299519 , -0.76871761, -0.50780816,\n         0.14650415, -1.99440767, -1.42771258,  0.07083269, -1.35589073,\n        -1.14376212, -0.21172463,  2.67166268,  0.63733058, -0.6751905 ,\n        -1.17053656, -0.22983988,  4.48363559, -6.29483304,  1.07027179]),\n 'y2': array([ 0.46498088,  1.7352239 , -2.29642543,  4.22868848,  2.00188552,\n        -0.10282999,  0.3195754 , -1.43252717,  0.10104565, -0.28667483,\n         1.88715078,  0.71528845, -0.16689841,  1.35561221,  1.11212075,\n         0.44543892, -3.05797096,  2.05842235, -2.33251752, -2.0191233 ,\n        -0.21053598,  1.02404432,  2.81545553, -3.37539266,  2.94246799,\n         3.27292581, -0.92278987, -0.40272454, -1.14363346, -1.20659823,\n        -2.67877844, -3.37930584, -0.39865468,  0.51554517,  3.65764143,\n        -2.00200309, -4.18338243,  0.29311941, -0.9327022 ,  0.71244601,\n        -0.79575947, -2.51844703, -1.37775738,  1.6052609 ,  0.54478208,\n        -1.938353  ,  1.74393624, -2.89271889, -1.07296253,  0.39584103])}\n\n\n\nstan_file = os.path.join(project_directory, \"stan\", \"two_means_diff.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n13:52:36 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n13:52:47 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n\n\ndata {\n  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\n  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\n  vector[N1] y1; // Dati del gruppo 1\n  vector[N2] y2; // Dati del gruppo 2\n}\nparameters {\n  real mu1; // Media del gruppo 1\n  real delta; // Differenza tra le medie\n  real&lt;lower=0&gt; sigma; // Deviazione standard comune\n  real&lt;lower=0&gt; nu; // Gradi di libert√† per la distribuzione t\n}\ntransformed parameters {\n  real mu2; // Media del gruppo 2\n  mu2 = mu1 + delta;\n}\nmodel {\n  // Priori\n  mu1 ~ normal(0, 5);\n  delta ~ normal(0, 2); // Priore su delta\n  sigma ~ cauchy(0, 5);\n  nu ~ gamma(2, 0.1); // Priore sulla t-student\n  \n  // Verosimiglianza\n  y1 ~ student_t(nu, mu1, sigma);\n  y2 ~ student_t(nu, mu2, sigma);\n}\ngenerated quantities {\n  real diff; // Differenza tra le medie (alias di delta per chiarezza)\n  diff = delta;\n}\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    iter_sampling=2_000,\n    iter_warmup=1_000,\n    show_progress=False,\n    show_console=False,\n)\n\n13:53:34 - cmdstanpy - INFO - CmdStan start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] start processing\n13:53:34 - cmdstanpy - INFO - Chain [2] start processing\n13:53:34 - cmdstanpy - INFO - Chain [3] start processing\n13:53:34 - cmdstanpy - INFO - Chain [4] start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] done processing\n13:53:34 - cmdstanpy - INFO - Chain [2] done processing\n13:53:34 - cmdstanpy - INFO - Chain [4] done processing\n13:53:34 - cmdstanpy - INFO - Chain [3] done processing\n13:53:34 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nConsider re-running with show_console=True if the above output is unclear!\n\n\n\naz.summary(\n    fit,\n    var_names=[\"mu1\", \"mu2\", \"delta\"],\n    round_to=2,\n    hdi_prob=0.95\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu1\n-0.43\n0.30\n-1.03\n0.15\n0.00\n0.0\n4961.74\n4696.27\n1.0\n\n\nmu2\n-0.15\n0.30\n-0.73\n0.42\n0.00\n0.0\n9396.35\n6530.40\n1.0\n\n\ndelta\n0.28\n0.42\n-0.52\n1.12\n0.01\n0.0\n4850.37\n5211.27\n1.0\n\n\n\n\n\n\n\n\n\n# Estrai i campioni di delta\ndelta_samples = fit.stan_variable(\"delta\")\n\n# Disegna la distribuzione a posteriori di delta\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(delta_samples, bins=30, density=True, alpha=0.75, color=color_fill)\nplt.axvline(\n    np.mean(delta_samples),\n    color=color_edge,\n    linestyle=\"--\",\n    label=f\"Mean: {np.mean(delta_samples):.2f}\",\n)\nplt.xlabel(\"delta\")\nplt.ylabel(\"Density\")\nplt.title(\"Posterior distribution of delta\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "href": "chapters/chapter_6/05_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.6 Il Giardino dei Sentieri che si Biforcano",
    "text": "71.6 Il Giardino dei Sentieri che si Biforcano\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti. Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: ‚ÄúGli studenti appassionati di cucina hanno una maggiore probabilit√† di essere figli unici?‚Äù o ‚ÄúGli studenti provenienti da famiglie battiste sono pi√π inclini a partecipare a club politici scolastici?‚Äù. Meehl evidenzi√≤ che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno ‚ÄúIl Giardino dei Sentieri che si Biforcano‚Äù [Garden of Forking Paths; Gelman e Loken (2013)], riferendosi ai molteplici gradi di libert√† a disposizione del ricercatore nell‚Äôanalisi dei dati. Come nell‚Äôesempio di Meehl, √® possibile esaminare le differenze intergruppo (se questo √® l‚Äôoggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno ‚Äústatisticamente significative‚Äù. Ci√≤ indica che, in quello specifico campione, quel particolare aspetto dei dati √® rilevante. Tuttavia, questa differenza ‚Äústatisticamente significativa‚Äù non sar√† necessariamente generalizzabile ad un altro campione, il quale presenter√† le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman, l‚Äôapproccio basato sul test dell‚Äôipotesi nulla si limita a ‚Äúdescrivere il rumore‚Äù. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all‚Äôavanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un‚Äôottica di inferenza statistica, questo problema √® riconducibile al concetto di ‚Äúp-hacking‚Äù o ‚Äúdata dredging‚Äù, dove l‚Äôesplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati pu√≤ portare a falsi positivi e a una sovrastima della significativit√† statistica.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#differenza-epistemologica-tra-i-due-approcci",
    "href": "chapters/chapter_6/05_crisis.html#differenza-epistemologica-tra-i-due-approcci",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.7 Differenza Epistemologica tra i Due Approcci",
    "text": "71.7 Differenza Epistemologica tra i Due Approcci\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l‚Äôipotesi nulla o non la si rifiuta. Ci√≤ implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, √® inevitabile trovare qualche effetto, anche se di minima entit√†.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell‚Äôeffetto e di fornire una distribuzione di probabilit√†. Una distribuzione di probabilit√† √® una rappresentazione grafica delle diverse possibilit√† che potrebbero verificarsi. In questo contesto, si tratta della ‚Äúprobabilit√† inversa‚Äù, ovvero della plausibilit√† dell‚Äôipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed √® il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l‚Äôaggiornamento bayesiano. Il parametro \\(\\delta\\) √® la nostra ipotesi sulla differenza tra le due medie, e l‚Äôinferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL‚Äôapproccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell‚Äôipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di ‚Äúsignificativit√† statistica‚Äù, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l‚Äôapproccio frequentista sia spesso considerato ‚Äúingenuo‚Äù da molti ricercatori, adottare l‚Äôapproccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione dell‚Äôincentivo accademico a pubblicare il maggior numero possibile di articoli, indipendentemente dalla loro qualit√†. Un principio fondamentale della ricerca √® ‚ÄúGarbage in, garbage out‚Äù. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualit√† delle misurazioni √® insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, pu√≤ trasformare la spazzatura in oro.\n\n\n\n\nLakens, Dani√´l. 2015. ¬´On the challenges of drawing conclusions from p-values just below 0.05¬ª. PeerJ 3: e1142.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#garbage-in-garbage-out",
    "href": "chapters/chapter_6/05_crisis.html#garbage-in-garbage-out",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.7 Garbage In, Garbage Out",
    "text": "71.7 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l‚Äôipotesi nulla o non la si rifiuta. Ci√≤ implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, √® inevitabile trovare qualche effetto, anche se di minima entit√†.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell‚Äôeffetto e di fornire una distribuzione di probabilit√†. Una distribuzione di probabilit√† √® una rappresentazione grafica delle diverse possibilit√† che potrebbero verificarsi. In questo contesto, si tratta della ‚Äúprobabilit√† inversa‚Äù, ovvero della plausibilit√† dell‚Äôipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed √® il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l‚Äôaggiornamento bayesiano. Il parametro \\(\\delta\\) √® la nostra ipotesi sulla differenza tra le due medie, e l‚Äôinferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL‚Äôapproccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell‚Äôipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di ‚Äúsignificativit√† statistica‚Äù, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l‚Äôapproccio frequentista sia spesso considerato ‚Äúingenuo‚Äù da molti ricercatori, adottare l‚Äôapproccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione dell‚Äôincentivo accademico a pubblicare il maggior numero possibile di articoli, indipendentemente dalla loro qualit√†. Un principio fondamentale della ricerca √® ‚ÄúGarbage in, garbage out‚Äù. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualit√† delle misurazioni √® insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, pu√≤ trasformare la spazzatura in oro.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#feeling-the-future",
    "href": "chapters/chapter_6/05_crisis.html#feeling-the-future",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "71.1 Feeling the Future",
    "text": "71.1 Feeling the Future\nNel 2011 si verific√≤ una serie di eventi che scosse profondamente la comunit√† scientifica, sebbene non tutti ne presero immediatamente coscienza. La cosiddetta ‚Äúcrisi della replicazione‚Äù probabilmente non influenz√≤ la vita quotidiana della maggior parte delle persone. Persino gran parte degli scienziati, compresi molti psicologi il cui campo fu il pi√π colpito, continu√≤ a lungo ad operare come se nulla fosse accaduto. Ciononostante, il 2011 si rivel√≤ un anno di fondamentale importanza per la scienza. Per gli scienziati dotati anche solo di una basilare comprensione della statistica e pi√π interessati alla ricerca della verit√† che all‚Äôaccumulo di citazioni o all‚Äôavanzamento di carriera, quell‚Äôanno assunse le caratteristiche di un vero e proprio ‚ÄúAnno Zero‚Äù.\nIn primo luogo, un eminente scienziato fu scoperto a falsificare i propri dati. Diederik Stapel, una stella nascente della psicologia sociale e professore presso l‚ÄôUniversit√† di Tilburg nei Paesi Bassi, aveva attirato l‚Äôattenzione con una serie di articoli sensazionali: uno suggeriva che mangiare carne rendeva le persone pi√π antisociali; un altro sosteneva che le persone sono pi√π inclini al razzismo se l‚Äôambiente circostante √® pieno di rifiuti. Tuttavia, si scopr√¨ che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti n√© raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati.\nNel marzo 2011, Daryl Bem, psicologo sociale della Cornell University, pubblic√≤ uno studio intitolato ‚ÄúFeeling the Future‚Äù che avrebbe scosso le fondamenta della psicologia sociale. Lo studio di Bem si inseriva nella tradizione degli esperimenti di ‚Äúpriming‚Äù, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ‚Äô70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio √® lo studio di John Bargh del 1996, che dimostr√≤ come l‚Äôesposizione a parole associate all‚Äôet√† avanzata inducesse i soggetti a camminare pi√π lentamente. Un altro studio del 2006 rivel√≤ che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilit√† della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali. Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in met√† delle prove, il priming avveniva dopo che i soggetti avevano gi√† visto e valutato l‚Äôimmagine.\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano pi√π veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l‚Äôipotesi nulla.\nBem interpret√≤ questi risultati come prova della chiaroveggenza, una conclusione che suscit√≤ notevoli controversie e ridicolizz√≤ la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l‚Äôordine temporale invertito, mostrarono risultati altrettanto significativi.\nQuesti risultati ponevano la comunit√† scientifica di fronte a un dilemma: accettare l‚Äôesistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validit√† dei suoi risultati come prova dell‚Äôesistenza di capacit√† precognitive.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_6/05_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_6/05_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "71¬† La Crisi della Replicabilit√† dei Risultati della Ricerca",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jul 29 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, Andrew, e Eric Loken. 2013. ¬´The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ‚Äúfishing expedition‚Äù or ‚Äúp-hacking‚Äù and the research hypothesis was posited ahead of time¬ª. Department of Statistics, Columbia University 348 (1-17): 3.\n\n\nLakens, Dani√´l. 2015. ¬´On the challenges of drawing conclusions from p-values just below 0.05¬ª. PeerJ 3: e1142.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La Crisi della Replicabilit√† dei Risultati della Ricerca</span>"
    ]
  }
]