[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analisi dei dati per psicologi",
    "section": "",
    "text": "Benvenuti\nQuesto sito web √® dedicato al materiale didattico dell‚Äôinsegnamento di Psicometria (A.A. 2024/2025), rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell‚ÄôUniversit√† degli Studi di Firenze.\nIl corso √® strutturato per fornire agli studenti una formazione teorica e pratica approfondita nell‚Äôinferenza statistica, enfatizzando particolarmente le applicazioni pratiche attraverso la programmazione. Attraverso esercitazioni guidate, gli studenti impareranno a manipolare e analizzare dati psicologici utilizzando Python, acquisendo cos√¨ le competenze necessarie per prendere decisioni informate e realizzare interpretazioni precise nei loro progetti di modellazione.\nIl programma copre un ampio spettro di tecniche, partendo dall‚Äôanalisi descrittiva per arrivare fino ai modelli gerarchici avanzati. Si pone un forte accento sull‚Äôinferenza causale, approcciata da una prospettiva bayesiana, includendo l‚Äôuso di Grafi Aciclici Diretti (DAG) per esplorare in modo approfondito le relazioni causali. L‚Äôintento √® di andare oltre i limiti della modellazione lineare tradizionale, mostrando come integrare efficacemente i modelli psicologici avanzati nell‚Äôanalisi statistica.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#informazioni-sullinsegnamento",
    "href": "index.html#informazioni-sullinsegnamento",
    "title": "Analisi dei dati per psicologi",
    "section": "Informazioni sull‚Äôinsegnamento",
    "text": "Informazioni sull‚Äôinsegnamento\nCodice: B000286 - PSICOMETRIA  Modulo: B000286 - PSICOMETRIA (Cognomi L-Z)  Corso di laurea: Scienze e Tecniche Psicologiche  Anno Accademico: 2024-2025  Materiali didattici: √à sufficiente disporre di un laptop/computer funzionante. Tutti i materiali didattici e il software necessario sono forniti gratuitamente a tutti gli studenti, senza richiedere alcun acquisto. Calendario: Il corso si terr√† dal 3 marzo al 31 maggio 2025. Orario delle lezioni: Le lezioni si svolgeranno il luned√¨ e il marted√¨ dalle 8:30 alle 10:30 e il gioved√¨ dalle 11:30 alle 13:30. Luogo: Le lezioni si terranno presso il Plesso didattico La Torretta. Modalit√† di svolgimento della didattica: Le lezioni ed esercitazioni saranno svolte in modalit√† frontale.\n\n\n\n\n\n\nIl presente sito web costituisce l‚Äôunica fonte ufficiale da consultare per ottenere informazioni sul programma dell‚Äôinsegnamento B000286 - PSICOMETRIA (Cognomi L-Z) A.A. 2024-2025 e sulle modalit√† d‚Äôesame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Analisi dei dati per psicologi",
    "section": "Syllabus",
    "text": "Syllabus\nIl Syllabus pu√≤ essere scaricato utilizzando questo link.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html",
    "href": "chapters/chapter_1/00_prelims.html",
    "title": "1¬† Preliminari",
    "section": "",
    "text": "1.1 Iniziare ad Usare Python üêç\nIn questo corso, utilizzeremo Python all‚Äôinterno di un ambiente Jupyter Notebook. L‚Äôappendice Appendice A fornisce le istruzioni per installare Jupyter Notebook sul vostro computer.\nIn alternativa, √® possibile scrivere uno script Python in un file con estensione .py, il quale pu√≤ essere eseguito tramite il comando python nome_file.py dalla linea di comando.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#jupyter-notebook",
    "href": "chapters/chapter_1/00_prelims.html#jupyter-notebook",
    "title": "1¬† Preliminari",
    "section": "1.2 Jupyter Notebook",
    "text": "1.2 Jupyter Notebook\nI Jupyter Notebook offrono un ambiente interattivo in cui √® possibile eseguire il codice suddiviso in celle. Sebbene sia possibile eseguire il codice nelle celle in qualsiasi ordine, √® considerata una pratica consigliata eseguirle in sequenza al fine di prevenire errori e garantire una corretta esecuzione del codice.\nI Jupyter Notebook supportano due tipi di celle:\n\nCelle di Testo: Queste celle consentono di scrivere testo formattato utilizzando la sintassi Markdown. Questo permette agli autori di inserire del testo descrittivo, comprese immagini, formule in formato \\(\\LaTeX\\), tabelle e altro ancora. Le celle di testo facilitano la documentazione del processo di analisi dei dati in modo chiaro e comprensibile.\nCelle di Codice: Le celle di codice consentono di scrivere e eseguire codice Python. Il codice pu√≤ essere eseguito facendo clic sul triangolo situato a sinistra di ogni cella. Diverse celle possono contenere istruzioni diverse e possono essere eseguite in sequenza. √à importante notare che una funzione definita in una cella precedente pu√≤ essere utilizzata solo se la cella precedente √® stata eseguita.\n\nQui sotto abbiamo una cella di codice.\n\n# Make plot\n%matplotlib inline\nimport math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntheta = np.arange(0, 4 * math.pi, 0.1)\neight = plt.figure()\naxes = eight.add_axes([0, 0, 1, 1])\naxes.plot(0.5 * np.sin(theta), np.cos(theta / 2))\n\n\n\n\n\n\n\n\nQuando lavori con il notebook, puoi essere all‚Äôinterno di una cella, digitando i suoi contenuti, oppure al di fuori delle celle, muovendoti nel notebook.\nQuando sei all‚Äôinterno di una cella, premi Esc per uscirne. Quando ti muovi al di fuori delle celle, premi Invio per entrare.\n\nFuori da una cella:\n\nUsa i tasti freccia per muoverti.\nPremi Shift+Invio per eseguire il codice nel blocco.\n\nAll‚Äôinterno di una cella:\n\nPremi Tab per suggerire completamenti delle variabili.\n\n\nIl nome \"Jupyter\" deriva dalle tre principali lingue di programmazione supportate: Julia, Python e R. Tuttavia, √® possibile utilizzare i Jupyter Notebook con molte altre lingue di programmazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#esecuzione-locale-o-su-colab",
    "href": "chapters/chapter_1/00_prelims.html#esecuzione-locale-o-su-colab",
    "title": "1¬† Preliminari",
    "section": "1.3 Esecuzione Locale o su Colab",
    "text": "1.3 Esecuzione Locale o su Colab\nI Jupyter Notebook possono essere eseguiti sia in locale, sul vostro computer, che su un server remoto, come Google Colab. Questa flessibilit√† permette agli utenti di accedere ai propri notebook da qualsiasi dispositivo connesso a Internet e di condividere agevolmente il proprio lavoro con altri.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#kernel-nei-jupyter-notebook",
    "href": "chapters/chapter_1/00_prelims.html#kernel-nei-jupyter-notebook",
    "title": "1¬† Preliminari",
    "section": "1.4 Kernel nei Jupyter Notebook",
    "text": "1.4 Kernel nei Jupyter Notebook\nI Jupyter Notebook sono strumenti che agevolano la programmazione in Python grazie a un componente essenziale: il kernel. Quest‚Äôultimo funge da motore di esecuzione per il codice Python presente nelle celle dei notebook. Ogni volta che eseguite una cella, il suo contenuto viene processato dal kernel. La caratteristica pi√π significativa del kernel √® la sua capacit√† di preservare lo stato delle variabili e delle funzioni tra le diverse celle. In pratica, ci√≤ significa che potete definire variabili o funzioni in una cella e poi riutilizzarle in celle successive. Questa interattivit√† facilita l‚Äôesecuzione iterativa del codice e offre un modo dinamico per esplorare i dati.\nDurante l‚Äôinstallazione di Jupyter Notebook, di norma ricevete anche IPython, un kernel ottimizzato per Python.\nSi noti che il kernel Python deve essere installato all‚Äôinterno di un ambiente di sviluppo dedicato noto come ‚Äúambiente virtuale‚Äù (per ulteriori dettagli, si veda {ref}sec-virtual-environment). Questo ambiente svolge un ruolo fondamentale nel separare e isolare le librerie e le dipendenze necessarie per il kernel. Ci√≤ aiuta a evitare conflitti tra diverse configurazioni e garantisce il corretto funzionamento del codice nel contesto desiderato. L‚Äôutilizzo di ambienti specifici risulta particolarmente vantaggioso nei progetti che richiedono versioni particolari di librerie.\nIn questo insegnamento, faremo ampio uso della funzionalit√† conda, inclusa nell‚Äôinstallazione di Anaconda, per la gestione di questi ambienti. conda mette a disposizione funzioni utili per la creazione, la gestione e l‚Äôattivazione di ambienti separati, ciascuno con le sue configurazioni e dipendenze uniche. Questa capacit√† semplifica notevolmente la transizione tra diversi ambienti, garantendo che ogni progetto o kernel disponga delle risorse necessarie per operare in modo efficiente e senza interferenze.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/00_prelims.html#visual-studio-code",
    "href": "chapters/chapter_1/00_prelims.html#visual-studio-code",
    "title": "1¬† Preliminari",
    "section": "1.5 Visual Studio Code",
    "text": "1.5 Visual Studio Code\nIl modo pi√π semplice di usare un Jupyter Notebook √® all‚Äôinterno di Visual Studio Code. Dopo aver installato Visual Studio Code, √® necessario installare l‚Äôestensione Python per sfruttare le funzionalit√† specifiche per Python, inclusa la capacit√† di lavorare con Jupyter Notebook.\n\nIn Visual Studio Code, si clicca sull‚Äôicona delle estensioni (quadrati che si intersecano) nella barra laterale a sinistra.\nSi cerca ‚ÄúPython‚Äù nella barra di ricerca e si seleziona l‚Äôestensione ufficiale offerta da Microsoft.\nSi clicca su ‚ÄúInstall‚Äù.\n\nUna volta completate le installazioni, siete pronti per creare il vostro primo Jupyter Notebook in VS Code.\n\nSi apre Visual Studio Code.\nSi clicca su File &gt; New File.\nSi preme Ctrl+Shift+P per aprire la Palette dei Comandi.\nSi digita ‚ÄúJupyter‚Äù e si seleziona Jupyter: Create New Blank Notebook.\nSi aprir√† un nuovo notebook dove si pu√≤ iniziare a scrivere il codice Python nelle celle.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html",
    "href": "chapters/chapter_1/01_python_1.html",
    "title": "2¬† Python (1)",
    "section": "",
    "text": "2.1 Scrivere Codice con il Supporto dei LLM\nI Large Language Models (LLM), come GPT-4, stanno rivoluzionando non solo molte applicazioni legate alla creazione di testi in linguaggio naturale, ma stanno anche aprendo nuove e interessanti potenzialit√† nel campo della programmazione e dell‚Äôanalisi dei dati. La programmazione, con le sue regole esplicite e la sintassi strutturata, si adatta particolarmente bene alle capacit√† di riconoscimento dei pattern degli LLM. A differenza dei linguaggi umani, ricchi di significati ambigui ed espressioni idiomatiche, i linguaggi di programmazione sono rigorosi e precisi.\nNel contesto dell‚Äôanalisi dei dati, √® naturale unire le capacit√† degli LLM con la potenza computazionale dei linguaggi statistici come R o di programmazione come Python. Sono gi√† stati pubblicati libri su come integrare le capacit√† degli LLM con l‚Äôanalisi dei dati Matter (2025), e sta emergendo una nuova branca dell‚Äôingegneria dedicata allo sviluppo dei prompt pi√π efficaci per l‚Äôuso con gli LLM. Pertanto, il problema non √® se utilizzare gli LLM a supporto della programmazione, ma come farlo nel modo pi√π efficace.\nUn principio fondamentale √® che, maggiore √® la conoscenza delle regole sintattiche di un linguaggio di programmazione, maggiore sar√† l‚Äôefficacia dell‚Äôuso degli LLM per scopi di analisi dei dati. Quindi, anche se i problemi di programmazione richiesti in questo corso di analisi dei dati sono relativamente semplici rispetto alle capacit√† degli LLM, gli utenti che utilizzeranno gli LLM a supporto delle proprie attivit√† di programmazione trarranno certamente beneficio dalla conoscenza delle regole sintattiche del linguaggio di programmazione utilizzato, che nel nostro caso sar√† principalmente Python (esamineremo anche degli esempi in R).\nGli LLM si basano sul concetto di ‚Äúpredizione del prossimo token‚Äù. Questo significa che sono addestrati per prevedere la parola o il carattere successivo in una sequenza, basandosi su quelli precedenti. Questo principio √® fondamentale per la capacit√† degli LLM di generare codice e per il loro utilizzo nel migliorare i flussi di lavoro di analisi dei dati in Python o R. Oltre a miliardi di parole provenienti da testi comuni (siti web, libri, articoli di riviste), gli LLM di OpenAI, come GPT-4, sono stati addestrati su un vasto corpus di codice open-source e discussioni sul codice presenti su piattaforme come Stack Overflow. Questo consente loro di generare codice sintatticamente e semanticamente corretto in molte situazioni.\nGli LLM possono assistere in diversi compiti di programmazione in Python e R, tra cui l‚Äôidentificazione degli errori negli script, la scrittura di codice a partire da descrizioni in linguaggio naturale, l‚Äôottimizzazione del codice, la generazione di documentazione e la creazione di casi di test.\nAcquisire conoscenze sull‚Äôuso pratico dell‚ÄôAI/LLM nelle attivit√† di programmazione e analisi √® pi√π di una tendenza: √® una necessit√† nel mercato del lavoro attuale. I professionisti che possono utilizzare efficacemente l‚ÄôAI/LLM per migliorare le loro competenze di programmazione e integrare questi strumenti in Python e R avranno un vantaggio competitivo. Man mano che l‚ÄôAI e gli LLM diventano sempre pi√π diffusi nell‚Äôindustria e nel mondo accademico, la domanda per queste competenze continuer√† a crescere.\nL‚Äôobiettivo di questo capitolo √® fornire una panoramica della sintassi di Python e delle principali funzioni di pacchetti come Pandas, Numpy e Matplotlib, utili per la data science. Python √® un linguaggio di programmazione versatile e di facile lettura, adatto a numerosi usi. Anche se il suo nome √® un omaggio al gruppo comico Monty Python, apprendere Python richiede tempo, pratica e impegno.\nQuesta guida si concentra sull‚Äôinsegnamento dei principi di base della programmazione, piuttosto che sui dettagli tecnici. Con questa conoscenza, gli studenti saranno pi√π capaci di risolvere problemi specifici e di cercare autonomamente la sintassi appropriata per il problema da risolvere.\nNel mondo attuale, in cui l‚Äôintelligenza artificiale riveste un ruolo sempre pi√π centrale, √® fondamentale sviluppare la capacit√† di pensare in modo algoritmico. Questa competenza va oltre la mera programmazione e offre un approccio strutturato per risolvere problemi complessi. Sebbene gli LLM siano in grado di risolvere molti dei problemi di programmazione che affronteremo in questo corso, una comprensione approfondita dei principi della programmazione rimane essenziale per interpretare, modificare o migliorare le soluzioni proposte da tali sistemi.\nIn conclusione, anche nell‚Äôera dell‚ÄôIA, una solida comprensione dei fondamenti della programmazione √® indispensabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#espressioni-e-operatori",
    "href": "chapters/chapter_1/01_python_1.html#espressioni-e-operatori",
    "title": "2¬† Python (1)",
    "section": "2.2 Espressioni e Operatori",
    "text": "2.2 Espressioni e Operatori\nI programmi sono insiemi di espressioni che elaborano dati per fornire istruzioni specifiche al computer. Ad esempio, in Python, l‚Äôoperazione di moltiplicazione si esegue utilizzando l‚Äôasterisco (*) tra due numeri. Quando si incontra un‚Äôespressione come 3 * 4, il computer la valuta e produce il risultato, che pu√≤ essere visualizzato in una cella successiva di un notebook Jupyter.\nLe regole sintattiche in un linguaggio di programmazione come Python sono stringenti. Ad esempio, non √® consentito inserire due simboli asterisco in sequenza senza un operando intermedio. Qualora un‚Äôespressione violi queste norme sintattiche, il sistema ritorner√† un ‚ÄúSyntaxError‚Äù, un errore che indica la non conformit√† alle regole del linguaggio. Per esempio\n3 * * 4\nrestituisce:\n Cell In[3], line 1\n    3 * * 4\n        ^\nSyntaxError: invalid syntax\nAnche piccole modifiche in un‚Äôespressione possono cambiarne completamente il significato. Nell‚Äôesempio successivo, lo spazio tra i due asterischi * √® stato rimosso. Tuttavia, poich√© gli asterischi compaiono tra due espressioni numeriche, l‚Äôespressione √® corretta e indica l‚Äôelevamento a potenza del primo numero al secondo: 3 elevato alla quarta potenza (\\(3 \\times 3 \\times 3 \\times 3\\)). In programmazione, simboli come * e ** sono noti come ‚Äúoperatori‚Äù, mentre i valori su cui agiscono sono denominati ‚Äúoperandi‚Äù.\n\n3 ** 4\n\n81\n\n\nLa tabella seguente elenca i principali operatori binari utilizzati in Python, chiamati cos√¨ perch√© agiscono su due operandi.\n\n\n\nOperazione\nOperatore\n\n\n\n\naddizione\n+\n\n\nsottrazione\n-\n\n\nmoltiplicazione\n*\n\n\ndivisione (reale)\n/\n\n\ndivisione (intera; rimuove il resto)\n//\n\n\nresto (modulo)\n%\n\n\nelevamento a potenza\n**\n\n\n\nLe due operazioni che potrebbero essere meno familiari sono % (trova il resto di una divisione) e // (esegui una divisione scartando il resto).\nPer esempio, la divisione intera (scartando il resto) di 11/2 produce 5.\n\n11 // 2\n\n5\n\n\nIl resto di 11/2 √® 1.\n\n11 % 2\n\n1\n\n\nUsando gli operatori che abbiamo elencato in precedenza possiamo usare Python come un calcolatore.\n\nprint(\"4 + 2 √®\", 4 + 2)\nprint(\"4 - 2 √®\", 4 - 2)\nprint(\"4 * 2 √®\", 4 * 2)\nprint(\"4 / 2 √®\", 4 / 2)\nprint(\"4 ** 2 √®\", 4**2)\nprint(\"9 % 4 √®\", 9 % 4)\nprint(\"9 // 4 √®\", 9 // 4)\n\n4 + 2 √® 6\n4 - 2 √® 2\n4 * 2 √® 8\n4 / 2 √® 2.0\n4 ** 2 √® 16\n9 % 4 √® 1\n9 // 4 √® 2\n\n\nL‚Äôapplicazione degli operatori aritmetici in Python dipende dalle seguenti regole di precedenza degli operatori, che sono analoghe a quelle usate in algebra.\n\nLe espressioni tra parentesi vengono valutate per prime.\nSuccessivamente si valutano gli elevamenti a potenza.\nIn seguito, si valutano moltiplicazioni, divisioni e moduli.\nPer ultime vengono valutate somme e sottrazioni.\n\n\n1 + 2 * 3 * 4 * 5 / 6 ** 3 + 7 + 8 - 9 + 10\n\n17.555555555555557\n\n\n\n1 + 2 * (3 * 4 * 5 / 6) ** 3 + 7 + 8 - 9 + 10\n\n2017.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#variabili",
    "href": "chapters/chapter_1/01_python_1.html#variabili",
    "title": "2¬† Python (1)",
    "section": "2.3 Variabili",
    "text": "2.3 Variabili\nQuando generiamo un risultato, la risposta viene visualizzata ma non viene memorizzata da nessuna parte, come abbiamo visto negli esempi precedenti. Se vogliamo recuperare quel risultato, dobbiamo memorizzarlo. Lo mettiamo in un oggetto, e diamo un nome a quell‚Äôoggetto. Questa √® una variabile.\nPer creare una variabile facciamo uso di un‚Äôistruzione di assegnazione. In un‚Äôistruzione di assegnazione, si specifica un nome seguito dal simbolo di uguale (=) e dall‚Äôespressione che si desidera assegnare a tale nome. L‚Äôoperazione di assegnazione consiste nell‚Äôassociare il valore dell‚Äôespressione a destra del simbolo di uguale al nome a sinistra. Da quel momento in poi, ogni volta che il nome viene utilizzato in un‚Äôespressione, il valore associato durante l‚Äôassegnazione viene utilizzato al suo posto.\n\na = 10\nb = 20\na + b\n\n30\n\n\n\na = 1/4\nb = 2 * a\nb\n\n0.5\n\n\n\nmy_var = 100\nconst = 3\n\nmy_var * const\n\n300\n\n\nIn Python, ogni ‚Äúoggetto‚Äù √® un‚Äôarea di memoria nel computer. Una ‚Äúvariabile‚Äù funge da etichetta che fa riferimento a quest‚Äôarea. Se un oggetto non ha pi√π etichette (ovvero, non ci sono pi√π variabili che lo referenziano), i dati contenuti nell‚Äôoggetto diventano inaccessibili. Il Garbage Collector del linguaggio si occuper√† di rilevare questi oggetti non referenziati e liberare la memoria, permettendo che venga riutilizzata per nuovi dati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#nomi-delle-variabili",
    "href": "chapters/chapter_1/01_python_1.html#nomi-delle-variabili",
    "title": "2¬† Python (1)",
    "section": "2.4 Nomi delle Variabili",
    "text": "2.4 Nomi delle Variabili\nI nomi delle variabili in Python possono contenere caratteri alfanumerici da a-z, A-Z, 0-9 e alcuni caratteri speciali come _. I nomi delle variabili normali devono iniziare con una lettera. I nomi delle variabili non possono contenere uno spazio; invece, √® comune utilizzare il carattere _ per sostituire ogni spazio. Sta al programmatore scegliere nomi facili da interpretare.\nPer convenzione, i nomi delle variabili iniziano con una lettera minuscola, mentre i nomi delle classi iniziano con una lettera maiuscola.\nInoltre, ci sono una serie di parole chiave (keyword) in Python che non possono essere utilizzate come nomi di variabili. Queste parole chiave sono:\n\nimport keyword\nprint(*keyword.kwlist, sep=\"\\n\")\n\nFalse\nNone\nTrue\nand\nas\nassert\nasync\nawait\nbreak\nclass\ncontinue\ndef\ndel\nelif\nelse\nexcept\nfinally\nfor\nfrom\nglobal\nif\nimport\nin\nis\nlambda\nnonlocal\nnot\nor\npass\nraise\nreturn\ntry\nwhile\nwith\nyield\n\n\nSi presti attenzione alla parola chiave ‚Äúlambda‚Äù, che potrebbe facilmente essere un nome di variabile naturale in un programma scientifico. Tuttavia, essendo una parola chiave, non pu√≤ essere utilizzata come nome di variabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#tipologie-di-dati-in-python",
    "href": "chapters/chapter_1/01_python_1.html#tipologie-di-dati-in-python",
    "title": "2¬† Python (1)",
    "section": "2.5 Tipologie di Dati in Python",
    "text": "2.5 Tipologie di Dati in Python\nIn Python, le variabili possono appartenere a diverse tipologie di dati, ciascuna con caratteristiche e utilizzi specifici.\n\n2.5.1 Stringhe (String)\nLe stringhe sono sequenze di caratteri, utilizzate per rappresentare testo. In Python, le stringhe possono essere create utilizzando apici singoli (' '), doppi (\" \") o tripli (''' ''' oppure \"\"\" \"\"\") per delimitare il testo. Esempi di stringhe sono:\n\"Hello, world!\"\n'Beyonce-Lemonade.txt'\n\"lemonade\"\nSi noti il risultato ottenuto quando si applica l‚Äôoperatore + a due stringhe.\n\n\"data\" + \"science\"\n\n'datascience'\n\n\n\n\"data\" + \" \" + \"science\"\n\n'data science'\n\n\nSia le virgolette singole che doppie possono essere utilizzate per creare le stringhe: ‚Äúciao‚Äù e ‚Äòciao‚Äô sono espressioni equivalenti. Tuttavia, le virgolette doppie sono spesso preferite poich√© consentono di includere virgolette singole all‚Äôinterno delle stringhe.\n\n\"Che cos'√® una parola?\"\n\n\"Che cos'√® una parola?\"\n\n\nL‚Äôespressione precedente avrebbe prodotto un SyntaxError se fosse stata racchiusa da virgolette singole.\n\n2.5.1.1 Parsing strings\nIn Python, una stringa √® concepita come una sequenza ordinata di caratteri. Grazie all‚Äôoperatore di indicizzazione, rappresentato dalle parentesi quadre [], √® possibile accedere a singoli elementi della stringa.\n√à importante ricordare che l‚Äôindicizzazione in Python parte da zero.\nL‚Äôindice del primo carattere √® [0], quello del secondo √® [1], del terzo [2], e cos√¨ via. Questa funzionalit√† consente di manipolare o consultare specifici segmenti della stringa, piuttosto che gestirla come un blocco unico.\nConsideriamo questo verso di Eugenio Montale:\n\nmy_string = \"Tendono alla chiarit√† le cose oscure\"\nprint(my_string)\n\nTendono alla chiarit√† le cose oscure\n\n\n\nmy_string[0]\n\n'T'\n\n\n\nmy_string[3]\n\n'd'\n\n\n\nlen(my_string)\n\n36\n\n\nLa stringa ‚Äúmy_string‚Äù conta 36 caratteri. Pertanto, gli indici validi per questa stringa vanno da 0 a 35. Per accedere all‚Äôultimo carattere, √® necessario utilizzare l‚Äôindice 35, che corrisponde a 36 meno 1.\n\nmy_string[35]\n\n'e'\n\n\nUn modo efficiente per ottenere l‚Äôultimo carattere √® ricorrere alla funzione len, sottraendo 1 al risultato:\n\nmy_string[len(my_string) - 1]\n\n'e'\n\n\nSi noti che len() √® una funzione. Una funzione √® un blocco di codice che esegue un‚Äôoperazione specifica. I programmatori chiamano anche gli input delle funzioni ‚Äúparametri‚Äù o ‚Äúargomenti‚Äù.\nLa funzione len prende un input e restituisce un output. L‚Äôoutput √® la lunghezza di ci√≤ che √® stato passato come input.\n\n\n2.5.1.2 Slicing strings\nOltre a estrarre caratteri individuali da una stringa, Python offre la possibilit√† di selezionare segmenti di testo attraverso la tecnica dello ‚Äúslicing‚Äù. Questo meccanismo √® simile all‚Äôindicizzazione, ma utilizza due indici separati da un carattere a due punti (:). Il primo indice indica la posizione di partenza dello ‚Äúslicing‚Äù nella stringa, mentre il secondo indice segnala il punto in cui terminare l‚Äôestrazione del segmento.\n\nmy_string[2:4]\n\n'nd'\n\n\nSe si omette il primo indice, Python utilizzer√† l‚Äôinizio della stringa; se si omette il secondo, utilizzer√† la fine della stringa.\n\nmy_string[:4]\n\n'Tend'\n\n\n\nmy_string[4:]\n\n'ono alla chiarit√† le cose oscure'\n\n\n\n\n2.5.1.3 Metodi\nA partire da una stringa esistente, si possono generare nuove stringhe mediante l‚Äôutilizzo di metodi specifici per le stringhe. Questi metodi sono essenzialmente funzioni che agiscono direttamente sull‚Äôoggetto stringa. Per invocare un metodo, basta posizionare un punto subito dopo la stringa e seguire con il nome del metodo desiderato. Ad esempio, il metodo successivo converte tutti i caratteri della stringa in maiuscole.\n\nmy_string.upper()\n\n'TENDONO ALLA CHIARIT√Ä LE COSE OSCURE'\n\n\nIl metodo my_string.title() √® utilizzato per convertire la prima lettera di ogni parola nella stringa my_string in maiuscolo, mentre rende tutte le altre lettere minuscole. In pratica, trasforma la stringa in una forma ‚Äúa titolo‚Äù, in cui ogni parola inizia con una lettera maiuscola.\n\nmy_string.title()\n\n'Tendono Alla Chiarit√† Le Cose Oscure'\n\n\n\n\n\n2.5.2 Numeri Interi (Integer)\nI numeri interi rappresentano numeri senza una componente decimale. In Python, possono essere creati assegnando un valore senza parte decimale a una variabile. Esempio di un numero intero √®:\n\nage = 20\n\n\n\n2.5.3 Numeri in Virgola Mobile (Float)\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, rappresentano numeri che hanno una componente decimale. Sono creati assegnando un valore con una parte decimale a una variabile. Esempio di un numero float √®:\n\ntemperature = 36.4\n\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, hanno una precisione limitata a circa 15-16 cifre decimali; oltre questo limite, la precisione viene persa. Nonostante questa limitazione, sono sufficienti per la maggior parte delle applicazioni.\nInoltre, √® possibile utilizzare la notazione scientifica per rappresentare numeri molto grandi o molto piccoli. In questa notazione, m * 10^n viene comunemente abbreviato come mEn, dove ‚ÄúE‚Äù rappresenta l‚Äôesponente dieci. Ad esempio, 1E9 equivale a un miliardo (\\(1 \\times 10^9\\)) e 1E-9 rappresenta un miliardesimo (\\(1 \\times 10^{-9}\\)).\n\n\n2.5.4 Valori Booleani (Boolean)\nI valori booleani possono assumere solo due stati: vero (True) o falso (False). Sono utilizzati per rappresentare le condizioni logiche e sono ottenuti attraverso espressioni di confronto. Esempio di un valore booleano √®:\n\nis_raining = False\n\nNel contesto delle operazioni aritmetiche, True √® equivalente al numero intero 1, mentre False corrisponde a 0. Questo permette di includere valori booleani in calcoli matematici. Per esempio:\n\nTrue + True + False\n\n2\n\n\nUn valore booleano viene ritornato quando si valuta un confronto. Per esempio:\n\n3 &gt; 1 + 1\n\nIl valore True indica che il confronto √® valido; Python ha confermato questo semplice fatto sulla relazione tra 3 e 1+1.\nSi noti la regola di precedenza: gli operatori &gt;, &lt;, &gt;=, &lt;=, ==, != hanno la precedenza pi√π bassa (vengono valutati per ultimi), il che significa che nell‚Äôespressione precedente viene prima valutato (1 + 1) e poi (3 &gt; 2).\n\n\n2.5.5 Operatori di confronto\nUn operatore di confronto √® un operatore che esegue un qualche tipo di confronto e restituisce un valore booleano (True oppure False). Per esempio, l‚Äôoperatore == confronta le espressioni su entrambi i lati e restituisce True se hanno gli stessi valori e False altrimenti. L‚Äôopposto di == √® !=, che si pu√≤ leggere come ‚Äònon uguale al valore di‚Äô. Gli operatori di confronto sono elencati qui sotto:\n\n\n\nConfronto\nOperatore\n\n\n\n\nMinore\n&lt;\n\n\nMaggiore\n&gt;\n\n\nMinore o uguale\n&lt;=\n\n\nMaggiore o uguale\n&gt;=\n\n\nUguale\n==\n\n\nNon uguale\n!=\n\n\n\nAd esempio:\n\na = 4\nb = 2\n\nprint(\"a &gt; b\", \"is\", a &gt; b)\nprint(\"a &lt; b\", \"is\", a &lt; b)\nprint(\"a == b\", \"is\", a == b)\nprint(\"a &gt;= b\", \"is\", a &gt;= b)\nprint(\"a &lt;= b\", \"is\", a &lt;= b)\n\nNella cella seguente si presti attenzione all‚Äôuso di = e di ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nL‚Äôoperatore = √® un‚Äôistruzione di assegnazione. Ovvero, crea un nuovo oggetto. L‚Äôoperatore == valuta invece una condizione logica e ritorna un valore booleano.\nUn‚Äôespressione pu√≤ contenere pi√π confronti e tutti devono essere veri affinch√© l‚Äôintera espressione sia vera. Ad esempio:\n\n1 &lt; 1 + 1 &lt; 3\n\n\n\n2.5.6 Tipizzazione Dinamica in Python\nPython √® un linguaggio con tipizzazione dinamica, il che significa che il tipo di una variabile √® determinato dal valore che le viene assegnato durante l‚Äôesecuzione del programma e non necessita di essere dichiarato esplicitamente.\nPer identificare il tipo di una variabile o del risultato di un‚Äôespressione, Python mette a disposizione la funzione type(). Questa funzione, quando chiamata con una variabile o un‚Äôespressione come argomento, restituisce il tipo di dati corrispondente.\nNell‚Äôesempio seguente il programma stamper√† &lt;class 'str'&gt;, indicando che x √® una variabile di tipo ‚Äústringa‚Äù.\n\nx = \"hello\"\nprint(type(x))\n\n&lt;class 'str'&gt;\n\n\nApplichiamo la funzione type() alle altre variabili che abbiamo definito in precedenza.\n\nage = 20\nprint(type(age))\n\n&lt;class 'int'&gt;\n\n\n\ntemperature = 36.4\nprint(type(temperature))\n\n&lt;class 'float'&gt;\n\n\n\nis_raining = False\nprint(type(is_raining))\n\n&lt;class 'bool'&gt;\n\n\n\n\n2.5.7 Operatori Booleani\nGli operatori booleani (o operatori logici) confrontano espressioni (non valori) e ritornano un valore booleano. Python ha tre operatori logici:\n\nand ‚Äì Ritorna True solo se entrambi le espressioni sono vere, altrimenti ritorna False\nor ‚Äì Ritorna True se almeno una delle due espressioni √® vera, altrimenti ritorna False.\nnot ‚Äì Ritorna True se l‚Äôespressione √® falsa, altrimenti ritorna False.\n\nAd esempio:\n\na = 2\nb = 3\n\n(a + b &gt; a) and (a + b &gt; b)\n\nTrue\n\n\nNella cella sopra le parentesi tonde sono opzionali ma facilitano la lettura.\nL‚Äôoperatore and restituisce True solo se entrambe le condizioni booleane sono vere. Ad esempio, True and False restituir√† False perch√© una delle condizioni √® falsa:\n\nTrue and False\n\nFalse\n\n\nL‚Äôoperatore or restituisce True se almeno una delle due condizioni booleane √® vera. Ad esempio, True or False restituir√† True perch√© almeno una delle condizioni √® vera.\n\nTrue or False\n\nTrue\n\n\nL‚Äôoperatore not viene utilizzato per invertire il valore di verit√† di una condizione booleana. Ad esempio, not True restituir√† False e not False restituir√† True.\n\nnot True\n\nFalse\n\n\nAlcuni esempi sono i seguenti (si noti l‚Äôuso della funzione len()):\n\nprint(3 &gt; 2)  # True, because 3 is greater than 2\nprint(3 &gt;= 2)  # True, because 3 is greater than 2\nprint(3 &lt; 2)  # False,  because 3 is greater than 2\nprint(2 &lt; 3)  # True, because 2 is less than 3\nprint(2 &lt;= 3)  # True, because 2 is less than 3\nprint(3 == 2)  # False, because 3 is not equal to 2\nprint(3 != 2)  # True, because 3 is not equal to 2\nprint(len(\"mango\") == len(\"avocado\"))  # False\nprint(len(\"mango\") != len(\"avocado\"))  # True\nprint(len(\"mango\") &lt; len(\"avocado\"))  # True\nprint(len(\"milk\") != len(\"meat\"))  # False\nprint(len(\"milk\") == len(\"meat\"))  # True\nprint(len(\"tomato\") == len(\"potato\"))  # True\nprint(len(\"python\") &gt; len(\"dragon\"))  # False\n\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\nAltri esempi di come questi operatori possono essere utilizzati sono i seguenti:\n\nprint(3 &gt; 2 and 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 and 4 &lt; 3)  # False - because the second statement is false\nprint(3 &lt; 2 and 4 &lt; 3)  # False - because both statements are false\nprint(\"True and True: \", True and True)\nprint(3 &gt; 2 or 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 or 4 &lt; 3)  # True - because one of the statements is true\nprint(3 &lt; 2 or 4 &lt; 3)  # False - because both statements are false\nprint(\"True or False:\", True or False)\nprint(not 3 &gt; 2)  # False - because 3 &gt; 2 is true, then not True gives False\nprint(not True)  # False - Negation, the not operator turns true to false\nprint(not False)  # True\nprint(not not True)  # True\nprint(not not False)  # False\n\nTrue\nFalse\nFalse\nTrue and True:  True\nTrue\nTrue\nFalse\nTrue or False: True\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\nAbbiamo tralasciato alcuni operatori in Python. Due di quelli che abbiamo omesso sono gli operatori di appartenenza, in e not in. Gli altri operatori che abbiamo tralasciato sono gli operatori bitwise e gli operatori sugli insiemi, che verranno trattati in seguito.\n\n\n2.5.8 Valori Numerici di True e False\n√à fondamentale comprendere i valori numerici associati alle parole chiave True e False. Queste due parole chiave hanno i valori numerici di 1 e 0, rispettivamente.\n\nTrue == 1\n\nTrue\n\n\n\nFalse == 0\n\nTrue\n\n\n\nTrue + False\n\n1\n\n\n\ntype(True + False)\n\nint",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#sequenze",
    "href": "chapters/chapter_1/01_python_1.html#sequenze",
    "title": "2¬† Python (1)",
    "section": "2.6 Sequenze",
    "text": "2.6 Sequenze\nOltre ai numeri e ai valori booleani, Python supporta anche un insieme di ‚Äúcontenitori‚Äù, ovvero i seguenti tipi strutturati:\n\nle liste,\nle tuple,\ngli insiemi,\ni dizionari.\n\n\n2.6.1 Le tuple\nUna tupla √® una collezione di diversi tipi di dati che √® ordinata e immutabile (non modificabile). Le tuple sono scritte tra parentesi tonde, (). Una volta creata una tupla, non √® possibile modificarne i contenuti.\n\ncolors = (\"Rosso\", \"Nero\", \"Bianco\")\ncolors\n\n('Rosso', 'Nero', 'Bianco')\n\n\n\ntype(colors)\n\ntuple\n\n\nLe stringhe sono tuple di caratteri. Pertanto non sono modificabili.\n\n\n2.6.2 Le liste\nGli oggetti di tipo lista sono simili alle tuple, ma con alcune differenze. La lista √® un oggetto mutabile, il che significa che possiamo aggiungere o rimuovere elementi dalla lista anche dopo la sua creazione. Una lista viene creata separando i suoi elementi tramite virgola e racchiudendo il tutto tra parentesi quadre.\nSi noti che una lista √® una struttura dati eterogenea contentente una sequenza di elementi che possono essere di tipo diverso.\n\nmy_list = [\"Pippo\", 3, -2.953, [1, 2, 3]]\nmy_list\n\n['Pippo', 3, -2.953, [1, 2, 3]]\n\n\n\ntype(my_list)\n\nlist\n\n\nLa lista my_list √® composta da diversi elementi: una stringa (‚ÄúPippo‚Äù), un numero intero (3), un numero decimale (-2.953) e un‚Äôaltra lista ([1, 2, 3]).\nGli elementi nella lista sono ordinati in base all‚Äôindice, il quale rappresenta la loro posizione all‚Äôinterno della lista. Gli indici delle liste partono da 0 e aumentano di uno. Per accedere a un elemento della lista tramite il suo indice, si utilizza la notazione delle parentesi quadre: nome_lista[indice]. Ad esempio:\n\nmy_list[1]\n\n3\n\n\n\nmy_list[0]\n\n'Pippo'\n\n\nPython prevede alcune funzioni che elaborano liste, come per esempio len che restituisce il numero di elementi contenuti in una lista:\n\nlen(my_list)\n\n4\n\n\nBench√© questa lista contenga come elemento un‚Äôaltra lista, tale lista nidificata conta comunque come un singolo elemento. La lunghezza di di my_list √® quattro.\nUna lista vuota si crea nel modo seguente:\n\nempty_list = []\nlen(empty_list)\n\n0\n\n\nEcco alcuni esempi.\n\nfruits = [\"banana\", \"orange\", \"mango\", \"lemon\"]  # list of fruits\nvegetables = [\"Tomato\", \"Potato\", \"Cabbage\", \"Onion\", \"Carrot\"]  # list of vegetables\n\nprint(\"Fruits:\", fruits)\nprint(\"Number of fruits:\", len(fruits))\nprint(\"Vegetables:\", vegetables)\nprint(\"Number of vegetables:\", len(vegetables))\n\nFruits: ['banana', 'orange', 'mango', 'lemon']\nNumber of fruits: 4\nVegetables: ['Tomato', 'Potato', 'Cabbage', 'Onion', 'Carrot']\nNumber of vegetables: 5\n\n\nSupponiamo di voler ordinare in ordine alfabetico i nomi presenti nella lista. Per fare ci√≤, √® necessario utilizzare il metodo sort sulla lista utilizzando la notazione con il punto (dot notation):\n\nnames = [\"Carlo\", \"Giovanni\", \"Giacomo\"]\nnames.sort()\n\nTale metodo per√≤ non restituisce alcun valore, in quanto l‚Äôordinamento √® eseguito in place: dopo l‚Äôinvocazione, gli elementi della lista saranno stati riposizionati nell‚Äôordine richiesto. Visualizziamo la listra trasformata:\n\nnames\n\n['Carlo', 'Giacomo', 'Giovanni']\n\n\nL‚Äôinvocazione di metodi (e di funzioni) prevede anche la possibilit√† di specificare degli argomenti opzionali. Per esempio:\n\nnames.sort(reverse=True)\nnames\n\n['Giovanni', 'Giacomo', 'Carlo']\n\n\nIl metodo remove() pu√≤ essere usato per rimuovere elementi da una lista.\n\nprint(fruits)\nfruits.remove(\"banana\")\nprint(fruits)\n\n['banana', 'orange', 'mango', 'lemon']\n['orange', 'mango', 'lemon']\n\n\nIl metodo insert() pu√≤ essere usato per aggiungere elementi ad una lista.\n\nprint(fruits)\nfruits.insert(2, \"watermelon\")\nprint(fruits)\n\n['orange', 'mango', 'lemon']\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n√à possibile copiare una lista in una nuova variabile:\n\nprint(fruits)\nnew_fruits = fruits.copy()\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\nprint(new_fruits)\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\n\n2.6.3 Operazioni su liste\nL‚Äôoperatore + concatena liste:\n\na = [1, 2, 3]\nb = [4, 5, 6]\nc = a + b\nprint(c)\n\n[1, 2, 3, 4, 5, 6]\n\n\nIn maniera simile, l‚Äôoperatore * ripete una lista un certo numero di volte:\n\n[0] * 4\n\n[0, 0, 0, 0]\n\n\n\n[1, 2, 3] * 3\n\n[1, 2, 3, 1, 2, 3, 1, 2, 3]\n\n\nL‚Äôaspetto importante da considerare √® che, essendo una sequenza di elementi eterogenei, √® difficile eseguire operazioni algebriche sulle liste in Python puro. Ad esempio, consideriamo la seguente lista:\n\nx = [1, 2, 3]\nx\n\n[1, 2, 3]\n\n\nSe desideriamo calcolare una semplice operazione, come la media di x, √® necessario seguire una procedura abbastanza articolata. Ad esempio:\n\ntotal = 0\ncounter = 0\n\nfor num in x:\n    counter += 1\n    total += num\n\navg = total / counter\n\nprint(avg)\n\n2.0\n\n\nIndubbiamente, sarebbe preferibile ottenere questo risultato con un approccio pi√π semplice. In seguito, vedremo che se utilizziamo una sequenza di elementi omogenei, il problema pu√≤ essere risolto in modo molto pi√π agevole. Ad esempio,\n\nimport numpy as np\n\nx = np.array([1, 2, 3])\nnp.mean(x)\n\n2.0\n\n\nPossiamo contare il numero degli elementi specificati che sono contenuti in una lista usando count().\n\nages = [22, 19, 24, 25, 26, 24, 25, 24]\nprint(ages.count(24))         \n\n3\n\n\nPossiamo trovare l‚Äôindice di un elemento in una lista con index().\n\nages.index(24)  # index of the first occurrence\n\n2\n\n\n\n\n2.6.4 Operatore slice\nL‚Äôoperatore di slice (:) applicato alle liste in Python consente di estrarre una porzione specifica di elementi dalla lista. L‚Äôoperatore di slice ha la seguente sintassi: lista[inizio:fine:passo].\n\ninizio rappresenta l‚Äôindice di partenza dell‚Äôintervallo (inclusivo).\nfine rappresenta l‚Äôindice di fine dell‚Äôintervallo (esclusivo).\npasso rappresenta il passo o l‚Äôincremento tra gli indici degli elementi selezionati (facoltativo).\n\nEcco alcuni esempi per illustrare l‚Äôutilizzo dell‚Äôoperatore di slice:\n\nlista = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# Estrarre una porzione della lista\nporzione = lista[2:6]  # [3, 4, 5, 6]\n\n# Estrarre una porzione con un passo specifico\nporzione_passo = lista[1:9:2]  # [2, 4, 6, 8]\n\n# Estrarre una porzione dalla fine della lista\nporzione_fine = lista[6:]  # [7, 8, 9, 10]\n\n# Estrarre una porzione dall'inizio della lista\nporzione_inizio = lista[:5]  # [1, 2, 3, 4, 5]\n\n\n\n2.6.5 Gli insiemi\nGli insiemi sono collezioni finite di elementi distinti e non memorizzati in un ordine specifico. Un insieme non pu√≤ contenere pi√π di un‚Äôistanza dello stesso elemento. Per creare un insieme si utilizzano le parentesi graffe {}. Ad esempio:\n\nmy_set = {\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"}\nmy_set\n\n{'A', 'B', 'C', 'D', 'E', 'F'}\n\n\n\ntype(my_set)\n\nset\n\n\nGli oggetti di tipo ‚Äúset‚Äù sono utili per eseguire operazioni matematiche sugli insiemi.\nPer verificare se un elemento esiste in un insieme usiamo l‚Äôoperatore in.\n\nprint(\"Does set my_set contain D? \", \"D\" in my_set)\n\nDoes set my_set contain D?  True\n\n\nL‚Äôunione di due insieme si ottiene con union().\n\nfruits = {\"banana\", \"orange\", \"mango\", \"lemon\"}\nvegetables = {\"tomato\", \"potato\", \"cabbage\", \"onion\", \"carrot\"}\nprint(fruits.union(vegetables))\n\n{'carrot', 'onion', 'lemon', 'mango', 'tomato', 'potato', 'banana', 'cabbage', 'orange'}\n\n\nL‚Äôintersezione di due insieme si trova con intersection().\n\npython = {\"p\", \"y\", \"t\", \"h\", \"o\", \"n\"}\ndragon = {\"d\", \"r\", \"a\", \"g\", \"o\", \"n\"}\npython.intersection(dragon)\n\n{'n', 'o'}\n\n\nUn insieme pu√≤ essere un sottoinsieme o un sovrainsieme di altri insiemi.\nPer verificare se un insieme √® un sottoinsieme di un altro, si utilizza il metodo issubset(). Per verificare se un insieme √® un sovrainsieme di un altro, si utilizza il metodo issuperset().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.issubset(st1)\n\nTrue\n\n\n\nst1.issuperset(st2) \n\nTrue\n\n\nLa differenza tra due insiemi si ottiene con difference().\n\nwhole_numbers = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\neven_numbers = {0, 2, 4, 6, 8, 10}\nwhole_numbers.difference(even_numbers)\n\n{1, 3, 5, 7, 9}\n\n\nPossiamo verificare se due insiemi sono disgiunti, ovvero non hanno elementi in comune, utilizzando il metodo isdisjoint().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.isdisjoint(st1)\n\nFalse\n\n\n\n\n2.6.6 I dizionari\nGli oggetti di tipo ‚Äúdizionario‚Äù vengono utilizzati per creare coppie chiave-valore, dove ogni chiave √® unica. Un dizionario viene creato specificando ogni coppia come chiave : valore, separando le diverse coppie con una virgola e racchiudendo il tutto tra parentesi graffe. Ad esempio:\n\nmusic = {\n    \"blues\": \"Betty Smith\",\n    \"classical\": \"Gustav Mahler\",\n    \"pop\": \"David Bowie\",\n    \"jazz\": \"John Coltrane\",\n}\n\nL‚Äôaccesso agli elementi di un dizionario viene fatto specificando all‚Äôinterno di parentesi quadre la chiave per ottenere o modificare il valore corrispondente:\n\nmusic[\"pop\"]\n\n'David Bowie'\n\n\nPer trovare il numero di coppie key: value nel dizionario usiamo len().\n\nprint(len(music))\n\n4\n\n\n\nmusic[\"new music\"] = \"Missy Mazzoli\"\nprint(music)\n\n{'blues': 'Betty Smith', 'classical': 'Gustav Mahler', 'pop': 'David Bowie', 'jazz': 'John Coltrane', 'new music': 'Missy Mazzoli'}\n\n\n\n\n2.6.7 Contenitori vuoti\nA volte √® utile creare dei contenitori vuoti. I comandi per creare liste vuote, tuple vuote, dizionari vuoti e insiemi vuoti sono rispettivamente lst = [], tup=(), dic={} e st = set().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "2¬† Python (1)",
    "section": "2.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "2.7 Informazioni sull‚ÄôAmbiente di Sviluppo\nAlla fine di ogni capitolo e, in effetti, alla fine (o all‚Äôinizio) di qualsiasi notebook che creiamo, √® utile includere informazioni sull‚Äôambiente di calcolo, compresi i numeri di versione di tutti i pacchetti che utilizziamo. Il pacchetto watermark pu√≤ essere usato per questo scopo. Il pacchetto watermark contiene comandi speciali ed √® un‚Äôestensione di IPython. In generale, per utilizzare tali comandi speciali, li precediamo con il segno % o %% in una cella. Utilizziamo la funzione speciale built-in %load_ext per caricare watermark, e quindi utilizziamo %watermark per invocarlo.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 24 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\nEcco una spiegazione dettagliata delle opzioni che sono state utilizzate nell‚Äôistruzione precedente.\n\n-n o --datename: Aggiunge la data e l‚Äôora correnti al watermark. Questo pu√≤ essere utile per mantenere una cronologia delle modifiche o delle esecuzioni del notebook.\n-u o --updated: Mostra l‚Äôultima volta in cui il notebook √® stato salvato. √à utile per tenere traccia delle modifiche recenti apportate al notebook.\n-v o --python: Mostra la versione di Python utilizzata nel kernel del notebook. Questo √® importante per garantire la compatibilit√† del codice e replicare gli ambienti di lavoro.\n-iv o --iversions: Visualizza le versioni delle librerie importate nel notebook. √à fondamentale per la replicabilit√† degli esperimenti e degli analisi, dato che diverse versioni delle librerie possono comportare risultati diversi.\n-w o --watermark: Aggiunge il watermark stesso, che √® semplicemente il logo ‚Äúwatermark‚Äù. √à pi√π una questione estetica che funzionale.\n-m o --machine: Fornisce informazioni sulla macchina su cui viene eseguito il Jupyter Notebook, come il tipo di sistema operativo e l‚Äôarchitettura della macchina (ad esempio, x86_64). Questo pu√≤ essere utile per documentare l‚Äôambiente hardware in cui vengono eseguiti gli esperimenti.\n\nQueste opzioni forniscono un modo semplice e immediato per documentare e tracciare importanti metadati nei notebook Jupyter.\n\n\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and R. 1st Edition. New York, NY: Manning Publications.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html",
    "href": "chapters/chapter_1/02_python_2.html",
    "title": "3¬† Python (2)",
    "section": "",
    "text": "3.1 Funzioni\nLo scopo delle funzioni √® raggruppare il codice in un formato organizzato, leggibile e riutilizzabile, contribuendo cos√¨ a ridurre la ridondanza del codice.\nUna regola generale per le funzioni √® che dovrebbero essere di piccole dimensioni e svolgere un‚Äôunica operazione.\nNella programmazione, una funzione accetta un input, esegue operazioni su di esso e pu√≤ restituire un output. Python mette a disposizione un‚Äôampia gamma di funzioni integrate, e si pu√≤ anche importare funzioni da pacchetti aggiuntivi o definirne di nuove.\nPer definire una nuova funzione in Python, si utilizza la parola chiave def, seguita dal nome della funzione e dai nomi simbolici dei suoi argomenti, separati da virgole e racchiusi tra parentesi. La definizione continua con i due punti (:) e il corpo della funzione, le cui istruzioni devono essere indentate. Il valore restituito dalla funzione viene specificato tramite la parola chiave return, generalmente nella riga finale del corpo della funzione.\ndef add_numbers(a, b):\n    \"\"\"\n    returns the sum of the two numeric arguments\n    \"\"\"\n    the_sum = a + b\n    return the_sum\nUna volta definita una funzione, √® possibile eseguirla chiamandola e passando gli argomenti appropriati. Ad esempio, possiamo chiamare la funzione add_numbers per sommare due numeri, come ad esempio 20 e 10:\nadd_numbers(20, 10)\n\n30\nConsideriamo la funzione roll_die():\nimport random\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return random.choice([1, 2, 3, 4, 5, 6])\nIl corpo della funzione √® composto da una singola riga di codice che utilizza la funzione choice() della libreria random, a cui viene passata una lista. Questo significa che una funzione pu√≤ utilizzare altre funzioni che sono gi√† state definite. In questo caso, la funzione si limita a specificare l‚Äôargomento da passare a choice(). La funzione choice() restituir√† un numero casuale tra quelli specificati in input. Pertanto, la funzione roll_die() simula il lancio di un dado:\nroll_die()\n\n6\nroll_die()\n\n5\nSi noti inoltre la docstring, cio√® una stringa (in genere racchiusa tra ‚Äú‚Äú‚Äú‚Ä¶‚Äù‚Äú‚Äú) che si trova come prima istruzione all‚Äôinterno di una funzione. La docstring contiene informazioni sullo scopo e sulle modalit√† d‚Äôuso della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#funzioni",
    "href": "chapters/chapter_1/02_python_2.html#funzioni",
    "title": "3¬† Python (2)",
    "section": "",
    "text": "3.1.1 Introspection\nUsando un punto interrogativo (?) prima o dopo una variabile √® possibile visualizzare alcune informazioni generale su quell‚Äôoggetto. Nel caso di una funzione viene stampata la doc string.\n\nroll_die?\n\nSignature: roll_die()\nDocstring: returns a random int between 1 and 6\nFile:      /var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_13125/63164766.py\nType:      function\n\n\n\n\n3.1.2 Metodi\nLe funzioni definite all‚Äôinterno di una classe, chiamate ‚Äúmetodi‚Äù, rappresentano operazioni specifiche che possono essere eseguite sugli oggetti di quella classe. Una classe √® una struttura concettuale che rappresenta un concetto o un oggetto nel contesto del problema che stiamo affrontando. Ad esempio, nel capitolo sull‚Äôintroduzione a Pandas, lavorando con dati organizzati in una tabella, utilizziamo un oggetto chiamato DataFrame, appartenente alla classe ‚Äúpandas.DataFrame‚Äù. Un DataFrame √® una struttura tabellare che contiene dati disposti in righe e colonne.\nI metodi specifici della classe DataFrame offrono funzionalit√† per manipolare e analizzare i dati in questa struttura. Per esempio, il metodo ‚Äúhist()‚Äù genera istogrammi dei valori presenti in una colonna specifica del DataFrame. Per invocare un metodo su un oggetto DataFrame, come ‚Äúdf‚Äù, utilizziamo la sintassi ‚Äúnome_oggetto.nome_metodo()‚Äù e possiamo passare eventuali parametri richiesti tra parentesi.\nD‚Äôaltra parte, gli attributi rappresentano le caratteristiche o le propriet√† degli oggetti di una classe. Gli attributi possono essere richiamati utilizzando la sintassi ‚Äúnome_oggetto.nome_attributo‚Äù e restituiscono un valore specifico associato a quell‚Äôoggetto. Per esempio, l‚Äôattributo ‚Äú.shape‚Äù applicato a un DataFrame come ‚Äúdf.shape‚Äù restituisce il numero di righe e colonne presenti nel DataFrame.\nIn sintesi, una classe definisce un tipo di oggetto che ha attributi che ne descrivono le caratteristiche e metodi che rappresentano le azioni eseguibili su di esso. Gli attributi forniscono informazioni specifiche sull‚Äôoggetto, mentre i metodi consentono di effettuare operazioni e manipolazioni sui dati contenuti nell‚Äôoggetto stesso.\n\n\n3.1.3 La funzione lambda\nPython offre una sintassi alternativa che consente di definire funzioni ‚Äúinline‚Äù, cio√® in una singola linea di codice. Queste funzioni, chiamate funzioni anonime, non richiedono una definizione esplicita poich√© vengono utilizzate solo nel punto in cui sono dichiarate. Per creare una funzione anonima, utilizziamo la parola chiave lambda, seguita da un elenco di argomenti separati da virgole, due punti ‚Äú:‚Äù e l‚Äôespressione che definisce il comportamento della funzione basandosi sugli argomenti forniti.\nlambda argomento1, argomento2, ... : espressione\nQuesta sintassi permette di creare funzioni semplici ed espressive in modo conciso.\nNell‚Äôesempio seguente, la funzione somma 1 al valore passato come input:\n\n(lambda x : x + 1)(2)\n\n3\n\n\nQuando eseguiamo (lambda x : x + 1)(2), avviene quanto segue:\n\nL‚Äôinterprete Python definisce la funzione lambda lambda x : x + 1.\nLa funzione lambda viene immediatamente chiamata con l‚Äôargomento 2.\nAll‚Äôinterno della funzione lambda, x viene sostituito da 2, quindi l‚Äôespressione x + 1 diventa 2 + 1.\nLa funzione lambda restituisce 3.\n\nQuindi, il risultato dell‚Äôespressione (lambda x : x + 1)(2) √® 3.\nIn sintesi, la funzione lambda (lambda x : x + 1) definisce una funzione che aggiunge 1 al suo argomento. Quando la chiamiamo con l‚Äôargomento 2, otteniamo 3 come risultato.\nIn questo secondo esempio sommiamo i due numeri in entrata:\n\n(lambda x, y: x + y)(2, 3)\n\n5\n\n\nLa sintassi seguente √® valida in quanto, per l‚Äôinterprete, il carattere _ corrisponde all‚Äôultima funzione che √® stata valutata:\n\nlambda x, y: x + y\n\n&lt;function __main__.&lt;lambda&gt;(x, y)&gt;\n\n\n\n_(20, 10)\n\n30\n\n\nSi noti che abbiamo valutato la funzione lambda x, y: x + y in una cella precedente a quella che contiene _(20, 10); inserendo le due espressioni in una singola cella si ottiene un SyntaxError.\n\n\n3.1.4 Le funzioni map() e filter()\nPer gli esercizi che svolgeremo in seguito, risultano utili le funzioni map() e filter().\nLa funzione map() prende come input una funzione e una lista, e restituisce il risultato dell‚Äôapplicazione della funzione a ciascun elemento della lista (√® anche possibile usare qualsiasi oggetto iterabile al posto della lista). La lista stessa rimane invariata. Ad esempio, la seguente linea di codice eleva al quadrato ciascuno degli elementi della lista a e salva il risultato nella lista b:\n\na = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nb = list(map(lambda x: x * x, a))\nb\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n\n\nUn‚Äôaltra funzione molto utile per manipolare gli oggetti iterabili √® la funzione filter(). Questa funzione filtra un oggetto iterabile selezionando solo gli elementi che rispondono ad un determinato predicato. (Il predicato √® una funzione che restituisce un booleano). Per esempio\n\nc = list(filter(lambda x: x &gt; 50, b))\nc\n\n[64, 81, 100]\n\n\nSia map() che filter() restituiscono risultati che non sono ancora stati calcolati.\n\nfilter(lambda x: x &gt; 50, b)\n\n&lt;filter at 0x171da9720&gt;\n\n\nPossiamo visualizzare il risultato convertendolo in una lista:\n\nlist(filter(lambda x: x &gt; 50, b))\n\n[64, 81, 100]\n\n\n\n\n3.1.5 La funzione zip()\nLa funzione zip() crea una lista di tuple dagli elementi di due contenitori. Come nel caso delle operazioni precedenti, gli elementi vengono calcolati solo quando viene richiesto. Per esempio:\n\na = list(range(4))\na\n\n[0, 1, 2, 3]\n\n\n\nb = list(range(4, 8))\nb\n\n[4, 5, 6, 7]\n\n\n\nb = zip(a, b)\nb\n\n&lt;zip at 0x172034f80&gt;\n\n\n\nlist(b)\n\n[(0, 4), (1, 5), (2, 6), (3, 7)]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#il-flusso-di-esecuzione",
    "href": "chapters/chapter_1/02_python_2.html#il-flusso-di-esecuzione",
    "title": "3¬† Python (2)",
    "section": "3.2 Il flusso di esecuzione",
    "text": "3.2 Il flusso di esecuzione\nIn Python il codice viene eseguito sequenzialmente, partendo dalla prima riga fino a quando non c‚Äô√® pi√π nulla da eseguire. L‚Äôordine di esecuzione delle varie istruzioni √® detto flusso di esecuzione.\nPer esempio la cella seguente prima memorizza la lista names, poi la lista born e infine la lista dead.\n\nnames = [\"Sigmund Freud\", \"Jean Piaget\", \"Burrhus Frederic Skinner\", \"Albert Bandura\"]\nborn = [1856, 1896, 1904, 1925]\ndead = [1939, 1980, 1990, None]\n\nHo usato il valore speciale None in quanto non risulta disponibile l‚Äôanno. In queste situazioni si parla di valori mancanti (missing values) che, di norma, vengono indicati con la sigla NA (not available).\nLa cella seguente include le istruzioni condizionali che specificano se e quando devono essere eseguiti determinati blocchi di codice. La pi√π semplice istruzione di controllo √® l‚Äôistruzione if. Per esempio:\n\nname = \"Maria\"\ngrade = 29\n\nif name == \"Maria\" and grade &gt; 28:\n    print(\"Maria, hai ottenuto un ottimo voto all'esame!\")\n\nif name == \"Giovanna\" or grade &gt; 28:\n    print(\n        \"Tu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\"\n    )\n\nif name != \"Giovanna\" and grade &gt; 28:\n    print(\"Tu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\")\n\nMaria, hai ottenuto un ottimo voto all'esame!\nTu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\nTu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\n\n\nTutte e tre le condizioni precedenti ritornano True, quindi vengono stampati tutti e tre i messaggi.\nSi noti che == e != confrontano valori, mentre is e not confrontano oggetti. Per esempio,\n\nname_list = [\"Maria\", \"Giovanna\"]\nname_list_two = [\"Marco\", \"Francesco\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nFalse\nFalse\n\n\nUna delle parole chiave condizionali pi√π utili √® in. Un esempio √® il seguente:\n\nname_list = [\"Maria\", \"Giovanna\", \"Marco\", \"Francesco\"]\n\nprint(\"Giovanna\" in name_list)\nprint(\"Luca\" in name_list)\n\nTrue\nFalse\n\n\nLa condizione opposta √® not in.\n\nprint(\"Luca\" not in name_list)\n\nTrue\n\n\nFacciamo un altro esempio.\n\nage = 26\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\n\nSei maggiorenne\n\n\nPython dispone di un‚Äôespressione ternaria che introduce la potenza dell‚Äôistruzione ‚Äòelse‚Äô in una sintassi concisa:\n\nage = 26\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei maggiorenne\n\n\n\nage = 16\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei minorenne\n\n\nUna struttura di selezione leggermente pi√π complessa √® ‚Äúif-else‚Äù. La sintassi di questa struttura √® la seguente:\nif &lt;condizione&gt;:\n    &lt;istruzione_se_condizione_vera&gt;\nelse:\n    &lt;istruzione_se_condizione_falsa&gt;\nLa semantica di ‚Äúif-else‚Äù √® quella che ci si aspetta: la condizione tra la parola chiave if e il carattere di due punti viene valutata: se risulta vera viene eseguita l‚Äôistruzione alla linea seguente, altrimenti viene eseguita l‚Äôistruzione dopo la parola chiave else. Anche in questo caso l‚Äôindentazione permette di identificare quali istruzioni devono essere eseguite nei due rami della selezione. Per esempio:\n\nage = 16\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\nelse:\n    print(\"Sei minorenne\")\n\nSei minorenne\n\n\nIn presenza di pi√π di due possibilit√† mutuamente esclusive ed esaustive possiamo usare l‚Äôistruzione elif. Per esempio:\n\ncfu = 36\nthesis_defense = False\n\nif cfu &gt;= 180 and thesis_defense == True:\n    print(\"Puoi andare a festeggiare!\")\nelif cfu &gt;= 180 and thesis_defense == False:\n    print(\"Devi ancora superare la prova finale!\")\nelse:\n    print(\"Ripassa tra qualche anno!\")\n\nRipassa tra qualche anno!\n\n\n\n3.2.1 Commenti\nIn Python √® possibile usare il carattere # per aggiungere commenti al codice. Ogni riga di commento deve essere preceduta da un #. I commenti non devono spiegare il metodo (cosa fa il codice: quello si vede), ma bens√¨ lo scopo: quello che noi intendiamo ottenere. I primi destinatari dei commenti siamo noi stessi tra un po‚Äô di tempo, ovvero quando ci saremo dimenticati cosa avevamo in mente quando abbiamo scritto il codice.\n\n# This is a comment and will not be executed.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#cicli",
    "href": "chapters/chapter_1/02_python_2.html#cicli",
    "title": "3¬† Python (2)",
    "section": "3.3 Cicli",
    "text": "3.3 Cicli\nUn ciclo √® un modo per eseguire una porzione di codice pi√π di una volta. I cicli sono fondamentali nei linguaggi di programmazione. Come molti altri linguaggi di programmazione, Python ha due tipi di cicli per gestire tutte le proprie necessit√† di iterazione: il ciclo ‚Äúwhile‚Äù e il ciclo ‚Äúfor‚Äù.\n\n3.3.1 Il ciclo while\nil ciclo while permette l‚Äôesecuzione di un blocco di codice finch√© una determinata condizione √® True. Per esempio:\n\ncounter = 0\n\nwhile counter &lt;= 10:\n    print(counter)\n    counter += 1\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nIl codice counter += 1 √® equivalente a counter = counter + 1 e, ogni qualvolta viene eseguito il ciclo, riassegna alla variabile counter il valore che aveva in precedenza + 1.\nL‚Äôistruzione while controlla se alla variabile counter √® associato un valore minore o uguale a 10. Nel primo passo del ciclo la condizione √® soddisfatta, avendo noi definito counter = 0, pertanto il programma entra nel loop, stampa il valore della variabile counter e incrementa counter di un‚Äôunit√†.\nQuesto comportamento si ripete finch√© la condizione counter &lt;= 10 risulta True. Quando il contatore counter assume il valore 11 il ciclo while si interrompe e il blocco di codice del ciclo non viene pi√π eseguito.\n\n\n3.3.2 Il ciclo for\nIl ciclo for √® un costrutto di controllo di flusso che viene utilizzato per iterare su una sequenza di valori, come ad esempio una lista, una tupla, una stringa o un dizionario.\nLa sintassi generale di un ciclo for in Python √® la seguente:\nfor element in sequence:\n    # codice da eseguire\nDove element √® una variabile temporanea che assume il valore di ciascun elemento della sequenza ad ogni iterazione del ciclo, e sequence √® la sequenza di valori su cui iterare.\nDurante l‚Äôesecuzione del ciclo, il blocco di codice indentato sotto la linea for viene eseguito una volta per ogni elemento della sequenza. Ad ogni iterazione, la variabile elemento assume il valore dell‚Äôelemento corrente della sequenza e il codice all‚Äôinterno del blocco viene eseguito con questo valore.\nIl ciclo for √® spesso utilizzato per eseguire operazioni su ciascun elemento di una sequenza, come ad esempio la somma degli elementi di una lista o la stampa di ciascun carattere di una stringa. Per esempio\n\nnumbers = [0, 1, 2, 3, 4, 5]\nfor number in numbers: # number is temporary name to refer to the list's items, valid only inside this loop\n    print(number)\n\n0\n1\n2\n3\n4\n5\n\n\n\nlanguage = \"Python\"\nfor letter in language:\n    print(letter)\n\nP\ny\nt\nh\no\nn\n\n\nLa funzione range() √® spesso usata nei cicli for e permette di impostare un intervallo di esecuzione tanto ampio quanto il numero che le passiamo come parametro meno uno.\nLa funzione range() prende tre parametri: start (default 0), stop e step (default 1), ovvero un punto di inizio dell‚Äôintervallo, un punto di fine e un passo di avanzamento. L‚Äôindicizzazione Python parte da 0; quindi range(0, 11, 1) una lista di 11 elementi, da 0 a 10 inclusi.\n\nprint(list(range(0, 11, 1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nAd esempio, impostiamo un punto di inizio a 3, il punto di fine a 11 e un passo di 2:\n\nprint(list(range(3, 12, 2)))\n\n[3, 5, 7, 9, 11]\n\n\nIn un ciclo for, l‚Äôintervallo di range() corrisponde al numero di iterazioni che verranno eseguite, ovvero al numero di volte che il ciclo verr√† processato. Nel caso seguente, l‚Äôindice del ciclo (qui chiamato number) assume il valore 0 la prima volta che il ciclo viene eseguito e il valore 10 nell‚Äôultima esecuzione del ciclo.\n\nfor number in range(11):\n    print(number)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nfor number in range(3, 12, 2):\n    print(number)\n\n3\n5\n7\n9\n11\n\n\n\n3.3.2.1 Cicli for annidati\nSono possibili i cicli for annidati, vale a dire un ciclo posto all‚Äôinterno del corpo di un altro (chiamato ciclo esterno). Al suo primo passo, il ciclo esterno mette in esecuzione quello interno che esegue il proprio blocco di codice fino alla conclusione. Quindi, al secondo passo, il ciclo esterno rimette in esecuzione quello interno. Questo si ripete finch√© il ciclo esterno non termina. Per esempio:\n\nfor i in range(4):\n    for j in range(4):\n        print((i, j))\n\n(0, 0)\n(0, 1)\n(0, 2)\n(0, 3)\n(1, 0)\n(1, 1)\n(1, 2)\n(1, 3)\n(2, 0)\n(2, 1)\n(2, 2)\n(2, 3)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)\n\n\n\n\n3.3.2.2 Modificare gli elementi di una lista\nIl ciclo for √® il modo pi√π comune per scorrere gli elementi di una lista, come abbiamo visto in precedenza.\n\nfor name in name_list:\n    print(name)\n\nMaria\nGiovanna\nMarco\nFrancesco\n\n\nQuesto approccio pu√≤ essere usato se abbiamo solo bisogno di leggere gli elementi della lista. Nel ciclo seguente, ad esempio, leggiamo gli elementi d una lista per incrementare una variabile cos√¨ da calcolare una somma.\n\nnumbers = [2, -4, 1, 6, 3]\n\ntotal = 0\nfor num in numbers:\n    total += num\n\nprint(total)\n\n8\n\n\nMa se vogliamo cambiare gli elementi di una lista l‚Äôapproccio precedente non funziona e dobbiamo usare gli indici. Nell‚Äôesempio seguente, questo risultato viene ottenuto utilizzando le funzioni range e len:\n\nnumbers = [2, -4, 1, 6, 3]\n\nfor i in range(len(numbers)):\n    numbers[i] = numbers[i] * 2\n\nprint(numbers)\n\n[4, -8, 2, 12, 6]\n\n\nNel codice seguente, la funzione len() ritorna 5.\n\nnumbers = [2, -4, 1, 6, 3]\nlen(numbers)\n\n5\n\n\nQuindi, range(5) produce la seguente sequenza iterabile:\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]\n\n\nQuesti sono gli indici che verranno usati nelle iterazioni del ciclo for.\n\nLa prima volta che il ciclo viene eseguito, l‚Äôindice i vale 0 e numbers[i] si riferisce al primo elemento della lista;\nla seconda volta che il ciclo viene eseguito, i vale 1 e numbers[i] si riferisce al secondo elemento della lista;\ne cos√¨ via.\n\nL‚Äôistruzione di assegnazione nel corpo del ciclo for usa i per leggere il valore i-esimo della lista originale (a destra dell‚Äôuguale) e per assegnargli un nuovo valore (a sinistra dell‚Äôuguale).\n\n\n\n3.3.3 List comprehension\nUna list comprehension √® un modo conciso di creare una lista. √à un modo compatto per creare una nuova lista. Accade speso di dover creare una lista dove ciascun elemento √® il risultato di un‚Äôoperazione condotta sugli elementi di un‚Äôaltra lista o di un iterabile; oppure, di dover estrarre gli elementi che soddisfano una certa condizione. Per esempio, supponiamo di volere sommare una costante ad una lista di numeri. Usando un ciclo for possiamo procedere nel modo seguente (si noti l‚Äôuso della funzione append):\n\nnew_list = []\nk = 10\nfor x in range(10):\n    new_list.append(x + k)\n\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nOppure, in maniera pi√π semplice, possiamo usare una list comprehension:\n\nnew_list = [x + k for x in range(10)]\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nUna list comprehension √® racchiusa tra parentesi quadre; contiene un‚Äôespressione, seguita da una clausola for, seguita da zero o pi√π clausole for o if. La sintassi √® la seguente:\n[ &lt;expression&gt; for item in iterable &lt;if optional_condition&gt; ]\nIl risultato √® una nuova lista costruita valutando l‚Äôespressione nel contesto delle clausole for e if che la seguono. Una list comprehension combina dunque un ciclo for e (se necessario) una o pi√π condizioni logiche in una singola riga di codice. Esaminiamo una variante dell‚Äôesempio precedente.\n\nlist1 = [1, 2, 3, 4, 5, 6]\nprint(\"list1:\", list1)\n\nlist1: [1, 2, 3, 4, 5, 6]\n\n\n\nlist2 = [item + 1 for item in list1]\nprint(\"list2:\", list2)\n\nlist2: [2, 3, 4, 5, 6, 7]\n\n\nSi noti che la parola item avrebbe potuto essere quasi qualsiasi stringa (in precedenza abbiamo usato x). La possiamo immaginare con la seguente definizione: ...per ogni elemento in .... Nel seguente esempio, sommiamo 1 agli elementi di list1 solo se sono pari:\n\nlist3 = [item + 1 for item in list1 if item % 2 == 0] \nprint('list3:', list3)\n\nlist3: [3, 5, 7]\n\n\nFacciamo un altro esempio usando range():\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nQui selezioniamo solo i numeri pari (oltre allo zero):\n\n[i for i in range(11) if i % 2 == 0]\n\n[0, 2, 4, 6, 8, 10]\n\n\nSpecificando una condizione, possiamo cambiare il segno solo dei numeri dispari nella lista:\n\n[-i if i % 2 else i for i in range(11)]\n\n[0, -1, 2, -3, 4, -5, 6, -7, 8, -9, 10]\n\n\nPossiamo anche eseguire pi√π iterazioni simultaneamente:\n\n[(i, j) for i in range(3) for j in range(4)]\n\n[(0, 0),\n (0, 1),\n (0, 2),\n (0, 3),\n (1, 0),\n (1, 1),\n (1, 2),\n (1, 3),\n (2, 0),\n (2, 1),\n (2, 2),\n (2, 3)]\n\n\nIn questo esempio vengono selezionati solo i nomi inclusi nella lista female_names:\n\nfirst_names = [\"Maria\", \"Marco\", \"Francesco\", \"Giovanna\"]\nfemale_names = [\"Alice\", \"Maria\", \"Giovanna\", \"Lisa\"]\nfemale_list = [name for name in first_names if name in female_names]\nprint(female_list)\n\n['Maria', 'Giovanna']\n\n\nNel seguente esempio vengono estratte le prime tre lettere di ciascuno dei nomi che compongono una lista:\n\nletters = [name[0:3] for name in first_names] \nletters\n\n['Mar', 'Mar', 'Fra', 'Gio']\n\n\nPer estrarre l‚Äôultimo carattere di una stringa usiamo [-1]:\n\nmy_string = \"barbabl√π\"\nmy_string[-1]\n\n'√π'\n\n\nPossiamo dunque usare seguente list comprehension estrae gli ultimi tre caratteri di ciascun elemento della lista first_names.\n\nletters = [name[-3:] for name in first_names] \nletters\n\n['ria', 'rco', 'sco', 'nna']\n\n\n√à possibile impiegare un‚Äôespressione ternaria all‚Äôinterno di una list comprehension per sfruttare la versatilit√† dell‚Äôistruzione ‚Äòelse‚Äô in modo sintatticamente efficace. Ad esempio, possiamo sostituire tutti i numeri dispari di una lista (un un NumPy array) con il valore 99.\n\nnum = np.array([4, 7, 2, 6, 3, 9])  # pu√≤ anche essere una lista Python\n[e if e % 2 == 0 else 99 for e in num]\n\n[4, 99, 2, 6, 99, 99]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#librerie-e-moduli",
    "href": "chapters/chapter_1/02_python_2.html#librerie-e-moduli",
    "title": "3¬† Python (2)",
    "section": "3.4 Librerie e moduli",
    "text": "3.4 Librerie e moduli\n\n3.4.1 Importare moduli\nI moduli (anche conosciuti come librerie in altri linguaggi) sono dei file usati per raggruppare funzioni e altri oggetti. Python include una lista estensiva di moduli standard (anche conosciuti come Standard Library), ma √® anche possibile scaricarne o definirne di nuovi. Prima di potere utilizzare le funzioni non presenti nella Standard Library all‚Äôinterno dei nostri programmi dobbiamo importare dei moduli aggiuntivi, e per fare ci√≤ usiamo il comando import.\nL‚Äôimportazione pu√≤ riguardare un intero modulo oppure solo uno (o pi√π) dei suoi elementi. Consideriamo per esempio la funzione mean. Essa √® disponibile nel modulo numpy. L‚Äôistruzione import numpy importa tutto il modulo numpy. Dopo che un modulo √® stato importato, √® possibile accedere a un suo generico elemento usando il nome del modulo, seguito da un punto e dal nome dell‚Äôelemento in questione. Ad esempio, numpy.mean().\nIndicare il nome di un modulo per poter accedere ai suoi elementi ha spesso l‚Äôeffetto di allungare il codice, diminuendone al contempo la leggibilit√†. √à per questo motivo che √® possibile importare un modulo specificando un nome alternativo, pi√π corto. √à quello che succede quando scriviamo l‚Äôistruzione import numpy as np. In questo caso, l‚Äôistruzione precedente diventa np.mean().\nI moduli pi√π complessi sono organizzati in strutture gerarchiche chiamate package. La seguente cella importa il modulo pyplot che √® contenuto nel package matplotlib (matplotlib √® la libreria di riferimento in Python per la creazione di grafici).\n\nimport matplotlib.pyplot as plt\n\nQui di seguito sono descritte tutte le possibilit√†:\n\n# import everything from library\nimport random\n# call function by\nrandom.random()\n\n0.16777284588756924\n\n\n\n#import everything, but change name\nimport random as rnd\n# call function by\nrnd.random()\n\n0.05690270000491682\n\n\n\n# select what to import from library\nfrom random import random\n#call function by\nrandom()\n\n0.037974565142151695\n\n\n\n# import everything from library\nfrom random import *\n# call function by\nrandom()\n\n0.20988431417194764\n\n\nNella cella seguente importiamo seaborn con il nome sns e usiamo le sue funzionalit√† per impostare uno stile e una palette di colori per la visualizzazione dei grafici.\n\nimport seaborn as sns\nsns.set_theme()\nsns.set_palette(\"colorblind\")\n\nNell‚Äôesempio seguente calcoliamo la somma degli elementi della lista numerica primes usando funzione sum() contenuta nella libreria NumPy che abbiamo importato con il nome di np:\n\nimport numpy as np\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nnp.sum(primes)\n\n42\n\n\nCalcolo la media di primes:\n\nnp.mean(primes)\n\n6.0\n\n\nScriviamo una nuova funzione per la media, \\(\\bar{x} = n^{-1}\\sum_{i=1}^n x_i\\):\n\ndef my_mean(x):\n    res = np.sum(x) / len(x)\n    return res\n\n\nmy_mean(primes)\n\n6.0\n\n\nSi noti che, nel corpo di una funzione, √® possibile usare altre funzioni: qui, np.sum() e len().\n√à sempre possibile usare la funzione di help su una funzione:\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n    \n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nIn Visual Studio Code √® sufficiente posizionare il cursore sul nome della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#formattazione-del-codice",
    "href": "chapters/chapter_1/02_python_2.html#formattazione-del-codice",
    "title": "3¬† Python (2)",
    "section": "3.5 Formattazione del codice",
    "text": "3.5 Formattazione del codice\n\nuewsvjq ../images/code_quality_2x.png :align: center",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "3¬† Python (2)",
    "section": "3.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "3.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.1.4\nnumpy     : 1.26.2\nseaborn   : 0.13.0\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html",
    "href": "chapters/chapter_1/03_numpy.html",
    "title": "4¬† NumPy",
    "section": "",
    "text": "4.1 Preparazione del Notebook\nimport numpy as np",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "href": "chapters/chapter_1/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "title": "4¬† NumPy",
    "section": "4.2 Utilizzo degli Array nel Modulo NumPy",
    "text": "4.2 Utilizzo degli Array nel Modulo NumPy\nIn Python standard, abbiamo a disposizione tipi di dati numerici (come numeri interi e decimali) e strutture come liste, dizionari e insiemi. NumPy, d‚Äôaltro canto, introduce un nuovo tipo di struttura dati: l‚Äôarray N-dimensionale, noto come ndarray. Questi array hanno alcune caratteristiche distintive:\n\nDimensioni: Gli ndarray possono variare nel numero di dimensioni, definite come ‚Äúassi‚Äù. Ad esempio, un array pu√≤ essere unidimensionale (simile a un vettore lineare), bidimensionale (come una matrice o una tabella), tridimensionale (simile a un cubo), e cos√¨ via.\nTipo di Dato: A differenza delle liste in Python standard che possono contenere diversi tipi di dati, ogni elemento all‚Äôinterno di un ndarray deve essere dello stesso tipo, come numeri interi, decimali, booleani o stringhe.\nForma: La ‚Äúforma‚Äù di un ndarray si riferisce alle sue dimensioni, ovvero quante righe, colonne o altri livelli di profondit√† ha. Per esempio, la forma (3, 4) indica un array con 3 righe e 4 colonne.\nIndicizzazione: Gli ndarray possono essere indicizzati in modo simile agli array standard di Python, ma offrono anche opzioni pi√π avanzate per l‚Äôindicizzazione.\n\nGli ndarray sono potenti per manipolare e analizzare i dati, grazie alle loro funzioni e metodi che includono operazioni matematiche e statistiche, trasformazioni e altre manipolazioni dei dati.\nTerminologia Importante: - Size: Indica il numero totale di elementi in un array. - Rank: Si riferisce al numero di dimensioni, o assi, di un array. - Shape: Denota le dimensioni specifiche dell‚Äôarray, ovvero una sequenza di numeri che rappresentano il conteggio degli elementi in ogni dimensione.\nCome Creare un ndarray: Il modo pi√π diretto per creare un ndarray √® attraverso la conversione di una lista Python. Ad esempio, √® possibile creare un array unidimensionale (1-D) a partire da una lista standard di Python.\n\nx = np.array([1, 2, 3, 4, 5, 6])\n\nL‚Äôistruzione precedente crea un array in NumPy, assegnandolo alla variabile x. Questo array √® un vettore unidimensionale contenente sei elementi, che sono i numeri interi specificati all‚Äôinterno delle parentesi quadre.\n\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nIndicizzazione\nSe vogliamo estrarre un singolo elemento del vettore lo indicizziamo con la sua posizione (si ricordi che l‚Äôindice inizia da 0):\n\nx[0]\n\n1\n\n\n\nx[2]\n\n3\n\n\nUn array 2-D si crea nel modo seguente:\n\ny = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nEstraiamo un singolo elemento dall‚Äôarray:\n\ny[0, 2]\n\n3\n\n\nEstraiamo la seconda riga dall‚Äôarray:\n\ny[1]\n\narray([5, 6, 7, 8])\n\n\nEstraiamo la seconda colonna dall‚Äôarray:\n\ny[:, 1] \n\narray([ 2,  6, 10])\n\n\nLa sintassi con i due punti √® chiamata ‚Äúslicing‚Äù dell‚Äôarray.\n\n# Display the first row of the array\nprint(\"Displaying the first row:\")\nprint(y[0, :])\n\nDisplaying the first row:\n[1 2 3 4]\n\n\n\n# Show the last two elements in the first row\nprint(\"Showing the last two elements in the first row:\")\nprint(y[0, -2:])\n\nShowing the last two elements in the first row:\n[3 4]\n\n\n\n# Retrieve every second element in the first row\nprint(\"Retrieving every second element in the first row:\")\nprint(y[0, ::2])\n\nRetrieving every second element in the first row:\n[1 3]\n\n\n\n# Extract a submatrix from the original array\nprint(\"Extracting a submatrix:\")\nprint(y[:2, 1:3])\n\nExtracting a submatrix:\n[[2 3]\n [6 7]]\n\n\n\n4.2.1 Funzioni per ndarray\nNumpy offre varie funzioni per creare ndarray. Per esempio, √® possibile creare un array 1-D con la funzione .arange(start, stop, incr, dtype=..) che fornisce l‚Äôintervallo di numeri compreso fra start, stop, al passo incr:\n\nz = np.arange(2, 9, 2)\nprint(z)\n\n[2 4 6 8]\n\n\nSi usa spesso .arange per creare sequenze a incrementi unitari:\n\nw = np.arange(11)\nprint(w)\n\n[ 0  1  2  3  4  5  6  7  8  9 10]\n\n\nUn‚Äôaltra funzione molto utile √® .linspace:\n\nx = np.linspace(0, 10, num=20)\nprint(x)\n\n[ 0.          0.52631579  1.05263158  1.57894737  2.10526316  2.63157895\n  3.15789474  3.68421053  4.21052632  4.73684211  5.26315789  5.78947368\n  6.31578947  6.84210526  7.36842105  7.89473684  8.42105263  8.94736842\n  9.47368421 10.        ]\n\n\nFissati gli estremi (qui 0, 10) e il numero di elementi desiderati, .linspace determina in maniera automatica l‚Äôincremento.\nUna propriet√† molto utile dei ndarray √® la possibilit√† di filtrare gli elementi di un array che rispondono come True ad un criterio. Per esempio:\n\nprint(x[x &gt; 7])\n\n[ 7.36842105  7.89473684  8.42105263  8.94736842  9.47368421 10.        ]\n\n\nperch√© solo gli ultimi sei elementi di x rispondono True al criterio \\(x &gt; 7\\).\nLe dimensioni (‚Äúassi‚Äù) di un ndarray vengono ritornate dal metodo .dim. Per esempio:\n\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\ny.ndim\n\n2\n\n\n\nprint(y.max(axis=1))\n\n[ 4  8 12]\n\n\n\nprint(y.max(axis=0))\n\n[ 9 10 11 12]\n\n\nIl numero di elementi per ciascun asse viene ritornato dal metodo .shape:\n\ny.shape\n\n(3, 4)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#manipolazione-di-array-con-numpy",
    "href": "chapters/chapter_1/03_numpy.html#manipolazione-di-array-con-numpy",
    "title": "4¬† NumPy",
    "section": "4.3 Manipolazione di Array con NumPy",
    "text": "4.3 Manipolazione di Array con NumPy\nNumPy rende pi√π agevole lavorare con grandi quantit√† di dati. Un concetto fondamentale in NumPy sono gli array monodimensionali, spesso utilizzati per rappresentare vettori, ovvero sequenze di numeri che possono rappresentare, ad esempio, le misurazioni di una variabile specifica. Grazie a NumPy, possiamo eseguire operazioni aritmetiche su questi vettori in modo semplice, applicando la stessa operazione a tutti gli elementi dell‚Äôarray contemporaneamente.\n\n4.3.1 Cosa Significa Vettorizzare un‚ÄôOperazione\nLa vettorizzazione √® una delle funzionalit√† pi√π efficaci di NumPy. Quando diciamo che un‚Äôoperazione √® vettorizzata, significa che questa operazione viene applicata in un colpo solo a tutti gli elementi dell‚Äôarray, invece di dover agire su ciascun elemento individualmente. Questo approccio rende la manipolazione di grandi insiemi di dati non solo pi√π veloce ma anche pi√π intuitiva, poich√© consente di trattare l‚Äôintero insieme di dati come un‚Äôunica entit√† anzich√© come una serie di punti dati individuali.\nSupponiamo di avere raccolto i dati di 4 individui\n\nm = np.array([1.62, 1.75, 1.55, 1.74])\nkg = np.array([55.4, 73.6, 57.1, 59.5])\n\nprint(m)\nprint(kg)\n\n[1.62 1.75 1.55 1.74]\n[55.4 73.6 57.1 59.5]\n\n\ndove m √® l‚Äôarray che contiene i dati relativi all‚Äôaltezza in metri dei quattro individui e kg √® l‚Äôarray che contiene i dati relativi al peso in kg. I dati sono organizzati in modo tale che il primo elemento di entrambi i vettori si riferisce alle misure del primo individuo, il secondo elemento dei due vettori si riferisce alle misure del secondo individuo, ecc.\nSupponiamo di volere calcolare l‚Äôindice BMI:\n\\[\nBMI = \\frac{kg}{m^2}.\n\\]\nPer il primo individuo del campione, l‚Äôindice di massa corporea √®\n\n55.4 / 1.62**2\n\n21.109586953208346\n\n\nSi noti che non abbiamo bisogno di scrivere 55.4 / (1.62**2) in quanto, in Python, l‚Äôelevazione a potenza viene eseguita prima della somma e della divisione (come in tutti i linguaggi). Usando i dati immagazzinati nei due vettori, lo stesso risultato si ottiene nel modo seguente:\n\nkg[0] / m[0]**2\n\n21.109586953208346\n\n\nSe ora non specifichiamo l‚Äôindice (per esempio, [0]), le operazioni aritmetiche indicate verranno eseguite per ciascuna coppia di elementi corrispondenti nei due vettori:\n\nbmi = kg / m**2\n\nOtteniamo cos√¨, con una sola istruzione, l‚Äôindice BMI dei quattro individui:\n\nbmi.round(1)\n\narray([21.1, 24. , 23.8, 19.7])\n\n\nQuesto esempio illustra come le operazioni aritmetiche standard vengano eseguite elemento per elemento negli array, grazie al processo di vettorizzazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#broadcasting",
    "href": "chapters/chapter_1/03_numpy.html#broadcasting",
    "title": "4¬† NumPy",
    "section": "4.4 Broadcasting",
    "text": "4.4 Broadcasting\nIl broadcasting √® una caratteristica distintiva di NumPy che facilita l‚Äôesecuzione di operazioni tra array di dimensioni diverse o tra un array e uno scalare, anche se le loro dimensioni non sono direttamente compatibili. Grazie al broadcasting, NumPy √® in grado di ‚Äúespandere‚Äù automaticamente le dimensioni di uno degli operandi per rendere possibile l‚Äôoperazione.\nQuesto significa che possiamo, per esempio, eseguire un‚Äôoperazione tra un array e un numero singolo (un vettore e uno scalare) o tra due array di dimensioni differenti, senza la necessit√† di modificare manualmente le dimensioni di questi array. Il broadcasting si occupa di adattare le dimensioni in modo coerente per consentire l‚Äôoperazione desiderata. Ci√≤ rende il codice pi√π snello e leggibile, eliminando la necessit√† di espandere gli array manualmente.\nIn breve, il broadcasting in NumPy √® un potente strumento che semplifica l‚Äôesecuzione di operazioni su array di dimensioni diverse o tra array e scalari, automatizzando l‚Äôallineamento delle dimensioni.\n\n4.4.1 Esempio di Broadcasting\nImmaginiamo di avere un array A con dimensioni 3x3 e un numero scalare B. Senza broadcasting, dovremmo espandere B in un array 3x3 riempiendo ogni cella con il valore di B per eseguire un‚Äôoperazione come l‚Äôaddizione su ciascun elemento di A. Grazie al broadcasting, possiamo semplicemente scrivere A + B, e NumPy si occuper√† automaticamente di ‚Äúespandere‚Äù B durante l‚Äôoperazione, applicando il valore scalare a ogni elemento di A.\n\n# Creiamo un array 3x3\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Definiamo uno scalare\nB = 5\n\n# Applichiamo il broadcasting per aggiungere lo scalare a ogni elemento dell'array\nC = A + B\n\nprint(C)\n\n[[ 6  7  8]\n [ 9 10 11]\n [12 13 14]]\n\n\nIn questo esempio, C conterr√† l‚Äôarray originale A con ogni elemento incrementato di 5, dimostrando come il broadcasting semplifichi operazioni che altrimenti richiederebbero passaggi aggiuntivi.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#altre-operazioni-sugli-array",
    "href": "chapters/chapter_1/03_numpy.html#altre-operazioni-sugli-array",
    "title": "4¬† NumPy",
    "section": "4.5 Altre operazioni sugli array",
    "text": "4.5 Altre operazioni sugli array\nC‚Äô√® un numero enorme di funzioni predefinite in NumPy che calcolano automaticamente diverse quantit√† sugli ndarray. Ad esempio:\n\nmean(): calcola la media di un vettore o matrice;\nsum(): calcola la somma di un vettore o matrice;\nstd(): calcola la deviazione standard;\nmin(): trova il minimo nel vettore o matrice;\nmax(): trova il massimo;\nndim: dimensione del vettore o matrice;\nshape: restituisce una tupla con la ‚Äúforma‚Äù del vettore o matrice;\nsize: restituisce la dimensione totale del vettore (=ndim) o della matrice;\ndtype: scrive il tipo numpy del dato;\nzeros(num): scrive un vettore di num elementi inizializzati a zero;\narange(start,stop,step): genera un intervallo di valori (interi o reali, a seconda dei valori di start, ecc.) intervallati di step. Nota che i dati vengono generati nell‚Äôintervallo aperto [start,stop)!\nlinstep(start,stop,num): genera un intervallo di num valori interi o reali a partire da start fino a stop (incluso!);\nastype(tipo): converte l‚Äôndarray nel tipo specificato\n\nPer esempio:\n\nx = np.array([1, 2, 3])\nprint(x)\n\n[1 2 3]\n\n\n\n[x.min(), x.max(), x.sum(), x.mean(), x.std()]\n\n[1, 3, 6, 2.0, 0.816496580927726]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#lavorare-con-formule-matematiche",
    "href": "chapters/chapter_1/03_numpy.html#lavorare-con-formule-matematiche",
    "title": "4¬† NumPy",
    "section": "4.6 Lavorare con formule matematiche",
    "text": "4.6 Lavorare con formule matematiche\nL‚Äôimplementazione delle formule matematiche sugli array √® un processo molto semplice con Numpy. Possiamo prendere ad esempio la formula della deviazione standard che discuteremo nel capitolo {ref}loc-scale-notebook:\n\\[\ns = \\sqrt{\\sum_{i=1}^n\\frac{(x_i - \\bar{x})^2}{n}}\n\\]\nL‚Äôimplementazione su un array NumPy √® la seguente:\n\nprint(x)\n\n[1 2 3]\n\n\n\nnp.sqrt(np.sum((x - np.mean(x)) ** 2) / np.size(x))\n\n0.816496580927726\n\n\nQuesta implementazione funziona nello stesso modo sia che x contenga 3 elementi (come nel caso presente) sia che x contenga migliaia di elementi. √à importante notare l‚Äôutilizzo delle parentesi tonde per specificare l‚Äôordine di esecuzione delle operazioni. In particolare, nel codice fornito, si inizia calcolando la media degli elementi del vettore x per mezzo della funzione np.mean(x). Questa operazione produce uno scalare, ovvero un singolo valore numerico che rappresenta la media degli elementi del vettore. L‚Äôutilizzo delle parentesi tonde √® fondamentale per garantire l‚Äôordine corretto delle operazioni. In questo caso, la funzione np.mean() viene applicata al vettore x prima di qualsiasi altra operazione matematica. Senza le parentesi tonde, le operazioni verrebbero eseguite in un ordine diverso e il risultato potrebbe essere errato.\n\nnp.mean(x)\n\n2.0\n\n\nSuccessivamente, eseguiamo la sottrazione dei singoli elementi del vettore x per la media del vettore stesso, ovvero \\(x_i - \\bar{x}\\), utilizzando il meccanismo del broadcasting.\n\nx - np.mean(x)\n\narray([-1.,  0.,  1.])\n\n\nEleviamo poi al quadrato gli elementi del vettore che abbiamo ottenuto:\n\n(x - np.mean(x)) ** 2\n\narray([1., 0., 1.])\n\n\nSommiamo gli elementi del vettore:\n\nnp.sum((x - np.mean(x)) ** 2)\n\n2.0\n\n\nDividiamo il numero ottenuto per \\(n\\). Questa √® la varianza di \\(x\\):\n\nres = np.sum((x - np.mean(x)) ** 2) / np.size(x)\nres\n\n0.6666666666666666\n\n\nInfine, per ottenere la deviazione standard, prendiamo la radice quadrata:\n\nnp.sqrt(res)\n\n0.816496580927726\n\n\nIl risultato ottenuto coincide con quello che si trova applicando la funzione np.std():\n\nnp.std(x)\n\n0.816496580927726",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#slicing",
    "href": "chapters/chapter_1/03_numpy.html#slicing",
    "title": "4¬† NumPy",
    "section": "4.7 Slicing",
    "text": "4.7 Slicing\nPer concludere, spendiamo ancora alcune parole sull‚Äôindicizzazione degli ndarray.\nSlicing in Numpy √® un meccanismo che consente di selezionare una porzione di un array multidimensionale, ovvero una sotto-matrice o un sotto-vettore. Per selezionare una porzione di un array, si utilizza la sintassi [start:stop:step], dove start indica l‚Äôindice di partenza della porzione, stop indica l‚Äôindice di fine e step indica il passo da utilizzare per la selezione. Se uno o pi√π di questi valori vengono omessi, vengono utilizzati dei valori di default.\nAd esempio, se abbiamo un array arr di dimensione (3, 4) e vogliamo selezionare la seconda colonna, possiamo usare la sintassi arr[:, 1]. In questo caso, il simbolo : indica che vogliamo selezionare tutte le righe, mentre il numero 1 indica che vogliamo selezionare la seconda colonna.\nInoltre, possiamo utilizzare il meccanismo di slicing anche per selezionare porzioni di array multidimensionali. Ad esempio, se abbiamo un array arr di dimensione (3, 4, 5) e vogliamo selezionare la prima riga di ciascuna matrice 4x5, possiamo usare la sintassi arr[:, 0, :].\nPer esempio, creiamo l‚Äôarray x di rango 2 con shape (3, 4):\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nUtilizziamo il meccanismo di slicing per estrarre la sottomatrice composta dalle prime 2 righe e dalle colonne 1 e 2. y √® l‚Äôarray risultante di dimensione (2, 2):\n\ny = x[:2, 1:3]\nprint(y)\n\n[[2 3]\n [6 7]]\n\n\n√à importante sapere che uno slice di un array in Numpy √® una vista degli stessi dati, il che significa che modificarlo implica la modifica dell‚Äôarray originale. In pratica, quando si modifica uno slice di un array, si sta modificando direttamente l‚Äôarray originale e tutte le altre visualizzazioni dell‚Äôarray vedranno la stessa modifica. Questo avviene perch√© Numpy √® progettato per gestire enormi quantit√† di dati, pertanto cerca di evitare il pi√π possibile di effettuare copie dei dati.\nQuesto comportamento deve essere preso in considerazione durante la modifica degli array in Numpy, al fine di evitare modifiche accidentali o indesiderate. In alcuni casi, √® possibile utilizzare il metodo copy() per creare una copia indipendente di un array e lavorare sulla copia senza modificare l‚Äôoriginale. Vediamo un esempio.\n\nprint(x[0, 1])   \n\n2\n\n\n\ny[0, 0] = 77     \n\n\nprint(x)\n\n[[ 1 77  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nz = x.copy()\nprint(z)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nz[0, 1] = 33\nprint(z)\n\n[[ 1 33  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#copia-e-copia-profonda-in-python",
    "href": "chapters/chapter_1/03_numpy.html#copia-e-copia-profonda-in-python",
    "title": "4¬† NumPy",
    "section": "4.8 Copia e ‚ÄúCopia Profonda‚Äù in Python",
    "text": "4.8 Copia e ‚ÄúCopia Profonda‚Äù in Python\nIn Python, per ottimizzare le prestazioni, le assegnazioni di solito non copiano gli oggetti sottostanti. Questo √® particolarmente importante, ad esempio, quando gli oggetti vengono passati tra funzioni, per evitare una quantit√† eccessiva di copie in memoria quando non sono necessarie (questo approccio √® noto tecnicamente come ‚Äúpassaggio per riferimento‚Äù).\nConsideriamo il seguente esempio con un array A:\n\nA = np.array([[1, 2], [3, 4]])\n\nSe creiamo un nuovo riferimento B a A:\n\nB = A\n\nOra B si riferisce allo stesso insieme di dati di A. Se modifichiamo B, anche A viene modificato di conseguenza:\n\nB[0,0] = 10\n\nDopo questa modifica, sia B che A saranno:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nSe desideriamo evitare questo comportamento, in modo tale che B diventi un oggetto completamente indipendente da A, dobbiamo effettuare una cosiddetta ‚Äúcopia profonda‚Äù utilizzando la funzione copy:\n\nB = np.copy(A)\n\nOra, se modificassimo B, A non subirebbe alcuna modifica. Ad esempio:\n\nB[0,0] = -5\n\nA questo punto, B sar√†:\n\nprint(B)\n\n[[-5  2]\n [ 3  4]]\n\n\nMa A rimarr√† invariato:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nQuesto esempio mostra chiaramente la differenza tra una semplice assegnazione, che crea un riferimento all‚Äôoggetto originale, e una ‚Äúcopia profonda‚Äù, che crea un nuovo oggetto indipendente.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "title": "4¬† NumPy",
    "section": "4.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "4.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy: 1.26.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html",
    "href": "chapters/chapter_1/04_pandas.html",
    "title": "5¬† Pandas (1)",
    "section": "",
    "text": "5.1 Preparazione del NoteBook\nimport pandas as pd\nimport numpy as np\n\n# Di default, Pandas mostrer√† 60 righe e 20 colonne. \n# Modifichiamo qui le impostazioni di visualizzazione predefinite di Pandas per mostrare pi√π righe.\npd.options.display.max_rows = 100",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#series",
    "href": "chapters/chapter_1/04_pandas.html#series",
    "title": "5¬† Pandas (1)",
    "section": "5.2 Series",
    "text": "5.2 Series\nIn Pandas, una Series √® un array unidimensionale composto da una sequenza di valori omogenei, simile ad un ndarray, accompagnato da un array di etichette chiamato ‚Äúindex‚Äù. A differenza degli indici degli array Numpy, che sono sempre interi e partono da zero, gli oggetti Series supportano etichette personalizzate che possono essere, ad esempio, delle stringhe. Inoltre, gli oggetti Series possono contenere dati mancanti che vengono ignorati da molte delle operazioni della classe.\nIl modo pi√π semplice di creare un oggetto Series √® di convertire una lista. Per esempio:\n\ngrades = pd.Series([27, 30, 24, 18, 22, 20, 29])\n\n√à possibile ottenere la rappresentazione dell‚Äôarray dell‚Äôoggetto e dell‚Äôindice dell‚Äôoggetto Series tramite i suoi attributi array e index, rispettivamente.\n\ngrades.array\n\n&lt;NumpyExtensionArray&gt;\n[27, 30, 24, 18, 22, 20, 29]\nLength: 7, dtype: int64\n\n\n\ngrades.index\n\nRangeIndex(start=0, stop=7, step=1)\n\n\nOppure, possiamo semplicemente stampare i contenuti dell‚Äôoggetto Series direttamente:\n\nprint(grades)\n\n0    27\n1    30\n2    24\n3    18\n4    22\n5    20\n6    29\ndtype: int64\n\n\nPer accedere agli elementi di un oggetto Series si usano le parentesi quadre contenenti un indice:\n\ngrades[0]\n\n27\n\n\n\ngrades[0:3]\n\n0    27\n1    30\n2    24\ndtype: int64\n\n\n√à possibile filtrare gli elementi di un oggetto Series con un array booleano:\n\ngrades &gt; 24\n\n0     True\n1     True\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: bool\n\n\n\ngrades[grades &gt; 24]\n\n0    27\n1    30\n6    29\ndtype: int64\n\n\n√à possibile manipolare gli elementi di un oggetto Series con le normali operazioni aritmetiche mediante la vettorializzazione:\n\ngrades / 10\n\n0    2.7\n1    3.0\n2    2.4\n3    1.8\n4    2.2\n5    2.0\n6    2.9\ndtype: float64\n\n\n\nnp.sqrt(grades)\n\n0    5.196152\n1    5.477226\n2    4.898979\n3    4.242641\n4    4.690416\n5    4.472136\n6    5.385165\ndtype: float64\n\n\nGli oggetti Series hanno diversi metodi per svolgere varie operazioni, per esempio per ricavare alcune statistiche descrittive:\n\n[grades.count(), grades.mean(), grades.min(), grades.max(), grades.std(), grades.sum()]\n\n[7, 24.285714285714285, 18, 30, 4.572172558506722, 170]\n\n\nMolto utile √® il metodo .describe():\n\ngrades.describe()\n\ncount     7.000000\nmean     24.285714\nstd       4.572173\nmin      18.000000\n25%      21.000000\n50%      24.000000\n75%      28.000000\nmax      30.000000\ndtype: float64",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#dataframe",
    "href": "chapters/chapter_1/04_pandas.html#dataframe",
    "title": "5¬† Pandas (1)",
    "section": "5.3 DataFrame",
    "text": "5.3 DataFrame\nUn pandas.DataFrame √® composto da righe e colonne. Ogni colonna di un dataframe √® un oggetto pandas.Series: quindi, un dataframe √® una collezione di serie. A differenza di un array NumPy, un dataframe pu√≤ combinare pi√π tipi di dati, come numeri e testo, ma i dati in ogni colonna sono dello stesso tipo.\nEsistono molti modi per costruire un DataFrame. Un primo metodo √® quello di utilizzare un dizionario che include una o pi√π liste o array Numpy di uguale lunghezza. Per esempio:\n\ndata = {\n    \"name\": [\n        \"Maria\",\n        \"Anna\",\n        \"Francesco\",\n        \"Cristina\",\n        \"Gianni\",\n        \"Gabriella\",\n        \"Stefano\",\n    ],\n    \"sex\": [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"],\n    \"group\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"],\n    \"x\": [1, 2, 3, 4, 5, 6, 7],\n    \"y\": [8, 9, 10, 11, 12, 13, 14],\n    \"z\": [15, 16, 17, 18, 19, 20, 21],\n}\nframe = pd.DataFrame(data)\nframe\n\n\n\n\n\n\n\n\n\nname\nsex\ngroup\nx\ny\nz\n\n\n\n\n0\nMaria\nf\na\n1\n8\n15\n\n\n1\nAnna\nf\nb\n2\n9\n16\n\n\n2\nFrancesco\nm\na\n3\n10\n17\n\n\n3\nCristina\nf\nb\n4\n11\n18\n\n\n4\nGianni\nm\nb\n5\n12\n19\n\n\n5\nGabriella\nf\nc\n6\n13\n20\n\n\n6\nStefano\nm\na\n7\n14\n21\n\n\n\n\n\n\n\n\nOppure possiamo procedere nel modo seguente:\n\ndf = pd.DataFrame()\n\ndf[\"x\"] = [1, 2, 3, 4, 5, 6, 7]\ndf[\"y\"] = [8, 9, 10, 11, 12, 13, 14]\ndf[\"z\"] = [14.4, 15.1, 16.7, 17.3, 18.9, 19.3, 20.2]\ndf[\"group\"] = [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"]\ndf[\"sex\"] = [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"]\ndf[\"name\"] = [\n    \"Maria\",\n    \"Anna\",\n    \"Francesco\",\n    \"Cristina\",\n    \"Gianni\",\n    \"Gabriella\",\n    \"Stefano\",\n]\n\nprint(df)\n\n   x   y     z group sex       name\n0  1   8  14.4     a   f      Maria\n1  2   9  15.1     b   f       Anna\n2  3  10  16.7     a   m  Francesco\n3  4  11  17.3     b   f   Cristina\n4  5  12  18.9     b   m     Gianni\n5  6  13  19.3     c   f  Gabriella\n6  7  14  20.2     a   m    Stefano\n\n\nMolto spesso un DataFrame viene creato dal caricamento di dati da file.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#lettura-di-dati-da-file",
    "href": "chapters/chapter_1/04_pandas.html#lettura-di-dati-da-file",
    "title": "5¬† Pandas (1)",
    "section": "5.4 Lettura di dati da file",
    "text": "5.4 Lettura di dati da file\nDi solito la quantit√† di dati da analizzare √® tale che non √® pensabile di poterli immettere manualmente in una o pi√π liste. Normalmente i dati sono memorizzati su un file ed √® necessario importarli. La lettura (importazione) dei file √® il primo fondamentale passo nel processo pi√π generale di analisi dei dati.\nIn un primo esempio, importiamo i dati da un repository remoto.\n\nurl = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\ntitanic = pd.read_csv(url, index_col=\"Name\")\n\n√à possibile usare il metodo .head() per visualizzare le prime cinque righe.\n\ntitanic.head()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBraund, Mr. Owen Harris\n1\n0\n3\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\n2\n1\n1\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\nHeikkinen, Miss. Laina\n3\n1\n3\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n4\n1\n1\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\nAllen, Mr. William Henry\n5\n0\n3\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\nLe statistiche descrittive per ciascuna colonna si ottengono con il metodo describe.\n\ntitanic.describe()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.000000\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.486592\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n0.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n0.000000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n0.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n1.000000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n1.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n\n\n\nIn questo modo possiamo ottenere informazioni sui nomi dei passeggeri, la sopravvivenza (0 o 1), l‚Äôet√†, il prezzo del biglietto, ecc. Con le statistiche riassuntive vediamo che l‚Äôet√† media √® di 29,7 anni, il prezzo massimo del biglietto √® di 512 USD, il 38% dei passeggeri √® sopravvissuto, ecc.\nPer fare un secondo esempio, importo i dati dal file penguins.csv situato nella directory ‚Äúdata‚Äù del mio computer. I dati relativi ai pinguini di Palmer sono resi disponibili da Kristen Gorman e dalla Palmer station, Antarctica LTER. La seguente cella legge il contenuto del file penguins.csv e lo inserisce nell‚Äôoggetto df utilizzando la funzione read_csv() di Pandas.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nPer il DataFrame df il significato delle colonne √® il seguente:\n\nspecies: a factor denoting penguin type (Ad√©lie, Chinstrap and Gentoo)\nisland: a factor denoting island in Palmer Archipelago, Antarctica (Biscoe, Dream or Torgersen)\nbill_length_mm: a number denoting bill length (millimeters)\nbill_depth_mm: a number denoting bill depth (millimeters)\nflipper_length_mm: an integer denoting flipper length (millimeters)\nbody_mass_g: an integer denoting body mass (grams)\nsex: a factor denoting sexuality (female, male)\nyear: the year of the study\n\nUsiamo il metodo .head() per visualizzare le prime cinque righe.\n\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nA volte potrebbero esserci dati estranei alla fine del file, quindi √® importante anche controllare le ultime righe:\n\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n\n\n\n\nUn breve tutorial in formato video √® disponibile tramite il seguente [collegamento](https://drive.google.com/file/d/12y7jZ0McvZBXThg6yjFgWx2ljQKrhoYR/view?usp=share_link), il quale illustra come effettuare la lettura dei dati da un file esterno in Visual Studio Code. \nL‚Äôattributo .dtypes restituisce il tipo dei dati:\n\ndf.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\nGli attributi pi√π comunemente usati sono elencati di seguito:\n\n\n\n\n\n\n\nAttributo\nRitorna\n\n\n\n\ndtypes\nIl tipo di dati in ogni colonna\n\n\nshape\nUna tupla con le dimensioni del DataFrame object (numero di righe, numero di colonne)\n\n\nindex\nL‚Äôoggetto Index lungo le righe del DataFrame\n\n\ncolumns\nIl nome delle colonne\n\n\nvalues\nI dati contenuti nel DataFrame\n\n\nempty\nCheck if the DataFrame object is empty\n\n\n\nPer esempio, l‚Äôistruzione della cella seguente restituisce l‚Äôelenco con i nomi delle colonne del DataFrame df:\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')\n\n\nLe dimensioni del Data Frame si ottengono con l‚Äôattributo .shape, che ritorna il numero di righe e di colonne. Nel caso presente, ci sono 344 righe e 8 colonne.\n\ndf.shape\n\n(344, 8)\n\n\nCome abbiamo gi√† visto in precedenza, un sommario dei dati si ottiene con il metodo .describe():\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\n\nUna descrizione del DataFrame si ottiene con il metodo .info().\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nSi noti che, alle volte, abbiamo utilizzato la sintassi `df.word` e talvolta la sintassi `df.word()`. Tecnicamente, la classe Pandas Dataframe ha sia attributi che metodi. Gli attributi sono `.word`, mentre i metodi sono `.word()` o `.word(arg1, arg2, ecc.)`. Per sapere se qualcosa √® un metodo o un attributo √® necessario leggere la documentazione.\nAbbiamo visto in precedenza come possiamo leggere i dati in un dataframe utilizzando la funzione read_csv(). Pandas comprende anche molti altri formati, ad esempio utilizzando le funzioni read_excel(), read_hdf(), read_json(), ecc. (e i corrispondenti metodi per scrivere su file: to_csv(), to_excel(), to_hdf(), to_json(), ecc.).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#gestione-dei-dati-mancanti",
    "href": "chapters/chapter_1/04_pandas.html#gestione-dei-dati-mancanti",
    "title": "5¬† Pandas (1)",
    "section": "5.5 Gestione dei dati mancanti",
    "text": "5.5 Gestione dei dati mancanti\nNell‚Äôoutput di .info() troviamo la colonna ‚ÄúNon-Null Count‚Äù, ovvero il numero di dati non mancanti per ciascuna colonna del DataFrame. Da questo si nota che le colonne del DataFrame df contengono alcuni dati mancanti. La gestione dei dati mancanti √® un argomento complesso. Per ora ci limitiamo ad escludere tutte le righe che, in qualche colonna, contengono dei dati mancanti.\nOttengo il numero di dati per ciascuna colonna del DataFrame:\n\ndf.isnull().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\nRimuovo i dati mancanti con il metodo .dropna(). L‚Äôargomento inplace=True specifica il DataFrame viene trasformato in maniera permanente.\n\ndf.dropna(inplace=True)\n\nVerifico che i dati mancanti siano stati rimossi.\n\ndf.shape\n\n(333, 8)\n\n\nIn alternativa, possiamo rimuovere solo le righe del DataFrame per le quali ci sono dei dati mancanti rispetto a specifiche colonne. Per esempio\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf0 = df.copy()\n\nmissing_data = df0.isnull()[[\"bill_length_mm\", \"body_mass_g\"]].any(axis=1)\n# Drop rows with any missing data\ndf0_cleaned = df0.loc[~missing_data]\ndf0_cleaned.shape\n\n(342, 8)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#rinominare-le-colonne",
    "href": "chapters/chapter_1/04_pandas.html#rinominare-le-colonne",
    "title": "5¬† Pandas (1)",
    "section": "5.6 Rinominare le colonne",
    "text": "5.6 Rinominare le colonne\n√à possibile rinominare tutte le colonne passando al metodo .rename() un dizionario che specifica quali colonne devono essere mappate a cosa. Nella cella seguente facciamo prima una copia del DataFrame con il metodo copy() e poi rinominiamo sex che diventa gender e year che diventa year_of_the_study:\n\ndf1 = df.copy()\n\n# rename(columns={\"OLD_NAME\": \"NEW_NAME\"})\ndf1.rename(columns={\n    \"sex\": \"gender\", \n    \"year\": \"year_of_the_study\"\n    }, \n           inplace=True)\ndf1.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\ngender\nyear_of_the_study\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python valgono le seguenti regole.\n\n- Il nome di una variabile deve iniziare con una lettera o con il trattino basso (*underscore*) `_`.\n- Il nome di una variabile non pu√≤ iniziare con un numero.\n- Un nome di variabile pu√≤ contenere solo caratteri alfanumerici e il trattino basso (A-z, 0-9 e _).\n- I nomi delle variabili fanno distinzione tra maiuscole e minuscole (`age`, `Age` e `AGE` sono tre variabili diverse).\n\nGli spazi non sono consentiti nel nome delle variabili: come separatore usate il trattino basso.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "href": "chapters/chapter_1/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "title": "5¬† Pandas (1)",
    "section": "5.7 Estrarre i dati dal DataFrame",
    "text": "5.7 Estrarre i dati dal DataFrame\nUna parte cruciale del lavoro con i DataFrame √® l‚Äôestrazione di sottoinsiemi di dati: vogliamo trovare le righe che soddisfano un determinato insieme di criteri, vogliamo isolare le colonne/righe di interesse, ecc. Per rispondere alle domande di interesse dell‚Äôanalisi dei dati, molto spesso √® necessario selezionare un sottoinsieme del DataFrame.\n\n5.7.1 Colonne\n√à possibile estrarre una colonna da un DataFrame usando una notazione simile a quella che si usa per il dizionario (DataFrame['word']) o utilizzando la notazione DataFrame.word. Per esempio:\n\ndf[\"bill_length_mm\"]\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\n\ndf.bill_length_mm\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\nSe tra parentesi quadre indichiamo una lista di colonne, come nel caso di df[['bill_length_mm','species']], otteniamo un nuovo DataFrame costituito unicamente dalle colonne selezionate:\n\ndf[[\"bill_length_mm\", \"species\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nspecies\n\n\n\n\n0\n39.1\nAdelie\n\n\n1\n39.5\nAdelie\n\n\n2\n40.3\nAdelie\n\n\n4\n36.7\nAdelie\n\n\n5\n39.3\nAdelie\n\n\n...\n...\n...\n\n\n339\n55.8\nChinstrap\n\n\n340\n43.5\nChinstrap\n\n\n341\n49.6\nChinstrap\n\n\n342\n50.8\nChinstrap\n\n\n343\n50.2\nChinstrap\n\n\n\n\n333 rows √ó 2 columns\n\n\n\n\n\n\n5.7.2 Righe\nIn un pandas.DataFrame, anche le righe hanno un nome. I nomi delle righe sono chiamati index:\n\ndf.index\n\nInt64Index([  0,   1,   2,   4,   5,   6,   7,  12,  13,  14,\n            ...\n            334, 335, 336, 337, 338, 339, 340, 341, 342, 343],\n           dtype='int64', length=333)\n\n\nCi sono vari metodi per estrarre sottoinsimi di righe da un DataFrame. √à possibile fare riferimento ad un intervallo di righe mediante un indice di slice. Per esempio, possiamo ottenere le prime 3 righe del DataFrame df nel modo seguente:\n\ndf[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python una sequenza √® determinata dal valore iniziale e quello finale ma si interrompe ad n-1. Pertanto, per selezionare una singola riga (per esempio, la prima) dobbiamo procedere nel modo seguente:\n\ndf[0:1]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n\n\n\n\n\n\n\n\n5.7.3 Indicizzazione, selezione e filtraggio\nPoich√© l‚Äôoggetto DataFrame √® bidimensionale, √® possibile selezionare un sottoinsieme di righe e colonne utilizzando le etichette degli assi (loc) o gli indici delle righe (iloc).\nPer esempio, usando l‚Äôattributo iloc posso selezionare la prima riga del DataFrame:\n\ndf.iloc[0]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            39.1\nbill_depth_mm             18.7\nflipper_length_mm        181.0\nbody_mass_g             3750.0\nsex                       male\nyear                      2007\nName: 0, dtype: object\n\n\nLa cella seguene seleziona le prime tre righe del DataFrame:\n\ndf.iloc[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nL‚Äôattributo loc consente di selezionare simultaneamente righe e colonne per ‚Äúnome‚Äù. Il ‚Äúnome‚Äù delle righe √® l‚Äôindice di riga. Per esempio, visualizzo il quinto valore della colonna body_mass_g:\n\ndf.loc[4, \"body_mass_g\"]\n\n3450.0\n\n\noppure, il quinto valore delle colonne bill_length_mm, bill_depth_mm, flipper_length_mm:\n\ndf.loc[4, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\nbill_length_mm        36.7\nbill_depth_mm         19.3\nflipper_length_mm    193.0\nName: 4, dtype: object\n\n\nVisualizzo ora le prime tre righe sulle tre colonne precedenti. Si noti l‚Äôuso di : per definire un intervallo di valori sull‚Äôindice di riga.\n\ndf.loc[0:2, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n39.1\n18.7\n181.0\n\n\n1\n39.5\n17.4\n186.0\n\n\n2\n40.3\n18.0\n195.0\n\n\n\n\n\n\n\n\nUna piccola variante della sintassi precedente si rivela molto utile. Qui, il segno di due punti (:) signfica ‚Äútutte le righe‚Äù:\n\nkeep_cols = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\nprint(df.loc[:, keep_cols])\n\n     bill_length_mm  bill_depth_mm  flipper_length_mm\n0              39.1           18.7              181.0\n1              39.5           17.4              186.0\n2              40.3           18.0              195.0\n4              36.7           19.3              193.0\n5              39.3           20.6              190.0\n..              ...            ...                ...\n339            55.8           19.8              207.0\n340            43.5           18.1              202.0\n341            49.6           18.2              193.0\n342            50.8           19.0              210.0\n343            50.2           18.7              198.0\n\n[333 rows x 3 columns]\n\n\n\n\n5.7.4 Filtrare righe in maniera condizionale\nIn precedenza abbiamo utilizzato la selezione delle righe in un DataFrame in base alla loro posizione. Tuttavia, √® pi√π comune selezionare le righe del DataFrame utilizzando una condizione logica, cio√® tramite l‚Äôindicizzazione booleana.\nIniziamo con un esempio relativo ad una condizione specificata sui valori di una sola colonna. Quando applichiamo un operatore logico come &gt;, &lt;, ==, != ai valori di una colonna del DataFrame, il risultato √® una sequenza di valori booleani (True, False), uno per ogni riga nel DataFrame, i quali indicano se, per quella riga, la condizione √® vera o falsa. Ad esempio:\n\ndf[\"island\"] == \"Torgersen\"\n\n0       True\n1       True\n2       True\n4       True\n5       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: island, Length: 333, dtype: bool\n\n\nUtilizzando i valori booleani che sono stati ottenuti in questo modo √® possibile filtrare le righe del DataFrame, ovvero, ottenere un nuovo DataFrame nel quale la condizione logica specificata √® vera su tutte le righe. Per esempio, nella cella seguente selezioniamo solo le osservazioni relative all‚Äôisola Torgersen, ovvero tutte le righe del DataFrame nelle quali la colonna island assume il valore Torgersen.\n\nonly_torgersen = df[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo scrivere:\n\nonly_torgersen = df.loc[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\n√à possibile combinare pi√π condizioni logiche usando gli operatori & (e), | (oppure). Si presti attenzione all‚Äôuso delle parentesi.\n\ndf.loc[(df[\"island\"] == \"Torgersen\") & (df[\"sex\"] == \"female\")].head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n12\nAdelie\nTorgersen\n41.1\n17.6\n182.0\n3200.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n\n5.7.5 Metodo .query\n√à anche possibile filtrare le righe del DataFrame usando il metodo query(). Ci sono diversi modi per generare sottoinsiemi con Pandas. I metodi loc e iloc consentono di recuperare sottoinsiemi in base alle etichette di riga e colonna o all‚Äôindice intero delle righe e delle colonne. E Pandas ha una notazione a parentesi quadre che consente di utilizzare condizioni logiche per recuperare righe di dati specifiche. Ma la sintassi di questi metodi non √® la pi√π trasparente. Inoltre, tali metodi sono difficili da usare insieme ad altri metodi di manipolazione dei dati in modo organico.\nIl metodo .query di Pandas cerca di risolve questi problemi. Il metodo .query consente di ‚Äúinterrogare‚Äù un DataFrame e recuperare sottoinsiemi basati su condizioni logiche. La sintassi √® un po‚Äô pi√π snella rispetto alla notazione a parentesi quadre di Pandas. Inoltre, il metodo .query pu√≤ essere utilizzato con altri metodi di Pandas in modo snello e semplice, rendendo la manipolazione dei dati maggiormente fluida e diretta.\nLa sintassi √® la seguente:\nyour_data_frame.query(expression, inplace = False)\nL‚Äôespressione utilizzata nella query √® una sorta di espressione logica che descrive quali righe restituire in output. Se l‚Äôespressione √® vera per una particolare riga, la riga verr√† inclusa nell‚Äôoutput. Se l‚Äôespressione √® falsa per una particolare riga, quella riga verr√† esclusa dall‚Äôoutput.\nIl parametro inplace consente di specificare se si desidera modificare direttamente il DataFrame con cui si sta lavorando.\nPer esempio:\n\neval_string = \"island == 'Torgersen' & sex == 'female' & year != 2009\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n6\n17.8\n181.0\n\n\n12\n17.6\n182.0\n\n\n15\n17.8\n185.0\n\n\n16\n19.0\n195.0\n\n\n18\n18.4\n184.0\n\n\n68\n16.6\n190.0\n\n\n70\n19.0\n190.0\n\n\n72\n17.2\n196.0\n\n\n74\n17.5\n190.0\n\n\n76\n16.8\n191.0\n\n\n78\n16.1\n187.0\n\n\n80\n17.2\n189.0\n\n\n82\n18.8\n187.0\n\n\n\n\n\n\n\n\nUn altro esempio usa la keyword in per selezionare solo le righe relative alle due isole specificate.\n\neval_string = \"island in ['Torgersen', 'Dream']\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n18.7\n181.0\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n5\n20.6\n190.0\n\n\n...\n...\n...\n\n\n339\n19.8\n207.0\n\n\n340\n18.1\n202.0\n\n\n341\n18.2\n193.0\n\n\n342\n19.0\n210.0\n\n\n343\n18.7\n198.0\n\n\n\n\n170 rows √ó 2 columns\n\n\n\n\nIl metodo query() pu√≤ anche essere utilizzato per selezionare le righe di un DataFrame in base alle relazioni tra le colonne. Ad esempio,\n\ndf.query(\"bill_length_mm &gt; 3*bill_depth_mm\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n152\n13.2\n211.0\n\n\n153\n16.3\n230.0\n\n\n154\n14.1\n210.0\n\n\n155\n15.2\n218.0\n\n\n156\n14.5\n215.0\n\n\n...\n...\n...\n\n\n272\n14.3\n215.0\n\n\n273\n15.7\n222.0\n\n\n274\n14.8\n212.0\n\n\n275\n16.1\n213.0\n\n\n293\n17.8\n181.0\n\n\n\n\n106 rows √ó 2 columns\n\n\n\n\n√à anche possibile fare riferimento a variabili non contenute nel DataFrame usando il carattere @.\n\noutside_var = 21\ndf.query(\"bill_depth_mm &gt; @outside_var\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n13\n21.2\n191.0\n\n\n14\n21.1\n198.0\n\n\n19\n21.5\n194.0\n\n\n35\n21.1\n196.0\n\n\n49\n21.2\n191.0\n\n\n61\n21.1\n195.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "href": "chapters/chapter_1/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "title": "5¬† Pandas (1)",
    "section": "5.8 Selezione casuale di un sottoinsieme di righe",
    "text": "5.8 Selezione casuale di un sottoinsieme di righe\nIl metodo sample() viene usato per ottenere un sottoinsieme casuale di righe del DataFrame. L‚Äôargomento replace=False indica l‚Äôestrazione senza rimessa (default); se specifichiamo replace=True otteniamo un‚Äôestrazione con rimessa. L‚Äôargomento n specifica il numero di righe che vogliamo ottenere. Ad esempio\n\ndf_sample = df.sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n204\nGentoo\nBiscoe\n45.1\n14.4\n210.0\n4400.0\nfemale\n2008\n\n\n69\nAdelie\nTorgersen\n41.8\n19.4\n198.0\n4450.0\nmale\n2008\n\n\n296\nChinstrap\nDream\n42.4\n17.3\n181.0\n3600.0\nfemale\n2007\n\n\n208\nGentoo\nBiscoe\n43.8\n13.9\n208.0\n4300.0\nfemale\n2008\n\n\n\n\n\n\n\n\n\ndf_sample = df[[\"bill_length_mm\", \"bill_depth_mm\"]].sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\n\n\n175\n46.3\n15.8\n\n\n133\n37.5\n18.5\n\n\n182\n47.3\n15.3\n\n\n251\n51.1\n16.5",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#selezione-di-colonne",
    "href": "chapters/chapter_1/04_pandas.html#selezione-di-colonne",
    "title": "5¬† Pandas (1)",
    "section": "5.9 Selezione di colonne",
    "text": "5.9 Selezione di colonne\nIl metodo drop() prende in input una lista con i nomi di colonne che vogliamo escludere dal DataFrame e pu√≤ essere usato per creare un nuovo DataFrame o per sovrascrivere quello di partenza. √à possibile usare le espressioni regolari (regex) per semplificare la ricerca dei nomi delle colonne.\nIn *regex* il simbolo `$` significa \"la stringa finisce con\"; il simbolo `^` significa \"la stringa inizia con\". L'espressione `regex` pu√≤ contenere (senza spazi) il simbolo `|` che significa \"oppure\". \nNel codice della cella seguente, alla funzione .columns.str.contains() viene passata l‚Äôespressione regolare mm$|year che significa: tutte le stringhe (in questo caso, nomi di colonne) che finiscono con mm oppure la stringa (nome di colonna) year.\n\nmask = df.columns.str.contains(\"mm$|year\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'year'], dtype='object')\n\n\n\ndf_new = df.drop(columns=columns_to_drop)\ndf_new.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n3750.0\nmale\n\n\n1\nAdelie\nTorgersen\n3800.0\nfemale\n\n\n2\nAdelie\nTorgersen\n3250.0\nfemale\n\n\n4\nAdelie\nTorgersen\n3450.0\nfemale\n\n\n5\nAdelie\nTorgersen\n3650.0\nmale\n\n\n\n\n\n\n\n\nIn un altro esempio, creaiamo l‚Äôelenco delle colonne che iniziano con la lettera ‚Äúb‚Äù, insieme a year e sex.\n\nmask = df.columns.str.contains(\"^b|year|sex\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'body_mass_g', 'sex', 'year'], dtype='object')\n\n\nOppure l‚Äôelenco delle colonne che contengono il patten ‚Äúlength‚Äù.\n\nmask = df.columns.str.contains(\"length\")\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'flipper_length_mm'], dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#creare-nuove-colonne",
    "href": "chapters/chapter_1/04_pandas.html#creare-nuove-colonne",
    "title": "5¬† Pandas (1)",
    "section": "5.10 Creare nuove colonne",
    "text": "5.10 Creare nuove colonne\nPer ciascuna riga, calcoliamo\n\nbill_length_mm - bill_depth_mm\nbill_length_mm / (body_mass_g / 1000)\n\nPer ottenere questo risultato possiamo usare una lambda function.\n\ndf = df.assign(\n    bill_difference=lambda x: x.bill_length_mm - x.bill_depth_mm,\n    bill_ratio=lambda x: x.bill_length_mm / (x.body_mass_g / 1000),\n)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n\n\n\n\n\n\n\n\nIn maniera pi√π semplice possiamo procedere nel modo seguente:\n\ndf[\"bill_ratio2\"] = df[\"bill_length_mm\"] / (df[\"body_mass_g\"] / 1000)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\nbill_ratio2\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n10.767123\n\n\n\n\n\n\n\n\nUn‚Äôutile funzionalit√† √® quella che consente di aggiungere una colonna ad un DataFrame (o di mofificare una colonna gi√† esistente) sulla base di una condizione True/False. Questo risultato pu√≤ essere raggiunto usando np.where(), con la seguente sintassi:\nnp.where(condition, value if condition is true, value if condition is false)\nSupponiamo di avere un DataFrame df con due colonne, A e B, e vogliamo creare una nuova colonna C che contenga il valore di A quando questo √® maggiore di 0, e il valore di B altrimenti. Possiamo utilizzare la funzione where() per ottenere ci√≤ come segue:\n\n# Creiamo un DataFrame di esempio\ndf = pd.DataFrame({\"A\": [-1, 2, 3, -4], \"B\": [5, 6, 0, 8]})\n\n# Creiamo una nuova colonna 'C' usando la funzione where()\ndf[\"C\"] = df[\"A\"].where(df[\"A\"] &gt; 0, df[\"B\"])\n\nprint(df)\n\n   A  B  C\n0 -1  5  5\n1  2  6  2\n2  3  0  3\n3 -4  8  8",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#formato-long-e-wide",
    "href": "chapters/chapter_1/04_pandas.html#formato-long-e-wide",
    "title": "5¬† Pandas (1)",
    "section": "5.11 Formato long e wide",
    "text": "5.11 Formato long e wide\nNella data analysis, i termini ‚Äúformato long‚Äù e ‚Äúformato wide‚Äù sono usati per descrivere la struttura di un set di dati. l formato wide (in inglese ‚Äúwide format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni variabile √® rappresentata da pi√π colonne. Un esempio √® il seguente, nel quale per ciascun partecipante, identificato da Name e ID abbiamo i punteggi di un ipotetico test per 6 anni consecutivi.\n\nscores = {\n    \"Name\": [\"Maria\", \"Carlo\", \"Giovanna\", \"Irene\"],\n    \"ID\": [1, 2, 3, 4],\n    \"2017\": [85, 87, 89, 91],\n    \"2018\": [96, 98, 100, 102],\n    \"2019\": [100, 102, 106, 106],\n    \"2020\": [89, 95, 98, 100],\n    \"2021\": [94, 96, 98, 100],\n    \"2022\": [100, 104, 104, 107],\n}\n\nwide_data = pd.DataFrame(scores)\nwide_data\n\n\n\n\n\n\n\n\n\nName\nID\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\n0\nMaria\n1\n85\n96\n100\n89\n94\n100\n\n\n1\nCarlo\n2\n87\n98\n102\n95\n96\n104\n\n\n2\nGiovanna\n3\n89\n100\n106\n98\n98\n104\n\n\n3\nIrene\n4\n91\n102\n106\n100\n100\n107\n\n\n\n\n\n\n\n\nIl formato long (in inglese ‚Äúlong format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni colonna rappresenta una singola variabile. Questo formato √® quello che viene richiesto per molte analisi statistiche. In Pandas √® possibile usare la funzione melt per trasformare i dati dal formato wide al formato long. Un esempio √® riportato qui sotto. Sono state mantenute le due colonne che identificano ciascun partecipante, ma i dati del test, che prima erano distribuiti su sei colonne, ora sono presenti in una singola colonna. Al DataFrame, inoltre, √® stata aggiunta una colonna che riporta l‚Äôanno.\n\nlong_data = wide_data.melt(id_vars=[\"Name\", \"ID\"], var_name=\"Year\", value_name=\"Score\")\nlong_data\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n1\nCarlo\n2\n2017\n87\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n3\nIrene\n4\n2017\n91\n\n\n4\nMaria\n1\n2018\n96\n\n\n5\nCarlo\n2\n2018\n98\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n7\nIrene\n4\n2018\n102\n\n\n8\nMaria\n1\n2019\n100\n\n\n9\nCarlo\n2\n2019\n102\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n11\nIrene\n4\n2019\n106\n\n\n12\nMaria\n1\n2020\n89\n\n\n13\nCarlo\n2\n2020\n95\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n15\nIrene\n4\n2020\n100\n\n\n16\nMaria\n1\n2021\n94\n\n\n17\nCarlo\n2\n2021\n96\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n19\nIrene\n4\n2021\n100\n\n\n20\nMaria\n1\n2022\n100\n\n\n21\nCarlo\n2\n2022\n104\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n23\nIrene\n4\n2022\n107\n\n\n\n\n\n\n\n\nPer migliorare la leggibilit√† dei dati, √® possibile riordinare le righe del set di dati utilizzando la funzione sort_values. In questo modo, le informazioni saranno presentate in un ordine specifico, che pu√≤ rendere pi√π facile la lettura dei dati.\n\nlong_data.sort_values(by=[\"ID\", \"Year\"])\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n4\nMaria\n1\n2018\n96\n\n\n8\nMaria\n1\n2019\n100\n\n\n12\nMaria\n1\n2020\n89\n\n\n16\nMaria\n1\n2021\n94\n\n\n20\nMaria\n1\n2022\n100\n\n\n1\nCarlo\n2\n2017\n87\n\n\n5\nCarlo\n2\n2018\n98\n\n\n9\nCarlo\n2\n2019\n102\n\n\n13\nCarlo\n2\n2020\n95\n\n\n17\nCarlo\n2\n2021\n96\n\n\n21\nCarlo\n2\n2022\n104\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n3\nIrene\n4\n2017\n91\n\n\n7\nIrene\n4\n2018\n102\n\n\n11\nIrene\n4\n2019\n106\n\n\n15\nIrene\n4\n2020\n100\n\n\n19\nIrene\n4\n2021\n100\n\n\n23\nIrene\n4\n2022\n107",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#copia-di-un-data-frame",
    "href": "chapters/chapter_1/04_pandas.html#copia-di-un-data-frame",
    "title": "5¬† Pandas (1)",
    "section": "5.12 Copia di un data frame",
    "text": "5.12 Copia di un data frame\nQuando in Python definiamo un nuovo data frame basandoci su un data frame esistente con l‚Äôistruzione new_df = old_df, √® importante essere consapevoli del fatto che non stiamo creando un nuovo data frame indipendente. In realt√†, new_df diventa solamente un riferimento all‚Äôoggetto originale old_df nell‚Äôambiente corrente. Questo significa che qualsiasi modifica apportata a new_df si rifletter√† automaticamente anche in old_df. In pratica, abbiamo un unico oggetto data frame accessibile attraverso due nomi diversi.\nPer creare effettivamente una copia indipendente di old_df, in modo che le modifiche apportate a questa copia non influiscano sull‚Äôoriginale, dobbiamo utilizzare il metodo .copy(). Questo metodo crea un nuovo oggetto data frame che √® una copia del data frame originale. L‚Äôistruzione corretta per fare ci√≤ in Python √® la seguente:\nnew_df = old_df.copy()\nUtilizzando old_df.copy(), otteniamo due data frame completamente indipendenti. Modifiche apportate a new_df non avranno alcun impatto su old_df, permettendoci di lavorare con i dati in modo sicuro e senza rischi di sovrascrittura o alterazione involontaria dei dati originali. Questa pratica √® fondamentale per mantenere l‚Äôintegrit√† dei dati e per gestire correttamente le variabili all‚Äôinterno di un programma Python.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "title": "5¬† Pandas (1)",
    "section": "5.13 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "5.13 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.2\npandas: 2.1.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/05_pandas_aggregate.html",
    "href": "chapters/chapter_1/05_pandas_aggregate.html",
    "title": "6¬† Pandas (2)",
    "section": "",
    "text": "6.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport arviz as az\nimport seaborn as sns\n%config InlineBackend.figure_format = 'retina'\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\naz.style.use(\"arviz-darkgrid\")\nsns.set_theme(palette=\"colorblind\")",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "href": "chapters/chapter_1/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "title": "6¬† Pandas (2)",
    "section": "6.2 Calcolo delle statistiche descrittive",
    "text": "6.2 Calcolo delle statistiche descrittive\nAgli oggetti Pandas possono essere applicati vari metodi matematici e statistici. La maggior parte di questi rientra nella categoria della riduzione di dati o delle statistiche descrittive. Rispetto ai metodi degli array NumPy, i metodi Pandas consentono la gestione dei dati mancanti. Alcuni dei metodi disponibili per gli oggetti Pandas sono elencati di seguito.\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncount\nNumber of non-NA values\n\n\ndescribe\nCompute set of summary statistics\n\n\nmin, max\nCompute minimum and maximum values\n\n\nargmin, argmax\nCompute index locations (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects\n\n\nidxmin, idxmax\nCompute index labels at which minimum or maximum value is obtained, respectively\n\n\nquantile\nCompute sample quantile ranging from 0 to 1 (default: 0.5)\n\n\nsum\nSum of values\n\n\nmean\nMean of values\n\n\nmedian\nArithmetic median (50% quantile) of values\n\n\nmad\nMean absolute deviation from mean value\n\n\nprod\nProduct of all values\n\n\nvar\nSample variance of values\n\n\nstd\nSample standard deviation of values\n\n\nskew\nSample skewness (third moment) of values\n\n\nkurt\nSample kurtosis (fourth moment) of values\n\n\ncumsum\nCumulative sum of values\n\n\ncummin, cummax\nCumulative minimum or maximum of values, respectively\n\n\ncumprod\nCumulative product of values\n\n\ndiff\nCompute first arithmetic difference (useful for time series)\n\n\npct_change\nCompute percent changes\n\n\n\nTali metodi possono essere applicati a tutto il DataFrame, oppure soltanto ad una o pi√π colonne.\nPer fare un esempio, esamineremo nuovamente i dati penguins.csv. Come in precedenza, dopo avere caricato i dati, rimuoviamo i dati mancanti.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\n\nUsiamo il metodo describe() su tutto il DataFrame:\n\ndf.describe(include=\"all\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\ncount\n333\n333\n333.000000\n333.000000\n333.000000\n333.000000\n333\n333.000000\n\n\nunique\n3\n3\nNaN\nNaN\nNaN\nNaN\n2\nNaN\n\n\ntop\nAdelie\nBiscoe\nNaN\nNaN\nNaN\nNaN\nmale\nNaN\n\n\nfreq\n146\n163\nNaN\nNaN\nNaN\nNaN\n168\nNaN\n\n\nmean\nNaN\nNaN\n43.992793\n17.164865\n200.966967\n4207.057057\nNaN\n2008.042042\n\n\nstd\nNaN\nNaN\n5.468668\n1.969235\n14.015765\n805.215802\nNaN\n0.812944\n\n\nmin\nNaN\nNaN\n32.100000\n13.100000\n172.000000\n2700.000000\nNaN\n2007.000000\n\n\n25%\nNaN\nNaN\n39.500000\n15.600000\n190.000000\n3550.000000\nNaN\n2007.000000\n\n\n50%\nNaN\nNaN\n44.500000\n17.300000\n197.000000\n4050.000000\nNaN\n2008.000000\n\n\n75%\nNaN\nNaN\n48.600000\n18.700000\n213.000000\n4775.000000\nNaN\n2009.000000\n\n\nmax\nNaN\nNaN\n59.600000\n21.500000\n231.000000\n6300.000000\nNaN\n2009.000000\n\n\n\n\n\n\n\n\nSe desideriamo solo le informazioni relative alle variabili qualitative, usiamo l‚Äôargomento include='object'.\n\ndf.describe(include=\"object\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nsex\n\n\n\n\ncount\n333\n333\n333\n\n\nunique\n3\n3\n2\n\n\ntop\nAdelie\nBiscoe\nmale\n\n\nfreq\n146\n163\n168\n\n\n\n\n\n\n\n\nI valori NaN indicano dati mancanti. Ad esempio, la colonna species contiene stringhe, quindi non esiste alcun valore per mean; allo stesso modo, bill_length_mm √® una variabile numerica, quindi non vengono calcolate le statistiche riassuntive per le variabili categoriali (unique, top, freq).\nEsaminimiamo le colonne singolarmente. Ad esempio, troviamo la media della colonna bill_depth_mm.\n\ndf[\"bill_depth_mm\"].mean()\n\n17.164864864864867\n\n\nPer la deviazione standard usiamo il metodo std(). Si noti l‚Äôargomento opzionale ddof:\n\ndf[\"bill_length_mm\"].std(ddof=1)\n\n5.46866834264756\n\n\nLa cella seguente fornisce l‚Äôindice della riga nella quale la colonna bill_length_mm assume il suo valore massimo:\n\ndf[\"bill_length_mm\"].idxmax()\n\n185\n\n\nLa colonna species nel DataFrame df √® una variabile a livello nominale. Elenchiamo le modalit√† di tale variabile.\n\ndf[\"species\"].unique()\n\narray(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n\nIl metodo value_counts ritorna la distribuzione di frequenza assoluta:\n\ndf[\"species\"].value_counts()\n\nspecies\nAdelie       146\nGentoo       119\nChinstrap     68\nName: count, dtype: int64\n\n\nPer le frequenze relative si imposta l‚Äôargomento normalize=True:\n\nprint(df[\"species\"].value_counts(normalize=True))\n\nspecies\nAdelie       0.438438\nGentoo       0.357357\nChinstrap    0.204204\nName: proportion, dtype: float64\n\n\nConsideriamo la lunghezza del becco dei pinguini suddivisa per ciascuna specie. Con l‚Äôistruzione seguente, possiamo generare gli istogrammi corrispondenti che rappresentano la distribuzione della lunghezza del becco in ciascun gruppo.\n\n_ = df.hist(\n    column=\"bill_length_mm\",\n    by=[\"species\"],\n    bins=20,\n    figsize=(12, 4),\n    layout=(1, 3),\n    rwidth=0.9,\n)\n\n\n\n\n\n\n\n\n\ndf\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n333 rows √ó 8 columns\n\n\n\n\n\n6.2.1 Aggregazione dei dati\nIl riepilogo di pi√π valori in un unico indice va sotto il nome di ‚Äúaggregazione‚Äù dei dati. Il metodo aggregate() pu√≤ essere applicato ai DataFrame e restituisce un nuovo DataFrame pi√π breve contenente solo i valori aggregati. Il primo argomento di aggregate() specifica quale funzione o quali funzioni devono essere utilizzate per aggregare i dati. Molte comuni funzioni di aggregazione sono disponibili nel modulo statistics. Ad esempio:\n\nmedian(): la mediana;\nmean(): la media;\nstdev(): la deviazione standard;\n\nSe vogliamo applicare pi√π funzioni di aggregazione, allora possiamo raccogliere prima le funzioni in una lista e poi passare la lista ad aggregate().\n\n# List of summary statistics functions\nsummary_stats = [np.min, np.median, np.mean, np.std, np.max]\n\n# Calculate summary statistics for numeric columns using aggregate\nresult = df[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n].aggregate(summary_stats)\n\nprint(result)\n\n        bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\nmin          32.100000      13.100000         172.000000  2700.000000\nmedian       44.500000      17.300000         197.000000  4050.000000\nmean         43.992793      17.164865         200.966967  4207.057057\nstd           5.468668       1.969235          14.015765   805.215802\nmax          59.600000      21.500000         231.000000  6300.000000\n\n\nSi noti che Pandas ha applicato le funzioni di riepilogo a ogni colonna, ma, per alcune colonne, le statistiche riassuntive non si possono calcolare, ovvero tutte le colonne che contengono stringhe anzich√© numeri. Di conseguenza, vediamo che alcuni dei risultati per tali colonne sono contrassegnati con ‚ÄúNaN‚Äù. Questa √® un‚Äôabbreviazione di ‚ÄúNot a Number‚Äù, talvolta utilizzata nell‚Äôanalisi dei dati per rappresentare valori mancanti o non definiti.\nMolto spesso vogliamo calcolare le statistiche descrittive separatamente per ciascun gruppo di osservazioni ‚Äì per esempio, nel caso presente, potremmo volere distinguere le statistiche descrittive in base alla specie dei pinguini. Questo risultato si ottiene con il metodo .groupby().\nIl nome ‚Äúgroup by‚Äù deriva da un comando nel linguaggio del database SQL, ma forse √® pi√π semplice pensarlo nei termini coniati da Hadley Wickham: split, apply, combine. Un esempio canonico di questa operazione di split-apply-combine, in cui ‚Äúapply‚Äù √® un‚Äôaggregazione di sommatoria, √® illustrato nella figura seguente:\nwzhkcqr ../images/split_apply_combine.png :height: 400px :name: split_apply_combine\nLa figura rende chiaro ci√≤ che si ottiene con groupby:\n\nla fase ‚Äúsplit‚Äù prevede la suddivisione e il raggruppamento di un DataFrame in base al valore della chiave specificata;\nla fase ‚Äúapply‚Äù implica il calcolo di alcune funzioni, solitamente un‚Äôaggregazione, una trasformazione o un filtro, all‚Äôinterno dei singoli gruppi;\nla fase ‚Äúcombine‚Äù unisce i risultati di queste operazioni in una matrice di output.\n\nPer esempio, ragruppiamo le osservazioni body_mass_g in funzione delle modalit√† della variabile species.\n\ngrouped = df[\"body_mass_g\"].groupby(df[\"species\"])\n\n&lt;pandas.core.groupby.generic.SeriesGroupBy object at 0x16276b490&gt;\n\n\nCalcoliamo ora la media della variabile body_mass_g separatamente per ciascun gruppo di osservazioni.\n\ngrouped.mean()\n\nspecies\nAdelie       3706.164384\nChinstrap    3733.088235\nGentoo       5092.436975\nName: body_mass_g, dtype: float64\n\n\n√à possibile applicare criteri di classificazione multipli. Per fare un altro esempio, contiamo il numero di pinguini presenti sulle tre isole, distinguendoli per specie e genere.\n\ndf.groupby([\"island\", \"species\", \"sex\"]).size()\n\nisland     species    sex   \nBiscoe     Adelie     female    22\n                      male      22\n           Gentoo     female    58\n                      male      61\nDream      Adelie     female    27\n                      male      28\n           Chinstrap  female    34\n                      male      34\nTorgersen  Adelie     female    24\n                      male      23\ndtype: int64\n\n\nCon il metodo aggregate() possiamo applicare diverse funzioni di aggregazione alle osservazioni ragruppate. Ad esempio\n\nsummary_stats = [np.mean, np.std]\n# Group by \"species\" and calculate summary statistics for numeric columns\nresult = df.groupby(\"species\").agg(\n    {col: summary_stats for col in df.columns if pd.api.types.is_numeric_dtype(df[col])}\n)\n\nprint(result)\n\n          bill_length_mm           bill_depth_mm           flipper_length_mm  \\\n                    mean       std          mean       std              mean   \nspecies                                                                        \nAdelie         38.823973  2.662597     18.347260  1.219338        190.102740   \nChinstrap      48.833824  3.339256     18.420588  1.135395        195.823529   \nGentoo         47.568067  3.106116     14.996639  0.985998        217.235294   \n\n                     body_mass_g                     year            \n                std         mean         std         mean       std  \nspecies                                                              \nAdelie     6.521825  3706.164384  458.620135  2008.054795  0.811816  \nChinstrap  7.131894  3733.088235  384.335081  2007.970588  0.863360  \nGentoo     6.585431  5092.436975  501.476154  2008.067227  0.789025  \n\n\nNella cella seguente troviamo la media di body_mass_g e flipper_length_mm separatamente per ciascuna isola e ciascuna specie:\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].mean()\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n188.795455\n\n\nGentoo\n5092.436975\n217.235294\n\n\nDream\nAdelie\n3701.363636\n189.927273\n\n\nChinstrap\n3733.088235\n195.823529\n\n\nTorgersen\nAdelie\n3708.510638\n191.531915\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per la deviazione standard.\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].std(ddof=1)\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n487.733722\n6.729247\n\n\nGentoo\n501.476154\n6.585431\n\n\nDream\nAdelie\n448.774519\n6.480325\n\n\nChinstrap\n384.335081\n7.131894\n\n\nTorgersen\nAdelie\n451.846351\n6.220062\n\n\n\n\n\n\n\n\nPrestiamo attenzione alla seguente sintassi:\n\nsummary_stats = (\n    df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]\n    .groupby([\"island\", \"species\"])\n    .aggregate([\"mean\", \"std\", \"count\"])\n)\nsummary_stats\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\n\n\nmean\nstd\ncount\nmean\nstd\ncount\n\n\nisland\nspecies\n\n\n\n\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n487.733722\n44\n188.795455\n6.729247\n44\n\n\nGentoo\n5092.436975\n501.476154\n119\n217.235294\n6.585431\n119\n\n\nDream\nAdelie\n3701.363636\n448.774519\n55\n189.927273\n6.480325\n55\n\n\nChinstrap\n3733.088235\n384.335081\n68\n195.823529\n7.131894\n68\n\n\nTorgersen\nAdelie\n3708.510638\n451.846351\n47\n191.531915\n6.220062\n47\n\n\n\n\n\n\n\n\nNell‚Äôistruzione precedente selezioniamo tutte le righe (:) di tre colonne di interesse: df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]. L‚Äôistruzione .groupby([\"island\", \"species\"]) ragruppa le osservazioni (righe) secondo le modalit√† delle variabili island e species. Infine .aggregate([\"mean\", \"std\", \"count\"]) applica i metodi statistici specificati a ciascun gruppo di osservazioni. Con questa sintassi la sequenza delle operazioni da eseguire diventa molto intuitiva.\n√à possibile approfondire questo argomento consultanto il capitolo 10 del testo Python for Data Analysis di {cite:t}mckinney2022python.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "title": "6¬† Pandas (2)",
    "section": "6.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "6.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.11.4\nseaborn   : 0.13.0\nnumpy     : 1.26.2\npandas    : 2.1.4\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html",
    "href": "chapters/chapter_1/06_pandas_functions.html",
    "title": "7¬† Pandas (3)",
    "section": "",
    "text": "7.1 pd.read_csv, pd.read_excel\nLa prima funzione da menzionare √® read_csv o read_excel. Le funzioni vengono utilizzate per leggere un file CSV o un file Excel in formato DataFrame di Pandas. Qui stiamo utilizzando la funzione read_csv per leggere il dataset penguins. In precedenza abbiamo anche visto come la funzione dropna viene utilizzata per rimuovere tutte le righe del DataFrame che includono dati mancanti.\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#columns",
    "href": "chapters/chapter_1/06_pandas_functions.html#columns",
    "title": "7¬† Pandas (3)",
    "section": "7.2 .columns",
    "text": "7.2 .columns\nQuando si dispone di un grande dataset, pu√≤ essere difficile visualizzare tutte le colonne. Utilizzando la funzione columns, √® possibile stampare tutte le colonne del dataset.\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#drop",
    "href": "chapters/chapter_1/06_pandas_functions.html#drop",
    "title": "7¬† Pandas (3)",
    "section": "7.3 .drop()",
    "text": "7.3 .drop()\n√à possibile eliminare alcune colonne non necessarie utilizzando drop.\n\ndf = df.drop(columns=[\"year\"])\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#len",
    "href": "chapters/chapter_1/06_pandas_functions.html#len",
    "title": "7¬† Pandas (3)",
    "section": "7.4 len()",
    "text": "7.4 len()\nFornisce il numero di righe di un DataFrame.\n\nlen(df)\n\n333",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#query",
    "href": "chapters/chapter_1/06_pandas_functions.html#query",
    "title": "7¬† Pandas (3)",
    "section": "7.5 .query()",
    "text": "7.5 .query()\n√à possibile filtrare un DataFrame utilizzando un‚Äôespressione booleana.\n\ndf1 = df.query(\"species == 'Chinstrap' & island == 'Dream'\")\nlen(df1)\n\n68",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#iloc",
    "href": "chapters/chapter_1/06_pandas_functions.html#iloc",
    "title": "7¬† Pandas (3)",
    "section": "7.6 .iloc[]",
    "text": "7.6 .iloc[]\nQuesta funzione accetta come parametri gli indici delle righe e delle colonne, fornendo una selezione del DataFrame in base a questi. In questo caso, stiamo selezionando le prime 3 righe di dati e le colonne con indice 2, 3 e 5.\n\ndf2 = df.iloc[:3, [2, 3, 5]]\ndf2\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nbody_mass_g\n\n\n\n\n0\n39.1\n18.7\n3750.0\n\n\n1\n39.5\n17.4\n3800.0\n\n\n2\n40.3\n18.0\n3250.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#loc",
    "href": "chapters/chapter_1/06_pandas_functions.html#loc",
    "title": "7¬† Pandas (3)",
    "section": "7.7 .loc[]",
    "text": "7.7 .loc[]\nQuesta funzione compie un‚Äôoperazione molto simile a quella della funzione .iloc. Tuttavia, in questo caso, abbiamo la possibilit√† di specificare gli indici delle righe che desideriamo, insieme ai nomi delle colonne che vogliamo includere nella nostra selezione.\n\ndf3 = df.loc[[2, 4, 6], [\"island\", \"flipper_length_mm\", \"sex\"]]\ndf3\n\n\n\n\n\n\n\n\n\nisland\nflipper_length_mm\nsex\n\n\n\n\n2\nTorgersen\n195.0\nfemale\n\n\n4\nTorgersen\n193.0\nfemale\n\n\n6\nTorgersen\n181.0\nfemale",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "title": "7¬† Pandas (3)",
    "section": "7.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "7.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.0\nnumpy     : 1.26.2\narviz     : 0.17.0\npandas    : 2.1.4\nmatplotlib: 3.8.2\nscipy     : 1.11.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html",
    "href": "chapters/chapter_1/07_matplotlib.html",
    "title": "8¬† Matplotlib",
    "section": "",
    "text": "8.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\n# Questa istruzione consente di visualizzare i grafici generati dai comandi di \n# plot direttamente all'interno del notebook.\n%config InlineBackend.figure_format = 'retina'\n\n# Questo valore viene usato come seed per il random number generator.\nRANDOM_SEED = 42\n\n# In questa riga, stai utilizzando il generatore di numeri casuali di NumPy per \n# creare una nuova istanza denominata rng. La funzione np.random.default_rng() viene \n# utilizzata per inizializzare un generatore di numeri casuali con un seme specifico, \n# che in questo caso √® RANDOM_SEED.\nrng = np.random.default_rng(RANDOM_SEED)\n\n# Queste due righe di codice sono spesso utilizzate per personalizzare l'aspetto dei \n# grafici in Python utilizzando le librerie ArviZ e Seaborn.\n# Questa riga di codice utilizza il metodo use() della libreria ArviZ per impostare uno \n# stile specifico per i tuoi grafici. In particolare, sta impostando lo stile chiamato \n# \"arviz-darkgrid\". Gli stili in ArviZ determinano come saranno visualizzati i grafici, inclusi colori, linee di griglia e altri dettagli estetici.\naz.style.use(\"arviz-darkgrid\")\n\n# Questa riga di codice utilizza la libreria Seaborn per impostare il tema dei grafici. \n# In questo caso, il tema viene impostato utilizzando set_theme() con il parametro palette \n# impostato su \"colorblind\". Questo significa che i colori utilizzati nei grafici saranno \n# scelti in modo da essere adatti alle persone con deficit visivi dei colori, rendendo i \n# grafici pi√π accessibili.\nsns.set_theme(palette=\"colorblind\")",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "href": "chapters/chapter_1/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "title": "8¬† Matplotlib",
    "section": "8.2 L‚ÄôInterfaccia pyplot per Creare Grafici",
    "text": "8.2 L‚ÄôInterfaccia pyplot per Creare Grafici\nMatplotlib √® una libreria in Python famosa per la creazione di grafici, e la sua interfaccia pyplot √® particolarmente apprezzata per la sua semplicit√†. Vediamo in dettaglio come funzionano le sue funzioni principali. Per comprendere meglio come funzionano le sue funzioni principali, possiamo fare un parallelo con il disegno su un supporto fisico.\n\nPrepariamo la Tela: Iniziamo con plt.figure(), che √® analogo a ottenere una tela bianca pronta per essere dipinta. √à il punto di partenza, una superficie vuota su cui creeremo il nostro grafico.\nDefiniamo le Aree di Disegno: Successivamente, utilizzando plt.subplot() o plt.axes(), creiamo delle aree specifiche o ‚Äúassi‚Äù sulla nostra tela. Questi assi corrispondono a diverse sezioni in cui posizioneremo vari elementi del nostro grafico, come se suddividessimo la tela fisica in diverse parti.\nAggiungiamo Elementi al Grafico: Una volta definiti gli assi, entriamo nel processo di creazione. Usandando funzioni come plt.plot() per tracciare linee o plt.scatter() per punti, aggiungiamo elementi grafici alla nostra area di disegno. √à simile a disegnare direttamente sulla tela fisica.\nRendiamo il Grafico Comprensibile: Per garantire che il grafico sia chiaro e informativo, aggiungiamo etichette e titoli con plt.xlabel(), plt.ylabel() e plt.title().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "href": "chapters/chapter_1/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "title": "8¬† Matplotlib",
    "section": "8.3 Principi Fondamentali di Pyplot",
    "text": "8.3 Principi Fondamentali di Pyplot\nEsploriamo le funzionalit√† essenziali di pyplot di Matplotlib:\n\nCreazione di Grafici Lineari: Utilizzando plt.plot(x, y), √® possibile generare grafici lineari. Questa funzione necessita delle coordinate x e y per disegnare il grafico, semplificando cos√¨ la rappresentazione visiva dei dati.\nDenominazione degli Assi: √à fondamentale assegnare un‚Äôetichetta appropriata agli assi per migliorare la comprensione del grafico. Si possono denominare gli assi tramite plt.xlabel('Nome') per l‚Äôasse X e plt.ylabel('Nome') per l‚Äôasse Y, facilitando l‚Äôinterpretazione dei dati visualizzati.\nInserimento del Titolo: Un titolo descrittivo clarifica lo scopo o il contesto del grafico. Aggiungere un titolo √® semplice con plt.title('Titolo'), che aiuta a comunicare il messaggio principale del grafico in modo efficace.\nInserimento di Legende: Per grafici che includono pi√π serie di dati o elementi distinti, l‚Äôaggiunta di una legenda √® cruciale per la distinzione tra questi. La funzione plt.legend() permette di integrare una legenda, migliorando la leggibilit√† del grafico.\nEsposizione del Grafico: Una volta completata la composizione del grafico, il passo finale √® la sua visualizzazione. Attraverso plt.show(), √® possibile mostrare il grafico elaborato, offrendo una visione complessiva dei dati analizzati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "title": "8¬† Matplotlib",
    "section": "8.4 Esempio 1: Grafico lineare semplice",
    "text": "8.4 Esempio 1: Grafico lineare semplice\n\nx = [1, 2, 3, 4]\ny = [10, 20, 30, 40]\n\nplt.plot(x, y)\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico Lineare Semplice\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "title": "8¬† Matplotlib",
    "section": "8.5 Esempio 2: Grafico con legenda e stile",
    "text": "8.5 Esempio 2: Grafico con legenda e stile\n\nx = [1, 2, 3, 4]\ny1 = [10, 20, 30, 40]\ny2 = [5, 15, 25, 35]\n\nplt.plot(x, y1, label=\"Linea 1\", color=\"C0\", linestyle=\"--\")\nplt.plot(x, y2, label=\"Linea 2\", color=\"C3\", linestyle=\"-\")\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico con Legenda\")\nplt.legend();",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-3-istogramma",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-3-istogramma",
    "title": "8¬† Matplotlib",
    "section": "8.6 Esempio 3: Istogramma",
    "text": "8.6 Esempio 3: Istogramma\n\ndata = rng.normal(100, 15, 1000)\n\nplt.hist(data, bins=20)\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Istogramma\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#esempio-4-pannelli-multipli",
    "href": "chapters/chapter_1/07_matplotlib.html#esempio-4-pannelli-multipli",
    "title": "8¬† Matplotlib",
    "section": "8.7 Esempio 4: pannelli multipli",
    "text": "8.7 Esempio 4: pannelli multipli\nFacciamo un altro esempio usando i dati penguins.csv.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\n\n\nplt.figure(figsize=(9, 8))\n\nplt.subplot(2, 2, 1)\nplt.hist(df[\"bill_depth_mm\"], 10, density=True, color=\"C3\")\nplt.title(\"Bill depth (mm)\");\n\nplt.subplot(2, 2, 2)\nsns.kdeplot(df[\"bill_length_mm\"], fill=True)\nplt.title(\"KDE of Bill length (mm)\");\n\nplt.subplot(2, 2, 3)\nplt.scatter(x=df[\"bill_length_mm\"], y=df[\"bill_depth_mm\"], alpha=0.4)\nplt.title(\"Bill depth as a function of bill length\");\n\nplt.subplot(2, 2, 4)\nplt.boxplot(df[\"bill_length_mm\"])\nplt.title(\"Boxplot of Bill Length (mm)\")\n\nplt.tight_layout()\n\n/var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_55046/1324325854.py:19: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nGli indici in plt.subplot() sono utilizzati per specificare come dividere una figura in diverse aree di tracciamento, chiamate ‚Äúsubplots‚Äù. La funzione plt.subplot(nrows, ncols, index) prende tre argomenti principali:\n\nnrows: Numero di righe in cui la figura sar√† suddivisa.\nncols: Numero di colonne in cui la figura sar√† suddivisa.\nindex: Indice del subplot su cui operare, partendo dall‚Äôangolo in alto a sinistra e proseguendo da sinistra a destra e dall‚Äôalto in basso.\n\nNel codice precedente, plt.subplot(2, 2, 1) indica che la figura sar√† divisa in una griglia 2x2 (2 righe e 2 colonne) e che la funzione plt.hist() agir√† sul primo subplot, che si trover√† nell‚Äôangolo in alto a sinistra.\nGli altri indici (2, 3, 4) selezionano rispettivamente il secondo subplot (in alto a destra), il terzo subplot (in basso a sinistra) e il quarto subplot (in basso a destra) della griglia 2x2.\nEcco come i subplot sono organizzati sulla figura:\n+---------------------+----------------------+\n|  plt.subplot(2,2,1) |  plt.subplot(2,2,2)  |\n+---------------------+----------------------+\n|  plt.subplot(2,2,3) |  plt.subplot(2,2,4)  |\n+---------------------+----------------------+\nOgni volta che si chiama plt.subplot() con un nuovo indice, il ‚Äúcurrent axes‚Äù cambia per puntare al subplot specificato. Quindi, le funzioni di tracciamento come plt.hist(), sns.kdeplot(), plt.scatter() e plt.boxplot() saranno applicate al subplot attualmente selezionato.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "title": "8¬† Matplotlib",
    "section": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\narviz     : 0.17.0\nmatplotlib: 3.8.2\npandas    : 2.1.4\nseaborn   : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html",
    "href": "chapters/chapter_1/08_seaborn.html",
    "title": "9¬† Seaborn",
    "section": "",
    "text": "9.1 Elevare la Visualizzazione dei Dati con Seaborn\nNel capitolo precedente, abbiamo esaminato Matplotlib, una libreria estremamente versatile per la visualizzazione dei dati in Python. Ora esamineremo le funzionalit√† di Seabonrn. Seaborn, che si basa su Matplotlib, arricchisce l‚Äôesperienza di visualizzazione dei dati offrendo una gamma pi√π ampia e specializzata di opzioni grafiche, particolarmente utili nel campo della data science.\nIl vero punto di forza di Seaborn √® la sua capacit√† di migliorare non solo l‚Äôaspetto estetico dei grafici ma anche di facilitare la creazione di visualizzazioni pi√π complesse. Questo rende il processo pi√π diretto e intuitivo. La libreria √® dotata di un‚Äôampia variet√† di strumenti, dalle mappe di calore ai grafici a violino, permettendo agli utenti di esplorare e rappresentare i dati in modi innovativi e informativi.\nPer chi vuole approfondire ulteriormente, i tutorial presenti sul sito ufficiale di Seaborn sono una risorsa preziosa e facilmente accessibile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#preparazione-del-notebook",
    "href": "chapters/chapter_1/08_seaborn.html#preparazione-del-notebook",
    "title": "9¬† Seaborn",
    "section": "9.2 Preparazione del Notebook",
    "text": "9.2 Preparazione del Notebook\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport arviz as az\n\n\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"seaborn\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "href": "chapters/chapter_1/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "title": "9¬† Seaborn",
    "section": "9.3 Visualizzare la distribuzione dei dati",
    "text": "9.3 Visualizzare la distribuzione dei dati\nVediamo alcuni esempi pratici per scoprire come Seaborn possa trasformare il modo in cui visualizziamo i dati.\nConsideriamo nuovamente i dati Palmer penguin.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nUna delle forme di visualizzazione pi√π comuni e informative nel campo dell‚Äôanalisi dei dati √® l‚Äôistogramma, e la sua variante pi√π sofisticata, l‚Äôistogramma lisciato. Vediamo dunque come generare istogrammi che, per il DataFrame df, sono stratificati sia in base alla specie che al genere dei pinguini.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n);\n\nGeneriamo la stessa figura usando questa volta gli istogrammi lisciati.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    height=3, kind=\"kde\", facet_kws=dict(margin_titles=True),\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "href": "chapters/chapter_1/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "title": "9¬† Seaborn",
    "section": "9.4 Visualizzazione di dati categoriali",
    "text": "9.4 Visualizzazione di dati categoriali\nConsideriamo ora il caso in cui si vuole rappresentare la relazione tra una variabile numerica e una o pi√π variabili categoriali.\nConsideriamo, ad esempio, la massa corporea in relazione alla specie, differenziando le osservazioni per genere. Creiamo il grafico utilizzando i boxplot.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"box\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\n\n\n\nDai diagrammi risulta evidente che i pinguini maschi hanno un peso maggiore rispetto alle femmine in tutte le specie, e che i pinguini Gentoo hanno un peso superiore rispetto ad Adelie e Chinstrap.\nCome alternativa, possiamo utilizzare il violinplot per la rappresentazione grafica dei dati.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"violin\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#relazioni-tra-variabili",
    "href": "chapters/chapter_1/08_seaborn.html#relazioni-tra-variabili",
    "title": "9¬† Seaborn",
    "section": "9.5 Relazioni tra variabili",
    "text": "9.5 Relazioni tra variabili\nCalcoliamo la correlazione tra le variabili.\n\nvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\ncorr_matrix = df[vars].corr().round(2)\ncorr_matrix\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.00\n-0.24\n0.66\n0.60\n\n\nbill_depth_mm\n-0.24\n1.00\n-0.58\n-0.47\n\n\nflipper_length_mm\n0.66\n-0.58\n1.00\n0.87\n\n\nbody_mass_g\n0.60\n-0.47\n0.87\n1.00\n\n\n\n\n\n\n\n\nQueste informazioni possono essere comunicate in forma pi√π diretta se usiamo una rappresentazione grafica.\n\nsns.heatmap(corr_matrix, annot=True, linecolor=\"white\", linewidths=5);\n\n\n\n\n\n\n\n\nLa lunghezza della pinna e la massa corporea mostrano un forte legame, con una correlazione di 0.87. Ci√≤ indica che i pinguini con pinne pi√π lunghe tendono a pesare di pi√π.\nDi seguito √® riportato un esempio di diagramma a dispersione che illustra questa relazione.\n\nsns.scatterplot(df, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\");\n\n\n\n\n\n\n\n\nEvidentemente, le osservazioni delle tre specie formano cluster distinti. Per ciascuna specie, la lunghezza e la larghezza del becco presentano un intervallo specifico.\nSpesso √® vantaggioso creare grafici separati in base a diverse dimensioni dei dati; nell‚Äôesempio seguente, suddividiamo i dati in base all‚Äôisola di appartenenza.\n\ng = sns.relplot(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    row=\"sex\",\n    col=\"island\",\n    height=3,\n    facet_kws=dict(margin_titles=True),\n)\ng.set_axis_labels(\n    \"Bill length (mm)\",\n    \"Bill depth (mm)\",\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_1/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_1/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "title": "9¬† Seaborn",
    "section": "9.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "9.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\narviz     : 0.18.0\npandas    : 2.2.2\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html",
    "href": "chapters/chapter_2/00_scientific_method.html",
    "title": "10¬† La scienza dei dati e il metodo scientifico",
    "section": "",
    "text": "10.1 Strumenti per Comprendere il Reale\nI modelli scientifici sono strumenti essenziali per la comprensione del mondo che ci circonda. Essi non sono delle descrizioni ‚Äúvere‚Äù della realt√†, ma piuttosto rappresentazioni che ci permettono di esplorare, testare e approfondire la nostra conoscenza dei fenomeni naturali.\nQueste domande devono essere sempre in primo piano nella nostra mente quando lavoriamo con i modelli scientifici (Johnson, Ott, e Dogucu 2022).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>La scienza dei dati e il metodo scientifico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#strumenti-per-comprendere-il-reale",
    "href": "chapters/chapter_2/00_scientific_method.html#strumenti-per-comprendere-il-reale",
    "title": "10¬† La scienza dei dati e il metodo scientifico",
    "section": "",
    "text": "Natura esplorativa dei modelli: Utilizziamo i modelli per sondare, valutare e testare i limiti della nostra comprensione. Li costruiamo, ammiriamo la loro bellezza, ma anche cerchiamo di comprenderne i limiti e, in ultima analisi, di superarli. √à questo processo di costruzione, test e revisione che ci permette di migliorare la nostra comprensione del mondo, non necessariamente il risultato finale, anche se talvolta possono coincidere (Vasishth e Gelman 2021).\nDualit√† tra mondo del modello e mondo reale: Nella costruzione dei modelli, √® fondamentale tenere presente sia il ‚Äúmondo del modello‚Äù - cio√® il contesto specifico in cui il modello opera - sia il mondo reale pi√π ampio di cui vogliamo parlare (McElreath 2020). I dataset su cui addestriamo i modelli spesso non sono rappresentativi delle popolazioni reali in certi aspetti. I modelli addestrati su tali dati non sono privi di valore, ma non sono nemmeno infallibili.\nQuestioni critiche da considerare:\n\nIn che misura il modello ci insegna qualcosa sui dati che abbiamo?\nIn che misura i dati che abbiamo riflettono il mondo su cui vorremmo trarre conclusioni?",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>La scienza dei dati e il metodo scientifico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#il-ruolo-della-statistica-e-della-data-science",
    "href": "chapters/chapter_2/00_scientific_method.html#il-ruolo-della-statistica-e-della-data-science",
    "title": "10¬† La scienza dei dati e il metodo scientifico",
    "section": "10.2 Il Ruolo della Statistica e della Data Science",
    "text": "10.2 Il Ruolo della Statistica e della Data Science\nLa statistica e la data science giocano un ruolo fondamentale nel processo scientifico moderno. Tuttavia, √® importante comprendere alcune sfumature:\n\nValidit√† statistica e assunzioni: La validit√† statistica si basa su determinate assunzioni. Mentre ci√≤ che viene insegnato nella teoria statistica √® corretto, le nostre circostanze specifiche potrebbero non soddisfare i criteri di partenza. √à essenziale essere consapevoli di queste limitazioni quando applichiamo metodi statistici.\nProcesso scientifico reale vs.¬†ideale: Un ulteriore aspetto da considerare riguarda la discrepanza tra l‚Äôinsegnamento teorico della statistica e la sua applicazione pratica nella ricerca. L‚Äôapproccio didattico tradizionale presenta spesso un processo lineare e ordinato: formulazione dell‚Äôipotesi, raccolta dati, analisi statistica e conclusione. La realt√† della ricerca, tuttavia, si rivela notevolmente pi√π complessa e dinamica. Gli scienziati reagiscono a incentivi, fanno tentativi, formulano ipotesi e seguono la loro intuizione, colmando le lacune quando necessario. Questo approccio euristico, sebbene possa sembrare caotico, √® spesso il terreno fertile per scoperte innovative. Questa metodologia pi√π flessibile, tuttavia, pone sfide significative all‚Äôapplicazione rigorosa dei concetti statistici tradizionali. Anche se √® fondamentale una comprensione approfondita di questi concetti, √® altrettanto importante sviluppare la capacit√† di riconoscere quando √® necessario andare oltre le metodologie convenzionali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>La scienza dei dati e il metodo scientifico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/00_scientific_method.html#implicazioni-epistemologiche",
    "href": "chapters/chapter_2/00_scientific_method.html#implicazioni-epistemologiche",
    "title": "10¬† La scienza dei dati e il metodo scientifico",
    "section": "10.3 Implicazioni Epistemologiche",
    "text": "10.3 Implicazioni Epistemologiche\n\nModelli come strumenti di apprendimento: I modelli non sono rappresentazioni definitive della realt√†, ma strumenti che ci permettono di apprendere le caratteristiche del reale. Il loro valore risiede nel processo di costruzione, test e revisione, piuttosto che nel risultato finale.\nLimiti della rappresentazione: √à fondamentale riconoscere che i modelli, per quanto sofisticati, sono sempre approssimazioni della realt√†. La loro utilit√† non sta nella perfezione della rappresentazione, ma nella capacit√† di generare intuizioni e previsioni utili.\nIterazione e miglioramento continuo: Il processo scientifico, attraverso l‚Äôuso di modelli, √® caratterizzato da un ciclo continuo di ipotesi, test e revisione. Questo approccio iterativo permette un raffinamento progressivo della nostra comprensione.\nConsapevolezza dei limiti: Una comprensione critica dei modelli richiede una costante consapevolezza dei loro limiti, delle assunzioni sottostanti e del contesto in cui sono stati sviluppati.\n\nIn conclusione, i modelli scientifici sono strumenti potenti per esplorare e comprendere la realt√†, ma la loro vera forza risiede nel processo di indagine che stimolano, piuttosto che nelle singole rappresentazioni che producono. La data science e la statistica forniscono il quadro metodologico per questo processo, ma √® fondamentale mantenere una prospettiva critica e consapevole dei limiti e delle assunzioni su cui si basano i nostri modelli e le nostre analisi.\n\n\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nVasishth, Shravan, e Andrew Gelman. 2021. ¬´How to embrace variation and accept uncertainty in linguistic and psycholinguistic data analysis¬ª. Linguistics 59 (5): 1311‚Äì42.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>La scienza dei dati e il metodo scientifico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html",
    "href": "chapters/chapter_2/01_key_notions.html",
    "title": "11¬† Concetti chiave",
    "section": "",
    "text": "11.1 Introduzione\nL‚Äôanalisi dei dati si colloca all‚Äôintersezione tra statistica, teoria della probabilit√† e informatica. Questa disciplina multidisciplinare richiede una solida comprensione dei concetti fondamentali provenienti da ciascuna di queste tre aree.\nLa statistica fornisce gli strumenti e le tecniche per raccogliere, analizzare e interpretare i dati. Attraverso metodi descrittivi e inferenziali, la statistica permette di trarre conclusioni dai dati e di prendere decisioni informate.\nLa teoria della probabilit√† costituisce la base matematica della statistica. Essa consente di modellare l‚Äôincertezza e di comprendere i fenomeni aleatori, fornendo i fondamenti per sviluppare metodi statistici rigorosi.\nL‚Äôinformatica gioca un ruolo cruciale nell‚Äôanalisi dei dati, offrendo gli strumenti necessari per la gestione, l‚Äôelaborazione e la visualizzazione dei dati su larga scala. Conoscere i principi dell‚Äôinformatica √® essenziale per sfruttare appieno le tecnologie moderne, come il machine learning e l‚Äôintelligenza artificiale, nell‚Äôanalisi dei dati. Ad esempio, l‚Äôuso di linguaggi di programmazione come Python e R, insieme a librerie specializzate, permette di eseguire analisi complesse e di visualizzare i dati in modo efficace.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#introduzione",
    "href": "chapters/chapter_2/01_key_notions.html#introduzione",
    "title": "11¬† Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine ‚Äústatistica‚Äù pu√≤ assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica √® una scienza e una disciplina che si occupa dello studio e dell‚Äôapplicazione di metodi e tecniche per la raccolta, l‚Äôorganizzazione, l‚Äôanalisi, l‚Äôinterpretazione e la presentazione di dati.\nNel secondo senso, il termine ‚Äústatistica‚Äù si riferisce a una singola misura o un valore numerico che √® stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#popolazioni-e-campioni",
    "href": "chapters/chapter_2/01_key_notions.html#popolazioni-e-campioni",
    "title": "11¬† Concetti chiave",
    "section": "11.2 Popolazioni e Campioni",
    "text": "11.2 Popolazioni e Campioni\nPer iniziare l‚Äôanalisi dei dati, √® fondamentale individuare le unit√† che contengono le informazioni rilevanti per il fenomeno di interesse. Questo insieme di unit√† costituisce la popolazione o universo, che rappresenta l‚Äôinsieme completo di entit√† capaci di fornire informazioni per l‚Äôindagine statistica in questione. Possiamo rappresentare la popolazione come $ N $ o $ $ nel caso di popolazioni finite o infinite, rispettivamente. Le singole unit√† dell‚Äôinsieme sono chiamate unit√† statistiche.\nNella ricerca psicologica, sia nelle ricerche sperimentali che in quelle osservazionali, l‚Äôobiettivo principale √® studiare i fenomeni psicologici all‚Äôinterno di una specifica popolazione. Pertanto, √® essenziale definire con chiarezza la popolazione di interesse, ovvero l‚Äôinsieme di individui ai quali verranno applicati i risultati della ricerca. Tale popolazione pu√≤ essere reale, come ad esempio tutte le persone sopravvissute per un anno dopo il bombardamento atomico di Hiroshima, o ipotetica, come ad esempio tutte le persone depresse che potrebbero beneficiare di un intervento psicologico. Il ricercatore deve sempre essere in grado di identificare se un individuo specifico appartiene o meno alla popolazione in questione.\n\n11.2.1 Sotto-popolazioni e Campioni\nUna sotto-popolazione √® un sottoinsieme di individui che possiedono propriet√† specifiche ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione degli uomini di et√† inferiore ai 30 anni o alla sotto-popolazione dei pazienti depressi che hanno ricevuto uno specifico intervento psicologico. Molte questioni scientifiche cercano di descrivere le differenze tra sotto-popolazioni, come ad esempio il confronto tra un gruppo di pazienti sottoposti a psicoterapia e un gruppo di controllo per valutare l‚Äôefficacia di un trattamento.\nIl campione √® un sottoinsieme della popolazione composto da un insieme di elementi, ognuno dei quali rappresenta un‚Äôunit√† statistica (abbreviata con u.s.) portatrice delle informazioni che verranno rilevate tramite un‚Äôoperazione di misurazione. Il campione viene utilizzato per ottenere informazioni sulla popolazione di riferimento.\n\n\n11.2.2 Metodi di Campionamento\nIl campionamento pu√≤ avvenire in diversi modi. Il campionamento casuale consente al ricercatore di trarre conclusioni sulla popolazione e di quantificare l‚Äôincertezza dei risultati. Un esempio di campione casuale √® quello utilizzato in un sondaggio. Tuttavia, esistono anche altre forme di campionamento, come il campione di convenienza, in cui si seleziona una coorte di studenti da un unico istituto, o il campionamento stratificato, dove la popolazione viene divisa in gruppi o strati, e vengono selezionati campioni proporzionali da ciascuno strato.\nIl ricercatore, indipendentemente dal metodo di acquisizione dei dati, deve sempre considerare la questione della rappresentativit√† statistica del campione, ovvero se il campione scelto √® in grado di riflettere in modo accurato e privo di distorsioni le caratteristiche di interesse della popolazione. Selezionare le unit√† statistiche in modo casuale rappresenta il metodo pi√π semplice per garantire la rappresentativit√† del campione. Tuttavia, in molti casi, soprattutto in psicologia, i ricercatori possono non avere a disposizione le risorse necessarie, inclusi i fondi, per utilizzare la tecnica del campionamento casuale nelle loro ricerche. In tali situazioni, possono ricorrere ad altri metodi di campionamento, come il campionamento di convenienza, a seconda delle esigenze e delle risorse disponibili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#variabili-e-costanti",
    "href": "chapters/chapter_2/01_key_notions.html#variabili-e-costanti",
    "title": "11¬† Concetti chiave",
    "section": "11.3 Variabili e Costanti",
    "text": "11.3 Variabili e Costanti\nNell‚Äôambito dell‚Äôanalisi statistica, le variabili rappresentano concetti centrali, denotando le caratteristiche o gli attributi che possono assumere una variet√† di valori, numerici o categoriali. Essi incarnano gli elementi quantificabili o osservabili ai quali le unit√† statistiche danno riscontro. Ad esempio, ponendo la domanda ‚ÄúQual √® l‚Äôet√† di questo partecipante?‚Äù e ottenendo come risposta ‚Äú19 anni‚Äù, si identifica ‚Äúet√†‚Äù come la variabile, e ‚Äú19‚Äù come il valore corrispondente.\n\n11.3.1 Tipi di Variabili\nIn pratica, nel contesto della ricerca empirica, una variabile rappresenta un insieme di osservazioni relative alla stessa misurazione, come ad esempio il punteggio di ‚Äúnevrosismo‚Äù ottenuto da interviste condotte su 744 bambini. Descrivere una variabile significa essere in grado di prendere tali osservazioni e comunicare chiaramente il loro significato, senza obbligare chi legge a dover esaminare ciascuno dei 744 punteggi di nevrosismo separatamente. Questo compito non √® affatto semplice.\nPossiamo distinguere varie classi di variabili:\n\nVariabili continue: Possono assumere valori in un intervallo potenzialmente infinito.\nVariabili di conteggio: Rappresentano la frequenza con cui si verificano eventi o la quantit√† di oggetti in una categoria specifica.\nVariabili ordinali: Caratterizzate da un ordine intrinseco tra i loro valori, ma non esiste una scala standard per quantificare la differenza tra essi.\nVariabili categoriche: Utilizzate per assegnare categorie o classi a un‚Äôosservazione, indicando a quale categoria appartiene.\nVariabili binarie: Una sottocategoria di variabili categoriche che possono assumere solo due valori distinti.\n\nLe modalit√† descrivono le diverse forme che una variabile statistica pu√≤ assumere. L‚Äôinsieme delle modalit√† di una variabile √® rappresentato dall‚Äôinsieme $ $, che include tutte le possibili manifestazioni della variabile. Le modalit√† presenti nel campione vengono etichettate come dati.\nIn statistica, la nozione di ‚Äúvariabile‚Äù si distingue da quella di ‚Äúcostante‚Äù, che rimane immutabile attraverso tutte le unit√† statistiche.\n\nEsempio 1: In uno studio relativo all‚Äôintelligenza degli adulti italiani, la variabile di interesse √® il punteggio nel test WAIS-IV, con modalit√† quali 112, 92, 121 ecc. Questa variabile √® classificata come quantitativa discreta.\nEsempio 2: Nell‚Äôanalisi del compito Stroop, focalizzata su bambini di et√† 6-8 anni, la variabile in esame √® l‚Äôinverso dei tempi di reazione, misurati in secondi, con modalit√† come 1.93, 2.35, 1.32 ecc. Questa variabile √® classificata come quantitativa continua.\nEsempio 3: In uno studio del disturbo di personalit√† condotto tra i detenuti nelle carceri italiane, la variabile scrutinata √® l‚Äôassessment del disturbo di personalit√†, valutato attraverso interviste cliniche strutturate. Le modalit√† sono i Cluster A, Cluster B, Cluster C, secondo la classificazione del DSM-V, e questa variabile √® classificata come qualitativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#la-distribuzione-delle-variabili",
    "href": "chapters/chapter_2/01_key_notions.html#la-distribuzione-delle-variabili",
    "title": "11¬† Concetti chiave",
    "section": "11.4 La Distribuzione delle Variabili",
    "text": "11.4 La Distribuzione delle Variabili\nUna volta compreso il tipo di variabile con cui lavoriamo, √® fondamentale esaminare la distribuzione di tale variabile. La distribuzione di una variabile rappresenta la frequenza con cui si verificano i diversi valori. Nel caso delle variabili discrete, la distribuzione √® semplicemente un elenco delle modalit√† (valori distinti) e delle relative frequenze. Ad esempio, se consideriamo la variabile ‚Äúgenere‚Äù all‚Äôinterno di un campione di studenti, possiamo affermare che l‚Äô82% sono donne e il 18% sono uomini.\nLe distribuzioni delle variabili sono descritte in termini di probabilit√†. Le frequenze relative possono essere interpretate come ‚Äúprobabilit√† empiriche‚Äù. Nell‚Äôesempio precedente, la probabilit√† di ‚Äúessere una donna‚Äù nel campione specifico √® 0.82, mentre la probabilit√† di ‚Äúessere un uomo‚Äù √® 0.18. La probabilit√† che una variabile $ X $ (come il genere) assuma un valore specifico $ x $ (ad esempio, ‚Äúdonna‚Äù) viene indicata come $ P(X = x) $, o pi√π semplicemente $ P(x) $.\nLe distribuzioni delle variabili continue sono pi√π complesse da descrivere. Per le variabili continue, non descriviamo la probabilit√† che la variabile assuma un valore specifico, ma la probabilit√† che essa cada in un intervallo vicino a quel valore specifico. In futuro, esploreremo come rappresentare graficamente la distribuzione di una variabile continua utilizzando un istogramma o un grafico della densit√† di probabilit√† chiamato ‚ÄúKernel Density Plot‚Äù.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#la-matrice-dei-dati",
    "href": "chapters/chapter_2/01_key_notions.html#la-matrice-dei-dati",
    "title": "11¬† Concetti chiave",
    "section": "11.5 La Matrice dei Dati",
    "text": "11.5 La Matrice dei Dati\nNell‚Äôambito dell‚Äôanalisi statistica, la matrice dei dati svolge un ruolo fondamentale nell‚Äôorganizzazione delle informazioni relative alle variabili. Si tratta di una tabella strutturata con righe e colonne, dove ogni riga individua un‚Äôunit√† statistica specifica e ogni colonna rappresenta una diversa variabile statistica in esame.\nVa enfatizzato che, all‚Äôinterno della matrice dei dati, le unit√† statistiche non seguono generalmente un ordine progressivo o gerarchico. L‚Äôindice attribuito a ciascuna unit√† statistica indica semplicemente la posizione che essa occupa all‚Äôinterno della tabella, senza implicare un valore intrinseco o una relazione ordinale. Tale strutturazione metodica offre un mezzo efficace per raccogliere, visualizzare e analizzare le informazioni ottenute durante lo studio statistico, permettendo una gestione chiara e sistematica dei dati raccolti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#capire-i-dati",
    "href": "chapters/chapter_2/01_key_notions.html#capire-i-dati",
    "title": "11¬† Concetti chiave",
    "section": "11.6 Capire i dati",
    "text": "11.6 Capire i dati\nA scopo illustrativo, prendiamo in considerazione il dataset contenuto nel file STAR.csv. Questi dati sono parte integrante del progetto STAR (Student-Teacher Achievement Ratio), un esperimento pedagogico sviluppato negli Stati Uniti nel periodo tra il 1985 e il 1990. La finalit√† centrale di questo studio era indagare l‚Äôimpatto delle dimensioni delle classi sulle performance accademiche degli studenti. In questo contesto, gli studenti venivano distribuiti casualmente in classi di dimensioni ridotte (13-17 studenti) o pi√π ampie (22-25 studenti).\nDopo aver preparato l‚Äôambiente di lavoro caricando i pacchetti necessari, √® possibile procedere all‚Äôimportazione dei dati in Python. Si pu√≤ fare ci√≤ utilizzando il seguente codice, prestando attenzione al fatto che l‚Äôargomento di read_csv() deve specificare il percorso relativo del file rispetto alla directory in cui √® situato lo script .ipynb:\n\ndf_star = pd.read_csv(\"../data/STAR.csv\")\n\nQuesto codice importa i dati dal file STAR.csv e li memorizza in un DataFrame di pandas. Questo passo √® fondamentale per consentire un‚Äôanalisi e una manipolazione efficiente delle informazioni relative all‚Äôesperimento STAR. In Python, il DataFrame rappresenta la struttura dati principale per la gestione e l‚Äôelaborazione dei dati. Il DataFrame attualizza il concetto di ‚Äúmatrice di dati‚Äù che abbiamo introdotto in precedenza.\n\ndf_star.shape\n\n(1274, 4)\n\n\nDato che il DataFrame √® troppo grande (1274 righe e 4 colonne), stampiamo sullo schermo le prime 5 righe.\n\ndf_star.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nNella terminologia statistica, l‚Äôosservazione √® l‚Äôinformazione raccolta da un individuo o un‚Äôentit√† specifica che partecipa allo studio. Considerando il dataset STAR, l‚Äôunit√† di osservazione √® costituita dagli studenti. Pertanto, nel DataFrame denominato df_star, ogni riga simboleggia uno studente distinto coinvolto nell‚Äôindagine.\nLe variabili, d‚Äôaltro canto, sono espressioni delle diverse caratteristiche degli individui o delle entit√† analizzate. Nel contesto del progetto STAR, questo concetto si traduce in:\n\nOgni colonna di df_star rappresenta una variabile che incarna una particolare propriet√† condivisa da tutti gli studenti partecipanti.\nLe variabili sono identificate attraverso etichette collegate alle colonne, come classtype (il tipo di classe assegnata, con modalit√† small e regular), reading (il punteggio nel test di lettura standardizzato), math (il punteggio nel test di matematica standardizzato) e graduated (indicazione se lo studente ha conseguito o meno il diploma di scuola superiore, con ‚Äú1‚Äù o ‚Äú0‚Äù rispettivamente).\n\nPer rappresentare un‚Äôosservazione singola della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l‚Äôindice dell‚Äôosservazione. Questo indice significa che abbiamo un valore differente di \\(X\\) per ogni valore distinto di \\(i\\). Ad esempio, nel caso di 1274 osservazioni, \\(i\\) pu√≤ variare da 1 a 1274. Pertanto, per simboleggiare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\). √à fondamentale tener presente che, mentre in Python gli indici iniziano da 0, nella notazione matematica tradizionale, come quella rappresentata da \\(X_i\\), l‚Äôindice ha inizio da 1. Questa differenza tra le convenzioni di indicizzazione pu√≤ essere un aspetto cruciale da considerare durante l‚Äôanalisi dei dati.\n\ndf_star[\"reading\"][1]\n\n612\n\n\nUna delle prime cose da fare, quando esaminiamo un dataset, √® capire che tipo di variabili sono incluse.\n\ndf_star.dtypes\n\nclasstype    object\nreading       int64\nmath          int64\ngraduated     int64\ndtype: object\n\n\nNel caso specifico, notiamo che la variabile classtype √® di tipo object, quindi √® una variabile qualitativa, mentre le altre variabili sono numeriche, rappresentate come numeri interi (int64). Se elenchiamo le modalit√† presenti in classtype utilizzando il metodo unique(), scopriamo che corrispondono a ‚Äúsmall‚Äù e ‚Äúregular‚Äù.\n\ndf_star[\"classtype\"].unique()\n\narray(['small', 'regular'], dtype=object)\n\n\nCon l‚Äôistruzione seguente verifichiamo che la variabile graduated sia una variabile binaria.\n\ndf_star[\"graduated\"].unique()\n\narray([1, 0])",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#variabili-indipendenti-e-variabili-dipendenti",
    "href": "chapters/chapter_2/01_key_notions.html#variabili-indipendenti-e-variabili-dipendenti",
    "title": "11¬† Concetti chiave",
    "section": "11.7 Variabili Indipendenti e Variabili Dipendenti",
    "text": "11.7 Variabili Indipendenti e Variabili Dipendenti\nNell‚Äôambito della ricerca statistica, √® fondamentale distinguere tra variabili indipendenti e dipendenti. Questa distinzione si basa sulla domanda di ricerca e sulla comprensione del fenomeno che si sta studiando.\n\n11.7.1 Variabili Indipendenti\nLe variabili indipendenti, a volte chiamate variabili predittive, rappresentano i fattori che si ipotizza influenzino l‚Äôesito di interesse. Esse sono spesso manipolate o controllate dal ricercatore.\n\n\n11.7.2 Variabili Dipendenti\nLe variabili dipendenti, d‚Äôaltra parte, rappresentano l‚Äôesito o il risultato che si sta cercando di spiegare o prevedere. Esse sono ci√≤ che il ricercatore sta cercando di capire e sono influenzate dalle variabili indipendenti.\nIn molti studi, √® abbastanza chiaro quali sono le variabili indipendenti e dipendenti. Tuttavia, in alcuni casi, la relazione pu√≤ essere pi√π sfumata o complessa. Ad esempio, nell‚Äôanalizzare la correlazione tra l‚Äôesercizio fisico e l‚Äôinsonnia, pu√≤ non essere immediatamente evidente quale sia la causa e quale l‚Äôeffetto. In tali circostanze, una comprensione delle relazioni causali inerenti il fenomeno considerato √® necessaria per una corretta distinzione tra variabili indipendenti (cause) e dipendenti (effetti).\nEsempio 5 Prendiamo in considerazione un esperimento in cui uno psicologo ha chiamato 120 studenti universitari per un test di memoria. Prima di iniziare, met√† dei partecipanti √® stata informata che il compito era particolarmente difficile, mentre all‚Äôaltra met√† non √® stata fornita alcuna indicazione sulla difficolt√†. Successivamente, √® stato misurato il punteggio ottenuto nella prova di memoria da ciascun partecipante.\nIn questo esperimento: - La variabile indipendente √® l‚Äôinformazione sulla difficolt√† del compito, che √® stata manipolata dallo sperimentatore attraverso l‚Äôassegnazione casuale dei soggetti alle due diverse condizioni (‚Äúinformazione fornita‚Äù e ‚Äúinformazione non fornita‚Äù). - La variabile dipendente √® il punteggio ottenuto nella prova di memoria, ovvero l‚Äôoutcome che lo sperimentatore sta cercando di capire e che potrebbe essere influenzato dalla variabile indipendente.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#effetto",
    "href": "chapters/chapter_2/01_key_notions.html#effetto",
    "title": "11¬† Concetti chiave",
    "section": "11.8 Effetto",
    "text": "11.8 Effetto\nIl concetto di ‚Äúeffetto‚Äù √® fondamentale nell‚Äôanalisi dei dati e nella statistica, poich√© rappresenta una misura del cambiamento o dell‚Äôinfluenza tra le variabili. Ad esempio, consideriamo uno studio sulla memoria che indaga l‚Äôeffetto delle mnemotecniche sul miglioramento della memoria. In questo studio, un gruppo riceve un intervento relativo al rilassamento, mentre un altro partecipa a un workshop di riorganizzazione mnemonica. Alla fine, i partecipanti vengono sottoposti a test di memoria e l‚Äôeffetto delle mnemotecniche √® determinato dalla differenza tra i punteggi medi dei due gruppi. Se il gruppo che ha seguito il workshop mostra un punteggio medio superiore, si pu√≤ affermare che le mnemotecniche hanno un effetto positivo sulla memoria.\nL‚Äôeffetto viene misurato attraverso diverse statistiche, come la differenza di medie, il rapporto di probabilit√†, ecc. Quando si analizzano i dati con metodi statistici, l‚Äôobiettivo √® determinare se l‚Äôeffetto osservato √® credibile, ovvero se ci sono evidenze che l‚Äôeffetto sia generalizzabile alla popolazione nel suo insieme. Questo aiuta a valutare l‚Äôimportanza dell‚Äôeffetto e a trarre conclusioni sulle relazioni tra le variabili nello studio.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#variabili-casuali",
    "href": "chapters/chapter_2/01_key_notions.html#variabili-casuali",
    "title": "11¬† Concetti chiave",
    "section": "11.9 Variabili Casuali",
    "text": "11.9 Variabili Casuali\nIl concetto di variabile nella statistica trova un corrispondente nella teoria delle probabilit√†, dove √® chiamato variabile casuale. Quando ci occupiamo di studi come quelli sugli interventi psicologici, le variabili casuali vengono utilizzate per rappresentare e misurare i risultati di tali interventi. In sostanza, una variabile casuale descrive una caratteristica specifica degli individui all‚Äôinterno di una popolazione, e i suoi valori possono variare tra gli individui. Teoricamente, una variabile casuale pu√≤ assumere una gamma di valori possibili, ma in pratica si osserva un valore specifico per ogni individuo.\nUtilizziamo notazioni particolari per riferirci alle variabili casuali e ai loro valori specifici. Ad esempio, le lettere maiuscole come $ X $ e $ Y $ denotano le variabili casuali, mentre le lettere minuscole come $ x $ e $ y $ si riferiscono ai valori che queste variabili possono assumere in circostanze specifiche.\n\n11.9.1 Differenza tra Variabili Casuali e Variabili Statistiche\nLa chiave per comprendere la differenza tra questi due concetti risiede nell‚Äôincertezza epistemica che il ricercatore affronta. Immaginiamo un esperimento casuale, come il lancio di un dado. Supponiamo che la variabile di interesse $ X $ rappresenti l‚Äôesito del lancio. Prima del lancio, $ X $ √® una variabile casuale, poich√© conosciamo i possibili valori che pu√≤ assumere (da 1 a 6), ma non sappiamo quale valore specifico si manifester√†. In questo stadio, $ X $ rappresenta una quantit√† incognita, suscettibile di variazione casuale.\nDopo il lancio, supponiamo che l‚Äôesito sia 5. A questo punto, la variabile $ X $ diventa una variabile statistica, poich√© rappresenta un dato osservato e concreto all‚Äôinterno del campione di osservazioni. L‚Äôincertezza √® risolta, e il valore di $ X $ √® ora noto e fisso.\nIn sintesi, una variabile casuale rappresenta una quantit√† che pu√≤ assumere diversi valori con una certa probabilit√†, mentre una variabile statistica √® una realizzazione specifica di quella quantit√† incognita. La transizione da una variabile casuale a una variabile statistica avviene attraverso l‚Äôosservazione e la misurazione, che trasformano un‚Äôincertezza teorica in una certezza empirica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#stima-e-inferenza",
    "href": "chapters/chapter_2/01_key_notions.html#stima-e-inferenza",
    "title": "11¬† Concetti chiave",
    "section": "11.10 Stima e Inferenza",
    "text": "11.10 Stima e Inferenza\n\n11.10.1 Stima\nLa stima √® un concetto centrale in statistica che si riferisce al processo attraverso il quale si ottengono informazioni sulle caratteristiche di una popolazione intera basandosi sui dati di un campione estratto da essa. Ad esempio, calcolando la media o la mediana dei dati all‚Äôinterno del campione, possiamo derivare stime per la media o la mediana della popolazione complessiva. Le caratteristiche che vogliamo conoscere della popolazione sono spesso chiamate ‚Äúparametri‚Äù, e la stima pu√≤ riguardare sia questi parametri sia la distribuzione di una variabile casuale nella popolazione.\n\n\n11.10.2 Inferenza Statistica\nDopo aver ottenuto queste stime, si passa al passaggio successivo: l‚Äôinferenza statistica. Questo processo va oltre la semplice stima e ci permette di trarre conclusioni pi√π ampie sulla popolazione. L‚Äôinferenza statistica riguarda la valutazione di specifiche ipotesi o risposte a domande di ricerca relative alla popolazione, utilizzando le stime ottenute dal campione.\nAd esempio, se abbiamo stimato la media dei redditi in un campione di famiglie, possiamo utilizzare l‚Äôinferenza statistica per testare se c‚Äô√® una differenza significativa nei redditi tra diverse regioni o gruppi demografici all‚Äôinterno della popolazione. In questo modo, l‚Äôinferenza statistica ci fornisce gli strumenti per fare previsioni e trarre conclusioni riguardanti la popolazione intera.\n\n\n11.10.3 Approcci all‚ÄôInferenza Statistica\nEsistono vari approcci e metodologie per condurre l‚Äôinferenza statistica, tra cui due dei pi√π comuni sono l‚Äôinferenza bayesiana e l‚Äôapproccio frequentista. L‚Äôinferenza bayesiana si basa sull‚Äôuso di probabilit√† a priori e a posteriori, mentre l‚Äôapproccio frequentista si basa su tecniche come i test d‚Äôipotesi e gli intervalli di confidenza.\nIn sintesi, la stima e l‚Äôinferenza statistica sono due fasi cruciali nell‚Äôanalisi statistica. La stima ci permette di utilizzare i dati del campione per ottenere informazioni su specifiche caratteristiche della popolazione, mentre l‚Äôinferenza statistica ci consente di utilizzare quelle stime per fare affermazioni pi√π generali e valutare ipotesi sulla popolazione nel suo insieme. Entrambi questi processi sono fondamentali per comprendere e interpretare i fenomeni che stiamo studiando.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#modelli-psicologici",
    "href": "chapters/chapter_2/01_key_notions.html#modelli-psicologici",
    "title": "11¬† Concetti chiave",
    "section": "11.11 Modelli Psicologici",
    "text": "11.11 Modelli Psicologici\n\n11.11.1 Concetto di Modello\nIn ambito statistico e nel campo della data science, un ‚Äúmodello‚Äù rappresenta una formulazione matematica semplificata di un fenomeno reale che si desidera studiare. Si tratta di un insieme di equazioni e ipotesi che delineano la struttura probabilistica e le relazioni tra le variabili, cercando di catturare gli aspetti essenziali del fenomeno senza rappresentarlo in ogni dettaglio. La scelta del modello specifico pu√≤ dipendere dai dati disponibili, dalla domanda di ricerca e dall‚Äôobiettivo dell‚Äôanalisi. Poich√© spesso esistono diversi modelli che possono essere applicati allo stesso problema, la data science si pone il problema dell‚Äôidentificazione del modello che meglio si adatta ai dati e che soddisfa certi criteri di validit√† e bont√†.\n\n\n11.11.2 Modelli in Psicologia\nNel contesto della psicologia, la modellazione assume un ruolo fondamentale e particolarmente delicato. I modelli psicologici sono strumenti concettuali utilizzati per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Data la complessit√† e la variabilit√† dei fenomeni psicologici, la costruzione di modelli efficaci richiede un approccio rigoroso e multidimensionale. Un modello psicologico robusto e valido deve soddisfare diverse caratteristiche essenziali:\n\nCoerenza descrittiva: Il modello deve fornire una rappresentazione logica e internamente coerente del fenomeno studiato. Deve catturare gli elementi essenziali del processo psicologico in esame, offrendo una struttura concettuale che organizzi le osservazioni in modo significativo e comprensibile.\nCapacit√† predittiva: Un aspetto cruciale di un modello psicologico efficace √® la sua abilit√† di formulare predizioni accurate sulle manifestazioni future del fenomeno. Questa caratteristica non solo aumenta l‚Äôutilit√† pratica del modello, ma fornisce anche un mezzo per testarne la validit√†.\nSupporto empirico: Il modello deve essere ancorato a solide prove empiriche. Ci√≤ implica che le sue assunzioni e previsioni devono essere confermate da dati osservabili raccolti attraverso ricerche sistematiche e metodologicamente rigorose.\nFalsificabilit√†: Forse la caratteristica pi√π critica, la falsificabilit√†, richiede che il modello sia costruito in modo da poter essere sottoposto a verifica o confutazione attraverso l‚Äôosservazione e l‚Äôesperimento. Questo principio, fondamentale per il metodo scientifico, assicura che il modello rimanga aperto al scrutinio critico e alla revisione basata su nuove evidenze.\nParsimonia: Un buon modello psicologico dovrebbe essere parsimonioso. Dovrebbe spiegare il fenomeno nel modo pi√π semplice possibile, evitando complessit√† non necessarie.\nGeneralizzabilit√†: Il modello dovrebbe essere applicabile a una vasta gamma di situazioni e contesti, non solo a specifici casi o condizioni sperimentali.\nUtilit√† pratica: Infine, un modello psicologico efficace dovrebbe avere implicazioni pratiche, fornendo insights utili per interventi, terapie o applicazioni nel mondo reale.\n\nLa modellazione in psicologia si trova spesso di fronte a sfide uniche dovute alla natura soggettiva e variabile dell‚Äôesperienza umana. I ricercatori devono bilanciare la necessit√† di precisione scientifica con la flessibilit√† richiesta per catturare la ricchezza e la complessit√† dei fenomeni psicologici. Inoltre, devono essere consapevoli dei limiti etici nella sperimentazione e delle potenziali implicazioni sociali dei loro modelli.\nLa creazione e l‚Äôutilizzo di modelli in psicologia √® un processo dinamico e iterativo. I modelli sono costantemente raffinati, testati e, se necessario, rivisti o sostituiti man mano che emergono nuove evidenze. Questo approccio assicura che la comprensione dei processi psicologici continui a evolvere e migliorare nel tempo.\nL‚Äôanalisi dei dati, attraverso l‚Äôapplicazione di tecniche statistiche, √® il mezzo attraverso il quale un modello psicologico viene valutato. Oltre a determinare se il modello √® in grado di spiegare i dati osservati, l‚Äôanalisi pu√≤ anche verificare la capacit√† del modello di fare previsioni accurate su dati non ancora osservati. In questo modo, la modellazione diventa uno strumento potente non solo per comprendere i fenomeni psicologici ma anche per prevedere e, in alcuni casi, influenzare il comportamento e le dinamiche mentali.\nIn sintesi, un modello, sia in statistica che in psicologia, √® uno strumento teorico che cerca di rappresentare un fenomeno complesso in una forma semplificata ma informativa, guidando la comprensione, la previsione e, in ultima analisi, l‚Äôintervento efficace su quel fenomeno. La scelta e la valutazione del modello giusto sono fondamentali per garantire che le conclusioni derivanti dall‚Äôanalisi siano valide e utili nel contesto specifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "title": "11¬† Concetti chiave",
    "section": "11.12 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "11.12 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html",
    "href": "chapters/chapter_2/02_measurement.html",
    "title": "12¬† La misurazione in psicologia",
    "section": "",
    "text": "12.1 Introduzione\nIl problema dello scaling psicologico riguarda la trasformazione dei dati osservati in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche misurate. Quando conduciamo ricerche in psicologia, spesso vogliamo assegnare numeri ai comportamenti o alle risposte degli individui per analizzarli in modo oggettivo. Tuttavia, questa trasformazione √® complessa e richiede attenzione a diverse considerazioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#introduzione",
    "href": "chapters/chapter_2/02_measurement.html#introduzione",
    "title": "12¬† La misurazione in psicologia",
    "section": "",
    "text": "12.1.1 Scaling di Guttman\nUno dei metodi di scaling pi√π noti √® il ¬´Scaling di Guttman¬ª, utilizzato per rappresentare relazioni ordinate tra elementi di una scala. Per esempio, in un questionario sui sintomi di ansia, le domande sono ordinate per intensit√† crescente. Se un partecipante risponde ‚Äús√¨‚Äù a una domanda pi√π intensa, dovrebbe aver risposto ‚Äús√¨‚Äù anche a tutte le domande meno intense precedenti, creando una scala ordinata di gravit√† dei sintomi.\n\n\n12.1.2 Scaling Thurstoniano\nLo ¬´Scaling Thurstoniano¬ª misura le preferenze o i giudizi soggettivi. Ad esempio, per valutare la preferenza per diversi tipi di cibi, i partecipanti confrontano due cibi alla volta e esprimono una preferenza. Queste risposte vengono usate per assegnare punteggi basati sulla preferenza media.\n\n\n12.1.3 Questionari Likert\nI questionari Likert richiedono ai partecipanti di esprimere il grado di accordo con affermazioni su una scala a pi√π livelli (da ¬´fortemente in disaccordo¬ª a ¬´fortemente d‚Äôaccordo¬ª). I punteggi ottenuti vengono sommati per rappresentare la posizione dell‚Äôindividuo rispetto all‚Äôoggetto di studio.\n\n\n12.1.4 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le propriet√† delle scale psicologiche, si utilizzano vari metodi. Ad esempio, l‚Äôaffidabilit√† delle misure pu√≤ essere analizzata con il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, che misurano la coerenza interna delle risposte ai vari item del questionario. Inoltre, la validit√† delle scale pu√≤ essere esaminata confrontando i risultati con misure simili o utilizzando analisi statistiche per verificare se la scala cattura accuratamente il costrutto che si intende misurare. La validit√† di costrutto √® cruciale, poich√© riguarda la capacit√† della scala di misurare effettivamente il concetto psicologico che si intende esaminare.\n\n\n12.1.5 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si √® arricchito di nuove prospettive, grazie all‚Äôavvento di tecnologie avanzate e all‚Äôintegrazione di approcci interdisciplinari. Ecco alcune delle tendenze pi√π rilevanti:\n\n12.1.5.1 Teoria della Risposta agli Item (IRT)\nLa Teoria della Risposta agli Item (IRT) ha guadagnato popolarit√† per la sua capacit√† di fornire stime pi√π precise delle abilit√† latenti rispetto ai modelli classici. La IRT considera la probabilit√† che un individuo risponda correttamente a un item in funzione della sua abilit√† e delle caratteristiche dell‚Äôitem stesso, offrendo una visione pi√π dettagliata delle propriet√† psicometriche degli strumenti di misurazione.\n\n\n12.1.5.2 Approcci Bayesiani\nGli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessit√† e l‚Äôincertezza inerenti alla misurazione psicologica.\n\n\n12.1.5.3 Analisi di Rete\nL‚Äôanalisi di rete √® un‚Äôaltra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio pu√≤ offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#le-scale-di-misurazione",
    "href": "chapters/chapter_2/02_measurement.html#le-scale-di-misurazione",
    "title": "12¬† La misurazione in psicologia",
    "section": "12.2 Le scale di misurazione",
    "text": "12.2 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le propriet√† psicologiche. La teoria delle scale di Stevens {cite:p}stevens_46 identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poich√© ciascuna di esse √® in grado di ‚Äúcatturare‚Äù solo alcune delle propriet√† dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n12.2.1 Scala nominale\nILa scala nominale √® il livello di misurazione pi√π semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica √® uguale o diversa da un‚Äôaltra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unit√† di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL‚Äôunica operazione algebrica consentita dalla scala nominale √® quella di contare le unit√† di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale √® possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unit√† di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n12.2.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unit√† di misura all‚Äôinterno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) √® uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale √® quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed √® scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto √® considerato pi√π duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearit√† della scala di Mohs (Burchard, 2004).\n\n\n\n\n12.2.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le propriet√† della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unit√† statistiche in termini di un intervallo costante, chiamato ‚Äúunit√† di misura‚Äù, a cui viene attribuito il valore ‚Äú1‚Äù. L‚Äôorigine della scala, ovvero il punto zero, √® scelta arbitrariamente e non indica l‚Äôassenza della propriet√† che si sta misurando. Ci√≤ significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all‚Äôunit√† statistica in cui la propriet√† risulta assente.\nLa scala ad intervalli equivalenti consente l‚Äôesecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli √® che non consente di calcolare il rapporto tra coppie di misure. √à possibile affermare la differenza tra \\(a\\) e \\(b\\) come la met√† della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non √® possibile affermare che \\(a\\) abbia una propriet√† misurata in quantit√† doppia rispetto a \\(b\\). In altre parole, non √® possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalit√† permettono tutte le operazioni aritmetiche, come la somma, l‚Äôelevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l‚Äôunit√† di misura √® arbitraria e pu√≤ essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l‚Äôaggiunta di una costante a tutti i valori della scala, √® ammessa poich√© non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l‚Äôuguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli √® la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, √® possibile stabilire se due modalit√† sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale √® possibile mettere due modalit√† in una relazione d‚Äôordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, per√≤, √® possibile definire una unit√† di misura per cui √® possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c‚Äô√® una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l‚Äôintensit√† del fenomeno, godono della propriet√† che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli √® quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non √® il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione ‚Äúil doppio di‚Äù che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla propriet√† misurata (cio√® la temperatura). La decisione di che scala usare (Centigrada vs.¬†Fahrenheit) √® arbitraria. Ma questa arbitrariet√† non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realt√† empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l‚Äôaspetto invariante di una trasformazione lineare, ovvero l‚Äôuguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\n√à facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall‚Äôunit√† di misura che √® stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n12.2.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non √® arbitrario e rappresenta l‚Äôelemento che ha intensit√† nulla rispetto alla propriet√† misurata. Per costruire questa scala, si associa il numero 0 all‚Äôelemento con intensit√† nulla e si sceglie un‚Äôunit√† di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall‚Äôorigine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensit√† della propriet√† misurata.\nIn questa scala, √® possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L‚Äôunica scelta arbitraria √® l‚Äôunit√† di misura, ma lo zero deve sempre rappresentare l‚Äôintensit√† nulla della propriet√† considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarit√† e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/chapter_2/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "12¬† La misurazione in psicologia",
    "section": "12.3 Gerarchia dei livelli delle scale di misurazione",
    "text": "12.3 Gerarchia dei livelli delle scale di misurazione\nSecondo {cite:t}stevens_46, esiste una gerarchia dei livelli delle scale di misurazione, denominati ‚Äúlivelli di scala‚Äù. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello pi√π basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello pi√π alto. - La scala nominale √® il livello pi√π elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine. - Al livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualit√† o caratteristica. Qui, √® possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non √® possibile quantificare la differenza tra di esse in modo preciso. - La scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse √® quantificabile in modo preciso. In questa scala, √® possibile effettuare operazioni matematiche come l‚Äôaddizione e la sottrazione tra i valori, ma non √® possibile stabilire un vero e proprio punto zero significativo. - Infine, la scala a rapporti equivalenti rappresenta il livello pi√π alto. In questa scala, le categorie sono ordinate, la differenza tra di esse √® quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l‚Äôassenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\nPassando da un livello di misurazione ad uno pi√π alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ci√≤ che riguarda le trasformazioni ammissibili, pi√π il livello di scala √® basso, pi√π le funzioni sono generali (sono minori cio√® i vincoli per passare da una rappresentazione numerica ad un‚Äôaltra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa pi√π restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/chapter_2/02_measurement.html#variabili-discrete-o-continue",
    "title": "12¬† La misurazione in psicologia",
    "section": "12.4 Variabili discrete o continue",
    "text": "12.4 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue. - Le variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l‚Äôelenco dei valori accettabili √® stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti. - D‚Äôaltra parte, le variabili continue possono assumere qualsiasi valore all‚Äôinterno di un intervallo specificato. Teoricamente, ci√≤ significa che √® possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/chapter_2/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "12¬† La misurazione in psicologia",
    "section": "12.5 Comprendere gli errori nella misurazione",
    "text": "12.5 Comprendere gli errori nella misurazione\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\n\n12.5.1 Precisione e Accuratezza\nLa precisione indica la coerenza tra misurazioni ripetute, mentre l‚Äôaccuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l‚Äôassessment psicometrico.\nUtilizzando l‚Äôanalogia del tiro al bersaglio, si pu√≤ avere una serie di colpi vicini tra loro ma lontani dal centro (precisione senza accuratezza) oppure colpi distribuiti in modo sparso ma in media vicini al centro (accuratezza senza precisione).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#assessment-psicometrico",
    "href": "chapters/chapter_2/02_measurement.html#assessment-psicometrico",
    "title": "12¬† La misurazione in psicologia",
    "section": "12.6 Assessment psicometrico",
    "text": "12.6 Assessment psicometrico\nL‚Äôassessment psicometrico valuta la qualit√† delle misurazioni psicologiche, considerando la validit√† e l‚Äôaffidabilit√†.\n\n12.6.1 Validit√† nella Misurazione Psicologica\nLa validit√† √® una propriet√† psicometrica fondamentale dei test psicologici. Secondo gli Standards for Educational and Psychological Testing (2014), la validit√† si riferisce al grado in cui evidenza e teoria supportano le interpretazioni dei punteggi dei test per gli usi proposti. Questo concetto evidenzia che la validit√† riguarda sia il significato dei punteggi sia il loro utilizzo, rendendola ‚Äúla considerazione pi√π fondamentale nello sviluppo e nella valutazione dei test‚Äù.\n\n\n12.6.2 Evoluzione del Concetto di Validit√†\nTradizionalmente, la validit√† era suddivisa in tre categorie:\n\nValidit√† di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell‚Äôattributo psicologico che il test intende misurare. √à importante che gli item siano pertinenti e rappresentativi dell‚Äôattributo misurato.\nValidit√† di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validit√† concorrente e predittiva.\nValidit√† di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validit√† convergente (accordo con strumenti che misurano lo stesso costrutto) e validit√† divergente (capacit√† di discriminare tra costrutti diversi).\n\nLa moderna teoria della validit√† non adotta pi√π questa visione tripartita. Gli Standards del 2014 descrivono la validit√† come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l‚Äôinterpretazione dei punteggi del test per il loro utilizzo previsto.\n\n\n12.6.3 Tipologie di Prove di Validit√†\nGli Standards del 2014 identificano cinque categorie principali di prove di validit√†:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L‚Äôanalisi fattoriale √® uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validit√† convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell‚Äôuso del test, sia intenzionali che non intenzionali.\n\n\n\n12.6.4 Minacce alla Validit√†\nLa validit√† pu√≤ essere compromessa quando un test non misura integralmente il costrutto di interesse (sotto-rappresentazione del costrutto) o quando include varianza estranea al costrutto. Inoltre, fattori esterni come l‚Äôansia o la bassa motivazione degli esaminandi, e deviazioni nelle procedure di amministrazione e valutazione, possono influenzare negativamente la validit√† delle interpretazioni dei risultati.\n\n\n12.6.5 Integrazione delle Prove di Validit√†\nLa validit√† di un test si costruisce attraverso l‚Äôintegrazione di diverse linee di evidenza. Ogni interpretazione o uso di un test deve essere validato specificamente, richiedendo una valutazione continua e accurata delle prove disponibili. Questo processo implica la costruzione di un argomento di validit√† che consideri attentamente la qualit√† tecnica del test e l‚Äôadeguatezza delle sue interpretazioni per gli scopi previsti.\nIn conclusione, la validit√† √® un concetto complesso e integrato che richiede un‚Äôanalisi continua e multidimensionale delle evidenze. La moderna teoria della validit√† enfatizza l‚Äôimportanza di considerare diverse forme di evidenza per supportare le interpretazioni dei punteggi dei test, garantendo che siano utilizzati in modo appropriato e significativo. Gli sviluppatori e gli utilizzatori di test devono impegnarsi a valutare costantemente la validit√† per assicurare misurazioni psicologiche accurate e affidabili.\n\n\n12.6.6 Affidabilit√†\nL‚Äôaffidabilit√† concerne la consistenza e stabilit√† delle misurazioni, verificata attraverso metodi come l‚Äôaffidabilit√† test-retest, inter-rater, intra-rater e l‚Äôaffidabilit√† interna.\n\nAffidabilit√† Test-Retest: Questa forma di affidabilit√† verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilit√† Inter-rater: In questo caso, l‚Äôaffidabilit√† √® determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se pi√π psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilit√† Intra-rater: Questa misura dell‚Äôaffidabilit√† si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilit√† Interna: Si riferisce alla coerenza delle risposte all‚Äôinterno dello stesso test. Ad esempio, se un test misura un costrutto come l‚Äôansia, gli item che misurano l‚Äôansia dovrebbero correlare positivamente l‚Äôuno con l‚Äôaltro. Un modo comune per valutare l‚Äôaffidabilit√† interna √® utilizzare il coefficiente \\(\\omega\\) di McDonald.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/02_measurement.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_2/02_measurement.html#commenti-e-considerazioni-finali",
    "title": "12¬† La misurazione in psicologia",
    "section": "12.7 Commenti e considerazioni finali",
    "text": "12.7 Commenti e considerazioni finali\nLa teoria della misurazione √® fondamentale nella ricerca empirica per valutare l‚Äôattendibilit√† e la validit√† delle misurazioni. √à cruciale valutare l‚Äôerrore nella misurazione per garantire la precisione e l‚Äôaccuratezza delle misure. L‚Äôassessment psicometrico si occupa di valutare la qualit√† delle misurazioni psicologiche, considerando l‚Äôaffidabilit√† e la validit√† per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre pi√π raffinati per la comprensione delle caratteristiche psicologiche.\n\n\n\n\nStevens, Stanley Smith. 1946. ¬´On the theory of scales of measurement¬ª. Science 103 (2684): 677‚Äì80.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html",
    "href": "chapters/chapter_2/03_freq_distr.html",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "",
    "text": "13.1 Introduzione\nIn questo capitolo, esploreremo le strategie per sintetizzare grandi quantit√† di dati, soffermandoci su concetti fondamentali come le distribuzioni di frequenza, i quantili e le tecniche di visualizzazione. Discuteremo sia il calcolo che l‚Äôinterpretazione di queste misure, fornendo strumenti utili per rappresentare graficamente le sintesi di dati. Prima di procedere, √® indispensabile leggere l‚Äôappendice {ref}sec-appendix-sums per comprendere appieno le operazioni descritte.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#i-dati-grezzi",
    "href": "chapters/chapter_2/03_freq_distr.html#i-dati-grezzi",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.2 I dati grezzi",
    "text": "13.2 I dati grezzi\nPer illustrare i principali strumenti della statistica descrittiva, analizzeremo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento della depressione. I ricercatori hanno confrontato 30 soggetti con episodi depressivi con un gruppo di controllo di 37 individui sani, utilizzando il Beck Depression Inventory (BDI-II) per misurare la depressione.\nCarichiamo quindi i dati dal file data.mood.csv.\n\ndf = pd.read_csv(\"../data/data.mood.csv\")\n\nPer conoscere le dimensioni del DataFrame utilizzo il metodo shape().\n\ndf.shape\n\n(1188, 44)\n\n\nIl DataFrame ha 1188 righe e 44 colonne. Visualizzo il nome delle colonne con il metodo .columns.\n\ndf.columns\n\nIndex(['Unnamed: 0', 'vpn_nr', 'esm_id', 'group', 'bildung', 'bdi',\n       'nr_of_episodes', 'nobs_mood', 'trigger_counter', 'form', 'traurig_re',\n       'niedergeschlagen_re', 'unsicher_re', 'nervos_re', 'glucklich_re',\n       'frohlich_re', 'mood_sad.5', 'mood_fearful.5', 'mood_neg.5',\n       'mood_happy.5', 'cesd_sum', 'rrs_sum', 'rrs_brood', 'rrs_reflect',\n       'forecast_sad', 'forecast_fear', 'forecast_neg', 'forecast_happy',\n       'recall_sad', 'recall_fear', 'recall_neg', 'recall_happy',\n       'diff_neg.fore.5', 'diff_sad.fore.5', 'diff_fear.fore.5',\n       'diff_happy.fore.5', 'diff_neg.retro.5', 'diff_sad.retro.5',\n       'diff_fear.retro.5', 'diff_happy.retro.5', 'mood_sad5_tm1',\n       'mood_neg5_tm1', 'mood_fearful5_tm1', 'mood_happy5_tm1'],\n      dtype='object')\n\n\nPer questo esercizio, ci concentriamo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf = df[[\"esm_id\", \"group\", \"bdi\"]]\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n1\n10\nmdd\n25.0\n\n\n2\n10\nmdd\n25.0\n\n\n3\n10\nmdd\n25.0\n\n\n4\n10\nmdd\n25.0\n\n\n\n\n\n\n\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf = df.drop_duplicates(keep=\"first\")\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndf.shape\n\n(67, 3)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n14\n9\nmdd\n30.0\n\n\n29\n6\nmdd\n26.0\n\n\n45\n7\nmdd\n35.0\n\n\n64\n12\nmdd\n44.0\n\n\n\n\n\n\n\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il ‚Äúnome‚Äù delle righe (ovvero, l‚Äôindice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga √® 15. Questo non ha nessuna conseguenza perch√© non useremo l‚Äôindice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf = df[pd.notnull(df[\"bdi\"])]\n\nOtteniamo cos√¨ il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndf.shape\n\n(66, 3)\n\n\nStampiamo i valori BDI-II presentandoli ordinati dal pi√π piccolo al pi√π grande:\n\nprint(df[\"bdi\"].sort_values())\n\n682     0.0\n455     0.0\n465     0.0\n485     0.0\n540     0.0\n       ... \n190    39.0\n810    41.0\n150    43.0\n135    43.0\n64     44.0\nName: bdi, Length: 66, dtype: float64\n\n\n√à chiaro dall‚Äôelenco precedente che i dati grezzi non sono molto informativi. Nella sezione successiva vedremo come creare una rappresentazione sintetica e comprensibile di questi dati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#distribuzioni-di-frequenze",
    "href": "chapters/chapter_2/03_freq_distr.html#distribuzioni-di-frequenze",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.3 Distribuzioni di frequenze",
    "text": "13.3 Distribuzioni di frequenze\nUna distribuzione di frequenze rappresenta il conteggio delle volte in cui i valori di una variabile si verificano all‚Äôinterno di un intervallo. Per i nostri dati BDI-II, categorizziamo i punteggi in quattro classi:\n\n0‚Äì13: depressione minima\n14‚Äì19: depressione lieve-moderata\n20‚Äì28: depressione moderata-severa\n29‚Äì63: depressione severa\n\nOgni classe \\(\\Delta_i\\) rappresenta un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\), con limiti inferiori e superiori \\(a_i\\) e \\(b_i\\), vengono associati un‚Äôampiezza \\(b_i - a_i\\) (che non √® necessariamente uguale per ogni classe) e un valore centrale \\(\\bar{x}_i\\). Poich√© ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), √® possibile calcolare le seguenti quantit√†.\n\nLa frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\n\nPropriet√†: \\(n_1 + n_2 + \\dots + n_m = n\\).\n\nLa frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.\n\nPropriet√†: \\(f_1+f_2+\\dots+f_m =1\\).\n\nLa frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\)\nLa frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\)\n\n\n13.3.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, √® necessario prima aggiungere al DataFrame df una colonna che contenga una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravit√† della depressione. Questo risultato si ottiene con il metodo pandas.cut().\nIn pandas.cut(), il primo argomento x √® un array unidimensionale (lista python, numpy.ndarray o pandas.Series) che contiene i dati e il secondo argomento bins specifica gli intervalli delle classi. La funzione restituisce un array che specifica la classe di appartenenza di ogni elemento dell‚Äôarray x. L‚Äôargomento include_lowest=True specifica classi chiuse a destra (nel nostro caso √® irrilevante dato che nessuna osservazione coincide con il limite di una classe).\n\n13.3.1.1 Frequenze assolute\n\ndf[\"bdi_class\"] = pd.cut(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], include_lowest=True)\ndf[\"bdi_class\"].value_counts()\n\nbdi_class\n(-0.001, 13.5]    36\n(28.5, 63.0]      17\n(19.5, 28.5]      12\n(13.5, 19.5]       1\nName: count, dtype: int64\n\n\n\n\n13.3.1.2 Frequenze relative\n\nabs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=[\"Abs. freq.\"])\nrel_freq = abs_freq / abs_freq.sum()\nrel_freq = rel_freq.round(2)\nrel_freq\n\n\n\n\n\n\n\n\ncol_0\nAbs. freq.\n\n\nbdi_class\n\n\n\n\n\n(-0.001, 13.5]\n0.55\n\n\n(13.5, 19.5]\n0.02\n\n\n(19.5, 28.5]\n0.18\n\n\n(28.5, 63.0]\n0.26\n\n\n\n\n\n\n\n\nControlliamo\n\nrel_freq.sum()\n\ncol_0\nAbs. freq.    1.01\ndtype: float64\n\n\n\ngrp_freq = pd.crosstab(index=df[\"group\"], columns=[\"Abs. freq.\"], colnames=[\"\"])\ngrp_freq\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nctl\n36\n\n\nmdd\n30\n\n\n\n\n\n\n\n\nVolendo modificare tale ordine √® possibile accedere al DataFrame tramite loc e specificando come secondo argomento una lista dei valori nell‚Äôordine desiderato:\n\ngrp_freq.loc[[\"mdd\", \"ctl\"], :]\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nmdd\n30\n\n\nctl\n36\n\n\n\n\n\n\n\n\nIn Python, il simbolo : utilizzato all‚Äôinterno delle parentesi quadre permette di ottenere uno slicing corrispondente all‚Äôintera lista.\n\n\n\n13.3.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l‚Äôinsieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l‚Äôinsieme di variabili \\(V\\) √® composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali pu√≤ assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell‚Äôesempio precedente, la funzione pd.crosstab pu√≤ essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti index e columns.\n\nbdi_group_abs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"])\nbdi_group_abs_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n36\n0\n\n\n(13.5, 19.5]\n0\n1\n\n\n(19.5, 28.5]\n0\n12\n\n\n(28.5, 63.0]\n0\n17\n\n\n\n\n\n\n\n\nOppure:\n\nbdi_group_rel_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"], normalize=True)\nbdi_group_rel_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n0.545455\n0.000000\n\n\n(13.5, 19.5]\n0.000000\n0.015152\n\n\n(19.5, 28.5]\n0.000000\n0.181818\n\n\n(28.5, 63.0]\n0.000000\n0.257576\n\n\n\n\n\n\n\n\nInvocando il metodo plot.bar sulla tabella, otteniamo un grafico a barre nel quale le barre relative a uno stesso valore bdi_class risultino affiancate. Nel caso presente, le due distribuzioni sono completamente separate, quindi non abbiamo mai due barre affiancate:\n\nbdi_group_rel_freq.plot.bar();",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#istogramma",
    "href": "chapters/chapter_2/03_freq_distr.html#istogramma",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.4 Istogramma",
    "text": "13.4 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densit√† della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densit√† della frequenza relativa √® misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) √® la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l‚Äôampiezza della classe. In questo modo, l‚Äôarea del rettangolo associato alla classe \\(\\Delta_i\\) sull‚Äôistogramma sar√† proporzionale alla frequenza relativa \\(f_i\\). √à importante notare che l‚Äôarea totale dell‚Äôistogramma delle frequenze relative √® uguale a 1.0, poich√© rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di {cite:t}zetsche_2019future. Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell‚Äôistogramma ‚Äì si notino le frequenze assolute sull‚Äôasse delle ordinate.\n\nplt.hist(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], density=True)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()\n\n\n\n\n\n\n\n\nAnche se nel caso presente √® sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un‚Äôampiezza uguale.\n\nplt.hist(df[\"bdi\"], density=True)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#kernel-density-plot",
    "href": "chapters/chapter_2/03_freq_distr.html#kernel-density-plot",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.5 Kernel density plot",
    "text": "13.5 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell‚Äôistogramma: la sua forma dipende dall‚Äôarbitrariet√† con cui vengono scelti il numero e l‚Äôampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficolt√†, possiamo utilizzare una tecnica alternativa chiamata stima della densit√† kernel (KDE). Mentre l‚Äôistogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione pi√π continua e meno dipendente dall‚Äôarbitrariet√† delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo √® ci√≤ che fa la KDE: smussa il profilo dell‚Äôistogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un‚Äôaltezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densit√† dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L‚Äôarea sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell‚Äôintervallo. Per esempio, se un intervallo ha un‚Äôarea maggiore sotto la curva rispetto ad altri, significa che in quell‚Äôintervallo c‚Äô√® una maggiore concentrazione di dati.\nLa curva di densit√† ottenuta tramite KDE fornisce dunque un‚Äôidea chiara di come i dati sono distribuiti senza dipendere dall‚Äôarbitrariet√† della scelta delle classi dell‚Äôistogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da {cite:t}zetsche_2019future.\n\nsns.kdeplot(data=df, x=\"bdi\", hue=\"group\", common_norm=False)\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI-II Scores\")\nplt.show()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#forma-di-una-distribuzione",
    "href": "chapters/chapter_2/03_freq_distr.html#forma-di-una-distribuzione",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.6 Forma di una distribuzione",
    "text": "13.6 Forma di una distribuzione\nIn generale, la forma di una distribuzione descrive come i dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un‚Äôillustrazione grafica √® fornita nella figura seguente. Nel pannello 1 la distribuzione √® unimodale con asimmetria negativa; nel pannello 2 la distribuzione √® unimodale con asimmetria positiva; nel pannello 3 la distribuzione √® simmetrica e unimodale; nel pannello 4 la distribuzione √® bimodale.\ndigaohn ../images/shape_distribution.png :alt: shape :class: bg-primary mb-1 :width: 420px :align: center\n\nIl kernel density plot dei valori BDI-II nel campione di {cite:t}zetsche_2019future √® bimodale. Ci√≤ indica che le osservazioni della distribuzione si addensano in due cluster ben distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l‚Äôaltro gruppo tende ad avere BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da {cite:t}zetsche_2019future.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#indici-di-posizione",
    "href": "chapters/chapter_2/03_freq_distr.html#indici-di-posizione",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.7 Indici di posizione",
    "text": "13.7 Indici di posizione\n\n13.7.1 Quantili\nLa distribuzione dei valori BDI-II di {cite:t}zetsche_2019future pu√≤ essere sintetizzata attraverso l‚Äôuso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) √® la dimensione del campione e \\(p\\) √® l‚Äôordine del quantile. Se \\(np\\) non √® un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) √® un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) √® la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che √® molto popolare e pu√≤ essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al.¬†(2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non √® un intero. Pertanto, il valore del secondo quartile √® pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che √® un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo numpy per trovare la soluzione dell‚Äôesercizio precedente.\n\nx = [19, 26, 27, 28, 28, 33, 33, 41, 43]\nnp.quantile(x, 2 / 3)\n\n33.0",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#mostrare-i-dati",
    "href": "chapters/chapter_2/03_freq_distr.html#mostrare-i-dati",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.8 Mostrare i dati",
    "text": "13.8 Mostrare i dati\n\n13.8.1 Diagramma a scatola\nIl box plot √® uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la ‚Äúscatola‚Äù) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) √® rappresentata da una linea all‚Äôinterno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti ‚Äúbaffi‚Äù, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore √® il valore pi√π basso tra le osservazioni che √® maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore √® il valore pi√π alto tra le osservazioni che √® minore o uguale al terzo quartile pi√π 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati ‚Äúvalori anomali‚Äù e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\ndigaohn ../images/boxplot.png :alt: fishy :class: bg-primary mb-1 :width: 640px :align: center\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nsns.boxplot(x=\"group\", y=\"bdi\", data=df)\nplt.xlabel(\"Group\")\nplt.ylabel(\"BDI-II\")\nplt.title(\"Boxplot of BDI-II Scores by Group\")\nplt.show()\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene usando un violin plot e mostrando anche i dati grezzi.\n\n\n13.8.2 Grafico a violino\nI violin plot combinano box plot e KDE plot per una rappresentazione pi√π dettagliata. Al grafico sono sovrapposti i dati grezzi.\n\nsns.violinplot(x=\"group\", y=\"bdi\", data=df, color=\"lightgray\")\nsns.stripplot(x=\"group\", y=\"bdi\", data=df, color=\"black\", size=5, jitter=True, alpha=0.3)\nplt.ylabel(\"BDI-II\")\nplt.xlabel(\"Group\")\nplt.title(\"Violin Plot with Overlay of Individual Data Points of BDI-II Scores by Group\")\nplt.show()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_2/03_freq_distr.html#commenti-e-considerazioni-finali",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.9 Commenti e considerazioni finali",
    "text": "13.9 Commenti e considerazioni finali\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densit√†. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/03_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/03_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "13¬† Distribuzioni di Frequenze",
    "section": "13.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "13.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jul 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\npandas    : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Distribuzioni di Frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html",
    "href": "chapters/chapter_2/04_loc_scale.html",
    "title": "14¬† Indici di posizione e di scala",
    "section": "",
    "text": "14.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, √® possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l‚Äôasimmetria, nonch√© la presenza di una o pi√π mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l‚Äôutilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/chapter_2/04_loc_scale.html#indici-di-tendenza-centrale",
    "title": "14¬† Indici di posizione e di scala",
    "section": "14.2 Indici di tendenza centrale",
    "text": "14.2 Indici di tendenza centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all‚Äôinterno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l‚Äôintero insieme. Gli indici di tendenza centrale sono fondamentali nell‚Äôanalisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media √® la somma di tutti i valori divisa per il numero totale di valori. √à spesso utilizzata come misura generale di tendenza centrale, ma √® sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana √® il valore che divide l‚Äôinsieme di dati in due parti uguali. A differenza della media, non √® influenzata da valori estremi ed √® quindi pi√π robusta in presenza di outlier.\nModa: La moda √® il valore che appare pi√π frequentemente in un insieme di dati. In alcuni casi, pu√≤ non essere presente o esserci pi√π di una moda.\n\nLa scelta dell‚Äôindice di tendenza centrale appropriato dipende dalla natura dei dati e dall‚Äôobiettivo dell‚Äôanalisi. Ad esempio, la mediana potrebbe essere preferita alla media se l‚Äôinsieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l‚Äôapplicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n14.2.1 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. √à calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed √® espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{14.1}\\]\ndove \\(x_i\\) rappresenta i valori nell‚Äôinsieme, \\(n\\) √® il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n14.2.1.1 Propriet√† della media\nUna propriet√† fondamentale della media √® che la somma degli scarti di ciascun valore dalla media √® zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{14.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta propriet√† implica che i dati sono equamente distribuiti intorno alla media.\n\n\n14.2.1.2 La media come centro di gravit√† dell‚Äôistogramma\nLa media aritmetica pu√≤ essere interpretata come il centro di gravit√† o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravit√† √® il punto in cui la massa di un sistema √® equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati √® in equilibrio. Ogni valore dell‚Äôinsieme di dati pu√≤ essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori pi√π grandi a destra e pi√π piccoli a sinistra, la media corrisponder√† esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n14.2.1.3 Principio dei minimi quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come ‚Äúmetodo dei minimi quadrati‚Äù. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media √® minima. Questo principio √® alla base dell‚Äôanalisi statistica dei modelli di regressione e conferma l‚Äôinterpretazione della media come centro di gravit√† dell‚Äôistogramma.\n\n\n14.2.1.4 Calcolo della media con NumPy\nPer calcolare la media di un piccolo numero di valori in Python, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n\n32.6\n\n\novvero\n\nx = np.array([12, 44, 21, 62, 24])\nnp.mean(x)\n\n32.6\n\n\n\nnp.average(x)\n\n32.6\n\n\n\n\n14.2.1.5 Le proporzioni sono medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione √® il numero di uni in essa, e la media della collezione √® la proporzione di uni.\n\nzero_one = np.array([1, 1, 1, 0])\nresult = sum(zero_one)\nprint(result) \n\n3\n\n\n\nnp.mean(zero_one)\n\n0.75\n\n\n√à possibile sostituire 1 con il valore booleano True e 0 con False:\n\nnp.mean(np.array([(True, True, True, False)]))\n\n0.75\n\n\n\n\n14.2.1.6 Limiti della media aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre √® l‚Äôindice pi√π adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, √® pi√π indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n14.2.1.7 Medie per gruppi\nMolto spesso per√≤ i nostri dati sono contenuti in file e inserire i dati manualmente non √® fattibile. Per fare un esempio, considereremo i dati del Progetto STAR, contenuti nel file STAR.csv, che rappresentano un‚Äôimportante indagine sulle prestazioni degli studenti in relazione alla dimensione delle classi. Negli anni ‚Äô80, i legislatori del Tennessee considerarono la possibilit√† di ridurre le dimensioni delle classi per migliorare il rendimento degli studenti. Al fine di prendere decisioni informate, commissionarono lo studio multimilionario ‚ÄúProgetto Student-Teacher Achievement Ratio‚Äù (Project STAR). Lo studio coinvolgeva bambini della scuola materna assegnati casualmente a classi piccole, con 13-17 studenti, o classi di dimensioni regolari, con 22-25 studenti, fino alla fine della terza elementare. I ricercatori hanno seguito il progresso degli studenti nel tempo, concentrandosi su variabili di risultato, come i punteggi dei test standardizzati di lettura (reading) e matematica (math) alla terza elementare, oltre ai tassi di diploma di scuola superiore (graduated, con valore 1 per s√¨ e 0 per no).\nPoniamoci il problema di calcolare la media dei punteggi math calcolata separatamente per i due gruppi di studenti: coloro che hanno completato la scuola superiore e coloro che non l‚Äôhanno completata.\nProcediamo all‚Äôimportazione dei dati per iniziare l‚Äôanalisi.\n\ndf = pd.read_csv(\"../../data/STAR.csv\")\ndf.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nEsaminiamo la numerosit√† di ciascun gruppo.\n\ndf.groupby(\"graduated\").size()\n\ngraduated\n0     166\n1    1108\ndtype: int64\n\n\nOra procediamo al calcolo delle medie dei punteggi math all‚Äôinterno dei due gruppi. Per rendere la risposta pi√π concisa, useremo la funzione round() per stampare solo 2 valori decimali.\n\ndf.groupby(\"graduated\")[\"math\"].mean().round(2)\n\ngraduated\n0    606.64\n1    635.33\nName: math, dtype: float64\n\n\nIn alternativa, possiamo usare il metodo .describe():\n\ndf.groupby(\"graduated\")[\"math\"].describe().round(1)\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\ngraduated\n\n\n\n\n\n\n\n\n\n\n\n\n0\n166.0\n606.6\n34.1\n526.0\n580.5\n606.0\n629.0\n711.0\n\n\n1\n1108.0\n635.3\n38.1\n515.0\n609.5\n634.0\n659.0\n774.0\n\n\n\n\n\n\n\n\n\n\n\n14.2.2 Media spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, √® un metodo di calcolo della media che prevede l‚Äôeliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all‚Äôinizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l‚Äôultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata √® calcolata come la media aritmetica dei dati rimanenti. Questo approccio √® utile quando ci sono valori anomali o quando la distribuzione √® asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\nA titolo di esempio, procediamo al calcolo della media spuntata dei valori math per i due gruppi definiti dalla variabile graduated, escludendo il 10% dei valori pi√π estremi.\n\nnot_graduated = df[df[\"graduated\"] == 0].math\nstats.trim_mean(not_graduated, 0.10)\n\n605.6492537313433\n\n\n\ngraduated = df[df[\"graduated\"] == 1].math\nstats.trim_mean(graduated, 0.10)\n\n634.4403153153153\n\n\n\n\n14.2.3 Quantili\nIl quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\) rappresenta il valore che divide la distribuzione dei dati in modo tale che una frazione \\(p\\) dei dati si trovi al di sotto di esso.\nLa formula per calcolare il quantile non interpolato √® la seguente:\n\\[\n    q_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) √® l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme di dati ordinato in modo crescente, e \\(k\\) √® calcolato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) √® il numero totale di dati nel campione, e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all‚Äôintero successivo. In questa definizione, il quantile non interpolato corrisponde al valore effettivo nell‚Äôinsieme di dati, senza effettuare alcuna interpolazione tra i valori circostanti.\nAd esempio, consideriamo il seguente insieme di dati: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}\\). Supponiamo di voler calcolare il quantile non interpolato di ordine \\(p = 0.3\\) (cio√® il 30¬∞ percentile).\nOrdiniamo i dati in modo crescente: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\\) Calcoliamo \\(k\\) utilizzando la formula \\(k = \\lceil p \\cdot n \\rceil\\), dove \\(n\\) √® il numero totale di dati nel campione. Nel nostro caso, \\(n = 10\\) e \\(p = 0.3\\):\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\nIl quantile non interpolato corrisponde al valore \\(x_{(k)}\\), ovvero l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme ordinato: \\(q_{0.3} = x_{(3)} = 23.\\)\nOltre al quantile non interpolato, esiste anche il concetto di quantile interpolato. A differenza del quantile non interpolato, il quantile interpolato pu√≤ essere calcolato anche per percentili che non corrispondono esattamente a valori presenti nell‚Äôinsieme di dati. Per ottenere il valore del quantile interpolato, viene utilizzato un procedimento di interpolazione lineare tra i valori adiacenti. In genere, il calcolo del quantile interpolato viene eseguito mediante l‚Äôuso di software dedicati.\nOra, procediamo al calcolo dei quantili di ordine 0.10 e 0.90 per i valori math all‚Äôinterno dei due gruppi. I quantili sono dei valori che dividono la distribuzione dei dati in parti specifiche. Ad esempio, il quantile di ordine 0.10 corrisponde al valore al di sotto del quale si trova il 10% dei dati, mentre il quantile di ordine 0.90 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\nCalcoliamo i quantili di ordine 0.1 e 0.9 della distribuzione dei punteggi math nei due gruppi definiti dalla variabile graduated.\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.1), \n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.9)\n]\n\n[588.0, 684.0]\n\n\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che non hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.1),\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.9),\n]\n\n[564.5, 651.0]\n\n\n\n\n14.2.4 Moda e mediana\nIn precedenza abbiamo gi√† incontrato altri due popolari indici di tendenza centrale: la moda (Mo), che rappresenta il valore centrale della classe con la frequenza massima (in alcune distribuzioni pu√≤ esserci pi√π di una moda, rendendola multimodale e facendo perdere a questo indice il suo significato di indicatore di tendenza centrale); e la mediana (\\(\\tilde{x}\\)), che rappresenta il valore corrispondente al quantile di ordine 0.5 della distribuzione.\n\n\n14.2.5 Quando usare media, moda, mediana\nLa moda pu√≤ essere utilizzata per dati a livello nominale o ordinale ed √® l‚Äôunica tra le tre statistiche che pu√≤ essere calcolata in questi casi.\nLa media, d‚Äôaltra parte, √® una buona misura di tendenza centrale solo se la distribuzione dei dati √® simmetrica, ossia se i valori sono distribuiti uniformemente a sinistra e a destra della media. Tuttavia, se ci sono valori anomali o se la distribuzione √® asimmetrica, la media pu√≤ essere influenzata in modo significativo e, pertanto, potrebbe non essere la scelta migliore come misura di tendenza centrale.\nIn queste situazioni, la mediana pu√≤ fornire una misura migliore di tendenza centrale rispetto alla media poich√© √® meno influenzata dai valori anomali e si basa esclusivamente sul valore centrale dell‚Äôinsieme di dati. Di conseguenza, la scelta tra media e mediana dipende dal tipo di distribuzione dei dati e dagli obiettivi dell‚Äôanalisi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#indici-di-dispersione",
    "href": "chapters/chapter_2/04_loc_scale.html#indici-di-dispersione",
    "title": "14¬† Indici di posizione e di scala",
    "section": "14.3 Indici di dispersione",
    "text": "14.3 Indici di dispersione\nLe misure di posizione descritte in precedenza, come le medie e gli indici di posizione, offrono una sintesi dei dati mettendo in evidenza la tendenza centrale delle osservazioni. Tuttavia, trascurano un aspetto importante della distribuzione dei dati: la variabilit√† dei valori numerici della variabile statistica. Pertanto, √® essenziale completare la descrizione della distribuzione di una variabile statistica utilizzando anche indicatori che valutino la dispersione delle unit√† statistiche. In questo modo, otterremo una visione pi√π completa e approfondita delle caratteristiche del campione analizzato.\n\n14.3.1 Indici basati sull‚Äôordinamento dei dati\nPer valutare la variabilit√† dei dati, √® possibile utilizzare indici basati sull‚Äôordinamento dei dati. L‚Äôindice pi√π semplice √® l‚Äôintervallo di variazione, che corrisponde alla differenza tra il valore massimo e il valore minimo di una distribuzione di dati. Tuttavia, questo indice ha il limite di essere calcolato basandosi solo su due valori della distribuzione, e non tiene conto di tutte le informazioni disponibili. Inoltre, l‚Äôintervallo di variazione pu√≤ essere fortemente influenzato dalla presenza di valori anomali.\nUn altro indice basato sull‚Äôordinamento dei dati √® la differenza interquartile, gi√† incontrata in precedenza. Anche se questo indice utilizza pi√π informazioni rispetto all‚Äôintervallo di variazione, presenta comunque il limite di essere calcolato basandosi solo su due valori della distribuzione, ossia il primo quartile \\(Q_1\\) e il terzo quartile \\(Q_3\\).\nPer valutare la variabilit√† in modo pi√π completo, √® necessario utilizzare altri indici di variabilit√† che tengano conto di tutti i dati disponibili. In questo modo, si otterr√† una valutazione pi√π accurata della dispersione dei valori nella distribuzione e si potranno individuare eventuali pattern o tendenze nascoste.\n\n\n14.3.2 Varianza\nDate le limitazioni delle statistiche descritte in precedenza, √® pi√π comune utilizzare una misura di variabilit√† che tenga conto della dispersione dei dati rispetto a un indice di tendenza centrale. La varianza √® la misura di variabilit√† pi√π utilizzata per valutare la variabilit√† di una variabile statistica. Essa √® definita come la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione, come segue:\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\end{equation}\n\\tag{14.3}\\]\nLa varianza √® una misura di dispersione pi√π completa rispetto a quelle descritte in precedenza. Tuttavia, √® appropriata solo nel caso di distribuzioni simmetriche ed √® fortemente influenzata dai valori anomali, come altre misure di dispersione. Inoltre, la varianza √® espressa in un‚Äôunit√† di misura che √® il quadrato dell‚Äôunit√† di misura dei dati originali, pertanto, potrebbe non essere facilmente interpretata in modo intuitivo.\nCalcoliamo la varianza dei valori math per i dati del progetto STAR. Applicando l‚Äôequazione della varianza, otteniamo:\n\nsum((df[\"math\"] - np.mean(df[\"math\"])) ** 2) / len(df[\"math\"])\n\n1507.2328523125227\n\n\nPi√π semplicemente, possiamo usare la funzione np.var():\n\nnp.var(df[\"math\"])\n\n1507.2328523125227\n\n\n\n14.3.2.1 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell‚ÄôEquazione¬†14.3, ho utilizzato \\(n\\) come denominatore (l‚Äôampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, √® possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{14.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si pu√≤ dimostrare che l‚ÄôEquazione¬†14.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l‚ÄôEquazione¬†14.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione √® illustrata nella figura seguente.\n\nx = np.arange(100 - 4 * 15, 100 + 4 * 15, 0.001)\n\nmu = 100\nsigma = 15\n\npdf = stats.norm.pdf(x, mu, sigma)\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()\n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza ‚Äì in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nx = rng.normal(loc=100, scale=15, size=4)\nprint(x)\n\n[ 96.66036673 119.88488115  91.43544977 110.02373805]\n\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza √® \\(15^2\\) = 225.\n\nnp.var(x)\n\n134.65656223872708\n\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nIl primo campione √®\n\nrandom_samples[0]\n\narray([ 70.73447217,  80.4673074 , 101.91760605,  95.25636111])\n\n\nIl decimo campione √®\n\nrandom_samples[9]\n\narray([111.14881257, 108.14731402,  90.01735439, 103.48241985])\n\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs = np.array(random_samples)\nrs\n\narray([[117.18071524, 108.81016091,  99.22835071,  72.32428097],\n       [ 95.39169462,  99.82359162, 109.53158888, 101.69933684],\n       [121.28194403, 111.99123812,  93.5863066 , 123.02032138],\n       [ 66.58961856, 104.23622977,  83.17674426, 119.51304508],\n       [107.69111686,  84.07010216,  98.52662251, 105.83838496],\n       [ 70.66964863, 105.06034379, 107.1614251 ,  83.45087842],\n       [ 92.51928633, 113.73691601,  90.51622696, 107.85154079],\n       [105.74034675, 102.67262674,  88.66272413,  87.55578622],\n       [108.18945322, 119.3681818 , 107.45218178,  81.44893886],\n       [ 84.56836494,  94.18203683,  97.52873515, 100.41911991]])\n\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo cos√¨ 10 stime della varianza della popolazione del QI.\n\nx_var = np.var(rs, axis=1)  # applichiamo la funzione su ciascuna riga\nprint(x_var)\n\n[284.45704733  26.15452963 136.44568199 405.65618265  86.35524345\n 231.95644125  97.72682684  66.1097433  193.53695841  35.63101473]\n\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno √® noto con il nome di variabilit√† campionaria;\nin media le stime sembrano troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=0, axis=1)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\nplt.hist(x_var, bins=10, color=\"skyblue\", edgecolor=\"black\")\nplt.xlabel(\"Varianza\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Varianza del QI in campioni di n = 4\")\nplt.show()\n\n\n\n\n\n\n\n\nLa stima pi√π verosimile della varianza del QI √® dato dalla media di questa distribuzione.\n\nnp.mean(x_var)\n\n170.04960311858687\n\n\nSi noti che il nostro spospetto √® stato confermato: il valore medio della stima della varianza ottenuta con l‚ÄôEquazione¬†14.3 √® troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=1, axis=1)\n\nnp.mean(x_var)\n\n222.53361717582456\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima √® molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilit√† di un particolare campione di osservazioni. D‚Äôaltro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione √® stato estratto.\n\n\n\n14.3.3 Deviazione standard\nPer interpretare la varianza in modo pi√π intuitivo, si pu√≤ calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard √® espressa nell‚Äôunit√† di misura originaria dei dati, a differenza della varianza che √® espressa nel quadrato dell‚Äôunit√† di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo pi√π facile la comprensione della variabilit√† dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) √® definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{14.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation √® stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano ‚Äúdeviazione standard‚Äù ne √® la traduzione pi√π utilizzata nel linguaggio comune; il termine dell‚ÄôEnte Nazionale Italiano di Unificazione √® tuttavia ‚Äúscarto tipo‚Äù, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media √® una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, √® importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard pu√≤ risultare ingannevole e non rappresentare accuratamente la variabilit√† complessiva della distribuzione. Pertanto, √® fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere pi√π appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilit√† dei dati in modo pi√π accurato e affidabile.\nPer fare un esempio, calcoliamo la deviazione standard per i valori math del campione di dati del progetto STAR. Applicando l‚ÄôEquazione¬†14.5, per tutto il campione abbiamo\n\nnp.std(df.math)\n\n38.82309689234648\n\n\nPer ciascun gruppo, abbiamo:\n\ndf.groupby(\"graduated\")[\"math\"].std()\n\ngraduated\n0    34.105746\n1    38.130136\nName: math, dtype: float64\n\n\n\n14.3.3.1 Interpretazione\nLa deviazione standard pu√≤ essere interpretata in modo semplice: essa rappresenta la dispersione dei dati rispetto alla media aritmetica. √à simile allo scarto semplice medio campionario, cio√® alla media aritmetica dei valori assoluti degli scarti tra ciascuna osservazione e la media, anche se non √® identica. La deviazione standard ci fornisce un‚Äôindicazione di quanto, in media, le singole osservazioni si discostino dal centro della distribuzione.\nPer verificare l‚Äôinterpretazione della deviazione standard, utilizziamo i valori math del campione di dati del progetto STAR.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nLa deviazione standard calcolata per questi dati √® \\(\\approx 38.8\\). Questo valore ci indica che, in media, ogni osservazione si discosta di circa 38.8 punti dalla media aritmetica dei punteggi math. Maggiore √® il valore della deviazione standard, maggiore √® la dispersione dei dati attorno alla media, mentre un valore pi√π piccolo indica che i dati sono pi√π concentrati vicino alla media. La deviazione standard ci offre quindi una misura quantitativa della variabilit√† dei dati nella distribuzione.\nPer questi dati, lo scarto semplice medio campionario √®\n\nnp.mean(np.abs(df.math - np.mean(df.math)))\n\n30.9682664274501\n\n\nSi noti che i due valori sono simili, ma non identici.\n\n\n\n14.3.4 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione √® la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana. Matematicamente, la formula per calcolare la MAD √®:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{14.6}\\]\nLa deviazione mediana assoluta √® particolarmente utile quando si affrontano distribuzioni con presenza di dati anomali o asimmetrie, poich√© √® meno influenzata da questi valori estremi rispetto alla deviazione standard.\nQuando i dati seguono una distribuzione gaussiana (normale), esiste una relazione specifica tra MAD e la deviazione standard (si veda il Capitolo {ref}cont-rv-distr-notebook). In una distribuzione normale, la MAD √® proporzionale alla deviazione standard. La costante di proporzionalit√† dipende dalla forma esatta della distribuzione normale, ma in generale, la relazione √® data da:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove: - $ $ √® la deviazione standard. - MAD √® la Mediana della Deviazione Assoluta. - $ k $ √® una costante che, per una distribuzione normale, √® tipicamente presa come circa 1.4826.\nQuesta costante di 1.4826 √® derivata dal fatto che, in una distribuzione normale, circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media. Quindi, per convertire la MAD (basata sulla mediana) nella deviazione standard (basata sulla media), si usa il reciproco di 0.6745, che √® approssimativamente 1.4826.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale √®:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione √® utile per stimare la deviazione standard in modo pi√π robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un‚Äôindicazione pi√π intuitiva della variabilit√† dei dati. Tuttavia, √® importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilit√† dei dati.\nPer verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori math del campione di dati del progetto STAR.\n\n1.4826 * np.median(np.abs(df[\"math\"] - np.median(df[\"math\"])))\n\n41.5128\n\n\nIn questo caso, la MAD per i punteggi di matematica √® simile alla deviazione standard.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nInfatti, la distribuzione dei punteggi math √® approssimativamente gaussiana.\n\nplt.hist(df[\"math\"], bins=10, color=\"skyblue\", edgecolor = \"black\")\nplt.xlabel(\"math\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione dei Punteggi di Matematica\")\nplt.show()\n\n\n\n\n\n\n\n\nVerifichiamo nuovamente il principio usando un campione di dati estratto da una popolazione normale. Usiamo, ad esempio, la distribuzione \\(\\mathcal{N}(100, 15)\\):\n\nx = np.random.normal(loc=100, scale=15, size=10000)\n1.4826 * np.median(np.abs(x - np.median(x)))\n\n15.179389799831695\n\n\n\n\n14.3.5 Quando usare la deviazione standard e MAD\nLa deviazione standard e la MAD sono entrambe misure di dispersione che forniscono informazioni su quanto i dati in un insieme si discostano dalla tendenza centrale. Tuttavia, ci sono alcune differenze tra le due misure e situazioni in cui pu√≤ essere pi√π appropriato utilizzare una rispetto all‚Äôaltra.\n\nDeviazione standard: Questa misura √® particolarmente utile per descrivere la dispersione dei dati in una distribuzione normale. La deviazione standard √® una scelta appropriata se si vuole sapere quanto i dati sono distribuiti intorno alla media, o se si vuole confrontare la dispersione di due o pi√π set di dati. Tuttavia, la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, e questo pu√≤ rappresentare una limitazione in casi in cui sono presenti valori estremi nell‚Äôinsieme di dati.\nDeviazione mediana assoluta (MAD): La MAD √® meno sensibile ai valori anomali rispetto alla deviazione standard, il che la rende una scelta migliore quando ci sono valori anomali nell‚Äôinsieme di dati. Inoltre, la MAD pu√≤ essere una buona scelta quando si lavora con dati non normalmente distribuiti, poich√© non assume una distribuzione specifica dei dati. La MAD √® calcolata utilizzando la mediana e i valori assoluti delle deviazioni dei dati dalla mediana, il che la rende una misura robusta di dispersione.\n\nIn sintesi, se si sta lavorando con dati normalmente distribuiti, la deviazione standard √® la misura di dispersione pi√π appropriata. Se si lavora con dati non normalmente distribuiti o si hanno valori anomali nell‚Äôinsieme di dati, la MAD pu√≤ essere una scelta migliore. In ogni caso, la scelta tra le due misure dipende dal tipo di dati che si sta analizzando e dall‚Äôobiettivo dell‚Äôanalisi.\n\n\n14.3.6 Indici di variabilit√† relativi\nA volte pu√≤ essere necessario confrontare la variabilit√† di grandezze incommensurabili, ovvero di caratteri misurati con differenti unit√† di misura. In queste situazioni, le misure di variabilit√† descritte in precedenza diventano inadeguate poich√© dipendono dall‚Äôunit√† di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilit√†.\nIl pi√π importante di questi indici √® il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{14.7}\\]\nIl coefficiente di variazione √® un numero puro e permette di confrontare la variabilit√† di distribuzioni con unit√† di misura diverse.\nUn altro indice relativo di variabilit√† √® la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice √® definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilit√† forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unit√† di misura e facilitando l‚Äôanalisi delle differenze di variabilit√† tra i dati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/chapter_2/04_loc_scale.html#la-fallacia-ergodica",
    "title": "14¬† Indici di posizione e di scala",
    "section": "14.4 La fallacia ergodica",
    "text": "14.4 La fallacia ergodica\nSebbene il concetto di ‚Äúmedia‚Äù possa sembrare chiaro, ci√≤ non implica che il suo utilizzo non presenti delle problematiche nell‚Äôambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi √® ci√≤ che viene definito ‚Äúfallacia ergodica‚Äù.\nIl concetto di ‚Äúfallacia ergodica‚Äù (Speelman et al. 2024) si riferisce all‚Äôerrore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all‚Äôinterno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio √® che l‚Äôuso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo √® ingiustificato, poich√© le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull‚Äôassunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere cos√¨ simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all‚Äôinterno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di pi√π individui non descrivono accuratamente nessuno di quegli individui in un dato momento, n√© possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell‚Äôassumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_2/04_loc_scale.html#commenti-e-considerazioni-finali",
    "title": "14¬† Indici di posizione e di scala",
    "section": "14.5 Commenti e considerazioni finali",
    "text": "14.5 Commenti e considerazioni finali\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un‚Äôidea della variabilit√† dei dati. In sintesi, le statistiche descrittive ci offrono un quadro chiaro e sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilit√†.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/04_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/04_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "14¬† Indici di posizione e di scala",
    "section": "14.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "14.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Feb 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.2\npandas    : 2.2.0\narviz     : 0.17.0\nnumpy     : 1.26.4\nscipy     : 1.12.0\nseaborn   : 0.13.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, e Marek McGann. 2024. ¬´Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals¬ª. Collabra: Psychology 10 (1).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html",
    "href": "chapters/chapter_2/05_correlation.html",
    "title": "15¬† Le relazioni tra variabili",
    "section": "",
    "text": "15.1 Introduzione\nNel linguaggio comune, termini quali ‚Äúdipendenza‚Äù, ‚Äúassociazione‚Äù e ‚Äúcorrelazione‚Äù sono spesso utilizzati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, ‚Äúassociazione‚Äù e ‚Äúdipendenza‚Äù sono sinonimi e entrambi si distinguono dalla ‚Äúcorrelazione‚Äù. L‚Äôassociazione implica una relazione molto ampia: conoscere il valore di una variabile ci fornisce informazioni su un‚Äôaltra variabile. Al contrario, la correlazione descrive una relazione pi√π specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico; ad esempio, in una tendenza crescente, se $ X &gt; _X $ allora √® probabile che anche $ Y &gt; _Y $.\n√à cruciale comprendere che non tutte le associazioni sono correlazioni e che, crucialmente, la correlazione non implica causalit√†. Questa distinzione √® vitale per interpretare accuratamente i dati e per evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, ci concentreremo su due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi strumenti sono essenziali per analizzare il grado e la direzione dell‚Äôassociazione lineare tra le variabili, permettendoci di quantificare in che modo le variabili variano congiuntamente.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#i-dati-grezzi",
    "href": "chapters/chapter_2/05_correlation.html#i-dati-grezzi",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.2 I dati grezzi",
    "text": "15.2 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione √® stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II √® uno strumento di autovalutazione utilizzato per valutare la gravit√† della depressione in adulti e adolescenti. Il test √® stato sviluppato per identificare e misurare l‚Äôintensit√† dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado pi√π basso e 3 il grado pi√π elevato di sintomatologia depressiva.\nNell‚Äôesercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche, Buerkner, e Renneberg (2019).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/chapter_2/05_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.3 Definizione delle relazioni tra variabili",
    "text": "15.3 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o pi√π variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ci√≤, prendiamo ad esempio l‚Äôaltezza e l‚Äôet√† tra un gruppo di bambini. In generale, √® possibile notare che all‚Äôaumentare dell‚Äôet√† di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l‚Äôet√† di un bambino, ad esempio tredici anni, e l‚Äôet√† di un altro, sei anni, ci fornisce un‚Äôindicazione su quale dei due bambini sia pi√π alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e et√† come positiva, il che significa che all‚Äôaumentare dei valori di una delle variabili (in questo caso, l‚Äôet√†), ci aspettiamo di vedere valori pi√π elevati anche nell‚Äôaltra variabile (l‚Äôaltezza). Tuttavia, esistono anche relazioni negative, in cui l‚Äôaumento di una variabile √® associato a un diminuzione dell‚Äôaltra (ad esempio, pi√π et√† √® correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo cos√¨ una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili pu√≤ essere categorica, rendendo difficile parlare di ‚Äúmaggioranza‚Äù o ‚Äúminoranza‚Äù ma piuttosto di ‚Äúdifferente‚Äù (ad esempio, i bambini pi√π grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini pi√π piccoli, senza necessariamente essere ‚Äúmigliori‚Äù o ‚Äúpeggiori‚Äù).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#sec-scatter-plot",
    "href": "chapters/chapter_2/05_correlation.html#sec-scatter-plot",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.4 Grafico a dispersione",
    "text": "15.4 Grafico a dispersione\nIl metodo pi√π diretto per visualizzare la relazione tra due variabili continue √® tramite un grafico a dispersione, comunemente noto come ‚Äúscatterplot‚Äù. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull‚Äôasse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l‚Äôidea pi√π chiara, consideriamo i dati dello studio condotto da Zetsche, Buerkner, e Renneberg (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II √® uno strumento di autovalutazione che valuta la presenza e l‚Äôintensit√† dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D √® una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poich√© entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf = pd.read_csv(\"../../data/data.mood.csv\", index_col=0)\n\n# Seleziona le colonne di interesse\ndf = df[[\"esm_id\", \"group\", \"bdi\", \"cesd_sum\"]]\n\n# Rimuovi le righe duplicate\ndf = df.drop_duplicates(keep=\"first\")\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf = df.dropna(subset=[\"bdi\"])\n\nPosizionando i valori del BDI-II sull‚Äôasse delle ascisse e quelli del CES-D sull‚Äôasse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. √à evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l‚Äôutilizzo di unit√† di misura arbitrarie per le due variabili. L‚Äôerrore di misurazione √® una componente inevitabile che influisce in parte su qualsiasi misurazione, ed √® particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione √® generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici √® che l‚Äôunit√† di misura della depressione √® una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all‚Äôuso di unit√† di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di ‚Äúassociazione lineare‚Äù, √® possibile esaminare i dati attraverso l‚Äôutilizzo di un diagramma a dispersione.\n\n# Crea uno scatterplot con colori diversi per i due gruppi\nplt.scatter(df[df[\"group\"] == \"mdd\"][\"bdi\"], df[df[\"group\"] == \"mdd\"][\"cesd_sum\"], label=\"Pazienti\", c=\"C0\")\nplt.scatter(df[df[\"group\"] == \"ctl\"][\"bdi\"], df[df[\"group\"] == \"ctl\"][\"cesd_sum\"], label=\"Controlli\", c=\"C2\")\n\n# Calcola i coefficienti della retta dei minimi quadrati\ncoeff_combined = np.polyfit(df[\"bdi\"], df[\"cesd_sum\"], 1)\n\n# Calcola la retta dei minimi quadrati\nline_combined = np.poly1d(coeff_combined)\n\n# Disegna la retta dei minimi quadrati\nx_values = np.linspace(df[\"bdi\"].min(), df[\"bdi\"].max(), 100)\nplt.plot(x_values, line_combined(x_values), linestyle='--', color='C3')\n\n# Etichette degli assi\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"CESD\")\n\n# Linee verticali ed orizzontali per le medie\nplt.axvline(np.mean(df[df[\"group\"] == \"mdd\"][\"bdi\"]), alpha=0.2, color=\"blue\")\nplt.axvline(np.mean(df[df[\"group\"] == \"ctl\"][\"bdi\"]), alpha=0.2, color=\"red\")\nplt.axhline(np.mean(df[df[\"group\"] == \"mdd\"][\"cesd_sum\"]), alpha=0.2, color=\"blue\")\nplt.axhline(np.mean(df[df[\"group\"] == \"ctl\"][\"cesd_sum\"]), alpha=0.2, color=\"red\")\n\n# Legenda\nplt.legend()\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, √® evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ci√≤ suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, √® importante notare che la relazione lineare tra le due variabili √® lontana dall‚Äôessere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realt√†, la dispersione dei punti dal comportamento lineare ideale √® evidente.\nDi conseguenza, sorge la necessit√† di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#covarianza",
    "href": "chapters/chapter_2/05_correlation.html#covarianza",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.5 Covarianza",
    "text": "15.5 Covarianza\nIniziamo a considerare il pi√π importante di tali indici, chiamato covarianza. In realt√† la definizione di questo indice non ci sorprender√† pi√π di tanto in quanto, in una forma solo apparentemente diversa, l‚Äôabbiamo gi√† incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) √® definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la ‚Äúcovarianza di una variabile con s√© stessa‚Äù. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) ‚Äúvariano insieme‚Äù (co-variano). √à facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{15.1}\\]\nL‚ÄôEquazione¬†15.1 ci fornisce la definizione della covarianza.\n\n15.5.1 Interpretazione\nPer capire il significato dell‚ÄôEquazione¬†15.1, supponiamo di dividere il grafico riportato nella ?sec-introduction in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avr√† un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avr√† segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avr√† un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avr√† segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l‚Äôassociazione lineare si dice positiva se la covarianza √® positiva, negativa se la covarianza √® negativa.\nEsercizio. Implemento l‚ÄôEquazione¬†15.1 in Python.\n\ndef cov_value(x, y):\n\n    mean_x = sum(x) / float(len(x))\n    mean_y = sum(y) / float(len(y))\n\n    sub_x = [i - mean_x for i in x]\n    sub_y = [i - mean_y for i in y]\n\n    sum_value = sum([sub_y[i] * sub_x[i] for i in range(len(x))])\n    denom = float(len(x))\n\n    cov = sum_value / denom\n    return cov\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD √® 207.4\n\nx = df[\"bdi\"]\ny = df[\"cesd_sum\"]\n\ncov_value(x, y)\n\n207.42653810835637\n\n\nOppure, in maniera pi√π semplice:\n\nnp.mean((x - np.mean(x)) * (y - np.mean(y)))\n\n207.42653810835628\n\n\nLo stesso risultato si ottiene con la funzione cov di NumPy.\n\nnp.cov(x, y, ddof=0)\n\narray([[236.23875115, 207.42653811],\n       [207.42653811, 222.83379247]])\n\n\nLa funzione np.cov(x, y, ddof=0) in Python, utilizzata tramite la libreria NumPy, calcola la covarianza tra due array, x e y. L‚Äôargomento ddof (Delta Degrees of Freedom) specifica il ‚Äúcorrettore‚Äù da applicare al denominatore della formula di covarianza.\nQuando si imposta ddof=0, la formula utilizzata per il calcolo della covarianza divide la somma dei prodotti delle deviazioni dalla media per n, dove n √® il numero totale degli elementi nel campione (ovvero, la dimensione del campione). Questo approccio assume che i dati forniti rappresentino l‚Äôintera popolazione da cui si vuole stimare la covarianza, producendo una stima non corretta (bias) se i dati sono effettivamente un campione di una popolazione pi√π ampia. Il ‚Äúbias‚Äù in questo contesto si riferisce al fatto che la stima tende sistematicamente a essere pi√π piccola rispetto alla vera covarianza della popolazione da cui il campione √® stato estratto.\nPer correggere questo errore sistematico e ottenere una stima non distorta (unbiased) della covarianza di una popolazione pi√π ampia basandosi su un campione, si utilizza ddof=1. Questo significa che al denominatore della formula si sottrae 1 a n, dividendo quindi per n-1. Il correttore n-1 √® noto come correttore di Bessel, e l‚Äôuso di ddof=1 rende la stima della covarianza non distorta nel contesto di un campione prelevato da una popolazione. La correzione √® importante in statistica perch√© fornisce una stima pi√π accurata delle propriet√† della popolazione, soprattutto quando la dimensione del campione √® piccola.\nIn sintesi: - Con ddof=0, si divide per n, assumendo che i dati rappresentino l‚Äôintera popolazione. Questo pu√≤ introdurre un bias nella stima della covarianza se i dati sono in realt√† un campione. - Con ddof=1, si divide per n-1, correggendo il bias e ottenendo una stima non distorta (unbiased) della covarianza se i dati rappresentano un campione di una popolazione pi√π grande. Questo approccio √® generalmente preferito per la stima delle propriet√† della popolazione basata su campioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#correlazione",
    "href": "chapters/chapter_2/05_correlation.html#correlazione",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.6 Correlazione",
    "text": "15.6 Correlazione\nLa direzione della relazione tra le variabili √® indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poich√© dipende dall‚Äôunit√† di misura delle variabili. Ad esempio, considerando l‚Äôaltezza e il peso delle persone, la covarianza sar√† pi√π grande se l‚Äôaltezza √® misurata in millimetri e il peso in grammi, rispetto al caso in cui l‚Äôaltezza √® in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l‚Äôindice di correlazione.\nLa correlazione √® ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr_{XY} = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{15.2}\\]\nLa quantit√† che si ottiene dall‚ÄôEquazione¬†15.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l‚Äôuno dall‚Äôaltro, l‚Äôhanno introdotta).\n\n15.6.1 Propriet√†\nIl coefficiente di correlazione ha le seguenti propriet√†:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\n√® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n15.6.2 Interpretazione\nAll‚Äôindice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensit√† diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza √® 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c‚Äô√® un‚Äôassociazione lineare positiva. Per capire quale sia l‚Äôintensit√† della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore √® prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\nnp.corrcoef(x, y)\n\narray([[1.        , 0.90406202],\n       [0.90406202, 1.        ]])\n\n\nReplichiamo il risultato implementando l‚Äôeq. {eq}eq-cor-def:\n\ns_xy = np.mean((x - np.mean(x)) * (y - np.mean(y)))\ns_x = x.std(ddof=0)\ns_y = y.std(ddof=0)\nr_xy = s_xy / (s_x * s_y)\nprint(r_xy)\n\n0.9040620189474861\n\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD √® quello di standardizzare le due variabili per poi applicare la formula della covarianza:\n\nz_x = (x - np.mean(x)) / np.std(x, ddof=0)\nz_y = (y - np.mean(y)) / np.std(y, ddof=0)\nnp.mean(z_x * z_y)\n\n0.9040620189474862\n\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al.¬†(2024). Il concetto di ‚Äúgender bias‚Äù si riferisce alla tendenza sistematica di favorire un sesso rispetto all‚Äôaltro, spesso a scapito delle donne. Lo studio di Guilbeault et al.¬†(2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralit√† di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella societ√†. Il lavoro di Guilbeault et al.¬†(2024) evidenzia che il preconcetto di genere √® molto pi√π evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto pu√≤ essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al.¬†(2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura √® vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi √® alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralit√† di genere. In sostanza, questa misura di frequenza pu√≤ essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell‚Äôaltro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere √® pi√π prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell‚Äôassociazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione √® stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al.¬†(2024)).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#correlazione-di-spearman",
    "href": "chapters/chapter_2/05_correlation.html#correlazione-di-spearman",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.7 Correlazione di Spearman",
    "text": "15.7 Correlazione di Spearman\nUn‚Äôalternativa per valutare la relazione lineare tra due variabili √® il coefficiente di correlazione di Spearman, che si basa esclusivamente sull‚Äôordine dei dati e non sugli specifici valori. Questo indice di associazione √® particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalit√† di risposta dei soggetti, ma non l‚Äôintensit√† della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come ‚Äúordinali‚Äù.\n\n\n\n\n\n\n√à importante ricordare che, nel caso di una variabile ordinale, non √® possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, √® possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalit√† di risposta. Come abbiamo appena visto, la direzione e l‚Äôintensit√† dell‚Äôassociazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\nstats.spearmanr([1, 2, 3, 4, 5], [5, 6, 7, 8, 7])\n\nSignificanceResult(statistic=0.8207826816681233, pvalue=0.08858700531354381)",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#correlazione-nulla",
    "href": "chapters/chapter_2/05_correlation.html#correlazione-nulla",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.8 Correlazione nulla",
    "text": "15.8 Correlazione nulla\nUn aspetto finale da sottolineare riguardo alla correlazione √® che essa descrive la direzione e l‚Äôintensit√† della relazione lineare tra due variabili. Tuttavia, la correlazione non cattura relazioni non lineari tra le variabili, anche se possono essere molto forti. √à fondamentale comprendere che una correlazione pari a zero non implica l‚Äôassenza di una relazione tra le due variabili, ma indica solamente l‚Äôassenza di una relazione lineare tra di esse.\nLa figura seguente fornisce tredici esempi di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili. In questi tredici insiemi di dati i coefficienti di correlazione di Pearson sono sempre uguali a 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n\ndatasaurus_data = pd.read_csv(\"../data/datasaurus.csv\")\ndatasaurus_data.groupby(\"dataset\").agg(\n    {\"x\": [\"count\", \"mean\", \"std\"], \"y\": [\"count\", \"mean\", \"std\"]}\n)\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\ncount\nmean\nstd\ncount\nmean\nstd\n\n\ndataset\n\n\n\n\n\n\n\n\n\n\naway\n142\n54.266100\n16.769825\n142\n47.834721\n26.939743\n\n\nbullseye\n142\n54.268730\n16.769239\n142\n47.830823\n26.935727\n\n\ncircle\n142\n54.267320\n16.760013\n142\n47.837717\n26.930036\n\n\ndino\n142\n54.263273\n16.765142\n142\n47.832253\n26.935403\n\n\ndots\n142\n54.260303\n16.767735\n142\n47.839829\n26.930192\n\n\nh_lines\n142\n54.261442\n16.765898\n142\n47.830252\n26.939876\n\n\nhigh_lines\n142\n54.268805\n16.766704\n142\n47.835450\n26.939998\n\n\nslant_down\n142\n54.267849\n16.766759\n142\n47.835896\n26.936105\n\n\nslant_up\n142\n54.265882\n16.768853\n142\n47.831496\n26.938608\n\n\nstar\n142\n54.267341\n16.768959\n142\n47.839545\n26.930275\n\n\nv_lines\n142\n54.269927\n16.769959\n142\n47.836988\n26.937684\n\n\nwide_lines\n142\n54.266916\n16.770000\n142\n47.831602\n26.937902\n\n\nx_shape\n142\n54.260150\n16.769958\n142\n47.839717\n26.930002\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(4, 4, figsize=(15, 15))\ndatasets = datasaurus_data[\"dataset\"].unique()\n\nfor i, dataset in enumerate(datasets):\n    row = i // 4\n    col = i % 4\n    ax = axs[row, col]\n    subset = datasaurus_data[datasaurus_data[\"dataset\"] == dataset]\n    ax.scatter(subset[\"x\"], subset[\"y\"], alpha=0.7)\n    ax.set_title(dataset)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_14701/188333220.py:14: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#considerazioni-conclusive",
    "href": "chapters/chapter_2/05_correlation.html#considerazioni-conclusive",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.9 Considerazioni conclusive",
    "text": "15.9 Considerazioni conclusive\nNel concludere questo capitolo dedicato allo studio di correlazione e covarianza, √® essenziale mettere in evidenza alcuni principi fondamentali. Il concetto di ‚Äúassociazione‚Äù equivale a quello di ‚Äúdipendenza‚Äù e pu√≤ manifestarsi sia attraverso cause dirette che indirette. Ci√≤ significa che variazioni in una variabile possono influenzare o essere influenzate da un‚Äôaltra, indipendentemente dalla natura diretta o mediata di questo legame.\nPer quanto riguarda la correlazione, questa descrive specifici tipi di associazione, come tendenze monotone. Ad esempio, la presenza di un incremento congiunto o di raggruppamenti in determinati intervalli tra due variabili √® indicativa di correlazione. √à per√≤ cruciale ricordare che correlazione non equivale a causalit√†; osservare una correlazione non implica necessariamente che una variabile causi l‚Äôaltra.\nNei contesti in cui il numero di variabili √® ampio rispetto alla grandezza del campione, possono emergere correlazioni elevate ma spurie. Questo accade perch√© un gran numero di variabili pu√≤ accidentalmente generare correlazioni elevate, non riflettendo un legame sostanziale tra di esse.\nD‚Äôaltra parte, con un numero elevato di osservazioni, anche le correlazioni pi√π deboli possono sembrare robuste. In campioni di grandi dimensioni, anche le pi√π piccole variazioni possono apparire accentuate rispetto alla variabilit√† generale del campione, bench√© queste correlazioni possano non avere una rilevanza pratica.\nIn conclusione, √® fondamentale adottare un approccio critico e ben informato nell‚Äôinterpretare i risultati delle analisi di correlazione e covarianza, tenendo sempre in considerazione le dimensioni del campione e il numero di variabili coinvolte. Tale prudenza aiuta a prevenire interpretazioni errate delle relazioni tra le variabili, specialmente riguardo alla causalit√†.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/05_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/05_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "15¬† Le relazioni tra variabili",
    "section": "15.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "15.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html",
    "href": "chapters/chapter_2/06_causality.html",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "",
    "text": "16.1 Introduzione\nPer assicurare l‚Äôintegrit√† e la validit√† scientifica dei modelli statistici, √® essenziale abbinarli a un‚Äôanalisi causale. La pura osservazione dei dati pu√≤ rivelare correlazioni e pattern nei dati, ma senza un‚Äôindagine sulle cause che stanno dietro a queste correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nAnche nell‚Äôambito di una discussione sull‚Äôanalisi descrittiva dei dati (e, forse, soprattutto in un tale contesto), √® importante sottolineare le limitazioni di un tale approccio. L‚Äôaspetto cruciale da tenere a mente √® che le cause dei fenomeni non possono essere inferite solamente dall‚Äôanalisi dei dati. N√© dall‚Äôanalisi descrittiva dei dati che stiamo discutendo adesso, n√© dall‚Äôanalisi inferenziale dei dati che discuteremo in seguito. Pertanto, per giungere ad una comprensione dei fenomeni √® necessario integrare il processo di modellazione statistica con una comprensione delle cause sottostanti del fenomeno oggetto d‚Äôesame. In altre parole, per una comprensione scientificamente valida, √® necessario combinare la modellazione statistica con l‚Äôanalisi causale.\nIn questo capitolo, ci concentreremo sull‚Äôintroduzione dei concetti fondamentali dell‚Äôanalisi causale, i quali costituiscono una base cruciale per l‚Äôinterpretazione dei dati. Cominceremo con la distinzione tra correlazione e causalit√†. La correlazione indica una relazione tra due variabili, mettendo in evidenza la loro forza e direzione, mentre la causalit√† implica un legame di causa ed effetto tra le variabili. √à di importanza cruciale comprendere che il fatto che due variabili siano correlate non implica automaticamente l‚Äôesistenza di un rapporto causale tra di esse. Il noto principio ‚Äúcorrelazione non implica causalit√†‚Äù sottolinea questa distinzione critica. Numerosi esempi di correlazioni che non sono basate su una relazione causale diretta possono essere esaminati sul sito spurious correlations.\nOltre a questo concetto fondamentale, procederemo ad esplorare una serie di concetti introdotti da Judea Pearl nel suo testo ‚ÄúCausality‚Äù (Pearl 2009). Questi concetti sono essenziali per descrivere le relazioni tra variabili. Essi includono strutture di relazione come biforcazioni, catene, collider e strutture discendenti. Questa cornice concettuale ci permetter√† di distinguere tra i diversi tipi di legami causali tra le variabili, ponendo cos√¨ le basi per condurre un‚Äôanalisi dei dati pi√π completa e accurata.\nMediante esempi numerici, dimostreremo l‚Äôimportanza dei fattori confondenti nell‚Äôanalisi della correlazione e della covarianza. Questo passo ci condurr√† oltre l‚Äôanalisi delle relazioni bivariate di base, introducendoci alle dinamiche pi√π complesse che regolano le relazioni tra le variabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#inferenza-causale",
    "href": "chapters/chapter_2/06_causality.html#inferenza-causale",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.2 Inferenza Causale",
    "text": "16.2 Inferenza Causale\nL‚Äôinferenza causale si pone l‚Äôobiettivo di rappresentare il processo sottostante a un fenomeno, permettendo di prevedere gli effetti di un intervento. Oltre a prevedere le conseguenze di una causa, consente di esplorare scenari controfattuali, immaginando gli esiti alternativi che si sarebbero verificati con decisioni diverse. Questo tipo di ragionamento √® cruciale sia in contesti descrittivi che inferenziali.\nMcElreath (2020) utilizza l‚Äôanalogia dei Golem, potenti ma privi di saggezza e previsione, per descrivere un approccio limitato che √® stato a lungo lo standard in psicologia. Questo approccio si concentra sul semplice test delle ipotesi nulle e non stabilisce una relazione chiara tra le problematiche causali della ricerca e i test statistici. Tale limitazione √® stata identificata come una delle principali cause della crisi di replicabilit√† dei risultati nella ricerca psicologica (si veda il capitolo {ref}generalizability-crisis-notebook) e, di conseguenza, della crisi della psicologia stessa.\n\n\n\nEsempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall‚Äôalto, l‚Äôutente risponde a una serie di domande riguardanti la misurazione e l‚Äôintento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).\n\n\nUn problema evidenziato da McElreath (2020) √® che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sul test dell‚Äôipotesi nulla non √® in grado di distinguere tra questi diversi scenari. Questa limitazione √® dimostrata numericamente nel capitolo {ref}causal-inference-notebook.\nIl test dell‚Äôipotesi nulla, ovvero l‚Äôapproccio frequentista, nonostante sia stato ampiamente utilizzato in psicologia per decenni, ha mostrato una bassa sensibilit√† nel rilevare le caratteristiche cruciali dei fenomeni studiati e un alto tasso di falsi positivi (Zwet et al. 2023).\nLa ricerca scientifica richiede una metodologia pi√π sofisticata rispetto all‚Äôapproccio che si limita a confutare ipotesi nulle. √à essenziale sviluppare modelli causali che rispondano direttamente alle domande di ricerca. Inoltre, √® fondamentale avere una strategia razionale per l‚Äôestrazione delle stime dei modelli e per la quantificazione dell‚Äôincertezza associata ad esse. In questo contesto, l‚Äôanalisi bayesiana dei dati emerge come un approccio altamente efficace. Anche se in analisi semplici le differenze rispetto all‚Äôapproccio frequentista potrebbero sembrare minime o addirittura introdurre alcune complicazioni, quando ci si trova ad affrontare analisi pi√π realistiche e complesse, la differenza diventa sostanziale.\n\n16.2.1 Passaggi Chiave per un‚ÄôAnalisi Causale\nPer condurre un‚Äôanalisi scientifica dei dati che superi l‚Äôapproccio ‚Äúamatoriale‚Äù frequentista, McElreath (2020) suggerisce di seguire una serie di passaggi chiave:\n\nComprendere il concetto teorico del fenomeno oggetto dell‚Äôanalisi.\nSviluppare modelli causali che descrivano accuratamente le relazioni tra le variabili coinvolte nel problema di ricerca, basandosi sulla teoria sottostante.\nFormulare modelli statistici appropriati che riflettano fedelmente il contesto scientifico e le relazioni causali identificate.\nEseguire simulazioni basate sui modelli causali per verificare se i modelli statistici sviluppati siano in grado di stimare correttamente ci√≤ che √® teoricamente atteso. Questa fase di verifica √® cruciale per garantire la validit√† dei modelli.\nCondurre l‚Äôanalisi dei dati effettivi utilizzando i modelli statistici sviluppati, avendo la fiducia che riflettano accuratamente le teorie sottostanti e le relazioni causali.\n\n\n\n16.2.2 Grafi Aciclici Direzionati (DAG)\nUn elemento chiave sottolineato da McElreath (2020) nel processo di analisi √® l‚Äôutilizzo dei Grafi Aciclici Direzionati (DAG), che rappresentano uno strumento essenziale per realizzare il flusso di lavoro descritto. I DAG forniscono una rappresentazione grafica dei modelli causali, consentendo una visualizzazione chiara delle relazioni tra le variabili coinvolte. Questi grafici rendono trasparenti le assunzioni alla base dell‚Äôanalisi, creando una connessione evidente tra le teorie sottostanti e l‚Äôanalisi statistica. In contrasto, l‚Äôapproccio frequentista √® caratterizzato dall‚Äôassenza di ipotesi sulle relazioni sottostanti tra le variabili, rendendo difficile comprendere e interpretare le implicazioni scientifiche dei risultati ottenuti.\nPer un approfondimento di questi temi, consiglio fortemente la lettura del primo capitolo di Statistical Rethinking.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#due-paradossi-comuni",
    "href": "chapters/chapter_2/06_causality.html#due-paradossi-comuni",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.3 Due Paradossi Comuni",
    "text": "16.3 Due Paradossi Comuni\nEsistono due situazioni comuni in cui i dati possono ingannarci, e che vale la pena esaminare esplicitamente. Questi sono:\n\nIl paradosso di Simpson\nIl paradosso di Berkson\n\n\n16.3.1 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando stimiamo una relazione per sottoinsiemi dei nostri dati, ma otteniamo una relazione diversa considerando l‚Äôintero dataset (Simpson 1951). √à un caso particolare della fallacia ecologica, che si verifica quando cerchiamo di fare affermazioni sugli individui basandoci sui loro gruppi. Ad esempio, potrebbe esserci una relazione positiva tra i voti universitari e la performance alla scuola di specializzazione in due dipartimenti considerati individualmente. Tuttavia, se i voti universitari tendono a essere pi√π alti in un dipartimento rispetto all‚Äôaltro, mentre la performance alla scuola di specializzazione tende a essere opposta, potremmo trovare una relazione negativa tra i voti universitari e la performance alla scuola di specializzazione.\n\n\n16.3.2 Paradosso di Berkson\nIl paradosso di Berkson si verifica quando stimiamo una relazione basandoci sul dataset che abbiamo, ma a causa della selezione del dataset, la relazione risulta diversa in un dataset pi√π generale (Berkson 1946). Ad esempio, se abbiamo un dataset di ciclisti professionisti, potremmo non trovare una relazione tra il loro VO2 max e la possibilit√† di vincere una gara di ciclismo (Coyle et al.¬†1988; Podlogar, Leo, and Spragg 2022). Tuttavia, se avessimo un dataset della popolazione generale, potremmo trovare una relazione tra queste due variabili. Il dataset professionale √® cos√¨ selezionato che la relazione scompare; non si pu√≤ diventare ciclisti professionisti senza avere un VO2 max adeguato, ma tra i ciclisti professionisti, tutti hanno un VO2 max sufficiente.\n\n\n16.3.3 I Disegni di Ricerca e la Causalit√†\nPer comprendere meglio l‚Äôuso dei DAG nell‚Äôinferenza causale, √® necessario distinguere tra ricerche basate su disegni osservazionali e sperimentali (Rohrer 2018).\nNei disegni osservazionali i ricercatori osservano e registrano gli eventi senza intervenire direttamente. A differenza degli esperimenti controllati, qui non si manipolano le variabili studiate, ma si osservano le relazioni naturali che emergono. Questi studi sono preziosi quando gli esperimenti non sono fattibili per motivi etici o pratici. Tuttavia, sebbene siano efficaci nell‚Äôidentificare correlazioni e tendenze, i disegni osservazionali spesso mancano della capacit√† di stabilire con certezza relazioni causali, a causa di variabili confondenti e bias di selezione. Esempi comuni di disegni osservazionali includono studi trasversali e longitudinali.\nI disegni sperimentali, d‚Äôaltra parte, si basano sulla manipolazione controllata delle variabili e sulla randomizzazione. Quest‚Äôultima, ovvero l‚Äôassegnazione casuale dei partecipanti ai gruppi, √® fondamentale per ridurre i bias e garantire la validit√† delle conclusioni causali. Gli esperimenti randomizzati sono considerati il gold standard per indagare le relazioni causali, poich√© la randomizzazione consente di bilanciare gli effetti delle variabili osservate e non osservate tra i diversi gruppi di trattamento.\nNonostante gli esperimenti offrano un elevato grado di certezza nella determinazione delle relazioni causali, i disegni osservazionali presentano vantaggi in termini di flessibilit√† e applicabilit√† in situazioni in cui gli esperimenti non possono essere condotti per ragioni etiche o pratiche. {cite:p}rohrer2018thinking nota che, mentre i disegni osservazionali spesso si basano su relazioni associative piuttosto che causali, gli esperimenti potrebbero non consentire una generalizzazione al di l√† delle condizioni artificiali del laboratorio.\nNel contesto della ricerca, il concetto di causalit√† si riferisce alla relazione tra una variabile (X) e un‚Äôaltra (Y), in cui X pu√≤ influenzare Y. Il linguaggio causale utilizza termini come ‚Äúcausa‚Äù, ‚Äúinfluenza‚Äù e ‚Äúdetermina‚Äù, a differenza di termini descrittivi come ‚Äúassociato‚Äù o ‚Äúcorrelato‚Äù, che indicano semplicemente relazioni senza implicare un legame causale diretto. √à importante ribadire che la causalit√† √® concepita come un concetto probabilistico, il che significa che una variazione in X aumenta la probabilit√† di un certo risultato in Y, piuttosto che determinarlo in modo assoluto.\nNel campo della ricerca psicologica, spesso √® necessario inferire relazioni causali da dati osservazionali poich√© gli esperimenti randomizzati non sono sempre praticabili o eticamente accettabili. Tuttavia, questo approccio presenta diverse sfide che possono influenzare l‚Äôintegrit√† e l‚Äôaccuratezza delle inferenze tratte dagli studi. Per affrontare tali sfide e migliorare la solidit√† delle loro analisi, i ricercatori impiegano una serie di strategie metodologiche.\n\nUtilizzo di interventi surrogati: questa tecnica √® preziosa in situazioni in cui la manipolazione diretta di una variabile di interesse √® impraticabile o eticamente inaccettabile. Piuttosto che intervenire direttamente, i ricercatori si avvalgono di variabili surrogate (o proxy) che presumibilmente sono associate alla variabile di interesse principale. L‚Äôobiettivo √® esplorare e dedurre gli effetti indiretti di una variabile su un‚Äôaltra, stabilendo associazioni che, sebbene non dirette, possono fornire importanti informazioni sul fenomeno in esame. Tuttavia, questa strategia presenta delle sfide intrinseche, come la difficolt√† nel garantire una relazione diretta tra la variabile surrogata e quella di interesse principale.\nLinguaggio cauto nell‚Äôinterpretazione dei dati: i ricercatori adottano un linguaggio prudente quando interpretano dati osservazionali, evitando di fare affermazioni causali dirette quando i dati mostrano solo correlazioni.\nUtilizzo di metodi statistici avanzati per controllare variabili confondenti: Le variabili confondenti sono fattori esterni che possono influenzare la relazione tra le variabili studiate. L‚Äôutilizzo di tecniche statistiche avanzate, come la regressione multipla o l‚Äôanalisi di matching, aiuta a controllare l‚Äôeffetto di queste variabili confondenti, consentendo una stima pi√π accurata della relazione tra le variabili di interesse. Tuttavia, questi metodi hanno limitazioni (si veda ?sec-causal-inference) e potrebbero non riuscire a controllare completamente tutte le variabili confondenti, specialmente in situazioni complesse.\n\nRohrer (2018) sottolinea che, nonostante l‚Äôadozione di queste strategie, persistono sfide in termini di validit√† esterna (cio√® la generalizzabilit√† dei risultati) e interpretazione dei dati. La validit√† esterna potrebbe essere limitata poich√© le condizioni specifiche dello studio potrebbero non rappresentare situazioni pi√π ampie o diverse, mentre l‚Äôinterpretazione dei risultati pu√≤ essere complicata dalla natura indiretta o surrogata delle evidenze raccolte.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#modelli-causali-grafici",
    "href": "chapters/chapter_2/06_causality.html#modelli-causali-grafici",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.4 Modelli Causali Grafici",
    "text": "16.4 Modelli Causali Grafici\nL‚Äôanalisi dei dati osservazionali per trarre inferenze causali √® intrinsecamente complessa, ma con precauzioni adeguate e approcci metodologici appropriati, √® possibile estrarre preziosi insight causali anche da questo tipo di dati. In questo contesto, Rohrer (2018) sottolinea l‚Äôimportanza dei DAG come strumento fondamentale per la rappresentazione visiva delle ipotesi causali. Questi diagrammi non solo agevolano la comprensione delle relazioni causali tra le variabili, ma forniscono anche una guida per l‚Äôidentificazione e il trattamento corretto delle variabili esterne, comunemente note come ‚Äúvariabili di confondimento‚Äù.\nUna delle funzioni pi√π cruciali dei DAG √® la loro capacit√† di individuare quali variabili di confondimento debbano essere considerate nell‚Äôanalisi e quali possano essere trascurate senza compromettere l‚Äôintegrit√† dell‚Äôinferenza causale. Questa caratteristica √® essenziale poich√© sia il controllo insufficiente sia quello eccessivo delle variabili di confondimento possono condurre a conclusioni erronee. In particolare, i DAG aiutano a determinare quando l‚Äôaggiustamento per determinate variabili di confondimento pu√≤ migliorare l‚Äôaccuratezza delle inferenze causali e quando, al contrario, tale aggiustamento potrebbe introdurre distorsioni (questo punto verr√† approfondito nel capitolo sec-causal-inference).\nGrazie ai DAG, i ricercatori possono esplicitare le loro ipotesi sulle relazioni causali tra le variabili, riducendo cos√¨ il rischio di interpretare erroneamente i dati osservazionali. Questo approccio consente di sviluppare strategie di analisi pi√π informate e metodologicamente solide, mirate a comprendere al meglio le dinamiche causali sottostanti.\n\n16.4.1 Importanza delle Assunzioni\n√à cruciale comprendere che l‚Äôestrazione di conclusioni causali da dati correlazionali non pu√≤ essere basata esclusivamente sui dati stessi. √à invece necessario possedere delle conoscenze sulle dinamiche causali del fenomeno esaminato. Questo principio deriva dalla consapevolezza che una correlazione osservata pu√≤ essere attribuita a una vasta gamma di fattori, inclusa l‚Äôinfluenza potenziale di variabili terze non considerate nell‚Äôanalisi. Di conseguenza, qualsiasi tentativo di inferenza causale privo di una comprensione preliminare delle possibili relazioni causali rischia di essere fallace.\nNonostante queste sfide, √® fondamentale non rinunciare davanti alla complessit√† intrinseca della ricerca osservazionale. Pur non potendo dimostrare inequivocabilmente la causalit√†, per via della loro incapacit√† di manipolare direttamente le variabili di interesse, gli studi osservazionali svolgono un ruolo irrinunciabile nel contesto scientifico. Questi studi sono fondamentali per la generazione di ipotesi e per guidare la ricerca futura verso domande scientifiche rilevanti. Allo stesso modo, gli studi sperimentali, bench√© considerati il gold standard per la determinazione delle relazioni causali, non sono esenti da limitazioni. Gli esperimenti, soprattutto quelli condotti in ambienti altamente controllati come i laboratori, presuppongono la generalizzabilit√† dei risultati al di l√† dei confini dello studio, un‚Äôassunzione che pu√≤ non sempre trovare riscontro nella realt√†.\nIn questo contesto, ci√≤ che rende un‚Äôindagine rigorosa, sia essa osservazionale che sperimentale, √® la capacit√† di riconoscere, articolare e comunicare chiaramente le premesse su cui si basa. Questo approccio non solo facilita una valutazione critica delle conclusioni causali da parte della comunit√† scientifica, ma promuove anche un dialogo costruttivo e produttivo all‚Äôinterno della stessa, fondamentale per il progresso della conoscenza. La trasparenza nell‚Äôesposizione delle premesse rappresenta un prerequisito essenziale per un avanzamento scientifico informato, consapevole e, soprattutto, veritiero.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#introduzione-ai-dag",
    "href": "chapters/chapter_2/06_causality.html#introduzione-ai-dag",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.5 Introduzione ai DAG",
    "text": "16.5 Introduzione ai DAG\nI Grafi Aciclici Diretti (DAG) offrono una rappresentazione grafica delle relazioni causali ipotizzate tra le variabili. In un DAG, le frecce vengono utilizzate per indicare le relazioni causali tra diverse variabili.\nSono chiamati cos√¨ perch√©:\n\nLe variabili presenti nel diagramma (nodi) possono essere collegate tra loro solo attraverso frecce, anzich√© semplici linee di collegamento, da cui il termine ‚Äúdiretti‚Äù.\nPartendo da un nodo, non √® possibile ritornare allo stesso nodo seguendo il percorso delle frecce, da cui il termine ‚Äúaciclici‚Äù.\n\nLe variabili sono chiamate nodi del DAG. Un cammino tra due nodi √® una sequenza di frecce che collegano i due nodi, indipendentemente dalla direzione delle frecce.\nAll‚Äôinterno di un DAG, la freccia che va dal nodo \\(X\\) al nodo \\(Y\\) evidenzia una relazione causale, implicando che \\(X\\) abbia un‚Äôinfluenza su \\(Y\\). Tuttavia, questa relazione non √® deterministica; piuttosto, le variazioni nel livello di \\(X\\) sono associate a cambiamenti in \\(Y\\) su base probabilistica. Pertanto, la presenza della freccia nel DAG causale indica che un aumento di \\(X\\) aumenta la probabilit√† che \\(Y\\) aumenti, ma non lo garantisce.\nSe tra due nodi c‚Äô√® una sola freccia, il nodo dal quale parte la freccia √® detto ‚Äúgenitore‚Äù, mentre quello di arrivo √® detto ‚Äúfiglio‚Äù. Se, partendo da un nodo A, si arriva a un nodo B seguendo il verso di una successione di frecce, allora il nodo A √® detto ‚Äúantenato‚Äù, mentre B √® detto ‚Äúdiscendente‚Äù.\nI DAG permettono di identificare quali variabili agiscono come confondenti e quali no, basandosi sulla teoria sviluppata da Judea Pearl (Pearl 2009). √à importante rappresentare tutte le possibili relazioni nel DAG, poich√© l‚Äôassenza di una freccia tra due variabili implica una certezza dell‚Äôassenza di relazione tra di esse.\nDue dei concetti fondamentali della teoria dei DAG sono la d-separazione e il back-door path.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#concetto-di-d-separazione",
    "href": "chapters/chapter_2/06_causality.html#concetto-di-d-separazione",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.6 Concetto di d-separazione",
    "text": "16.6 Concetto di d-separazione\nLa d-separazione √® un concetto fondamentale per comprendere come le variabili all‚Äôinterno di un DAG possano influenzarsi reciprocamente. Essa definisce se un insieme di variabili pu√≤ bloccare l‚Äôinfluenza di una variabile su un‚Äôaltra. In altre parole, la d-separazione ci aiuta a capire se un percorso che collega due variabili √® attivo o inattivo, considerando un insieme di nodi specifico.\n\n16.6.1 Definizione di d-separazione\nUn cammino tra due nodi √® d-separato (o bloccato) da un insieme Œõ di nodi se e solo se si verificano le seguenti condizioni:\n\nCatena (Sequenza di frecce): Se il cammino √® costituito da una sequenza di frecce nella stessa direzione (ad esempio, \\(X \\rightarrow Z \\rightarrow Y\\)), il nodo intermedio (\\(Z\\)) deve appartenere all‚Äôinsieme Œõ affinch√© il cammino sia bloccato. Questo significa che la variabile \\(Z\\) deve essere inclusa nell‚Äôanalisi per bloccare l‚Äôinfluenza di \\(X\\) su \\(Y\\).\nFork (Nodo con due frecce in uscita): Se nel cammino c‚Äô√® un nodo da cui partono due frecce (ad esempio, \\(X \\leftarrow Z \\rightarrow Y\\)), il nodo di partenza delle frecce (\\(Z\\)) deve appartenere all‚Äôinsieme Œõ affinch√© il cammino sia bloccato. In questo caso, \\(Z\\) agisce come una variabile confondente, e includerla nell‚Äôanalisi blocca il percorso.\nCollider (Nodo con due frecce in entrata): Se nel cammino c‚Äô√® un nodo in cui convergono due frecce (ad esempio, \\(X \\rightarrow Z \\leftarrow Y\\)), n√© il nodo di convergenza (\\(Z\\)) n√© i suoi discendenti devono appartenere all‚Äôinsieme Œõ affinch√© il cammino sia bloccato. Un collider introduce un‚Äôassociazione tra \\(X\\) e \\(Y\\) solo se \\(Z\\) o i suoi discendenti sono inclusi nell‚Äôanalisi.\n\nLa d-separazione √® uno strumento potente per identificare i percorsi di confondimento e determinare quali variabili devono essere considerate nel modello statistico per ottenere inferenze causali accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#il-criterio-del-back-door",
    "href": "chapters/chapter_2/06_causality.html#il-criterio-del-back-door",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.7 Il criterio del back-door",
    "text": "16.7 Il criterio del back-door\nIl criterio del back-door √® uno strumento grafico utile per individuare le variabili confondenti che devono essere considerate per ottenere stime causali corrette. Questo criterio si basa sulla verifica dei percorsi non causali, detti ‚Äúback-door paths‚Äù, che collegano l‚Äôesposizione all‚Äôoutcome.\nIl criterio del back-door pu√≤ essere applicato mediante i seguenti passaggi:\n\nEliminare le frecce dirette: Rimuovere tutte le frecce che vanno dall‚Äôesposizione all‚Äôoutcome nel grafo.\nVerificare i percorsi non bloccati: Controllare se esistono percorsi non bloccati tra l‚Äôesposizione e l‚Äôoutcome nel grafo modificato.\n\nSe tutti i percorsi sono bloccati, significa che non c‚Äô√® confondimento, e quindi l‚Äôesposizione e l‚Äôoutcome sono indipendenti. Se invece esistono percorsi non bloccati, √® necessario individuare e aggiustare per le variabili che possono bloccarli.\n\n16.7.1 Esempi di applicazione del criterio del back-door\nConsideriamo un DAG che rappresenta la relazione tra autostima (A) e performance accademica (P), tenendo conto di variabili come il supporto familiare (S) e il livello di stress (L). Il DAG √® strutturato come segue:\n\nA ‚Üí P\nS ‚Üí A\nS ‚Üí P\nL ‚Üê S\n\nRimuovendo la freccia diretta A ‚Üí P, rimangono i percorsi:\n\nA ‚Üê S ‚Üí P\nA ‚Üê S ‚Üí L ‚Üí P\n\nPer bloccare questi percorsi, √® necessario condizionare su S, che blocca entrambi i percorsi. Pertanto, per ottenere una stima non distorta della relazione tra autostima e performance accademica, √® sufficiente aggiustare per il supporto familiare (S).\n\n16.7.1.1 Esempio 2: Relazione tra attivit√† fisica e benessere psicologico\nConsideriamo un DAG con le seguenti relazioni:\n\nAttivit√† fisica (F) ‚Üí Benessere psicologico (B)\nGenere (G) ‚Üí F\nGenere (G) ‚Üí B\nEt√† (E) ‚Üí F\nEt√† (E) ‚Üí B\n\nIn questo caso, abbiamo i percorsi:\n\nF ‚Üê G ‚Üí B\nF ‚Üê E ‚Üí B\n\nRimuovendo la freccia diretta F ‚Üí B, rimangono i percorsi non bloccati:\n\nF ‚Üê G ‚Üí B\nF ‚Üê E ‚Üí B\n\nPer bloccare questi percorsi, √® necessario condizionare sia su G (genere) che su E (et√†). Pertanto, per ottenere una stima non distorta della relazione tra attivit√† fisica e benessere psicologico, √® necessario aggiustare per le variabili genere ed et√†.\n\n\n\n16.7.2 Procedura per determinare l‚Äôinsieme sufficiente di variabili\nPer decidere se un insieme di variabili √® sufficiente per l‚Äôaggiustamento, √® possibile seguire questi passaggi:\n\nEliminare le frecce dell‚Äôesposizione: Rimuovere tutte le frecce che partono dalla variabile di esposizione.\nAggiungere archi di controllo: Aggiungere tutti gli archi necessari generati dal controllo sulle variabili dell‚Äôinsieme considerato.\nVerificare i percorsi non bloccati: Se tutti i percorsi non bloccati tra l‚Äôesposizione e l‚Äôoutcome contengono almeno una variabile dell‚Äôinsieme considerato, allora l‚Äôinsieme √® sufficiente per il controllo.\n\nL‚Äôinsieme pu√≤ anche essere vuoto se non √® necessario aggiustare per alcuna variabile.\nIn sintesi, il criterio del back-door consente di ridurre il numero di variabili da considerare per l‚Äôaggiustamento, risolvendo un importante problema pratico. Identificare l‚Äôinsieme sufficiente minimale di variabili aiuta a mantenere l‚Äôanalisi gestibile e precisa, migliorando la validit√† delle inferenze causali. Questo √® particolarmente utile in psicologia, dove le variabili confondenti sono spesso numerose e complesse.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#strutture-causali-elementari",
    "href": "chapters/chapter_2/06_causality.html#strutture-causali-elementari",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.8 Strutture Causali Elementari",
    "text": "16.8 Strutture Causali Elementari\nAll‚Äôinterno dei DAG causali, si possono riconoscere quattro tipologie fondamentali di strutture causali: confondente, catena, collider e discendenti. La comprensione di queste strutture causali di base √® fondamentale per analizzare i percorsi causali pi√π complessi.\n\n\n\nI quattro confondenti di base. (Figura tratta da McElreath (2020)).\n\n\n\n16.8.1 Catena\nIl concetto di catena (pipe) in un DAG descrive una sequenza in cui una variabile \\(X\\) influisce su una variabile \\(Y\\) attraverso una variabile intermedia \\(Z\\), formando una catena causale del tipo \\(X \\rightarrow Z \\rightarrow Y\\). In questo scenario, \\(Z\\) agisce come mediatore della relazione causale tra \\(X\\) e \\(Y\\). Controllando per \\(Z\\), la relazione diretta osservata tra \\(X\\) e \\(Y\\) scompare perch√© \\(X\\) influisce su \\(Y\\) esclusivamente attraverso \\(Z\\).\nIn sintesi,\n\n\\(X\\) e \\(Y\\) sono associati: \\(X \\not\\perp Y\\).\nL‚Äôinfluenza di \\(X\\) su \\(Y\\) viene trasmessa tramite \\(Z\\).\nStratificando i dati in base a \\(Z\\), l‚Äôassociazione tra \\(X\\) e \\(Y\\) scompare: \\(X \\perp Y \\mid Z\\).\n\nEsempio. Consideriamo l‚Äôeffetto dell‚Äôeducazione sull‚Äôoccupabilit√† attraverso l‚Äôacquisizione di competenze specifiche.\nVariabili: - \\(X\\): Livello di Educazione (ad es., nessun diploma, diploma di scuola superiore, laurea) - \\(Z\\): Competenze Specifiche Acquisite (ad es., competenze informatiche, competenze linguistiche, competenze professionali specifiche) - \\(Y\\): Occupabilit√† (misurata come probabilit√† di ottenere un lavoro nel proprio campo di studio entro un certo periodo dopo il completamento degli studi)\nRelazione Causale: Il livello di educazione (\\(X\\)) influisce sull‚Äôoccupabilit√† (\\(Y\\)) attraverso l‚Äôacquisizione di competenze specifiche (\\(Z\\)). In altre parole, non √® tanto il titolo di studio in s√© a determinare direttamente l‚Äôoccupabilit√†, quanto le competenze specifiche acquisite durante il percorso educativo. Questo √® un classico esempio di relazione di tipo ‚Äúpipe‚Äù.\nScenario senza Stratificazione: Senza stratificare per \\(Z\\), si potrebbe osservare una correlazione positiva tra \\(X\\) e \\(Y\\), suggerendo che un maggiore livello di educazione √® associato a una maggiore occupabilit√†. Tuttavia, questa osservazione non chiarisce se il titolo di studio in s√© sia il fattore determinante o se ci√≤ dipenda dalle competenze acquisite.\nScenario con Stratificazione per \\(Z\\): Quando si stratifica per le competenze specifiche acquisite (\\(Z\\)), controllando quindi per il tipo e il livello di competenze ottenute, la relazione diretta tra il livello di educazione e l‚Äôoccupabilit√† potrebbe scomparire o indebolirsi fortemente. Questo indica che, una volta considerate le competenze acquisite, il livello di educazione in s√© non ha un impatto diretto sull‚Äôoccupabilit√†. L‚Äôeffetto osservato del livello di educazione sull‚Äôoccupabilit√† √® quindi mediato completamente dalle competenze specifiche acquisite.\nQuesto esempio mostra come, in una relazione a catena, la variabile mediatrice (\\(Z\\)) spiega completamente la relazione tra la variabile indipendente (\\(X\\)) e la variabile dipendente (\\(Y\\)).\n\n\n16.8.2 Confondente\nIl concetto di confondente (fork) si riferisce a una struttura in cui una variabile comune \\(Z\\) causa due variabili \\(X\\) e \\(Y\\), formando una relazione del tipo \\(X \\leftarrow Z \\rightarrow Y\\). In questo scenario, \\(Z\\) √® una variabile confondente che pu√≤ generare una correlazione apparente tra \\(X\\) e \\(Y\\), anche se non esiste una relazione causale diretta tra di loro. Analizzare adeguatamente il ruolo di \\(Z\\) √® fondamentale per comprendere le vere relazioni causali tra \\(X\\) e \\(Y\\).\nEsempio. Consideriamo l‚Äôinfluenza dell‚Äôet√† sul numero di scarpe e abilit√† matematiche.\nVariabili: - \\(Z\\): Et√† (variabile confondente) - \\(X\\): Numero di Scarpe - \\(Y\\): Abilit√† Matematiche\nRelazione Causale: In questo esempio, l‚Äôet√† (\\(Z\\)) √® la variabile confondente che influisce sia sul numero di scarpe (\\(X\\)) che sulle abilit√† matematiche (\\(Y\\)). Con l‚Äôaumentare dell‚Äôet√†, generalmente aumenta il numero di scarpe a causa della crescita fisica e migliorano le abilit√† matematiche grazie all‚Äôapprendimento scolastico e allo sviluppo cognitivo.\nSenza Considerare l‚ÄôEt√†: Se non consideriamo l‚Äôet√† (\\(Z\\)) nell‚Äôanalisi, potremmo erroneamente concludere che esiste una relazione diretta tra il numero di scarpe (\\(X\\)) e le abilit√† matematiche (\\(Y\\)), dato che entrambi aumentano nel tempo. Tuttavia, questa correlazione non implica una relazione causale diretta tra il numero di scarpe e le abilit√† matematiche, ma √® piuttosto il risultato dell‚Äôinfluenza dell‚Äôet√†.\nConsiderando l‚ÄôEt√†: Una volta che l‚Äôet√† viene inclusa nell‚Äôanalisi come variabile confondente, diventa chiaro che qualsiasi correlazione osservata tra il numero di scarpe e le abilit√† matematiche √® spiegata dalla loro relazione comune con l‚Äôet√†. Stratificando per et√† o utilizzando metodi statistici per controllare l‚Äôeffetto dell‚Äôet√†, possiamo correttamente interpretare che non esiste una relazione causale diretta tra il numero di scarpe e le abilit√† matematiche.\nQuesto esempio illustra l‚Äôimportanza di identificare e controllare le variabili confondenti nelle analisi causali.\n\n\n16.8.3 Collider\nLa struttura causale nota come collider si verifica quando due variabili, \\(X\\) e \\(Y\\), convergono influenzando una terza variabile, \\(Z\\), formando una configurazione del tipo \\(X \\rightarrow Z \\leftarrow Y\\). In questo schema, \\(X\\) e \\(Y\\) sono indipendenti, il che significa che non esiste una relazione causale diretta o un‚Äôinfluenza reciproca evidente tra di loro. Sebbene entrambe influenzino \\(Z\\), non si pu√≤ dedurre l‚Äôesistenza di un legame causale diretto tra \\(X\\) e \\(Y\\) basandosi esclusivamente sulla loro comune influenza su \\(Z\\).\nEsempio. Consideriamo quali variabili, il talento musicale, il supporto familiare e il successo in una carriera musicale.\nVariabili: - \\(X\\): Talento Musicale - \\(Y\\): Supporto Familiare - \\(Z\\): Successo nella Carriera Musicale\nRelazione Causale: In questo esempio, sia il talento musicale (\\(X\\)) che il supporto familiare (\\(Y\\)) influenzano il successo nella carriera musicale (\\(Z\\)). Tuttavia, il talento musicale e il supporto familiare sono indipendenti l‚Äôuno dall‚Äôaltro. Non esiste una relazione causale diretta tra il talento musicale e il supporto familiare.\nSenza Considerare \\(Z\\): \\(X\\) e \\(Y\\) sono indipendenti (\\(X \\perp Y\\)). Il talento musicale e il supporto familiare non hanno alcuna influenza reciproca diretta.\nConsiderando \\(Z\\): Quando ci si concentra esclusivamente sulle persone che hanno raggiunto il successo musicale (\\(Z\\)), si potrebbe erroneamente percepire un‚Äôassociazione tra talento musicale e supporto familiare. Questo √® conosciuto come bias del collider. Questa associazione artificiale emerge perch√© stiamo selezionando un sottogruppo basato su \\(Z\\), che √® influenzato sia da \\(X\\) che da \\(Y\\). Pertanto, quando si stratifica per \\(Z\\), \\(X\\) e \\(Y\\) appaiono associati (\\(X \\not\\perp Y \\mid Z\\)).\nIn sintesi,\n\nIndipendenza: \\(X\\) e \\(Y\\) sono indipendenti: \\(X \\perp Y\\).\nInfluenza: Sia \\(X\\) che \\(Y\\) influenzano \\(Z\\).\nAssociazione Spuria: Stratificando i dati in base a \\(Z\\), emerge un‚Äôassociazione spuria: \\(X \\not\\perp Y \\mid Z\\).\n\nIl bias del collider si verifica quando la selezione di casi basata su \\(Z\\) introduce un‚Äôassociazione artificiale tra \\(X\\) e \\(Y\\), che non riflette le relazioni presenti nell‚Äôintera popolazione. Questo pu√≤ portare a interpretazioni errate e conclusioni fuorvianti.\n\n\n16.8.4 Il Discendente\nLa configurazione del discendente √® caratterizzata dalla presenza di una variabile, \\(Z\\), che riceve l‚Äôinfluenza da una variabile \\(X\\) e trasmette tale effetto a una variabile \\(Y\\). Inoltre, \\(Z\\) esercita un‚Äôinfluenza diretta su un‚Äôaltra variabile, \\(A\\). Pertanto, \\(Z\\) agisce sia come mediatore nella relazione causale tra \\(X\\) e \\(Y\\), sia come collegamento causale diretto con \\(A\\). La struttura risultante pu√≤ essere rappresentata come \\(X \\rightarrow Z \\rightarrow Y\\), con una ramificazione aggiuntiva da \\(Z\\) ad \\(A\\) (\\(Z \\rightarrow A\\)).\nEsempio. Consideriamo l‚Äôeffetto del supporto sociale sulla felicit√† attraverso l‚Äôautostima.\nVariabili: - \\(X\\): Supporto Sociale - \\(Z\\): Autostima - \\(Y\\): Felicit√† - \\(A\\): Livello di Stress\nRelazione Causale: Il supporto sociale (\\(X\\)) migliora l‚Äôautostima (\\(Z\\)), che a sua volta influisce sulla felicit√† (\\(Y\\)) e sul livello di stress (\\(A\\)). In questo caso, \\(Z\\) agisce come mediatore tra \\(X\\) e \\(Y\\) e ha un effetto diretto su \\(A\\).\nSenza Considerare \\(A\\): Concentrandosi sul percorso \\(X \\rightarrow Z \\rightarrow Y\\), si pu√≤ isolare l‚Äôeffetto del supporto sociale sulla felicit√† attraverso l‚Äôautostima, mantenendo chiara la relazione causale.\nConsiderando \\(A\\): Quando si include \\(A\\) nell‚Äôanalisi, si introduce complessit√† poich√© \\(A\\) pu√≤ aprire nuovi percorsi causali o introdurre bias, complicando l‚Äôinterpretazione dell‚Äôeffetto diretto di \\(X\\) su \\(Y\\). Se \\(A\\) ha un discendente \\(D\\) che funge da collider, influenzato sia da \\(A\\) che da una causa comune non osservata con \\(Y\\) (\\(U\\)), condizionare su \\(D\\) pu√≤ introdurre un bias aprendo un percorso non causale (\\(A \\rightarrow D \\leftarrow U \\rightarrow Y\\)). Questo esemplifica come l‚Äôinclusione di discendenti e colliders possa alterare l‚Äôinterpretazione degli effetti causali.\nIn sintesi,\n\n\\(X\\) e \\(Y\\) sono associati causalmente attraverso \\(Z\\): \\(X \\not\\perp Y\\).\n\\(A\\) fornisce informazioni su \\(Z\\).\nStratificando i dati in base ad \\(A\\), l‚Äôassociazione tra \\(X\\) e \\(Y\\) pu√≤ indebolirsi o scomparire: \\(X \\perp Y \\mid A\\).\n\nComprendere il ruolo dei discendenti e dei collider √® cruciale per evitare interpretazioni errate dei dati e per fare inferenze causali accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#considerazioni-conclusive",
    "href": "chapters/chapter_2/06_causality.html#considerazioni-conclusive",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.9 Considerazioni Conclusive",
    "text": "16.9 Considerazioni Conclusive\nNegli studi basati su dati osservazionali, districarsi tra le complesse maglie delle inferenze causali richiede un‚Äôacuta analisi e una particolare sensibilit√† verso vari aspetti critici del processo di ricerca. Ogni fase, dall‚Äôidentificazione dei fattori confondenti all‚Äôanalisi accurata dei percorsi causali, passando per la gestione dei mediatori e dei collider, fino alla valutazione della robustezza interna ed esterna degli studi, presenta sfide e opportunit√†.\nIl primo passo verso un‚Äôinterpretazione corretta dei dati osservazionali consiste nel saper riconoscere e gestire le variabili confondenti. Queste variabili, agendo su entrambe le variabili indipendenti e dipendenti, possono generare correlazioni ingannevoli che mascherano la vera natura delle relazioni in esame.\nL‚Äôuso dei DAG (Grafi Aciclici Diretti) emerge come uno strumento molto utile in questo contesto, offrendo una rappresentazione visiva dei percorsi causali e fornendo indicazioni preziose su come evitare trappole analitiche quali il sovracontrollo o il controllo inappropriato di variabili post-trattamento.\nQuando si tratta di mediatori e collider, il terreno si fa ancora pi√π insidioso. I mediatori, essendo ponti tra cause ed effetti, necessitano di una gestione oculata per non perdere di vista l‚Äôeffetto causale che si intende esplorare. Allo stesso tempo, √® fondamentale resistere alla tentazione di controllare indiscriminatamente i collider, poich√© ci√≤ pu√≤ aprire la porta a correlazioni spurie che distorcono la realt√† dei fenomeni studiati.\nLa questione del bilanciamento tra validit√† interna ed esterna ricorda che, sebbene gli esperimenti randomizzati possano offrire garanzie solide di validit√† interna, la loro capacit√† di generalizzare i risultati al mondo esterno ‚Äì la validit√† esterna ‚Äì non √® sempre garantita. Solo un approccio che valorizza la diversit√† metodologica, abbracciando tanto gli studi sperimentali quanto quelli osservazionali, pu√≤ rispondere in modo completo alle domande di ricerca.\nIn conclusione, per studiare con successo le dinamiche nascoste che regolano le relazioni tra le variabili, √® essenziale non solo un‚Äôattenta valutazione dei dati disponibili ma anche una profonda riflessione sulle strutture causali in gioco. Integrare diversi approcci di ricerca arricchisce la nostra comprensione e ci avvicina a conclusioni causali solide e generalizzabili.\nUn sommario ironico di questi concetti √® fornito nella vignetta di xkcd.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_2/06_causality.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_2/06_causality.html#informazioni-sullambiente-di-sviluppo",
    "title": "16¬† Causalit√† dai dati osservazionali",
    "section": "16.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "16.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\nseaborn   : 0.13.0\nscipy     : 1.11.4\nmatplotlib: 3.8.2\narviz     : 0.17.0\ngraphviz  : 0.20.1\npandas    : 2.1.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nDagan, Noa, Noam Barda, Eldad Kepten, Oren Miron, Shay Perchik, Mark Katz, Miguel Hern√°n, Marc Lipsitch, Ben Reis, e Ran Balicer. 2021. ¬´BNT162b2 mRNA Covid-19 Vaccine in a Nationwide Mass Vaccination Setting¬ª. New England Journal of Medicine 384 (15): 1412‚Äì23. https://doi.org/10.1056/NEJMoa2101765.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to Research Design and Causality. 1¬™ ed. Chapman & Hall. https://theeffectbook.net.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nPearl, Judea. 2009. Causality. Cambridge University Press.\n\n\nRiederer, Emily. 2021. ¬´Causal design patterns for data analysts¬ª, gennaio. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nRohrer, Julia M. 2018. ¬´Thinking clearly about correlations and causation: Graphical causal models for observational data¬ª. Advances in methods and practices in psychological science 1 (1): 27‚Äì42.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon Schwab, e Steven N Goodman. 2023. ¬´A New Look at P Values for Randomized Clinical Trials¬ª. NEJM Evidence 3 (1): EVIDoa2300003.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01_intro_prob.html",
    "href": "chapters/chapter_3/01_intro_prob.html",
    "title": "17¬† Introduzione al calcolo delle probabilit√†",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo alcuni concetti generali e fondamentali che sono cruciali per una comprensione dei metodi bayesiani. Ulteriori concetti legati alla probabilit√† verranno introdotti o approfonditi nei capitoli successivi, a seconda delle necessit√†. Tuttavia, per uno studio dettagliato della teoria delle probabilit√†, consiglio vivamente il libro ‚ÄúIntroduction to Probability‚Äù di Blitzstein e Hwang (2019).\nNel corso di questo capitolo, esploreremo varie concezioni della probabilit√†, tra cui la visione classica, frequentista e bayesiana. Approfondiremo anche argomenti come le variabili casuali, le funzioni di massa di probabilit√† e le funzioni di ripartizione. Inoltre, introdurremo la simulazione con Python per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell‚Äôambito della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Introduzione al calcolo delle probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "href": "chapters/chapter_3/01_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "title": "17¬† Introduzione al calcolo delle probabilit√†",
    "section": "17.1 Storia e definizioni della probabilit√†",
    "text": "17.1 Storia e definizioni della probabilit√†\nLa probabilit√† √® un modo formale di quantificare l‚Äôincertezza, assegnando plausibilit√† o credibilit√† a un insieme di possibilit√† mutuamente esclusive o risultati di un esperimento o osservazione.\n\n17.1.1 Che cos‚Äô√® la probabilit√†?\nCi sono due modi principali per interpretare la probabilit√†:\n\nFrequentista: Secondo il framework frequentista, la probabilit√† rappresenta il limite della frequenza relativa con cui un evento di interesse si verifica quando il numero di esperimenti condotti ripetutamente nelle stesse condizioni tende all‚Äôinfinito. In questa visione, chiamata ‚Äúontologica‚Äù, la probabilit√† √® considerata una propriet√† intrinseca del mondo, indipendente dalla nostra esperienza. La probabilit√† √® quindi vista come una caratteristica oggettiva della realt√†.\nBayesiana: Al contrario, il framework bayesiano interpreta la probabilit√† come una credenza soggettiva riguardo alla probabilit√† di accadimento di un evento. In questa prospettiva ‚Äúepistemica‚Äù, la probabilit√† √® una misura della nostra conoscenza del mondo piuttosto che una propriet√† oggettiva. Questa visione soggettiva della probabilit√† dipende dalle informazioni disponibili e dal punto di vista dell‚Äôosservatore.\n\n\n\n17.1.2 Storia della probabilit√†\nLa storia della probabilit√† √® lunga e complessa, come illustrato in varie opere (Tabak 2004, Stigler 1986, Weisberg 2014). L‚Äôorigine della probabilit√† moderna risale a una domanda posta da Antoine Gombaud (Chevalier de M√©r√©) a Blaise Pascal (1623‚Äì1662) su come dividere equamente le puntate di un gioco di carte interrotto.\n\n17.1.2.1 Problema dei punti\nIl problema pu√≤ essere formulato cos√¨:\n\nImmaginiamo due persone che partecipano a un gioco a pi√π round. In ogni round, entrambe le persone hanno la stessa probabilit√† di vincere. La prima persona che vince sei round consecutivi si aggiudicher√† un ricco premio in denaro. Supponiamo che A e B abbiano gi√† disputato sei round, con A che ha vinto cinque volte e B una volta. In quel momento, il gioco √® interrotto. Poich√© n√© A n√© B hanno raggiunto le sei vittorie, hanno deciso di dividere il premio. Ma qual √® il modo pi√π equo per farlo?\n\nLa discussione tra Pierre de Fermat (1607‚Äì1665) e Pascal ha portato alla formalizzazione dell‚Äôutilizzo della matematica per risolvere questo problema, proponendo di considerare le probabilit√† di vincita di ciascun giocatore. Ad esempio, se A ha una probabilit√† del 97% di vincere il premio e B ha una probabilit√† del 3%, sembrerebbe equo assegnare ad A il 97% del premio. L‚Äôinteresse pubblico per la loro corrispondenza √® sopravvissuto grazie al libro di Christian Huygens del 1657 ‚ÄúDe Ratiociniis in Ludo Aleae‚Äù (Sul Ragionamento nei Giochi di Dadi), che √® rimasto il riferimento per la probabilit√† per circa 50 anni.\n\n\n17.1.2.2 Sviluppi successivi\nIl libro postumo di Jacob Bernoulli, ‚ÄúL‚ÄôArte della Congettura‚Äù (1713), ha segnato una svolta nella storia della probabilit√†. Bernoulli ha definito la probabilit√† come un indice di incertezza compreso tra 0 e 1 e ha collegato il calcolo della probabilit√† ai dati e alla frequenza a lungo termine di un evento, noto come legge dei grandi numeri. Bernoulli ha applicato la probabilit√† anche a settori diversi dal gioco d‚Äôazzardo, come la mortalit√† umana e la giustizia penale, creando la cosiddetta ‚Äúprobabilit√† soggettiva‚Äù.\n\n\n\n17.1.3 Interpretazione ‚Äúclassica‚Äù\nStoricamente, la prima definizione di probabilit√† √® stata proposta da Pierre-Simon Laplace (1749-1827), che si √® avvalso del calcolo combinatorio. Secondo Laplace, la probabilit√†\\(P\\)di un evento √® definita come il rapporto tra il numero di casi in cui l‚Äôevento si verifica e il numero totale di casi possibili. In questa definizione, un evento √® qualcosa a cui √® possibile assegnare un valore di verit√†, ovvero qualcosa che pu√≤ essere vero o falso. Ad esempio, la probabilit√† di ottenere un 3 in un lancio di un singolo dado √® 1/6 ‚âÉ 0.17, poich√© c‚Äô√® un solo caso favorevole (il lancio ha prodotto un 3) su sei casi possibili (i numeri da 1 a 6). Tuttavia, questa definizione √® insoddisfacente in quanto si basa sull‚Äôassunzione che ogni evento sia equiprobabile, il che non √® sempre vero. Inoltre, questa definizione √® circolare poich√© per definire il concetto di probabilit√†, √® necessario prima definire cosa significa che gli eventi siano equiprobabili, e quindi si deve gi√† conoscere il concetto di probabilit√†.\n\n\n17.1.4 Interpretazione frequentista\nUn secondo tentativo di definire la probabilit√† (dopo quello ‚Äúclassico‚Äù di Laplace) si basa sull‚Äôapproccio frequentista, che pu√≤ essere attribuito a molti autori. In questo approccio, la probabilit√† √® definita sulla base delle frequenze osservate dell‚Äôoccorrenza di un evento. Questo approccio nasce dalla difficolt√† di assegnare una probabilit√† agli eventi assumendo il principio di equiprobabilit√†, come nel caso delle monete, dei dadi o delle carte di un mazzo. Sebbene la probabilit√† di ottenere testa come risultato del lancio di un dado sia 1/2 se crediamo che la moneta sia bilanciata, se cos√¨ non fosse non potremmo assegnare la stessa probabilit√† a tutti i risultati possibili. Tuttavia, possiamo stimare le probabilit√† come la frequenza\\(f_t\\), definita come il rapporto tra il numero di volte in cui un lancio ha prodotto ‚Äútesta‚Äù e il numero totale di lanci.\nSi osservi che l‚Äôosservazione della frequenza \\(f_t\\) √® solo un‚Äô approssimazione della probabilit√†, ma l‚Äôaccuratezza migliora all‚Äôaumentare del numero totale di lanci, \\(N\\). In linea di principio, la probabilit√† di ottenere ‚Äútesta‚Äù, \\(P(T)\\), √® il limite della frequenza \\(f_t\\) quando il numero totale di lanci \\(N\\) tende all‚Äôinfinito. Tuttavia, questa definizione richiede l‚Äôinfinita ripetizione di un esperimento, il che pu√≤ essere impraticabile o impossibile in molti casi. Inoltre, questa definizione assume che gli eventi futuri siano simili agli eventi passati, il che non √® sempre garantito.\n\ndef coin_flips(n, run_label):\n    # Genera un array di 0 e 1 dove 1 rappresenta 'testa' e 0 'croce'\n    # usando una distribuzione binomiale.\n    heads = np.random.binomial(1, 0.5, n)\n    \n    # Calcola la proporzione cumulativa di teste.\n    flips = np.arange(1, n + 1) \n    proportion_heads = np.cumsum(heads) / flips\n    \n    # Crea un DataFrame per un facile accesso e visualizzazione dei dati.\n    df = pd.DataFrame({'flips': flips, 'proportion_heads': proportion_heads, 'run': run_label})\n\n    return df\n\nn = 1000\n\ndf = pd.concat([coin_flips(n, f'run{i+1}') for i in range(4)], axis=0)\nax = sns.lineplot(data = df, x = 'flips', y = 'proportion_heads', hue = 'run')\n\n\n\n\n\n\n\n\n\n\n17.1.5 La Legge dei Grandi Numeri\nLa simulazione precedente fornisce un esempio della Legge dei grandi numeri. La Legge dei Grandi Numeri afferma che, man mano che il numero di esperimenti casuali ripetuti aumenta, la stima della probabilit√† di un evento \\(P(Y=y)\\) diventa sempre pi√π accurata.\nIl teorema sostiene che, con l‚Äôaumento del numero di ripetizioni di un esperimento casuale, la media dei risultati osservati tende a convergere al valore atteso teorico della variabile casuale. In altre parole, la media empirica dei risultati osservati si avvicina sempre di pi√π al valore medio teorico.\nQuesta legge √® cruciale perch√© garantisce che, con un numero sufficientemente grande di prove, la stima empirica della probabilit√† di un evento si avvicina al valore reale. Questo rende le stime probabilistiche pi√π precise e affidabili.\nDal punto di vista pratico, la Legge dei Grandi Numeri consente di utilizzare modelli probabilistici per interpretare fenomeni reali. Anche se le osservazioni singole possono variare in modo casuale, la media delle osservazioni su un ampio numero di ripetizioni rifletter√† fedelmente le probabilit√† teoriche.\nFormalmente, data una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), ciascuna con media \\(\\mu\\), la Legge dei Grandi Numeri √® espressa come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{X_1 + X_2 + \\ldots + X_n}{n} - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) √® un valore positivo arbitrariamente piccolo e \\(P(\\cdot)\\) indica la probabilit√†. Questo significa che, con un numero molto grande di ripetizioni, la media campionaria osservata sar√† vicina alla media teorica attesa, permettendo inferenze affidabili sulla probabilit√† degli eventi.\nIn sintesi, la Legge dei Grandi Numeri assicura che, aumentando il numero di prove, le stime empiriche delle probabilit√† diventano sempre pi√π precise, allineandosi con i valori teorici attesi.\n\n17.1.5.1 Problema del caso singolo\nNell‚Äôambito dell‚Äôapproccio frequentista alla probabilit√†, basato sulla concezione delle frequenze relative di eventi osservati su lunghe serie di ripetizioni, emerge un limite concettuale nel trattare la probabilit√† di eventi singolari e non ripetibili. Secondo questa prospettiva, infatti, non risulta rigorosamente appropriato discutere di probabilit√† relative a eventi unici e non replicabili nel tempo. Esempi emblematici di tali eventi includono la possibilit√† che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023 o che si verifichi pioggia a Firenze il giorno di Ferragosto del 2024. Questi scenari, essendo unici e circoscritti a un preciso momento storico, sfuggono alla logica frequentista che richiede, per definizione, la possibilit√† di osservazione ripetuta degli eventi per valutarne la probabilit√†. Nonostante ci√≤, nel linguaggio comune non specialistico, √® comune l‚Äôuso del termine ‚Äúprobabilit√†‚Äù per riferirsi anche a tali eventi specifici e non ripetibili, evidenziando cos√¨ una discrepanza tra l‚Äôuso tecnico e quello colloquiale del concetto di probabilit√†.\n\n\n\n17.1.6 Collegamento tra probabilit√† e statistica\nDurante gli anni ‚Äô20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l‚Äôinferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significativit√†, i metodi di campionamento, l‚Äôanalisi della varianza e il disegno sperimentale.\nNegli anni ‚Äô30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull‚Äôinterpretazione frequentista della probabilit√†. Definirono due tipologie di errori decisionali e utilizzarono il test di significativit√† di Fisher, interpretando i valori\\(p\\)come indicatori dei tassi di errore a lungo termine.\n\n\n17.1.7 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della ‚Äúprobabilit√† inversa‚Äù (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l‚Äôinferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell‚Äôutilizzo dell‚Äôinferenza basata sul metodo della probabilit√† inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato ‚ÄúTheory of Probability‚Äù rappresent√≤ una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ‚Äô80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell‚Äôapproccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n17.1.8 Interpretazione soggettivista\nUna visione alternativa della probabilit√† la considera come una credenza soggettiva. De Finetti (2017) ha proposto un‚Äôinterpretazione in cui la probabilit√† non √® vista come una caratteristica oggettiva degli eventi, ma piuttosto come una misura della credenza soggettiva, suggerendo di trattare \\(p(¬∑)\\) come una probabilit√† soggettiva. √à interessante notare che de Finetti era un soggettivista radicale. Infatti, la frase di apertura del suo trattato in due volumi sulla probabilit√† afferma che ‚ÄúLa probabilit√† non esiste‚Äù, intendendo che la probabilit√† non ha uno status oggettivo, ma rappresenta piuttosto la quantificazione della nostra esperienza di incertezza. Riteneva che l‚Äôidea di una probabilit√† esterna all‚Äôindividuo, con uno status oggettivo, fosse pura superstizione, paragonabile al credere in ‚ÄúEtere cosmico, Spazio e Tempo assoluti, ‚Ä¶, o Fate e Streghe‚Ä¶‚Äù. Secondo de Finetti, ‚Äú‚Ä¶ esistono solo probabilit√† soggettive - cio√®, il grado di credenza nell‚Äôoccorrenza di un evento attribuito da una determinata persona in un dato momento con un dato insieme di informazioni.‚Äù\nCome sottolineato da Press (2009), la prima menzione della probabilit√† come grado di credenza soggettiva fu fatta da Ramsey (1926), ed √® questa nozione di probabilit√† come credenza soggettiva che ha portato a una notevole resistenza alle idee bayesiane. Una trattazione dettagliata degli assiomi della probabilit√† soggettiva si trova in Fishburn (1986).\nLa denominazione ‚Äúsoggettivo‚Äù legata alla probabilit√† potrebbe risultare infelice, poich√© potrebbe suggerire un ragionamento vago o non scientifico. Lindley (2013) condivide queste riserve, proponendo l‚Äôalternativa ‚Äúprobabilit√† personale‚Äù rispetto a ‚Äúprobabilit√† soggettiva‚Äù. Analogamente, Howson e Urbach (2006) preferiscono utilizzare l‚Äôespressione ‚Äúprobabilit√† epistemica‚Äù, che riflette il grado di incertezza di un individuo di fronte al problema trattato. In sostanza, la probabilit√† epistemica si riferisce all‚Äôincertezza personale riguardo a variabili sconosciute. Questa terminologia viene adottata anche nel testo di Kaplan (2023), fornendo un linguaggio pi√π neutro per discutere di questi concetti.\nVa inoltre notato che l‚Äôinterpretazione soggettiva si adatta bene a eventi singoli, permettendo di esprimere una convinzione su eventi specifici, come la probabilit√† di pioggia in un dato giorno o l‚Äôesito di una competizione sportiva.\n\n\n17.1.9 Nota\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli‚Äôs Fallacy (Clayton 2021) offre un‚Äôintroduzione molto leggibile alle tematiche della definizione della probabilit√† nella storia della scienza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Introduzione al calcolo delle probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01_intro_prob.html#definizioni-e-assiomi",
    "href": "chapters/chapter_3/01_intro_prob.html#definizioni-e-assiomi",
    "title": "17¬† Introduzione al calcolo delle probabilit√†",
    "section": "17.2 Definizioni e assiomi",
    "text": "17.2 Definizioni e assiomi\nIndipendentemente dalla controversia in corso sulla sua interpretazione, la probabilit√† √® stata stabilita come teoria matematica dal matematico sovietico Andrey Kolmogorov all‚Äôinizio del XX secolo. Poich√© sia i frequentisti che i bayesiani utilizzano questa teoria matematica, il disaccordo riguarda l‚Äôinterpretazione e non la matematica.\n√à possibile definire la probabilit√† utilizzando i seguenti tre concetti: esperimento, spazio campionario ed evento.\n\n17.2.1 Esperimenti casuali ed eventi\nSia i fenomeni deterministici che quelli stocastici influenzano la nostra vita quotidiana, determinando le dinamiche degli eventi che ci circondano.\n\nUn fenomeno deterministico produce sempre lo stesso risultato ogni volta che viene ripetuto nelle stesse condizioni. Ad esempio, se riscaldiamo l‚Äôacqua a 100¬∞C a livello del mare, essa bollir√† sempre.\nUn fenomeno casuale √® caratterizzato da condizioni in cui il risultato non pu√≤ essere determinato con certezza prima che si verifichi. In altre parole, ogni volta che il processo o l‚Äôesperimento viene ripetuto, si osserva uno tra i vari possibili risultati. Ad esempio, quando si lancia una moneta, l‚Äôesito pu√≤ essere testa (T) o croce (C), ma non si pu√≤ conoscere in anticipo quale sar√†.\n\nNella teoria delle probabilit√†, un esperimento casuale √® un processo o una situazione in cui il risultato non pu√≤ essere previsto con certezza prima dell‚Äôesecuzione dell‚Äôesperimento. Per poter analizzare correttamente gli esperimenti casuali, sono fondamentali alcune nozioni chiave, come indicato nelle sezioni successive.\n\n\n17.2.2 Spazi Campionari ed Eventi\nLo spazio campionario \\(\\Omega\\) √® l‚Äôinsieme degli esiti possibili di un esperimento. I punti\\(\\omega\\)in\\(\\Omega\\)sono chiamati esiti campionari o realizzazioni.\nAd esempio, se lanciamo un dado a 6 facce, lo spazio campionario √® costituito dai sei possibili risultati, Œ© = {1, 2, 3, 4, 5, 6}. Diversi esperimenti casuali hanno spazi campionari differenti che possono essere rappresentati in modo equivalente. Ad esempio:\n\nLancio di una moneta: Œ© = {T, C}\nLancio di due monete: Œ© = {TT, TC, CT, CC}\n\nGli eventi sono sottoinsiemi di\\(\\Omega\\).\nUn evento √® denotato da una lettera maiuscola come A, B, o C. Ad esempio, nel caso del lancio di un dado, l‚Äôevento ‚Äúnumero pari‚Äù pu√≤ essere rappresentato da A = {2, 4, 6}, che √® un sottoinsieme di Œ© (A ‚äÇ Œ©), e l‚Äôevento ‚Äúnumero dispari‚Äù da B = {1, 3, 5}, anch‚Äôesso un sottoinsieme di Œ© (B ‚äÇ Œ©).\nSe un evento √® costituito da un singolo risultato dello spazio campionario, √® detto evento elementare. Ad esempio, l‚Äôevento di ottenere il numero 1 nel lancio di un dado, denotato come A = {1}. Se un evento √® costituito da pi√π risultati dello spazio campionario, √® detto evento composto, come l‚Äôevento di ottenere un numero pari nel lancio di un dado, A = {2, 4, 6}.\nDato un evento\\(A\\), sia \\(A^c = \\{ \\omega \\in \\Omega : \\text{non } (\\omega \\in A) \\}\\) il complemento di \\(A\\). Il complemento di\\(\\Omega\\)√® l‚Äôinsieme vuoto \\(\\varnothing\\).\nL‚Äôunione degli eventi\\(A\\)e\\(B\\)√® definita come \\(A \\cup B = \\{ \\omega \\in \\Omega : \\omega \\in A \\text{ o } \\omega \\in B \\}\\). Se\\(A_1, A_2, \\dots\\)√® una sequenza di insiemi, allora\n\\[\\cup_{i=1}^\\infty A_i = \\left\\{ \\omega \\in \\Omega : \\omega \\in A_i \\text{ per qualche } i \\right\\}\\]\nL‚Äôintersezione di \\(A\\) e \\(B\\) √® \\(A \\cap B = \\{ \\omega \\in \\Omega : \\omega \\in A \\text{ e } \\omega \\in B \\}\\). Se \\(A_1, A_2, \\dots\\) √® una sequenza di insiemi, allora\n\\[\\cap_{i=1}^\\infty A_i = \\left\\{ \\omega \\in \\Omega : \\omega \\in A_i \\text{ per tutti } i \\right\\}\\]\nSia \\(A - B = \\left\\{ \\omega \\in \\Omega : \\omega \\in A \\text{ e non } (\\omega \\in B) \\right\\}\\). Se ogni elemento di \\(A\\) √® contenuto in \\(B\\), scriviamo \\(A \\subset B\\)o\\(B \\supset A\\). Se \\(A\\) √® un insieme finito, sia \\(|A|\\) il numero di elementi in \\(A\\).\n\n\n\n\n\n\n\nNotazione\nSignificato\n\n\n\n\n\\(\\Omega\\)\nspazio campionario\n\n\n\\(\\omega\\)\nesito\n\n\n\\(A\\)\nevento (sottoinsieme di\\(\\Omega\\))\n\n\n\\(\\vert A \\vert\\)\nnumero di elementi in\\(A\\)(se finito)\n\n\n\\(A^c\\)\ncomplemento di\\(A\\)(non\\(A\\))\n\n\n\\(A \\cup B\\)\nunione (\\(A\\)o\\(B\\))\n\n\n\\(A \\cap B\\)o\\(AB\\)\nintersezione (\\(A\\)e\\(B\\))\n\n\n\\(A - B\\)\ndifferenza insiemistica (punti in\\(A\\)ma non in\\(B\\))\n\n\n\\(A \\subset B\\)\ninclusione insiemistica (\\(A\\)√® un sottoinsieme di\\(B\\))\n\n\n\\(\\varnothing\\)\nevento nullo (sempre falso)\n\n\n\\(\\Omega\\)\nevento certo (sempre vero)\n\n\n\nDiciamo che\\(A_1, A_2, \\dots\\)sono disgiunti o mutuamente esclusivi se\\(A_i \\cap A_j = \\varnothing\\)ogni volta che\\(i \\neq j\\).\nUna partizione di\\(\\Omega\\)√® una sequenza di insiemi disgiunti\\(A_1, A_2, \\dots\\)tale che\\(\\cup_{i=1}^\\infty A_i = \\Omega\\).\nDato un evento\\(A\\), definiamo la funzione indicatrice di\\(A\\) come\n\\[I_A(\\omega) = I(\\omega \\in A) = \\begin{cases}\n1 &\\text{se } \\omega \\in A \\\\\n0 &\\text{altrimenti}\n\\end{cases}\n\\]\nUna sequenza di insiemi \\(A_1, A_2, \\dots\\) √® monotona crescente se \\(A_1 \\subset A_2 \\subset \\dots\\), e definiamo \\(\\lim_{n \\rightarrow \\infty} A_n = \\cup_{i=1}^\\infty A_i\\). Una sequenza di insiemi \\(A_1, A_2, \\dots\\) √® monotona decrescente se \\(A_1 \\supset A_2 \\supset \\dots\\) e allora definiamo \\(\\lim_{n \\rightarrow \\infty} A_n = \\cap_{i=1}^n A_i\\). In entrambi i casi, scriveremo \\(A_n \\rightarrow A\\).\n\n\n17.2.3 Probabilit√†\nLa probabilit√† di un evento √® una misura numerica che indica la possibilit√† che tale evento si verifichi. Nel caso del lancio di una moneta, la probabilit√† di ottenere testa √® 1/2, cos√¨ come la probabilit√† di ottenere croce. I valori di probabilit√† P(A) = 0 rappresentano eventi impossibili, mentre P(A) = 1 rappresentano eventi certi.\nPer denotare la probabilit√† che un evento A non si verifichi, possiamo usare la notazione P(¬¨A) o P(AÃÖ), dove P(AÃÖ) = 1 - P(A).\n\n\n17.2.4 Gli Assiomi di Kolmogorov\nUna funzione \\(\\mathbb{P}\\) che assegna un numero reale \\(\\mathbb{P}(A)\\) a ogni evento \\(A\\) √® una distribuzione di probabilit√† o una misura di probabilit√† se soddisfa i seguenti tre assiomi:\n\nAssioma 1. La probabilit√† di un evento \\(A\\) √® un numero non negativo: \\(\\mathbb{P}(A) \\geq 0\\) per ogni \\(A\\).\nAssioma 2. La probabilit√† di tutti i possibili esiti, o spazio campionario \\(\\Omega\\), √® pari a uno: \\(\\mathbb{P}(\\Omega) = 1\\).\nAssioma 3. Se \\(A_1, A_2, \\dots\\) sono disgiunti (mutuamente esclusivi) allora\n\n\\[\\mathbb{P} \\left( \\cup_{i=1}^\\infty A_i \\right) = \\sum_{i=1}^\\infty \\mathbb{P}(A_i).\\]\nI primi due assiomi insieme implicano che la probabilit√† varia da 0 a 1. Per comprendere l‚Äôultimo assioma, consideriamo il concetto di eventi mutuamente esclusivi, ossia due eventi, \\(A\\) e \\(B\\), che non condividono alcun risultato. In questo caso, possiamo applicare la regola dell‚Äôaddizione per concludere che \\(P(A \\cup B) = P(A) + P(B)\\).\n\n# Creare una nuova figura\nfig, ax = plt.subplots()\n\n# Creare cerchi per A e B\ncircle_A = patches.Circle((0.3, 0.5), 0.2, edgecolor='blue', facecolor='lightblue', alpha=0.5)\ncircle_B = patches.Circle((0.5, 0.5), 0.2, edgecolor='blue', facecolor='lightblue', alpha=0.5)\n\n# Aggiungere cerchi alla trama\nax.add_patch(circle_A)\nax.add_patch(circle_B)\n\n# Aggiungere etichette per A, B e le regioni\nax.text(0.2, 0.7, 'A', fontsize=12, ha='center')\nax.text(0.6, 0.7, 'B', fontsize=12, ha='center')\nax.text(0.4, 0.5, 'A ‚à© B', fontsize=12, ha='center', color='black')\nax.text(0.15, 0.5, 'A ‚à© B^c', fontsize=12, ha='center', color='black')\nax.text(0.7, 0.5, 'B ‚à© A^c', fontsize=12, ha='center', color='black')\n\n# Impostare i limiti dell'asse\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\n\n# Rimuovere assi\nax.axis('off')\n\n# Mostrare la trama\nplt.show()\n\n\n\n\n\n\n\n\nOra, consideriamo due eventi che non sono mutuamente esclusivi perch√© condividono un risultato. In questo caso, la regola dell‚Äôaddizione non si applica perch√© sia \\(A\\) che \\(B\\) contengono alcuni stessi risultati. Per eventi che non sono mutuamente esclusivi, possiamo applicare la seguente regola generale dell‚Äôaddizione:\nPer qualsiasi evento dato\\(A\\)e\\(B\\), la regola dell‚Äôaddizione √® data da:\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B).\\]\nUsando il terzo assioma della probabilit√†, abbiamo:\n\\[P(A \\cup B) = P(A \\cap B^c) + P(B \\cap A^c) + P(A \\cap B).\\]\nQuando \\(A\\) e \\(B\\) sono mutuamente esclusivi, \\(P(A \\cap B^c)\\) e \\(P(B \\cap A^c)\\) si riducono a \\(P(A)\\) e \\(P(B)\\) rispettivamente. Inoltre, abbiamo \\(P(A \\cap B) = 0\\) in questo caso di mutua esclusivit√†.\nInfine, notiamo che l‚Äôevento \\(A\\) pu√≤ essere scomposto in due eventi mutuamente esclusivi, \\({A \\cap B}\\) (regione sovrapposta) e \\({A \\cap B^c}\\) (regione non sovrapposta). Questo √® chiamato legge della probabilit√† totale. Per qualsiasi evento dato \\(A\\) e \\(B\\), la legge della probabilit√† totale √® data da:\n\\[P(A) = P(A \\cap B) + P(A \\cap B^c).\\]\nSecondo la legge della probabilit√† totale, possiamo scrivere \\(P(A \\cap B^c) = P(A) - P(A \\cap B)\\) sottraendo \\(P(A \\cap B)\\) da entrambi i lati dell‚Äôequazione. Analogamente, la legge della probabilit√† totale pu√≤ essere applicata all‚Äôevento \\(B\\), ottenendo \\(P(B \\cap A^c) = P(B) - P(A \\cap B)\\). Sostituendo questi risultati nell‚Äôequazione precedente e semplificando l‚Äôespressione, si arriva alla regola generale dell‚Äôaddizione. Sottolineiamo che questo risultato √® ottenuto utilizzando solo gli assiomi della probabilit√†.\nAlcune propriet√† che possono essere derivate dagli assiomi:\n\n\\(\\mathbb{P}(\\varnothing) = 0\\),\n\\(A \\subset B \\Rightarrow \\mathbb{P}(A) \\leq \\mathbb{P}(B)\\),\n\\(0 \\leq \\mathbb{P}(A) \\leq 1\\),\n\\(\\mathbb{P}\\left(A^c\\right) = 1 - \\mathbb{P}(A)\\),\n\\(A \\cap B = \\varnothing \\Rightarrow \\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B)\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Introduzione al calcolo delle probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01_intro_prob.html#elementi-di-calcolo-combinatorio",
    "href": "chapters/chapter_3/01_intro_prob.html#elementi-di-calcolo-combinatorio",
    "title": "17¬† Introduzione al calcolo delle probabilit√†",
    "section": "17.3 Elementi di calcolo combinatorio",
    "text": "17.3 Elementi di calcolo combinatorio\n\n17.3.1 Permutazioni\nQuando ogni risultato √® ugualmente probabile, per calcolare la probabilit√† di un evento \\(A\\), √® necessario contare il numero di elementi nell‚Äôevento \\(A\\) e il numero totale di elementi nello spazio campionario:\n\\[\\mathbb{P}(A) = \\frac{|A|}{|\\Omega|}.\\]\nOra introduciamo una tecnica di conteggio utile, chiamata permutazioni. Le permutazioni si riferiscono al numero di modi in cui gli oggetti possono essere disposti. Ad esempio, consideriamo tre oggetti distinti A, B e C. Ci sono 6 modi diversi per disporli: {ABC, ACB, BAC, BCA, CAB, CBA}.\nCome possiamo calcolare il numero di permutazioni senza enumerare ogni disposizione, specialmente quando il numero di oggetti √® grande? C‚Äô√® un modo semplice per farlo. Consideriamo l‚Äôesempio di disporre tre oggetti, A, B e C. Prima di tutto, ci sono tre modi per scegliere il primo oggetto: A, B o C. Una volta scelto il primo oggetto, ci sono due modi per scegliere il secondo oggetto. Infine, rimane un solo modo per scegliere l‚Äôultimo oggetto. Possiamo concettualizzare questo processo come un albero, dove il numero totale di foglie √® uguale al numero di permutazioni. Per calcolare il numero di foglie, basta moltiplicare sequenzialmente il numero di rami a ogni livello, cio√® \\(3 \\times 2 \\times 1\\).\nGeneralizzando questa idea, possiamo calcolare il numero di permutazioni di\\(k\\)oggetti su un insieme di \\(n\\) oggetti unici, denotato da \\(nPk\\) dove\\(k \\leq n\\), usando la seguente formula:\nIl numero di permutazioni di\\(k\\)oggetti su\\(n\\)oggetti unici √® dato da:\n\\[nPk = \\frac{n!}{(n - k)!}.\\]\nUn fattoriale √® definito come:\n\\[n! = n \\times (n - 1) \\times \\cdots \\times 2 \\times 1.\\]\nSi noti che \\(0!\\) √® definito come 1.\n\n17.3.1.1 Problema dei Compleanni\nIl problema dei compleanni √® un noto esempio controintuitivo di permutazioni. Il problema chiede quanti individui sono necessari affinch√© la probabilit√† che almeno due persone abbiano lo stesso compleanno superi 0.5, assumendo che ogni compleanno sia ugualmente probabile. Sorprendentemente, la risposta √® solo 23 persone, molto meno di quanto la maggior parte delle persone immagina.\nPer risolvere questo problema usando le permutazioni, notiamo la seguente relazione:\n\\[P(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - P(\\text{nessuno ha lo stesso compleanno}).\\]\nQuesta uguaglianza vale perch√© l‚Äôevento ‚Äúnessuno ha lo stesso compleanno‚Äù √® il complemento dell‚Äôevento ‚Äúalmeno due persone hanno lo stesso compleanno‚Äù. Questo significa che dobbiamo solo calcolare la probabilit√† che nessuno abbia lo stesso compleanno.\nSia \\(k\\) il numero di persone. Per calcolare la probabilit√† che nessuno abbia lo stesso compleanno, contiamo il numero di modi in cui \\(k\\) persone possono avere compleanni diversi. Poich√© ogni compleanno √® ugualmente probabile, possiamo usare le permutazioni per contare il numero di modi in cui \\(k\\) compleanni unici possono essere disposti su 365 giorni:\n\\[365Pk = \\frac{365!}{(365 - k)!}.\\]\nDividiamo questo numero per il numero totale di elementi nello spazio campionario, che √® il numero totale di modi in cui \\(k\\) compleanni non unici possono essere disposti su 365 giorni:\n\\[365^k .\\]\nQuindi, abbiamo:\n\\[P(\\text{nessuno ha lo stesso compleanno}) = \\frac{365Pk}{365^k} = \\frac{365!}{365^k (365 - k)!} .\\]\nInsieme alla precedente equazione, la soluzione al problema dei compleanni √®:\n\\[1 - \\frac{365!}{365^k (365 - k)!} .\\]\n\ndef birthday(k):\n    logdenom = k * math.log(365) + math.lgamma(365 - k + 1) # log denominatore\n    lognumer = math.lgamma(366) # log numeratore\n    pr = 1 - np.exp(lognumer - logdenom) # trasformazione inversa\n    return pr\n\nk = np.arange(1, 51)\nbday = [birthday(i) for i in k]\n\nplt.plot(k, bday, marker='o')\nplt.xlabel('Numero di persone')\nplt.ylabel('Probabilit√† che almeno due persone\\nabbiano lo stesso compleanno')\nplt.axhline(y=0.5, color='r', linestyle='-')\nplt.xlim(0, 50)\nplt.ylim(0, 1)\nplt.grid(True)\nplt.title('Probabilit√† del Problema dei Compleanni')\nplt.show()\n\nprint(\"Probabilit√† per 20-25 persone:\", bday[19:25])\n\n\n\n\n\n\n\n\nProbabilit√† per 20-25 persone: [0.41143838358049944, 0.44368833516523465, 0.47569530766240553, 0.507297234324024, 0.5383442579144757, 0.5686997039694264]\n\n\nOsserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno supera 0.5. Quando il numero di persone √® pi√π di 50, questa probabilit√† √® quasi 1.\n\n\n\n17.3.2 Campionamento con e senza reinserimento\nAbbiamo derivato una soluzione analitica esatta per il problema dei compleanni, ma possiamo anche produrre una soluzione approssimata utilizzando il metodo della simulazione Monte Carlo. Il nome deriva dal Casin√≤ di Monte Carlo a Monaco, ma possiamo semplicemente chiamarlo metodo di simulazione. La simulazione Monte Carlo √® una classe generale di metodi stocastici (contrariamente ai metodi deterministici) che possono essere utilizzati per risolvere approssimativamente problemi analitici generando casualmente le quantit√† di interesse.\nPer il problema dei compleanni, campioniamo\\(k\\)compleanni potenzialmente non unici su 365 giorni e verifichiamo se i\\(k\\) compleanni campionati sono tutti diversi. Utilizziamo il campionamento con reinserimento perch√© ad ogni estrazione ogni giorno dei 365 √® ugualmente probabile, indipendentemente dai giorni estratti in precedenza. In altre parole, il fatto che una persona sia nata in un certo giorno dell‚Äôanno non esclude che qualcun altro possa essere nato lo stesso giorno. Dopo aver ripetuto questa procedura di campionamento molte volte, calcoliamo la frazione di prove di simulazione in cui almeno due compleanni sono uguali, e questa frazione serve come stima della probabilit√† corrispondente. Questa procedura di simulazione √® intuitiva perch√© emula il processo di generazione dei dati descritto nel problema dei compleanni.\nPer implementare il campionamento con o senza reinserimento in Python, utilizziamo la funzione numpy.random.choice. Nel caso del campionamento con reinserimento, impostiamo l‚Äôargomento replace su True. Il campionamento senza reinserimento significa che, una volta campionato un elemento, questo non sar√† disponibile per estrazioni successive.\n\nk = 23  # numero di persone\nsims = 1000  # numero di simulazioni\nevent = 0  # contatore eventi\n\nfor _ in range(sims):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event += 1\n\n# frazione di prove in cui almeno due compleanni sono uguali\nanswer = event / sims\nprint(f\"Stima della probabilit√†: {answer}\")\n\n# Aumentare il numero di simulazioni a un milione per maggiore accuratezza\nsims_large = 1000000\nevent_large = 0\n\nfor _ in range(sims_large):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event_large += 1\n\nanswer_large = event_large / sims_large\nprint(f\"Stima con un milione di simulazioni: {answer_large}\")\n\nStima della probabilit√†: 0.509\nStima con un milione di simulazioni: 0.506191\n\n\nNel codice sopra, abbiamo impostato il numero di simulazioni a 1000. Aumentando il numero di simulazioni a un milione, otteniamo una stima pi√π accurata. Osserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno √® superiore a 0.5. Quando il numero di persone supera 50, questa probabilit√† √® vicina a 1.\nLa simulazione Monte Carlo √® una classe generale di procedure di campionamento casuale ripetuto utilizzate per risolvere approssimativamente problemi analitici. I metodi comunemente utilizzati includono il campionamento con reinserimento, in cui la stessa unit√† pu√≤ essere campionata ripetutamente, e il campionamento senza reinserimento, in cui ogni unit√† pu√≤ essere campionata al massimo una volta.\n\n\n17.3.3 Combinazioni\nIntroduciamo un‚Äôaltra utile tecnica di conteggio chiamata combinazioni. Le combinazioni sono simili alle permutazioni, ma ignorano l‚Äôordine degli elementi. In altre parole, le combinazioni rappresentano i modi di scegliere \\(k\\) elementi distinti da\\(n\\)elementi senza considerare l‚Äôordine. Ad esempio, scegliendo 2 elementi da 3 (A, B e C), le permutazioni sono 6 (AB, BA, AC, CA, BC, CB), mentre le combinazioni sono 3 (AB, AC, BC).\nPer calcolare le combinazioni, prima calcoliamo le permutazioni\\(nPk\\)e poi dividiamo per \\(k!\\). Questo perch√© ci sono \\(k!\\) modi per disporre \\(k\\) elementi in ordine diverso, ma tutte queste disposizioni contano come una singola combinazione. La formula generale per le combinazioni √®:\n\\[\nnCk = \\frac{n!}{k!(n-k)!} .\n\\]\n\n17.3.3.1 Esempio: Problema di una Commissione Psicologica\nSupponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual √® la probabilit√† che almeno 2 psicologi clinici siano nella commissione? Per calcolare questa probabilit√†, notiamo prima la seguente uguaglianza:\n\\[\nP(\\text{almeno 2 psicologi clinici}) = 1 - P(\\text{nessun psicologo clinico}) - P(\\text{esattamente 1 psicologo clinico}).\n\\]\nIl numero totale di modi per selezionare 5 persone dalla commissione su 20 √® dato da:\n\\[\n20C5 = \\frac{20!}{5!(15!)} = 15,504 .\n\\]\nIl numero di modi per avere nessun psicologo clinico nella commissione √®:\n\\[\n10C0 \\times 10C5 = 1 \\times 252 = 252 .\n\\]\nQuindi, la probabilit√† di avere nessun psicologo clinico √® \\(\\frac{252}{15,504} \\approx 0.016\\).\nIl numero di modi per avere esattamente 1 psicologo clinico nella commissione √®:\n\\[\n10C1 \\times 10C4 = 10 \\times 210 = 2,100 .\n\\]\nQuindi, la probabilit√† di avere esattamente 1 psicologo clinico √® \\(\\frac{2,100}{15,504} \\approx 0.135\\).\nLa probabilit√† di avere almeno 2 psicologi clinici nella commissione √® quindi:\n\\[\nP(\\text{almeno 2 psicologi clinici nella commissione}) = 1 - 0.016 - 0.135 = 0.849 .\n\\]\n\n# Funzione per calcolare le combinazioni\ndef nCk(n, k):\n    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n\n# Calcolo delle probabilit√† per il problema della commissione\ntotal_ways = nCk(20, 5)\nno_clinical = nCk(10, 0) * nCk(10, 5)\none_clinical = nCk(10, 1) * nCk(10, 4)\n\np_no_clinical = no_clinical / total_ways\np_one_clinical = one_clinical / total_ways\n\np_at_least_two_clinical = 1 - p_no_clinical - p_one_clinical\n\nprint(f\"Probabilit√† di almeno 2 psicologi clinici: {p_at_least_two_clinical:.3f}\")\n\nProbabilit√† di almeno 2 psicologi clinici: 0.848\n\n\n\n\n17.3.3.2 Esempio: Problema del Messaggio di Schwarzenegger\nConsideriamo un incidente del 2009 quando il Governatore della California Arnold Schwarzenegger invi√≤ un messaggio all‚Äôassemblea statale riguardo il veto al disegno di legge 1176. Questo messaggio formava un‚Äôacrostico volgare con le prime lettere di ogni riga.\n\n\n\n\n\n\nFigura¬†17.1: Il Messaggio di Schwarzenegger.\n\n\n\nQual √® la probabilit√† che questo acrostico sia stato casuale?\nSupponiamo che il messaggio sia stato diviso in 7 righe in modo casuale. Per ottenere 7 righe, devono essere inseriti 6 interruzioni di riga in 84 spazi possibili (prima della seconda parola, terza parola, ecc.). Il numero di modi per inserire 6 interruzioni in 84 spazi √® dato da:\n\\[\n84C6 = \\frac{84!}{6!(78!)} \\approx 406,481,544 .\n\\]\nTuttavia, ci sono solo 12 modi per produrre questo particolare acrostico. Quindi, la probabilit√† che questo acrostico si verifichi casualmente √®:\n\\[\n\\frac{12}{84C6} \\approx \\frac{12}{406,481,544} \\approx 1 \\text{ su } 34,000,000 .\n\\]\n\n# Calcolo del numero di combinazioni\ntotal_ways_acrostic = nCk(84, 6)\nacrostic_ways = 12\n\np_acrostic = acrostic_ways / total_ways_acrostic\nprint(f\"Probabilit√† dell'acrostico: {p_acrostic:.2e}\")\n\nProbabilit√† dell'acrostico: 2.95e-08\n\n\nQuesta analisi suggerisce che, secondo questo modello probabilistico, la ‚Äúcoincidenza‚Äù √® un evento altamente improbabile.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Introduzione al calcolo delle probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01_intro_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/01_intro_prob.html#commenti-e-considerazioni-finali",
    "title": "17¬† Introduzione al calcolo delle probabilit√†",
    "section": "17.4 Commenti e considerazioni finali",
    "text": "17.4 Commenti e considerazioni finali\nIn questo capitolo, abbiamo esplorato i fondamenti della teoria delle probabilit√†, tra cui la costruzione dello spazio campione per gli esperimenti casuali e le propriet√† fondamentali della probabilit√†. Abbiamo imparato a calcolare le probabilit√† degli eventi in uno spazio campione discreto. Inoltre, abbiamo introdotto il concetto di simulazione come metodo per approssimare le distribuzioni di probabilit√† empiriche quando non √® possibile ottenere soluzioni analitiche.\nLa teoria delle probabilit√† √® essenziale per la statistica e ha diverse applicazioni pratiche, tra cui la psicologia. Comprendere le probabilit√† ci consente di prendere decisioni informate in situazioni incerte e di sviluppare previsioni affidabili. Con una solida comprensione delle nozioni di base della probabilit√†, possiamo affrontare una vasta gamma di problemi e prendere decisioni basate sulla probabilit√† dei risultati possibili. Tuttavia, √® fondamentale ricordare che i modelli probabilistici sono solo approssimazioni della realt√† e possono essere influenzati da semplificazioni e limitazioni dei dati disponibili. Pertanto, √® importante esercitare cautela nell‚Äôinterpretazione dei risultati e comprendere le assunzioni alla base delle analisi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Introduzione al calcolo delle probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "17¬† Introduzione al calcolo delle probabilit√†",
    "section": "17.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "17.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nDe Finetti, Bruno. 2017. Theory of probability: A critical introductory treatment. Vol. 6. John Wiley & Sons.\n\n\nFishburn, Peter C. 1986. ¬´The axioms of subjective probability¬ª. Statistical Science 1 (3): 335‚Äì45.\n\n\nHowson, Colin, e Peter Urbach. 2006. Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, David. 2023. Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, Dennis V. 2013. Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S James. 2009. Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, Frank P. 1926. ¬´Truth and probability¬ª. In Readings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Introduzione al calcolo delle probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html",
    "href": "chapters/chapter_3/02_conditional_prob.html",
    "title": "18¬† Probabilit√† condizionata",
    "section": "",
    "text": "Introduzione\nUn principio fondamentale nel campo della probabilit√† √® il concetto di condizionamento. Il condizionamento si verifica quando, all‚Äôinterno di un esperimento aleatorio, le probabilit√† vengono calcolate focalizzandosi esclusivamente su un sottoinsieme specifico dei risultati possibili. In pratica, questo significa che la probabilit√† viene determinata tenendo conto solo di quei risultati che rientrano in un certo criterio o condizione predefinita.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/chapter_3/02_conditional_prob.html#indipendenza-stocastica",
    "title": "18¬† Probabilit√† condizionata",
    "section": "18.1 Indipendenza Stocastica",
    "text": "18.1 Indipendenza Stocastica\nNel contesto della probabilit√† condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilit√† in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull‚Äôaltro.\n\n18.1.1 Indipendenza di Due Eventi\nDue eventi \\(A\\) e \\(B\\) sono detti indipendenti se il verificarsi di uno non influenza la probabilit√† di verificarsi dell‚Äôaltro. Formalmente, questa condizione √® espressa come:\n\\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B),\\]\ndove \\(\\mathbb{P}(A \\cap B)\\) rappresenta la probabilit√† che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino simultaneamente.\nSe questa condizione √® soddisfatta, scriviamo \\(A \\text{ ‚´´ } B\\), il che significa ‚ÄúA √® indipendente da B‚Äù.\n\n\n18.1.2 Indipendenza di un Insieme di Eventi\nL‚Äôindipendenza stocastica √® un concetto fondamentale nell‚Äôapplicazione della probabilit√† in campo statistico. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) √® detto indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilit√† dell‚Äôintersezione degli eventi nel sottoinsieme \\(J\\) √® uguale al prodotto delle loro singole probabilit√†. Formalmente:\n\\[\\mathbb{P} \\left( \\cap_{i \\in J} A_i \\right) = \\prod_{i \\in J} \\mathbb{P}(A_i).\\]\nQuesto significa che ogni combinazione finita di eventi nell‚Äôinsieme √® indipendente.\nL‚Äôindipendenza pu√≤ essere assunta o derivata a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perch√© questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l‚Äôindipendenza pu√≤ essere derivata dai dati o da altre propriet√† del modello.\n\n\n18.1.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cio√® \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno una probabilit√† positiva di verificarsi, allora non possono essere indipendenti. Questo perch√© per eventi disgiunti con \\(\\mathbb{P}(A) &gt; 0\\) e \\(\\mathbb{P}(B) &gt; 0\\), l‚Äôequazione di indipendenza \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) non pu√≤ essere soddisfatta, dato che \\(\\mathbb{P}(A \\cap B) = 0\\) e \\(\\mathbb{P}(A) \\mathbb{P}(B) &gt; 0\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#sec-v",
    "href": "chapters/chapter_3/02_conditional_prob.html#sec-v",
    "title": "18¬† Probabilit√† condizionata",
    "section": "18.2 Probabilit√† condizionata su altri eventi",
    "text": "18.2 Probabilit√† condizionata su altri eventi\nLa probabilit√† di un evento √® intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilit√† specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilit√† associata all‚Äôevento verr√† corrispondentemente aggiornata.\nIn realt√†, tutte le probabilit√† possono essere intese come probabilit√† condizionate, anche quando la variabile o l‚Äôevento condizionante non √® esplicitamente specificato. Ci√≤ implica che le probabilit√† sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.\nQuesto quadro concettuale ci induce a considerare le probabilit√† come una ‚Äòmisura di plausibilit√†‚Äô che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell‚Äôacquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilit√†, e quindi la probabilit√† attribuita agli eventi, pu√≤ essere rivista.\n\nTeorema 18.1 Siano \\(A\\) e \\(B\\) due eventi definiti su uno spazio campionario \\(S\\). Supponendo che l‚Äôevento \\(B\\) si verifichi, la probabilit√† condizionata di \\(A\\) dato \\(B\\) √® data da\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{per}\\, P(B) &gt; 0,\n\\tag{18.1}\\]\ndove \\(P(A \\cap B)\\) rappresenta la probabilit√† congiunta dei due eventi, ovvero la probabilit√† che entrambi si verifichino.\n\nNell‚ÄôEquazione¬†18.1, \\(P(A \\cap B)\\) √® la probabilit√† congiunta che entrambi gli eventi si verifichino, mentre \\(P(B)\\) √® la probabilit√† marginale dell‚Äôevento \\(B\\). Riorganizzando i termini, otteniamo la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nUtilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilit√† totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c).\n\\]\nDove \\(B^c\\) rappresenta il complemento dell‚Äôevento \\(B\\).\n√à importante notare che \\(P(A \\mid B)\\) non √® definita se \\(P(B) = 0\\).\nLa probabilit√† condizionata pu√≤ essere interpretata come una ricalibrazione dello spazio campionario da \\(S\\) a \\(B\\). Per spazi campionari discreti, la probabilit√† condizionata √® espressa come\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\n\nEsempio 18.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilit√† che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilit√† in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poich√© ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilit√† di ottenere una somma minore di 8 √® 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma √® minore di 8. Quindi, la probabilit√† di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l‚Äôinformazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in Python.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nevent = [roll for roll in sample if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample)}\")\n\n21 / 36\n\n\n\nsample_odd = [roll for roll in sample if (sum(roll) % 2) != 0]\nsample_odd\n\n[(1, 2),\n (1, 4),\n (1, 6),\n (2, 1),\n (2, 3),\n (2, 5),\n (3, 2),\n (3, 4),\n (3, 6),\n (4, 1),\n (4, 3),\n (4, 5),\n (5, 2),\n (5, 4),\n (5, 6),\n (6, 1),\n (6, 3),\n (6, 5)]\n\n\n\nevent = [roll for roll in sample_odd if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample_odd)}\")\n\n12 / 18\n\n\nSe applichiamo l‚ÄôEquazione¬†18.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilit√† di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l‚Äôinformazione che la somma √® dispari, la probabilit√† di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 18.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilit√† del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificit√† del test: 90%. Ci√≤ indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo √® il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne √® affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual √® la probabilit√† che una donna scelta a caso ottenga una mammografia positiva? Poich√© il 1% delle donne ha il cancro al seno, la probabilit√† di ottenere una mammografia positiva (test positivo) √® pari alla sensibilit√† del test, ovvero 0.90 (cio√® 90%).\nSe la mammografia √® positiva, qual √® la probabilit√† che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test dar√† un risultato positivo (vera positivit√†) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test dar√† un risultato positivo (falsa positivit√†) in 99 casi (10%).\n\nQuesta situazione pu√≤ essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura¬†18.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test d√† un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilit√† di ottenere un risultato positivo al test √® \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilit√† di avere il cancro al seno, dato un risultato positivo al test, √® pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all‚Äô8.3%.\nIn questo esempio, la probabilit√† dell‚Äôevento ‚Äúottenere un risultato positivo al test‚Äù √® una probabilit√† non condizionata, poich√© calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D‚Äôaltra parte, la probabilit√† dell‚Äôevento ‚Äúavere il cancro al seno, dato che il test ha prodotto un risultato positivo‚Äù √® una probabilit√† condizionata, poich√© calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) pu√≤ influenzare la probabilit√† di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilit√† condizionate e non condizionate.\n\n\nEsempio 18.3 Il paradosso di Monty Hall rappresenta un curioso esempio di come l‚Äôintroduzione di nuove informazioni possa influenzare l‚Äôesito di una situazione probabilistica. Questo famoso problema trae origine dal popolare programma televisivo americano ‚ÄúLet‚Äôs Make a Deal‚Äù e deve la sua notoriet√† al conduttore Monty Hall.\nNel gioco ci sono tre porte chiuse: dietro una si nasconde un‚Äôautomobile, mentre dietro le altre due ci sono delle capre. Inizialmente, il concorrente sceglie una delle tre porte senza aprirla. Successivamente, Monty Hall apre una delle due porte rimaste, rivelando una capra. A questo punto, offre al concorrente la possibilit√† di cambiare la sua scelta iniziale e optare per l‚Äôaltra porta ancora chiusa. Il paradosso si presenta quando si scopre che cambiando la scelta in questa fase, il concorrente aumenta le sue probabilit√† di vincere l‚Äôautomobile, passando da 1/3 a 2/3.\n\n\n\nLo show televisivo Monty Hall.\n\n\nPer confermare questo risultato inaspettato, √® possibile eseguire una simulazione in Python. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilit√† del concorrente di vincere l‚Äôautomobile.\nDi seguito √® riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nporte = [\n    \"capra1\",\n    \"capra2\",\n    \"macchina\",\n]  # definisco il gioco, scelgo una porta a caso per n volte\ncounter = 0\ncontatore_cambio = 0\nn = 10000\nporta_vincente = \"macchina\"\nfor i in range(n):\n    scelta_casuale = random.choice(porte)\n    porte_rimaste = [x for x in porte if x != scelta_casuale]\n    porta_rivelata = random.choice([x for x in porte_rimaste if x != porta_vincente])\n    porta_alternativa = [\n        x for x in porte if x != scelta_casuale and x != porta_rivelata\n    ]\n    if \"macchina\" in porta_alternativa:\n        contatore_cambio += 1\n    if scelta_casuale == \"macchina\":\n        counter += 1\n\nprint(counter / n)  # quante volte vinco non cambiando porta\nprint(contatore_cambio / n)  # quante volte vinco cambiando porta\n\nQuesto script Python √® stato creato da un gruppo di studenti di Psicometria nell‚ÄôAA 2023-2023. La simulazione mostra che, effettivamente, la probabilit√† di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\nEcco una spiegazione del paradosso:\n\nFase Iniziale: Nel gioco, il concorrente deve scegliere una delle tre porte (A, B, C), dietro una delle quali si trova una macchina. Inizialmente, la probabilit√† che la macchina si trovi dietro la porta scelta √® \\(1/3\\), dato che esistono tre possibilit√† ugualmente probabili e solo una contiene la macchina.\nAggiunta di Informazioni: Dopo la scelta iniziale, Monty Hall, che conosce il contenuto dietro ogni porta, apre una delle due porte non scelte, rivelando sempre una capra. Questo passaggio √® fondamentale: non cambia la probabilit√† \\(1/3\\) che la macchina sia dietro la porta originariamente scelta dal concorrente, ma la probabilit√† che la macchina si trovi dietro l‚Äôaltra porta non scelta aumenta ora a \\(2/3\\). Questo aumento di probabilit√† deriva dal fatto che Monty ha scelto deliberatamente una porta con una capra, basando la sua scelta sulla posizione della macchina.\n\nConsideriamo i tre possibili scenari dopo che il concorrente ha scelto la porta A:\n\nLa macchina √® dietro la porta A: La probabilit√† di questo scenario √® \\(1/3\\). Monty pu√≤ aprire sia la porta B che la porta C, poich√© entrambe nascondono una capra. Se il concorrente cambia la sua scelta, perder√†.\nLa macchina √® dietro la porta B: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta C, perch√© sa che la macchina √® dietro la porta B e non pu√≤ rivelarla. Se il concorrente cambia la sua scelta da A a B, vincer√†.\nLa macchina √® dietro la porta C: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta B. Se il concorrente cambia la sua scelta da A a C, vincer√†.\n\nIn conclusione, cambiare la scelta originale porta alla vittoria in due dei tre scenari possibili. Pertanto, la probabilit√† complessiva di vincere cambiando la scelta √® \\(2/3\\).\nQuesto paradosso evidenzia come, in presenza di informazioni aggiuntive, le probabilit√† iniziali possano essere riviste significativamente. √à un classico esempio di come l‚Äôintuizione umana spesso si scontri con i principi della teoria delle probabilit√†, sottolineando l‚Äôimportanza della revisione bayesiana delle probabilit√† alla luce di nuove informazioni.\n\n\n18.2.1 Il paradosso di Simpson\nNel campo della probabilit√† condizionata, uno dei fenomeni pi√π interessanti e, nel contempo, pi√π controintuitivi, √® rappresentato dal paradosso di Simpson. Il paradosso di Simpson √® un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l‚Äôimportanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 18.4 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d‚Äôansia e coaching per migliorare le prestazioni lavorative. Ogni terapia pu√≤ avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d‚Äôansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi √® efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno √® un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere pi√π precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo √® che Rossi, presumibilmente a causa della sua reputazione come terapeuta pi√π esperto, sta effettuando un numero maggiore di terapie per disturbi d‚Äôansia, che sono intrinsecamente pi√π complesse e con una probabilit√† di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale √® inferiore non a causa di una minore abilit√† in un particolare tipo di terapia, ma perch√© una frazione maggiore delle sue terapie riguarda casi pi√π complessi.\nL‚Äôaggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilit√† dei terapeuti perch√© perdiamo l‚Äôinformazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, √® fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#teorema-della-probabilit√†-composta",
    "href": "chapters/chapter_3/02_conditional_prob.html#teorema-della-probabilit√†-composta",
    "title": "18¬† Probabilit√† condizionata",
    "section": "18.3 Teorema della probabilit√† composta",
    "text": "18.3 Teorema della probabilit√† composta\n√à possibile scrivere l‚ÄôEquazione¬†18.1 nella forma:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{18.2}\\]\nQuesto secondo modo di scrivere l‚ÄôEquazione¬†18.1 √® chiamato teorema della probabilit√† composta (o regola moltiplicativa, o regola della catena). La legge della probabilit√† composta ci dice che la probabilit√† che si verifichino contemporaneamente due eventi \\(A\\) e \\(B\\) √® pari alla probabilit√† di uno dei due eventi moltiplicata per la probabilit√† dell‚Äôaltro evento condizionata al verificarsi del primo.\nL‚Äôl‚ÄôEquazione¬†18.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{18.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 18.5 Per fare un esempio, consideriamo il problema seguente. Da un‚Äôurna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell‚Äôurna. Indichiamo con \\(B_i\\) l‚Äôevento: ‚Äúesce una pallina bianca alla \\(i\\)-esima estrazione‚Äù e con \\(N_i\\) l‚Äôestrazione di una pallina nera. L‚Äôevento: ‚Äúescono due palline bianche nelle prime due estrazioni‚Äù √® rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l‚ÄôEquazione¬†18.2, la sua probabilit√† vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perch√© nella prima estrazione \\(\\Omega\\) √® costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilit√† condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perch√© nella seconda estrazione, se √® verificato l‚Äôevento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l‚Äôesperimento consiste nell‚Äôestrazione successiva di 3 palline, la probabilit√† che queste siano tutte bianche, per l‚ÄôEquazione¬†18.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilit√† dell‚Äôestrazione di tre palline nere √® invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "href": "chapters/chapter_3/02_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "title": "18¬† Probabilit√† condizionata",
    "section": "18.4 Il teorema della probabilit√† totale",
    "text": "18.4 Il teorema della probabilit√† totale\nIl teorema della probabilit√† totale (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario \\(\\Omega\\) in \\(n\\) eventi mutualmente esclusivi e tali che la loro unione formi \\(\\Omega\\), allora la probabilit√† di un qualsiasi evento in \\(\\Omega\\) pu√≤ essere calcolata sommando la probabilit√† dell‚Äôevento su ciascun sottoinsieme della partizione, pesata in base alla probabilit√† del sottoinsieme.\nIn altre parole, se \\(H_1, H_2, \\dots, H_n\\) sono eventi mutualmente esclusivi e tali che \\(\\bigcup_{i=1}^n H_i = \\Omega\\), allora per ogni evento \\(E \\subseteq \\Omega\\), la probabilit√† di \\(E\\) √® data dalla formula:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{18.4}\\]\ndove \\(P(E \\mid H_i)\\) rappresenta la probabilit√† condizionata di \\(E\\) dato che si √® verificato l‚Äôevento \\(H_i\\), e \\(P(H_i)\\) √® la probabilit√† dell‚Äôevento \\(H_i\\).\nIl teorema della probabilit√† totale riveste un ruolo fondamentale in quanto fornisce il denominatore nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione √® di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilit√† valida. Per ulteriori dettagli e approfondimenti, √® possibile fare riferimento al Capitolo 30.\nNell‚Äôambito della probabilit√† discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilit√† di un evento, sfruttando le probabilit√† dei singoli eventi della partizione. Il caso pi√π semplice √® quello di una partizione dello spazio campione in due sottoinsiemi: \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\).\n\n\n\n\n\n\nFigura¬†18.2: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nIn tali circostanza abbiamo che\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nL‚ÄôEquazione¬†18.4 √® utile per calcolare \\(P(E)\\), se \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono facili da trovare.\n\nEsempio 18.6 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un‚Äôurna anch‚Äôessa scelta a caso. Qual √® la probabilit√† che la pallina estratta sia di colore rosso?\nSia \\(R\\) l‚Äôevento ‚Äúla pallina estratta √® rossa‚Äù e sia \\(U_i\\) l‚Äôevento che corrisponde alla scelta dell‚Äô\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilit√† totale, la probabilit√† di estrarre una pallina rossa √® dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]\n\n\n18.4.1 Indipendenza e probabilit√† condizionata\nL‚Äôindipendenza tra due eventi \\(A\\) e \\(B\\) pu√≤ essere espressa in modo intuitivo utilizzando la probabilit√† condizionata. Se \\(A\\) e \\(B\\) sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilit√† del verificarsi dell‚Äôaltro. In altre parole, la probabilit√† che \\(A\\) accada non cambia se sappiamo che \\(B\\) √® avvenuto, e viceversa.\nPossiamo esprimere questa idea con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nQuindi, due eventi \\(A\\) e \\(B\\) sono indipendenti se soddisfano le condizioni:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQuesto significa che la probabilit√† di \\(A\\) rimane invariata indipendentemente dal fatto che \\(B\\) sia accaduto o meno, e lo stesso vale per \\(B\\).\n\n18.4.1.1 Indipendenza di Tre Eventi\nTre eventi \\(A\\), \\(B\\) e \\(C\\) sono indipendenti se soddisfano le seguenti condizioni:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C), \\\\\nP(A \\cap B \\cap C) &= P(A) P(B) P(C).\n\\end{align}\n\\]\nLe prime tre condizioni verificano l‚Äôindipendenza a due a due, ovvero l‚Äôindipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l‚Äôultima condizione, che riguarda l‚Äôintersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che \\(A\\), \\(B\\) e \\(C\\) sono completamente indipendenti.\nIn sintesi, l‚Äôindipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilit√† del verificarsi degli altri.\n\nEsempio 18.7 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilit√† con un mazzo completo\nIn un mazzo completo, la probabilit√† di pescare una carta di picche (\\(P(A)\\)) √® $ = \\(, poich√© ci sono 13 picche su 52 carte totali. La probabilit√† di pescare una regina (\\)P(B)$) √® $ = $, poich√© ci sono 4 regine su 52 carte.\nOra consideriamo la probabilit√† congiunta di pescare la regina di picche (\\(P(AB)\\)). Poich√© esiste solo una regina di picche nel mazzo, la probabilit√† di pescare questa specifica carta √® $ $.\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoich√© \\(P(AB) = \\frac{1}{52}\\) √® uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilit√† dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilit√† con questo mazzo ridotto:\nLa probabilit√† di pescare la regina di picche (\\(P(AB)\\)) √® ora $ $, poich√© ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa $ $, poich√© ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa $ $, poich√© ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilit√†:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoich√© $ $, gli eventi \\(A\\) e \\(B\\) non sono pi√π indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l‚Äôindipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilit√† cambiano e gli eventi non sono pi√π indipendenti. Questo evidenzia l‚Äôimportanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilit√† e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilit√†, influenzando le relazioni di indipendenza tra eventi specifici.\nIn generale, l‚Äôindipendenza tra due eventi significa che la probabilit√† di uno non √® influenzata dal verificarsi dell‚Äôaltro. Questo concetto √® cruciale per analisi probabilistiche e modelli statistici pi√π complessi.\n\n\nEsempio 18.8 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = ‚Äúesce un 1 o un 2 nel primo lancio‚Äù e \\(B\\) = ‚Äúil punteggio totale √® 8‚Äù. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nCalcoliamo \\(P(A)\\):\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nA = [roll for roll in sample if roll[0] == 1 or roll[0] == 2]\nprint(A)\nprint(f\"{len(A)} / {len(sample)}\")\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n12 / 36\n\n\nCalcoliamo \\(P(B)\\):\n\nB = [roll for roll in sample if roll[0] + roll[1] == 8]\nprint(B)\nprint(f\"{len(B)} / {len(sample)}\")\n\n[(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)]\n5 / 36\n\n\nCalcoliamo \\(P(A \\cap B)\\):\n\nI = [\n    roll\n    for roll in sample\n    if (roll[0] == 1 or roll[0] == 2) and (roll[0] + roll[1] == 8)\n]\nprint(I)\nprint(f\"{len(I)} / {len(sample)}\")\n\n[(2, 6)]\n1 / 36\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti dato che \\(P(A \\cap B) \\neq P(A)P(B)\\):\n\n12/36 * 5/36 == 1/36\n\nFalse",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/02_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "18¬† Probabilit√† condizionata",
    "section": "18.5 Commenti e considerazioni finali",
    "text": "18.5 Commenti e considerazioni finali\nLa probabilit√† condizionata riveste un ruolo fondamentale poich√© ci permette di definire in modo preciso il concetto di indipendenza statistica. Uno degli aspetti cruciali dell‚Äôanalisi statistica riguarda la valutazione dell‚Äôassociazione tra due variabili. Nel capitolo attuale, ci siamo concentrati sul concetto di indipendenza, che indica l‚Äôassenza di relazione tra le variabili. Tuttavia, in futuro, esploreremo come fare inferenze sulla correlazione tra variabili, ovvero come determinare se le variabili sono associate tra loro o se esiste una relazione statistica credibile tra di esse.\nNell‚Äôambito dell‚Äôinferenza bayesiana, il condizionamento emerge come uno strumento essenziale. L‚Äôinferenza bayesiana √® un approccio statistico che sfrutta proprio il condizionamento per rivedere e aggiornare le credenze o le incertezze relative a determinate ipotesi, basandosi sull‚Äôintroduzione di nuove informazioni.\nIl processo inizia stabilendo una probabilit√† iniziale, denominata probabilit√† a priori (\\(P(A)\\)), che esprime la nostra convinzione o supposizione iniziale riguardo all‚Äôipotesi \\(A\\), prima di ricevere qualsiasi dato aggiuntivo. Questa probabilit√† a priori si fonda su conoscenze gi√† acquisite o su supposizioni precedentemente formulate.\nIl cuore dell‚Äôinferenza bayesiana si trova nell‚Äôaggiornamento di questa credenza iniziale in risposta all‚Äôacquisizione di nuove informazioni, rappresentate dalla variabile \\(E\\). L‚Äôaggiornamento avviene mediante il condizionamento, culminando nella determinazione di una probabilit√† a posteriori (\\(P(A | E)\\)). Questa nuova probabilit√† rappresenta la nostra credenza aggiornata sull‚Äôipotesi \\(A\\) dopo aver preso in esame l‚Äôevidenza \\(E\\) appena acquisita. In questo modo, l‚Äôinferenza bayesiana permette di affinare le nostre supposizioni e le nostre previsioni su determinati fenomeni, incorporando sistematicamente nuove prove nel nostro quadro di conoscenza.\nLa formula di Bayes governa questo processo di aggiornamento:\n\\[\nP(A | E) = \\frac{P(E | A) \\times P(A)}{P(E)}\n\\]\nIn questa formula, troviamo:\n\n\\(P(A | E)\\): la probabilit√† a posteriori, che √® la probabilit√† dell‚Äôipotesi \\(A\\) date le nuove prove \\(E\\).\n\\(P(E | A)\\): la verosimiglianza, ovvero la probabilit√† di osservare le prove \\(E\\) se l‚Äôipotesi \\(A\\) fosse vera.\n\\(P(A)\\): la probabilit√† a priori, che indica il nostro livello di convinzione iniziale nell‚Äôipotesi \\(A\\).\n\\(P(E)\\): la probabilit√† di osservare le prove \\(E\\), tenendo conto di tutte le ipotesi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/02_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/02_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "18¬† Probabilit√† condizionata",
    "section": "18.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "18.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Feb 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas: 2.2.0\nnumpy : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html",
    "href": "chapters/chapter_3/03_bayes_theorem.html",
    "title": "19¬† Il teorema di Bayes",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esploreremo il teorema di Bayes, un fondamentale risultato della teoria delle probabilit√† che ci permette di calcolare le probabilit√† a posteriori di eventi ipotetici, dati i loro valori a priori e nuove informazioni. In altre parole, ci consente di aggiornare razionalmente le nostre conoscenze alla luce di nuove evidenze.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#storia",
    "href": "chapters/chapter_3/03_bayes_theorem.html#storia",
    "title": "19¬† Il teorema di Bayes",
    "section": "19.1 Storia",
    "text": "19.1 Storia\nIl teorema di Bayes, cos√¨ denominato in onore del Reverendo Thomas Bayes, un matematico e filosofo del XVIII secolo, rappresenta uno dei concetti fondamentali nel campo della statistica e del calcolo delle probabilit√†. Sebbene Bayes non abbia pubblicato il suo lavoro durante la sua vita, ritenendolo non abbastanza significativo, fu il suo amico Richard Price a riconoscere il valore delle sue scoperte. Price non solo edit√≤ il manoscritto inedito di Bayes ma lo arricch√¨ significativamente prima di sottometterlo per la pubblicazione nelle ‚ÄúPhilosophical Transactions‚Äù nel 1763. Questa pubblicazione non solo introdusse il teorema di Bayes al mondo scientifico ma forn√¨ anche una base filosofica per quello che sarebbe poi diventato noto come l‚Äôapproccio bayesiano alla statistica.\nParallelamente e indipendentemente dai lavori di Bayes, Pierre-Simon Laplace, un eminente matematico e astronomo francese, formul√≤ concetti simili. Nel 1774, e pi√π dettagliatamente nella sua opera ‚ÄúTh√©orie analytique des probabilit√©s‚Äù del 1812, Laplace esplor√≤ l‚Äôuso della probabilit√† condizionale per aggiornare le conoscenze precedenti (probabilit√† a priori) sulla base di nuove evidenze (probabilit√† a posteriori). Sebbene Laplace abbia sviluppato questi principi senza conoscere il lavoro di Bayes, i suoi contributi hanno notevolmente esteso l‚Äôapplicazione e l‚Äôinterpretazione delle statistiche bayesiane.\nIl teorema di Bayes, nella sua essenza, fornisce un meccanismo matematico per aggiornare le probabilit√† iniziali di un‚Äôipotesi in base all‚Äôosservazione di nuove evidenze. Questo processo di revisione continua della probabilit√† si basa sulla combinazione di conoscenze preesistenti (il prior) con informazioni appena acquisite (la likelihood), per produrre una nuova comprensione (il posterior). Tale meccanismo riflette un approccio olistico alla conoscenza, che considera la comprensione come un processo dinamico e iterativo.\nNel contesto contemporaneo, l‚Äôimportanza e l‚Äôapplicabilit√† del teorema di Bayes vanno ben oltre la teoria della probabilit√† e la statistica, influenzando vari campi come l‚Äôintelligenza artificiale, l‚Äôapprendimento automatico, la psicologia, la medicina e persino la presa di decisioni nella vita quotidiana. La capacit√† di aggiornare costantemente le nostre convinzioni in base a nuove informazioni √® fondamentale in un‚Äôera caratterizzata da un flusso incessante di dati. In modo emblematico, potremmo affermare che rilevanza universale del teorema di Bayes nella comprensione dei fenomeni e nella previsione degli eventi √® enfatizzata nel titolo del libro di Tom Chivers pubblicato nel 2024: ‚ÄúEverything is predictable: how bayesian statistics explain our world‚Äù.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#teorema",
    "href": "chapters/chapter_3/03_bayes_theorem.html#teorema",
    "title": "19¬† Il teorema di Bayes",
    "section": "19.2 Teorema",
    "text": "19.2 Teorema\nConsideriamo una situazione in cui lo spazio degli eventi possibili, \\(\\Omega\\), √® diviso in due eventi distinti e mutualmente esclusivi, denominati ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo di avere gi√† una certa comprensione di questi eventi, espressa attraverso le loro probabilit√† a priori \\(P(H_1)\\) e \\(P(H_2)\\). A questo punto, introduciamo un nuovo evento \\(E\\), la cui occorrenza √® accompagnata da una probabilit√† non nulla e per il quale conosciamo le probabilit√† condizionate \\(P(E \\mid H_1)\\) e \\(P(E \\mid H_2)\\), che indicano quanto sia probabile osservare \\(E\\) assumendo che una delle due ipotesi sia vera. Se \\(E\\) si verifica, siamo interessati a determinare le probabilit√† a posteriori \\(P(H_1 \\mid E)\\) e \\(P(H_2 \\mid E)\\) delle nostre ipotesi alla luce di questa nuova evidenza.\nLa seguente illustrazione rappresenta come lo spazio totale degli eventi si suddivide tra le ipotesi \\(H_1\\) e \\(H_2\\), con l‚Äôevidenza \\(E\\) posizionata all‚Äôinterno di questo contesto.\n\n\n\n\n\n\nFigura¬†19.1: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nPer calcolare la probabilit√† a posteriori dell‚Äôipotesi 1 data l‚Äôosservazione di \\(E\\), utilizziamo la formula:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\cap H_1)}{P(E)}.\n\\]\nQuesto calcolo pu√≤ essere semplificato sfruttando la definizione di probabilit√† condizionata, che ci permette di sostituire \\(P(E \\cap H_1)\\) con \\(P(E \\mid H_1)P(H_1)\\). Applicando questa sostituzione, otteniamo:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n\\]\nDato che \\(H_1\\) e \\(H_2\\) si escludono a vicenda, la probabilit√† totale di \\(E\\) pu√≤ essere espressa come la somma delle probabilit√† di \\(E\\) occorrente in concomitanza con ciascuna ipotesi, utilizzando il teorema della probabilit√† totale:\n\\[\nP(E) = P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n\\]\nIncorporando questi valori nella formula di Bayes, giungiamo a:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n\\tag{19.1}\\]\nQuesta espressione costituisce l‚Äôessenza della formula di Bayes per il caso semplificato in cui le ipotesi si limitano a due eventi mutualmente esclusivi, \\(H_1\\) e \\(H_2\\).\nNel quadro delle probabilit√† discrete, questa formula pu√≤ essere generalizzata per accogliere un insieme pi√π ampio di ipotesi che formano una partizione completa dello spazio degli eventi \\(\\Omega\\), dove ogni \\(E\\) rappresenta un evento con probabilit√† maggiore di zero. Per ogni ipotesi \\(H_i\\) all‚Äôinterno di un insieme numerabile, la formula di Bayes si estende come segue:\n\\[\nP(H_i \\mid E) = \\frac{P(E \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(E \\mid H_j)P(H_j)}.\n\\tag{19.2}\\]\nQui, il denominatore agisce come un fattore di normalizzazione che integra i prodotti delle probabilit√† a priori e delle verosimiglianze associate a ogni ipotesi considerata.\nPer variabili continue, la formula di Bayes assume una forma integrale, adattandosi a situazioni in cui le ipotesi \\(H_i\\) rappresentano valori in un continuum. In questo contesto, la formula diventa:\n\\[\nP(H_i \\mid E) = \\frac{P(E \\mid H_i) \\cdot P(H_i)}{\\int P(E \\mid H) \\cdot P(H) \\, dH},\n\\tag{19.3}\\]\noffrendo un framework potente per aggiornare le probabilit√† a posteriori di ipotesi continue basate su nuove evidenze, sottolineando l‚Äôimportanza della formula di Bayes non solo come strumento matematico, ma anche come filosofia di apprendimento continuo e adattamento alle nuove informazioni.\n\n19.2.1 Interpretazione della Formula di Bayes\nLa formula di Bayes si articola in tre elementi fondamentali che ne facilitano la comprensione e l‚Äôapplicazione in diversi campi di studio:\n\nProbabilit√† a Priori, \\(P(H)\\): Questa componente riflette la nostra valutazione preliminare riguardo la verosimiglianza dell‚Äôipotesi \\(H\\) prima di prendere in esame nuove evidenze \\(E\\). Essa incarna il livello di credibilit√† o fiducia attribuita all‚Äôipotesi, basandosi su conoscenze preesistenti o su deduzioni logiche. In sostanza, la probabilit√† a priori quantifica le nostre convinzioni pregresse o le aspettative iniziali su quanto sia probabile che l‚Äôipotesi sia vera.\nProbabilit√† a Posteriori, \\(P(H \\mid E)\\): Questo valore aggiorna la nostra fiducia nell‚Äôipotesi \\(H\\) in seguito all‚Äôosservazione dell‚Äôevidenza \\(E\\). In termini pi√π intuitivi, rappresenta il livello di convinzione ricalibrato in \\(H\\) dopo aver considerato l‚Äôevidenza. La formula di Bayes ci offre un meccanismo matematicamente rigoroso per modulare questa probabilit√† alla luce delle nuove informazioni ricevute.\nVerosimiglianza, \\(P(E \\mid H)\\): La verosimiglianza esprime la probabilit√† di rilevare l‚Äôevidenza \\(E\\) dato che l‚Äôipotesi \\(H\\) sia vera. √à un indice di quanto l‚Äôevidenza supporti o confermi l‚Äôipotesi. Un valore elevato di verosimiglianza indica che l‚Äôevidenza √® fortemente in linea o prevista dalla veridicit√† dell‚Äôipotesi.\n\nGrazie alla formula di Bayes, possiamo adottare un processo di aggiornamento continuo delle nostre credenze in base a nuove informazioni, promuovendo un metodo dinamico per navigare tra conoscenza e incertezza. Questa metodologia ci fornisce un approccio strutturato per rivedere e adattare le nostre convinzioni riguardo l‚Äôipotesi \\(H\\) di fronte a nuovi dati o evidenze \\(E\\). La capacit√† di rielaborare costantemente le nostre aspettative in funzione di informazioni aggiuntive si rivela essenziale in una vasta gamma di ambiti, inclusi l‚Äôintelligenza artificiale, la ricerca statistica, le discipline scientifiche e umanistiche. Tale prassi ci consente di prendere decisioni pi√π informate, di interpretare con maggiore precisione i dati disponibili e di affinare significativamente le nostre previsioni e comprensioni del mondo circostante.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#alcuni-esempi",
    "href": "chapters/chapter_3/03_bayes_theorem.html#alcuni-esempi",
    "title": "19¬† Il teorema di Bayes",
    "section": "19.3 Alcuni esempi",
    "text": "19.3 Alcuni esempi\nEsamineremo alcuni esempi basilari per illustrare in maniera pi√π chiara il modo in cui il teorema di Bayes viene applicato e funziona.\n\nEsempio 19.1 Consideriamo il caso in cui osserviamo una persona con i capelli lunghi e desideriamo valutare la probabilit√† che questa persona sia femminile. In termini formali, definiamo \\(H = \\text{\"donna\"}\\) e \\(E = \\text{\"capelli lunghi\"}\\), e miriamo a stimare \\(P(H \\mid E)\\).\nLe nostre conoscenze preliminari includono:\n\nLa probabilit√† a priori che la persona osservata sia una donna, \\(P(H) = 0.5\\),\nLa probabilit√† generale di osservare qualcuno con i capelli lunghi, \\(P(E) = 0.4\\),\nLa probabilit√† di avere i capelli lunghi dato che la persona √® una donna, \\(P(E \\mid H) = 0.7\\).\n\nApplicando la formula di Bayes, possiamo determinare:\n\\[ P(H \\mid E) = \\frac{P(H) \\cdot P(E \\mid H)}{P(E)} = \\frac{0.5 \\cdot 0.7}{0.4} = 0.875. \\]\nQuesto risultato ci mostra che, alla luce delle informazioni a nostra disposizione, la probabilit√† che una persona con i capelli lunghi sia una donna √® dell‚Äô0.875. In altre parole, prima di osservare l‚Äôevidenza (i capelli lunghi), partivamo da una conoscenza di base secondo cui c‚Äôera una chance su due (50%) che la persona fosse una donna. Dopo aver considerato l‚Äôevidenza dei capelli lunghi, abbiamo aggiornato la nostra stima alla probabilit√† ‚Äúa posteriori‚Äù di 0.875, riflettendo cos√¨ un incremento della nostra convinzione che la persona sia una donna basandoci su quest‚Äôultima osservazione.\n\n\nEsempio 19.2 Un esempio pratico che illustra efficacemente l‚Äôuso del teorema di Bayes √® l‚Äôanalisi del rapporto tra la mammografia e la diagnosi del cancro al seno, gi√† considerato in precedenza. In questo contesto, si considerano due ipotesi: la presenza della malattia, indicata con \\(M^+\\), e l‚Äôassenza della malattia, denotata con \\(M^-\\). L‚Äôevidenza in questo caso √® rappresentata dal risultato positivo di un test di mammografia, che indicheremo con \\(T^+\\). Applicando la formula di Bayes, possiamo esprimere la probabilit√† di avere il cancro al seno dato un risultato positivo al test come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) √® la probabilit√† di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)),\n\\(P(T^+ \\mid M^+)\\) rappresenta la probabilit√† che il test di mammografia risulti positivo (\\(T^+\\)) in presenza effettiva del cancro (\\(M^+\\)),\n\\(P(M^+)\\) denota la probabilit√† a priori che una persona abbia il cancro prima di sottoporsi al test,\n\\(P(T^+ \\mid M^-)\\) indica la probabilit√† che il test risulti positivo (\\(T^+\\)) nonostante l‚Äôassenza del cancro (\\(M^-\\)); dal momento che la specificit√† √® data e uguale a 0.9, possiamo calcolare la probabilit√† di un falso positivo come segue:\n\n\\[ P(T^+ \\mid M^-) = 1 - \\text{Specificit√†} = 1 - 0.9 = 0.1. \\]\nQuindi, in questo contesto, \\(P(T^+ \\mid M^-) = 0.1\\) significa che c‚Äô√® un 10% di probabilit√† che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\n\\(P(M^-)\\) rappresenta la probabilit√† a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nInserendo i valori specifici del contesto analizzato otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\\\\n&= \\frac{9}{108} \\\\\n&\\approx 0.083.\n\\end{align}\n\\]\nQuesto calcolo dimostra che, considerando una mammografia con risultato positivo ottenuta tramite un test con una sensibilit√† del 90% e una specificit√† del 90%, la probabilit√† che il paziente sia effettivamente affetto da cancro al seno √® approssimativamente dell‚Äô8.3%.\n\n\n19.3.1 Il Valore Predittivo di un Test di Laboratorio\nL‚Äôapplicazione del teorema di Bayes nell‚Äôinterpretazione dei risultati dei test di laboratorio √® cruciale nella pratica clinica. Questo teorema consente di calcolare la probabilit√† che un individuo sia affetto da una specifica malattia dopo un risultato positivo al test, nonch√© la probabilit√† di non essere malati in caso di esito negativo. La comprensione di tre elementi √® fondamentale per questo calcolo: la prevalenza della malattia, la sensibilit√† e la specificit√† del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione che sono affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza del 0.5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilit√†: Indica la capacit√† del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilit√† (\\(Sens\\)) √® la seguente:\n\n\\[ Sens = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilit√† misura la probabilit√† che il test risulti positivo se la malattia √® effettivamente presente.\n\nSpecificit√†: Misura la capacit√† del test di riconoscere gli individui sani, producendo un risultato negativo per chi non √® affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificit√† (\\(Spec\\)) si definisce come:\n\n\\[ Spec = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Cos√¨, la specificit√† rappresenta la probabilit√† che il test risulti negativo in assenza della malattia.\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilit√†)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilit√†)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificit√†)\n\\(P(T^- \\cap M^-)\\)  (Specificit√†)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilit√† totale di avere la malattia (\\(P(M^+)\\)) e la probabilit√† totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilit√† totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilit√† totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilit√†, che per definizione √® 1, rappresentando l‚Äôintera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilit√† post-test di avere o non avere la malattia basandoci sul risultato del test, fornendo cos√¨ una base razionale per decisioni diagnostiche e terapeutiche.\nLa probabilit√† post-test che un individuo sia malato dato un risultato positivo del test √® calcolata come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\nQuesta formula rappresenta il valore predittivo positivo, indicando la probabilit√† che un individuo sia realmente malato se il test √® positivo. Analogamente, il valore predittivo negativo, che √® la probabilit√† che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\nQuesti valori predittivi sono essenziali per valutare l‚Äôefficacia di un test diagnostico, aiutando a determinare quanto sia affidabile un risultato positivo o negativo nel contesto di una specifica popolazione e malattia.\n\n\n\n\n\n\nFigura¬†19.2\n\n\n\n\nEsempio 19.3 Calcoliamo ora il valore predittivo del test positivo e il valore predittivo del test negativo per i dati dell‚Äôesempio sulla mammografia e cancro al seno.\n\ndef positive_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n\nValore Predittivo Positivo (Positive Predictive Value, PPV): Questa misura indica la probabilit√† che un individuo sia effettivamente malato se ha ricevuto un risultato positivo al test. La formula che hai fornito per il PPV √®:\n\\[ PPV = \\frac{Sens \\cdot Prev}{Sens \\cdot Prev + (1 - Spec) \\cdot (1 - Prev)} \\]\nQui, sens rappresenta la sensibilit√† del test, spec la specificit√†, e prev la prevalenza della malattia nella popolazione. La formula riflette il calcolo del PPV basato sul teorema di Bayes.\n\ndef negative_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n\nValore Predittivo Negativo (Negative Predictive Value, NPV): Questa misura indica la probabilit√† che un individuo non sia malato se ha ricevuto un risultato negativo al test. La formula per il NPV √®:\n\\[ NPV = \\frac{Spec \\cdot (1 - Prev)}{Spec \\cdot (1 - Prev) + (1 - Sens) \\cdot Prev} \\]\nAnche in questo caso, sens, spec, e prev hanno gli stessi significati menzionati sopra. Questa formula calcola il NPV basandosi sul teorema di Bayes.\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilit√†\nspec = 0.9  # specificit√†\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo √®:\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.083\n\n\nIl valore predittivo del test negativo √®:\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\n\n\nEsempio 19.4 Consideriamo ora un altro esempio relativo al test antigenico rapido per il virus SARS-CoV-2, che pu√≤ essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L‚ÄôIstituto Superiore di Sanit√† ha pubblicato un documento il 5 novembre 2020, nel quale viene sottolineato che, fino a quel momento, i dati disponibili sui vari test sono quelli forniti dai produttori: la sensibilit√† varia tra il 70% e l‚Äô86%, mentre la specificit√† si attesta tra il 95% e il 97%.\nPer fare un esempio, consideriamo i dati di un certo momento temporale. Nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus √® stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa 0.2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n\n0.002349135593220339\n\n\nL‚Äôobiettivo √® determinare la probabilit√† di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2 # specificit√†\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.044\n\n\nPertanto, se il risultato del tampone √® positivo, la probabilit√† di essere effettivamente affetti da Covid-19 √® solo del 4.4%, approssimativamente.\nSe la prevalenza fosse 100 volte superiore (cio√®, pari al 23.5%), la probabilit√† di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l‚Äô86%.\n\nprev = 138599 / 59000000 * 100\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.857\n\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilit√† di non essere infetto sarebbe del 99.9%, approssimativamente.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2  # specificit√†\nprev = 138599 / 59000000  # prevalenza\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\nTuttavia, un‚Äôesito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia √® molto bassa; in altre parole, il risultato negativo conferma una situazione gi√† presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell‚Äôasserire l‚Äôassenza della malattia quanto piuttosto nel confermarne la presenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/03_bayes_theorem.html#commenti-e-considerazioni-finali",
    "title": "19¬† Il teorema di Bayes",
    "section": "19.4 Commenti e considerazioni finali",
    "text": "19.4 Commenti e considerazioni finali\nLa riflessione epistemologica contemporanea ha ribadito che la conoscenza non pu√≤ essere vista come una certezza inconfutabile o una garanzia razionale di verit√†. Invece, essa emerge come una serie di decisioni prese all‚Äôinterno di un contesto di incertezza. Questa comprensione √® particolarmente pertinente nel campo della ricerca scientifica, dove n√© la logica deduttiva n√© le rigorose dimostrazioni matematiche sono sufficienti. Di conseguenza, la scienza necessita di una ‚Äúlogica dell‚Äôincertezza,‚Äù che √® efficacemente fornita dalla teoria delle probabilit√†, e pi√π specificamente, dal teorema di Bayes.\nIl teorema di Bayes ci offre un framework per interpretare la probabilit√† come una valutazione soggettiva influenzata da diversi fattori condizionanti. In pratica, il teorema esprime la probabilit√† a posteriori \\(P(H_i \\mid E)\\) come un risultato derivato dalla combinazione della probabilit√† a priori \\(P(H_i)\\) e della verosimiglianza \\(P(E \\mid H_i)\\). Questa formulazione sottolinea che la nostra valutazione probabilistica di una data ipotesi \\(H_i\\) √® modulata sia dall‚Äôevidenza empirica \\(E\\) che dalle nostre credenze a priori \\(P(H_i)\\).\nPoich√© la probabilit√† √® una valutazione intrinsecamente soggettiva, √® possibile che diversi osservatori arrivino a conclusioni differenti. Tuttavia, il teorema di Bayes fornisce un meccanismo razionale‚Äîconosciuto come ‚Äúaggiornamento bayesiano‚Äù‚Äîper ricalibrare queste credenze in risposta a nuove informazioni o evidenze.\nL‚Äôapproccio bayesiano offre strumenti per valutare l‚Äôefficacia di diverse strategie di trattamento o interventi in psicologia clinica. Per esempio, se si afferma che la meditazione mattutina √® efficace nel trattamento della depressione, √® essenziale valutare questa affermazione nel contesto di tutte le evidenze disponibili, compresi i casi in cui la meditazione non ha portato a miglioramenti.\nIn sintesi, la metodologia bayesiana fornisce una cornice robusta per l‚Äôaggiornamento delle probabilit√† in presenza di nuove informazioni, offrendo spunti importanti sia per la ricerca che per la pratica clinica in psicologia.\nNel contesto di questo capitolo, abbiamo focalizzato la nostra discussione sul teorema di Bayes nel caso delle variabili casuali discrete. Tuttavia, nel prossimo capitolo, esploreremo come il teorema pu√≤ essere applicato anche alle variabili casuali continue.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/03_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/03_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "19¬† Il teorema di Bayes",
    "section": "19.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "19.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\narviz     : 0.17.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html",
    "href": "chapters/chapter_3/04a_random_var.html",
    "title": "20¬† Variabili casuali",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, introdurremo il concetto di variabili casuali e delle loro distribuzioni di probabilit√†, ampliando ulteriormente l‚Äôambito delle analisi matematiche degli eventi considerati finora. Le variabili casuali possono essere discrete o continue, a seconda dei valori che possono assumere. Iniziamo con una definizione.\nLe variabili casuali si dividono in due categorie principali:\nQuesto processo di assegnazione di numeri a stati semplifica notevolmente l‚Äôanalisi dei dati, permettendoci di applicare concetti matematici e statistici agli eventi del mondo reale. In generale, le variabili casuali vengono utilizzate principalmente in due modi:\nIn sintesi, le variabili casuali ci permettono di modellare e analizzare matematicamente la complessit√† e l‚Äôincertezza del mondo reale, fornendo un ponte tra le osservazioni empiriche e la teoria statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#introduzione",
    "href": "chapters/chapter_3/04a_random_var.html#introduzione",
    "title": "20¬† Variabili casuali",
    "section": "",
    "text": "Definizione 20.1 Una variabile casuale reale √® una funzione che associa gli esiti possibili di un esperimento (lo spazio campionario \\(\\Omega\\)) a valori numerici reali. Matematicamente, si descrive come \\(X : \\Omega \\rightarrow \\mathbb{R}\\), dove \\(X\\) √® la variabile casuale e \\(\\mathbb{R}\\) rappresenta l‚Äôinsieme dei numeri reali.\n\n\n\nDiscrete: Queste variabili possono assumere solo un numero limitato di valori distinti e contabili. Un esempio √® il numero di libri letti in un mese.\nContinue: Queste variabili possono assumere qualsiasi valore in un intervallo. Un esempio √® la temperatura di un giorno, che pu√≤ variare continuamente e assumere un numero infinito di valori all‚Äôinterno di un dato range.\n\n\nEsempio 20.1 Consideriamo l‚Äôesperimento casuale del lancio di una moneta. Ogni volta che lanciamo la moneta, otteniamo un risultato specifico: testa o croce. Questi risultati sono gli esiti reali che possiamo osservare. In matematica e statistica, ci interessa analizzare tutti i possibili risultati in modo strutturato. Le variabili casuali ci permettono di trasformare questi esiti in valori numerici utilizzabili nei calcoli; per esempio, possiamo assegnare il numero 1 a testa e il numero 0 a croce.\n\n\nEsempio 20.2 Un altro esempio √® la variabile casuale \\(Y\\) che rappresenta il risultato di un lancio di dado. Se definiamo \\(Y = 1\\) per indicare che il risultato del lancio √® un numero dispari (1, 3 o 5) e \\(Y = 0\\) per indicare che il risultato del lancio √® un numero pari (2, 4 o 6), abbiamo trasformato un‚Äôosservazione fisica (il lancio del dado) in un valore numerico che rappresenta un certo tipo di evento.\n\n\n\nModellazione delle conoscenze (osservazioni): Le variabili casuali aiutano a quantificare e strutturare le informazioni raccolte da esperimenti o studi.\nModellazione delle incognite (variabili latenti, parametri, predizioni): Le variabili casuali rappresentano ci√≤ che non sappiamo o che vogliamo prevedere, come i parametri nascosti di un modello o i futuri esiti di un esperimento.\n\n\n\n20.0.1 Convenzioni Notazionali\nNella teoria della probabilit√†, √® usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come ‚ÄòX‚Äô, per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D‚Äôaltro canto, la corrispondente lettera minuscola, ‚Äòx‚Äô nel nostro esempio, √® impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale pu√≤ assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (X) o di un suo specifico valore (x).\nUlteriori convenzioni di notazione includono:\n\n‚ÄòX‚Äô √® spesso usata per rappresentare variabili casuali non osservate, come parametri sconosciuti o variabili latenti di un modello.\n‚ÄòY‚Äô, al contrario, √® generalmente riservata a variabili casuali osservate, ovvero dati che sono stati effettivamente raccolti o misurati in un esperimento",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#variabili-casuali-multiple",
    "href": "chapters/chapter_3/04a_random_var.html#variabili-casuali-multiple",
    "title": "20¬† Variabili casuali",
    "section": "20.1 Variabili casuali multiple",
    "text": "20.1 Variabili casuali multiple\nNella teoria della probabilit√†, le variabili casuali spesso non operano in isolamento ma in contesti dove interagiscono o si combinano tra loro. Per esemplificare, immaginiamo di avere una moneta perfettamente bilanciata e di decidere di lanciarla tre volte. Ogni lancio di questa moneta pu√≤ essere descritto da una variabile casuale separata: \\(Y_1\\), \\(Y_2\\), e \\(Y_3\\). Queste variabili rappresentano i risultati dei lanci individuali, e ogni lancio √® considerato indipendente dagli altri. Ci√≤ significa che l‚Äôesito di un lancio non influisce sugli esiti degli altri. Poich√© la moneta √® bilanciata, la probabilit√† di ottenere testa (che possiamo rappresentare come 1) o croce (rappresentata come 0) in ogni lancio √® del 50%, dunque abbiamo \\(P(Y_n = 1) = 0.5\\) e \\(P(Y_n = 0) = 0.5\\), per \\(n\\) uguale a 1, 2 o 3.\nQuando combiniamo variabili casuali attraverso operazioni aritmetiche, possiamo creare nuove variabili che offrono ulteriori insight. Prendiamo, per esempio, i tre lanci della moneta bilanciata menzionati prima. Se definiamo \\(Y_1\\), \\(Y_2\\), e \\(Y_3\\) come i risultati di questi lanci, possiamo introdurre una nuova variabile casuale \\(Z\\) che rappresenta la somma dei risultati:\n\\[\nZ = Y_1 + Y_2 + Y_3.\n\\]\nLa variabile \\(Z\\) √® un esempio di variabile casuale discreta, il che significa che pu√≤ assumere solo valori interi specifici. A differenza delle variabili continue che possono assumere qualsiasi valore in un intervallo, \\(Z\\) pu√≤ solo risultare in una serie limitata di numeri interi, che nel contesto dei nostri lanci di moneta sono i possibili totali di testa ottenuti nei tre tentativi. La notazione \\(\\mathbb{Z}\\) qui √® un po‚Äô fuorviante poich√© sembra riferirsi all‚Äôinsieme di tutti i numeri interi, ma nel contesto specifico di \\(Z\\) come somma dei risultati di tre lanci di moneta, i valori possibili di \\(Z\\) vanno da 0 (nessun testa in tre lanci) a 3 (testa in tutti e tre i lanci), rendendo \\(Z\\) una variabile che riflette il numero totale di testa ottenuti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#sec-fun-mass-prob",
    "href": "chapters/chapter_3/04a_random_var.html#sec-fun-mass-prob",
    "title": "20¬† Variabili casuali",
    "section": "20.2 Distribuzione di Probabilit√†",
    "text": "20.2 Distribuzione di Probabilit√†\nIl concetto di distribuzione di probabilit√† √® fondamentale per analizzare come le probabilit√† si distribuiscono tra i vari esiti possibili di una variabile casuale. Questo concetto varia a seconda che stiamo considerando variabili casuali discrete o continue.\n\n20.2.1 Variabili Casuali Discrete\nPer le variabili casuali discrete, che assumono valori specifici e contabili (come il lancio di un dado), la distribuzione di probabilit√† √® rappresentata dalla cosiddetta funzione di massa di probabilit√†, spesso abbreviata con \\(P(\\cdot)\\). Questa funzione attribuisce una probabilit√† precisa a ciascun esito possibile della variabile. Prendendo l‚Äôesempio del lancio di un dado equilibrato, se ci concentriamo sul risultato ‚Äú1‚Äù, la funzione di massa di probabilit√† potrebbe esprimersi come \\(P(Y = 1) = \\frac{1}{6}\\), indicando che, in una serie di lanci indipendenti, il risultato ‚Äú1‚Äù si verificherebbe circa un sesto delle volte. Qui, la probabilit√† pu√≤ essere interpretata in due modi principali: come una misura di credenza nella teoria bayesiana o come una frequenza di occorrenza a lungo termine nell‚Äôapproccio frequentista.\n\n\n20.2.2 Variabili Casuali Continue\nNel caso delle variabili casuali continue, che possono assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo, si parla di densit√† di probabilit√†, indicata con \\(p(\\cdot)\\). Questa funzione non assegna probabilit√† a valori puntuali (dato che la probabilit√† di un singolo esatto valore √® zero), ma determina la probabilit√† che la variabile si collochi entro un certo intervallo di valori.\n\n\n20.2.3 Supporto della Variabile Casuale\nIl concetto di supporto di una variabile casuale si riferisce all‚Äôinsieme di tutti i valori che la variabile pu√≤ effettivamente assumere. Per esempio, il supporto di un dado standard a sei facce √® l‚Äôinsieme \\(\\{1, 2, 3, 4, 5, 6\\}\\), mentre per una variabile casuale che segue una distribuzione continua, come quella gaussiana, il supporto potrebbe essere l‚Äôintero insieme dei numeri reali.\n\n\n20.2.4 Assegnazione di Probabilit√†\nPer le variabili casuali discrete, √® essenziale specificare la probabilit√† di ogni valore possibile per definire la loro distribuzione di probabilit√† in modo completo. Per le variabili continue, invece, ci affidiamo alla densit√† di probabilit√† per capire la probabilit√† che la variabile rientri in specifici intervalli di valori.\nIn conclusione, la distribuzione di probabilit√†, rappresentata attraverso la funzione di massa di probabilit√† per le variabili discrete o la densit√† di probabilit√† per quelle continue, √® cruciale per descrivere il modo in cui le probabilit√† si distribuiscono tra i diversi esiti possibili di una variabile casuale, offrendo una visione completa del suo comportamento.\n\nEsempio 20.3 Supponiamo che la variabile casuale discreta \\(X\\) per il tipo di sangue sia definita esplicitamente come segue:\n\\[\nX =\n\\begin{cases}\n1 & \\text{se la persona ha il tipo di sangue A} \\\\\n2 & \\text{se la persona ha il tipo di sangue B} \\\\\n3 & \\text{se la persona ha il tipo di sangue AB} \\\\\n4 & \\text{se la persona ha il tipo di sangue O}\n\\end{cases}\n\\]\nPertanto, \\(X\\) √® una variabile casuale discreta con quattro possibili esiti. Possiamo anche trovare la distribuzione di probabilit√† che descrive la probabilit√† dei diversi valori possibili della variabile casuale \\(X\\). Notiamo che gli assiomi e le propriet√† delle probabilit√† che abbiamo discusso in precedenza si applicano anche alle variabili casuali (ad esempio, la probabilit√† totale per tutti i valori possibili di una variabile casuale √® pari a uno).\nLe distribuzioni di probabilit√† sono spesso presentate utilizzando tabelle di probabilit√† o grafici. Ad esempio, supponiamo che le probabilit√† individuali per i diversi tipi di sangue in una popolazione siano \\(P(A) = 0.41\\), \\(P(B) = 0.10\\), \\(P(AB) = 0.04\\), e \\(P(O) = 0.45\\). Notiamo che:\n\\[ P(A) + P(B) + P(AB) + P(O) = 0.41 + 0.10 + 0.04 + 0.45 = 1. \\]\n\n\n\nTipo di sangue\nA\nB\nAB\nO\n\n\n\n\n\\(X\\)\n1\n2\n3\n4\n\n\n\\(P(X)\\)\n0.41\n0.10\n0.04\n0.45\n\n\n\nQui, \\(x\\) denota un valore specifico (cio√® 1, 2, 3 o 4) della variabile casuale \\(X\\). Quindi, invece di dire \\(P(A) = 0.41\\), cio√® il tipo di sangue √® A con probabilit√† 0.41, possiamo dire che \\(P(X = 1) = 0.41\\), cio√® \\(X\\) √® uguale a 1 con probabilit√† 0.41.\nPossiamo usare la distribuzione di probabilit√† per rispondere a domande di probabilit√†. Ad esempio, qual √® la probabilit√† che una persona selezionata a caso dalla popolazione possa donare sangue a qualcuno con tipo di sangue B?\nSappiamo che le persone con tipo di sangue B o O possono donare a una persona con tipo di sangue B.\nPertanto, dobbiamo trovare la probabilit√† \\(P(\\text{tipo di sangue B} \\cup \\text{tipo di sangue O})\\). Poich√© gli eventi tipo di sangue B e tipo di sangue O sono mutuamente esclusivi, possiamo usare la regola dell‚Äôaddizione per eventi mutuamente esclusivi per ottenere:\n\\[ P(\\text{B} \\cup \\text{O}) = P(B) + P(O) = 0.10 + 0.45 = 0.55 \\]\nQuindi, c‚Äô√® una probabilit√† del 55% che una persona selezionata a caso nella nostra popolazione possa donare sangue a qualcuno con tipo di sangue B.\n\n\nEsempio 20.4 Immaginiamo di lanciare due dadi equilibrati, ciascuno con sei facce. Definiamo una variabile casuale discreta \\(Z\\), che rappresenta la somma dei valori ottenuti in ciascun lancio dei dadi. Indichiamo con \\(D_1\\) il risultato del primo dado e con \\(D_2\\) quello del secondo dado, quindi \\(Z = D_1 + D_2\\).\nPer analizzare questa variabile casuale, dobbiamo prima costruire lo spazio campionario associato all‚Äôesperimento. Lo spazio campionario in questo caso √® l‚Äôinsieme di tutte le possibili combinazioni dei risultati dei due lanci di dado. Dato che ogni dado ha sei facce, ci sono in totale \\(6 \\times 6 = 36\\) possibili esiti.\nOgni esito pu√≤ essere rappresentato come una coppia ordinata (i, j), dove i e j sono i risultati dei dadi \\(D_1\\) e \\(D_2\\), rispettivamente. Quindi, lo spazio campionario pu√≤ essere descritto come \\({(1,1), (1,2), (1,3), \\dots, (6,4), (6,5), (6,6)}\\).\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nprint(sample)\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\n\nelements_per_row = 6\n\nfor i in range(0, len(sample), elements_per_row):\n    print(sample[i:i+elements_per_row])\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)]\n[(2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n[(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)]\n[(4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6)]\n[(5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6)]\n[(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLe sequenze come (1, 1), (1, 2), ecc. sono gli eventi elementari di questo esperimento casuale. Lo spazio campione di questo esperimento casuale √® costituito da 36 eventi elementari:\n\nlen(sample)\n\n36\n\n\nPer ogni possibile combinazione (i, j) risultante dal lancio dei due dadi, la variabile casuale \\(Z\\) assume un valore che corrisponde alla somma dei numeri i e j. Ad esempio, se i risultati dei dadi sono 3 e 4, allora \\(Z = 3 + 4 = 7\\). Pertanto, il valore di \\(Z\\) pu√≤ variare da un minimo di 2 (ottenuto dal lancio di due 1) fino a un massimo di 12 (ottenuto dal lancio di due 6), coprendo cos√¨ tutti i possibili risultati della somma dei due dadi. La distribuzione di \\(Z\\) ci offre una panoramica sulle probabilit√† associate a ogni possibile somma risultante.\n√à importante sottolineare che l‚Äôevento \\(Z = u\\), dove \\(u\\) √® un valore compreso tra 2 e 12, rappresenta un ‚Äúevento composto‚Äù. Ci√≤ significa che pu√≤ essere formato da pi√π di un ‚Äúevento elementare‚Äù. Ad esempio, l‚Äôevento \\(Z = 2\\) corrisponde esclusivamente all‚Äôevento elementare (1, 1), mentre l‚Äôevento \\(Z = 3\\) √® il risultato di due eventi elementari differenti: (1, 2) e (2, 1). La stessa logica si applica agli altri valori di \\(Z\\), dove il numero di eventi elementari che contribuiscono a un dato evento composto \\(Z = u\\) aumenta all‚Äôaumentare del valore di \\(u\\). Questa caratteristica della distribuzione di \\(Z\\) √® fondamentale per comprendere e calcolare le probabilit√† associate ai diversi totali possibili nella somma dei due dadi.\nNel nostro esempio costruito usando Python, ogni elemento della lista sample √® una lista di due elementi. Per trovare il valore della variabile casuale \\(Z\\), quindi, dobbiamo sommare i due elementi di ciascuna lista. Nel primo punto campione (1, 1), il valore di \\(Z\\) √® 2:\n\nsum(sample[0])\n\n2\n\n\nIn corrispondenza dell‚Äôultimo punto dello spazio campione (6, 6), il valore di \\(Z\\) √® 12:\n\nsum(sample[35])\n\n12\n\n\nCreiamo ora la lista z che memorizza il valore assunto dalla variabile casuale \\(Z\\) in corrispondenza di ciascun punto dello spazio campione:\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nz = [sum(point) for point in sample]\n\n# Arrange and print `z` in a format with 6 elements per row to reflect a 6x6 sample space\nelements_per_row = 6\nformatted_output = [z[i:i+elements_per_row] for i in range(0, len(z), elements_per_row)]\n\nformatted_output\n\n[[2, 3, 4, 5, 6, 7],\n [3, 4, 5, 6, 7, 8],\n [4, 5, 6, 7, 8, 9],\n [5, 6, 7, 8, 9, 10],\n [6, 7, 8, 9, 10, 11],\n [7, 8, 9, 10, 11, 12]]\n\n\nContiamo dunque quante volte si presenta ciascun possibile valore \\(Z\\) nello spazio campione.\n\n# Inizializzo un dizionario per memorizzare le frequenze di ciascun valore di Z\nfrequenze_z = {}\n\n# Calcolo le frequenze per ciascun valore di Z\nfor valore in z:\n    if valore in frequenze_z:\n        frequenze_z[valore] += 1\n    else:\n        frequenze_z[valore] = 1\n\nfrequenze_z\n\n{2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}\n\n\nI valori di probabilit√† per ciascun valore di \\(z\\) sono calcolati in base alla frequenza con cui quel particolare valore di \\(z\\) emerge all‚Äôinterno dell‚Äôintero insieme dei risultati. In altre parole, per ogni valore \\(z\\), la probabilit√† corrispondente √® determinata dalla proporzione di occorrenze di quel valore \\(z\\) nell‚Äôelenco dei risultati prodotti dall‚Äôesperimento casuale. Questo elenco rappresenta tutti i possibili valori che la variabile casuale \\(Z\\) pu√≤ assumere, calcolati per ogni combinazione di punti nello spazio campionario dell‚Äôesperimento.\nCostruiamo ora la distribuzione di massa di probabilit√† per la variabile casuale \\(Z\\). La probabilit√† di ciascun valore di \\(Z\\) si trova dividendo la sua frequenza per il numero totale di esiti nello spazio campione.\n\n# Calcoliamo il numero totale di esiti nello spazio campione\nnumero_totale_esiti = len(z)\n\n# Inizializzo un dizionario per memorizzare la distribuzione di massa di probabilit√† di Z\ndistribuzione_massa_probabilita = {}\n\n# Calcolo della distribuzione di massa di probabilit√† per ciascun valore di Z\nfor valore, frequenza in frequenze_z.items():\n    distribuzione_massa_probabilita[valore] = frequenza / numero_totale_esiti\n\ndistribuzione_massa_probabilita\n\n{2: 0.027777777777777776,\n 3: 0.05555555555555555,\n 4: 0.08333333333333333,\n 5: 0.1111111111111111,\n 6: 0.1388888888888889,\n 7: 0.16666666666666666,\n 8: 0.1388888888888889,\n 9: 0.1111111111111111,\n 10: 0.08333333333333333,\n 11: 0.05555555555555555,\n 12: 0.027777777777777776}\n\n\nCreiamo un DataFrame con due colonne: i valori di Z e le associate probabilit√†.\n\ndf_distribuzione = pd.DataFrame(list(distribuzione_massa_probabilita.items()), columns=['Valore di Z', 'Probabilit√†'])\n\ndf_distribuzione\n\n\n\n\n\n\n\n\n\nValore di Z\nProbabilit√†\n\n\n\n\n0\n2\n0.027778\n\n\n1\n3\n0.055556\n\n\n2\n4\n0.083333\n\n\n3\n5\n0.111111\n\n\n4\n6\n0.138889\n\n\n5\n7\n0.166667\n\n\n6\n8\n0.138889\n\n\n7\n9\n0.111111\n\n\n8\n10\n0.083333\n\n\n9\n11\n0.055556\n\n\n10\n12\n0.027778\n\n\n\n\n\n\n\n\nPossiamo usare un un grafico a barre per rappresentare la distribuzione di probabilit√† di \\(Z\\).\n\nplt.figure(figsize=(6, 4))\nplt.bar(df_distribuzione['Valore di Z'], df_distribuzione['Probabilit√†'])\nplt.xlabel('Valore di Z')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione di Probabilit√† di Z')\nplt.xticks(range(2, 13))  # Per mostrare tutte le etichette sull'asse x\nplt.grid(axis='y')\nplt.show()\n\n\n\n\n\n\n\n\nNel corso di questo esercizio, abbiamo calcolato le probabilit√† determinando il numero di casi favorevoli, cio√® le occorrenze di ogni possibile somma \\(D_1 + D_2\\), all‚Äôinterno dello spazio campionario dell‚Äôesperimento di lancio di due dadi. Queste probabilit√† si ottengono dividendo il numero di tali occorrenze per il numero totale di combinazioni possibili nello spazio campionario. In termini formali, la probabilit√† di ogni valore specifico di $ Z $ √® indicata come \\(P_Z(z) = P(Z = z)\\), dove \\(P_Z(z)\\) rappresenta ‚Äúla probabilit√† che la variabile casuale \\(Z\\) assuma il valore \\(z\\)‚Äù. La funzione che associa a ogni valore $ u $ di \\(Z\\) la probabilit√† dell‚Äôevento \\(Z = u\\) √® nota come funzione di massa di probabilit√† della variabile casuale \\(Z\\).\nQuesta funzione, $ p_Z $, √® definita per ciascun valore possibile di $ Z $ come segue:\n\\[\n\\begin{array}{rclll}\np_Z(2) & = & 1/36, \\\\\np_Z(3) & = & 2/36, \\\\\np_Z(4) & = & 3/36, \\\\\np_Z(5) & = & 4/36, \\\\\np_Z(6) & = & 5/36, \\\\\np_Z(7) & = & 6/36, \\\\\np_Z(8) & = & 5/36, \\\\\np_Z(9) & = & 4/36, \\\\\np_Z(10) & = & 3/36, \\\\\np_Z(11) & = & 2/36, \\\\\np_Z(12) & = & 1/36. \\\\\n\\end{array}\n\\]\n\n\n\n20.2.5 Propriet√† della funzione di massa di probabilit√†\nOgni variabile casuale discreta possiede una funzione di massa di probabilit√† unica che rispetta le seguenti propriet√†:\n\nLa probabilit√† di ogni evento singolo √® compresa tra 0 e 1, ovvero \\(0 \\leq P(Z=z) \\leq 1\\).\nLa somma delle probabilit√† di tutti gli eventi possibili √® pari a 1, cio√® \\(\\sum_{z \\in Z} P(Z=z) = 1\\).\n\nSe consideriamo un sottoinsieme \\(A\\) della variabile casuale \\(Z\\), la probabilit√† associata a \\(A\\) dalla distribuzione \\(P_Z\\) √® data da:\n\\[\nP_Z(A) = \\sum_{z \\in A} P(Z = z).\n\\]\nPer esempio, per la variabile casuale \\(Z\\) relativa al lancio di due dadi, la probabilit√† che \\(Z\\) sia un numero dispari si calcola sommando le probabilit√† dei valori dispari:\n\\[\n\\begin{align}\nP(\\text{\"Z √® un numero dispari\"}) &= P_Z(3) + P_Z(5) + P_Z(7) + P_Z(9) + P_Z(11) \\\\\n&= \\frac{2}{36} + \\frac{4}{36} + \\frac{6}{36} + \\frac{4}{36} + \\frac{2}{36} \\\\\n&= \\frac{18}{36} \\\\\n&= \\frac{1}{2}.\n\\end{align}\n\\]\nQuesta formula ci permette di calcolare la probabilit√† di qualsiasi sottoinsieme di $ Z $ utilizzando la distribuzione di probabilit√† \\(P_Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "href": "chapters/chapter_3/04a_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "title": "20¬† Variabili casuali",
    "section": "20.3 Funzione di Distribuzione Cumulativa (CDF)",
    "text": "20.3 Funzione di Distribuzione Cumulativa (CDF)\nLa funzione di distribuzione cumulativa (CDF) descrive come le probabilit√† si accumulano fino a un certo valore per una variabile casuale. La CDF di una variabile casuale \\(X\\), denotata \\(F_X(x)\\), √® definita come la probabilit√† che \\(X\\) assuma un valore minore o uguale a \\(x\\):\n\\[\nF_X(x) = \\mathbb{P}(X \\leq x).\n\\]\nIn altre parole, \\(F_X(x)\\) ci dice la probabilit√† totale che la variabile casuale \\(X\\) sia inferiore o uguale a un certo valore \\(x\\).\nUna funzione \\(F\\) √® una CDF se soddisfa le seguenti tre propriet√†:\n\nNon-decrescente: Intuitivamente, questa propriet√† significa che, man mano che ci spostiamo lungo la linea dei numeri reali, la probabilit√† cumulativa non diminuisce mai. Se \\(x_1 &lt; x_2\\), allora \\(F(x_1) \\leq F(x_2)\\). In altre parole, se consideriamo un valore pi√π grande, la probabilit√† cumulativa pu√≤ solo restare la stessa o aumentare, mai diminuire.\nNormalizzazione: Questa propriet√† assicura che la probabilit√† totale su tutta la linea dei numeri reali sia corretta. Specificamente, la CDF deve partire da 0 quando ci spostiamo verso l‚Äôinfinito negativo (\\(\\lim_{x \\rightarrow -\\infty} F(x) = 0\\)) e deve arrivare a 1 quando ci spostiamo verso l‚Äôinfinito positivo (\\(\\lim_{x \\rightarrow +\\infty} F(x) = 1\\)). Questo significa che l‚Äôintera probabilit√† √® distribuita lungo la linea reale.\nContinuit√† a destra: Questa propriet√† significa che la CDF non salta bruscamente quando ci avviciniamo a un punto da destra. Matematicamente, \\(F(x) = F(x^+)\\) per ogni \\(x\\), dove \\(F(x^+)\\) √® il limite della funzione \\(F\\) quando \\(y\\) si avvicina a \\(x\\) da destra. In pratica, questo implica che se ci avviciniamo a un punto specifico da destra, la probabilit√† cumulativa raggiunge quel punto senza salti improvvisi.\n\n\n20.3.1 Funzione di Ripartizione per Variabili Casuali Discrete\nNel contesto delle variabili casuali discrete, la funzione di distribuzione cumulativa viene spesso chiamata funzione di ripartizione. Per una variabile casuale discreta \\(X\\), la funzione di ripartizione, denotata \\(F(x)\\), √® definita come:\n\\[\nF(x_k) = \\mathbb{P}(X \\leq x_k) = \\sum_{x_i \\leq x_k} \\mathbb{P}(x_i)\n\\]\nIn questa formula, \\(F(x_k)\\) rappresenta la probabilit√† che la variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x_k\\). La funzione di ripartizione cumula le probabilit√† dei singoli valori fino a \\(x_k\\).\n\nEsempio 20.5 Per il caso del lancio di due dadi e la variabile casuale \\(Z\\) definita come la loro somma, la funzione di ripartizione di \\(Z\\) pu√≤ essere illustrata come segue:\n\n\n\nz\np(z)\nF(z)\n\n\n\n\n2\n1/36\n1/36\n\n\n3\n2/36\n3/36\n\n\n4\n3/36\n6/36\n\n\n5\n4/36\n10/36\n\n\n6\n5/36\n15/36\n\n\n7\n6/36\n21/36\n\n\n8\n5/36\n26/36\n\n\n9\n4/36\n30/36\n\n\n10\n3/36\n33/36\n\n\n11\n2/36\n35/36\n\n\n12\n1/36\n36/36\n\n\n\nIn questa tabella, \\(F(z)\\) rappresenta la funzione di ripartizione cumulativa per ciascun valore \\(z\\). Questo aiuta a comprendere la distribuzione cumulativa delle probabilit√† per la variabile casuale \\(Z\\) nel contesto del lancio dei due dadi.\n\n\n20.3.1.1 Trovare la distribuzione di probabilit√† con una simulazione\nLa distribuzione di probabilit√† che abbiamo precedentemente calcolato per il lancio dei due dadi √® corretta, ma esiste un altro metodo per ottenere un risultato molto simile attraverso la simulazione. Questo metodo implica la generazione di un elevato numero di ripetizioni dell‚Äôesperimento casuale e l‚Äôanalisi delle frequenze relative dei risultati ottenuti. In altre parole, simulando l‚Äôesperimento numerose volte, possiamo approssimare la distribuzione di probabilit√† empirica, che si avvicina sempre di pi√π alla distribuzione teorica man mano che il numero di ripetizioni aumenta. Questo approccio √® comune in statistica ed √® particolarmente utile quando la distribuzione di probabilit√† teorica non √® facilmente calcolabile o √® troppo complessa per essere gestita in modo analitico.\n\nEsempio 20.6 Nel Capitolo 2 abbiamo visto come creare una funzione che ritorna il risultato del lancio di un dado:\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return rng.choice([1, 2, 3, 4, 5, 6])\n\nPossiamo ora definire una funzione che ritorna la somma dei punti prodotti dal lancio di due dadi. La funzione ha come argomento il numero di ripetizioni di questo esperimento casuale.\n\ndef roll_two_dice(n):\n    \"\"\"\n    returns a random int between 2 and 12\n    \"\"\"\n    rolls = []\n    for i in range(n):\n        two_dice = roll_die() + roll_die()\n        rolls.append(two_dice)\n    \n    return rolls\n\nEseguiamo 100,000 ripetizioni dell‚Äôesperimento casuale e memorizzo i risultati ottenuti.\n\nnrolls = 100000\nres = roll_two_dice(nrolls)\nprint(*res[1:20])\n\n12 10 7 10 7 9 8 7 5 9 8 7 4 9 7 2 10 10 5\n\n\nCreiamo un DataFrame che contiene la variabile y corrispondente ai risultati delle 10,000 ripetizioni dell‚Äôesperimento casuale.\n\ndf = pd.DataFrame()\ndf[\"y\"] = res \n\nUtilizziamo dunque il metodo value_counts(), che pu√≤ essere applicato a un DataFrame, come abbiamo visto nel Capitolo 13, per trovare le frequenze assolute di ciascuno dei possibili risultati dell‚Äôesperimento casuale (cio√®, 2, 3, ‚Ä¶, 12). Dividendo per il numero totale delle ripetizioni, otterremo una stima empirica della probabilit√†. Si noti che i risultati saranno simili a quelli teorici ottenuti in precedenza.\n\nabs_freqs = df[\"y\"].value_counts().sort_index()\npx = abs_freqs / nrolls\nlist(zip(list(range(2, 13)), px))\n\n[(2, 0.02775),\n (3, 0.05625),\n (4, 0.08331),\n (5, 0.11109),\n (6, 0.13915),\n (7, 0.16824),\n (8, 0.13751),\n (9, 0.11167),\n (10, 0.08238),\n (11, 0.05567),\n (12, 0.02698)]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04a_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/04a_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "20¬† Variabili casuali",
    "section": "20.4 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "20.4 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html",
    "href": "chapters/chapter_3/04b_expval_var.html",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "Introduzione\nUna variabile casuale rappresenta un elemento centrale nella teoria della probabilit√† e nelle sue applicazioni statistiche. Dal punto di vista formale, una variabile casuale √® definita come una funzione che associa elementi di uno spazio campionario \\(S\\) a valori in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di quantificare numericamente gli esiti di un fenomeno aleatorio, attribuendo un valore specifico ad ogni possibile risultato.\nLe variabili casuali possono essere classificate in due categorie principali: le variabili casuali discrete e quelle continue. Le variabili casuali discrete sono caratterizzate dal fatto di assumere valori in un insieme finito o al pi√π numerabile, mentre le variabili casuali continue si distinguono per la loro capacit√† di assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo continuo.\nCon il concetto di variabile casuale ben definito, emergono questioni relative alla descrizione dell‚Äôinsieme completo dei possibili esiti e delle probabilit√† associate a ciascun esito. Queste considerazioni portano alla nozione di ‚Äúdistribuzione‚Äù di una variabile casuale. Per le variabili casuali discrete, la distribuzione √® una funzione che elenca tutti i possibili valori che la variabile pu√≤ assumere, insieme alle probabilit√† corrispondenti a ciascun valore. In questo modo, la distribuzione di una variabile casuale fornisce un quadro completo delle sue caratteristiche probabilistiche, consentendo analisi e inferenze statistiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#valore-atteso",
    "href": "chapters/chapter_3/04b_expval_var.html#valore-atteso",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.1 Valore atteso",
    "text": "21.1 Valore atteso\nSpesso √® utile sintetizzare la distribuzione di una variabile casuale tramite indicatori caratteristici. Questi indicatori permettono di cogliere le caratteristiche principali della distribuzione, come la posizione (cio√® il baricentro) e la variabilit√† (cio√® la dispersione attorno ad un centro). In questo modo, si pu√≤ avere una descrizione sintetica della distribuzione di probabilit√† della variabile casuale. In questo capitolo introdurremo i concetti di valore atteso e di varianza di una variabile casule.\nQuando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual √® il suo ‚Äúvalore tipico‚Äù. La nozione di ‚Äúvalore tipico‚Äù, tuttavia, √® ambigua. Infatti, essa pu√≤ essere definita in almeno tre modi diversi:\n\nla media (somma dei valori divisa per il numero dei valori),\nla mediana (il valore centrale della distribuzione, quando la variabile √® ordinata in senso crescente o decrescente),\nla moda (il valore che ricorre pi√π spesso).\n\nPer esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) √® \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana √® \\(3\\) e la moda √® \\(1\\). Tuttavia, la teoria delle probabilit√† si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per ‚Äúvalore tipico‚Äù quando facciamo riferimento alle variabili casuali. Giungiamo cos√¨ alla seguente definizione.\n\nDefinizione 21.1 Sia \\(Y\\) √® una variabile casuale discreta che assume i valori \\(y_1, \\dots, y_n\\) con distribuzione \\(P(Y = y_i) = p(y_i)\\). Per definizione il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), √®\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^n y_i \\cdot p(y_i).\n\\tag{21.1}\\]\n\nA parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale √® definito come la somma di tutti i valori che la variabile casuale pu√≤ prendere, ciascuno pesato dalla probabilit√† con cui il valore √® preso.\n\nEsempio 21.1 Calcoliamo il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0).\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5.\n\\]\n\n\nEsempio 21.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente alla somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nAbbiamo visto nel Capitolo 17 che \\(X\\) pu√≤ assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con distribuzione di massa di probabilit√† pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando l‚ÄôEquazione¬†21.1 otteniamo:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n\\]\nSvolgiamo ora l‚Äôesercizio in Python.\nDefinisco i valori della variabile casuale \\(X\\) e li trasformiamo in un array NumPy:\n\nx = np.array(list(range(2, 13)))\nx\n\narray([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n\n\nPer trovare la distribuzione di massa della variabile \\(X\\) ripeto qui il codice che abbiamo usato nel Capitolo 17.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\n\npx = []\n\nfor i in range(2, 13):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n\npx = np.array(px)\npx\n\narray([0.02777778, 0.05555556, 0.08333333, 0.11111111, 0.13888889,\n       0.16666667, 0.13888889, 0.11111111, 0.08333333, 0.05555556,\n       0.02777778])\n\n\nCalcolo ora il valore atteso della \\(X\\) usando l‚Äôeq. {eq}eq-expval-discr:\n\nex = np.sum(x * px)\nex.round(3)\n\n7.0\n\n\nIn alternativa, posso usare le funzioni del modulo rv_discrete della libreria stats:\n\nx = np.arange(2, 13)\npx = np.array([1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36])\nX = stats.rv_discrete(values=(x, px))\n\nUna volta definito l‚Äôoggetto \\(X\\) con rv_discrete(), il valore atteso viene ritornato dalla funzione expect():\n\nx_ev = X.expect()\nround(x_ev, 3)\n\n7.0\n\n\n\n\n21.1.1 Interpretazione\nIl valore atteso corrisponde alla media aritmetica di un grande numero di realizzazioni indipendenti della variabile casuale.\nPer fare un esempio, ritorniamo all‚Äôesempio precedente relativo al lancio di due dadi bilanciati a sei facce nel quale \\(X\\) rappresenta la ‚Äúsomma dei due dadi‚Äù. Per interpretare il valore atteso, simuliamo un grande numero di realizzazioni indipendenti della \\(X\\) mediante la funzione random.choice() della libreria NumPy. Tale funzione prende come argomenti i valori della variabile casuale, il numero di ripetizioni indipedenti (qui 1,000,000) e la distribuzione di massa di probabilit√†:\n\nx_samples = np.random.choice(x, size=1000000, p=px)\n\nL‚Äôistruzione np.random.choice(x, size=1000000, p=px) utilizza la libreria NumPy per generare un array di 1.000.000 di elementi (parametro size), scelti casualmente dall‚Äôarray x con le probabilit√† specificate nell‚Äôarray px. In particolare, x √® l‚Äôarray di cui si vuole effettuare una scelta casuale e px √® un array che contiene le probabilit√† associate ad ogni elemento di x.\nCome ci aspettavamo, per un grande numero di realizzazioni indipendenti della \\(X\\), la media aritmetica approssima il valore atteso:\n\nnp.mean(x_samples).round(3)\n\n7.002\n\n\n\n\n21.1.2 Propriet√† del valore atteso\nLa propriet√† pi√π importante del valore atteso √® la linearit√†: il valore atteso di una somma di variabili casuali √® uguale alla somma dei lori rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{21.2}\\]\nL‚ÄôEquazione¬†21.2 sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma √® anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{21.3}\\]\nL‚ÄôEquazione¬†21.3 ci dice che possiamo estrarre una costante dall‚Äôoperatore di valore atteso. Tale propriet√† si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che\n\\[\n\\mathbb{E}(X Y) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{21.4}\\]\nLa media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione di media \\(\\mu\\) ha valore atteso\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\mathbb{E}(X_1)+ \\dots \\mathbb{E}(X_n) = \\frac{1}{n} n \\mathbb{E}(X) = \\mu.\n\\]\n\nEsempio 21.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell‚Äôesperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado √® indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avr√† la stessa probabilit√† di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) √® dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l‚ÄôEquazione¬†21.2:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\nSvolgiamo ora l‚Äôesercizio in Python.\n\ncoin = range(0, 2)\ndie = range(1, 7)\n\nsample = [(c, d) for c in coin for d in die]\nlist(sample)\n\n[(0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (0, 5),\n (0, 6),\n (1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6)]\n\n\n\npx = []\nfor i in range(1, 8):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n    print(f\"P(X + Y = {i}) = {len(event)} / {len(sample)}\")\n\nP(X + Y = 1) = 1 / 12\nP(X + Y = 2) = 2 / 12\nP(X + Y = 3) = 2 / 12\nP(X + Y = 4) = 2 / 12\nP(X + Y = 5) = 2 / 12\nP(X + Y = 6) = 2 / 12\nP(X + Y = 7) = 1 / 12\n\n\n\nx = np.arange(1, 8)\nsum(x * px)\n\n4.0\n\n\n\n\nEsempio 21.4 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilit√† congiunta \\(P(X, Y)\\) √® fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l‚ÄôEquazione¬†21.4. Infatti, il valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerci√≤\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\nSvolgiamo l‚Äôesercizio in Python.\n\nr = range(0, 2)\nsample = [(i, j, w) for i in r for j in r for w in r]\n\nfor i in range(0, 4):\n    event = [toss for toss in sample if sum(toss) * toss[0] == i]\n    print(f\"P(Z = {i}) : {len(event)} / {len(sample)}\")\n\nP(Z = 0) : 4 / 8\nP(Z = 1) : 1 / 8\nP(Z = 2) : 2 / 8\nP(Z = 3) : 1 / 8\n\n\n\nz = np.array([0, 1, 2, 3])\npz = np.array([4/8, 1/8, 2/8, 1/8])\nsum(z * pz)\n\n1.0\n\n\n\n\n\n21.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa:\n\\[\n\\mathbb{E}(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname{d}\\!y.\n\\tag{21.5}\\]\nAnche in questo caso il valore atteso √® una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) √® ponderato per il corrispondente valore della densit√† \\(p(y)\\). Possiamo leggere l‚Äôintegrale pensando che \\(y\\) rappresenti l‚Äôampiezza delle barre infinitamente strette di un istogramma, con la densit√† \\(p(y)\\) che corrisponde all‚Äôaltezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma.1\n\n21.1.3.1 Moda\nUn‚Äôaltra misura di tendenza centrale delle variabili casuali continue √® la moda. La moda di \\(Y\\) individua il valore \\(y\\) pi√π plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densit√† \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{21.6}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#varianza",
    "href": "chapters/chapter_3/04b_expval_var.html#varianza",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.2 Varianza",
    "text": "21.2 Varianza\nLa seconda pi√π importante propriet√† di una variabile casuale, dopo che conosciamo il suo valore atteso, √® la varianza.\n\nDefinizione 21.2 Se \\(Y\\) √® una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), √®\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big].\n\\tag{21.7}\\]\n\nA parole: la varianza √® la deviazione media quadratica della variabile dalla sua media.2 Se denotiamo \\(\\mathbb{E}(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\).\n\nEsempio 21.5 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilit√†:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\nSvolgiamo l‚Äôesercizio in Python.\n\nx = np.arange(2, 13)\npx = np.array(\n    [\n        1 / 36,\n        2 / 36,\n        3 / 36,\n        4 / 36,\n        5 / 36,\n        6 / 36,\n        5 / 36,\n        4 / 36,\n        3 / 36,\n        2 / 36,\n        1 / 36,\n    ]\n)\nX = stats.rv_discrete(values=(x, px))\nex = X.expect()\nex\n\n6.999999999999998\n\n\nApplichiamo l‚ÄôEquazione¬†21.7:\n\n((x - ex) ** 2 * px).sum()\n\n5.833333333333333\n\n\nUsiamo la funzione var() di rv_discrete:\n\nX.var()\n\n5.833333333333364\n\n\n\n\n21.2.1 Formula alternativa per la varianza\nC‚Äô√® un modo pi√π semplice per calcolare la varianza:\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big] &= \\mathbb{E}\\big(Y^2 - 2Y\\mathbb{E}(Y) + \\mathbb{E}(Y)^2\\big)\\notag\\\\\n&= \\mathbb{E}(Y^2) - 2\\mathbb{E}(Y)\\mathbb{E}(Y) + \\mathbb{E}(Y)^2,\n\\end{align}\n\\]\ndato che \\(\\mathbb{E}(Y)\\) √® una costante. Pertanto\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2.\n\\tag{21.8}\\]\nA parole: la varianza √® la media dei quadrati meno il quadrato della media della variabile.\n\nEsempio 21.6 Consideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilit√† di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) √®\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\nSvolgiamo l‚Äôesercizio in Python:\n\ny = np.array([0, 1])\npy = np.array([0.2, 0.8])\n\nsum(y**2 * py) - (sum(y * py)) ** 2\n\n0.15999999999999992\n\n\n\n\n\n21.2.2 Propriet√†\nSegno della varianza. La varianza di una variabile aleatoria non √® mai negativa, ed √® zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza √® invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\nx = np.array([2, 1, 4, 7])\ny = 100 + 2 * x\n\nnp.var(y) == 2**2 * np.var(x)\n\nTrue\n\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio √® fornita sotto.\n\nx = np.array([2, 1, 4, 7])\ny = np.array([1, 3, 5, 11])\n\nnp.var(x + y, ddof=0)\n\n35.25\n\n\n\nnp.var(x, ddof=0) + np.var(y, ddof=0) + 2 * np.cov(x, y, ddof=0)[0, 1]\n\n35.25\n\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente √® illustrato dalla seguente simulazione.\n\n# Set up the population distribution\npopulation = np.random.normal(loc=50, scale=10, size=10000)\n\n# Set up the sample size and number of samples\nsample_size = 30\nnum_samples = 100000\n\n# Create an array to hold the sample means\nsample_means = np.zeros(num_samples)\n\n# Generate the samples and compute their means\nfor i in range(num_samples):\n    sample = np.random.choice(population, size=sample_size)\n    sample_means[i] = np.mean(sample)\n\n# Calculate the variance of the sample means\nsampling_dist_mean_var = np.var(sample_means)\nsampling_dist_mean_var\n\n3.4103710835201433\n\n\nIl valore teorico della varianza della distribuzione campionaria della media √®\n\n10**2 / 30\n\n3.3333333333333335\n\n\n\n\n21.2.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\), la varianza diventa:\n\\[\n\\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\mathbb{E}(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y.\n\\tag{21.9}\\]\nCome nel caso discreto, la varianza di una v.c. continua \\(Y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(y\\) dalla loro media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#deviazione-standard",
    "href": "chapters/chapter_3/04b_expval_var.html#deviazione-standard",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.3 Deviazione standard",
    "text": "21.3 Deviazione standard\nQuando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell‚Äôunit√† di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente √® denotato dalla lettera greca \\(\\sigma\\).\n\nDefinizione 21.3 Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:\n\\[\n\\sigma_Y = \\sqrt{\\mathbb{V}(Y)}.\n\\tag{21.10}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media.\nPer i dadi equilibrati dell‚Äôesemio precedebte, la deviazione standard della variabile casuale \\(S\\) √® uguale a \\(\\sqrt{5.833} = 2.415\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#standardizzazione",
    "href": "chapters/chapter_3/04b_expval_var.html#standardizzazione",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.4 Standardizzazione",
    "text": "21.4 Standardizzazione\n\nDefinizione 21.4 Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l‚Äôespressione\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}.\n\\tag{21.11}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/chapter_3/04b_expval_var.html#momenti-di-variabili-casuali",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.5 Momenti di variabili casuali",
    "text": "21.5 Momenti di variabili casuali\n\nDefinizione 21.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densit√† \\(p(x)\\), la quantit√†\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{21.12}\\]\nSe \\(X\\) √® una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i).\n\\tag{21.13}\\]\n\nI momenti sono importanti parametri indicatori di certe propriet√† di \\(X\\). I pi√π noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x ‚àí \\mathbb{E}(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#alcuni-esempi-in-python",
    "href": "chapters/chapter_3/04b_expval_var.html#alcuni-esempi-in-python",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.6 Alcuni esempi in Python",
    "text": "21.6 Alcuni esempi in Python\nUtilizzando il modulo stats di scipy, √® possibile semplificare i calcoli del valore atteso e della varianza di variabili casuali discrete.\nConsideriamo ad esempio una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilit√†: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx = np.arange(7)\nprint(x)\n\n[0 1 2 3 4 5 6]\n\n\nIl vettore px conterr√† le probabilit√† associate ai valori x:\n\npx = [0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\nprint(px)\n\n[0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\n\n\nControlliamo che la somma sia 1:\n\nnp.sum(px)\n\n1.0\n\n\nUsiamo ora la funzione rv_discrete() che √® una funzione della libreria stats di Python. Tale funzione viene utilizzata per creare una distribuzione discreta personalizzata. La funzione richiede che vengano forniti dei valori discreti (ossia interi) e le rispettive probabilit√† di occorrenza.\nUna volta definita la distribuzione discreta, rv_discrete() permette di eseguire operazioni come la generazione di numeri casuali dalla distribuzione, il calcolo della funzione di probabilit√† cumulativa (CDF) e della funzione di densit√† di probabilit√† (PDF), e la valutazione della media, della varianza e di altre statistiche della distribuzione.\nLa sintassi di base della funzione rv_discrete() √® la seguente:\nrv = stats.rv_discrete(name='rv', values=(xk, pk))\ndove name √® il nome della distribuzione discreta, xk sono i valori discreti e pk sono le rispettive probabilit√† di occorrenza. Ad esempio, creiamo la variabile casuale X:\n\nX = stats.rv_discrete(name='rv', values=(x, px))\n\n\n# Distribuzione di massa di probabilit√† di X.\nprint(X.pmf(x))\n\n[0.1 0.2 0.3 0.1 0.1 0.  0.2]\n\n\n\n# Distribuzione comulativa di probabilit√† di X.\nprint(X.cdf(x))\n\n[0.1 0.3 0.6 0.7 0.8 0.8 1. ]\n\n\nGeneriamo un grafico che rappresenta la distribuzione di massa con Matplotlib.\n\nfig, ax = plt.subplots(1, 1)\nax.plot(x, X.pmf(x), \"o\", ms=6)\nax.vlines(x, 0, X.pmf(x), lw=2)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso, ovvero utilizzando i vettori x e px.\n\nx_ev = (x * px).sum()\nx_ev\n\n2.7\n\n\nLo stesso risultato si ottience applicando il metodo .expect() all‚Äôoggetto X.\n\nx_ev = X.expect()\nx_ev\n\n2.7\n\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px.\n\nx_var = ((x - x_ev)**2 * X.pmf(x)).sum()\nx_var\n\n3.8100000000000005\n\n\nOtteniamo lo stesso risultato applicando il metodo .var() all‚Äôoggetto X.\n\nX.var()\n\n3.8099999999999987\n\n\nCalcoliamo la deviazione standard di \\(X\\) prendento la radice quadrata della varianza.\n\nnp.sqrt(x_var)\n\n1.9519221295943137\n\n\nOppure, in maniera equivalente, applicando il metodo .std() all‚Äôoggetto X.\n\nX.std()\n\n1.9519221295943132",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/04b_expval_var.html#commenti-e-considerazioni-finali",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.7 Commenti e considerazioni finali",
    "text": "21.7 Commenti e considerazioni finali\nL‚Äôinferenza bayesiana mira a descrivere la distribuzione a posteriori di variabili casuali che rappresentano i parametri di un modello statistico. Nel capitolo precedente, abbiamo esaminato le caratteristiche principali delle variabili casuali, concentrandoci sul caso discreto. In questo capitolo, abbiamo approfondito le propriet√† di una singola variabile casuale. Nel prossimo capitolo, invece, esploreremo il problema di descrivere il verificarsi congiunto di due o pi√π variabili casuali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/04b_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "21.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "21.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nscipy     : 1.14.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04b_expval_var.html#footnotes",
    "href": "chapters/chapter_3/04b_expval_var.html#footnotes",
    "title": "21¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "Per il significato della notazione di integrale, si veda l‚ÄôAppendice K.‚Ü©Ô∏é\nData una variabile casuale \\(Y\\) con valore atteso \\(\\mathbb{E}(Y)\\), le ‚Äúdistanze‚Äù tra i valori di \\(Y\\) e il valore atteso \\(\\mathbb{E}(Y)\\) definiscono la variabile casuale \\(Y - \\mathbb{E}(Y)\\) chiamata scarto, oppure deviazione oppure variabile casuale centrata. La variabile \\(Y - \\mathbb{E}(Y)\\) equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell‚Äôorigine degli assi. Si pu√≤ dimostrare facilmente che il valore atteso della variabile scarto \\(Y - \\mathbb{E}(Y)\\) vale zero, dunque la media di tale variabile non pu√≤ essere usata per quantificare la ‚Äúdispersione‚Äù dei valori di \\(Y\\) relativamente al suo valore medio. Occorre rendere sempre positivi i valori di \\(Y - \\mathbb{E}(Y)\\) e tale risultato viene ottenuto considerando la variabile casuale \\(\\left(Y - \\mathbb{E}(Y)\\right)^2\\).‚Ü©Ô∏é",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html",
    "href": "chapters/chapter_3/04c_sampling_distr.html",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† verranno utilizzate per costruire gli strumenti fondamentali dell‚Äôinferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/chapter_3/04c_sampling_distr.html#popolazione-e-campioni",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.1 Popolazione e campioni",
    "text": "22.1 Popolazione e campioni\nNell‚Äôanalisi dei dati, l‚Äôobiettivo spesso √® comprendere una quantit√† specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantit√† sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta √® chiamata stima, e la formula che utilizziamo per ottenerla √® conosciuta come stimatore. In termini formali, uno stimatore √® una funzione dei dati osservati, utilizzata per fornire un‚Äôapprossimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo √® inferire determinate propriet√† della popolazione intera dalla quale il campione √® stato tratto. Il parametro √® l‚Äôindicatore numerico di queste propriet√†, ma poich√© spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore √® la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\n√à importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "href": "chapters/chapter_3/04c_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.2 La relazione tra stime e parametri",
    "text": "22.2 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo √® capire e caratterizzare l‚Äôincertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l‚Äôapproccio frequentista, facendo uso di un importante strumento statistico chiamato distribuzione campionaria.\n\n22.2.1 Distribuzione campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, √® fondamentale notare che le propriet√† e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci d√† una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all‚Äôintera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornir√† una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell‚Äôincertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL‚Äôistogramma seguente descrive la distribuzione di frequenza della popolazione.\n\nplt.hist(x, bins=5, density=True, alpha=0.5);\n\n\n\n\n\n\n\n\n\nconteggi, intervalli, _ = plt.hist(x, bins=5, density=True, alpha=0.5)\n\n# Stampiamo gli intervalli utilizzati per l'istogramma\nprint(\"Intervalli utilizzati per l'istogramma:\", intervalli)\nprint(\"Frequenze relative utilizzate per l'istogramma:\", conteggi)\n\nIntervalli utilizzati per l'istogramma: [2.  2.7 3.4 4.1 4.8 5.5]\nFrequenze utilizzate per l'istogramma: [0.35714286 0.         0.         0.35714286 0.71428571]\n\n\n\n\n\n\n\n\n\nLe frequenze assolute si ottengono usando l‚Äôargomento density=False.\n\nconteggi, intervalli, _ = plt.hist(x, bins=5, density=False, alpha=0.5)\nprint(\"Frequenze assolute utilizzate per l'istogramma:\", conteggi)\n\nFrequenze assolute utilizzate per l'istogramma: [1. 0. 0. 1. 2.]\n\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nSupponiamo ora di voler considerare l‚Äôestrazione di tutti i possibili campioni di dimensione \\(n\\) = 2 da una popolazione rappresentata dall‚Äôarray x. Per fare ci√≤, possiamo fare uso di uno strumento di programmazione, come la funzione product del modulo itertools in Python.\nSpecificamente, possiamo utilizzare product con l‚Äôargomento repeat impostato a 2, che indica che vogliamo formare tutte le possibili coppie di valori. In altre parole, stiamo cercando tutte le combinazioni in cui ogni valore nell‚Äôarray x pu√≤ essere abbinato a se stesso o a un altro valore nell‚Äôarray.\nDopo aver utilizzato la funzione product, otteniamo una lista di tuple, che rappresenta tutte le possibili coppie di valori. Possiamo convertire questa lista in un array NumPy pi√π maneggevole utilizzando la funzione np.array. Stampando il risultato, otteniamo un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie che possono essere formate dall‚Äôarray x.\nQuesta rappresentazione di tutte le possibili coppie √® coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento pu√≤ essere scelto pi√π di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sar√† $4^2 = 16 $. Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di \\(4 \\times 4 = 16\\) possibili coppie.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nConvertiamo l‚Äôoutput di itertools.product in un array NumPy per sfruttare le funzionalit√† di questa libreria. L‚Äôarray risultante, samples, √® un array 2D, dove ogni riga rappresenta una coppia di valori.\n\nsamples.shape\n\n(16, 2)\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), possiamo utilizzare la funzione mean del modulo NumPy e applicarla lungo l‚Äôasse delle colonne dell‚Äôarray di coppie di valori. In questo modo otterremo un array unidimensionale contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nLa funzione np.mean(samples, axis=1) calcola la media lungo l‚Äôasse specificato, che in questo caso √® l‚Äôasse 1. In NumPy, l‚Äôasse 0 rappresenta le righe (verticale) e l‚Äôasse 1 rappresenta le colonne (orizzontale).\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\nplt.hist(means, bins=5, density=True, alpha=0.5);\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x.\n\n\n22.2.2 Valore atteso della media campionaria\nSupponiamo che $ X_1, X_2, , X_n $ siano variabili aleatorie iid con valore atteso $ $ e varianza $ ^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nEcco la dimostrazione:\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n\\]\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid √® uguale al valore atteso di ciascuna variabile singola, che in questo caso √® $ $.\nVerifichiamo che ci√≤ sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\n\n\n22.2.3 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid √® uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso √® \\(\\sigma^2/n\\).\nPer l‚Äôesempio in discussione, il valore della varianza delle medie dei campioni √® dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione √® diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall‚Äôanalisi delle medie campionarie:\n\nMedia delle medie campionarie e media della popolazione: La media della distribuzione delle medie campionarie √® identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ $ √®:\n\n\\[\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\nVarianza delle medie campionarie e varianza della popolazione: La varianza della distribuzione delle medie campionarie √® inferiore alla varianza della popolazione e, precisamente, √® pari alla varianza della popolazione divisa per la dimensione del campione:\n\n\\[\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\nInoltre, √® importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\nSe la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sar√† anch‚Äôessa normale.\nSe la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/chapter_3/04c_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale",
    "text": "22.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale\nNella statistica inferenziale, l‚Äôerrore standard √® una misura frequentemente utilizzata per rappresentare l‚Äôincertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L‚Äôerrore standard quantifica quanto possa variare la stima di una statistica da un campione all‚Äôaltro; un errore standard minore indica una stima pi√π precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di ‚Äúmedia pi√π o meno uno (o due) errori standard.‚Äù Questa espressione fornisce una gamma di valori entro cui √® plausibile che ricada il valore vero del parametro della popolazione.\nL‚Äôuso dell‚Äôerrore standard nei grafici non √® soltanto una convenzione; esso √® uno strumento per quantificare e visualizzare l‚Äôincertezza inferenziale. Contribuisce alla comprensione dell‚Äôaffidabilit√† delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, √® importante notare che questo utilizzo dell‚Äôerrore standard pu√≤ essere problematico (Ward e Mann 2022).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/chapter_3/04c_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.4 Legge dei Grandi Numeri",
    "text": "22.4 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) √® un principio fondamentale della teoria delle probabilit√† che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione ‚Äúforte‚Äù e quella ‚Äúdebole‚Äù, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n22.4.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilit√† 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell‚Äôinsieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilit√† √® zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) ‚Äúquasi certamente‚Äù.\n\n\n22.4.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantit√† maggiore di \\(\\epsilon\\) tende a zero all‚Äôaumentare di \\(n\\). Questo fenomeno √® definito come convergenza in probabilit√† verso la media teorica \\(\\mu\\).\n\n\n22.4.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, pi√π in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l‚Äôutilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l‚Äôaffidabilit√† delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 22.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di ‚ÄúTesta‚Äù in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di ‚ÄúTesta‚Äù dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilit√† 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) converger√† a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di ‚ÄúTesta‚Äù (HHHHHH‚Ä¶) o sequenze irregolari come HHTHHTHHTHHT‚Ä¶, ma queste hanno una probabilit√† collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che \\(\\bar{X}_n\\) sia distante pi√π di \\(\\epsilon\\) da \\(1/2\\) pu√≤ essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realt√† non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All‚Äôinizio, notiamo una certa variazione nella proporzione cumulativa di ‚ÄúTesta‚Äù. Tuttavia, con l‚Äôaumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Number of sequences\nnum_sequences = 6\n# Number of tosses\nnum_tosses = 300\n# Initialize a figure\nplt.figure()\n\n# Loop through each sequence\nfor i in range(num_sequences):\n    \n    # Generate a sequence of fair coin tosses (Heads=1, Tails=0)\n    coin_tosses = np.random.choice([0, 1], num_tosses)\n    \n    # Calculate the running proportion of Heads\n    running_proportion = np.cumsum(coin_tosses) / np.arange(1, num_tosses + 1)\n    \n    # Plot the running proportion as a function of the number of tosses\n    plt.plot(np.arange(1, num_tosses + 1), running_proportion, label=f'Sequence {i+1}')\n\n# Plotting the true mean (1/2)\nplt.axhline(y=0.5, color='r', linestyle='--', label='True Mean (1/2)')\n\n# Adding labels and title\nplt.xlabel('Number of Tosses')\nplt.ylabel('Running Proportion of Heads')\nplt.title('Running Proportion of Heads in Six Sequences of Fair Coin Tosses')\nplt.legend()\nplt.legend(fontsize='small')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/chapter_3/04c_sampling_distr.html#teorema-del-limite-centrale",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.5 Teorema del Limite Centrale",
    "text": "22.5 Teorema del Limite Centrale\nIl teorema del limite centrale √® un risultato fondamentale in statistica che √® stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare cos√¨ frequentemente nei fenomeni naturali. Ecco la formulazione essenziale:\n\n22.5.1 Enunciato\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all‚Äôinfinito, la distribuzione di \\(Z\\) converger√† a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n\n22.5.2 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma pu√≤ essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacit√† di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l‚Äôaltezza degli esseri umani adulti pu√≤ essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalit√† rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 22.2 Per visualizzare il TLC in azione, si pu√≤ condurre una simulazione. Immaginiamo una popolazione iniziale con una distribuzione asimmetrica, come una Beta(2, 1). Estraiamo 50.000 campioni di dimensione \\(n\\) da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornir√† un‚Äôillustrazione concreta dell‚Äôefficacia del TLC nell‚Äôapprossimare distribuzioni reali.\n\n# parameters of the beta distribution\na=2\nb=1\n\ndef plotSamples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n          v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together \n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(sample_means)\n    ax2 = ax.twinx()\n    sns.lineplot(x=x,y=y, ax=ax2)\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l‚Äôampiezza campionaria √® 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplotSamples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non √® certamente Normale, inizia ad avvicinarsi alla gaussianit√†.\n\nplotSamples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c‚Äô√® ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l‚Äôapprossimazione migliora.\n\nplotSamples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplotSamples(30)\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, √® possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ci√≤ avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed √® espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/chapter_3/04c_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.6 Distribuzioni campionarie di altre statistiche",
    "text": "22.6 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax)\nax2 = ax.twinx()\nsns.lineplot(x=x, y=y, ax=ax2);\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione √® uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto √® stato interessante: in media, l‚Äôutilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n180.41605015674438\n\n\n\n\n\n\n\n\n\nAbbiamo gi√† visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n224.79716214228156\n\n\n\n\n\n\n\n\n\nLa differenza tra la stima di un parametro e il valore vero del parametro √® chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici √® uguale al valore del parametro che si vuole stimare. In altre parole, l‚Äôerrore medio di stima √® zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) √® uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#considerazioni-conclusive",
    "href": "chapters/chapter_3/04c_sampling_distr.html#considerazioni-conclusive",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.7 Considerazioni conclusive",
    "text": "22.7 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/04c_sampling_distr.html#watermark",
    "href": "chapters/chapter_3/04c_sampling_distr.html#watermark",
    "title": "22¬† Stime, stimatori e parametri",
    "section": "22.8 Watermark",
    "text": "22.8 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.0\nseaborn   : 0.13.2\npandas    : 2.2.1\nnumpy     : 1.26.4\nscipy     : 1.12.0\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nWard, Andrew, e Traci Mann. 2022. ¬´Control yourself: Broad implications of narrowed attention¬ª. Perspectives on Psychological Science 17 (6): 1692‚Äì1703.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html",
    "href": "chapters/chapter_3/05_joint_prob.html",
    "title": "23¬† Probabilit√† congiunta",
    "section": "",
    "text": "Introduzione\nLa probabilit√† congiunta √® la probabilit√† che due o pi√π eventi si verifichino contemporaneamente. In questo capitolo verr√† esaminato il caso discreto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#sec-fun-join-prob",
    "href": "chapters/chapter_3/05_joint_prob.html#sec-fun-join-prob",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.1 Funzione di Probabilit√† Congiunta",
    "text": "23.1 Funzione di Probabilit√† Congiunta\nDopo aver esplorato la distribuzione di probabilit√† di singole variabili casuali, che associa un unico numero reale ad ogni possibile risultato di un esperimento, si procede naturalmente all‚Äôestensione di questo concetto al caso di due o pi√π variabili casuali.\n\n23.1.1 Esempio: Lancio di Tre Monete Equilibrate\nConsideriamo l‚Äôesperimento del lancio di tre monete equilibrate. Lo spazio campione \\(\\Omega\\) √® dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove T rappresenta ‚Äútesta‚Äù e C rappresenta ‚Äúcroce‚Äù. Assumendo che i lanci siano indipendenti, ogni risultato nell‚Äôinsieme \\(\\Omega\\) ha la stessa probabilit√† di occorrenza, ovvero \\(1/8\\).\nDefiniamo le seguenti variabili casuali sullo spazio campione \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il ‚Äúnumero di teste ottenute nei tre lanci‚Äù.\n\\(Y \\in \\{0, 1\\}\\) indica se ‚Äúla testa √® stata ottenuta nel primo lancio‚Äù (1) o no (0).\n\nLa tabella seguente illustra lo spazio campione e le variabili casuali \\(X\\) e \\(Y\\), insieme alle rispettive probabilit√†:\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nPer ogni coppia \\((x, y)\\) definita su \\(\\Omega\\), associamo una probabilit√† come segue:\n\n\\(P(X=0, Y=0) = P(\\text{CCC}) = 1/8\\),\n\ne similmente per le altre coppie.\nLe probabilit√† calcolate per tutte le possibili coppie \\((X, Y)\\) sono:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= 1/8, \\\\\nP(X = 2, Y = 0) &= 1/8, \\\\\nP(X = 2, Y = 1) &= 1/4, \\\\\nP(X = 3, Y = 1) &= 1/8.\n\\end{aligned}\n\\]\nQueste probabilit√† compongono la distribuzione di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\).\n\n\n23.1.2 Definizione: Funzione di Probabilit√† Congiunta\nLa funzione di probabilit√† congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilit√† \\(P(X = x, Y = y)\\).\n\n\n23.1.3 Propriet√†\nUna distribuzione di probabilit√† congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilit√† su tutte le coppie deve essere 1.\n\n\n\n23.1.4 Calcolo della Probabilit√† di Eventi Specifici\nData la distribuzione di probabilit√† congiunta, possiamo determinare la probabilit√† di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilit√† che \\(X + Y \\leq 1\\), sommiamo le probabilit√† di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).\n\n\n23.1.5 Funzioni di Probabilit√† Marginali\nLa distribuzione marginale di un insieme di variabili casuali descrive la distribuzione di probabilit√† di queste variabili considerate singolarmente, indipendentemente dalle altre. La ‚Äúmarginalizzazione‚Äù √® un processo che permette di ottenere la distribuzione di probabilit√† di una o pi√π variabili casuali marginali sommando o integrando la distribuzione congiunta su tutte le possibili realizzazioni delle altre variabili casuali, ovvero quelle non considerate (e quindi ‚Äúmarginalizzate‚Äù).\nPer esempio, data la distribuzione congiunta di due variabili casuali discrete \\(X\\) e \\(Y\\), la distribuzione marginale di \\(X\\), indicata come \\(P(X=x)\\), si calcola come:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilit√† congiunta di \\(X\\) e \\(Y\\). Le distribuzioni marginali e congiunte di variabili casuali discrete sono frequentemente rappresentate in tabelle di contingenza. Si garantisce che le distribuzioni marginali siano normalizzate:\n\\[\n\\sum_x P(X=x) = 1, \\quad \\sum_y P(Y=y) = 1.\n\\]\nPer variabili casuali continue, la somma √® sostituita dall‚Äôintegrazione.\n\nEsempio 23.1 Prendiamo come riferimento l‚Äôesperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilit√† marginali di \\(X\\) e \\(Y\\), sommiamo le probabilit√† congiunte su una dimensione. La probabilit√† marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilit√† lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilit√† marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilit√† lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilit√† congiunta \\(P(X, Y)\\) e le probabilit√† marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n23.1.6 Marginalizzazione per Variabili Casuali Continue\nNell‚Äôambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo √®:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l‚Äôestensione dell‚Äôapproccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/chapter_3/05_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.2 Indipendenza tra Variabili Casuali",
    "text": "23.2 Indipendenza tra Variabili Casuali\nL‚Äôindipendenza tra variabili casuali √® un concetto fondamentale in statistica e probabilit√†, parallelo all‚Äôidea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l‚Äôinformazione su una non altera in alcun modo la distribuzione di probabilit√† dell‚Äôaltra. Questa sezione offre una formalizzazione dell‚Äôindipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilit√† congiunta.\n\n23.2.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ci√≤ significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilit√† congiunta √® il prodotto delle rispettive distribuzioni di probabilit√† marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l‚Äôindipendenza si verifica quando la funzione di densit√† congiunta √® il prodotto delle funzioni di densit√† marginali.\n\n\n23.2.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, √® utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile √® associata alla variazione dell‚Äôaltra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l‚Äôindipendenza tra variabili casuali √® un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate √® fondamentale per l‚Äôanalisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#covarianza",
    "href": "chapters/chapter_3/05_joint_prob.html#covarianza",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.3 Covarianza",
    "text": "23.3 Covarianza\nLa covarianza √® un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell‚Äôaltra. Per esempio, considerando l‚Äôaltezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando cos√¨ una covarianza positiva. La covarianza √® denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n23.3.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) √® definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini pi√π espliciti, la covarianza pu√≤ essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) √® la funzione di probabilit√† congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che √® la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza pu√≤ essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n23.3.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n23.3.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si pu√≤ ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) √®:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 23.2 Per fare un esempio con Python, consideriamo l‚Äôesempio precedente nel quale \\(X\\) √® il numero che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) √® il numero di teste al primo lancio. Troviamo \\(Cov(X, Y)\\).\nCreiamo il prodotto cartesiano che si ottiene per tutti i possibili valori \\(X\\) e i possibili valori \\(Y\\).\n\nc3 = np.arange(0, 4)\nc1 = np.arange(0, 2)\nsample = [(i, j) for i in c1 for j in c3]\nsample\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo numero √® il valore di \\(X\\). Come abbiamo visto in precedenza, per√≤, quete coppie di valori \\(X, Y\\) non hanno tutte la stessa probabilit√† di verificarsi. Infatti, la probabilit√† che ciascuna coppia \\(X, Y\\) si osservi √® data, in sequenza, dai valori 1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8. Questi valori rappresentano la distribuzione di massa di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\). Possiamo quindi applicare l‚Äôeq. {eq}eq-cov-def-rv:\n\nres = []\n\npmf = np.array([1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8])\n\nfor i in range(8):\n    res.append((sample[i][0] - 0.5) * (sample[i][1] - 1.5) * pmf[i])\n\nsum(res)\n\nLa covarianza tra \\(X\\) e \\(Y\\) √® dunque uguale a 0.25.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#correlazione",
    "href": "chapters/chapter_3/05_joint_prob.html#correlazione",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.4 Correlazione",
    "text": "23.4 Correlazione\nMentre la covarianza fornisce un‚Äôindicazione della tendenza di due variabili casuali a variare insieme, essa √® influenzata dalle unit√† di misura delle variabili, rendendo difficile valutare l‚Äôintensit√† della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo cos√¨ una misura standardizzata dell‚Äôassociazione lineare tra di esse.\n\nDefinizione 23.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), √® definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) √® un valore adimensionale, ovvero non dipende dalle unit√† di misura delle variabili, e varia nell‚Äôintervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#propriet√†-1",
    "href": "chapters/chapter_3/05_joint_prob.html#propriet√†-1",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.5 Propriet√†",
    "text": "23.5 Propriet√†\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) √® sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza √® simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unit√† di Misura: La correlazione √® indipendente dalle unit√† di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) √® una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, √® \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n23.5.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza √® nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza pi√π debole rispetto all‚Äôindipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 23.3 Consideriamo una distribuzione di probabilit√† congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilit√† uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilit√† congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilit√† congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) √® zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ci√≤ non implica la loro indipendenza. L‚Äôindipendenza richiede che la funzione di probabilit√† congiunta si possa esprimere come il prodotto delle funzioni di probabilit√† marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l‚Äôassenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l‚Äôincorrelazione non garantisce l‚Äôindipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#variabili-continue",
    "href": "chapters/chapter_3/05_joint_prob.html#variabili-continue",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.6 Variabili continue",
    "text": "23.6 Variabili continue\nConsideriamo ora le distribuzioni di densit√†. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilit√† congiunta \\(p(A,B)\\), le probabilit√† marginali \\(p(A)\\) e \\(p(B)\\), e le probabilit√† condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densit√† (figura tratta da Martin (2024)).\n\n\n\nProbabilit√† congiunta \\(p(A,B)\\): rappresenta la probabilit√† che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa √® data dall‚Äôintegrazione della funzione di densit√† congiunta su un‚Äôarea o volume di interesse.\nProbabilit√† marginale \\(p(A)\\) e \\(p(B)\\): √® la probabilit√† di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densit√† congiunta sull‚Äôintero intervallo di valori dell‚Äôaltra variabile.\nProbabilit√† condizionale \\(p(A \\mid B)\\): esprime la probabilit√† di A dato B. Si calcola dividendo la probabilit√† congiunta per la probabilit√† marginale di B, applicando la definizione di probabilit√† condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilit√† congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/05_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.7 Commenti e considerazioni finali",
    "text": "23.7 Commenti e considerazioni finali\nIn alcune situazioni, ogni singolo elemento di una popolazione pu√≤ essere associato a diverse variabili casuali. Ad esempio, consideriamo l‚Äôelenco di tutti gli studenti iscritti a un‚Äôuniversit√† e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione √® associato a due variabili casuali, l‚Äôaltezza e il peso. Quando si hanno due o pi√π variabili casuali associate ad ogni elemento di una popolazione, √® possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilit√† congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/05_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/05_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "23¬† Probabilit√† congiunta",
    "section": "23.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "23.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMartin, Osvaldo. 2024. Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html",
    "href": "chapters/chapter_3/06_density_func.html",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Introduction\nIn precedenza abbiamo trattato solo variabili casuali discrete, ossia variabili che assumono solo valori interi. Tuttavia, se vogliamo rappresentare grandezze come lunghezze, volumi, distanze o qualsiasi altra propriet√† continua del mondo fisico o psicologico, √® necessario generalizzare l‚Äôapproccio utilizzato finora.\nLe variabili casuali continue assumono valori reali, e l‚Äôinsieme dei numeri reali √® non numerabile in quanto √® pi√π grande dell‚Äôinsieme degli interi.1 Le leggi della probabilit√† valgono sia per le variabili casuali discrete che per quelle continue. Tuttavia, la nozione di funzione di massa di probabilit√† deve essere sostituita dal suo equivalente continuo, la funzione di densit√† di probabilit√†. In questo capitolo, il nostro obiettivo √® chiarire il significato di questa nozione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "chapters/chapter_3/06_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "24.1 Spinner e variabili casuali continue uniformi",
    "text": "24.1 Spinner e variabili casuali continue uniformi\nConsideriamo l‚Äôesperimento casuale in cui facciamo ruotare ad alta velocit√† uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma, identificata dall‚Äôangolo acuto con segno tra il suo asse e l‚Äôasse orizzontale del goniometro. Denotiamo con \\(\\Theta\\) la variabile casuale corrispondente alla ‚Äúpendenza dello spinner‚Äù. In questo contesto, l‚Äôassunzione che lo spinner sia simmetrico implica che, in ogni prova, la rotazione produce un angolo qualunque da 0 a 360 gradi con la stessa probabilit√†. In altre parole, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilit√† di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, dal momento che 36 gradi corrisponde a un decimo del percorso intorno al cerchio, la probabilit√† di ottenere un qualsiasi intervallo di 36 gradi sar√† sempre uguale al 10%. Pi√π precisamente, si ha \\(P(0 \\leq \\Theta \\leq 36) = \\frac{1}{10}\\) e \\(P(200 \\leq \\Theta \\leq 236) = \\frac{1}{10}\\).\n√à importante sottolineare che le probabilit√† sopra menzionate non si riferiscono al fatto che la variabile casuale \\(\\Theta\\) assuma un valore specifico, ma piuttosto all‚Äôevento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilit√† che la pendenza \\(\\Theta\\) cada in un intervallo specificato √® data dalla frazione del cerchio rappresentata dall‚Äôintervallo, cio√® \\(P(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}\\), per ogni intervallo \\([\\theta_1, \\theta_2]\\) tale che \\(0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360\\).\nNel caso di una variabile casuale continua, come l‚Äôangolo dello spinner, dunque, √® facile capire come assegnare una probabilit√† all‚Äôevento in cui la variabile casuale assuma un valore compreso in un intervallo.\n\n24.1.1 Distribuzione uniforme\nL‚Äôesempio dello spinner rappresenta il ‚Äúmeccanismo generatore dei dati‚Äù della variabile casuale continua pi√π semplice, ovvero la distribuzione continua uniforme. In teoria della probabilit√†, la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna la stessa probabilit√† a tutti i punti appartenenti ad un intervallo [a, b] contenuto in un certo insieme.\nLa distribuzione uniforme continua definita sull‚Äôintervallo \\({\\displaystyle S=[a,b]\\subset \\mathbb {R}}\\) viene denotata con \\({\\displaystyle {\\mathcal {U}}(a,b)={\\mathcal {U}}([a,b])}\\). La sua densit√† di probabilit√† √®\n\\[\nf(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n\\]\ne 0 altrimenti. La distribuzione uniforme continua √® caratterizzata dalla sua propriet√† di equidistribuzione: tutti gli intervalli di pari lunghezza all‚Äôinterno dell‚Äôintervallo [a, b] hanno la stessa probabilit√†. In altre parole, se \\({\\displaystyle [c,d]}\\) √® un sottointervallo di \\({\\displaystyle [a,b]}\\), allora la probabilit√† che una variabile casuale continua con distribuzione uniforme in \\({\\displaystyle [a,b]}\\) cada in \\({\\displaystyle [c,d]}\\) √® \\({\\displaystyle (d-c)/(b-a)}\\).\nSvolgiamo un esercizio con Python in cui, per continuare il nostro esempio dello spinner, consideriamo una \\(\\mathcal {U}(0, 360)\\).\n\na = 0\nb = 360\nsize = 101\nx = np.linspace(a, b, size)\ny = st.uniform.pdf(x, loc=a, scale=b)\n\nplt.figure()\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.ylabel(\"Densit√†\");\n\n\n\n\n\n\n\n\nGeneriamo 100,000 valori casuali di una v.c. \\(\\Theta \\sim \\mathcal {U}(0, 360)\\).\n\ndata = rng.uniform(0, 360, size=100000)\n\nL‚Äôistogramma delle 100,000 realizzazioni di \\(\\Theta\\) √® il seguente.\n\nplt.figure()\nplt.hist(data, density=True, alpha=0.5)\nplt.xlabel(\"Theta ~ U[0, 360]\")\nplt.ylabel(\"Densit√†\")\nplt.title(\"Distribuzione uniforme\")\nplt.show()\n\n\n\n\n\n\n\n\n√à chiaro che, all‚Äôaumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell‚Äôistogramma tender√† a diventare una linea retta. Ci√≤ significa che la funzione di densit√† di una variabile casuale uniforme continua √® una costante: \\(f(\\Theta) = c\\).\nDalla figura precedente vediamo che l‚Äôarea sottesa alla funzione di densit√† √® \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densit√† di una variabile casuale uniforme continua non dipende da \\(\\theta\\) ‚Äì √® costante e identica per ogni possibile valore \\(\\theta\\).\nIl valore atteso di \\(X \\sim \\mathcal {U}(a,b)\\) √® dato da\n\\[\n\\mathbb{E} = \\frac{b - a}{2}.\n\\]\nNel caso della presente simulazione otteniamo\n\ndata.mean()\n\n180.44171561785456\n\n\nSvolgiamo un altro semplice esercizio. Consideriamo una variabile casuale uniforme \\(X\\) definita sull‚Äôintervallo [0, 100]. Poniamoci il problema di trovare la probabilit√† \\(P(20 &lt; X &lt; 60)\\).\nPer trovare la soluzione √® sufficiente calcolare l‚Äôarea di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilit√† cercata √® dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/chapter_3/06_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "24.2 Il paradosso delle variabili casuali continue",
    "text": "24.2 Il paradosso delle variabili casuali continue\nConsideriamo ora la probabilit√† che la variabile casuale continua assuma un valore specifico, come ad esempio una pendenza dello spinner esattamente uguale a 36 gradi. Sorprendentemente, la risposta √® zero:\n\\[\nP(\\Theta = 36) = 0.\n\\]\nCi√≤ √® dovuto al fatto che se la probabilit√† di un valore specifico fosse maggiore di zero, allora ogni altro possibile valore dovrebbe avere la stessa probabilit√†, poich√© abbiamo assunto che tutti i valori \\(\\Theta\\) sono egualmente probabili. Ma se sommiamo tutte queste probabilit√†, il totale sarebbe maggiore di uno, il che √® impossibile.\nNel caso delle variabili casuali continue, dobbiamo quindi rinunciare all‚Äôidea che ogni singolo valore della variabile casuale possa avere una massa di probabilit√† maggiore di zero. Invece, una massa di probabilit√† viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. Questo √® ci√≤ che differenzia le variabili casuali continue dalle variabili casuali discrete, dove ogni singolo valore ha una probabilit√† di massa non nulla. In sintesi, le variabili casuali continue non hanno una massa di probabilit√†, ma una densit√† di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#dagli-istogrammi-alle-densit√†",
    "href": "chapters/chapter_3/06_density_func.html#dagli-istogrammi-alle-densit√†",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "24.3 Dagli istogrammi alle densit√†",
    "text": "24.3 Dagli istogrammi alle densit√†\nLe considerazioni precedenti ci fanno comprendere che, a differenza delle variabili casuali discrete, non esiste l‚Äôequivalente di una funzione di massa di probabilit√† per le variabili casuali continue. Invece, esiste una funzione di densit√† di probabilit√† che pu√≤ essere definita in termini di una simulazione. Considerando un numero enorme di casi e facendo tendere l‚Äôampiezza \\(\\Delta\\) di ciascuna classe a 0, il profilo dell‚Äôistogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) √® detta funzione di densit√† di probabilit√†.\nIn un istogramma, l‚Äôarea di ogni barra √® proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo considerato. Dato che tutti gli intervalli hanno la stessa ampiezza, l‚Äôaltezza di ogni barra sar√† proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo. Nella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore nell‚Äôintervallo considerato. Con l‚Äôaumentare del numero di osservazioni \\(M\\), le probabilit√† stimate si avvicinano sempre di pi√π ai valori effettivi della probabilit√†. Inoltre, all‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo tende a 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® appunto la funzione di densit√† di probabilit√† della variabile casuale.\nIn precedenza, nella statistica descrittiva, abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico utilizzato per stimare la funzione di densit√† di probabilit√† di una variabile casuale.\nPer fare un esempio, generiamo 50 valori dalla distribuzione del quoziente di intelligenza. Stampiamo i primi 5 valori.\n\nmu, sigma = 100, 15\nsize = 50\nx = rng.normal(loc=mu, scale=sigma, size=size)\nx[:5]\n\narray([ 91.33354594, 104.82329102, 112.23027301, 123.44901535,\n        98.12903873])\n\n\nCreiamo ora un istogramma a cui sovrapponiamo la funzione di densit√† Normale con parametri corrispondenti alla media e deviazione standard del campione. Con poche osservazioni, non c‚Äô√® una buona corrispondenza tra l‚Äôistogramma e la curva continua che abbiamo chiamato ‚Äúfunzione di densit√†‚Äù.\n\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=25, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.58 e 13.34')\n\n\n\n\n\n\n\n\n\nOra aumentiamo il numero di osservazioni. In questo caso consideriamo 20,000 valori del QI. Generiamo dunque una figura simile alla precedente, solo considerando un campione di dati pi√π grande.\n\nsize = 10000\nx = rng.normal(loc=mu, scale=sigma, size=size)\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=50, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.39 e 15.05')\n\n\n\n\n\n\n\n\n\nOra vediamo che c‚Äô√® una corrispondenza molto buona tra il profilo dell‚Äôistogramma e la curva continua. Questo ci consente la seguente interpretazione: la funzione di densit√† √® una curva che approssima il profilo di un istogramma, quando consideriamo un grande numero di osservazioni. In altre parole, una funzione di densit√† non √® altro che un (profilo di un) istogramma nel caso di un numero infinito di osservazioni e intervalli di ampiezza \\(\\Delta\\) infinitamente piccoli.\nIn un istogramma, l‚Äôarea di ciascuna barra √® proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo. Perch√© tutti gli intervalli hanno la stessa ampiezza, anche l‚Äôaltezza di ciascuna barra sar√† proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo.\nNella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore compreso nell‚Äôintervallo considerato. All‚Äôaumentare del numero \\(M\\) di osservazioni, le probabilit√† stimate si avvicinano sempre di pi√π ai veri valori della probabilit√†. All‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo \\(\\rightarrow\\) 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® la funzione di densit√† di probabilit√† della variabile casuale.\nNella statistica descrittiva abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico per stimare la funzione di densit√† di probabilit√† di una variabile casuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "href": "chapters/chapter_3/06_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "24.4 Funzione di densit√† di probabilit√†",
    "text": "24.4 Funzione di densit√† di probabilit√†\nDa un punto di vista matematico, l‚Äôintuizione precedente si pu√≤ esprimere nel modo seguente.\nPer descrivere le probabilit√† che possono essere associate ad una variabile casuale continua \\(X\\) √® necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due propriet√†:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l‚Äôordinata della funzione di densit√† √® 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l‚Äôarea sottesa dalla \\(p(x)\\) √® unitaria2;\n\\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l‚Äôarea sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilit√† che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. √à possibile che \\(p(x) &gt; 1\\), quindi una densit√† di probabilit√† non pu√≤ essere interpretata come una probabilit√†. Piuttosto, la densit√† \\(p(x)\\) pu√≤ essere utilizzata per confrontare la credibilit√† relativa che pu√≤ essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui √® disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che √® pi√π credibile, in termini relativi, osservare realizzazioni \\(X\\) nell‚Äôintorno di \\(x_k\\) piuttosto che nell‚Äôintorno di \\(x_l\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/chapter_3/06_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "24.5 La funzione di ripartizione per una variabile casuale continua",
    "text": "24.5 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) √® definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCio√®, √® la probabilit√† che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua pu√≤ essere utilizzata per calcolare la probabilit√† che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/06_density_func.html#informazioni-sullambiente-di-sviluppo",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "24.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "24.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.3\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/06_density_func.html#footnotes",
    "href": "chapters/chapter_3/06_density_func.html#footnotes",
    "title": "24¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Georg Cantor dimostr√≤ che era impossibile mappare uno a uno i reali negli interi, dimostrando cos√¨ che l‚Äôinsieme dei reali √® non numerabile.‚Ü©Ô∏é\nPer quel che riguarda la notazione dell‚Äôintegrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html‚Ü©Ô∏é",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html",
    "href": "chapters/chapter_3/07_discr_rv_distr.html",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esploreremo le distribuzioni di probabilit√† discrete, che sono fondamentali per la comprensione dei fenomeni aleatori con un numero finito o numerabile di esiti.\nOgni distribuzione di probabilit√† pu√≤ essere parametrizzata specificando dei parametri che permettono di controllare certi aspetti della distribuzione per raggiungere un obiettivo specifico.\nInizieremo con la distribuzione Bernoulliana, che rappresenta esperimenti con due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù. Questi esperimenti costituiscono il nucleo di ci√≤ che √® definito un processo Bernoulliano. Il parametro della distribuzione Bernoulliana √® la probabilit√† di successo in ciascuna prova.\nQuando tali prove Bernoulliane vengono ripetute per un numero fisso di volte \\(n\\), il conteggio totale dei successi segue una distribuzione binomiale. Anche la distribuzione binomiale dipende da un parametro, la probabilit√† di successo in ciascuna singola prova. Questa distribuzione nasce dalla somma di prove Bernoulliane indipendenti, quando il numero totale di prove \\(n\\) √® stabilito in anticipo.\nSe, invece, il numero stesso di prove diventa una variabile casuale, la distribuzione dei successi all‚Äôinterno di questa serie di prove segue la distribuzione di Poisson. Questa distribuzione √® particolarmente adatta a modellare eventi che avvengono raramente o su intervalli variabili. La distribuzione di Poisson dipende da un unico parametro: il tasso medio di successo per unit√† di tempo o spazio.\nSe la probabilit√† di successo in una serie di prove Bernoulliane non √® costante, ma varia seguendo una distribuzione Beta, il numero di successi osservati in \\(N\\) prove non seguir√† pi√π la distribuzione binomiale, ma seguir√† invece la distribuzione Beta-Binomiale. Questa distribuzione offre una rappresentazione pi√π flessibile e aderente alla realt√† in alcuni contesti.\nInfine, esamineremo la distribuzione uniforme discreta, dove ogni evento all‚Äôinterno di un determinato intervallo finito ha la stessa probabilit√† di verificarsi. Questa distribuzione √® particolarmente utile quando non esistono motivi per privilegiare un risultato rispetto a un altro. La distribuzione uniforme √® molto specifica e non dipende da alcun parametro: una volta stabilito il supporto della distribuzione, c‚Äô√® un unico modo per assegnare le probabilit√† agli eventi.\nIn sintesi, attraverso queste distribuzioni, possiamo modellare e analizzare matematicamente una vasta gamma di situazioni reali, fornendo strumenti utili per comprendere e prevedere fenomeni aleatori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-bernoulliana",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-bernoulliana",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "25.1 Distribuzione Bernoulliana",
    "text": "25.1 Distribuzione Bernoulliana\nIn statistica, un esperimento che presenta soltanto due esiti possibili viene modellato attraverso ci√≤ che √® noto come ‚Äúprova Bernoulliana‚Äù. Un esempio classico √® il lancio di una moneta, che pu√≤ risultare in testa o croce.\n\nDefinizione 25.1 Una variabile casuale \\(Y\\) che assume valori in \\(\\{0, 1\\}\\) √® definita come variabile di Bernoulli. La sua distribuzione di probabilit√† √® descritta come segue:\n\\[\nP(Y \\mid \\theta) =\n  \\begin{cases}\n    \\theta     & \\text{se $Y = 1$ (successo)}, \\\\\n    1 - \\theta & \\text{se $Y = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq \\theta \\leq 1\\). Il parametro \\(\\theta\\) rappresenta la probabilit√† dell‚Äôevento ‚Äúsuccesso‚Äù (\\(Y = 1\\)), mentre \\(1 - \\theta\\) quella dell‚Äôevento ‚Äúinsuccesso‚Äù (\\(Y = 0\\)).\n\nNella distribuzione Bernoulliana, la probabilit√† di osservare l‚Äôesito 1 √® \\(\\theta\\), mentre quella di osservare 0 √® \\(1 - \\theta\\). Questa distribuzione viene utilizzata per modellare situazioni in cui esistono due sole possibili risposte, come un ‚Äús√¨‚Äù o un ‚Äúno‚Äù, un ‚Äúsuccesso‚Äù o un ‚Äúinsuccesso‚Äù.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\\n\\mathbb{V}(Y) &= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta).\n\\end{align}\n\\tag{25.1}\\]\nEsplicitando ulteriormente la formula della varianza con \\(P(Y=0) = 1 - \\theta\\) e \\(P(Y=1) = \\theta\\), abbiamo:\n\\[ \\mathbb{V}(Y) = (0 - \\theta)^2 \\cdot (1 - \\theta) + (1 - \\theta)^2 \\cdot \\theta \\]\nCalcoliamo ora le singole parti dell‚Äôespressione: 1. $ (0 - )^2 = ^2 $ 2. $ (1 - )^2 = 1 - 2+ ^2 $\nSostituendo queste espressioni nell‚Äôequazione della varianza, otteniamo:\n\\[ \\mathbb{V}(Y) = \\theta^2 \\cdot (1 - \\theta) + (1 - 2\\theta + \\theta^2) \\cdot \\theta \\]\n\\[ \\mathbb{V}(Y) = \\theta^2 - \\theta^3 + \\theta - 2\\theta^2 + \\theta^3 \\]\nSemplificando:\n\\[ \\mathbb{V}(Y) = \\theta - \\theta^2 \\]\n\\[ \\mathbb{V}(Y) = \\theta(1-\\theta) \\]\nQuindi, l‚Äôequazione iniziale mostra come la varianza di una variabile casuale binaria \\(Y\\), che segue una distribuzione di Bernoulli con parametro \\(\\theta\\), sia espressa come \\(\\theta(1-\\theta)\\). Questo rispecchia il fatto che la varianza di una distribuzione di Bernoulli raggiunge il suo massimo quando \\(\\theta = 0.5\\), indicando la massima incertezza (o variabilit√†) quando la probabilit√† di successo √® uguale a quella di fallimento.\n\n# Define theta values between 0 and 1\ntheta = np.linspace(0, 1, 100)\n\n# Variance of a Bernoulli distribution is theta(1-theta)\nvariance = theta * (1 - theta)\n\nplt.plot(theta, variance, label='Varianza', color='blue')\nplt.title('Varianza di una variabile Bernoulliana in funzione di $\\\\theta$')\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Varianza')\nplt.show()\n\n\n\n\n\n\n\n\nUtilizziamo la notazione \\(Y \\sim Bernoulli(\\theta)\\) per indicare che la variabile casuale \\(Y\\) segue una distribuzione Bernoulliana di parametro \\(\\theta\\).\nAd esempio, nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilit√† di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilit√† assegna una probabilit√† di \\(\\frac{1}{2}\\) sia per \\(Y = 0\\) che per \\(Y = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-binomiale",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "25.2 Distribuzione Binomiale",
    "text": "25.2 Distribuzione Binomiale\nLa distribuzione binomiale √® una distribuzione di probabilit√† discreta fondamentale, che si concentra sul conteggio del numero di successi in una serie di prove Bernoulliane indipendenti. Queste prove sono caratterizzate dal fatto che ogni evento ha solo due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù, con una probabilit√† di successo costante denotata da \\(\\theta\\).\n\nDefinizione 25.2 La distribuzione binomiale quantifica la probabilit√† di osservare esattamente \\(y\\) successi in \\(n\\) tentativi indipendenti di Bernoulli:\n\\[\nP(Y=y) = \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} = \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y},\n\\] (eq-binomialdistribution)\nQui, \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di combinazioni possibili per ottenere \\(y\\) successi in \\(n\\) prove, mentre \\(\\theta\\) √® la probabilit√† costante di successo per ogni prova.\n\nLa distribuzione binomiale √® spesso illustrata con esempi come il lancio di una moneta o l‚Äôestrazione da un‚Äôurna. Ad esempio, nel caso del lancio ripetuto di una moneta, questa distribuzione descrive la probabilit√† di ottenere un numero specifico di teste in un certo numero di lanci, con ciascun lancio che segue una distribuzione di Bernoulli con probabilit√† di successo \\(\\theta\\).\nUn aspetto interessante della distribuzione binomiale √® la sua propriet√† di riproducibilit√†: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\), ma con diversi numeri di prove (\\(N_1\\) e \\(N_2\\)), allora la loro somma, \\(y = y_1 + y_2\\), sar√† anch‚Äôessa distribuita binomialmente, con parametri \\(N_1 + N_2\\) e \\(\\theta\\).\n\n25.2.1 Calcolo delle Probabilit√†\nPer approfondire il calcolo delle probabilit√† in questa distribuzione, esaminiamo una serie di prove Bernoulliane. Consideriamo una serie di \\(n\\) prove che risultano in \\(y\\) successi:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots I}^\\text{$n-y$ volte}\n\\]\nOgni sequenza con \\(y\\) successi specifici ha una probabilit√† di \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\). Tuttavia, siamo interessati alla probabilit√† complessiva di osservare qualsiasi sequenza con \\(y\\) successi, che si ottiene moltiplicando la probabilit√† di una sequenza singola per il numero totale di sequenze possibili, dato dal coefficiente binomiale \\(\\binom{n}{y}\\).\nIn questo modo, la distribuzione binomiale diventa uno strumento statistico per analizzare fenomeni che presentano esiti binari, con prove che sono indipendenti e identicamente distribuite. Questa distribuzione trova applicazione in una moltitudine di scenari, dalla valutazione del numero di successi in una serie di tentativi, come i lanci di moneta, fino a sondaggi di opinione e altro ancora.\n\n\n25.2.2 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l‚Äôapplicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilit√† di successo in ogni prova √® \\(\\theta = 0.2\\). La probabilit√† di ottenere questo risultato specifico √® calcolata utilizzando l‚Äôeq. {eq}eq-binomialdistribution:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo pu√≤ essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\nn = 4\ntheta = 0.2\ny = 2\n\nprob = math.comb(n, y) * theta**y * (1 - theta) ** (n - y)\nprint(prob)\n\n0.15360000000000007\n\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\nstats.binom.pmf(y, n, theta)\n\n0.15359999999999993\n\n\nUtilizzando scipy.stats.binom.pmf(y, n, p), possiamo trovare le probabilit√† per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\ny = np.arange(0, n + 1)\nprint(y)\n\n[0 1 2 3 4]\n\n\n\nprobabilities = stats.binom.pmf(y, n, theta)\nprint(*probabilities)\n\n0.40959999999999985 0.4096 0.15359999999999993 0.02559999999999999 0.0016000000000000003\n\n\nVisualizziamo la distribuzione di massa di probabilit√†:\n\nplt.figure()\nplt.plot(y, probabilities, \"o\", ms=8)\nplt.vlines(y, 0, probabilities, linestyles=\"-\", lw=1)\nplt.title(f\"Distribuzione binomiale: $n$={n}, $\\\\theta$={theta}\")\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.xlim(-0.5, n + 0.5)\nplt.ylim(0, max(probabilities) + 0.05)\nplt.show()\n\n\n\n\n\n\n\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilit√† di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\nplt.figure()\n\nfor theta in np.arange(0.3, 1.0, 0.3):\n    y = np.arange(0, 25)\n    binom_dist = stats.binom.pmf(y, 20, theta)\n    plt.plot(y, binom_dist, \"-o\", label=f\"theta = {theta:.1f}\")\n\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.title(\"Distribuzione binomiale al variare di $\\\\theta$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nUn‚Äôaltra propriet√† interessante della distribuzione binomiale √® la sua riproducibilit√†. Se abbiamo due variabili casuali indipendenti che seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\) ma con diversi numeri di prove, la loro somma seguir√† anch‚Äôessa una distribuzione binomiale. Questo pu√≤ essere dimostrato analiticamente o sperimentato empiricamente.\n\n# Parameters\nn1, n2 = 10, 15  # Number of trials\ntheta = 0.5  # Success probability\n\n# Analytical binomial distributions\nx1 = np.arange(0, n1+1)\ny1 = stats.binom.pmf(x1, n1, theta)\nx2 = np.arange(0, n2+1)\ny2 = stats.binom.pmf(x2, n2, theta)\n\n# Combined analytical distribution\nx_combined = np.arange(0, n1+n2+1)\ny_combined = stats.binom.pmf(x_combined, n1+n2, theta)\n\n# Simulated distributions\nsimulated1 = rng.binomial(n1, theta, 10000)\nsimulated2 = rng.binomial(n2, theta, 10000)\nsimulated_combined = simulated1 + simulated2\n\n# Plotting\nplt.figure(figsize=(18, 6))\n\n# Plot 1: Binomial 1\nplt.subplot(1, 3, 1)\nplt.bar(x1, y1, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated1, bins=range(n1+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n1}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.ylabel('Probability')\nplt.legend()\n\n# Plot 2: Binomial 2\nplt.subplot(1, 3, 2)\nplt.bar(x2, y2, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated2, bins=range(n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\n# Plot 3: Combined Binomial\nplt.subplot(1, 3, 3)\nplt.bar(x_combined, y_combined, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated_combined, bins=range(n1+n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Combined Binomial Distribution n={n1+n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual √® la probabilit√† che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\nstats.binom.pmf(2, n=5, p=0.5) + stats.binom.pmf(3, n=5, p=0.5) + stats.binom.pmf(4, n=5, p=0.5) +  stats.binom.pmf(5, n=5, p=0.5)\n\n0.8125\n\n\n\nnp.sum([stats.binom.pmf(k, n=5, p=0.5) for k in range(2, 6)])\n\n0.8125\n\n\nPi√π facilmente, si trova la risposta usando la funzione di ripartizione stats.binom.cdf.\n\n1 - stats.binom.cdf(1, n=5, p=0.5) \n\n0.8125\n\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\nn = 5\ntheta = 0.5\ny = np.arange(0, n+1)\n\nplt.figure()\nplt.plot(y, stats.binom.cdf(y, n=n, p=theta))\nplt.scatter(y, stats.binom.cdf(y, n=n, p=theta))\nplt.axhline(1, color=\"k\", alpha=0.7, linestyle=\"--\", lw=1)\nplt.title(f\"Funzione di ripartizione binomiale: $n$={n}, $\\\\theta$={theta}\", loc=\"left\")\nplt.xlabel(\"y\")\n_ = plt.ylabel(\"Probabilit√†\")\n\n\n\n\n\n\n\n\nUn‚Äôaltra funzione utile √® quella che trova il numero di successi in una distribuzione binomiale che corrisponde ad una data probabilit√† (nella coda sinistra della funzione ripartizione). Per l‚Äôesempio presente:\n\ntarget_probability = 1 - 0.8125\nstats.binom.ppf(target_probability, n, theta)\n\n1.0\n\n\nUtilizzando la funzione punto percentuale (PPF), che √® l‚Äôinverso della funzione di distribuzione cumulativa (CDF), possiamo trovare il numero di successi corrispondente alla probabilit√† target di \\(1 - 0.8125 = 0.1875\\) in una distribuzione binomiale con parametri \\(n = 5\\) e \\(\\theta = 0.5\\). Il risultato mostra che il numero di successi cercato per questa probabilit√† target √® 1.\nFacciamo un altro esempio. Consideriamo la probabilit√† cumulativa \\(P(Y \\leq 4)\\) per una variabile casuale \\(Y\\) che segue una distribuzione binomiale con numero di prove \\(n = 10\\) e probabilit√† di successo \\(\\theta = 0.2\\). La funzione stats.binom.cdf(4, n=10, p=0.2) calcola la probabilit√† che ci siano al massimo 4 successi in 10 tentativi, dove la probabilit√† di successo in ogni tentativo √® del 20%.\n\ntarget_probability = stats.binom.cdf(4, n=10, p=0.2)\ntarget_probability\n\n0.9672065024\n\n\nDi conseguenza, la funzione inversa √®:\n\nstats.binom.ppf(target_probability, n=10, p=0.2)\n\n4.0\n\n\nPer generare una sequenza di valori casuali seguendo una distribuzione binomiale possiamo utilizzare la funzione random() di NumPy. Dopo aver inizializzato rng = np.random.default_rng(RANDOM_SEED), per esempio,\n\nrng = np.random.default_rng(42)\n\npossiamo impiegare rng per generare valori casuali da una distribuzione binomiale:\n\nx = rng.binomial(p=.5, n=5, size=30)\nprint(*x)\n\n3 5 1 2 3 2 3 3 3 1 2 4 2 3 0 2 2 2 3 3 4 4 2 0 4 2 2 1 3 2\n\n\nPer una discussione sulla generazione di numeri pseudo-casuali in Python, si veda il capitolo {ref}appendix-rng.\n\n\n25.2.3 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si trovano nel modo seguente:\n\\[\n\\begin{align}\n\\mu    &= n\\theta,  \\notag \\\\\n\\sigma &= \\sqrt{n\\theta(1-\\theta)}.\n\\end{align}\n\\tag{25.2}\\]\nDimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), √® facile vedere che\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = n\\theta, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = n \\theta (1-\\theta).\n\\end{align}\n\\]\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilit√† di ottenere testa (successo) pari a \\(\\theta = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo √® dato da \\(\\mu = n \\theta\\), dove \\(n\\) √® il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(\\theta = 0.2\\), abbiamo:\n\\[\n\\mu = n \\theta = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale √® calcolata come \\(n \\theta (1-\\theta)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n \\theta (1-\\theta) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nx = rng.binomial(p=.2, n=4, size=1000000)\n\n\nnp.mean(x)\n\n0.79956\n\n\n\nnp.var(x, ddof=0)\n\n0.6397598064000003\n\n\n\n\n25.2.4 Funzioni Python associate alle distribuzioni di probabilit√†\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (y | n, Œ∏)\nEsempio: Normale (y | Œº, œÉ)\n\n\n\n\nFunzione di verosimiglianza\nbinom.pmf(y, n, Œ∏)\nnorm.pdf(y, Œº, œÉ)\n\n\nProb Y=y\nbinom.pmf(y, n, Œ∏)\nsempre 0\n\n\nProb Y ‚â• y, Y ‚â§ y, y1 &lt; Y &lt; y2\nbinom.cdf(y, n, Œ∏) o binom.sf(y, n, Œ∏)\nnorm.cdf(y, Œº, œÉ) o norm.sf(y, Œº, œÉ)\n\n\nInversa della CDF\nbinom.ppf(q, n, Œ∏)\nnorm.ppf(q, Œº, œÉ)\n\n\nGenerazione di dati simulati\nrng.binomial(p, n, size)\nrng.normal(Œº, œÉ, size\n\n\n\nIn seguito, utilizzeremo altre distribuzioni, come Uniforme, Beta, ecc., e ognuna di queste ha il proprio insieme di funzioni in Python trovate in scipy.stats. √à possibile consultare queste diverse distribuzioni in opere di riferimento o documentazione online.\nSi noti che pmf (funzione di massa di probabilit√†) √® usato per le distribuzioni discrete come la binomiale, mentre pdf (funzione di densit√† di probabilit√†) √® usata per le distribuzioni continue come la normale. cdf (funzione di distribuzione cumulativa) e sf (funzione di sopravvivenza, che √® 1 - cdf) sono utilizzate per calcolare le probabilit√† cumulative. ppf (percent point function) √® l‚Äôinverso della cdf e viene utilizzata per determinare il valore di variabile al di sotto del quale cade una certa percentuale delle osservazioni. rvs (random variates) √® usata per generare dati simulati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "25.3 Distribuzione Discreta Uniforme",
    "text": "25.3 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme √® un tipo particolare di distribuzione di probabilit√†, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilit√† \\(p\\) di verificarsi. Questa distribuzione √® caratterizzata dalla sua semplicit√† e dalla sua propriet√† fondamentale di equiprobabilit√†.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che pu√≤ assumere valori nell‚Äôinsieme \\(\\{1, 2, \\dots, N\\}\\). Un‚Äôistanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilit√† di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilit√† che \\(X\\) assuma un valore specifico \\(x\\) √® uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilit√† di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci d√† un‚Äôidea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che √® la somma dei primi \\(N\\) numeri naturali. Questa somma √® data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) √® \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo √® calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilit√† (che √® \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l‚Äôidentit√† per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo gi√† stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l‚Äôespressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) √® \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-di-poisson",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-di-poisson",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "25.4 Distribuzione di Poisson",
    "text": "25.4 Distribuzione di Poisson\nLa distribuzione di Poisson √® utilizzata per modellare il numero di eventi indipendenti che si verificano in un intervallo di tempo o spazio prefissato. La variabile casuale discreta \\(Y\\) denota il numero di tali eventi, mentre il parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza di questi eventi in un intervallo specifico.\nLa funzione di massa di probabilit√† associata alla distribuzione di Poisson, che indica la probabilit√† che si verifichino esattamente \\(y\\) eventi, √® definita come segue:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\tag{25.3}\\]\nQuesta equazione illustra:\n\n\\(P(Y = y \\mid \\lambda)\\), la probabilit√† che esattamente \\(y\\) eventi si verifichino.\n\\(\\lambda\\), il tasso medio di occorrenza degli eventi per l‚Äôintervallo considerato.\n\\(y\\), il numero di eventi, che √® limitato ai valori interi non negativi.\n\nUna peculiarit√† della distribuzione di Poisson √® che sia il valore atteso (\\(E[Y]\\)) sia la varianza (\\(Var[Y]\\)) sono equivalenti a \\(\\lambda\\). Questo significa che con l‚Äôaumentare del valore di \\(\\lambda\\), aumenta anche la dispersione dei dati attorno al valore medio, evidenziando un incremento della variabilit√† degli eventi.\nQuale esempio, presentiamo qui sotto un grafico con la distribuzione di Poisson di parametro \\(\\lambda\\) = 2.\n\n# Tasso medio di occorrenza di eventi\nlambda_value = 2\n\n# Creazione della distribuzione di Poisson con il tasso medio specificato\npoisson_dist = stats.poisson(mu=lambda_value)\n\n# Calcolo della probabilit√† di avere un certo numero di eventi\nk_values = range(0, 11)  # Consideriamo valori da 0 a 10\n\n# Calcolo delle probabilit√† corrispondenti\nprobabilities = poisson_dist.pmf(k_values)\n\nplt.figure()\n\n# Plot della distribuzione di massa di probabilit√†\nplt.bar(k_values, probabilities, alpha=0.5)\nplt.xlabel('Numero di Eventi (k)')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione di Massa di Probabilit√† di Poisson')\nplt.show()\n\n\n\n\n\n\n\n\nLa probabilit√† di ottenere un singolo valore \\(y\\) si calcola utilizzando la funzione di massa di probabilit√† (pmf), dove l‚Äôargomento k rappresenta il numero di eventi (\\(y\\)) e mu √® uguale a \\(\\lambda\\). Ad esempio, per determinare la probabilit√† di osservare esattamente tre eventi (\\(y = 3\\)) con un tasso di occorrenza \\(\\lambda\\) = 2, indicata come \\(P(Y = 3)\\), si utilizza la seguente istruzione:\n\nstats.poisson.pmf(k=3, mu=2)\n\n0.18044704431548356\n\n\nLa probabilit√† di non pi√π di 3 eventi, indicata come \\(P(Y \\leq 3)\\), si ottiene nel modo seguente:\n\np = stats.poisson.pmf(k=0, mu=2) + stats.poisson.pmf(k=1, mu=2) + stats.poisson.pmf(k=2, mu=2) + stats.poisson.pmf(k=3, mu=2)\np\n\n0.857123460498547\n\n\nLa funzione ppf, con la probabilit√† e \\(\\lambda\\) come argomenti, restituisce il quantile della distribuzione di Poisson. Ad esempio, nel caso precedente, abbiamo:\n\nstats.poisson.ppf(p, mu=2)\n\n3.0\n\n\nLa funzione di distribuzione cumulativa si calcola utilizzando cdf. Ad esempio, per calcolare \\(P(Y \\leq 3)\\) si utilizza:\n\nstats.poisson.cdf(3, mu=2)\n\n0.857123460498547\n\n\nLa generazione di numeri casuali dalla distribuzione di Poisson pu√≤ essere ottenuta utilizzando rng. Ad esempio:\n\nmu = 2\nx = rng.poisson(mu, 1000000)\n\nVerifichiamo:\n\nnp.mean(x)\n\n1.998219\n\n\n\nnp.var(x, ddof=0)\n\n1.996941828039\n\n\nEsempio. I dati provenienti dal reparto di maternit√† di un certo ospedale mostrano che c‚Äô√® una media storica di 4.5 bambini nati in questo ospedale ogni giorno. Qual √® la probabilit√† che domani nascano 6 bambini in questo ospedale?\nPer prima cosa, calcoliamo la probabilit√† teorica di questo evento utilizzando dpois(). Il numero di successi che stiamo considerando √® 6, quindi imposteremo x = 6. Inoltre, questa media storica di 4,5 nascite al giorno √® il nostro valore per lambda, quindi imposteremo lambda = 6.\n\np = stats.poisson.pmf(k=6, mu=4.5)\nprint(f\"La probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: {p:.4f}\")\n\nLa probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: 0.1281\n\n\nSimuliamo le nascite in questo ospedale per un anno (n = 365) utilizzando la funzione np.random.poisson e confrontiamo la proporzione di giorni in cui ci sono stati 6 nascite con la probabilit√† teorica che abbiamo calcolato in precedenza.\n\n# Simuliamo le nascite in un anno (365 giorni) con una media storica di 4.5 nascite al giorno\nn_days = 365\nmean_births_per_day = 4.5\nsimulated_births = rng.poisson(mean_births_per_day, n_days)\n\n# Calcoliamo la proporzione di giorni in cui sono nati esattamente 6 bambini nella simulazione\nproportion_six_births = np.mean(simulated_births == 6)\n\n# Stampiamo la proporzione calcolata\nprint(f\"La proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: {proportion_six_births:.4f}\")\n\nLa proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: 0.0959\n\n\nVisualizziamo i risultati della simulazione.\n\n# Visualizziamo l'istogramma delle nascite simulate\nplt.hist(simulated_births, bins=np.arange(12) - 0.5, density=True, alpha=0.5)\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\nplt.xticks(np.arange(11));\n\n\n\n\n\n\n\n\nCalcoliamo la probabilit√† teorica della nascita di pi√π di 6 bambini in un giorno.\n\nprob_more_than_six = 1 - stats.poisson.cdf(6, mean_births_per_day)\nprint(f\"La probabilit√† teorica di pi√π di 6 bambini nati √®: {prob_more_than_six:.4f}\")\n\nLa probabilit√† teorica di pi√π di 6 bambini nati √®: 0.1689\n\n\nCalcoliamo la proporzione corrispondente nella simulazione\n\nproportion_more_than_six = np.mean(simulated_births &gt; 6)\nprint(f\"La proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: {proportion_more_than_six:.4f}\")\n\nLa proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: 0.1836\n\n\n\nbins = np.arange(12) - 0.5\nhist, edges = np.histogram(simulated_births, bins=bins, density=True)\n\n# Disegna l'istogramma\nfor i in range(len(hist)):\n    if edges[i] &gt;= 6:\n        color = 'red'  # Colore per x &gt; 6\n    else:\n        color = 'blue'  # Colore per x &lt;= 6\n    plt.bar(edges[i], hist[i], width=1, align='edge', color=color, alpha=0.5)\n\n# Imposta etichette e titolo\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\n_ = plt.xticks(np.arange(11))",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "25.5 Distribuzione Beta-Binomiale",
    "text": "25.5 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilit√† nella probabilit√† di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilit√† per la distribuzione beta-binomiale √® data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{25.4}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilit√† nella probabilit√† di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, √® definita tramite l‚Äôuso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL‚Äôimportanza della distribuzione beta-binomiale deriva dalla sua capacit√† di modellare situazioni in cui la probabilit√† di successo non √® fissa, ma segue una distribuzione di probabilit√†, specificatamente una distribuzione beta. Ci√≤ la rende particolarmente adatta per applicazioni in cui le probabilit√† di successo cambiano in maniera incerta da un tentativo all‚Äôaltro, come pu√≤ avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilit√† di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione pi√π realistica e flessibile per dati empirici che presentano variabilit√† nelle probabilit√† di successo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#considerazioni-conclusive",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#considerazioni-conclusive",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "25.6 Considerazioni Conclusive",
    "text": "25.6 Considerazioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarit√†. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilit√† nella probabilit√† di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilit√† a ogni evento in un insieme finito e discreto. Questa distribuzione √® particolarmente utile quando non abbiamo ragioni per assegnare probabilit√† diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell‚Äôanalisi statistica discreta e trovano applicazione in un‚Äôampia gamma di settori. In particolare, nel contesto dell‚Äôanalisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale √® cruciale, poich√© queste distribuzioni forniscono le basi per l‚Äôaggiornamento bayesiano, un concetto chiave che sar√† esplorato nei capitoli successivi.\nPer coloro interessati a tecniche pi√π avanzate, la generazione di valori casuali a partire da queste distribuzioni √® trattata nell‚Äôappendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l‚Äôapplicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni √® cruciale per chiunque desideri esplorare il vasto campo della probabilit√† e della statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/07_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/07_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "25¬† Distribuzioni di v.c. discrete",
    "section": "25.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "25.7 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html",
    "href": "chapters/chapter_3/08_cont_rv_distr.html",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "Introduzione\nDopo avere introdotto con una simulazione il concetto di funzione di densit√† nel Capitolo 24, prendiamo ora in esame alcune delle densit√† di probabilit√† pi√π note. Iniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-uniforme",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-uniforme",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.1 Distribuzione uniforme",
    "text": "26.1 Distribuzione uniforme\nLa distribuzione uniforme √® la pi√π sempilce funzione di densit√† di probabilit√†. Consideriamo nuovamente l‚Äôesperimento con lo spinner che abbiamo introdotto nel capitolo {ref}density-function-notebook. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\ny = rng.uniform(low=0, high=360, size=20)\nprint(y)\n\n[272.91158643 127.62934853 349.45128878 321.52360368 280.21805895\n  70.06993483 168.01956134  15.76935568  55.54421714 245.89762317\n 268.11437613 348.30350368 117.29712893 133.36549417 169.04009206\n  68.20968927  46.77174192 171.25377344  81.68736566 241.13303809]\n\n\n\nplt.figure()\ncount, bins, ignored = plt.hist(y, bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\nplt.ylabel(\"Frequenza relativa\");\n\n\n\n\n\n\n\n\nSebbene possiamo pensare che sia ugualmente probabile che si verifichi qualsiasi risultato tra 0 e 360, l‚Äôistogramma non sembra suggerire questo. Ma lo spinner √® stato fatto ruotare solo 20 volte. Proviamo con 100,000 ripetizioni.\n\nplt.figure()\ncount, bins, ignored = plt.hist(rng.uniform(0, 360, 100000), bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\n_ = plt.ylabel(\"Frequenza relativa\")\n\n\n\n\n\n\n\n\nIn questo caso, anche se c‚Äô√® una variazione nelle altezze delle barre (con \\(\\Delta\\) = 10), la forma generale dell‚Äôistogramma sembra essere piuttosto piatta, ovvero uniforme, nell‚Äôintero intervallo dei valori possibili di \\(X\\), ovvero \\(0 &lt;= X &lt;= 360\\). Se potessimo ottenere un numero enorme di risultati dello spinner, il profilo dell‚Äôistogramma assumerebbe la forma della funzione di densit√† uniforme mostratra nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 100)\nplt.plot(x, stats.uniform.pdf(x, 0, 360), lw=2, label=\"uniform pdf\")\nplt.xlabel(\"x\")\nplt.ylabel(\"p(x)\");\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) √® continua, come nel caso del risultato della rotazione dello spinner, allora per rappresentare le probabilit√† usiamo una curva chiamata funzione di densit√† di probabilit√†. Poich√© la scala dello spinner va da 0 a 360, sappiamo che tutti i risultati possibili devono cadere in questo intervallo, quindi la probabilit√† che \\(X\\) assuma un valore nell‚Äôintervallo [0, 360] √® 1.0. Questa probabilit√† √® rappresentata dall‚Äôarea totale sotto la funzione di densit√† della figura precedente tra 0 e 360. Poich√© l‚Äôarea di questo rettangolo √® data dall‚Äôaltezza per la base e la base √® uguale a 360, l‚Äôaltezza di questa curva di densit√† deve essere 1/360 = 0.00278. L‚Äôordinata della funzione di densit√† (qui 0.00278 nell‚Äôintervallo [0, 360] e 0 altrove) √® chiamata densit√†.\nLe probabilit√† corrispondono alle aree sottese alla curva di densit√† nell‚Äôintervallo di valori \\(X\\) specificato. Per esempio, nell‚Äôesperimento dello spinner possiamo chiederci quale sia la probabilit√† di ottenere un numero compreso tra 150 e 250, ovvero \\(P(150 &lt; X &lt; 250)\\). Per trovare la risposta dobbiamo calcolare l‚Äôarea di un rettangolo. La base √® 250 - 150 = 100. L‚Äôaltezza √® 0.00278. Dunque, la probabilit√† √®\n\n100*1/360\n\n0.2777777777777778\n\n\nPer svolgere questo calcolo i software utilizzano la funzione di ripartizione, \\(P(X &lt; x)\\). Per trovare l‚Äôarea in un intervallo √® necessario sottrarre due aree. Nel caso presente abbiamo \\(P(x &lt; 250) - P(x &lt; 150)\\), ovvero:\n\nstats.uniform.cdf(250, 0, 360) - stats.uniform.cdf(150, 0, 360)\n\n0.27777777777777773\n\n\nLa probabilit√† cercata √® rappresentata dal rettangolo indicato nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 1000)\nfx = stats.uniform.pdf(x, 0, 360)\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 150) & (x &lt;= 250), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera pi√π formale possiamo dire che la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l‚Äôintervallo unitario \\(I=[0,1]\\).\nLa densit√† di probabilit√† di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) √®\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto √®\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza √®\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn Python √® possibile manipolare la distribuzione uniforme mediante la funzione uniform del modulo scipy.stats. Di default, la funzione scipy.stats.uniform() √® un‚Äôistanziazione di \\({\\mathcal{U}}(0,1)\\). Se utilizziamo la funzione pdf() (probability density function) otteniamo l‚Äôordinata della funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei valori \\(x\\) passati in input. Per esempio, esaminiamo la funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza di 0.5, 0.8 e 1.2. Per i primi due valori ci aspettiamo di ottenere 1; in corrispondenza di 1.2 ci aspettiamo di ottenere 0, poich√© questo valore √® al di fuori dell‚Äôintervallo \\([ 0, 1]\\).\n\nstats.uniform.pdf([0.5, 0.8, 1.2])\n\narray([1., 1., 0.])\n\n\nCon la funzione cdf() (cumulative density function) otteniamo la funzione di ripartizione. Per esempio, per \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei punti 0.5 e 0.8 otteniamo\n\nstats.uniform.cdf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nUsando la funzione di ripartizione √® possibile calcolare la probabilit√† che la variabile casuale continua assuma un valore nell‚Äôintervallo specificato. Per esempio, per \\({\\mathcal{U}}(0,1)\\) troviamo \\(P(0.5 &lt; x &lt; 0.8)\\)\n\nstats.uniform.cdf(0.8) - stats.uniform.cdf(0.5)\n\n0.30000000000000004\n\n\nI quantili di una funzione di densit√† (ovvero, il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input) si ottengono con la funzione ppf() (probability point function). Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di una \\({\\mathcal  {U}}(0,1)\\).\n\nstats.uniform.ppf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nInfine, √® possibile simulare dei valori casuali della distribuzione \\({\\mathcal{U}}(0,1)\\) usando la funzione stats.uniform(). Se vogliamo 5 valori da una \\({\\mathcal{U}}(0,1)\\), scriviamo:\n\nrng.uniform(0, 1, 5)\n\narray([0.51383373, 0.32883263, 0.16402071, 0.13786892, 0.15572435])\n\n\nVerifico il valore atteso di 100,000 realizzazioni di \\({\\mathcal {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).mean()\n\n0.4993283752250098\n\n\nVerifico la varianza di 100,000 realizzazioni di \\({\\mathcal  {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).var()\n\n0.0832097723457758\n\n\n\n1 / 12\n\n0.08333333333333333",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.2 Distribuzione esponenziale",
    "text": "26.2 Distribuzione esponenziale\nUn‚Äôaltra distribuzione di densit√† molto semplice √® la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale √® l‚Äôunica distribuzione di probabilit√† continua che possiede la propriet√† di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinch√© un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si √® rotto dopo 3 anni dal primo utilizzo. L‚Äôassenza di memoria significa che la probabilit√† che questo bicchiere da vino non si rompa nel prossimo anno √® la stessa della probabilit√† che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densit√† esponenziale √®\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{26.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale √®\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale √®\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard √® dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\nPer disegnare un grafico della funzione esponenziale possiamo usare la funzione stats.expon(). La densit√† √® data da pdf(x, loc, scale), laddove il parametro loc √® 0 e scale √® la deviazione standard. Nel caso presente abbiamo:\n\nx = np.arange(0, 20, 0.01)\nmu = 4\nlam = 1 / mu\nstdev = 1 / lam\npdf = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\");\n\n\n\n\n\n\n\n\nChiediamoci, ad esempio, quale sia la probabilit√† di dovere aspettare non pi√π di un giorno e mezzo per conoscere il voto dell‚Äôesame. La risposta a questa domanda √® data dalla funzione di ripartizione in corrispondenza di 1.5, ovvero \\(F(1.5) = P(X \\leq 1.5)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 0) & (x &lt;= 1.5), color=\"0.75\");\n\n\n\n\n\n\n\n\nPossiamo trovare la risposta usando la funzione cdf():\n\nstats.expon.cdf(1.5, loc=0, scale=stdev) \n\n0.3127107212090278\n\n\nChiediamoci, ad esempio quale sia la probabilit√† di conoscere il voto in un tempo compreso tra 1 e 6 giorni. Dobbiamo trovare l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo [1, 6]. Usando la fuzione di ripartizione, calcoliamo \\(F(6) - F(1) = P(X &lt;= 6) - P(X &lt;= 1)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1) & (x &lt;= 6), color=\"0.75\");\n\n\n\n\n\n\n\n\n\nstats.expon.cdf(6, loc=0, scale=stdev) - stats.expon.cdf(1, loc=0, scale=stdev)\n\n0.5556706229229751\n\n\nTroviamo la probabilit√† di dovere aspettare almeno 5 giorni e mezzo.\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 5.5) & (x &lt;= 21), color=\"0.75\");\n\n\n\n\n\n\n\n\nLa probabilit√† cercata √® data dalla probabilit√† dell‚Äôevento complementare di quello fornito dalla funzione di ripartizione.\n\n1 - stats.expon.cdf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\n\nstats.expon.sf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\nSe la media del tempo di attesa nel Corso di Laurea fosse di 4 giorni, allora circa una volta su 4 lo studente dovr√† aspettare almeno 5.5 giorni per conoscere il voto dello scritto.\nLa figura seguente mostra un istogramma di 1000000 valori casuali estratti dalla distribuzione esponenziale di parametro \\(\\lambda = 1/4\\). All‚Äôistogramma √® sovrapposta la funzione di densit√†.\n\nsamps = rng.exponential(stdev, 100000)\n\nplt.figure()\ncount, bins, ignored = plt.hist(samps, bins=100, density=True, alpha=0.5)\nplt.plot(x, fx)\nplt.xlim([0, 20])\nplt.ylabel(\"Frequenza relativa\")\nplt.xlabel(\"Tempo di attesa\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.3 Distribuzione Gaussiana",
    "text": "26.3 Distribuzione Gaussiana\nLa pi√π importante distribuzione di densit√† √® la Gaussiana. Non c‚Äô√® un‚Äôunica distribuzione gaussiana (o Normale): la distribuzione gaussiana √® una famiglia di distribuzioni. Tali distribuzioni sono dette ‚Äúgaussiane‚Äù in onore di Carl Friedrich Gauss (uno dei pi√π grandi matematici della storia il quale, tra le altre cose, scopr√¨ l‚Äôutilit√† di tale funzione di densit√† per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densit√† alle misurazioni dell‚Äôuomo. Karl Pearson us√≤ per primo il termine ‚Äúdistribuzione normale‚Äù anche se ammise che questa espressione ‚Äúha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell‚Äôaltro, non siano normali.‚Äù\n\n26.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre not√≤ che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilit√† di successo di 0.9, la distribuzione √® chiaramente asimmetrica.\n\nn = 10\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist);\n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilit√† di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densit√† di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilit√† binomiale.\n\nn = 1000\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist)\nplt.xlim(850, 950);\n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.4 La Normale prodotta con una simulazione",
    "text": "26.4 La Normale prodotta con una simulazione\nIl libro ‚ÄúRethinking Statistics‚Äù di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo pu√≤ variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall‚Äôorigine, che √® il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non √® possibile determinare la posizione esatta di ogni individuo, ma √® possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall‚Äôorigine.\nAd esempio, √® possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall‚Äôorigine. Queste previsioni sono fattibili perch√© la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sar√† usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando cos√¨ il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps √® un elenco di numeri di passi in cui il codice traccer√† linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array √® riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verr√† utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri della simulazione\nnumero_passi = 16  # Numero di passi per passeggiata\nripetizioni = 1000  # Numero di passeggiate da generare\npunti_da_evidenziare = [4, 8, 16]  # Punti da evidenziare sul grafico\n\n# Inizializza l'array per registrare le passeggiate casuali\nx = np.zeros((numero_passi + 1, ripetizioni))\n\n# Genera le passeggiate casuali\nfor i in range(ripetizioni):\n    passi = rng.uniform(-1, 1, numero_passi)  # Genera passi casuali\n    x[1:, i] = np.cumsum(passi)  # Calcola la posizione cumulativa\n\n# Prepara il grafico\nfig, ax = plt.subplots()\nplt.plot(x, color=\"blue\", alpha=0.05)  # Disegna tutte le passeggiate\nplt.plot(x[:, 0], color=\"black\")  # Evidenzia la prima passeggiata\n\n# Evidenzia i punti specifici\nfor punto in punti_da_evidenziare:\n    plt.axvline(punto, linestyle=\"--\", color=\"black\", alpha=0.5)\n\n# Imposta etichette e aspetti del grafico\nplt.xlabel(\"Numero di passi\")\nplt.ylabel(\"Distanza dall'origine\")\nax.set_xticks(punti_da_evidenziare)\nplt.xlim(0, numero_passi + 0.1)\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota √® che, man mano che procediamo nel numero di passi, le densit√† iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\n# Crea una figura con 3 subplots in orizzontale, condividendo l'asse X\nfig, axs = plt.subplots(1, 3, figsize=(9, 3), sharex=True)\n\n# Itera sui punti da evidenziare e sugli assi corrispondenti\nfor step, ax in zip(punti_da_evidenziare, axs):\n    # Estrae le posizioni al passo specificato per tutte le ripetizioni\n    posizioni_al_passo = x[step, :]\n    \n    az.plot_kde(posizioni_al_passo, bw=0.01, ax=ax)\n    \n    ax.set_title(f\"{step} passi\")\n    ax.set_ylabel(\"Densit√†\")\n    ax.set_xlabel(\"Posizioni\")\n    ax.set_xlim(-6, 6)\n    ax.set_xticks([-6, -3, 0, 3, 6])\n\nplt.tight_layout() \nplt.show()\n\n\n\n\n\n\n\n\nLa chiarezza dell‚Äôinformazione presentata nei grafici precedenti pu√≤ essere migliorata utilizzando un KDE plot.\n\n# Genera la distribuzione uniforme e calcola la somma come prima\npos = rng.uniform(-1, 1, size=(16, 1000)).sum(0)\n\n# Calcola media e deviazione standard dei dati generati\nmedia, dev_std = np.mean(pos), np.std(pos)\n\n# Spazio dei valori per la distribuzione normale\nvalori = np.linspace(np.min(pos), np.max(pos), 1000)\n\n# Calcola la distribuzione normale con la stessa media e deviazione standard\ndistribuzione_normale = stats.norm.pdf(valori, media, dev_std)\n\n# Disegna la stima della densit√† kernel dei dati\naz.plot_kde(pos, label='Distribuzione KDE')\n\n# Sovrappone la distribuzione normale\nplt.plot(valori, distribuzione_normale, label='Distribuzione Normale', color = \"C1\", linestyle='--')\n\nplt.xlabel(\"Posizione\")\nplt.ylabel(\"Densit√†\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilit√†: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che pu√≤ essere uniforme, come nell‚Äôesempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocit√† con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocit√† di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno √® rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana √® quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa pu√≤ essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ci√≤, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni pi√π lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densit√† di probabilit√† √® distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{26.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densit√† normale √® unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densit√† in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell‚Äôeq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densit√† Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 √® fornita nella figura seguente.\n\nx = np.arange(-5, 6, 0.001)\n\nmus = [-1.0, -0.5, 0.0, 1.0]\nsigmas = [0.25, 0.5, 1, 2]\n\nplt.figure()\n\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.norm.pdf(x, mu, sigma)\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n26.4.1 Concentrazione\n√à istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media √® superiore a 3 volte la deviazione standard presenti un carattere di eccezionalit√† perch√© meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n26.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) √® l‚Äôarea sottesa alla curva di densit√† \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilit√† \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEsaminiamo le funzioni per la densit√† Normale. Il metodo rng.normal(loc, scale, size) produce size valori casuali estratti dalla distribuzione Normale specificata. Per esempio, un singolo valore casuale dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\) √®:\n\nrng.normal(loc=100, scale=15, size=1)\n\narray([77.8271813])\n\n\nEstraiamo ora 10 valori a caso dalla \\(\\mathcal{N}(100, 15)\\):\n\nqi = rng.normal(loc=100, scale=15, size=10)\nprint(qi)\n\n[107.37134121  74.33288092  70.05953321 100.16099998  67.01041676\n 102.19573565 114.68076458  58.88627549  69.38274746 112.14401099]\n\n\nPer trovare la probabilit√† che un‚Äôosservazione estratta a caso dalla \\(\\mathcal{N}(100, 15)\\) abbia un valore minore o uguale a, diciamo, 115, troviamo il valore della funzione di ripartizione (o funzione cumulativa di densit√†) nel punto 115.\n\nstats.norm.cdf(115, 100, 15)\n\n0.8413447460685429\n\n\nQuesta √® l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo \\([-\\infty, 115]\\), come indicato nella figura seguente.\n\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\n\nplt.figure()\nplt.plot(x, fx)\n_ = plt.fill_between(x, fx, where=x &lt;= 115, color=\"0.75\")\n\n\n\n\n\n\n\n\nSolo per fare un esempio, qui di seguito fornisco il codice Python per calcolare l‚Äôintegrale che stiamo discutendo per mezzo della funzione quad della libreria SciPy:\n\ndef gaussian(x, mu, sig):\n    return (\n        1.0 / (np.sqrt(2.0 * np.pi) * sig) * np.exp(-np.power((x - mu) / sig, 2.0) / 2)\n    )\n\nmu = 100\nsigma = 15\nresult, error = quad(gaussian, -1000, 115, args=(mu, sigma))\nprint(\"Il risultato √®\", result, \"con errore\", error)\n\nIl risultato √® 0.8413447460685429 con errore 4.0191197364560644e-10\n\n\nIl risultato replica quello prodotto da .norm.cdf().\nPer trovare la proporzione di persone nella popolazione che hanno un QI maggiore di 2 deviazioni standard dalla media consideriamo l‚Äôevento complementare:\n\n1 - stats.norm.cdf(130, 100, 15)\n\n0.02275013194817921\n\n\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=x &gt;= 130, color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo usare la Survival Function:\n\nstats.norm.sf(130, 100, 15)\n\n0.022750131948179198\n\n\nLa funzione ppf restituisce il quantile della Normale. Ad esempio:\n\nstats.norm.ppf(1 - 0.022750131948179195, 100, 15)\n\n130.0\n\n\n\n\n26.4.3 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale √® l‚Äôinsieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL‚Äôarea sottesa alla curva di densit√† di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) √® uguale all‚Äôarea sottesa alla densit√† Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) √® il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l‚Äôarea sottesa nella semiretta \\([1, \\infty)\\) √® uguale all‚Äôarea sottesa nella semiretta \\((-\\infty, 1]\\) e quest‚Äôultima coincide con \\(F(-1)\\). Analogamente, l‚Äôarea sottesa nell‚Äôintervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), √® pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema √® quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato √® detto quantile di ordine \\(p\\) della Normale standard e pu√≤ essere trovato mediante un software.\nSupponiamo che l‚Äôaltezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un‚Äôaltezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l‚Äôarea sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell‚Äôintervallo \\([1.7, 1.8]\\):\n\nstats.norm.cdf(1.8, 1.7, 0.1) - stats.norm.cdf(1.7, 1.7, 0.1)\n\n0.34134474606854315\n\n\n\nmu = 1.7\nsigma = 0.1\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1.7) & (x &lt;= 1.8), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l‚Äôintervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell‚Äôintervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\nstats.norm.cdf(1.0, 0, 1) - stats.norm.cdf(0, 0, 1)\n\n0.3413447460685429\n\n\nIl modo pi√π semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilit√† richiesta non √® altro che la met√† dell‚Äôarea sottesa dalle distribuzioni Normali nell‚Äôintervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l‚Äôinverso della CDF della distribuzione normale.\n\n# Definisco i parametri della distribuzione\nmu = 100\nsigma = 15\n\n# Creo un range di valori su cui calcolare le funzioni\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\n\n# Calcolo la PDF, CDF, e l'inverso della CDF\npdf = stats.norm.pdf(x, mu, sigma)\ncdf = stats.norm.cdf(x, mu, sigma)\nppf = stats.norm.ppf(np.linspace(0.01, 0.99, 100), mu, sigma)  # Evitiamo 0 e 1 per l'inverso\n\n# Creo i grafici in una sola riga\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n# Grafico della PDF\naxs[0].plot(x, pdf, label='PDF')\naxs[0].set_title('PDF')\naxs[0].set_xlabel('Valori')\naxs[0].set_ylabel('Probabilit√†')\naxs[0].legend()\n\n# Grafico della CDF\naxs[1].plot(x, cdf, label='CDF', color='orange')\naxs[1].set_title('CDF')\naxs[1].set_xlabel('Valori')\naxs[1].set_ylabel('Cumulativa')\naxs[1].legend()\n\n# Grafico dell'inverso della CDF\naxs[2].plot(np.linspace(0.01, 0.99, 100), ppf, label='Inverse CDF', color='green')\naxs[2].set_title('Inverse CDF')\naxs[2].set_xlabel('Probabilit√†')\naxs[2].set_ylabel('Valori')\naxs[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalit√† di osservare la stessa informazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.5 Distribuzione Chi-quadrato",
    "text": "26.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libert√† descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libert√†. La densit√† di probabilit√† di \\(\\chi^2_{~\\nu}\\) √®\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) √® una costante positiva.\nLa figura seguente mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\n\nx = np.arange(0, 40, 0.1)\n\nnus = [2, 4, 8, 16]\nplt.figure()\nfor nu in nus:\n    pdf = stats.chi2.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n26.5.1 Propriet√†\n\nLa distribuzione di densit√† \\(\\chi^2_{~\\nu}\\) √® asimmetrica.\nIl valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(\\nu\\).\nLa varianza di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(2\\nu\\).\nPer \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).\nSe \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libert√†, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti.\n\nPer fare un esempio, consideriamo la v.c. \\(\\chi^2_5\\).\n\n# Set the degrees of freedom\ndf = 5\n\n# Create a chi-square distribution object\nchi2_dist = stats.chi2(df)\n\n# Generate x values for the plot\nx = np.linspace(0, 20, 200)\n\n# Calculate the probability density function (PDF) of the chi-square distribution for x values\npdf = chi2_dist.pdf(x)\n\n# Plot the PDF\nplt.figure()\nplt.plot(x, pdf)\nplt.title('Chi-Square Distribution (df=5)')\nplt.xlabel('x')\nplt.ylabel('PDF');\n\n\n\n\n\n\n\n\nGeneriamo 1000000 valori da questa distribuzione.\n\nx = rng.chisquare(5, 1000000)\nx[0:20]\n\narray([3.66284512, 2.96353593, 4.93609572, 4.67151242, 4.10927523,\n       4.16530706, 3.36823832, 9.92342755, 7.02541475, 3.23262943,\n       2.73771833, 3.01973299, 4.83304038, 3.16952063, 5.98040985,\n       6.26951139, 8.73351727, 7.28411818, 7.75225854, 5.77346535])\n\n\nCalcoliamo la media di questi valori.\n\nnp.mean(x)\n\n5.0050584059950385\n\n\nCalcolo la varianza.\n\nnp.var(x, ddof=0)\n\n10.013703149640937",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.6 Distribuzione \\(t\\) di Student",
    "text": "26.6 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un‚Äôaltra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\tag{26.3}\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libert√†. Si usa scrivere \\(T \\sim t_{\\nu}\\). L‚Äôandamento della distribuzione \\(t\\) di Student √® simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code pi√π pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa seguente mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\nx = np.arange(-5, 5, 0.1)\n\nnus = [1, 2, 5, 30]\n\nplt.figure()\nfor nu in nus:\n    pdf = stats.t.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.plot(x, stats.norm.pdf(x, 0, 1), label=\"N(Œº = 0, œÉ = 1)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n26.6.1 Propriet√†\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti propriet√†:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densit√† della \\(t_{\\nu}\\) √® una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto √® sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\).\n\nPer esempio, calcoliamo il valore della funzione di ripartizione di ordine 0.025 nel caso di una \\(t_{30}\\).\n\nstats.t.ppf(0.025, 30)\n\n-2.042272456301238\n\n\nAumentiamo i gradi di libert√†: \\(\\nu\\) = 1000.\n\nstats.t.ppf(0.025, 1000)\n\n-1.9623390808264078\n\n\nQuesto valore √® quasi identico a quello della Normale stanardizzata.\n\nstats.norm.ppf(0.025, 0, 1)\n\n-1.9599639845400545\n\n\nLa ragione per cui il quantile della distribuzione \\(t\\) con \\(\\nu=30\\) √® maggiore (in valore assoluto) del quantile omotetico della distribuzione Normale Standard √® che la distribuzione \\(t\\) ha una varianza maggiore rispetto alla distribuzione Normale Standard.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.7 Funzione Beta di Eulero",
    "text": "26.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero √® una funzione matematica, non una densit√† di probabilit√†. La menzioniamo qui perch√© viene utilizzata nella densit√† di probabilit√† Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si pu√≤ scrivere in molti modi diversi; per i nostri scopi la presentiamo cos√¨:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{26.4}\\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, ovvero il fattoriale discendente, cio√®\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore\n\nalpha = 3\nbeta = 9\nsc.beta(alpha, beta)\n\n0.00202020202020202\n\n\nSi noti che abbiamo usato la funzione beta della libreria scipy.special. Lo stesso risultato si ottiene svolgendo i calcoli in maniera esplicita:\n\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n\n0.00202020202020202\n\n\n\n(math.factorial(alpha-1)*math.factorial(beta-1)) / math.factorial(alpha+beta-1)\n\n0.00202020202020202\n\n\noppure usando la funzione gamma di scipy.special:\n\nsc.gamma(alpha) * sc.gamma(beta) / sc.gamma(alpha + beta)\n\n0.00202020202020202",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-beta",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.8 Distribuzione Beta",
    "text": "26.8 Distribuzione Beta\nLa distribuzione di probabilit√† Beta, denotata comunemente come \\(Beta(\\alpha, \\beta)\\), √® utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione √® la sua definizione esclusiva nell‚Äôintervallo \\((0, 1)\\). In pratica, ci√≤ significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l‚Äô1 come estremi.\n\n26.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale pu√≤ assumere qualunque valore nell‚Äôintervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densit√† √® descritta dalla seguente formula:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) √® la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n26.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. √à essenziale che entrambi questi parametri siano positivi.\n\n\n26.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta pu√≤ essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilit√† di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilit√† di successo √® un parametro fisso; nella distribuzione Beta, questa probabilit√† diventa una variabile aleatoria.\n\n\n26.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione √® analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall‚Äôaspettativa iniziale della probabilit√† di successo: - Se si presume un‚Äôalta probabilit√† di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa pi√π stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali √® dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un‚Äôillustrazione √® fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\nx = np.linspace(0, 1, 200)\nalphas = [0.5, 5.0, 1.0, 2.0, 2.0]\nbetas = [0.5, 1.0, 3.0, 2.0, 5.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.beta.pdf(x, a, b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.ylim(0, 4.5)\nplt.legend(loc=9);\n\n\n\n\n\n\n\n\n\n\n26.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densit√† di probabilit√† che si estende sull‚Äôintervallo \\([0,1]\\), con l‚Äôarea sottesa dalla curva (l‚Äôintegrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo\n\ndef integrand(p, a, b):\n    return p ** (a - 1) * (1 - p) ** (b - 1)\n\na = 3\nb = 9\nresult, error = quad(integrand, 0, 1, args=(a, b))\nprint(result)\n\n0.00202020202020202\n\n\novvero\n\nresult = (math.gamma(a) * math.gamma(b)) / math.gamma(a + b)\nprint(result)\n\n0.00202020202020202\n\n\novvero, usando la funzione beta di Eulero di scipy.special\n\nsc.beta(a, b)\n\n0.00202020202020202\n\n\n\n\n26.8.6 Propriet√†\nIl valore atteso, la moda e la varianza di una densit√† di probabilit√† Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire la funzione beta_mean_mode_variance() in Python per calcolare la media, la moda e la varianza di una distribuzione di probabilit√† Beta:\n\ndef beta_mean_mode_variance(alpha, beta):\n    mean = alpha / (alpha + beta)\n    mode = (alpha - 1) / (alpha + beta - 2)\n    variance = alpha * beta / ((alpha + beta) ** 2 * (alpha + beta + 1))\n    return mean, mode, variance\n\nPer esempio\n\nalpha = 7\nbeta = 3\nmean, mode, variance = beta_mean_mode_variance(alpha, beta)\nprint(f\"Mean: {mean}, Mode: {mode}, Variance: {variance}\")\n\nMean: 0.7, Mode: 0.75, Variance: 0.019090909090909092\n\n\n\n\n26.8.7 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell‚Äôambito dell‚Äôinferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poich√© permette di bypassare onerose computazioni numeriche tipicamente associate all‚Äôinferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(Œ±, Œ≤), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterr√† la forma funzionale della distribuzione Beta. Ci√≤ significa che, una volta raccolti i dati, l‚Äôaggiornamento a posteriori pu√≤ essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri Œ± e Œ≤ del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (Œ±+x, Œ≤+n-x), senza la necessit√† di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\n√à importante prestare attenzione all‚Äôuso del termine ‚ÄúBeta‚Äù in questo contesto, poich√© assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilit√† continua. - La funzione Beta, una funzione matematica speciale. - Il parametro Œ≤, che insieme ad Œ±, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.9 Distribuzione di Cauchy",
    "text": "26.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy √® un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libert√†. √à definita da una densit√† di probabilit√† che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{26.5}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\nx = np.linspace(-5, 5, 500)\nalphas = [0.0, 0.0, 0.0, -2.0]\nbetas = [0.5, 1.0, 2.0, 1.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.cauchy.pdf(x, loc=a, scale=b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-gamma",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.10 Distribuzione Gamma",
    "text": "26.10 Distribuzione Gamma\nLa densit√† di probabilit√† Gamma √® una distribuzione di probabilit√† continua che gioca un ruolo chiave nella modellazione del tempo di attesa per l‚Äôoccorrenza di un certo numero di eventi indipendenti e rari. Essa √® caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti come parametro di forma e parametro di scala, rispettivamente.\n\n26.10.1 Parametro \\(\\alpha\\) ‚Äì parametro di forma\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione gamma si riduce a una distribuzione esponenziale.\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco attorno a \\((\\alpha - 1) \\cdot \\beta\\).\nSe \\(\\alpha &lt; 1\\), la distribuzione √® inclinata verso destra, mostrando una coda lunga che si estende verso valori pi√π bassi.\n\nIn termini interpretativi, \\(\\alpha\\) rappresenta il numero di eventi che si stanno aspettando. Ad esempio, potrebbe rappresentare il numero di ricordi vividi che ci si aspetta di esperire in un certo periodo di tempo.\n\n\n26.10.2 Parametro \\(\\beta\\) ‚Äì parametro di scala\nIl parametro di scala, \\(\\beta\\), controlla la ‚Äúlarghezza‚Äù della distribuzione:\n\nUn valore pi√π grande di \\(\\beta\\) produce una curva pi√π piatta, indicando una maggiore variabilit√† nel tempo di attesa.\nUn valore pi√π piccolo di \\(\\beta\\) rende la curva pi√π appuntita, indicando una minore variabilit√†.\n\nNel contesto del tempo di attesa, \\(\\beta\\) agisce come una scala temporale, con un valore pi√π grande che indica un periodo di tempo pi√π lungo tra gli eventi, e un valore pi√π piccolo che indica un periodo di tempo pi√π breve.\n\n\n26.10.3 Formula della funzione di densit√† di probabilit√†\nLa formula matematica per la funzione di densit√† di probabilit√† (PDF) della distribuzione gamma √®:\n\\[\nf(x|\\alpha, \\theta) = \\frac{x^{\\alpha-1}e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove,\n\n\\(x\\) √® la variabile casuale continua, con \\(x &gt; 0\\).\n\\(\\theta = \\frac{1}{\\beta}\\).\n\\(\\Gamma(\\alpha)\\) √® la funzione Gamma di Eulero, che estende la nozione di fattoriale ai numeri reali e complessi. Per numeri interi \\(n\\), si ha che \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma √® definita come \\(\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1}e^{-x}dx\\).\n\nLe espressioni per media e varianza della distribuzione Gamma sono le seguenti:\n\nLa media (\\(\\mu\\)) della distribuzione Gamma √® \\(\\mu = \\alpha / \\beta\\), o equivalentemente \\(\\mu = \\alpha \\theta\\), usando il parametro di scala.\nLa varianza (\\(\\sigma^2\\)) della distribuzione Gamma √® \\(\\sigma^2 = \\alpha / \\beta^2\\), o equivalentemente \\(\\sigma^2 = \\alpha \\theta^2\\), adottando il parametro di scala.\n\nQuesto chiarisce la relazione tra i parametri \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso) o \\(\\theta\\) (scala), e come influenzano la distribuzione Gamma.\nPer esempio, qui √® riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\nalpha = 3\nbeta = 5/3\n\nmean = alpha / beta\nprint(mean)\n\n1.7999999999999998\n\n\n\n# Standard deviation = sqrt(alpha / beta^2)\n\nsigma = np.sqrt(alpha / beta**2)\nprint(sigma)\n\n1.0392304845413263\n\n\n\n# Generazione di dati dalla distribuzione Gamma\ndata = rng.gamma(shape=alpha, scale=1/beta, size=100000)\n\n# Plot dell'istogramma dei dati generati\nplt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n\n# Plot della PDF (Probability Density Function) della distribuzione Gamma\nx = np.linspace(0, 10, 1000)\nplt.plot(x, stats.gamma.pdf(x, a=alpha, scale=1/beta), 'r-', lw=2, label='PDF')\n\nplt.xlabel('Valore')\nplt.ylabel('Densit√† di probabilit√†')\nplt.title('Distribuzione Gamma con alpha=3 e beta=5/3')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-log-normale",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#distribuzione-log-normale",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.11 Distribuzione log-normale",
    "text": "26.11 Distribuzione log-normale\nSia \\(y\\) una variabile casuale avente distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo poi una nuova variabile casuale \\(x\\) attraverso la relazione\n\\[\nx = e^y \\quad \\Longleftrightarrow \\quad y = \\log x.\n\\]\nIl dominio di definizione della \\(x\\) √® il semiasse \\(x &gt; 0\\) e la densit√† di probabilit√† \\(f(x)\\) √® data da\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\frac{1}{x} \\exp \\left\\{-\\frac{(\\log x -  \\mu)^2}{2 \\sigma^2} \\right\\}.\n\\tag{26.6}\\]\nQuesta funzione di densit√† √® chiamata log-normale.\nIl valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(x) = \\exp \\left\\{\\mu + \\frac{\\sigma^2}{2} \\right\\}.\n\\]\n\\[\n\\mathbb{V}(x) = \\exp \\left\\{2 \\mu + \\sigma^2 \\right\\} \\left(\\exp \\left\\{\\sigma^2 \\right\\}  -1\\right).\n\\]\nSi puoÃÄ dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale.\nLa figura mostra tre distribuzioni log-normali con \\(\\mu\\) = 0.0 e \\(\\sigma\\) = .25, .5, 1.0.\n\nx = np.linspace(0, 3, 100)\nmus = [0.0, 0.0, 0.0]\nsigmas = [0.25, 0.5, 1.0]\nplt.figure()\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.lognorm.pdf(x, sigma, scale=np.exp(mu))\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.12 Commenti e considerazioni finali",
    "text": "26.12 Commenti e considerazioni finali\nLa statistica bayesiana impiega le distribuzioni di probabilit√† come motore inferenziale per la stima dei parametri e dell‚Äôincertezza. Immaginiamo che le distribuzioni di probabilit√† siano piccoli pezzi di ‚ÄúLego‚Äù con cui possiamo costruire qualsiasi cosa desideriamo. Questo principio si applica analogamente ai modelli statistici bayesiani. Possiamo costruire modelli che vanno dai pi√π semplici ai pi√π complessi, utilizzando le distribuzioni di probabilit√† e le loro interrelazioni.\nPython, oltre al modulo stats, offre la capacit√† di generare campioni casuali da varie distribuzioni di probabilit√† attraverso il generatore di numeri casuali disponibile in NumPy. Dopo aver importato NumPy con il comando:\nimport numpy as np\n√® possibile inizializzare il generatore di numeri casuali (rng) con un valore di seme (seed) specifico, garantendo cos√¨ la riproducibilit√† degli esperimenti:\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nA questo punto, si possono generare campioni da diverse distribuzioni di probabilit√†. Ad esempio, per generare un campione dalla distribuzione normale (gaussiana), si pu√≤ procedere nel seguente modo:\nmedia, deviazione_standard = 0, 1  # Valori per media e deviazione standard\ncampione_normale = rng.normal(media, deviazione_standard, size=100)\nIn questo esempio, size=100 indica che vogliamo generare un campione di 100 valori dalla distribuzione. Analogamente, si possono generare campioni da altre distribuzioni di probabilit√† specificando i relativi parametri:\nDistribuzione Uniforme: Per generare valori da una distribuzione uniforme, definita in un intervallo da a a b, si pu√≤ usare:\na, b = 0, 10  # Estremi dell'intervallo\ncampione_uniforme = rng.uniform(a, b, size=100)  # Aggiunta del parametro 'size'\nDistribuzione t di Student: Per ottenere valori dalla distribuzione t di Student, con un dato numero di gradi di libert√†:\ngradi_libert√† = 10  # Gradi di libert√†\ncampione_t = rng.standard_t(gradi_libert√†, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Beta: Per la distribuzione Beta, specificando i parametri alpha e beta:\nalpha, beta = 2, 5  # Parametri alpha e beta\ncampione_beta = rng.beta(alpha, beta, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Gamma: Infine, per generare un campione dalla distribuzione Gamma, con i parametri di forma e scala:\nforma, scala = 2, 1  # Parametri di forma e scala\ncampione_gamma = rng.gamma(forma, scala, size=100)  # Aggiunta del parametro 'size'\nIn tutti i casi, l‚Äôaggiunta del parametro size consente di specificare la dimensione del campione desiderato.\nPer analizzare le propriet√† statistiche di diverse distribuzioni di probabilit√†, oltre alla generazione di campioni casuali, si utilizzano le funzioni di densit√† di probabilit√† (PDF), le funzioni di ripartizione cumulativa (CDF) e le funzioni quantili. Queste operazioni possono essere effettuate efficacemente utilizzando la libreria SciPy in Python.\nPer determinare la funzione densit√† di probabilit√† (PDF), la quale rappresenta la probabilit√† relativa di osservare un valore all‚Äôinterno di un intervallo continuo, il procedimento √® il seguente. Per la distribuzione normale, ad esempio:\nimport numpy as np\nfrom scipy.stats import norm, uniform, t, beta, gamma\n\nmedia, deviazione_standard = 0, 1\nx = np.linspace(media - 4*deviazione_standard, media + 4*deviazione_standard, 100)\npdf_normale = norm.pdf(x, loc=media, scale=deviazione_standard)\nSimili operazioni possono essere effettuate per altre distribuzioni, come mostrato di seguito:\nDistribuzione Uniforme:\na, b = 0, 10\nx = np.linspace(a, b, 100)\npdf_uniforme = uniform.pdf(x, loc=a, scale=b-a)\nDistribuzione t di Student:\ngradi_libert√† = 10\nx = np.linspace(-5, 5, 100)\npdf_t = t.pdf(x, df=gradi_libert√†)\nDistribuzione Beta:\nalpha, beta_param = 2, 5\nx = np.linspace(0, 1, 100)\npdf_beta = beta.pdf(x, alpha, beta_param)\nDistribuzione Gamma:\nforma, scala = 2, 1\nx = np.linspace(0, 10, 100)\npdf_gamma = gamma.pdf(x, a=forma, scale=scala)\nPer determinare i quantili, ovvero i valori corrispondenti a specifiche probabilit√† cumulate nella funzione di distribuzione, si utilizza la funzione ppf (Percent Point Function). Ad esempio, per la distribuzione normale:\nprobabilit√† = 0.5\nquantile_normale = norm.ppf(probabilit√†, loc=media, scale=deviazione_standard)\nE per le altre distribuzioni:\nDistribuzione Uniforme:\nquantile_uniforme = uniform.ppf(probabilit√†, loc=a, scale=b-a)\nDistribuzione t di Student:\nquantile_t = t.ppf(probabilit√†, df=gradi_libert√†)\nDistribuzione Beta:\nquantile_beta = beta.ppf(probabilit√†, alpha, beta_param)\nDistribuzione Gamma:\nquantile_gamma = gamma.ppf(probabilit√†, a=forma, scale=scala)\nInfine, per calcolare la probabilit√† cumulativa associata a un dato quantile (ovvero la probabilit√† che una variabile casuale sia minore o uguale a quel quantile), si utilizza la funzione cdf (Cumulative Distribution Function). Questo permette di determinare la probabilit√† che si verifichi un evento entro un certo intervallo di valori per la distribuzione considerata. Ad esempio, per la distribuzione normale:\nquantile = 0\nprobabilit√†_normale = norm.cdf(quantile, loc=media, scale=deviazione_standard)\nE analogamente per le altre distribuzioni:\nDistribuzione Uniforme:\nprobabilit√†_uniforme = uniform.cdf(quantile, loc=a, scale=b-a)\nDistribuzione t di Student:\nprobabilit√†_t = t.cdf(quantile, df=gradi_libert√†)\nDistribuzione Beta:\nprobabilit√†_beta = beta.cdf(quantile, alpha, beta_param)\nDistribuzione Gamma:\nprobabilit√†_gamma = gamma.cdf(quantile, a=forma, scale=scala)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/08_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/08_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "26¬† Distribuzioni di v.c. continue",
    "section": "26.13 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "26.13 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\npandas    : 2.2.1\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html",
    "href": "chapters/chapter_3/09_likelihood.html",
    "title": "27¬† La verosimiglianza",
    "section": "",
    "text": "Introduzione\nOltre agli approcci frequentisti e bayesiani, esiste un terzo metodo fondamentale nell‚Äôambito dell‚Äôinferenza statistica: la metodologia basata sulla verosimiglianza. Questo approccio consente ai ricercatori di valutare l‚Äôevidenza relativa quando si confrontano due modelli o ipotesi, in maniera simile alla metodologia bayesiana. Ci√≤ che lo distingue √® il suo esplicito rifiuto di incorporare informazioni pregresse (priori) nelle analisi statistiche.\nQuesto capitolo si concentra sulla funzione di verosimiglianza, concetto centrale che si estende attraverso tutti e tre gli approcci statistici, fungendo da collegamento tra i dati osservati e i parametri di un modello statistico specifico. La rilevanza della funzione di verosimiglianza risiede nella sua capacit√† di fornire un fondamento robusto per l‚Äôinterpretazione e la quantificazione dell‚Äôadeguatezza dei dati ai modelli teorici. Questo la rende uno strumento cruciale per l‚Äôinferenza statistica, indispensabile per comprendere e valutare la conformit√† dei dati rispetto alle teorie proposte.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/chapter_3/09_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "27¬† La verosimiglianza",
    "section": "27.1 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "27.1 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza e la funzione di densit√† (o massa) di probabilit√† sono due concetti fondamentali in statistica che, nonostante condividano la stessa espressione matematica, rivestono ruoli e interpretazioni distinti a seconda del contesto in cui vengono applicati. La chiave per distinguere tra i due concetti risiede nel modo in cui trattiamo i dati e i parametri del modello.\nNel caso della funzione di densit√† (o massa) di probabilit√†, i parametri del modello sono fissati e l‚Äôobiettivo √® valutare la probabilit√† di osservare un certo insieme di dati. Qui, i dati sono variabili, mentre i parametri sono considerati costanti. Per esempio, in un esperimento in cui lanciamo una moneta diverse volte, potremmo usare una distribuzione binomiale per calcolare la probabilit√† di ottenere un certo numero di teste, assumendo un valore noto e fisso per la probabilit√† di ottenere testa in un singolo lancio.\nAl contrario, nella funzione di verosimiglianza, manteniamo i dati osservati come fissi e variamo i parametri del modello per valutare quanto bene questi ultimi si adattino ai dati osservati. Questo processo ci permette di esplorare la plausibilit√† di diversi valori dei parametri dati gli stessi dati. L‚Äôobiettivo √® identificare il set di parametri che meglio spiega i dati osservati.\nFormalmente, la relazione tra la funzione di verosimiglianza e la funzione di densit√† di probabilit√† √® espressa come segue:\n\\[\nL(\\theta | y) \\propto p(y | \\theta),\n\\]\ndove \\(L(\\theta | y)\\) rappresenta la funzione di verosimiglianza per i parametri \\(\\theta\\) dati gli osservazioni \\(y\\), e \\(p(y | \\theta)\\) indica la probabilit√† (o densit√†) di osservare i dati \\(y\\) dato un certo set di parametri \\(\\theta\\).\nPrendiamo l‚Äôesempio del lancio di una moneta. Se osserviamo 7 teste su 10 lanci, la funzione di massa di probabilit√† della distribuzione binomiale ci permette di calcolare la probabilit√† di questo esito per un dato valore di \\(p\\) (la probabilit√† di testa). In questo contesto, \\(p\\) √® fisso e i dati (\\(y = 7\\) teste in \\(n = 10\\) lanci) sono variabili.\nDall‚Äôaltro lato, se consideriamo \\(p\\) variabile, la funzione di verosimiglianza ci permette di valutare come diversi valori di \\(p\\) si adattano all‚Äôesito osservato di 7 teste su 10 lanci, mantenendo i dati osservati fissi.\n√à importante sottolineare che, bench√© le due funzioni condividano la stessa forma matematica, il loro utilizzo e interpretazione sono profondamente diversi. La funzione di densit√† di probabilit√† si concentra sulla probabilit√† degli esiti dati i parametri, mentre la funzione di verosimiglianza valuta la plausibilit√† dei parametri dati gli esiti. Questa distinzione √® cruciale per l‚Äôinferenza statistica, permettendoci di stimare i parametri del modello che meglio si adattano ai dati osservati e di comprendere in modo pi√π approfondito la struttura e le caratteristiche del fenomeno studiato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/chapter_3/09_likelihood.html#verosimiglianza-binomiale",
    "title": "27¬† La verosimiglianza",
    "section": "27.2 Verosimiglianza Binomiale",
    "text": "27.2 Verosimiglianza Binomiale\nProseguendo con l‚Äôesempio della distribuzione binomiale, approfondiamo la rilevanza della funzione di verosimiglianza nell‚Äôanalisi statistica attraverso uno scenario pratico. Supponiamo di condurre un esperimento con un numero definito di prove \\(n\\), ognuna delle quali pu√≤ terminare con un successo o un fallimento, come nel caso dei lanci di una moneta. Se registriamo \\(y\\) successi e \\(n - y\\) fallimenti, la probabilit√† di osservare esattamente \\(y\\) successi segue la funzione di massa di probabilit√† (FMP) binomiale, che √® definita come:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\theta\\) √® la probabilit√† di successo in una singola prova di Bernoulli.\nNell‚Äôutilizzo della funzione di verosimiglianza, ci concentriamo su come i diversi valori di \\(\\theta\\) possono spiegare i dati osservati \\(y\\). La verosimiglianza √® espressa come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y},\n\\]\ndato che il coefficiente binomiale \\(\\binom{n}{y}\\), non dipendendo da \\(\\theta\\), pu√≤ essere omesso per la semplicit√† della formulazione.\n\nEsempio 27.1 Per esemplificare, immaginiamo uno studio su un gruppo di 30 individui, di cui 23 presentano un atteggiamento negativo verso il futuro, un indicatore comune in pazienti con depressione (Zetsche, Buerkner, e Renneberg 2019). Qui, i nostri dati \\(y\\) e \\(n\\) sono fissi, e la funzione di verosimiglianza per \\(\\theta\\) sconosciuto diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} (1 - \\theta)^7.\n\\]\nValutando questa funzione per una serie di valori di \\(\\theta\\) possiamo determinare quale valore di \\(\\theta\\) rende i dati osservati pi√π verosimili. Procediamo simulando 100 valori equidistanti di \\(\\theta\\) nell‚Äôintervallo [0, 1] e calcoliamo la verosimiglianza per ciascuno di questi valori.\n\nn = 30\ny = 23\n\nCreiamo i possibili valori del parametro \\(\\theta\\) per i quali calcoleremo la verosimiglianza.\n\ntheta = np.linspace(0.0, 1.0, num=100)\nprint(theta)\n\n[0.         0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n 0.06060606 0.07070707 0.08080808 0.09090909 0.1010101  0.11111111\n 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n 0.18181818 0.19191919 0.2020202  0.21212121 0.22222222 0.23232323\n 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n 0.3030303  0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n 0.36363636 0.37373737 0.38383838 0.39393939 0.4040404  0.41414141\n 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.5959596\n 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n 0.66666667 0.67676768 0.68686869 0.6969697  0.70707071 0.71717172\n 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n 0.78787879 0.7979798  0.80808081 0.81818182 0.82828283 0.83838384\n 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.8989899\n 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n 0.96969697 0.97979798 0.98989899 1.        ]\n\n\nPer esempio, ponendo \\(\\theta = 0.1\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.1)\n\n9.7371682902e-18\n\n\nPonendo \\(\\theta = 0.2\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.2)\n\n3.58141723492221e-11\n\n\nSe ripetiamo questo processo 100 volte, una volta per ciascuno dei valori \\(\\theta\\) che abbiamo elencato sopra, otteniamo 100 coppie di punti \\(\\theta\\) e \\(f(\\theta)\\). A tale fine, definiamo la seguente funzione.\n\ndef like(r, n, theta):\n    return math.comb(n, r) * theta**r * (1 - theta) ** (n - r)\n\nLa curva che interpola i punti ottenuti √® la funzione di verosimiglianza, come indicato dalla figura seguente.\n\nplt.figure()\nplt.plot(theta, like(r=y, n=n, theta=theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");\n\n\n\n\n\n\n\n\n\n\n27.2.1 Interpretazione della Funzione di Verosimiglianza\nL‚Äôinterpretazione della funzione di verosimiglianza ci permette di misurare l‚Äôadattamento dei vari valori di \\(\\theta\\) ai dati. Il valore che massimizza la funzione indica la stima pi√π plausibile di \\(\\theta\\) dati i dati osservati. In termini pratici, se per esempio il valore che massimizza la verosimiglianza √® \\(\\theta = 0.767\\), ci√≤ suggerisce che la probabilit√† pi√π plausibile di successo (o atteggiamento negativo) nella nostra popolazione di studio √® del 76.7%.\nLa determinazione numerica di questo valore ottimale pu√≤ avvenire attraverso tecniche computazionali, come l‚Äôidentificazione del punto di massimo della funzione di verosimiglianza tramite metodi di ottimizzazione. L‚Äôuso di librerie statistiche e matematiche in linguaggi di programmazione come Python consente di effettuare queste analisi con precisione e efficienza, offrendo una stima accurata del parametro \\(\\theta\\) che meglio si adatta ai dati osservati.\nQuesta metodologia, basata sull‚Äôuso della funzione di verosimiglianza, √® cruciale per l‚Äôinferenza statistica, permettendo agli scienziati di stimare i parametri dei modelli statistici in modo informato e di valutare l‚Äôadeguatezza di tali modelli in rappresentanza dei dati reali.\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si pu√≤ localizzare l‚Äôindice nel vettore dei valori di verosimiglianza dove questa raggiunge il suo picco. Metodi computazionali, come l‚Äôuso della funzione argmax in NumPy, possono automatizzare questo processo. Una volta individuato l‚Äôindice che massimizza la verosimiglianza, si pu√≤ risalire al valore corrispondente di \\(\\theta\\) nel vettore dei parametri, ottenendo cos√¨ la stima di \\(\\theta\\) che rende i dati osservati pi√π plausibili.\n\nl = like(r=y, n=n, theta=theta)\nl.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\n√à importante notare che, invece di utilizzare la funzione like() che abbiamo definito precedentemente per motivi didattici, √® possibile ottenere lo stesso risultato utilizzando in modo equivalente la funzione binom.pmf().\n\nplt.figure()\nplt.plot(theta, stats.binom.pmf(y, n, theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#massima-verosimiglianza",
    "href": "chapters/chapter_3/09_likelihood.html#massima-verosimiglianza",
    "title": "27¬† La verosimiglianza",
    "section": "27.3 Massima verosimiglianza",
    "text": "27.3 Massima verosimiglianza\nTra tutti i possibili valori \\(\\theta\\) cerchiao il valore che massimizzi la probabilit√† dei dati osservati, ovvero, cerchiamo il valore \\(\\theta\\) che corrisponde al massimo della funzione di verosimiglianza.\nParliamo di ‚Äúminimizzazione‚Äù quando l ‚Äôobiettivo √® trovare il punto pi√π basso in una valle (minimizzare) o di ‚Äúmassimizzazione‚Äù, quando l‚Äôobiettivo √® quello di trovare il punto pi√π alto su una collina, a seconda della funzione. Nel caso della funzione di verosimiglianza, cerchiamo il punto in cui questa funzione raggiunge il suo valore massimo, ma poich√© molti algoritmi sono progettati per trovare minimi, possiamo cercare il minimo del negativo della funzione di verosimiglianza, che corrisponde al massimo della funzione stessa.\nLa Strategia di Base\n\nPunto di Partenza: L‚Äôalgoritmo inizia da un punto di partenza, che pu√≤ essere scelto casualmente o basato su una qualche ipotesi ragionevole.\nEsplorazione: L‚Äôalgoritmo esplora la ‚Äúsuperficie‚Äù della funzione, muovendosi in direzioni che sembrano portare verso il punto pi√π basso (o pi√π alto, se stiamo massimizzando). Questo √® simile a sentire la pendenza del terreno intorno a noi per decidere in quale direzione camminare.\nAggiustamento: Man mano che procede, l‚Äôalgoritmo aggiusta la sua traiettoria basandosi su ci√≤ che ha ‚Äúsentito‚Äù durante l‚Äôesplorazione. Se trova una discesa, continua in quella direzione; se incontra una salita, prova una direzione differente.\nConvergenza: Il processo continua finch√© l‚Äôalgoritmo non trova un punto in cui non ci sono pi√π discese significative in nessuna direzione, suggerendo che ha trovato il punto pi√π basso (o il punto pi√π alto, se stiamo massimizzando) raggiungibile da quel percorso.\n\nEsistono diversi metodi che l‚Äôalgoritmo pu√≤ utilizzare per decidere come muoversi. Alcuni esempi includono:\n\nDiscesa pi√π ripida (Gradient Descent): Utilizza il gradiente (la direzione e la pendenza della collina) per decidere in quale direzione muoversi.\nNewton-Raphson: Utilizza sia il gradiente sia la ‚Äúcurvatura‚Äù della funzione per fare passi pi√π informati verso il minimo.\nAlgoritmi Genetici: Ispirati dall‚Äôevoluzione biologica, questi algoritmi ‚Äúevolvono‚Äù una soluzione attraverso iterazioni che simulano la selezione naturale.\n\nIn termini intuitivi, dunque, l‚Äôottimizzazione √® un processo metodico di esplorazione e aggiustamento basato su feedback immediato dalla funzione che stiamo cercando di ottimizzare, con l‚Äôobiettivo di trovare il punto di massimo o minimo valore.\nDefiniamo dunque il negativo della funzione di verosimiglianza per l‚Äôottimizzazione (trovare il massimo della funzione):\n\ndef negative_likelihood(theta, n, y):\n    # Calcolo del negativo della funzione di verosimiglianza\n    return - (math.comb(n, y) * theta**y * (1 - theta) ** (n - y))\n\nUtilizziamo ora scipy.optimize.minimize per trovare il valore di theta che massimizza la verosimiglianza. Bisogna specificare un valore iniziale per theta, qui assumiamo 0.5 come punto di partenza. I vincoli su theta sono che deve essere compreso tra 0 e 1.\n\nresult = minimize(negative_likelihood, x0=0.5, args=(n, y), bounds=[(0, 1)])\nresult.x\n\narray([0.76666666])\n\n\n\n27.3.1 La Funzione di Log-Verosimiglianza\nProseguendo con il nostro approfondimento sull‚Äôanalisi statistica mediante la funzione di verosimiglianza, ci spostiamo verso una sua trasformazione matematica spesso preferita dagli statistici: la funzione di log-verosimiglianza. Il passaggio alla log-verosimiglianza, definita come il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y),\n\\tag{27.1}\\]\nnon altera la posizione del massimo della funzione originale grazie alla propriet√† di monotonicit√† del logaritmo. In termini pratici, ci√≤ significa che il valore di \\(\\theta\\) che massimizza la log-verosimiglianza, \\(\\hat{\\theta}\\), √® lo stesso che massimizza la verosimiglianza originale:\n\\[\n\\hat{\\theta} = \\arg \\max_{\\theta \\in \\Theta} \\ell(\\theta) = \\arg \\max_{\\theta \\in \\Theta} \\mathcal{L}(\\theta).\n\\]\nNell‚Äôanalisi di un campione di osservazioni, l‚Äôuso della log-verosimiglianza semplifica il processo di massimizzazione, che pu√≤ risultare complicato con la verosimiglianza tradizionale, soprattutto quando si gestiscono numeri molto piccoli. Questa semplificazione avviene perch√© la log-verosimiglianza trasforma il prodotto delle probabilit√† in una somma di logaritmi, rendendo il problema pi√π semplice e numericamente stabile. L‚Äôespressione della log-verosimiglianza per un modello binomiale, ad esempio, si presenta come segue:\n\\[\n\\ell(\\theta \\mid y) = \\log(\\theta^y (1 - \\theta)^{n - y}) = y \\log(\\theta) + (n - y) \\log(1 - \\theta).\n\\]\nQuesta formulazione trasforma il prodotto delle probabilit√† di osservazioni indipendenti in una somma, facilitando notevolmente i calcoli, specialmente per dataset di grandi dimensioni o in presenza di calcoli complessi. La forma logaritmica √® pi√π gestibile e si presta meglio all‚Äôapplicazione di tecniche di ottimizzazione numerica, grazie alla sua maggiore stabilit√† e alla riduzione di problemi come l‚Äôunderflow, comuni quando si lavora con probabilit√† molto piccole.\nRitornando all‚Äôesempio della distribuzione binomiale, l‚Äôapplicazione della log-verosimiglianza per il calcolo del parametro \\(\\theta\\) che meglio si adatta ai dati osservati pu√≤ essere eseguita con efficienza attraverso metodi computazionali. Per esempio, l‚Äôutilizzo di funzioni specifiche disponibili in pacchetti statistici, come binom.logpmf() in Python, permette di calcolare direttamente la log-verosimiglianza di un dato set di osservazioni per diversi valori di \\(\\theta\\). Questo approccio facilita la ricerca del valore di \\(\\theta\\) che massimizza la log-verosimiglianza, fornendo una stima accurata e computazionalmente efficiente del parametro.\nL‚Äôadozione della funzione di log-verosimiglianza, quindi, non solo consente di affrontare i limiti pratici legati alla manipolazione di piccole probabilit√†, ma offre anche un quadro concettuale chiaro per l‚Äôinterpretazione della plausibilit√† dei parametri del modello alla luce dei dati osservati. Questa trasformazione logaritmica rappresenta un passaggio cruciale nell‚Äôanalisi inferenziale, consentendo di stimare i parametri dei modelli statistici con maggiore precisione e affidabilit√†.\nPer illustrare questo concetto, riprendiamo l‚Äôesempio precedente e applichiamo la funzione di log-verosimiglianza per identificare il valore di $ $ che massimizza questa funzione. La rappresentazione grafica della funzione di log-verosimiglianza fornisce ulteriori intuizioni sul comportamento di questa funzione.\n\nn = 30\nr = 23\nplt.figure()\nplt.plot(theta, stats.binom.logpmf(y, n, theta), \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Log-verosimiglianza\");\n\n\n\n\n\n\n\n\nIl risultato replica quello trovato in precedenza con la funzione di verosimiglianza.\n\nll = stats.binom.logpmf(y, n, theta)\nll.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\nDefinizione della funzione del negativo della log-verosimiglianza con correzioni per evitare errori di dominio:\n\ndef corrected_negative_log_likelihood(theta, n, y):\n    # Assicurarsi che theta sia all'interno di un intervallo valido per evitare errori di logaritmo\n    theta = np.clip(theta, 1e-10, 1-1e-10)\n    return - (y * np.log(theta) + (n - y) * np.log(1 - theta))\n\nUtilizzo di scipy.optimize.minimize per trovare il valore di theta che massimizza la log-verosimiglianza:\n\nresult_log_likelihood_corrected = minimize(\n    corrected_negative_log_likelihood, x0=[0.5], args=(n, y), bounds=[(0, 1)]\n)\n\n\n# Il risultato ottimizzato per theta utilizzando la log-verosimiglianza corretta\noptimized_theta = result_log_likelihood_corrected.x\noptimized_theta\n\narray([0.76666666])\n\n\n\n\n27.3.2 Verosimiglianza Congiunta\nProseguendo nella nostra esplorazione dell‚Äôinferenza statistica attraverso la funzione di verosimiglianza, ci concentriamo ora sul caso in cui abbiamo pi√π osservazioni, tutte provenienti dalla stessa distribuzione binomiale e considerate indipendenti ed identicamente distribuite (IID). Tale scenario si presenta frequentemente nelle applicazioni pratiche, dove un insieme di \\(n\\) osservazioni \\(Y = [y_1, y_2, \\ldots, y_n]\\) viene raccolto sotto le stesse condizioni sperimentali.\nLa chiave per analizzare queste osservazioni congiuntamente risiede nel calcolo della probabilit√† congiunta di \\(y_1, y_2, \\ldots, y_n\\) data un‚Äôunica probabilit√† di successo \\(\\theta\\) comune a tutte le prove. L‚Äôindipendenza delle osservazioni ci consente di esprimere questa probabilit√† congiunta come il prodotto delle probabilit√† individuali di ciascuna osservazione:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa bellezza di questo approccio sta nel fatto che la verosimiglianza congiunta, che rappresenta la plausibilit√† complessiva di \\(\\theta\\) data l‚Äôintera sequenza di osservazioni \\(Y\\), √® semplicemente il prodotto delle verosimiglianze individuali di ogni osservazione \\(y_i\\) rispetto a \\(\\theta\\):\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta formulazione della verosimiglianza congiunta non solo evidenzia quanto bene il parametro \\(\\theta\\) si adatta all‚Äôintero set di dati \\(Y\\), ma offre anche una base metodologica solida per stimare \\(\\theta\\). Il parametro che massimizza la verosimiglianza congiunta, noto come stimatore di massima verosimiglianza (MLE) di \\(\\theta\\), √® quello che si ritiene essere il pi√π plausibile data l‚Äôosservazione dei dati.\nQuando abbiamo pi√π gruppi di osservazioni bernoulliane indipendenti ed identicamente distribuite (iid), la funzione di log-verosimiglianza congiunta per tutti i gruppi pu√≤ essere espressa come la somma delle log-verosimiglianze di ciascun gruppo. Ci√≤ √® dovuto alla propriet√† che il logaritmo del prodotto √® la somma dei logaritmi.\nSupponiamo di avere i seguenti dati per 4 gruppi di osservazioni:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 21 successi\nGruppo 3: 40 prove con 31 successi\nGruppo 4: 36 prove con 29 successi\n\nLa funzione di log-verosimiglianza congiunta per questi dati, assumendo una singola probabilit√† di successo \\(\\theta\\) per tutti i gruppi, √® data da:\n\\[\n\\log L(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove \\(n_i\\) e \\(y_i\\) sono rispettivamente il numero di prove e il numero di successi nel \\(i\\)-esimo gruppo.\nPer trovare il valore di \\(\\theta\\) che massimizza questa funzione di log-verosimiglianza, possiamo usare il metodo di ottimizzazione scipy.optimize.minimize, come abbiamo fatto in precedenza. Definiamo prima la funzione di log-verosimiglianza congiunta (usiamo np.clip per evitare errori):\n\ndef log_verosimiglianza_congiunta(theta, dati):\n    theta = np.clip(theta, 1e-10, 1-1e-10)  # Evita valori esattamente 0 o 1\n    log_likelihood = 0\n    for n, y in dati:\n        log_likelihood += y * np.log(theta) + (n - y) * np.log(1 - theta)\n    return -log_likelihood  # Restituisce il negativo per l'ottimizzazione\n\n\n# Dati dei gruppi: (prove, successi)\ndati_gruppi = [(30, 23), (28, 20), (40, 29), (36, 29)]\nprint(dati_gruppi)\n\n[(30, 23), (28, 20), (40, 29), (36, 29)]\n\n\nOttimizzazione con la funzione log_verosimiglianza_congiunta\n\nresult = minimize(\n    log_verosimiglianza_congiunta, x0=[0.5], args=(dati_gruppi,), bounds=[(0, 1)]\n)\n\n# Il risultato ottimizzato per theta con la funzione corretta\nresult.x\n\narray([0.75373134])\n\n\n\n# Intervallo di valori di theta da esplorare\ntheta_values = np.linspace(0.01, 0.99, 100)\n\n# Calcolo dei valori di log-verosimiglianza per ogni theta\nlog_likelihood_values = [log_verosimiglianza_congiunta(theta, dati_gruppi) for theta in theta_values]\n\n# Creazione del grafico\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, log_likelihood_values, label='Log-verosimiglianza')\nplt.xlabel('Theta')\nplt.ylabel('Log-verosimiglianza negativa')\nplt.title('Funzione di Log-verosimiglianza')\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/chapter_3/09_likelihood.html#la-verosimiglianza-marginale",
    "title": "27¬† La verosimiglianza",
    "section": "27.4 La Verosimiglianza Marginale",
    "text": "27.4 La Verosimiglianza Marginale\nAvanzando nella nostra discussione sulla verosimiglianza, approfondiamo ora un passaggio cruciale nell‚Äôapplicazione della teoria bayesiana: il concetto di verosimiglianza marginale. Questo approccio si rivela essenziale quando affrontiamo situazioni in cui il parametro di interesse, \\(\\theta\\), non √® definito da un valore singolo e fisso, ma √® invece descritto da una distribuzione di probabilit√† che riflette la nostra incertezza o variabilit√† su di esso.\nIn contesti pratici, non √® raro incontrare scenari in cui \\(\\theta\\) pu√≤ assumere una gamma di valori, ciascuno con una probabilit√† associata, piuttosto che un valore deterministico. L‚Äôintegrazione del parametro \\(\\theta\\) permette di calcolare la probabilit√† complessiva (o verosimiglianza) di osservare un determinato risultato dati tutti i possibili valori di \\(\\theta\\), piuttosto che appoggiarsi a un‚Äôanalisi basata su un singolo valore di \\(\\theta\\).\nConsideriamo, per esempio, una situazione in cui stiamo osservando una sequenza di prove binomiali, con un risultato specifico di interesse (ad esempio, \\(k=7\\) successi su \\(n=10\\) prove). Se \\(\\theta\\) rappresenta la probabilit√† di successo in ciascuna prova e pu√≤ assumere un insieme discreto di valori (per esempio, 0.1, 0.5, e 0.9) con probabilit√† uniforme, la verosimiglianza di osservare il nostro risultato specifico pu√≤ essere espressa come:\n\\[p(k=7, n=10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta),\\]\ndove \\(p(\\theta)\\) rappresenta la probabilit√† associata a ciascun possibile valore di \\(\\theta\\).\nTuttavia, in molte applicazioni reali, \\(\\theta\\) pu√≤ variare continuamente all‚Äôinterno di un intervallo, come tra 0 e 1 per una distribuzione binomiale. In questi casi, il calcolo della verosimiglianza marginale richiede l‚Äôutilizzo dell‚Äôintegrazione su tutto lo spazio dei valori possibili di \\(\\theta\\), riflettendo la gamma continua di possibili probabilit√† di successo. La formula si estende quindi a:\n\\[p(k=7, n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta) d\\theta,\\]\ndove \\(p(\\theta) d\\theta\\) rappresenta la densit√† di probabilit√† di \\(\\theta\\) su un intervallo infinitesimale, e l‚Äôintegrale copre tutti i possibili valori di \\(\\theta\\) da 0 a 1. Implementare questo calcolo nell‚Äôambito di uno spazio continuo richiede l‚Äôutilizzo di tecniche di integrazione.\nVediamo come sia possibile eseguire questo calcolo in Python, utilizzando la libreria scipy per l‚Äôintegrazione su uno spazio continuo:\n\n# Definire la funzione di verosimiglianza\ndef likelihood(theta):\n    return stats.binom.pmf(k=7, n=10, p=theta)\n\n# Calcolare la verosimiglianza marginale integrando su Œ∏\nmarginal_likelihood, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(\"La verosimiglianza marginale √®:\", marginal_likelihood)\n\nLa verosimiglianza marginale √®: 0.09090909090909094\n\n\nQuesto codice esegue l‚Äôintegrazione della funzione di verosimiglianza binomiale su tutti i possibili valori di Œ∏ (da 0 a 1), fornendo cos√¨ la verosimiglianza marginale per il nostro esempio. Questo processo ci permette di considerare l‚Äôincertezza su Œ∏, offrendo una visione completa della verosimiglianza dell‚Äôevento osservato senza fissare Œ∏ a un singolo valore.\nNumericamente, nell‚Äôesempio della verosimiglianza basata su una distribuzione binomiale precedente, la verosimiglianza marginale √® effettivamente interpretata come l‚Äôarea sottesa dalla funzione di verosimiglianza, calcolata integrandola su tutto l‚Äôintervallo dei possibili valori di \\(\\theta\\) (da 0 a 1, nel contesto di probabilit√†). Questa operazione di integrazione fornisce un valore che quantifica l‚Äôarea sotto la curva della funzione di verosimiglianza. Importante sottolineare, questo valore non corrisponde alla probabilit√† dei dati dati i parametri, dato che la verosimiglianza non √® una densit√† di probabilit√† sui parametri. Piuttosto, esso misura in che misura l‚Äôintero modello, considerando tutti i possibili valori del parametro, √® in grado di spiegare i dati osservati.\nLa vera importanza della verosimiglianza marginale emerge nel contesto dell‚Äôinferenza bayesiana: essa agisce come fattore di normalizzazione nella formula di Bayes. Nello specifico, la verosimiglianza marginale normalizza la funzione risultante dal prodotto tra la verosimiglianza e la distribuzione a priori dei parametri (il numeratore nella formula di Bayes), garantendo che il risultato sia una distribuzione di probabilit√† valida sullo spazio dei parametri. In altre parole, la verosimiglianza marginale assicura che l‚Äôarea sotto la curva della distribuzione posteriore sia esattamente 1, rendendola cos√¨ una vera distribuzione di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/chapter_3/09_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "27¬† La verosimiglianza",
    "section": "27.5 Modello Gaussiano e Verosimiglianza",
    "text": "27.5 Modello Gaussiano e Verosimiglianza\nAmpliamo ora la nostra analisi al caso della distribuzione gaussiana. Inizieremo con la verosimiglianza associata a una singola osservazione $ Y $, per poi estendere la discussione a un insieme di osservazioni gaussiane indipendenti e identicamente distribuite (IID).\n\n27.5.1 Caso di una Singola Osservazione\nIniziamo esaminiamo il caso di una singola osservazione. Quale esempio, prendiamo in considerazione la situazione in cui una variabile casuale rappresenta il Quoziente d‚ÄôIntelligenza (QI) di un individuo. Se consideriamo la distribuzione del QI come gaussiana, possiamo esprimere la funzione di verosimiglianza per un singolo valore osservato di QI tramite la formula della distribuzione gaussiana, che misura la probabilit√† di osservare quel particolare valore di QI dato un insieme di parametri specifici, \\(\\mu\\) (la media) e \\(\\sigma\\) (la deviazione standard). La verosimiglianza offre quindi un modo per quantificare quanto bene i parametri \\(\\mu\\) e \\(\\sigma\\) si accordano con il valore osservato di QI.\nSupponiamo che il QI osservato sia 114 e, per semplicit√†, assumiamo che la deviazione standard \\(\\sigma\\) sia conosciuta e pari a 15. Vogliamo esaminare un‚Äôampia gamma di possibili valori per la media \\(\\mu\\), diciamo tra 70 e 160, e valutare quale di questi valori rende pi√π plausibile l‚Äôosservazione fatta Definiamo quindi un insieme di 1000 valori per \\(\\mu\\) da esplorare:\n\nmu = np.linspace(70.0, 160.0, num=1000)\ny = 114\n\nLa nostra analisi consiste nell‚Äôapplicare la funzione di densit√† di probabilit√† gaussiana a ciascuno di questi 1000 valori di \\(\\mu\\), mantenendo fisso il valore osservato di QI, \\(y=114\\), e la deviazione standard, \\(\\sigma=15\\). In questo modo, possiamo costruire la funzione di verosimiglianza che esprime la plausibilit√† di ciascun valore di \\(\\mu\\) alla luce del QI osservato.\nIl calcolo specifico della densit√† di probabilit√† per ogni valore di \\(\\mu\\) pu√≤ essere eseguito con la funzione norm.pdf di scipy.stats, che accetta il valore osservato \\(y\\), un array di medie (i nostri valori di \\(\\mu\\)) e la deviazione standard \\(\\sigma\\). Per un singolo valore mu = 70, otteniamo\n\nstats.norm.pdf(y, loc=70, scale=15)\n\n0.00036007041207962535\n\n\nPer il valore mu = 70.05 otteniamo\n\nstats.norm.pdf(y, loc=70.05, scale=15)\n\n0.00036360634900376967\n\n\ne cos√¨ via. Se usiamo utti i 1000 valori possibili di mu, otteniamo un vettore di 1000 risultati:\n\nf_mu = stats.norm.pdf(y, loc=mu, scale=15)\n\nQuesto passaggio ci fornisce un array di valori che rappresentano la verosimiglianza di ciascun valore di \\(\\mu\\) data l‚Äôosservazione \\(y\\). Tracciando questi valori f_mu in funzione di \\(\\mu\\), otteniamo una curva di verosimiglianza che illustra visivamente quanto bene ciascun valore di \\(\\mu\\) si adatta al dato osservato y = 114:\n\nplt.figure()\nplt.plot(mu, f_mu, \"-\")\nplt.title(\"Funzione di verosimiglianza per QI = 114\")\nplt.xlabel(\"Valore di mu [70, 160]\")\nplt.ylabel(\"Verosimiglianza\")\nplt.xlim([70, 160])\nplt.show()\n\n\n\n\n\n\n\n\nAbbiamo dunque proceduto come nel caso della distribuzione binomiale esaminata in precedenza. Abbiamo utilizzato la formula\n\\[\nf(x | \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ntenendo costante il valore \\(x\\) = 114 e considerando noto \\(\\sigma\\) = 15, e abbiamo applicato la formula 1000 volte facendo variare mu ogni volta utilizziando ciascuno dei valori definiti con np.linspace(70.0, 160.0, num=1000).\nLa moda della distribuzione, si trova con\n\noptimal_mu = mu[f_mu.argmax()]\nprint(optimal_mu)\n\n113.96396396396396\n\n\nIn questo esempio, otteniamo il valore \\(\\mu\\) = 113.96 che massimizza la verosimiglianza.\nPer calcolare il massimo della log-verosimiglianza per una distribuzione Gaussiana usando la funzione optimize() di SciPy, possiamo seguire questi passi. Partiamo dalla formula della densit√† di probabilit√† della distribuzione gaussiana per una singola osservazione \\(y\\), con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La formula √®:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\n\\]\nPoich√© abbiamo una singola osservazione \\(y\\), la funzione di verosimiglianza coincide con la funzione di densit√† di probabilit√†. Quindi, prendiamo il logaritmo naturale di entrambi i lati della equazione della densit√† di probabilit√† gaussiana per ottenere la log-verosimiglianza:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log \\left( \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right) \\right)\n\\]\nApplichiamo le propriet√† dei logaritmi. Ricordiamo che:\n\n\\(\\log(ab) = \\log(a) + \\log(b)\\)\n\\(\\log\\left(\\frac{1}{a}\\right) = -\\log(a)\\)\n\\(\\log(e^x) = x\\)\n\nQuindi, possiamo scrivere:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log\\left(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\right) + \\log\\left(\\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\\right)\n\\]\n\\[\n= -\\log(\\sigma \\sqrt{2\\pi}) -\\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nRicordando che \\(\\log(ab) = \\log(a) + \\log(b)\\), possiamo scrivere \\(\\log(\\sigma \\sqrt{2\\pi})\\) come la somma di due logaritmi:\n\\[\n-\\log(\\sigma \\sqrt{2\\pi}) = -\\log(\\sigma) - \\log(\\sqrt{2\\pi}).\n\\]\nE dato che \\(\\log(\\sqrt{2\\pi}) = \\frac{1}{2}\\log(2\\pi)\\), possiamo sostituire per ottenere:\n\\[\n-\\log(\\sigma) - \\frac{1}{2}\\log(2\\pi).\n\\]\nCombinando tutto, otteniamo:\n\\[\n\\log L(\\mu; y, \\sigma) = -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2 \\sigma^2}.\n\\]\nQuesta √® la trasformata logaritmica della funzione di densit√† di probabilit√† gaussiana per una singola osservazione, che rappresenta la log-verosimiglianza di osservare \\(y\\) dato \\(\\mu\\) e \\(\\sigma\\).\nVogliamo trovare il valore di \\(\\mu\\) che massimizza questa funzione di log-verosimiglianza. Siccome optimize() di SciPy minimizza una funzione, possiamo passare il negativo della log-verosimiglianza per trovare il massimo.\n\n# Dati osservati\ny_obs = 114\nsigma = 15\n\n# Definizione della funzione negativa della log-verosimiglianza\ndef negative_log_likelihood(mu, y, sigma):\n    return 0.5 * np.log(2 * np.pi) + np.log(sigma) + ((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza\nresult = minimize(negative_log_likelihood, x0=0, args=(y_obs, sigma))\n\n# Il risultato ottimizzato per mu\nresult.x\n\narray([113.99997648])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per una distribuzione Gaussiana con \\(y = 114\\) e \\(\\sigma = 15\\) √® circa \\(114\\). Questo risultato dimostra che, nel caso di una distribuzione Gaussiana con una singola osservazione e deviazione standard nota, il massimo della log-verosimiglianza si ottiene quando la media stimata \\(\\mu\\) √® molto vicina al valore osservato \\(y\\).\n\n\n27.5.2 Campione indipendente di osservazioni da una distribuzione gaussiana\nPassiamo ora all‚Äôesame di un contesto pi√π complesso: quello di un campione composto da \\(n\\) osservazioni indipendenti, tutte provenienti da una distribuzione gaussiana. Consideriamo questo insieme di osservazioni come realizzazioni indipendenti ed identicamente distribuite (i.i.d.) di una variabile casuale \\(X\\), che segue una distribuzione normale con media $ $ e deviazione standard \\(\\sigma\\), entrambi parametri sconosciuti. Denotiamo questa situazione con la notazione \\(X \\sim N(\\mu, \\sigma^2)\\).\nIn presenza di osservazioni i.i.d., la densit√† di probabilit√† congiunta del campione √® il prodotto delle funzioni di densit√† per ogni singola osservazione. Matematicamente, ci√≤ si esprime attraverso l‚Äôequazione:\n\\[ p(y_1, y_2, \\ldots, y_n | \\mu, \\sigma) = \\prod_{i=1}^{n} p(y_i | \\mu, \\sigma), \\]\ndove \\(p(y_i | \\mu, \\sigma)\\) indica la funzione di densit√† gaussiana per l‚Äôosservazione \\(y_i\\), parametrizzata da \\(\\mu\\) e \\(\\sigma\\).\nSe manteniamo i dati osservati come costanti, ci√≤ che cambia in questa equazione quando variamo $ $ e \\(\\sigma\\) sono le probabilit√† associate ad ogni configurazione dei parametri, portandoci cos√¨ alla funzione di verosimiglianza congiunta per il campione.\n\nEsempio 27.2 Consideriamo, per illustrare questa dinamica, il caso di uno studio clinico che misura i punteggi del Beck Depression Inventory II (BDI-II) su trenta partecipanti. Supponiamo che questi punteggi seguano una distribuzione normale. Dati i punteggi BDI-II per i trenta partecipanti, il nostro obiettivo √® costruire una funzione di verosimiglianza per questi dati, assumendo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria di 6.50.\nPer la totalit√† del campione, la densit√† di probabilit√† congiunta diventa quindi il prodotto delle densit√† per ogni osservazione. Di conseguenza, la funzione di verosimiglianza per il campione intero √® rappresentata dal prodotto delle densit√† di probabilit√† di tutte le osservazioni.\nIn questo contesto, ogni possibile valore di \\(\\mu\\) viene valutato in termini di verosimiglianza. Per esemplificare, consideriamo un range di 1000 valori per \\(\\mu\\) e calcoliamo la funzione di verosimiglianza per ognuno di questi. Per rendere pi√π gestibili i calcoli, utilizziamo il logaritmo della funzione di verosimiglianza.\nDefinendo una funzione log_likelihood in Python che accetta i punteggi BDI-II \\(y\\), un valore medio \\(\\mu\\), e imposta \\(\\sigma\\) al valore noto, possiamo calcolare la log-verosimiglianza per un‚Äôampia gamma di valori di \\(\\mu\\) entro un intervallo specifico. Ci√≤ ci permette di visualizzare la credibilit√† relativa di ciascun valore di \\(\\mu\\) alla luce dei dati osservati.\nInfine, il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza corrisponde alla stima di massima verosimiglianza di \\(\\mu\\) data la distribuzione dei punteggi BDI-II nel campione. Questo valore, nel nostro esempio, coincide con la media campionaria dei punteggi BDI-II, offrendo una stima concorde con l‚Äôintuizione che la media del campione sia un buon rappresentante del parametro \\(\\mu\\) in una distribuzione normale.\nI dati sono:\n\ny = [\n    26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25,\n    28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n]\n\nIl nostro scopo √® sviluppare una funzione di verosimiglianza utilizzando le 30 osservazioni indicate sopra. Basandoci su studi precedenti, ipotizziamo che questi punteggi seguano una distribuzione normale. Assumiamo inoltre che la deviazione standard \\(\\sigma\\) sia nota e corrisponda a quella osservata nel campione, ossia 6.50.\nPer la prima osservazione del campione, dove \\(y_1 = 26\\), la funzione di densit√† di probabilit√† si esprime come:\n\\[\nf(26 \\,|\\, \\mu, \\sigma = 6.50) = \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(26 - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\]\nEstendendo questo calcolo all‚Äôintero campione, la funzione di densit√† di probabilit√† congiunta si ottiene come il prodotto delle densit√† di tutte le osservazioni individuali:\n\\[\nf(y \\,|\\, \\mu, \\sigma = 6.50) = \\prod_{i=1}^{n} f(y_i \\,|\\, \\mu, \\sigma = 6.50).\n\\]\nDi conseguenza, la funzione di verosimiglianza, indicata con \\(\\mathcal{L}(\\mu, \\sigma = 6.50 \\,|\\, y)\\), si determina moltiplicando insieme le densit√† di probabilit√† di tutte le osservazioni nel campione:\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu, \\sigma=6.50 \\,|\\, y) &= \\prod_{i=1}^{30} \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right) \\\\\n&= \\left( \\frac{1}{6.50\\sqrt{2\\pi}} \\right)^{30} \\exp\\left( -\\sum_{i=1}^{30} \\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\end{aligned}\n\\]\nIn questa formula, \\(\\mu\\) rappresenta il parametro di interesse, la media della distribuzione, la cui stima massimizza la funzione di verosimiglianza. Se si considerano 1000 valori differenti per \\(\\mu\\), dovremmo calcolare la funzione di verosimiglianza per ciascuno di questi valori.\nPer rendere i calcoli pi√π gestibili, √® consigliabile utilizzare il logaritmo della funzione di verosimiglianza. In Python, possiamo definire una funzione log_likelihood() che accetta come argomenti y, mu e sigma = true_sigma. Per semplificare, impostiamo true_sigma uguale alla deviazione standard osservata nel campione.\n\ntrue_sigma = np.std(y)\nprint(true_sigma)\n\n6.495810615739622\n\n\n\ndef log_likelihood(y, mu, sigma=true_sigma):\n    return np.sum(stats.norm.logpdf(y, loc=mu, scale=true_sigma))\n\nConsideriamo, ad esempio, il valore \\(\\mu_0 = \\bar{y}\\), ovvero\n\nbar_y = np.mean(y)\nprint(bar_y)\n\n30.933333333333334\n\n\nL‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di \\(\\mu = 30.93\\) √®\n\nlog_likelihood(y, 30.93, sigma=true_sigma)\n\n-98.70288339960591\n\n\nTroviamo ora i valori della log-verosimiglianza per ciascuno dei 1000 valori \\(\\mu\\) nell‚Äôintervallo \\([\\bar{y} - 2 \\sigma, \\bar{y} + 2 \\sigma]\\). Iniziamo a definire il vettore mu.\n\nmu = np.linspace(np.mean(y) - 2 * np.std(y), np.mean(y) + 2 * np.std(y), num=1000)\n\nTroviamo il valore dell‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di ciascuno dei 1000 valori mu che abbiamo definito.\n\nll = [log_likelihood(y, mu_val, true_sigma) for mu_val in mu]\n\nNel caso di un solo parametro sconosciuto (nel caso presente, \\(\\mu\\)) √® possibile rappresentare la log-verosimiglianza con una curva che interpola i punti (mu, ll). Tale funzione descrive la credibilit√† relativa che pu√≤ essere attribuita ai valori del parametro \\(\\mu\\) alla luce dei dati osservati.\n\nplt.figure()\nplt.plot(mu, ll, \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale mu\")\nplt.ylabel(\"Log-verosimiglianza\")\nplt.axvline(x=np.mean(y), alpha=0.4, ls=\"--\");\n\n\n\n\n\n\n\n\nIl valore \\(\\mu\\) pi√π credibile corrisponde al massimo della funzione di log-verosimiglinza e viene detto stima di massima verosimiglianza.\nIl massimo della funzione di log-verosimiglianza, ovvero 30.93 per l‚Äôesempio in discussione, √® identico alla media dei dati campionari.\nPer applicare lo stesso approccio usato precedentemente con optimize ad un campione di dati, anzich√© a una singola osservazione, possiamo modificare la funzione di log-verosimiglianza per prendere in considerazione tutte le osservazioni nel campione. La log-verosimiglianza per un campione da una distribuzione Gaussiana, dove ogni osservazione \\(y_i\\) ha la stessa media \\(\\mu\\) e deviazione standard \\(\\sigma\\), √® la somma delle log-verosimiglianze di ogni osservazione individuale.\nLa formula modificata per il campione sar√†:\n\\[\n\\log L(\\mu; y, \\sigma) = \\sum_{i=1}^{n} \\left[ -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y_i - \\mu)^2}{2 \\sigma^2} \\right],\n\\]\ndove \\(y\\) √® l‚Äôarray delle osservazioni e \\(n\\) √® il numero di osservazioni nel campione.\nPoich√©, per semplicit√†, assumiamo \\(\\sigma\\) come la deviazione standard del campione, prima calcoleremo \\(\\sigma\\) dal campione fornito e poi useremo quel valore per l‚Äôottimizzazione della log-verosimiglianza, cercando il valore di \\(\\mu\\) che la massimizza.\n\n# Calcolo della deviazione standard del campione\nsigma_sample = np.std(y, ddof=1)\n\n# Definizione della funzione negativa della log-verosimiglianza per il campione\ndef negative_log_likelihood_sample(mu, y, sigma):\n    n = len(y)\n    return n * 0.5 * np.log(2 * np.pi) + n * np.log(sigma) + np.sum((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza per il campione\nresult_sample = minimize(negative_log_likelihood_sample, x0=np.mean(y), args=(y, sigma_sample))\n\n# Il risultato ottimizzato per mu\nresult_sample.x\n\narray([30.93333333])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per il campione di dati fornito, assumendo noto il valore di \\(\\sigma\\) (la deviazione standard del campione), √® circa \\(30.93\\). Questo rappresenta la stima ottimale per la media della distribuzione Gaussiana che meglio si adatta al campione di dati dato.\n\n\n\n27.5.3 La Stima di Massima Verosimiglianza per \\(\\mu\\)\nPer determinare il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza, procediamo calcolando la sua derivata parziale rispetto a \\(\\mu\\) e impostando il risultato uguale a zero:\n\nPartiamo dalla funzione di log-verosimiglianza, che √® data da:\n\\[\n\\ell = -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\nCalcoliamo la derivata parziale di $ $ rispetto a $ $:\n\\[\n\\frac{\\partial \\ell}{\\partial \\mu} = \\sum_{i=1}^n \\frac{(y_i - \\mu)}{\\sigma^2}.\n\\]\nImpostiamo la derivata uguale a zero per trovare il punto di massimo:\n\\[\n\\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu) = 0.\n\\]\n\nRisolvendo questa equazione per $ $, otteniamo la stima di massima verosimiglianza:\n\\[\n\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar{y}.\n\\]\nQuesta formula ci mostra che la stima di massima verosimiglianza per \\(\\mu\\) corrisponde semplicemente alla media aritmetica delle osservazioni.\nQuesto processo pu√≤ essere analogamente applicato per stimare \\(\\sigma^2\\), la varianza, e si trova che la stima di massima verosimiglianza per \\(\\sigma^2\\) √® pari alla varianza campionaria.\nIn conclusione, all‚Äôinterno di una distribuzione gaussiana, le stime di massima verosimiglianza per \\(\\mu\\) (la media) e \\(\\sigma^2\\) (la varianza) coincidono con la media campionaria e la varianza campionaria, rispettivamente.\n\nEsempio 27.3 Consideriamo un esempio relativo all‚Äôapprendimento per rinforzo. Lo scopo degli studi sull‚Äôapprendimento per rinforzo √® quello di comprendere come le persone imparano a massimizzare le loro ricompense in situazioni in cui la scelta migliore √® inizialmente sconosciuta. In modo pi√π specifico, consideriamo il seguente problema di apprendimento. Un partecipante deve effettuare ripetutamente delle scelte tra diverse opzioni o azioni, e dopo ogni scelta riceve una ricompensa numerica estratta da una distribuzione di probabilit√† che dipende dall‚Äôazione selezionata. L‚Äôobiettivo del partecipante √® massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte. Per descrivere questa situazione, viene spesso utilizzata la metafora di un giocatore che deve fare una serie di \\(T\\) scelte tra \\(K\\) slot machine (conosciute anche come ‚Äúmulti-armed bandits‚Äù) al fine di massimizzare le sue vincite. Se nella scelta \\(t\\) viene selezionata la slot machine \\(k\\), viene ottenuta una ricompensa \\(r_t\\) che ha valore 1 con una probabilit√† di successo \\(\\mu^k_t\\), altrimenti ha valore 0. Le probabilit√† di successo sono diverse per ogni slot machine e inizialmente sono sconosciute al partecipante. Nella versione pi√π semplice di questo compito, le probabilit√† di successo rimangono costanti nel tempo.\nIl modello di Rescorla-Wagner √® un modello di apprendimento associativo che descrive come gli animali o gli umani aggiornano le loro aspettative di rinforzo in risposta a stimoli. Il modello pu√≤ essere descritto con la seguente formula di aggiornamento:\n\\[ V_{t+1} = V_t + \\alpha (\\lambda - V_t), \\]\ndove:\n\n\\(V_t\\) √® il valore predetto del rinforzo al tempo \\(t\\),\n\\(\\alpha\\) √® il tasso di apprendimento, un parametro che vogliamo stimare,\n\\(\\lambda\\) √® l‚Äôintensit√† del rinforzo,\n\\(V_{t+1}\\) √® il valore aggiornato dopo aver sperimentato il rinforzo.\n\nPer semplificare, consideriamo un caso in cui gli stimoli si presentano in maniera binaria (rinforzo presente o assente), e \\(\\lambda\\) √® noto. L‚Äôobiettivo √® stimare il valore di \\(\\alpha\\) che massimizza la verosimiglianza dei dati osservati sotto il modello.\nLa funzione di verosimiglianza per questo modello dipende dalla differenza tra i valori predetti e gli effettivi rinforzi ricevuti. Tuttavia, la formulazione esatta della funzione di verosimiglianza pu√≤ variare a seconda della specifica formulazione del problema e dei dati disponibili. Per mantenere le cose semplici, consideriamo una versione semplificata in cui la ‚Äúverosimiglianza‚Äù √® basata sulla somma dei quadrati degli errori (SSE) tra i rinforzi previsti e quelli osservati (anche se tecnicamente questo non √® un approccio basato sulla verosimiglianza nel senso statistico classico).\nPer questo esempio, assumiamo di avere un semplice set di dati di rinforzi osservati e vogliamo trovare il valore di \\(\\alpha\\) che minimizza l‚ÄôSSE:\n\\[ SSE = \\sum_{t=1}^{n} (\\lambda - V_t)^2. \\]\nEcco un esempio di implementazione in Python che utilizza scipy.optimize.minimize per stimare \\(\\alpha\\):\n\n# Dati di esempio: rinforzi osservati (lambda)\n# In questo esempio, assumiamo lambda = 1 per rinforzo presente e lambda = 0 per rinforzo assente\n# per semplicit√†. In pratica, lambda potrebbe essere diverso a seconda degli esperimenti.\nrinforzi_osservati = [1, 0, 1, 1, 0, 1]  # Esempio di sequenza di rinforzi\n\n\n# Funzione che calcola l'SSE per un dato valore di alpha\ndef sse(alpha, rinforzi, V0=0):\n    V = V0\n    sse = 0\n    for lambda_ in rinforzi:\n        sse += (lambda_ - V)**2\n        V += alpha * (lambda_ - V)  # Aggiornamento del valore secondo il modello Rescorla-Wagner\n    return sse\n\n# Ottimizzazione per trovare il valore di alpha che minimizza l'SSE\nresult_alpha = minimize(sse, x0=0.5, args=(rinforzi_osservati,))\n\n# Il risultato ottimizzato per alpha\nresult_alpha.x\n\narray([0.29739989])\n\n\nIl valore di \\(\\alpha\\) (tasso di apprendimento) che minimizza la somma dei quadrati degli errori (SSE) per il modello di Rescorla-Wagner, dato il campione di rinforzi osservati, √® circa \\(0.297\\). Questo suggerisce che il tasso di apprendimento ottimale per adattare il modello ai dati osservati in questo esempio semplificato √® di circa 0.297, secondo l‚Äôapproccio di minimizzazione dell‚Äôerrore utilizzato qui.\n\n\nEsempio 27.4 Consideriamo ora un esempio relativo alla distribuzione esponenziale. Supponiamo che i seguenti siano i tempi di attesa per un certo evento:\n\ndata = np.array([27, 64, 3, 18, 8])\n\nDefiniamo la funzione di log-verosimiglianza negativa. Per iniziare, ricordiamo che la funzione di densit√† di probabilit√† (PDF) per una distribuzione esponenziale, dato un tasso \\(\\lambda\\), √® definita come:\n\\[\nf(x; \\lambda) = \\lambda e^{-\\lambda x} \\quad \\text{per } x \\geq 0.\n\\]\nLa verosimiglianza (\\(L\\)) di osservare un insieme di dati \\(\\{x_1, x_2, ..., x_n\\}\\) dato un parametro \\(\\lambda\\) √® il prodotto delle funzioni di densit√† di probabilit√† per ogni punto dati, assumendo che ciascun dato sia indipendente dagli altri. Quindi, per \\(n\\) dati osservati, la funzione di verosimiglianza √®:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} f(x_i; \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\n\\]\nLa log-verosimiglianza (\\(\\log(L(\\lambda))\\)) √® il logaritmo naturale di \\(L(\\lambda)\\). Utilizziamo il logaritmo per semplificare la moltiplicazione in una somma, il che rende pi√π semplici sia il calcolo che la differenziazione. Pertanto, la log-verosimiglianza diventa:\n\\[\n\\log(L(\\lambda)) = \\log\\left(\\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\\right) = \\sum_{i=1}^{n} \\log(\\lambda e^{-\\lambda x_i}) = \\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nIl motivo per utilizzare il negativo della log-verosimiglianza, cio√® \\(-\\log(L(\\lambda))\\), nelle tecniche di ottimizzazione, √® perch√© molte librerie e funzioni di ottimizzazione sono progettate per minimizzare una funzione obiettivo piuttosto che massimizzarla. Dato che vogliamo trovare il valore di \\(\\lambda\\) che massimizza la log-verosimiglianza (e quindi la verosimiglianza), possiamo invece minimizzare il suo negativo. Di conseguenza, la funzione obiettivo che passiamo all‚Äôalgoritmo di minimizzazione √®:\n\\[\n-\\log(L(\\lambda)) = -\\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nScriviamo la funzione in Python:\n\ndef neg_log_likelihood(lambda_, data, eps=1e-8):\n    lambda_ = np.clip(lambda_, eps, None)  # Assicura che lambda_ sia almeno eps\n    return -np.sum(np.log(lambda_) - lambda_ * data)\n\nMinimizzaziamo la funzione di log-verosimiglianza negativa:\n\nresult = minimize(neg_log_likelihood, x0=0.1, args=(data,), bounds=[(0, None)])\nprint(f\"Il valore di lambda che massimizza la log-verosimiglianza √®: {result.x[0]}\")\n\nIl valore di lambda che massimizza la log-verosimiglianza √®: 0.04166666292998713\n\n\nAvendo trovato il tasso \\(\\lambda\\), la stima di massima verosimiglianza del tempo di attesa medio diventa:\n\n1 / result.x\n\narray([24.00000215])\n\n\nVisualizzazione.\n\nlambda_opt = result.x[0]\nlambda_array = np.geomspace(0.01, 0.1, 100)\nLL = [-neg_log_likelihood(L, data) for L in lambda_array]\n\nplt.plot(lambda_array, LL, label='Log-likelihood')\nplt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\nplt.xlabel('$\\lambda$')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood over a range of $\\lambda$ values')\nplt.legend()\nplt.show()\n\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:6: SyntaxWarning: invalid escape sequence '\\l'\n  plt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:7: SyntaxWarning: invalid escape sequence '\\l'\n  plt.xlabel('$\\lambda$')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:9: SyntaxWarning: invalid escape sequence '\\l'\n  plt.title('Log-likelihood over a range of $\\lambda$ values')",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#conclusione-e-riflessioni-finali",
    "href": "chapters/chapter_3/09_likelihood.html#conclusione-e-riflessioni-finali",
    "title": "27¬† La verosimiglianza",
    "section": "27.6 Conclusione e Riflessioni Finali",
    "text": "27.6 Conclusione e Riflessioni Finali\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilit√† dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l‚Äôinsieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza √® centrale nella pratica dell‚Äôinferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo √® fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto √® indispensabile per un‚Äôanalisi dati rigorosa e per un‚Äôinterpretazione accurata dei risultati.\nUn‚Äôapplicazione pratica e illustrativa dei principi esposti in questo capitolo √® fornita nella sezione sul modello Rescorla-Wagner, che √® un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l‚Äôapplicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi √® impegnato nella ricerca empirica e nell‚Äôinterpretazione di dati complessi.\n\n\n\n\n\n\nAll‚Äôesame ti verr√† chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/09_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/09_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "27¬† La verosimiglianza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Apr 06 2024\n\nPython implementation: CPython\nPython version       : 3.12.2\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.1\nnumpy     : 1.26.4\nscipy     : 1.12.0\nseaborn   : 0.13.2\nmatplotlib: 3.8.3\narviz     : 0.17.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html",
    "href": "chapters/chapter_3/10_grid_gauss.html",
    "title": "28¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo √® estendere la discussione precedente sul calcolo della distribuzione a posteriori utilizzando la verosimiglianza gaussiana, introducendo il metodo basato sulla griglia.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#un-prior-uniforme",
    "href": "chapters/chapter_3/10_grid_gauss.html#un-prior-uniforme",
    "title": "28¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "28.1 Un prior uniforme",
    "text": "28.1 Un prior uniforme\nConsideriamo il caso in cui abbiamo un campione di 10 osservazioni. Questo campione √® generato mediante il campionamento casuale da una Normale di media 50 e deviazione standard pari a 5. Nella simulazione successiva considereremo \\(\\sigma\\) nota.\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilit√†\nvera_media = 50  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione)\nprint(campione)\n\n[48.54283933 43.64834594 54.59899393 61.47236626 48.30510499 43.11175964\n 60.88971922 39.33729382 52.25731836 50.64725801]\n\n\nCreiamo ora una griglia di 100 elementi con valori compresi tra 40 e 60.\n\nmedia_griglia = np.linspace(start=40, stop=60, num=100)  # 100 punti tra 40 e 60\nprint(media_griglia)\n\n[40.         40.2020202  40.4040404  40.60606061 40.80808081 41.01010101\n 41.21212121 41.41414141 41.61616162 41.81818182 42.02020202 42.22222222\n 42.42424242 42.62626263 42.82828283 43.03030303 43.23232323 43.43434343\n 43.63636364 43.83838384 44.04040404 44.24242424 44.44444444 44.64646465\n 44.84848485 45.05050505 45.25252525 45.45454545 45.65656566 45.85858586\n 46.06060606 46.26262626 46.46464646 46.66666667 46.86868687 47.07070707\n 47.27272727 47.47474747 47.67676768 47.87878788 48.08080808 48.28282828\n 48.48484848 48.68686869 48.88888889 49.09090909 49.29292929 49.49494949\n 49.6969697  49.8989899  50.1010101  50.3030303  50.50505051 50.70707071\n 50.90909091 51.11111111 51.31313131 51.51515152 51.71717172 51.91919192\n 52.12121212 52.32323232 52.52525253 52.72727273 52.92929293 53.13131313\n 53.33333333 53.53535354 53.73737374 53.93939394 54.14141414 54.34343434\n 54.54545455 54.74747475 54.94949495 55.15151515 55.35353535 55.55555556\n 55.75757576 55.95959596 56.16161616 56.36363636 56.56565657 56.76767677\n 56.96969697 57.17171717 57.37373737 57.57575758 57.77777778 57.97979798\n 58.18181818 58.38383838 58.58585859 58.78787879 58.98989899 59.19191919\n 59.39393939 59.5959596  59.7979798  60.        ]\n\n\nCalcoliamo la likelihood.\n\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\nlikelihood\n\narray([4.43497974e-25, 1.00961743e-24, 2.26116493e-24, 4.98216199e-24,\n       1.07997486e-23, 2.30313636e-23, 4.83209939e-23, 9.97383700e-23,\n       2.02534436e-22, 4.04618453e-22, 7.95248204e-22, 1.53769396e-21,\n       2.92514449e-21, 5.47437998e-21, 1.00793553e-20, 1.82574775e-20,\n       3.25356129e-20, 5.70410371e-20, 9.83843533e-20, 1.66945554e-19,\n       2.78698020e-19, 4.57723393e-19, 7.39575534e-19, 1.17563407e-18,\n       1.83853539e-18, 2.82866831e-18, 4.28156219e-18, 6.37577071e-18,\n       9.34056882e-18, 1.34624518e-17, 1.90890888e-17, 2.66290968e-17,\n       3.65458340e-17, 4.93434508e-17, 6.55437614e-17, 8.56531629e-17,\n       1.10119860e-16, 1.39282995e-16, 1.73316833e-16, 2.12174698e-16,\n       2.55538678e-16, 3.02781890e-16, 3.52950131e-16, 4.04768775e-16,\n       4.56678807e-16, 5.06903062e-16, 5.53540208e-16, 5.94680409e-16,\n       6.28533301e-16, 6.53556524e-16, 6.68572052e-16, 6.72858096e-16,\n       6.66206627e-16, 6.48940106e-16, 6.21885576e-16, 5.86308990e-16,\n       5.43817056e-16, 4.96237176e-16, 4.45487960e-16, 3.93452986e-16,\n       3.41869158e-16, 2.92238345e-16, 2.45767628e-16, 2.03339784e-16,\n       1.65512287e-16, 1.32540414e-16, 1.04418297e-16, 8.09310345e-17,\n       6.17111697e-17, 4.62937824e-17, 3.41658127e-17, 2.48068172e-17,\n       1.77198703e-17, 1.24526055e-17, 8.60934527e-18, 5.85585374e-18,\n       3.91850601e-18, 2.57965137e-18, 1.67075095e-18, 1.06456606e-18,\n       6.67334716e-19, 4.11552289e-19, 2.49698841e-19, 1.49045282e-19,\n       8.75246011e-20, 5.05652605e-20, 2.87398541e-20, 1.60704142e-20,\n       8.84056013e-21, 4.78456761e-21, 2.54750949e-21, 1.33444023e-21,\n       6.87689899e-22, 3.48655374e-22, 1.73904286e-22, 8.53364173e-23,\n       4.11972976e-23, 1.95665048e-23, 9.14256335e-24, 4.20274369e-24])\n\n\nLa likelihood rappresenta quanto sono verosimili i dati osservati dato un certo parametro (o set di parametri) del modello. Nel contesto della distribuzione gaussiana, la likelihood di un insieme di osservazioni dato un valore specifico della media (\\(\\mu\\)) e conoscendo la deviazione standard (\\(\\sigma\\)) si calcola come il prodotto delle densit√† di probabilit√† di ogni osservazione data quella media e deviazione standard. Questo approccio si basa sull‚Äôassunzione di indipendenza tra le osservazioni.\nIl codice precedente calcola la likelihood per una serie di valori possibili della media (\\(\\mu\\)), mantenendo la deviazione standard (\\(\\sigma\\)) come un valore noto e fisso. Ecco come funziona passo dopo passo:\nlikelihood = np.array([np.prod(norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\nnorm.pdf(campione, loc=media, scale=sigma_conosciuta): Per ogni valore di media nella griglia specificata (media_griglia), questa espressione calcola la densit√† di probabilit√† (PDF) della distribuzione normale per ciascun punto nel campione (campione). loc=media specifica il valore medio della distribuzione normale considerata in quel momento, mentre scale=sigma_conosciuta indica la deviazione standard della distribuzione, che √® considerata nota e costante per tutti i calcoli. Il risultato di norm.pdf per ogni valore di media √® un array che contiene le probabilit√† di ogni osservazione del campione date quella media e la deviazione standard conosciuta.\nnp.prod(...): Calcola il prodotto degli elementi nell‚Äôarray restituito da norm.pdf, ovvero moltiplica tra loro le probabilit√† di tutte le osservazioni del campione per il valore corrente di media. Questo prodotto rappresenta la likelihood complessiva del campione dato quel valore specifico della media, assumendo che le osservazioni siano indipendenti. Il concetto di indipendenza √® cruciale qui perch√© ci permette di moltiplicare le probabilit√† delle singole osservazioni per ottenere la probabilit√† complessiva (likelihood) del set di dati.\nComprehension list [...] for media in media_griglia: Questa parte del codice esegue il calcolo della likelihood per ogni valore di media nella griglia e salva i risultati in un array NumPy. Quindi, per ciascun valore possibile della media considerata, calcoliamo quanto il campione osservato sia verosimile, data quella media e la deviazione standard nota.\n\nIl risultato finale, likelihood, √® un array dove ogni elemento corrisponde alla likelihood del campione di dati osservati per un specifico valore della media sulla griglia.\nPer fare un esempio, consideriamo il primo punto della griglia, corrispondente ad una una media di \\(40\\) (dato che media_griglia √® definita da 40 a 60). Calcoliamo la densit√† di probabilit√† (PDF) per ogni osservazione nel campione dato questo valore della media (\\(40\\)) e una deviazione standard conosciuta di \\(5\\). Ecco le PDF per ciascuna osservazione nel campione:\n[2.28493333e-02, 4.62542534e-02, 3.31420922e-02, 3.00464741e-02,\n 1.11418804e-05, 1.96649746e-02, 2.18282203e-02, 2.11292630e-02,\n 4.05476440e-03, 1.40537162e-07]\nQuesti valori rappresentano la densit√† di probabilit√† di osservare ciascuna misurazione data una distribuzione normale con media \\(40\\) e deviazione standard \\(5\\). La likelihood del campione dato questo valore della media √® calcolata come il prodotto di queste densit√† di probabilit√†, risultando in \\(6.060521630996206 \\times 10^{-26}\\).\nQuesto numero molto piccolo riflette il fatto che, dato un valore medio di \\(40\\), la probabilit√† complessiva di osservare questo specifico campione √® estremamente bassa.\nPer costruire la likelihood completa, ripetiamo questa procedura per ogni punto della nostra griglia di valori.\nDopo aver calcolato la likelihood per ogni punto, procediamo moltiplicandola per il valore del prior corrispondente. Questo passaggio ci consente di ottenere una distribuzione a posteriori non ancora normalizzata.\nNel contesto di una griglia discreta, la normalizzazione della distribuzione a posteriori pu√≤ essere facilmente conseguita dividendo ogni valore per la somma totale dei valori della distribuzione a posteriori.\n\nprior = np.ones(len(media_griglia))  # Una prior uniforme\nposterior_non_norm = likelihood * prior  # Calcoliamo la posterior non normalizzata moltiplicando per la prior\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizziamo la posterior\n\nLa figura successiva presenta una rappresentazione grafica della distribuzione a posteriori normalizzata.\n\nplt.plot(media_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media')\nplt.xlabel('Media')\nplt.ylabel('Probabilit√†')\nplt.show()\n\n\n\n\n\n\n\n\nPer fare un altro esempio, consideriamo un prior non uniforme corrispondente ad una distribuzione gaussiana con media 40 e \\(\\sigma\\) = 3.\n\n# Calcolo della prior gaussiana per ogni valore della griglia della media\nprior = stats.norm.pdf(media_griglia, loc=40, scale=3)\n\n# Calcolo della likelihood (rimane invariato)\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\n# Calcolo della distribuzione a posteriori (aggiornamento con la nuova prior)\nposterior_non_norm = likelihood * prior  # Moltiplicazione element-wise\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizzazione\n\nRiesaminiamo la distribuzione a posteriori calcolata in questo caso, confrontandola con la distribuzione a priori. √à importante notare che, in questo secondo esempio, la distribuzione a posteriori mostra una ‚Äútraslazione‚Äù in direzione del prior.\n\nplt.plot(media_griglia, posterior, label='Posterior')\nplt.plot(media_griglia, prior / np.sum(prior), label='Prior', linestyle='--')\nplt.title('Distribuzione a Posteriori e Prior della Media')\nplt.xlabel('Media')\nplt.ylabel('Densit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nDopo aver calcolato la distribuzione a posteriori come mostrato sopra, per ottenere un campione casuale da questa distribuzione possiamo seguire un approccio di campionamento discreto. Poich√© la distribuzione a posteriori √® definita su una griglia di valori della media, possiamo utilizzare il campionamento ponderato per selezionare casualmente un valore dalla griglia secondo le probabilit√† a posteriori.\nQuesto metodo ci permette di ‚Äúcampionare‚Äù dalla distribuzione a posteriori nonostante essa sia rappresentata in forma discreta anzich√© continua. Ecco come si pu√≤ fare in Python:\n\n# Selezione casuale di un indice dalla griglia secondo le probabilit√† a posteriori\nindice_campionato = np.random.choice(a=len(media_griglia), size=1000, p=posterior)\n\n# Estrazione del valore della media corrispondente all'indice campionato\nmedia_campionata = media_griglia[indice_campionato]\nmedia_campionata.shape\n\n(1000,)\n\n\nIl metodo np.random.choice permette di selezionare un indice dalla griglia con probabilit√† proporzionale ai valori della distribuzione a posteriori. In questo modo, i valori della media con probabilit√† a posteriori pi√π alta saranno selezionati pi√π frequentemente, riflettendo la loro maggiore plausibilit√† data la combinazione dei dati osservati e della prior.\nQuesto campione dalla distribuzione a posteriori rappresenta quindi una possibile stima della media della popolazione, tenendo conto sia dei dati osservati (attraverso la likelihood) sia delle nostre conoscenze o supposizioni precedenti (attraverso la prior).\nL‚Äôistogramma seguente mostra la distribuzione di un campione casuale ottenuto dalla distribuzione a posteriori.\n\n_ = sns.histplot(media_campionata)\n\n\n\n\n\n\n\n\nCalcoliamo ora la media a posteriori:\n\nnp.mean(media_campionata)\n\n48.07676767676767\n\n\nL‚Äôintervallo di credibilit√† al 94% √® dato da:\n\n# Calcolo del 3¬∞ e 97¬∞ percentile dei campioni per ottenere l'intervallo di credibilit√† al 95%\nlimite_inferiore = np.percentile(media_campionata, 3)\nlimite_superiore = np.percentile(media_campionata, 97)\n\nprint(f\"Intervallo di credibilit√† al 94% per la media: [{limite_inferiore}, {limite_superiore}]\")\n\nIntervallo di credibilit√† al 94% per la media: [45.45454545454545, 50.511111111111106]\n\n\nL‚Äôintervallo di credibilit√† al 94%, calcolato come descritto sopra, rappresenta un intervallo all‚Äôinterno del quale ci aspettiamo che si trovi il vero valore della media della popolazione con una probabilit√† del 94%. In altre parole, basandoci sulle informazioni ottenute dai campioni e su precedenti conoscenze rappresentate dalla distribuzione a priori, possiamo essere il 94% confidenti che l‚Äôintervallo definito dal 3¬∞ al 97¬∞ percentile includa la vera media della popolazione.\nL‚Äôintervallo di credibilit√† che √® stato calcolato offre una stima probabilitica di dove si trova il vero valore della media della popolazione, basandosi sui dati del campione e sull‚Äôapproccio inferenziale bayesiano. Questo intervallo fornisce quindi una misura diretta dell‚Äôincertezza della nostra stima, riflettendo la forza e la precisione delle evidenze a nostra disposizione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#la-log-verosimiglianza",
    "href": "chapters/chapter_3/10_grid_gauss.html#la-log-verosimiglianza",
    "title": "28¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "28.2 La Log-Verosimiglianza",
    "text": "28.2 La Log-Verosimiglianza\nNell‚Äôesempio presente abbiamo calcolato la verosimiglianza con una somma. Tuttavia questo produce dei problemi e, in generale, √® preferibile lavorare con i logaritmi.\nStabilit√† Numerica I prodotti di molte probabilit√† piccole possono portare a un ‚Äúunderflow‚Äù numerico, dove il valore risultante √® cos√¨ piccolo che viene arrotondato a zero dalla rappresentazione in virgola mobile del computer. I logaritmi trasformano questi prodotti in somme, riducendo significativamente il rischio di underflow.\nSemplificazione dei Calcoli Il logaritmo di un prodotto √® uguale alla somma dei logaritmi (log(ab) = log(a) + log(b)). Questo trasforma il prodotto di molte verosimiglianze in una somma di logaritmi, semplificando i calcoli e migliorando l‚Äôefficienza computazionale.\nMiglioramento della Precisione I calcolatori sono generalmente pi√π precisi nel sommare che nel moltiplicare numeri, specialmente quando si tratta di numeri molto grandi o molto piccoli. L‚Äôuso dei logaritmi pu√≤ quindi aiutare a mantenere una maggiore precisione nei calcoli.\nFacilit√† di Ottimizzazione Molti algoritmi di ottimizzazione lavorano meglio con somme piuttosto che con prodotti, soprattutto perch√© le derivate delle funzioni somma sono pi√π semplici da calcolare rispetto a quelle dei prodotti. Questo √® particolarmente utile nella stima di massima verosimiglianza e in altri contesti di ottimizzazione bayesiana.\nGestione di Valori Estremi I logaritmi possono aiutare a gestire meglio un ampio range di valori, riducendo gli effetti di valori estremamente grandi o piccoli che potrebbero altrimenti dominare il prodotto di verosimiglianze e portare a risultati distorti.\nIn conclusione, l‚Äôuso dei logaritmi nella stima delle distribuzioni posteriori e in altri calcoli probabilistici offre numerosi vantaggi in termini di stabilit√† numerica, precisione e efficienza computazionale, rendendolo un approccio preferibile in molte situazioni.\nPer riprodurre l‚Äôesempio precedente utilizzando la log-verosimiglianza, anzich√© lavorare direttamente con i valori delle verosimiglianze, convertiremo i calcoli in termini di logaritmi. Questo approccio migliora la stabilit√† numerica e l‚Äôefficienza dei calcoli, come discusso precedentemente. Seguiamo il processo passo dopo passo:\n\nGenerazione del Campione: Iniziamo generando un campione dalla distribuzione normale con una media vera e una deviazione standard conosciuta.\nDefinizione della Griglia per la Media: Stabiliremo una griglia di valori possibili per la media sulla quale calcoleremo la log-verosimiglianza.\nCalcolo della Log-Likelihood: Calcoleremo la log-verosimiglianza per ciascun valore della griglia, utilizzando la densit√† di probabilit√† normale.\nApplicazione della Prior e Calcolo della Posterior: Moltiplicheremo la log-verosimiglianza per la log-prior (se applicabile) e normalizzeremo per ottenere la distribuzione a posteriori.\nVisualizzazione: Infine, visualizzeremo la distribuzione a posteriori della media.\n\nProcediamo con l‚Äôimplementazione in Python:\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilit√†\nvera_media = 50  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione)\n\n# Definizione della griglia per la media\nmedia_griglia = np.linspace(start=40, stop=60, num=100)  \n\n# Calcolo della log-likelihood\nlog_likelihood = np.array([np.sum(stats.norm.logpdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\n# Calcoliamo la log-prior gaussiana\nlog_prior = stats.norm.logpdf(media_griglia, loc=40, scale=3)\n\n# Calcoliamo la log-posterior non normalizzata sommando log-likelihood e log-prior\nlog_posterior_non_norm = log_likelihood + log_prior  \n\n# Normalizziamo la log-posterior\nlog_posterior = log_posterior_non_norm - np.log(np.sum(np.exp(log_posterior_non_norm - np.max(log_posterior_non_norm))))\nposterior = np.exp(log_posterior)\n\n# Visualizzazione della distribuzione a posteriori\nplt.plot(media_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media (Log-verosimiglianza)')\nplt.xlabel('Media')\nplt.ylabel('Probabilit√†')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#deviazione-standard-ignota",
    "href": "chapters/chapter_3/10_grid_gauss.html#deviazione-standard-ignota",
    "title": "28¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "28.3 Deviazione Standard Ignota",
    "text": "28.3 Deviazione Standard Ignota\nEstendere l‚Äôapproccio usato sopra al caso in cui la deviazione standard (\\(\\sigma\\)) della popolazione non √® conosciuta introduce una complessit√† maggiore nell‚Äôinferenza bayesiana, poich√© ora dobbiamo stimare due parametri (la media e la deviazione standard) invece di uno solo. In questo contesto, la distribuzione a posteriori diventa una funzione delle due dimensioni (media e \\(\\sigma\\)), e la sua esplorazione richiede metodi pi√π sofisticati per navigare efficacemente lo spazio dei parametri. Vediamo come affrontare questo problema:\n\n28.3.1 1. Definizione dello Spazio dei Parametri\nDobbiamo definire una griglia bidimensionale che copra le possibili combinazioni di valori per la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)). Questo approccio, sebbene computazionalmente intensivo, √® fattibile per problemi di dimensioni moderate.\n\nmu_griglia = np.linspace(start=40, stop=60, num=100)\nsigma_griglia = np.linspace(start=1, stop=10, num=50)\n\n\n\n28.3.2 2. Calcolo della Log-Likelihood Bidimensionale\nPer ogni coppia di valori (\\(\\mu\\), \\(\\sigma\\)) nella griglia, calcoliamo la log-likelihood del campione. Questo richiede un‚Äôiterazione su entrambe le dimensioni della griglia.\n\nlog_likelihood_2d = np.array([[np.sum(stats.norm.logpdf(campione, loc=mu, scale=sigma))\n                                for sigma in sigma_griglia] for mu in mu_griglia])\n\n\n\n28.3.3 3. Applicazione delle Priors\nLe priors per \\(\\mu\\) e \\(\\sigma\\) possono essere definite in modo indipendente e poi combinate, o si pu√≤ definire una prior congiunta che rifletta la conoscenza o le assunzioni sui parametri. Le log-priors per \\(\\mu\\) e \\(\\sigma\\) sono calcolate su ogni griglia rispettivamente e poi sommate per ottenere una log-prior congiunta.\n\nlog_prior_mu = stats.norm.logpdf(mu_griglia, loc=40, scale=5)\nlog_prior_sigma = stats.norm.logpdf(sigma_griglia, loc=5, scale=2)\nlog_prior_2d = log_prior_mu[:, np.newaxis] + log_prior_sigma\n\n\n\n28.3.4 4. Calcolo della Distribuzione a Posteriori Bidimensionale\nSommando la log-likelihood con la log-prior congiunta e normalizzando, otteniamo la distribuzione a posteriori bidimensionale.\n\nlog_posterior_2d = log_likelihood_2d + log_prior_2d\nlog_posterior_2d -= np.max(log_posterior_2d)  # Stabilizzazione\nposterior_2d = np.exp(log_posterior_2d)\nposterior_2d /= np.sum(posterior_2d)\n\n\n\n28.3.5 5. Visualizzazione\nLa visualizzazione di distribuzioni bidimensionali pu√≤ essere effettuata tramite contour plot o heatmaps.\n\nplt.contourf(mu_griglia, sigma_griglia, posterior_2d.T)\nplt.xlabel('Media ($\\mu$)')\nplt.ylabel('Deviazione Standard ($\\sigma$)')\nplt.colorbar(label='Densit√† Posterior')\nplt.title('Distribuzione a Posteriori Bidimensionale')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#conclusione-e-riflessioni-finali",
    "href": "chapters/chapter_3/10_grid_gauss.html#conclusione-e-riflessioni-finali",
    "title": "28¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "28.4 Conclusione e Riflessioni Finali",
    "text": "28.4 Conclusione e Riflessioni Finali\nQuesto approccio richiede di navigare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, rendendo l‚Äôanalisi pi√π computazionalmente intensiva. Inoltre, la scelta delle priors per pi√π parametri richiede attenzione, poich√© influenzer√† direttamente le stime a posteriori.\nPer problemi con pi√π dimensioni o quando l‚Äôesplorazione della griglia diventa impraticabile, metodi come il campionamento di Markov Chain Monte Carlo (MCMC) diventano essenziali. Questi metodi permettono di campionare efficacemente dalla distribuzione a posteriori senza dover esplorare esplicitamente tutto lo spazio dei parametri.\nIn sintesi, l‚Äôestensione dell‚Äôapproccio bayesiano a casi in cui pi√π parametri sono sconosciuti richiede una maggiore attenzione nella definizione dello spazio dei parametri, nella scelta delle priors, e nel calcolo delle distribuzioni a posteriori",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_3/10_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_3/10_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "28¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Mar 20 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.1\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html",
    "href": "chapters/chapter_4/01_intro_bayes.html",
    "title": "29¬† Modellazione bayesiana",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo Capitolo √® di introdurre il quadro concettuale dela modellizzazione bayesiana.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#inferenza-statistica",
    "href": "chapters/chapter_4/01_intro_bayes.html#inferenza-statistica",
    "title": "29¬† Modellazione bayesiana",
    "section": "29.1 Inferenza Statistica",
    "text": "29.1 Inferenza Statistica\nL‚Äôinferenza statistica si configura come un processo che integra deduzione e induzione, finalizzato all‚Äôesame di dati campionari per dedurre le propriet√† di una popolazione pi√π ampia. Immaginiamo di analizzare l‚Äôaltezza di cinque soggetti selezionati casualmente. Un meccanismo sottostante, che chiameremo ‚Äúprocesso T‚Äù, governa la determinazione delle loro altezze. Comprendere o stimare questo processo √® l‚Äôobiettivo dell‚Äôinferenza statistica. La natura di T √® spesso avvolta nel mistero, oscurata dalla variabilit√† dei dati che osserviamo. Questa variabilit√† pu√≤ essere scissa in due grandi cause: la variabilit√† intrinseca del fenomeno sotto osservazione (come differenze genetiche o ambientali) e le limitazioni delle nostre capacit√† di osservazione e analisi.\nMcElreath (2020) nel suo lavoro ‚ÄúStatistical Rethinking‚Äù introduce il concetto di ‚ÄúGrande Mondo‚Äù, che rappresenta l‚Äôinfinit√† di processi possibili che potrebbero spiegare le nostre osservazioni. Di fronte a questa infinit√†, effettuare inferenze dirette su tutte le possibili propriet√† del Grande Mondo si rivela impraticabile. Ci orientiamo quindi verso il ‚ÄúPiccolo Mondo‚Äù, una rappresentazione semplificata che considera un insieme finito di modelli e parametri ritenuti rilevanti per il nostro studio. Per esempio, nell‚Äôanalisi dell‚Äôaltezza, potremmo proporre un modello probabilistico in cui l‚Äôaltezza segue una distribuzione normale, caratterizzata da una media (¬µ) e una deviazione standard (œÉ), con l‚Äôintento di stimare questi parametri ignoti.\nLa collezione di distribuzioni di probabilit√† derivante dalla variazione dei parametri del modello nel Piccolo Mondo costituisce la funzione di verosimiglianza. Questo insieme, tuttavia, √® spesso troppo ampio per essere gestito con facilit√†. La nostra conoscenza pregressa o le nostre convinzioni riguardo al fenomeno in esame ci assistono nel restringere le possibilit√†.\nNell‚Äôinferenza bayesiana, queste convinzioni iniziali vengono espresse tramite una densit√† di probabilit√† a priori, che attribuisce un peso ai possibili parametri del modello in base alle nostre convinzioni iniziali. La regola di Bayes sta al cuore dell‚Äôinferenza bayesiana, permettendoci di aggiornare queste convinzioni alla luce dei nuovi dati osservati. Attraverso questo processo, otteniamo la probabilit√† a posteriori dei parametri, che fornisce una stima pi√π accurata del processo generativo dei dati, T.\nL‚Äôinferenza statistica, dunque, ci avvicina alla comprensione di fenomeni complessi attraverso la modellazione delle osservazioni via processi semplificati nel ‚ÄúPiccolo Mondo‚Äù. Grazie all‚Äôinferenza bayesiana, che integra le conoscenze pregresse ai nuovi dati, perfezioniamo le nostre stime per una comprensione pi√π profonda del vero processo sottostante.\nLa nota affermazione di Box, Luceno, e del Carmen Paniagua-Quinones (2011)\n\nTutti i modelli sono sbagliati, ma alcuni sono utili\n\ncattura l‚Äôessenza dell‚Äôinferenza statistica. Non miriamo a un ‚Äúmodello perfetto‚Äù che rifletta ogni dettaglio del ‚ÄúGrande Mondo‚Äù, bens√¨ a individuare modelli del ‚ÄúPiccolo Mondo‚Äù che siano efficaci nel fare previsioni sul fenomeno studiato.\nAttraverso la statistica, disponiamo degli strumenti per costruire, valutare e selezionare modelli basati sull‚Äôinferenza bayesiana, che ci consentono di aggiornare e rifinire i nostri modelli in risposta a nuove informazioni. Questo processo ci guida verso modelli ‚Äúutili‚Äù, che, seppur non perfetti, ci permettono di fare previsioni accurate e di approfondire la nostra comprensione del fenomeno di interesse.\n\n29.1.1 I Metodi Bayesiani in Psicologia\nNell‚Äôambito dell‚Äôinferenza statistica, i metodi bayesiani hanno guadagnato sempre popolarit√† anche in psicologia, dove l‚Äôadozione di approcci bayesiani ha visto una crescita esponenziale, grazie anche alla disponibilit√† di risorse educative e pubblicazioni specializzate. In particolare, diversi testi di rilievo hanno contribuito in modo significativo a fornire agli studiosi gli strumenti necessari per applicare con successo l‚Äôinferenza bayesiana all‚Äôanalisi dei dati psicologici. Tra questi testi spiccano opere come quelle di Albert e Hu (2019), Johnson, Ott, e Dogucu (2022), McElreath (2020) e Kruschke (2014), che hanno svolto un ruolo fondamentale nel facilitare l‚Äôintegrazione dei metodi bayesiani nella pratica analitica della psicologia.\n\n\n29.1.2 Approccio Bayesiano alla Statistica\nL‚Äôapproccio bayesiano alla statistica si distingue non solo per l‚Äôuso del Teorema di Bayes, ma anche per il suo modo di gestire l‚Äôincertezza e di valutare l‚Äôintero spettro di possibili esiti attraverso le distribuzioni di probabilit√†. Questo approccio rifiuta l‚Äôadozione acritica di stime puntuali, favorendo invece una visione probabilistica che accoglie una vasta gamma di esiti, rimanendo fedele alla concezione bayesiana della probabilit√†.\n\n\n29.1.3 Elementi Fondamentali della Modellazione Statistica Bayesiana\nI fondamenti della modellazione statistica bayesiana includono variabili casuali, distribuzioni di probabilit√† priori e posteriori, e il processo di aggiornamento bayesiano.\n\nVariabili casuali rappresentano elementi chiave nella modellazione bayesiana, consentendoci di esprimere e quantificare relazioni probabilistiche.\nDistribuzioni di probabilit√† sono strumenti cruciali per rappresentare quantitativamente l‚Äôincertezza e le conoscenze pregresse. Le distribuzioni priori esprimono le nostre convinzioni iniziali, mentre le distribuzioni posteriori risultano dall‚Äôintegrazione delle nuove evidenze.\nL‚Äôaggiornamento bayesiano √® il meccanismo che affina le distribuzioni priori alla luce di nuovi dati, riducendo l‚Äôincertezza e migliorando le stime dei parametri.\n\nLa modellazione bayesiana segue un approccio metodologico strutturato in progettazione del modello, applicazione del teorema di Bayes, e valutazione critica del modello. Questo flusso di lavoro bayesiano (Baribault e Collins 2023) costituisce un ciclo di apprendimento e affinamento continuo, che esploreremo nei capitoli successivi per una comprensione approfondita del processo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#riesame-del-teorema-di-bayes",
    "href": "chapters/chapter_4/01_intro_bayes.html#riesame-del-teorema-di-bayes",
    "title": "29¬† Modellazione bayesiana",
    "section": "29.2 Riesame del Teorema di Bayes",
    "text": "29.2 Riesame del Teorema di Bayes\nPrima di approfondire il flusso di lavoro bayesiano, √® opportuno rivisitare il teorema di Bayes. Quando ci riferiamo ad eventi osservabili discreti, possiamo esprimere la regola nel modo seguente:\n\\[ P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)} \\]\nDato un vettore di dati \\(y\\), il teorema di Bayes ci permette di calcolare le distribuzioni posteriori dei parametri di interesse, che possiamo rappresentare con il vettore dei parametri \\(\\theta\\). Questo calcolo si realizza riformulando la formula precedente come quella scritta di seguito. La differenza qui consiste nel fatto che il teorema di Bayes √® scritto in termini di distribuzioni di probabilit√†. In questo contesto, \\(p(\\cdot)\\) rappresenta una funzione di densit√† di probabilit√† (nel caso continuo) o una funzione di massa di probabilit√† (nel caso discreto).\n\\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta) \\times p(\\theta)}{p(y)} \\]\nLa suddetta affermazione pu√≤ essere riscritta in parole nel modo seguente:\n\\[\n\\text{Posteriore} = \\frac{\\text{Verosimiglianza √ó A Priori}}{\\text{Verosimiglianza Marginale}}  \n\\]\nI termini qui presentati hanno il seguente significato.\n\nIl Posteriore, \\(p(\\theta \\mid y)\\), √® la distribuzione di probabilit√† dei parametri condizionata ai dati.\nLa Verosimiglianza, \\(p(y \\mid \\theta)\\), come descritto nel capitolo {ref}notebook-likelihood, √® la PMF (nel caso discreto) o la PDF (nel caso continuo) espressa come funzione di \\(\\theta\\).\nL‚ÄôA Priori, \\(p(\\theta)\\), √® la distribuzione di probabilit√† iniziale dei parametri, prima di osservare i dati.\nLa Verosimiglianza Marginale, \\(p(y)\\) standardizza la distribuzione posteriore per garantire che l‚Äôarea sotto la curva della distribuzione sommi a 1, ossia, si assicura che il posteriore sia una distribuzione di probabilit√† valida.\n\nNell‚Äôambito bayesiano, si utilizzano le distribuzioni posteriori aggiornate dei parametri per l‚Äôinferenza, ad esempio per calcolare la probabilit√† che un parametro si trovi entro un determinato intervallo.\nLe distribuzioni a priori, indicate con \\(p(\\theta)\\), sono basate su risultati precedenti, o possono assumere la forma di ‚Äúdistribuzioni di regolarizzazione‚Äù non informative. Un vantaggio significativo delle distribuzioni a priori emerge quando si lavora con campioni di dati di piccole dimensioni; in tali contesti, le distribuzioni a priori di regolarizzazione possono esercitare un effetto moderatore, attenuando le fluttuazioni causate dalla limitata numerosit√† del campione.\nNel definire il processo di modellazione, consideriamo una variabile casuale \\(Y\\), con un valore osservato \\(y\\). Ad esempio, il punteggio ottenuto da uno studente in un test di psicometria pu√≤ essere modellato come \\(Y\\), che assume uno specifico valore \\(y\\) una volta osservato il punteggio. Per spiegare come i dati osservati \\(y\\) siano generati, specificiamo un modello di probabilit√†, il cosiddetto processo generatore di dati (DGP).\nIl parametro \\(\\theta\\) caratterizza il modello di probabilit√† di interesse, potendo essere uno scalare (come media o varianza) o un vettore (ad esempio, coefficienti di regressione). L‚Äôobiettivo dell‚Äôinferenza statistica √® stimare questi parametri sconosciuti a partire dai dati. A differenza dell‚Äôinferenza frequentista, che considera \\(\\theta\\) come fisso ma sconosciuto, l‚Äôinferenza bayesiana tratta \\(\\theta\\) come una variabile casuale soggetta a una distribuzione di probabilit√† a priori.\nIn questo contesto, la probabilit√† congiunta di parametri e dati si calcola come funzione della distribuzione condizionale dei dati dati i parametri e della distribuzione a priori dei parametri. La distribuzione posteriore di \\(\\theta\\) dato \\(y\\) si deriva moltiplicando la funzione di verosimiglianza dei dati \\(p(y \\mid \\theta)\\) per la distribuzione a priori \\(p(\\theta)\\), e normalizzando per \\(p(y)\\). Nei modelli complessi con numerosi parametri, l‚Äôelaborazione della distribuzione posteriore pu√≤ richiedere tecniche computazionali avanzate.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#costruzione-del-modello-dellaggiornamento-bayesiano",
    "href": "chapters/chapter_4/01_intro_bayes.html#costruzione-del-modello-dellaggiornamento-bayesiano",
    "title": "29¬† Modellazione bayesiana",
    "section": "29.3 Costruzione del Modello dell‚ÄôAggiornamento Bayesiano",
    "text": "29.3 Costruzione del Modello dell‚ÄôAggiornamento Bayesiano\nPer spiegare il concetto di aggiornamento bayesiano in maniera intuitiva, McElreath (2020) propone il seguente esempio. Supponiamo di avere un mappamondo e di volere stimare qual √® la proporzione coperta d‚Äôacqua del globo. Per stimare questa proporzione eseguiamo il seguente esperimento casuale: lanciamo in aria il mappamondo e poi lo afferriamo quando cade. Registriamo se la superficie sotto il nostro indice destro √® terra o acqua. Ripetiamo questa procedura un certo numero di volte e calcoliamo la proporzione di volte in cui abbiamo osservato ‚Äúacqua‚Äù. In ogni lancio, ogni valore della proporzione sconosciuta \\(p\\) pu√≤ essere pi√π o meno plausibile, date le evidenze fornite dai lanci precedenti.\nUn modello bayesiano inizia assegnando un insieme di plausibilit√† iniziali a ciascuno dei possibili valori \\(p\\), dette plausibilit√† priori. Poi, queste plausibilit√† vengono aggiornate alla luce dei dati raccolti, producendo le plausibilit√† posteriori. Questo processo di aggiornamento √® una forma di apprendimento, conosciuto come aggiornamento bayesiano.\nNell‚Äôesempio di McElreath (2020), supponiamo che il nostro modello bayesiano assegni inizialmente la stessa plausibilit√† a ogni possibile valore di \\(p\\) (proporzione di acqua). Ora, osserviamo il primo grafico in alto a sinistra nella figura generata dallo script. La linea tratteggiata orizzontale rappresenta la plausibilit√† iniziale di ciascun possibile valore di \\(p\\). Dopo aver visto il primo lancio, che risulta in ‚ÄúW‚Äù (acqua), il modello aggiorna le plausibilit√† alla linea continua. La plausibilit√† che \\(p\\) = 0 scende a zero, indicando che √® ‚Äúimpossibile‚Äù non avere acqua, dato che abbiamo osservato almeno una traccia di acqua sul globo. Allo stesso modo, la plausibilit√† che \\(p\\) &gt; 0.5 aumenta, poich√© non c‚Äô√® ancora evidenza di terra sul globo, quindi le plausibilit√† iniziali vengono modificate per essere coerenti con questa osservazione. Tuttavia, le differenze nelle plausibilit√† non sono ancora molto grandi, poich√© le evidenze raccolte finora sono limitate. In questo modo, la quantit√† di evidenza vista finora si riflette nelle plausibilit√† di ciascun valore di \\(p\\): la plausibilit√† che \\(p\\) sia 0 √® zero e la plausibilit√† che \\(p\\) sia 1 √® massima. Quindi, la distribuzione a posteriori di \\(p\\) √® rappresentata dalla linea continua che collega questi due estremi.\nNei grafici successivi, vengono introdotti ulteriori campioni dal globo, uno alla volta. Ogni curva tratteggiata rappresenta la curva continua dal grafico precedente, spostandosi da sinistra a destra e dall‚Äôalto in basso. La seconda osservazione √® ‚Äúterra‚Äù (L). La distribuzione a priori √® la linea tratteggiata del secondo pannello e la distribuzione a postriori √® la linea curva. Otteniamo questa curva perch√© assegniamo una verosimiglianza 0 agli eventi \\(p\\) = 0 (abbiamo osservato ‚Äúacqua‚Äù) e \\(p\\) = 1 (abbiamo osservato ‚Äúterra‚Äù). In due lanci abbiamo osservato una volta ‚Äúterra‚Äù e una volta ‚Äúacqua‚Äù. Dunque la plausibilit√† che \\(p\\) = 0.5 √® massima. Da cui la curva che abbiamo disegnato.\nIl terzo lancio del mappamondo produce nuovamente ‚Äúacqua‚Äù. Quindi a questo punto il valore pi√π plausibile di \\(p\\) √® 0.75. modifichiamo dunque la distribuzione a priori (linea tratteggiata nel terzo pannello) in modo da rappresentare le nostre nuove conoscenze, come indicato dalla linea continua.\nOgni volta che viene osservato un ‚ÄúW‚Äù, il picco della curva di plausibilit√† si sposta a destra, verso valori maggiori di \\(p\\). Ogni volta che viene osservato un ‚ÄúL‚Äù (terra), si sposta nella direzione opposta. L‚Äôaltezza massima della curva aumenta con ogni campione, significando che la plausibilit√† complessiva (1) viene ridistribuita ad un numero minore di valori di \\(p\\) i quali accumulano una maggiore plausibilit√† man mano che aumenta la quantit√† di evidenza. Con l‚Äôaggiunta di ogni nuova osservazione, la curva viene aggiornata in modo coerente con tutte le osservazioni precedenti.\n√à importante notare che ogni set aggiornato di plausibilit√† diventa la plausibilit√† iniziale per l‚Äôosservazione successiva. Ogni conclusione √® il punto di partenza per l‚Äôinferenza futura. Questo processo di aggiornamento funziona anche al contrario: conoscendo l‚Äôultimo set di plausibilit√† e l‚Äôultima osservazione, √® possibile matematicamente dedurre la curva di plausibilit√† precedente. I dati potrebbero essere presentati al modello in qualsiasi ordine, o anche tutti insieme. Nella maggior parte dei casi, i dati verranno considerati tutti insieme per comodit√†, ma √® importante capire che ci√≤ rappresenta solo l‚Äôabbreviazione di un processo di apprendimento iterato.\n\ndef beta(W, L, p):\n    return factorial(W + L + 1) / (factorial(W) * factorial(L)) * p ** W * (1-p) ** L\n\n\ndef plot_beta_from_observations(observations: str, resolution: int = 50, **plot_kwargs):\n    \"\"\"Calcualte the posterior for a string of observations\"\"\"\n    n_W = len(observations.replace(\"L\", \"\"))\n    n_L = len(observations) - n_W\n    proportions = np.linspace(0, 1, resolution)\n        \n    probs = beta(n_W, n_L, proportions)\n    plt.plot(proportions, probs, **plot_kwargs)\n    plt.yticks([])\n    plt.title(observations)\n    \n\n# Tossing the globe\nobservations = \"WLWWWLWLW\"\nfig, axs = plt.subplots(3, 3, figsize=(8, 8))\nfor ii in range(9):\n    ax = axs[ii // 3][ii % 3]\n    plt.sca(ax)\n    # Plot previous\n    if ii &gt; 0:\n        plot_beta_from_observations(observations[:ii], color='k', linestyle='--')\n    else:\n        # First observation, no previous data\n        plot_beta_from_observations('', color='k', linestyle='--')\n        \n    color = 'C1' if observations[ii] == 'W' else 'C0'\n    plot_beta_from_observations(observations[:ii+1], color=color, linewidth=4, alpha=.5)\n    \n    if not ii % 3:\n        plt.ylabel(\"posterior probability\")\n\n\n\n\n\n\n\n\nIl lettore attento si sar√† chiesto se la curva continua dell‚Äôultimo pannello non sia in realt√† identica alla funzione di verosimiglianza binomiale con 6 successi in 9 prove ‚Äì si veda il Capitolo 27. In effetti √® proprio cos√¨. Lo stesso vale, ovviamente, per ciascuno dei pannelli della figura.\n\ny = 6\nn = 9\ntheta = np.linspace(0.0, 1.0, num=100)\n\nlike = stats.binom.pmf(y, n, theta)\n\nplt.plot(theta, like, \"-\", linewidth=4, alpha=.5)\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\n_ = plt.ylabel(\"Verosimiglianza\")\n\n\n\n\n\n\n\n\nQuesto esempio illustra come la funzione di probabilit√† a posteriori si modifichi progressivamente con l‚Äôacquisizione di nuove evidenze. Tale processo avviene in maniera automatica, riflettendo il meccanismo di aggiornamento delle credenze che caratterizza l‚Äôinferenza bayesiana. In ogni pannello, la transizione dalla linea tratteggiata alla linea piena simboleggia questo aggiornamento: la linea tratteggiata rappresenta la distribuzione di probabilit√† a priori, ovvero le nostre credenze iniziali prima dell‚Äôosservazione dei nuovi dati; la linea piena, invece, rappresenta la distribuzione di probabilit√† a posteriori, che integra le nuove evidenze ai preconcetti iniziali. Quest‚Äôultima rispecchia dunque una sintesi ottimizzata delle informazioni pregresse e attuali, offrendo una rappresentazione aggiornata e pi√π accurata della realt√† in esame.\n\n29.3.1 Il flusso di lavoro bayesiano\nMetaforicamente descritto come ‚Äúgirare la manovella bayesiana‚Äù, il flusso di lavoro bayesiano √® composto da diverse fasi.\n\nStudio di Simulazione: Questa fase prevede la generazione di dati sintetici che riproducono il contesto di ricerca. Questo aiuta a valutare la robustezza del disegno sperimentale e ad assicurare che il modello sia adeguato.\nRaccolta e Identificazione dei Dati: Qui si acquisiscono e analizzano i dati reali, assicurandosi che siano appropriati per le analisi successive.\nSelezione del Modello Statistico: In questa fase si formula un modello statistico che rappresenta le teorie e le ipotesi alla base della ricerca, basandosi su una solida comprensione del fenomeno e su principi statistici.\nDefinizione delle Distribuzioni a Priori: Si stabiliscono le distribuzioni a priori dei parametri del modello, basandosi su conoscenze pregresse e un ragionamento teorico robusto.\nCalcolo delle Distribuzioni a Posteriori: Utilizzando metodi analitici o tecniche di campionamento come le Catene di Markov Monte Carlo (MCMC), si derivano le distribuzioni a posteriori dei parametri.\nRisoluzione dei Problemi e Diagnostica: In questa fase si eseguono controlli per assicurare la convergenza del modello e la validit√† delle inferenze, utilizzando metriche e diagnosi specializzate.\nControlli di Coerenza: Oltre alla diagnostica tecnica, si valuta la coerenza e la plausibilit√† del modello rispetto ai dati e al contesto teorico, incluso un esame predittivo a posteriori.\nInterpretazione e Comunicazione dei Risultati: Infine, i risultati vengono interpretati nel contesto della teoria sottostante e comunicati in modo chiaro, integrandoli nell‚Äôambito pi√π ampio della comprensione del fenomeno in studio.\n\nQuesto processo iterativo mira a ottenere inferenze valide, fornendo una base solida per la ricerca scientifica. Una rappresentazione visiva di questo flusso di lavoro bayesiano √® illustrata nella figura tratta dall‚Äôarticolo di Baribault e Collins (2023).\n\n\n\n\n\n\nFigura¬†29.1: Una rappresentazione abbreviata del flusso di lavoro bayesiano. L‚Äôoutput del modello che non supera il filtro (che rappresenta i necessari controlli computazionali e di coerenza) deve essere respinto. √à necessario migliorare la specifica del modello in modo che l‚Äôoutput possa superare tutti i controlli. Solo allora il modello bayesiano pu√≤ essere utilizzato come base per l‚Äôinferenza. (Figura tratta da Baribault e Collins (2023)).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#notazione",
    "href": "chapters/chapter_4/01_intro_bayes.html#notazione",
    "title": "29¬† Modellazione bayesiana",
    "section": "29.4 Notazione",
    "text": "29.4 Notazione\nLa costruzione di modelli statistici bayesiani che incorporano questo approccio probabilistico per caratterizzare l‚Äôincertezza richiede innanzitutto una familiarizzazione con il linguaggio e le notazioni matematiche utilizzate nella formulazione di questi modelli. Questa conoscenza facilita la comunicazione delle caratteristiche del modello e l‚Äôestensione del linguaggio di modellazione a vari domini.\nNel seguito utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo invece \\(x\\) per denotare le quantit√† note, come ad esempio i predittori di un modello lineare.\nAl fine di rappresentare in modo pi√π conciso i modelli probabilistici, adotteremo una notazione specifica. Ad esempio, anzich√© scrivere la distribuzione di probabilit√† di \\(\\theta\\) come \\(p(\\theta) = Beta(1, 1)\\), scriveremo semplicemente \\(\\theta \\sim Beta(1, 1)\\). Il simbolo ‚Äú\\(\\sim\\)‚Äù viene comunemente letto come ‚Äúsegue la distribuzione di‚Äù. Possiamo anche interpretarlo nel senso che \\(\\theta\\) √® un campione casuale estratto dalla distribuzione Beta(1, 1). Analogamente, la verosimiglianza di un modello binomiale sar√† espressa come \\(y \\sim \\text{Bin}(n, \\theta)\\), dove ‚Äú\\(\\sim\\)‚Äù indica che \\(y\\) segue una distribuzione binomiale con parametri \\(n\\) e \\(\\theta\\). Questa notazione semplifica la rappresentazione dei modelli probabilistici, rendendo pi√π chiara la relazione tra i dati, i parametri e le distribuzioni di probabilit√† coinvolte nelle analisi statistiche.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#metodi-di-stima-della-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/01_intro_bayes.html#metodi-di-stima-della-distribuzione-a-posteriori",
    "title": "29¬† Modellazione bayesiana",
    "section": "29.5 Metodi di Stima della Distribuzione a Posteriori",
    "text": "29.5 Metodi di Stima della Distribuzione a Posteriori\nLa formulazione completa della distribuzione posteriore √® data da:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) \\cdot p(\\theta)}{\\int_{\\Theta} p(y \\mid \\theta) \\cdot p(\\theta) \\, d\\theta}, \\quad \\text{dove} \\quad \\theta \\in \\Theta,\n\\]\nin cui \\(\\Theta\\) denota l‚Äôinsieme di tutti i possibili valori del parametro \\(\\theta\\).\nIl calcolo di \\(p(\\theta \\mid y)\\) richiede la normalizzazione del prodotto tra la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) e la distribuzione a priori \\(p(\\theta)\\) attraverso una costante di normalizzazione. Questa costante, nota come verosimiglianza marginale, assicura che l‚Äôintegrale di \\(p(\\theta \\mid y)\\) su tutto lo spazio dei parametri \\(\\Theta\\) sia pari a uno.\nIn questa sezione, approfondiremo il concetto di likelihood marginale (che significa semplicemente la verosimiglianza media) attraverso il processo noto come integrazione di un parametro. Tale processo consente il calcolo della likelihood marginale, rimuovendo effettivamente il parametro incognito dalla distribuzione in esame. Per illustrare questo concetto, utilizzeremo la distribuzione binomiale, ma √® importante sottolineare che l‚Äôapplicabilit√† di questa tecnica si estende ben oltre, coprendo una vasta gamma di distribuzioni.\nConsideriamo una variabile casuale binomiale \\(Y\\) caratterizzata da una funzione di massa di probabilit√† (PMF) \\(p(Y)\\), definita in relazione a un parametro \\(\\theta\\). Supponiamo che quest‚Äôultimo pu√≤ assumere uno di tre valori specifici: 0.1, 0.5, o 0.9, ognuno dei quali ha identica probabilit√† di verificarsi, ossia \\(\\frac{1}{3}\\).\nFissiamo i dati a \\(n = 10\\) prove e \\(k = 7\\) successi, ottenendo la seguente funzione di likelihood:\n\\[\np(k = 7, n = 10 | \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la likelihood marginale, denotata con \\(p(k = 7, n = 10)\\), ‚Äúmarginalizziamo‚Äù il parametro \\(\\theta\\). Questo si realizza valutando la likelihood per ciascun valore possibile di \\(\\theta\\), moltiplicandola per la probabilit√†/densit√† di quel particolare valore di \\(\\theta\\) e sommando i risultati ottenuti.\nDati i valori di \\(\\theta\\), \\(\\theta_1 = 0.1\\), \\(\\theta_2 = 0.5\\), e \\(\\theta_3 = 0.9\\), ciascuno con una probabilit√† di \\(\\frac{1}{3}\\), calcoliamo la likelihood marginale nel seguente modo:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 | \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e la loro probabilit√† di \\(\\frac{1}{3}\\), otteniamo:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesta espressione ci consente di calcolare la likelihood marginale, basandoci sui valori discreti di \\(\\theta\\). Tale processo evidenzia come la marginalizzazione faccia emergere una comprensione globale della likelihood, incorporando tutte le possibili variazioni del parametro \\(\\theta\\) per ottenere una misura complessiva che tenga conto dell‚Äôincertezza su \\(\\theta\\).\nIn questo esempio abbiamo mostrato come sia possibile applicare la marginalizzazine (ovvero, l‚Äôintegrazione di un parametro) non solo in contesti continui, tramite l‚Äôuso dell‚Äôintegrale, ma anche in scenari discreti, sommando semplicemente i valori di likelihood moltiplicati per le rispettive probabilit√† di occorrenza del parametro.\nPer implementare un calcolo analogo in Python, possiamo definire una funzione che calcoli la likelihood per i valori discreti di \\(\\theta\\) e poi sommare i risultati. Per l‚Äôintegrazione su un intervallo continuo tra 0 e 1, invece, possiamo utilizzare la libreria scipy.\n\n# Funzione di likelihood\ndef likelihood(theta, k=7, n=10):\n    return comb(n, k) * (theta**k) * ((1 - theta)**(n - k))\n\n# Likelihood marginale per valori discreti di theta\ntheta_vals = np.array([0.1, 0.5, 0.9])\nprob_theta = 1/3\nmarginal_likelihood_discrete = sum([likelihood(theta) * prob_theta for theta in theta_vals])\n\nprint(f\"Likelihood Marginale (discreta): {marginal_likelihood_discrete}\")\n\n# Likelihood marginale su un intervallo continuo [0, 1]\nmarginal_likelihood_continuous, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(f\"Likelihood Marginale (continua): {marginal_likelihood_continuous}\")\n\nLikelihood Marginale (discreta): 0.05819729199999999\nLikelihood Marginale (continua): 0.09090909090909091\n\n\nIl punto da notare, tuttavia, √® che il calcolo analitico della verosimiglianza marginale √® fattibile solo in circostanze particolari. In generale, √® necessario procedere per approssimazione numerica.\n\n29.5.1 Metodi per determinare la distribuzione a posteriori\nPer determinare la distribuzione posteriore, dunque, si possono adottare due approcci principali:\n\nApproccio Analitico: Questa strategia si applica quando la distribuzione a priori e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, dette coniugate. In tali circostanze, √® possibile calcolare analiticamente la distribuzione posteriore. Questo metodo si distingue per la sua eleganza e efficienza computazionale, ma √® limitato alle situazioni in cui esiste una coniugazione tra le distribuzioni a priori e le funzioni di verosimiglianza.\nApproccio Numerico: Quando l‚Äôapproccio analitico non √® applicabile, ad esempio a causa dell‚Äôassenza di coniugazione tra distribuzioni a priori e funzioni di verosimiglianza, l‚Äôintegrale al denominatore (la likelihood marginale) della regola di Bayes non pu√≤ essere risolto con metodi analitici. In questi casi, l‚Äôinferenza bayesiana procede attraverso tecniche di approssimazione numerica. Tecniche come le catene di Markov Monte Carlo (MCMC) vengono impiegate per stimare numericamente la distribuzione posteriore. Questo metodo √® pi√π versatile e adattabile a un‚Äôampia gamma di problemi, ma richiede un maggiore impegno computazionale e pu√≤ essere pi√π oneroso in termini di tempo rispetto all‚Äôapproccio analitico.\n\n\n\n29.5.2 Linguaggi di programmazione probabilistici\nL‚Äôapproccio moderno alla statistica bayesiana si avvale ampiamente di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. In questo contesto, si fa largo uso di linguaggi di programmazione probabilistica, noti come ‚ÄúProbabilistic Programming Languages‚Äù (PPL), che facilitano l‚Äôimplementazione computazionale dell‚Äôaggiornamento bayesiano.\nQuesto sviluppo ha trasformato radicalmente il modo in cui si effettuano le analisi statistiche bayesiane, democratizzando l‚Äôaccesso a modelli statistici avanzati. L‚Äôintroduzione di metodi computazionali ha reso la modellazione bayesiana pi√π accessibile, riducendo le barriere di competenza matematica e computazionale precedentemente necessarie. Questi strumenti hanno inoltre ampliato le possibilit√† di affrontare questioni analitiche complesse, che prima sarebbero state difficili da gestire. Utilizzando i linguaggi di programmazione probabilistica, gli analisti possono formulare modelli probabilistici con maggiore chiarezza e flessibilit√†, facilitando l‚Äôesplorazione delle distribuzioni posteriori e l‚Äôanalisi di questioni complesse con tecniche bayesiane. Questo ha aperto nuovi orizzonti nell‚Äôanalisi bayesiana, permettendo di affrontare e risolvere problemi in modi precedentemente impensabili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "title": "29¬† Modellazione bayesiana",
    "section": "29.6 Commenti e considerazioni finali",
    "text": "29.6 Commenti e considerazioni finali\nL‚Äôapproccio bayesiano rappresenta un modo distintivo di affrontare l‚Äôincertezza associata ai parametri di interesse, contrapponendosi in modo significativo alla metodologia classica. Mentre il paradigma classico tratta i parametri come valori fissi e sconosciuti, l‚Äôapproccio bayesiano li considera come quantit√† probabilistiche, attribuendo loro una distribuzione a priori che riflette le nostre credenze e intuizioni iniziali prima dell‚Äôesperimento. Grazie all‚Äôapplicazione del teorema di Bayes, queste credenze vengono progressivamente raffinate e aggiornate sulla base dei dati osservati, conducendo alla definizione della distribuzione a posteriori. Tale distribuzione rappresenta una prospettiva aggiornata dell‚Äôincertezza, integrando sia l‚Äôevidenza empirica che le informazioni pregresse.\nLa potenza dell‚Äôapproccio bayesiano risiede nella sua capacit√† di amalgamare le conoscenze pregresse con le nuove osservazioni, producendo stime dei parametri di interesse che non solo sono pi√π accurate ma anche pi√π significative dal punto di vista interpretativo. Oltre a essere un semplice strumento statistico, il bayesianesimo si rivela un potente strumento decisionale che favorisce un‚Äôinterazione dinamica tra teoria ed esperienza.\nTuttavia, uno svantaggio dell‚Äôapproccio bayesiano risiede nella sua potenziale lentezza e inefficienza nel trattare dataset molto estesi. Ci√≤ significa che quando si applicano metodi basati sulla teoria bayesiana all‚Äôanalisi dei dati, potrebbero sorgere problemi di scalabilit√† e di efficienza computazionale, specialmente di fronte a insiemi di dati di dimensioni considerevoli.\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nBaribault, Beth, e Anne GE Collins. 2023. ¬´Troubleshooting Bayesian cognitive models.¬ª Psychological Methods.\n\n\nBox, G. E., A. Luceno, e M. del Carmen Paniagua-Quinones. 2011. Statistical control by monitoring and adjustment. John Wiley; Sons.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html",
    "href": "chapters/chapter_4/02_subj_prop.html",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Introduzione\nQuesto capitolo mira a esplorare in profondit√† il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L‚Äôobiettivo √® dimostrare come le nostre credenze preesistenti sulla probabilit√† \\(\\theta\\) di un evento specifico possano essere affinate mediante l‚Äôosservazione di nuovi dati.\nInizieremo descrivendo come rappresentare le nostre convinzioni iniziali, ovvero quelle formulate prima di raccogliere qualsiasi dato, tramite una distribuzione a priori. Successivamente, delineeremo i passaggi calcolativi necessari per derivare la distribuzione a posteriori di \\(\\theta\\). Questa distribuzione rappresenta le nostre credenze aggiornate su \\(\\theta\\) una volta considerati i dati osservati. L‚Äôottenimento della distribuzione a posteriori avviene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, seguita da una normalizzazione per garantire che il risultato sia una distribuzione di probabilit√† valida.\nIl capitolo si focalizza principalmente sul modello binomiale, un contesto elementare ma cruciale per l‚Äôinferenza bayesiana. Questo modello √® utilizzato per stimare una proporzione di popolazione sconosciuta a partire da una serie di ‚Äúprove di Bernoulli‚Äù, ovvero dati \\(y_1, \\ldots, y_n\\), ciascuno dei quali assume valore 0 o 1. Questo problema rappresenta un punto di partenza relativamente semplice ma fondamentale per la discussione dell‚Äôinferenza bayesiana. Inizieremo esplorando il caso in cui la distribuzione a priori √® discreta, per poi passare all‚Äôanalisi di scenari in cui essa √® continua.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/chapter_4/02_subj_prop.html#verosimiglianza-binomiale",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.1 Verosimiglianza Binomiale",
    "text": "30.1 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova d√† origine a uno dei due possibili esiti, convenzionalmente etichettati come ‚Äòsuccesso‚Äô e ‚Äòfallimento‚Äô. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilit√† di successo in ciascuna prova. Il modello di campionamento binomiale √®:\n\\[ p(y|\\theta) = \\text{Bin}(y|n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}, \\]\ndove nella parte sinistra dell‚Äôequazione non si indica la dipendenza da \\(n\\) perch√© viene considerato parte del disegno sperimentale e fissato; tutte le probabilit√† discusse per questo problema sono considerate condizionate su \\(n\\), cio√® assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/chapter_4/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.2 Applicazione Specifica del Modello Binomiale",
    "text": "30.2 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, consideriamo un‚Äôapplicazione specifica del modello binomiale per stimare la proporzione di presenza di ideazione suicidaria all‚Äôinterno di una popolazione specifica. Prenderemo in esame lo studio di Comtois et al. (2023), in cui viene valutata l‚Äôefficacia di un intervento volto a prevenire l‚Äôideazione suicidaria nella comunit√† universitaria. I partecipanti allo studio erano pazienti reclutati secondo i seguenti criteri: 1. Ricovero ospedaliero o accesso al pronto soccorso per rischio suicidario. 2. Tentativo di suicidio nel mese precedente (compresi tentativi interrotti o auto-interrotti).\nNel gruppo di controllo dello studio, composto da 75 pazienti, √® stato somministrato il trattamento standard (TAU), che seguiva le politiche e procedure standard per i servizi brevi e orientati alla crisi. Questo trattamento comprendeva una valutazione iniziale seguita da 1-11 visite con un clinico (con una media di 4,5 visite) e gestione dei farmaci, se necessario, terminando con un rinvio a un altro servizio per il follow-up delle cure primarie o per un ulteriore trattamento per la salute mentale o l‚Äôabuso di sostanze.\nDopo 12 mesi, l‚Äôideazione suicidaria √® stata misurata utilizzando la Beck Scale for Suicide Ideation (BSS; Beck & Steer, 1993), la versione self-report della Scale for Suicide Ideation (Beck, Brown, & Steer, 1997), una misura valida e affidabile dell‚Äôideazione suicidaria. I dati mostrano che, dopo 12 mesi, 35 pazienti del gruppo TAU hanno riportato almeno un episodio di ideazione suicidaria. L‚Äôobiettivo dell‚Äôanalisi √® quantificare l‚Äôincertezza di questa stima di \\(\\theta\\), la proporzione di presenza di ideazione suicidaria in questa popolazione dopo un anno.\nConsideriamo ogni paziente come una prova bernoulliana in cui emerge (1) o non emerge (0) almeno un episodio di ideazione suicidaria nel corso dell‚Äôanno considerato. Utilizzando il modello binomiale, stimiamo quindi la probabilit√† \\(\\theta\\) di ideazione suicidaria nella popolazione e quantifichiamo l‚Äôincertezza associata a questa stima.\n\n30.2.1 Processo di Lavoro\nMcElreath (2020) descrive il flusso lavoro bayesiano nel modo seguente.\n\nDefinire un Modello Generativo per i Dati: Un modello generativo spiega come i dati sono stati prodotti. Nel nostro caso, consideriamo ogni paziente come un esperimento di Bernoulli con due possibili esiti: presenza (1) o assenza (0) di ideazione suicidaria. Definiamo \\(\\theta\\) come la probabilit√† di osservare ideazione suicidaria in un singolo paziente. Il modello generativo dei dati si esprime quindi come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, ..., 75\\) e \\(X_i\\) assume valore 1 in caso di presenza e 0 in caso di assenza di ideazione suicidaria.\nDefinire uno Stimatore per il Parametro di Interesse: Uno stimatore √® una regola o una formula che utilizza i dati del campione per calcolare una stima del parametro di interesse. Nel nostro caso, lo stimatore che cerchiamo √® la probabilit√† \\(\\theta\\) di osservare un episodio di ideazione suicidaria dopo 12 mesi dall‚Äôepisodio di crisi. L‚Äôobiettivo √® stimare l‚Äôincertezza di questa probabilit√† basandoci sui dati raccolti.\nSviluppare un Metodo Statistico per la Stima del Parametro di Interesse: Per stimare \\(\\theta\\), applichiamo l‚Äôapproccio bayesiano. Nella statistica bayesiana, partiamo da una distribuzione a priori che esprime le nostre convinzioni iniziali su \\(\\theta\\), per poi aggiornarla con i dati osservati e ottenere una distribuzione a posteriori. Una scelta comune per la priori in un contesto Bernoulli/Binomiale √® la distribuzione Beta. Partiamo da una priori non informativa, \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme.\nLa verosimiglianza dei nostri dati (35 ‚Äúsuccessi‚Äù, 40 ‚Äúinsuccessi‚Äù) √® data dalla distribuzione binomiale:\n\\[\nL(p) = {75 \\choose 35} \\theta^{35} (1-\\theta)^{40}.\n\\]\nUtilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}\n\\]\nValidazione del Modello attraverso Simulazioni: Prima di esaminare i dati concreti, effettuiamo una simulazione predittiva a priori per verificare se il modello pu√≤ generare dati plausibili. Dopo l‚Äôadattamento del modello ai dati veri, conduciamo una simulazione predittiva a posteriori per testare la capacit√† del modello di produrre dati comparabili a quelli osservati.\nAnalisi e Sintesi dei Risultati: Infine, procediamo con l‚Äôanalisi dei dati veri, calcolando la distribuzione a posteriori, solitamente attraverso metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per inferire su \\(\\theta\\), utilizzando statistiche descrittive quali media, mediana e intervalli di credibilit√†.\n\nNel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano",
    "text": "30.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano\nDopo aver discusso l‚Äôaggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia √® un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l‚Äôuso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilit√† sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l‚Äôarea totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "30.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente considerare un valore di 0.5, suggerendo una probabilit√† ugualmente bilanciata tra la presenza e l‚Äôassenza di ideazione suicidaria. Tuttavia, questo valore non rappresenta adeguatamente l‚Äôintero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilit√† distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilit√† a priori uguale, creando cos√¨ una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) pi√π probabili.\nDopo aver osservato i dati ‚Äî ad esempio, 35 casi di ideazione suicidaria su 75 ‚Äî applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilit√† a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilit√† a posteriori aggiornata per \\(\\theta\\).\nLa distribuzione a posteriori integra quindi le nostre conoscenze pregresse con le nuove informazioni ottenute dalle osservazioni, offrendoci una visione aggiornata e quantitativamente informata del parametro \\(\\theta\\). Attraverso questo esempio, possiamo osservare un approccio sistematico ed efficace per affinare le nostre credenze alla luce di nuove prove.\n\ntheta = np.linspace(0, 1, 11)\nprint(theta)\n\n[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n\n\nNel caso in cui non vi siano motivi fondati per assegnare probabilit√† diverse ai vari valori di \\(\\theta\\), √® possibile attribuire la stessa probabilit√† a ciascun valore, creando cos√¨ una distribuzione uniforme. √à importante prestare attenzione alla seconda riga di codice, che esegue una standardizzazione. Poich√© unif_discr_pdf √® un vettore composto da un numero finito di elementi, questi elementi devono essere considerati come probabilit√†, e tali probabilit√† devono obbligatoriamente sommarsi a uno.\n\nunif_distr_pdf = stats.uniform.pdf(theta) \nunif_distr_pdf = unif_distr_pdf / np.sum(unif_distr_pdf)\nunif_distr_pdf\n\narray([0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909])\n\n\nUna rappresentazione visiva di questa distribuzione di massa di probabilit√† si ottiene nel modo seguente.\n\nplt.stem(theta, unif_distr_pdf, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nSe, al contrario, riteniamo che i valori centrali nella distribuzione di \\(\\theta\\) siano pi√π credibili rispetto a quelli situati agli estremi, potremmo esprimere questa opinione soggettiva mediante la seguente distribuzione di massa di probabilit√†.\n\nnot_unif_distr_pdf = [0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05]\nplt.stem(theta, not_unif_distr_pdf, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nLa prima distribuzione di probabilit√† √® una distribuzione discreta uniforme, in quanto assegna la stessa probabilit√† a ciascun elemento dell‚Äôinsieme discreto su cui √® definita, ossia i valori \\(\\{0, 0.1, 0.2, \\dots, 1.0\\}\\). La seconda distribuzione di probabilit√†, pur essendo discreta, segue un andamento non uniforme: si presume che \\(\\theta\\) abbia una probabilit√† maggiore di assumere un valore nell‚Äôinsieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) rispetto all‚Äôinsieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).\nLe credenze iniziali riguardo ai possibili valori di \\(\\theta\\) costituiscono la ‚Äúdistribuzione a priori‚Äù. L‚Äôinferenza bayesiana aggiorna queste credenze iniziali utilizzando le informazioni ottenute dai dati. Queste informazioni vengono combinate con le credenze iniziali su \\(\\theta\\) attraverso l‚Äôapplicazione del teorema di Bayes, allo scopo di ottenere la ‚Äúdistribuzione a posteriori‚Äù. Quest‚Äôultima rappresenta le nostre credenze aggiornate sui possibili valori di \\(\\theta\\) dopo l‚Äôosservazione dei dati.\nSupponiamo di aver osservato 35 ‚Äúsuccessi‚Äù in 75 prove. Per calcolare la distribuzione a posteriori, utilizzeremo la seconda delle due distribuzioni a priori precedentemente descritte. In base al teorema di Bayes, la distribuzione a posteriori si ottiene moltiplicando la verosimiglianza per la distribuzione a priori e quindi dividendo per una costante di normalizzazione (la verosimiglianza marginale):\n\\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}. \\]\nPer calcolare la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), dobbiamo comprendere il processo mediante il quale i dati sono stati generati. Nel nostro contesto, i dati rappresentano i risultati di 75 ripetizioni di un esperimento casuale che pu√≤ produrre solo due risultati possibili: ‚Äúpresenza‚Äù e ‚Äúassenza‚Äù di ideazione suicidaria. Inoltre, i 75 casi esaminati sono tra loro indipendenti (i pazienti non si influenzano reciprocamente). In tali circostanze, possiamo assumere che il modello generativo dei dati sia il modello binomiale con probabilit√† sconosciuta \\(\\theta\\).\nUtilizzando Python, √® possibile calcolare la funzione di verosimiglianza tramite la funzione binom.pmf().\n\nlk = stats.binom.pmf(35, 70, theta)\nlk = lk / np.sum(lk)\nlk\n\narray([0.00000000e+00, 1.99180385e-16, 1.10906788e-07, 1.50811359e-03,\n       1.61492440e-01, 6.73998671e-01, 1.61492440e-01, 1.50811359e-03,\n       1.10906788e-07, 1.99180385e-16, 0.00000000e+00])\n\n\nPer i 10 valori \\(\\theta\\) considerati, la funzione di verosimiglianza assume la forma indicata dalla figura seguente.\n\nplt.stem(theta, lk, markerfmt=\" \")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"$L(\\\\theta)$\");\n\n\n\n\n\n\n\n\nPer calcolare la distribuzione a posteriori, eseguiamo una moltiplicazione elemento per elemento tra il vettore contenente i valori della distribuzione a priori e il vettore contenente i valori della funzione di verosimiglianza. Usando Python, il risultato si trova nel modo seguente.\n\nnot_unif_distr_pdf * lk\n\narray([0.00000000e+00, 9.95901924e-18, 5.54533942e-09, 7.54056793e-05,\n       2.82611770e-02, 1.17949767e-01, 2.82611770e-02, 2.63919878e-04,\n       5.54533942e-09, 9.95901924e-18, 0.00000000e+00])\n\n\nPer illustrare con un esempio, il valore dell‚Äôottavo elemento della distribuzione a posteriori si calcola come segue (tenendo presente che in Python gli indici partono da 0):\n\nnot_unif_distr_pdf[7] * lk[7]\n\n0.0002639198775144677\n\n\nDopo questa moltiplicazione, otteniamo una distribuzione che rappresenta le probabilit√† condizionate dei possibili valori di \\(\\theta\\) alla luce dei dati osservati. Tuttavia, questa distribuzione potrebbe non √® normalizzata, il che significa che la somma di tutte le probabilit√† condizionate non √® uguale a 1.\nPer ottenere una distribuzione di probabilit√† correttamente normalizzata, dobbiamo dividere ciascun valore ottenuto precedentemente per la probabilit√† marginale dei dati \\(y\\). La probabilit√† marginale dei dati \\(y\\) √® una costante di normalizzazione e pu√≤ essere calcolata utilizzando la legge della probabilit√† totale (si veda l‚Äôeq. {eq}eq-prob-tot).\nPer chiarire, ricordiamo che, nel capitolo {ref}cond-prob-notebook abbiamo considerato il caso di una partizione dello spazio campione in due eventi mutualmente esclusivi ed esaustivi, \\(H_1\\) e \\(H_2\\). All‚Äôinterno dello spazio campione abbiamo definito un evento \\(E\\) non nullo e abbiamo visto che \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\), ovvero \\(P(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2)\\). Usando la terminologia che stiamo usando qui, \\(P(E \\mid H_i)\\) corrisponde alla funzione di verosimiglianza e \\(P(H_i)\\) corrisponde alla funzione a priori. Nel caso discreto, come quello che stiamo considerando ora, il teorema della probabilit√† totale ci dice dunque che dobbiamo fare la somma dei prodotti tra i valori della funzione di verosimiglianza e i corrispondenti valori della distribuzione a priori.\n\nnp.sum(not_unif_distr_pdf * lk)\n\n0.17481145807507814\n\n\nOtteniamo dunque il seguente risultato.\n\npost = (not_unif_distr_pdf * lk) / np.sum(not_unif_distr_pdf * lk)\nprint(post)\n\n[0.00000000e+00 5.69700599e-17 3.17218304e-08 4.31354330e-04\n 1.61666617e-01 6.74725608e-01 1.61666617e-01 1.50974015e-03\n 3.17218304e-08 5.69700599e-17 0.00000000e+00]\n\n\nVerifichiamo di avere ottenuto una distribuzione di massa di probabilit√†:\n\nnp.sum(post)\n\n1.0000000000000002\n\n\nEsaminiamo la distribuzione a posteriori di \\(\\theta\\) con un grafico.\n\nplt.stem(theta, post, markerfmt=\" \")\nplt.title(\"Distribuzione a posteriori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\");\n\n\n\n\n\n\n\n\nUna volta trovata la distribuzione a posteriori di \\(\\theta\\), possiamo calcolare altre quantit√† di interesse. Ad esempio, la moda a posteriori di \\(\\theta\\) pu√≤ essere individuata direttamente dal grafico precedente e risulta pari a 0.5. Per calcolare invece la media a posteriori, ci avvaliamo della formula del valore atteso delle variabili casuali.\n\nnp.sum(theta * post)\n\n0.5002156771647586\n\n\nLa varianza della distribuzione a posteriori √®\n\nnp.sum(theta**2 * post) - (np.sum(theta * post)) ** 2\n\n0.0033109353091205773\n\n\nCon questo metodo, possiamo calcolare la distribuzione a posteriori di \\(\\theta\\) per qualsiasi distribuzione a priori discreta.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/chapter_4/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "30.5 Aggiornamento bayesiano con una distribuzione a priori continua\nA fini didattici, abbiamo esaminato il caso di una distribuzione a priori discreta. Tuttavia, √® importante notare che l‚Äôimpiego di una distribuzione a priori continua, come la distribuzione Beta, risulta pi√π appropriato in quanto permette di rappresentare un‚Äôampia gamma di possibili valori per il parametro non noto \\(\\theta\\), senza essere vincolati a un insieme discreto di valori. Inoltre, la distribuzione Beta presenta l‚Äôulteriore vantaggio di avere un dominio definito nell‚Äôintervallo [0, 1], che corrisponde alla gamma dei possibili valori per la proporzione \\(\\theta\\).\nPer esempio, consideriamo la distribuzione Beta(2, 2), caratterizzata da una simmetria nella sua forma. Per valutare la distribuzione Beta in corrispondenza di punti specifici, come ad esempio 0.5, 0.8 e 1.2, possiamo fare affidamento sulla funzione beta.pdf. A titolo illustrativo, la densit√† di probabilit√† della distribuzione Beta(2, 2) nel caso del valore 0.5 risulta essere 1.5, suggerendo che i valori di \\(\\theta\\) vicini a 0.5 appaiono pi√π plausibili rispetto a quelli intorno a 0.8, dove la funzione assume un valore di 0.96. √à importante sottolineare che la densit√† di probabilit√† della distribuzione Beta(2, 2) relativa al valore 1.2 √® pari a 0, poich√© tale valore esula dall‚Äôintervallo di definizione della distribuzione (0 e 1). La distribuzione Beta(2, 2) √® illustrata nella figura qui di seguito.\n\nalpha = 2\nbeta = 2\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nSupponiamo ‚Äì solo allo scopo di illustrare la procedura ‚Äì che le nostre credenze a priori siano rappresentate da una Beta(2, 5).\n\nalpha = 2\nbeta = 5\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nNel seguente esempio, useremo la funzione beta.pdf() per generare una distribuzione a priori discretizzata.\n\nprint(stats.beta.pdf(theta, 2, 5))\n\n[0.     1.9683 2.4576 2.1609 1.5552 0.9375 0.4608 0.1701 0.0384 0.0027\n 0.    ]\n\n\n\n_ = plt.plot(theta, stats.beta.pdf(theta, 2, 5))\n\n\n\n\n\n\n\n\nOra per√≤ usiamo un numero maggiore di valori \\(\\theta\\).\n\ntheta = np.linspace(0, 1, 1001)\nprint(theta)\n\n[0.    0.001 0.002 ... 0.998 0.999 1.   ]\n\n\nCalcoliamo la distribuzione a priori normalizzata.\n\nprior = stats.beta.pdf(theta, 2, 5) \nprior = prior / np.sum(prior)\nprint(prior)\n\n[0.00000000e+00 2.98802546e-05 5.95215869e-05 ... 4.79041198e-13\n 2.99700749e-14 0.00000000e+00]\n\n\n\nsum(prior)\n\n1.0000000000000002\n\n\nPer calcolare la verosimiglianza, seguiamo la medesima procedura illustrata nel capitolo {ref}cap-likelihood. In aggiunta, effettuiamo la normalizzazione dei valori discretizzati della verosimiglianza, come precedentemente descritto.\n\nlk = stats.binom.pmf(6, 9, theta)\nlk = lk / np.sum(lk)\nprint(lk)\n\n[0.00000000e+00 8.37482519e-19 5.34380847e-17 ... 6.63976213e-09\n 8.34972583e-10 0.00000000e+00]\n\n\nInfine, otteniamo la distribuzione a posteriori moltiplicando la distribuzione a priori per la verosimiglianza e dividendo per la costante di normalizzazione.\n\npost = (prior * lk) / np.sum(prior * lk)\n\n\nnp.sum(post)\n\n1.0\n\n\n\nplt.plot(theta, prior, linestyle=\"solid\", color=\"C0\", label=\"Prior\")\nplt.plot(theta, lk, linestyle=\"solid\", color=\"C2\", label=\"Likelihood\")\nplt.plot(theta, post, linestyle=\"solid\", color=\"C3\", label=\"Posterior\")\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nPossiamo calcolare la media e la deviazione standard della distribuzione a posteriori come abbiamo fatto in precedenza.\n\n# media\nnp.sum(theta * post)\n\n0.5000000000000001\n\n\n\n# deviazione standard\nnp.sqrt(np.sum(theta**2 * post) - (np.sum(theta * post)) ** 2)\n\n0.12126781251816628",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori",
    "text": "30.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori\nUna volta ottenuta la distribuzione a posteriori, √® possibile generare un campione casuale da questa distribuzione. A titolo di esempio, possiamo estrarre un campione di 10000 punti dalla distribuzione a posteriori di \\(\\theta\\) che abbiamo calcolato.\n\nsamples = np.random.choice(theta, p=post, size=int(1e4), replace=True)\n\nL‚Äôistruzione precedente genera un array denominato samples contenente 10000 punti campionati dalla distribuzione a posteriori calcolata. La funzione np.random.choice viene impiegata per selezionare casualmente i valori theta basandosi sulle probabilit√† definite da post.\n\n# First subplot: Scatter plot\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\nplt.plot(samples, 'o', alpha=0.1)\nplt.xlabel(\"sample number\")\nplt.ylabel(r\"$\\theta$\")\n\n# Second subplot: KDE plot\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\naz.plot_kde(samples)\nplt.xlabel(r\"$\\theta$\")\n_ = plt.ylabel(\"density\")\n\n\n\n\n\n\n\n\nSfruttando il campione estratto dalla distribuzione a posteriori, √® possibile calcolare diverse quantit√† di interesse. Ad esempio, la stima della media a posteriori di \\(\\theta\\) si ottiene semplicemente calcolando la media dei valori cos√¨ ottenuti.\n\nnp.mean(samples)\n\n0.499356\n\n\nIn maniera analoga possiamo calcolare la deviazione standard della distribuzione a posteriori di \\(\\theta\\).\n\nnp.std(samples)\n\n0.1199298022344738\n\n\nLa moda a posteriori si pu√≤ calcolare nel modo seguente.\n\nprint(theta[post == max(post)])\n\n[0.5]\n\n\nOppure, usando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo\n\nstats.mode(samples)[0]\n\n0.507\n\n\nUsando il campione estratto dalla distribuzione a posteriori, √® immediato trovare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(samples)\n\n0.5\n\n\nPossiamo calcolare la probabilit√† di varie ipotesi relative a \\(\\theta\\) nella distribuzione a posteriori. Per esempio, calcoliamo la probabilit√† \\(P(\\theta &lt; 0.5)\\).\n\nsum(post[theta &lt; 0.5])\n\n0.49842895507812507\n\n\nAlternativamente, utilizzando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo un risultato analogo, sebbene soggetto a variazioni dovute all‚Äôapprossimazione numerica.\n\nsum(samples &lt; 0.5) / 1e4\n\n0.4996\n\n\nPossiamo trovare la probabilit√† a posteriori che \\(\\theta\\) sia compresa in un dato intervallo. Per esempio, troviamo \\(P(0.5 &lt; \\theta &lt; 0.75)\\).\n\nsum((samples &gt; 0.6) & (samples &lt; 0.8)) / 1e4\n\n0.2073\n\n\nUtilizzando il campionamento effettuato dalla distribuzione a posteriori di \\(\\theta\\), √® possibile risolvere il problema inverso, ovvero determinare l‚Äôintervallo che contiene \\(\\theta\\) con una specifica probabilit√†. Ad esempio, si pu√≤ calcolare l‚Äôintervallo che ha una probabilit√† pari a 0.94 di contenere \\(\\theta\\), basandosi sulla distribuzione a posteriori campionata.\n\nnp.percentile(samples, [2, 98])\n\narray([0.261, 0.741])\n\n\nL‚Äôintervallo specificato √® noto come intervallo di credibilit√† e rappresenta una quantificazione statistica dell‚Äôincertezza associata alla stima del parametro \\(\\theta\\). In termini probabilistici, si pu√≤ affermare con il 94% di credibilit√† che il valore ‚Äúvero‚Äù di \\(\\theta\\) √® contenuto nell‚Äôintervallo [0.26, 0.74].\nSe vogliamo trovare l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPD), usiamo la funzione ArviZ hdi() (si veda il capitolo {ref}sintesi-distr-post-notebook).\n\naz.hdi(samples, hdi_prob=0.94)\n\narray([0.278, 0.721])\n\n\nNel contesto attuale, la distribuzione a posteriori √® simmetrica. Di conseguenza, l‚Äôintervallo di credibilit√† calcolato attraverso i quantili e l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPDI) sono molto simili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "href": "chapters/chapter_4/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?",
    "text": "30.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?\nNonostante abbiamo discusso in precedenza dei diversi metodi di stima puntuale e intervallare per riassumere la distribuzione a posteriori di \\(\\theta\\), la migliore stima del parametro che stiamo cercando di inferire √® rappresentata dall‚Äôintera distribuzione a posteriori. Per citare le parole di McElreath (2020):\n\nThat an arbitrary interval contains an arbitrary value is not meaningful. Use the whole distribution.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/chapter_4/02_subj_prop.html#metodo-basato-su-griglia",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.8 Metodo basato su griglia",
    "text": "30.8 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori √® noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l‚Äôapprossimazione della distribuzione a posteriori pu√≤ essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l‚Äôapprossimazione della densit√† a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densit√† a posteriori normalizzata.\n\nQuesto metodo pu√≤ essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all‚Äôaumentare della dimensionalit√† dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l‚Äôapproccio basato sulla griglia √® intuitivo e non richiede competenze di programmazione avanzate per l‚Äôimplementazione. Inoltre, fornisce un risultato che pu√≤ essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilit√† a posteriori condizionata ai dati. Tuttavia, questo metodo √® limitato a causa della maledizione della dimensionalit√†1, il che significa che pu√≤ essere applicato soltanto a modelli statistici semplici con non pi√π di due parametri. Di conseguenza, in pratica, √® spesso sostituito da altre tecniche pi√π efficienti, poich√© i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/02_subj_prop.html#commenti-e-considerazioni-finali",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "30.9 Commenti e Considerazioni Finali",
    "text": "30.9 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato l‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l‚Äôelaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell‚Äôinferenza relativa alle proporzioni, dove la distribuzione a priori √® modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, √® possibile derivare analiticamente la distribuzione a posteriori. L‚Äôanalisi dettagliata di questo caso sar√† trattata nel capitolo successivo.\nL‚Äôaspetto fondamentale della discussione presente risiede nell‚Äôapproccio adottato per affrontare una specifica questione di ricerca, ossia la quantificazione dell‚Äôincertezza relativa alla proporzione di presenza di ideazione suicidaria nella popolazione considerata. Abbiamo illustrato come sia possibile mettere in pratica alcuni dei passaggi del flusso di lavoro bayesiano proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nComtois, Katherine Anne, Karin E Hendricks, Christopher R DeCou, Samantha A Chalker, Amanda H Kerbrat, Jennifer Crumlish, Tierney K Huppert, e David Jobes. 2023. ¬´Reducing short term suicide risk after hospitalization: A randomized controlled trial of the Collaborative Assessment and Management of Suicidality¬ª. Journal of affective disorders 320: 656‚Äì66.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/02_subj_prop.html#footnotes",
    "href": "chapters/chapter_4/02_subj_prop.html#footnotes",
    "title": "30¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalit√†, possiamo considerare l‚Äôesempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). √à evidente che la quantit√† di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, √® necessario utilizzare un approccio diverso.‚Ü©Ô∏é",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html",
    "href": "chapters/chapter_4/10_metropolis.html",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "",
    "text": "Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana relativi alla distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche discusso l‚Äôutilizzo di approcci come l‚Äôapprossimazione tramite griglia e i metodi dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione e spiegheremo perch√© sono necessari approcci speciali noti come metodi di Monte Carlo a Catena di Markov (MCMC).",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/chapter_4/10_metropolis.html#il-denominatore-bayesiano",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.1 Il denominatore bayesiano",
    "text": "31.1 Il denominatore bayesiano\nNell‚Äôapproccio bayesiano, il nostro obiettivo principale √® determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando sia i dati osservati $ y $ che la distribuzione a priori \\(p(\\theta)\\). Questo processo si basa sul teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIn questa formula, il denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta l‚Äôintegrazione (o la somma, nel caso di variabili discrete) su tutti i possibili valori di \\(\\theta\\), fornendo cos√¨ la probabilit√† marginale di \\(y\\). Questo assicura che $ p(y) $ sia una distribuzione di probabilit√† valida che si integra (o si somma) a 1.\nTuttavia, spesso incontriamo una sfida significativa: il calcolo dell‚Äôevidenza \\(p(y) = \\int p(y \\mid \\theta) p(\\theta) d\\theta\\) pu√≤ essere estremamente complesso, specialmente per modelli pi√π articolati, rendendo difficile ottenere con precisione la distribuzione a posteriori.\nUna soluzione possibile √® rappresentata dalle distribuzioni a priori coniugate, che offrono un metodo analitico per determinare la distribuzione a posteriori. Tuttavia, questo limita la selezione delle distribuzioni a priori e di verosimiglianza.\nUn metodo per superare questa limitazione √® ricorrere a soluzioni numeriche, ma i metodi di campionamento a griglia sono applicabili solo nel caso di modelli con un numero di parametri molto piccolo.\nLa soluzione generale √® utilizzare i Metodi di Monte Carlo a Catena di Markov (MCMC). Questi metodi consentono di derivare la distribuzione a posteriori basandosi su presupposti teorici e senza restrizioni nella scelta delle distribuzioni. L‚Äôapproccio Monte Carlo si basa sulla generazione di sequenze di numeri casuali per creare un ampio campione di osservazioni dalla distribuzione a posteriori. Da questi campioni, possiamo poi stimare empiricamente le propriet√† di interesse. Questo approccio richiede l‚Äôuso di metodi computazionalmente intensivi e, con la crescente potenza di calcolo dei computer moderni, tali metodi stanno diventando sempre pi√π accessibili e popolari nell‚Äôanalisi dei dati.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#il-metodo-di-monte-carlo",
    "href": "chapters/chapter_4/10_metropolis.html#il-metodo-di-monte-carlo",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.2 Il Metodo di Monte Carlo",
    "text": "31.2 Il Metodo di Monte Carlo\nNei capitoli precedenti abbiamo gi√† esplorato l‚Äôefficacia della simulazione nel campo della teoria delle probabilit√†. Un esempio classico √® il problema di Monty Hall, che mostra come la simulazione ripetuta possa fornire stime affidabili per la media e la varianza di variabili casuali. Inoltre, applicando la legge dei grandi numeri, queste stime diventano pi√π accurate all‚Äôaumentare del numero di simulazioni. Ci√≤ evidenzia la potenza dei metodi Monte Carlo, che evitano la necessit√† di calcolare integrali complessi.\nIl Metodo di Monte Carlo, sviluppato durante il Progetto Manhattan negli anni ‚Äô40, utilizza numeri casuali per risolvere problemi matematici complessi. Originariamente ideato da Stanislaw Ulam e successivamente implementato da John von Neumann, il metodo prende il nome dallo zio giocatore d‚Äôazzardo di Ulam, come suggerito da Nicholas Metropolis. Da allora, questo metodo √® diventato una tecnica fondamentale in diverse discipline, contribuendo significativamente alla risoluzione di problemi complessi.\nLa metodologia di Monte Carlo genera un‚Äôampia serie di punti casuali per stimare quantit√† di interesse, come l‚Äôintegrazione numerica. Un esempio classico √® l‚Äôapprossimazione dell‚Äôintegrale di un cerchio in 2D, dove il rapporto tra il numero di punti che cadono all‚Äôinterno del cerchio e tutti i campioni fornisce un‚Äôapprossimazione dell‚Äôarea (per un esempio numerico, si veda Appendice L).\nPer illustrare ulteriormente questo concetto, consideriamo ora una distribuzione continua \\(p(\\theta \\mid y)\\) con una media \\(\\mu\\). Se siamo in grado di generare una sequenza di campioni casuali \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) indipendenti e identicamente distribuiti secondo \\(p(\\theta \\mid y)\\), possiamo stimare il valore atteso teorico di \\(\\theta\\) utilizzando la media campionaria \\(\\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}\\). Questa approssimazione diventa sempre pi√π accurata man mano che aumenta il numero di campioni \\(T\\), grazie alla Legge Forte dei Grandi Numeri.\nUn altro vantaggio del Metodo di Monte Carlo √® la sua capacit√† di approssimare la probabilit√† che una variabile casuale \\(\\theta\\) cada all‚Äôinterno di un intervallo specifico \\((l, u)\\). Questo pu√≤ essere ottenuto calcolando la media campionaria della funzione indicatrice \\(I(l &lt; \\theta &lt; u)\\) per ogni realizzazione \\(\\theta^{(t)}\\), cio√® \\(Pr(l &lt; \\theta &lt; u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\in (l, u)}{T}\\).\nNonostante la loro efficacia, un limite dei metodi Monte Carlo tradizionali risiede nella generazione efficiente di un elevato numero di campioni \\(X_1, X_2, \\ldots, X_n\\). In risposta a questa sfida, i metodi di Monte Carlo basati su catene di Markov (MCMC) offrono una soluzione potente per simulare da distribuzioni complesse attraverso catene di Markov. L‚Äôevoluzione di questi algoritmi ha trasformato radicalmente la statistica e il calcolo scientifico, permettendo la simulazione da una vasta gamma di distribuzioni, anche in spazi di alta dimensionalit√†.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#le-catene-di-markov",
    "href": "chapters/chapter_4/10_metropolis.html#le-catene-di-markov",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.3 Le Catene di Markov",
    "text": "31.3 Le Catene di Markov\nLe catene di Markov, ideate da Andrey Markov nel 1906, rappresentano un tentativo di estendere la legge dei grandi numeri a contesti in cui le variabili casuali non sono indipendenti. Tradizionalmente, la statistica si concentra su sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), simboleggiate come \\(X_0, X_1, \\ldots, X_n, \\ldots\\). In tali sequenze, ogni variabile √® indipendente dalle altre e segue la stessa distribuzione, con \\(n\\) che rappresenta un indice temporale discreto. Tuttavia, questa assunzione di indipendenza non √® sempre realistica nei modelli di fenomeni complessi, portando alla necessit√† di esplorare forme alternative di dipendenza tra variabili.\nPer superare le limitazioni dell‚Äôindipendenza, le catene di Markov introducono una cosiddetta ‚Äúdipendenza a un passo‚Äù, incarnata nella ‚Äúpropriet√† di Markov‚Äù. Questa propriet√† stabilisce che la previsione di un evento futuro \\(X_{n+1}\\) dipende unicamente dall‚Äôevento immediatamente precedente \\(X_n\\), indipendentemente dagli eventi passati \\(X_0, X_1, X_2, \\ldots, X_{n-1}\\). La propriet√† di Markov √® espressa matematicamente come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta propriet√† afferma che la previsione di un evento futuro dipende solo dall‚Äôevento immediatamente precedente, semplificando i calcoli relativi alle probabilit√† condizionali.\nLe catene di Markov rappresentano un framework fondamentale per la modellazione delle dipendenze tra variabili casuali, una nozione cruciale in numerosi campi della statistica e della scienza dei dati, inclusa la metodologia MCMC (Markov Chain Monte Carlo). In particolare, nell‚Äôambito dell‚Äôanalisi bayesiana, l‚Äôuso di MCMC si rivela di estrema importanza, soprattutto quando non √® possibile calcolare in modo analitico la distribuzione a posteriori.\nL‚Äôalgoritmo di Metropolis rappresenta una delle implementazioni pi√π semplici del metodo MCMC. Questo algoritmo sfrutta la natura dipendente delle catene di Markov per navigare in modo efficace attraverso lo spazio della distribuzione a posteriori. Questo aspetto rende il MCMC uno strumento di grande potenza per affrontare problemi complessi in cui i metodi analitici tradizionali non possono essere applicati (per ulteriori dettagli, si veda Appendice L). In breve, il MCMC consente di generare un vasto insieme di valori per il parametro \\(\\theta\\). Idealmente, questi valori riflettono la distribuzione a posteriori \\(p(\\theta \\mid y)\\) quando questa non pu√≤ essere ottenuta direttamente. Questa caratteristica rende il MCMC uno strumento essenziale per risolvere problemi complessi in cui i metodi analitici convenzionali non sono applicabili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/10_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.4 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "31.4 Estrazione di campioni dalla distribuzione a posteriori\nNella discussione seguente ci porremo l‚Äôobiettivo di comprendere come utilizzare l‚Äôalgoritmo di Metropolis per approssimare la distribuzione a posteriori \\(p(\\theta \\mid y)\\). A questo fine, il capitolo √® strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o ‚Äúa posteriori,‚Äù sia gi√† conosciuta o disponibile per l‚Äôanalisi.\nIn seguito, passeremo a illustrare come l‚Äôalgoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non √® direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un‚Äôapprossimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse √® focalizzato sulla determinazione della probabilit√† che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilit√† sar√† indicata come \\(\\pi\\). Iniziamo importando i dati.\n\nmoma_sample = pd.read_csv(\"../../data/moma_sample.csv\")\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample.head()\n\n\n\n\n\n\n\n\n\nartist\ncountry\nbirth\ndeath\nalive\ngenx\ngender\ncount\nyear_acquired_min\nyear_acquired_max\n\n\n\n\n0\nAd Gerritsen\ndutch\n1940\n2015.0\nFalse\nFalse\nmale\n1\n1981\n1981\n\n\n1\nKirstine Roepstorff\ndanish\n1972\nNaN\nTrue\nTrue\nfemale\n3\n2005\n2005\n\n\n2\nLisa Baumgardner\namerican\n1958\n2015.0\nFalse\nFalse\nfemale\n2\n2016\n2016\n\n\n3\nDavid Bates\namerican\n1952\nNaN\nTrue\nFalse\nmale\n1\n2001\n2001\n\n\n4\nSimon Levy\namerican\n1946\nNaN\nTrue\nFalse\nmale\n1\n2012\n2012\n\n\n\n\n\n\n\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\nresult = moma_sample[\"genx\"].value_counts()\nprint(result)\n\ngenx\nFalse    86\nTrue     14\nName: count, dtype: int64\n\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che √® stato osservato. Tuttavia, poich√© il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilit√† di appartenere alla generazione X o a una generazione successiva) all‚Äôinterno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l‚Äôesito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le propriet√† delle distribuzioni coniugate, possiamo calcolare la distribuzione a posteriori esatta:\nY ~ Binomiale(100, œÄ)\nŒ∏ = Beta(4, 6)\nŒ∏ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) ‚Üí Beta(18, 92)\nNella figura successiva √® rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori scelta.\n\nx = np.linspace(0, 1, 1000)\n\nprior_density = stats.beta.pdf(x, 4, 6)\nposterior_density = stats.beta.pdf(x, 18, 92)\n\nplt.fill_between(x, prior_density, alpha=0.5, label=\"Prior: Beta(4, 6)\")\nplt.fill_between(x, posterior_density, alpha=0.5, label=\"Posterior: Beta(18, 92)\")\nplt.xlabel(\"Parameter Value\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.title(\"Prior and Posterior Densities\")\nplt.show()\n\n\n\n\n\n\n\n\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto √®\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n31.4.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un‚Äôapprossimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con poche osservazioni (ad esempio, 10), possiamo procedere con la seguente simulazione:\n\ny = stats.beta(18, 92).rvs(10)\nprint(y)\n\n[0.18694021 0.12067309 0.17576971 0.1608302  0.12912987 0.20527983\n 0.14209658 0.15057358 0.12001648 0.13024873]\n\n\n\nnp.mean(y)\n\n0.1521558285153169\n\n\nTuttavia, con solo 10 campioni l‚Äôapprossimazione potrebbe non essere molto accurata. Pi√π aumentiamo il numero di campioni (cio√® il numero di osservazioni casuali generate), pi√π precisa sar√† l‚Äôapprossimazione. Aumentando il numero di campioni, ad esempio a 10000, otteniamo un risultato pi√π preciso:\n\nstats.beta(18, 92).rvs(10000).mean()\n\n0.16380917953899665\n\n\nQuando il numero di campioni a posteriori diventa molto grande, la distribuzione campionaria converge alla densit√† della popolazione. Questo concetto si applica non solo alla media, ma anche ad altre statistiche descrittive, come la moda e la varianza.\n√à importante sottolineare che l‚Äôapplicazione della simulazione di Monte Carlo √® efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ci√≤ √® stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poich√© le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l‚Äôespressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l‚Äôutilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, per√≤, √® possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l‚Äôuso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l‚Äôalgoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#algoritmo-di-metropolis",
    "href": "chapters/chapter_4/10_metropolis.html#algoritmo-di-metropolis",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.5 Algoritmo di Metropolis",
    "text": "31.5 Algoritmo di Metropolis\nL‚Äôalgoritmo di Metropolis √® un metodo avanzato per il campionamento da distribuzioni probabilistiche complesse. Appartiene alla famiglia dei metodi Monte Carlo Markov Chain (MCMC) e combina strategie di campionamento Monte Carlo con catene di Markov per navigare nello spazio dei parametri in modo intelligente. Questo consente di ottenere campioni rappresentativi della distribuzione di interesse indipendentemente dal punto di partenza, riducendo il rischio di bias nei risultati.\n\n31.5.1 Passaggi Fondamentali dell‚ÄôAlgoritmo di Metropolis\n\nScegli un valore iniziale \\(\\theta_1\\). Imposta \\(t = 1\\).\nCampiona un possibile nuovo valore \\(\\theta_p\\) basato su una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\). Di solito, si usa una distribuzione normale \\(N(\\theta_t, \\tau)\\) come distribuzione di proposta, dove \\(\\tau\\) funge da parametro di regolazione che controlla la dimensione del passo.\nCalcola il rapporto \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\).\nSe \\(\\alpha \\geq 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\).\nSe \\(\\alpha &lt; 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\) con probabilit√† \\(\\alpha\\). Altrimenti, imposta \\(\\theta_{t+1} = \\theta_t\\).\nRipeti dal passo 2 per campionare un nuovo valore \\(\\theta_p\\).\n\n\n\n31.5.2 Dettagli dell‚ÄôAlgoritmo\n\nDistribuzione di Proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) √® usata per generare nuovi campioni di \\(\\theta_p\\) basati sul valore corrente \\(\\theta_t\\). Una scelta comune √® la distribuzione normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) √® un parametro di tuning che controlla la dimensione dei passi del campionamento. Un valore di \\(\\tau\\) troppo grande o troppo piccolo pu√≤ influenzare negativamente l‚Äôefficienza del campionamento.\nCalcolo del Rapporto \\(\\alpha\\): Il rapporto \\(\\alpha\\) √® dato dalla probabilit√† a posteriori del nuovo valore \\(\\theta_p\\) rispetto alla probabilit√† a posteriori del valore corrente \\(\\theta_t\\). Questo rapporto determina l‚Äôaccettazione o il rifiuto del nuovo campione.\nDecisione di Accettazione:\n\nSe \\(\\alpha \\geq 1\\), il nuovo valore \\(\\theta_p\\) √® sempre accettato.\nSe \\(\\alpha &lt; 1\\), il nuovo valore \\(\\theta_p\\) √® accettato con probabilit√† \\(\\alpha\\). Se non viene accettato, il valore corrente \\(\\theta_t\\) √® mantenuto per il prossimo passo.\n\n\nQuesto processo permette di esplorare lo spazio dei parametri \\(\\theta\\) generando una catena di Markov che, nel tempo, converge verso la distribuzione a posteriori \\(p(\\theta \\mid y)\\). Utilizzando questa catena, possiamo stimare empiricamente le propriet√† della distribuzione a posteriori.\nLa procedura continua con l‚Äôiterazione dei passi dal 2 al 5, permettendo alla catena di campioni di convergere alla distribuzione target. Inizialmente, i campioni potrebbero non essere rappresentativi, ma dopo un sufficiente numero di iterazioni (il cosiddetto ‚Äúburn-in‚Äù), la distribuzione dei punti accettati dovrebbe avvicinarsi a quella che si intende esplorare.\nL‚Äôefficienza di questo algoritmo deriva dalla sua abilit√† nel mantenere un equilibrio tra l‚Äôesplorazione di nuove possibilit√† e l‚Äôutilizzo di quelle gi√† note. Questo viene realizzato attraverso l‚Äôadozione di un meccanismo che accetta i punti suggeriti in modo probabilistico, facilitando cos√¨ la raccolta di un campione che riflette accuratamente la distribuzione di probabilit√† complessa sotto indagine.\nPer una visualizzazione del comportamento dell‚Äôalgoritmo di Metropolis nell‚Äôesplorare lo spazio dei parametri, si pu√≤ consultare questo post. La distinzione tra i diversi metodi MCMC si basa principalmente sul tipo di distribuzione proposta e sul criterio di accettazione dei punti nel campionamento.\n\n\n31.5.3 Implementazione dell‚ÄôAlgoritmo di Metropolis\nIniziamo col definire la distribuzione a priori. In questo esempio, la distribuzione a priori √® una distribuzione Beta(4, 6).\n\ndef prior(p):\n    alpha = 4\n    beta = 6\n    return stats.beta.pdf(p, alpha, beta)\n\nDefiniamo la verosimiglianza. Il problema presente richiede una verosimiglianza binomiale.\n\ndef likelihood(p):\n    y = 14\n    n = 100\n    return stats.binom.pmf(y, n, p)\n\nLa distribuzione a posteriori non normalizzata √® il prodotto della distribuzione a priori e della verosimiglianza. Si noti che, per il motivo spiegato prima, non √® necessario normalizzare la distribuzione a posteriori.\n\ndef posterior(p):\n    return likelihood(p) * prior(p)\n\nNell‚Äôimplementazione di un algoritmo di Metropolis in ambito bayesiano, vi sono diversi aspetti da considerare attentamente. Ecco alcuni punti cruciali:\n\nSimmetria della Distribuzione Proposta: √à fondamentale che la distribuzione proposta sia simmetrica. Questa √® una condizione necessaria per il funzionamento dell‚Äôalgoritmo di Metropolis, ma non per quello di Metropolis-Hastings.\nValore Iniziale: Il valore iniziale scelto dovrebbe essere plausibile in base alla distribuzione a priori, in modo da facilitare la convergenza dell‚Äôalgoritmo.\nProbabilit√† Zero: Nel caso in cui la verosimiglianza o il prior assumano un valore di zero, il rapporto tra le densit√† di probabilit√† (pdfratio) all‚Äôinterno dell‚Äôalgoritmo di Metropolis risulter√† indefinito. Pertanto, √® importante garantire che il valore x_star, generato dalla distribuzione proposta, cada sempre entro i limiti del supporto sia del prior che della verosimiglianza.\n\nDi seguito √® presentato il codice dell‚Äôalgoritmo di Metropolis.\n\n# Definizione della funzione dell'algoritmo di Metropolis.\n# nsamp: Numero di campioni da generare.\n# xinit: Valore iniziale da cui iniziare il sampling.\ndef metropolis(nsamp, xinit):\n    # Inizializza un array vuoto per conservare i campioni generati.\n    samples = np.empty(nsamp)\n\n    # Imposta il primo valore (valore iniziale) da cui partire per la generazione dei campioni.\n    x_prev = xinit\n\n    # Inizia un ciclo che si ripeter√† per il numero di volte specificato da nsamp (numero di campioni da generare).\n    for i in range(nsamp):\n        # Genera un nuovo punto (x_star) usando una distribuzione normale (gaussiana).\n        # Questo nuovo punto √® generato in modo da essere \"vicino\" al punto precedente (x_prev),\n        # con una deviazione standard di 0.1. Questo significa che la maggior parte dei punti\n        # sar√† entro 0.1 unit√† da x_prev, ma alcuni potrebbero essere pi√π lontani.\n        x_star = np.random.normal(x_prev, 0.1)\n\n        # Verifica che il nuovo punto (x_star) sia un valore plausibile nel contesto del problema.\n        # Qui, l'assunzione √® che x_star debba essere tra 0 e 1. Se non lo √®, il punto √® rifiutato.\n        if 0 &lt;= x_star &lt;= 1:\n            # Calcola il valore della funzione di densit√† di probabilit√† posterior per il nuovo punto e il punto precedente.\n            # La funzione posterior √® definita altrove e rappresenta il prodotto del prior e della likelihood.\n            p_star = posterior(x_star)\n            p_prev = posterior(x_prev)\n\n            # Calcola il rapporto tra le densit√† posterior del nuovo punto e del punto precedente.\n            # Questo rapporto determina la probabilit√† di accettare il nuovo punto.\n            # Se p_prev √® 0, per evitare la divisione per zero, il rapporto √® impostato a 1.\n            pdfratio = p_star / p_prev if p_prev &gt; 0 else 1\n\n            # Genera un numero casuale tra 0 e 1.\n            random_chance = np.random.uniform()\n\n            # Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n            # Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n            # Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\n            acceptance_probability = min(1, pdfratio)\n\n            # Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n            # Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n            # mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\n            if random_chance &lt; acceptance_probability:\n                samples[i] = x_star  # Accetta il nuovo punto.\n                x_prev = (\n                    x_star  # Aggiorna il punto precedente con il nuovo punto accettato.\n                )\n            else:\n                samples[i] = (\n                    x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\n                )\n        else:\n            samples[i] = (\n                x_prev  # Se x_star non √® nel supporto, conserva il punto precedente.\n            )\n\n    # Dopo aver generato il numero desiderato di campioni, ritorna l'array dei campioni.\n    return samples\n\nL‚Äôidea fondamentale dietro la fase dell‚Äôalgoritmo di Metropolis successiva al calcolo di p_star e p_prev √® decidere se ‚Äúmuoversi‚Äù verso un nuovo punto basandosi su quanto √® probabile (o ‚Äúbuono‚Äù) quel punto rispetto al punto attuale, in termini della densit√† posteriore. Qui, la ‚Äúprobabilit√†‚Äù di un punto √® data dalla sua densit√† posteriore, che √® un modo per misurare quanto bene un certo valore del parametro si adatta ai dati osservati, dato un modello.\nEcco come funziona:\n\nGenerazione di un numero casuale.\nConfronto tra i punti: Si confronta il ‚Äúvalore‚Äù del nuovo punto (x_star) con quello del punto precedente (x_prev). Questo ‚Äúvalore‚Äù √® dato dalla densit√† posteriore: pi√π alto √®, meglio √®.\nDecisione:\n\nSe il nuovo punto √® migliore del precedente (ovvero, ha una densit√† posteriore maggiore o uguale), lo accettiamo sempre.\nSe il nuovo punto √® peggiore del precedente (ha una densit√† posteriore minore), non lo rifiutiamo subito. Invece, gli diamo una chance di essere scelto, ma questa chance √® pi√π piccola quanto pi√π il nuovo punto √® ‚Äúpeggiore‚Äù.\n\n\nIn termini di codice, questa logica si traduce cos√¨:\n# Genera un numero casuale tra 0 e 1.\nrandom_chance = np.random.uniform()\n\n# Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n# Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n# Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\nacceptance_probability = min(1, pdfratio)\n\n# Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n# Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n# mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\nif random_chance &lt; acceptance_probability:\n    samples[i] = x_star  # Accetta il nuovo punto.\n    x_prev = x_star      # Aggiorna il punto precedente con il nuovo punto accettato.\nelse:\n    samples[i] = x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\nIn sintesi, questo meccanismo consente all‚Äôalgoritmo di esplorare lo spazio dei parametri in modo efficiente, accettando sempre miglioramenti e, occasionalmente, facendo passi in direzioni non ottimali per evitare di rimanere intrappolati in ‚Äúminimi locali‚Äù, ovvero in soluzioni che sembrano buone rispetto a quelle vicine ma non sono le migliori globalmente.\nSi osservi un punto importante: nel calcolo di pdfratio, il rapporto tra la densit√† a posteriori del parametro proposto x_star e quella del parametro corrente x_prev, la costante di normalizzazione si annulla grazie alla regola di Bayes. Questo lascia nel rapporto solamente le componenti relative alla verosimiglianza e alla distribuzione a priori, che sono entrambe facilmente calcolabili. Matematicamente, questo si esprime come:\n\\[\n\\begin{equation}\n\\text{pdfratio} = \\frac{p(\\theta^* \\mid y)}{p(\\theta^{\\text{prev}} \\mid y)} = \\frac{\\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y)}}{\\frac{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}{p(y)}}\n= \\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}\n\\end{equation}\n\\] (eq-ratio-metropolis)\nEseguiamo dunque il campionamento usando l‚Äôalgoritmo che abbiamo definito.\n\nn_samples = 100_000\nsamps = metropolis(n_samples, 0.5)\n\nIn somma, l‚Äôalgoritmo Metropolis accetta come input il numero nsamp di passi da simulare e il punto di partenza. Come output, l‚Äôalgoritmo restituisce una catena di valori del parametro, specificamente la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{\\text{nsamp}}\\). Uno degli aspetti cruciali per la riuscita dell‚Äôalgoritmo √® il raggiungimento della stazionariet√† da parte della catena. In genere, i primi 1000-5000 valori vengono scartati in quanto rappresentano il periodo di ‚Äúburn-in‚Äù della catena. Dopo un determinato numero di passi \\(k\\), la catena converge e i valori diventano campioni effettivi dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nIl modello descritto √® stato inizialmente proposto da Metropolis et al.¬†nel 1953 (Metropolis et al. 1953). Hastings nel 1970 introdusse un‚Äôestensione nota come algoritmo Metropolis-Hastings (Hastings 1970). Altre varianti includono il campionatore di Gibbs, introdotto da Geman e Geman nel 1984 (Geman e Geman 1984), l‚ÄôHamiltonian Monte Carlo (Duane et al. 1987), e il No-U-Turn Sampler (NUTS) utilizzato in pacchetti come PyMC e Stan (Hoffman, Gelman, et al. 2014). Per un‚Äôanalisi pi√π dettagliata e intuitiva dell‚Äôalgoritmo Metropolis, si rimanda a Kruschke (2014).\nUn elemento chiave da considerare nell‚Äôuso dell‚Äôalgoritmo Metropolis √® il tasso di accettazione, che √® il rapporto tra il numero di valori del parametro proposti e il numero di quei valori che vengono effettivamente accettati. Un limite di questo algoritmo √® la sua inefficienza relativa: rispetto alle sue varianti pi√π moderne, l‚Äôalgoritmo Metropolis tende ad essere meno efficiente.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#aspetti-computazionali",
    "href": "chapters/chapter_4/10_metropolis.html#aspetti-computazionali",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.6 Aspetti computazionali",
    "text": "31.6 Aspetti computazionali\n\n31.6.1 Warm-up/Burn-in\nUna catena di Markov ha bisogno di alcune iterazioni per raggiungere la distribuzione stazionaria. Queste iterazioni sono comunemente chiamate iterazioni di warm-up o burn-in (a seconda dell‚Äôalgoritmo e del software utilizzato) e vengono di solito scartate. In molti programmi software, la prima met√† delle iterazioni viene considerata come iterazioni di warm-up, quindi, nel caso presente, anche se abbiamo ottenuto 100000 iterazioni, ne utilizzeremo solo 50000.\n\n\n31.6.2 Sintesi della distribuzione a posteriori\nL‚Äôarray samps contiene 100000 valori di una catena di Markov. Escludiamo i primi 50000 valori considerati come burn-in e consideriamo i restanti 50000 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nMediante i valori della catena cos√¨ ottenuta √® facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, possiamo trovare la stima della media a posteriori.\n\nburnin = int(n_samples * 0.5)\nburnin\n\n50000\n\n\n\nnp.mean(samps[burnin:])\n\n0.16408968344081415\n\n\nOppure possiamo stimare la deviazione standard della distribuzione a posteriori.\n\nnp.std(samps[burnin:])\n\n0.03513787973422409\n\n\nVisualizziamo un trace plot dei valori della catena di Markov dopo il periodo di burn-in.\n\nplt.plot(samps[burnin:])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nIl trace plot indica che la catena inizia con un valore casuale per poi spostarsi rapidamente nell‚Äôarea intorno a 0.16, che √® l‚Äôarea con alta densit√† a posteriori. Successivamente, oscilla intorno a quel valore per le iterazioni successive.\n\nplt.plot(samps[:500])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nL‚Äôistogramma mostrato di seguito, sul quale √® stata sovrapposta la distribuzione a posteriori derivata analiticamente ‚Äì specificamente una \\(\\text{Beta}(25, 17)\\) ‚Äì dimostra che la catena converge effettivamente alla distribuzione a posteriori desiderata.\n\nplt.hist(samps[burnin:], bins=30, alpha=0.4, label=\"MCMC distribution\", density=True)\n# plot the true function\nx = np.linspace(0, 1, 1000)\nplt.plot(x, stats.beta.pdf(x, 18, 92), \"C0\", label=\"True distribution\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n√à possibile usare la funzione summary del pacchetto AriviZ per calolare l‚Äôintervallo di credibilit√†, ovvero l‚Äôintervallo che contiene la proporzione indicata dei valori estratti a caso dalla distribuzione a posteriori.\n\naz.summary(samps[burnin:], kind=\"stats\", hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nx\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\n\nUn KDE plot corrispondente all‚Äôistogramma precedente si pu√≤ generare usando az.plot_posterior(). La curva rappresenta l‚Äôintera distribuzione a posteriori e viene calcolata utilizzando la stima della densit√† del kernel (KDE) che serve a ‚Äúlisciare‚Äù l‚Äôistogramma.\n\naz.plot_posterior(samps[burnin:])\nplt.show()\n\n\n\n\n\n\n\n\nL‚ÄôHDI √® una scelta comune nelle statistiche bayesiane e valori arrotondati come 50% o 95% sono molto popolari. Ma ArviZ utilizza il 94% come valore predefinito. La ragione di questa scelta √® che il 94% √® vicino al valore ampiamente utilizzato del 95%, ma √® anche diverso da questo, cos√¨ da servire da ‚Äúamichevole promemoria‚Äù che non c‚Äô√® niente di speciale nella soglia del 5%. Idealmente sarebbe opportuno scegliere un valore che si adatti alle specifiche esigenze dell‚Äôanalisi statistica che si sta svolgendo, o almeno riconoscere che si sta usando un valore arbitrario.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/chapter_4/10_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.7 Diagnostiche della soluzione MCMC",
    "text": "31.7 Diagnostiche della soluzione MCMC\n\n31.7.1 Catene multiple\nPoich√© ciascuno stato in una catena di Markov dipende dagli stati precedenti, il valore o i valori iniziali possono influenzare i valori campionati. Una soluzione per verificare la sensibilit√† rispetto ai valori iniziali √® utilizzare pi√π catene, ognuna con diversi valori iniziali. Se pi√π catene campionano la stessa distribuzione target, queste dovrebbero mescolarsi bene, ovvero intersecarsi l‚Äôuna con l‚Äôaltra in un trace plot.\n\n\n31.7.2 Stazionariet√†\nUn punto importante da verificare √® se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta ‚Äúmixing‚Äù.\n\n\n31.7.3 Autocorrelazione\nOgni passo nell‚Äôalgoritmo MCMC √® chiamato iterazione. I valori campionati sono dipendenti, il che significa che il valore all‚Äôiterazione \\(m\\) dipende dal valore all‚Äôiterazione \\(m-1\\). Questa √® una differenza importante rispetto alle funzioni che generano campioni casuali indipendenti, come beta(25, 17).rvs(). I valori campionati formano una catena di Markov, il che significa che ciascun valore campionato √® correlato con il valore precedente (ad esempio, se \\(\\theta(m)\\) √® grande, \\(\\theta(m+1)\\) sar√† anch‚Äôesso grande).\nInformazioni sul ‚Äúmixing‚Äù della catena di Markov sono fornite dall‚Äôautocorrelazione. L‚Äôautocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantit√† \\(k\\) (dove \\(k\\) √® l‚Äôentit√† del ritardo) per verificare quanto si correli al variare di \\(k\\). L‚Äôautocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l‚Äôautocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due ‚Äúpassi‚Äù (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e cos√¨ via.\nL‚Äôautocorrelazione di ordine \\(k\\) √® data da \\(\\rho_k\\) e pu√≤ essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\] (eq-autocor)\nPer fare un esempio pratico, simuliamo dei dati autocorrelati.\n\nx = pd.array([22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51])\nprint(x)\n\n&lt;IntegerArray&gt;\n[22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51]\nLength: 15, dtype: Int64\n\n\nL‚Äôautocorrelazione di ordine 1 √® semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza.\n\nsm.tsa.acf(x)\n\narray([ 1.        ,  0.83174224,  0.65632458,  0.49105012,  0.27863962,\n        0.03102625, -0.16527446, -0.30369928, -0.40095465, -0.45823389,\n       -0.45047733, -0.36933174])\n\n\nNell‚Äôesempio, il vettore x √® una sequenza temporale di 15 elementi. Il vettore \\(x'\\) include gli elementi con gli indici da 0 a 13 nella sequenza originaria, mentre il vettore \\(x''\\) include gli elementi 1:14. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((0, 1)\\), \\((1, 2), (2, 3), \\dots (13, 14)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori \\(x'\\) e \\(x''\\) corrisponde all‚Äôautocorrelazione di ordine 1 della serie temporale.\nNell‚Äôoutput precedente\n\n0.83174224 √® l‚Äôautocorrelazione di ordine 1 (lag = 1),\n0.65632458 √® l‚Äôautocorrelazione di ordine 2 (lag = 2),\n0.49105012 √® l‚Äôautocorrelazione di ordine 3 (lag = 3),\necc.\n\n√à possibile specificare il numero di ritardi (lag) da utilizzare con l‚Äôargomento nlags:\n\nsm.tsa.acf(x, nlags=4)\n\narray([1.        , 0.83174224, 0.65632458, 0.49105012, 0.27863962])\n\n\nIn Python possiamo creare un grafico della funzione di autocorrelazione (correlogramma) per una serie temporale usando la funzione tsaplots.plot_acf() dalla libreria statsmodels.\n\ntsaplots.plot_acf(x, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nPer i dati dell‚Äôesempio in discussione otteniamo la situazione seguente.\n\ntsaplots.plot_acf(samps[burnin:], lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nIl correlogramma √® uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall‚Äôautocorrelazione \\(\\rho_k\\) di una catena di Markov in funzione del ritardo \\(k\\) con cui l‚Äôautocorrelazione √® calcolata: nel grafico ogni barretta verticale riporta il valore dell‚Äôautocorrelazione (sull‚Äôasse delle ordinate) in funzione del ritardo (sull‚Äôasse delle ascisse).\nIn situazioni ottimali l‚Äôautocorrelazione diminuisce rapidamente ed √® effettivamente pari a 0 per piccoli lag. Ci√≤ indica che i valori della catena di Markov che si trovano a pi√π di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del ‚Äúmixing‚Äù della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l‚Äôautocorrelazione √® quella di assottigliare l‚Äôoutput immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning.\nNel seguente correlogramma, analizziamo la medesima catena di Markov. Tuttavia, in questa occasione applichiamo un ‚Äúthinning‚Äù (sottocampionamento) con un fattore di 5.\n\nthin = 5\nsampsthin = samps[burnin::thin]\ntsaplots.plot_acf(sampsthin, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nSi pu√≤ notare come l‚Äôautocorrelazione diminuisce molto pi√π rapidamente.\n\n31.7.3.1 Tasso di accettazione\nQuando si utilizza l‚Äôalgoritmo Metropolis, √® importante monitorare il tasso di accettazione e assicurarsi che sia nell‚Äôintervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegher√† molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D‚Äôaltra parte, se il tasso di accettazione √® molto basso, la catena rimarr√† bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l‚Äôalgoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale √® compreso tra il 40% e il 50%.\n\n\n31.7.3.2 Test di convergenza\nPer valutare la convergenza di una catena di Markov Monte Carlo (MCMC), esistono diversi metodi, tra cui approcci grafici e test statistici. Ecco una spiegazione pi√π chiara e dettagliata:\n\n\n\n31.7.4 Approcci Grafici: Tracce delle Serie Temporali (Trace Plots)\nLe tracce delle serie temporali, o trace plots, sono grafici che mostrano l‚Äôevoluzione dei valori campionati rispetto al numero di iterazioni. Questi grafici sono utili per valutare visivamente se la catena ha raggiunto la convergenza. Segni che indicano una potenziale convergenza includono:\n\nAssenza di Tendenze: Non ci sono trend ascendenti o discendenti nel corso delle iterazioni.\nCostanza dell‚ÄôAmpiezza: La variabilit√† dei valori campionati rimane costante nel tempo, senza significative fluttuazioni.\nMancanza di Periodicit√†: Non si osservano cicli o ripetizioni regolari che potrebbero indicare la presenza di correlazioni residue.\n\n\n\n31.7.5 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n31.7.5.1 Test di Geweke\nIl test di Geweke √® una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l‚Äôultimo 50% dei campioni, dopo aver escluso un iniziale periodo di ‚Äúburn-in‚Äù (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base √® che, se la catena √® in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n\n31.7.5.2 Geweke Z-score\nUna variante del test di Geweke √® lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in pi√π esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. √à importante notare che nessun test pu√≤ garantire con certezza la convergenza, ma l‚Äôutilizzo congiunto di approcci grafici e test statistici pu√≤ offrire una buona indicazione dello stato della catena.\n\n\n\n31.7.6 Effective sample size (ESS)\nQuando le iterazioni sono dipendenti, ogni iterazione contiene informazioni sovrapposte con le iterazioni precedenti. In altre parole, quando si ottengono 500 campioni dipendenti dalla distribuzione a posteriori, questi contengono solo informazioni equivalenti a &lt; 500 campioni indipendenti. L‚ÄôESS (Effective Sample Size) quantifica la quantit√† effettiva di informazioni, quindi una catena con ESS = n conterr√† approssimativamente la stessa quantit√† di informazioni di n campioni indipendenti. In generale, vogliamo che l‚ÄôESS sia almeno 400 per un‚Äôutilizzazione generale nel riassumere la distribuzione a posteriori.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#caso-normale-normale",
    "href": "chapters/chapter_4/10_metropolis.html#caso-normale-normale",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.8 Caso Normale-Normale",
    "text": "31.8 Caso Normale-Normale\nConsideriamo ora il caso Normale-Normale di cui √® possibile trovare una soluzione analitica. Supponiamo, come prior, una \\(\\mathcal{N}(30, 5\\).\n\ndef prior(mu):\n    return stats.norm.pdf(mu, 30, 5)\n\nPer la verosimiglianza del parametro \\(\\mu\\), supponiamo \\(\\sigma\\) nota e uguale alla deviazione standard del campione.\n\ndef likelihood(mu, data):\n    std_data = np.std(data)  # Calcola la deviazione standard dei dati\n    return np.prod(stats.norm.pdf(data, mu, std_data))\n\nDefiniamo il posterior non normalizzato:\n\ndef posterior(mu, data):\n    return likelihood(mu, data) * prior(mu)\n\nModifichiamo ora l‚Äôalgoritmo di Metropolis descritto sopra per adattarlo al caso presente.\n\n# Algoritmo di Metropolis per il caso normale-normale\ndef metropolis_for_normal(nsamp, xinit, data):\n    samples = np.empty(nsamp)\n    x_prev = xinit\n\n    for i in range(nsamp):\n        x_star = np.random.normal(x_prev, 0.5)  # Genera un nuovo punto dalla proposta\n\n        # Calcola il rapporto di accettazione e accetta il nuovo punto con una certa probabilit√†\n        if posterior(x_star, data) / posterior(x_prev, data) &gt; np.random.uniform():\n            x_prev = x_star\n\n        samples[i] = x_prev\n\n    return samples\n\nVediamo cosa fa la presente versione dell‚Äôalgoritmo di Metropolis passo dopo passo:\n\nCiclo sui Campioni: for i in range(nsamp): inizia un ciclo che si ripeter√† nsamp volte, dove nsamp √® il numero totale di campioni che vogliamo generare. Ogni iterazione di questo ciclo produrr√† un campione dalla distribuzione di interesse.\nGenerazione di un Nuovo Punto: x_star = np.random.normal(x_prev, 0.5) genera un nuovo punto (x_star) come proposta per il prossimo passo del campionamento. Questo √® fatto campionando da una distribuzione normale con media uguale all‚Äôultimo punto accettato (x_prev) e una deviazione standard di 0.5. Questa distribuzione √® detta distribuzione di proposta e serve a esplorare lo spazio dei parametri.\nCalcolo del Rapporto di Accettazione:\n\nIl rapporto di accettazione √® calcolato come posterior(x_star, data) / posterior(x_prev, data), che √® il rapporto tra la probabilit√† del posterior del nuovo punto proposto (x_star) e la probabilit√† del posterior dell‚Äôultimo punto accettato (x_prev).\nQuesto rapporto indica quanto sia preferibile il nuovo punto rispetto al precedente, basandosi sulla funzione posterior, che calcola la probabilit√† a posteriori del modello dato il parametro e i dati osservati.\n\nDecisione di Accettazione del Nuovo Punto:\n\nLa decisione se accettare o meno il nuovo punto (x_star) si basa su un confronto del rapporto di accettazione con un numero casuale uniformemente distribuito tra 0 e 1 (np.random.uniform()).\nSe il rapporto di accettazione √® maggiore di questo numero casuale, il nuovo punto √® accettato come il prossimo punto nella catena (x_prev = x_star). Ci√≤ significa che il nuovo punto ha una probabilit√† a posteriori pi√π alta rispetto al punto precedente, o √® stato ‚Äúfortunato‚Äù nel processo di selezione casuale, consentendo all‚Äôalgoritmo di esplorare lo spazio dei parametri anche in zone di minore probabilit√†.\nSe il nuovo punto non viene accettato, la catena rimane nel punto precedente (x_prev), e questo punto viene nuovamente aggiunto all‚Äôarray dei campioni.\n\nSalvataggio del Campione: samples[i] = x_prev salva il punto corrente (che pu√≤ essere il nuovo punto accettato o il punto precedente se il nuovo punto √® stato rifiutato) nell‚Äôarray samples. Questo processo si ripete fino a quando non si raggiunge il numero desiderato di campioni.\n\nCome dati, usiamo il campione di 30 valori BDI-II ottenuti dai soggetti clinici esaminati da {cite}zetsche_2019future.\n\ny = np.array([\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n    41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n])\n\nProcediamo con l‚Äôesecuzione dell‚Äôalgoritmo di Metropolis.\n\nsamples = metropolis_for_normal(100_000, np.mean(y), y)\nsamples.shape\n\n(100000,)\n\n\n\n31.8.1 Calcolo dei Parametri del Posterior Analitico\nNel caso normale-normale, possiamo derivare analiticamente la distribuzione posteriore quando sia il prior che la likelihood sono distribuzioni normali. La bellezza di questo approccio sta nella forma chiusa del posterior, che √® anch‚Äôesso una distribuzione normale con parametri specifici facilmente calcolabili. Ecco come si fa:\n\nMedia Posteriore (\\(\\mu_{post}\\)): La media del posterior √® un peso tra la media del campione e la media del prior, dove i pesi sono determinati dalle varianze del prior e dei dati.\n\\[\n\\mu_{post} = \\frac{\\frac{\\mu_{prior}}{\\sigma_{prior}^2} + \\frac{\\sum y_i}{\\sigma_{data}^2}}{\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}}\n\\]\nVarianza Posteriore (\\(\\sigma_{post}^2\\)): La varianza del posterior √® determinata dalle varianze del prior e dei dati.\n\\[\n\\sigma_{post}^2 = \\left(\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}\\right)^{-1}\n\\]\n\nDove: - \\(\\mu_{prior}\\) √® la media del prior (in questo caso, 30), - \\(\\sigma_{prior}^2\\) √® la varianza del prior (\\(5^2\\) in questo caso), - \\(\\sigma_{data}^2\\) √® la varianza dei dati (calcolata dai dati), - \\(n\\) √® il numero di osservazioni, - \\(\\sum y_i\\) √® la somma delle osservazioni.\n\n\n31.8.2 Codice per il Grafico\nPer produrre il grafico con l‚Äôistogramma dei campioni dal posterior (usando l‚Äôalgoritmo di Metropolis) e la curva della distribuzione posteriore analitica, usiamo i parametri calcolati:\n\n# Parametri del prior\nmu_prior = 30\nstd_prior = 5\nvar_prior = std_prior ** 2\n\n# Dati osservati\nn = len(y)\nsum_y = np.sum(y)\nvar_data = np.var(y, ddof=1)  # ddof=1 for sample variance\n\n# Calcolo dei parametri posterior\nmu_post = (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post = 1 / (1 / var_prior + n / var_data)\nstd_post = np.sqrt(var_post)\n\n# Generazione dei punti x per il grafico\nx = np.linspace(mu_post - 4 * std_post, mu_post + 4 * std_post, 1000)\n\n# Istogramma dei campioni dal posterior\nplt.hist(samples[burnin:], bins=30, alpha=0.4, density=True, label=\"MCMC Samples Distribution\")\n\n# Curva della distribuzione posteriore analitica\nplt.plot(x, stats.norm.pdf(x, mu_post, std_post), \"C1\", label=\"Analytical Posterior Distribution\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice mostra come integrare l‚Äôanalisi MCMC con l‚Äôapproccio analitico per il caso normale-normale, offrendo sia una visualizzazione dei risultati del sampling che la conferma attraverso la soluzione analitica.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/10_metropolis.html#commenti-e-considerazioni-finali",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "31.9 Commenti e considerazioni finali",
    "text": "31.9 Commenti e considerazioni finali\nIn generale, la distribuzione a posteriori dei parametri di un modello statistico non pu√≤ essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilit√† che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre pi√π semplice l‚Äôuso dei metodi MCMC, insieme all‚Äôincremento della potenza di calcolo dei computer, ha contribuito a rendere sempre pi√π popolare il metodo dell‚Äôinferenza bayesiana che, in questo modo, pu√≤ essere estesa a problemi di qualunque grado di complessit√†.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/10_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/10_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "31¬† Monte Carlo a Catena di Markov",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 15 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nsys        : 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:35:20) [Clang 16.0.6 ]\nmatplotlib : 3.8.4\narviz      : 0.18.0\nstatsmodels: 0.14.2\nscipy      : 1.13.1\nnumpy      : 1.26.4\nseaborn    : 0.13.2\npymc       : 5.15.1\npandas     : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, e Duncan Roweth. 1987. ¬´Hybrid monte carlo¬ª. Physics letters B 195 (2): 216‚Äì22.\n\n\nGeman, Stuart, e Donald Geman. 1984. ¬´Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images¬ª. IEEE Transactions on pattern analysis and machine intelligence 6: 721‚Äì41.\n\n\nHastings, W. Keith. 1970. ¬´Monte Carlo sampling methods using Markov chains and their applications¬ª. Biometrika 57 (1): 97‚Äì109.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ¬´The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.¬ª Journal of Machine Learning Research 15 (1): 1593‚Äì623.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, e Edward Teller. 1953. ¬´Equation of state calculations by fast computing machines¬ª. The Journal of Chemical Physics 21 (6): 1087‚Äì92.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html",
    "title": "32¬† Linguaggio Stan",
    "section": "",
    "text": "32.1 Introduzione\nNel presente capitolo, presenteremo un linguaggio di programmazione probabilistica denominato Stan. Stan consente di estrarre campioni da distribuzioni di probabilit√† mediante la costruzione di una catena di Markov, la cui distribuzione di equilibrio (o stazionaria) coincide con la distribuzione desiderata. Il nome del linguaggio deriva da uno dei pionieri del metodo Monte Carlo, Stanislaw Ulam. Un‚Äôintroduzione dettagliata al linguaggio Stan √® fornita nell‚ÄôAppendice M. In questo capitolo, utilizzeremo Stan per fare inferenza su una proporzione.\nIl linguaggio di programmazione probabilistica Stan √® compatibile con diverse piattaforme e offre varie interfacce (R, Python, Julia). In questo corso, useremo CmdStanPy, un‚Äôinterfaccia per Stan pensata per gli utenti di Python. CmdStanPy √® un pacchetto puramente in Python3 che √® un wrapper di CmdStan, l‚Äôinterfaccia a riga di comando per Stan scritta in C++. Pertanto, oltre a Python3, CmdStanPy richiede un toolchain C++ per compilare ed eseguire i modelli Stan.\nLa procedura per installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge √® descritta nel capitolo Appendice E.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#inferenza-bayesiana-e-metodi-mcmc",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#inferenza-bayesiana-e-metodi-mcmc",
    "title": "32¬† Linguaggio Stan",
    "section": "32.2 Inferenza Bayesiana e Metodi MCMC",
    "text": "32.2 Inferenza Bayesiana e Metodi MCMC\nL‚Äôinferenza bayesiana, impiegata per la stima dei parametri, la previsione e la valutazione della probabilit√† di eventi, si basa sulle aspettative a posteriori. Queste aspettative si configurano come integrali multidimensionali nello spazio dei parametri. Stan, un software all‚Äôavanguardia per l‚Äôanalisi statistica, si avvale del metodo Monte Carlo per risolvere questi integrali complessi. I metodi Monte Carlo sfruttano il campionamento casuale per affrontare integrali ad alta dimensionalit√†.\nTuttavia, per la maggior parte dei problemi bayesiani, non √® possibile utilizzare i metodi Monte Carlo standard, poich√© non √® fattibile generare campioni indipendenti dalla densit√† a posteriori di interesse, fatta eccezione per modelli estremamente semplici con prior coniugati. Di conseguenza, √® necessario ricorrere ai metodi Monte Carlo a Catena di Markov (MCMC), che producono campioni correlati tra loro. Stan implementa il Monte Carlo Hamiltoniano (HMC), il metodo MCMC pi√π efficiente e scalabile per le densit√† target. Altri metodi, come il Metropolis-Hastings e il campionamento di Gibbs, risultano pi√π semplici ma meno efficienti dell‚ÄôHMC.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "title": "32¬† Linguaggio Stan",
    "section": "32.3 Stan e la Programmazione Probabilistica",
    "text": "32.3 Stan e la Programmazione Probabilistica\nStan si configura come un linguaggio di programmazione probabilistica (PPL) concepito per definire modelli statistici complessi e effettuare inferenze su di essi. Un PPL consente di esprimere modelli probabilistici in modo conciso e di utilizzare algoritmi avanzati per l‚Äôinferenza. Ci√≤ risulta particolarmente utile nell‚Äôinferenza bayesiana, dove si aggiornano le distribuzioni a priori con dati osservati per ottenere distribuzioni a posteriori.\n\n32.3.1 Struttura di un Programma Stan\nUn programma Stan richiede la specificazione di variabili e parametri, definendo le distribuzioni a priori dei parametri del modello statistico e la funzione di verosimiglianza. In sostanza, un programma Stan descrive l‚Äôinterazione tra dati e parametri e le distribuzioni probabilistiche che li governano. Questo consente di effettuare inferenze sulle distribuzioni a posteriori dei parametri del modello, dedotte dai dati osservati e dalle distribuzioni a priori.\n\n\n32.3.2 Esecuzione di un Programma Stan\nUn programma Stan utilizza metodi di inferenza avanzati:\n\nCampionamento MCMC: Stan impiega metodi come il Monte Carlo a Catena di Markov per generare campioni dalle distribuzioni a posteriori.\nInferenza Variazionale: Un metodo approssimativo che fornisce stime delle distribuzioni a posteriori.\nApprossimazione di Laplace: Un ulteriore metodo approssimativo per l‚Äôinferenza.\n\nStan √® accessibile attraverso vari linguaggi di programmazione e strumenti di analisi open-source, tra cui Python, R e Julia, ed √® compatibile con gli strumenti di analisi bayesiana integrati in questi linguaggi. √à inoltre disponibile in ambienti come Mathematica, Stata e MATLAB, sebbene queste interfacce siano meno complete.\nStan genera dati attraverso procedure pseudo-casuali, applicabili sia per simulazioni in avanti che per risolvere il problema inverso.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#simulazione-in-avanti-e-problema-inverso",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#simulazione-in-avanti-e-problema-inverso",
    "title": "32¬† Linguaggio Stan",
    "section": "32.4 Simulazione in Avanti e Problema Inverso",
    "text": "32.4 Simulazione in Avanti e Problema Inverso\nStan genera dati attraverso procedure pseudo-casuali, applicabili sia per simulazioni in avanti che per risolvere il problema inverso.\n\n32.4.1 Simulazione in Avanti\nLa simulazione in avanti consiste nella generazione di dati simulati a partire da un insieme di parametri noti di un modello probabilistico. In altri termini, date determinate assunzioni sui parametri di un modello, si utilizza la simulazione in avanti per prevedere i possibili risultati.\nAd esempio, consideriamo uno studio clinico con \\(N\\) soggetti e una probabilit√† \\(\\theta\\) di esito positivo per ciascun soggetto. Conoscendo il valore di \\(\\theta\\) e il numero di soggetti \\(N\\), possiamo impiegare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci consente di generare dati che riflettono le nostre assunzioni sui parametri del modello.\nIn notazione statistica, questo si esprime come:\n\\[\nY \\sim \\text{Binomiale}(N, \\theta)\n\\]\ndove \\(Y\\) rappresenta il numero di esiti positivi su \\(N\\) pazienti, con probabilit√† \\(\\theta\\) di esito positivo per ciascun paziente.\n\n32.4.1.1 Esempio di Simulazione in Avanti\nSupponiamo di avere \\(N = 100\\) soggetti in uno studio clinico e un tasso di successo \\(\\theta = 0.3\\). Possiamo simulare un risultato \\(Y\\) generando casualmente il numero di soggetti con esito positivo. Utilizzando una distribuzione binomiale, possiamo calcolare la probabilit√† di ottenere esattamente \\(y\\) esiti positivi su \\(N\\) tentativi:\n\\[\np(Y = y \\mid N, \\theta) = \\binom{N}{y} \\cdot \\theta^y \\cdot (1 - \\theta)^{N - y}\n\\]\nQuesta espressione ci permette di calcolare la probabilit√† di ottenere un certo numero di successi, dato il numero di soggetti e la probabilit√† di successo.\n\n\n\n32.4.2 Un Primo Programma in Stan: Generazione di Dati Casuali\nSupponiamo di voler generare dei valori casuali \\(Y\\) da una distribuzione binomiale con parametri \\(N\\) e \\(\\theta\\). Ad esempio, possiamo impostare \\(\\theta = 0.3\\), per rappresentare una probabilit√† del 30% di un esito positivo (in statistica, il termine ‚Äòsuccesso‚Äô indica un esito positivo), e possiamo impostare \\(N = 100\\). Il seguente programma Stan pu√≤ essere utilizzato per generare valori di \\(Y\\) compresi tra 0 e 100.\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\n\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;\n  y = binomial_rng(N, theta);\n}\n\n\n32.4.3 Organizzazione di un Programma Stan\nLa prima cosa da notare √® che un programma Stan √® organizzato in blocchi. Qui abbiamo due blocchi: un blocco dei dati (data)contenente le dichiarazioni delle variabili che devono essere fornite come dati e un blocco delle quantit√† generate (generated quantities), che non solo dichiara variabili ma assegna loro un valore. In questo programma Stan, la variabile y viene assegnata come risultato di una singola estrazione da una distribuzione \\(\\textrm{binomiale}(N, \\theta)\\), che Stan fornisce attraverso la funzione binomial_rng.\n\n\n32.4.4 Tipi di Variabili in Stan\nLa seconda cosa da notare √® che tutte le variabili in un programma Stan sono dichiarate con tipi specifici. Stan utilizza la tipizzazione statica, il che significa che, a differenza di Python o R, il tipo di una variabile √® dichiarato nel programma prima del suo utilizzo, piuttosto che essere determinato al momento dell‚Äôesecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile non cambia mai.\nIl programma in esame dichiara tre variabili: N e y di tipo int (interi) e theta di tipo real (numeri reali). Nei computer, gli interi hanno limiti precisi e i numeri reali possono avere errori di calcolo. Stan utilizza numeri reali con precisione doppia (64 bit) secondo lo standard IEEE 754, tranne in alcune operazioni ottimizzate che possono perdere un po‚Äô di precisione.\n\n\n32.4.5 Vincoli sui Tipi\nUn tipo di variabile pu√≤ avere dei vincoli. Poich√© N √® un conteggio, deve essere maggiore o uguale a zero, cosa che indichiamo con il vincolo lower=0. Allo stesso modo, la variabile y, che rappresenta il numero di esiti positivi su N, deve essere compresa tra 0 e N (inclusi); questo √® indicato con il vincolo lower=0, upper=N. Infine, la variabile theta √® un numero reale e deve essere compresa tra 0 e 1, cosa che indichiamo con il vincolo lower=0, upper=1. Anche se tecnicamente i limiti per i numeri reali sono aperti, in pratica possiamo ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.\n\n\n32.4.6 Esecuzione del Programma Stan\nLa funzione cmdstan_model() crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan. In background, CmdStan traduce un programma Stan in C++ e creare un eseguibile compilato.\n\nmodel = CmdStanModel(stan_file='../../stan/binomial-rng.stan')\n\nDurante l‚Äôesecuzione, il programma Stan compilato richiede i valori di N e theta. Ad ogni iterazione, il programma campiona un valore di y utilizzando il suo generatore di numeri pseudocasuali integrato. I valori di N e theta devono essere forniti in un dizionario Python.\n\nN = 100\ntheta = 0.3\ndata = {\n    'N': N, \n    'theta': theta\n}\n\nInfine campioniamo dal modello utilizzando il metodo sample di CmdStanModel.\n\ntrace = model.sample(\n    data=data, \n    seed=123, \n    chains=1,\n    iter_sampling=30, \n    iter_warmup=1,\n    show_progress=False, \n    show_console=False\n)\n\n\n\n32.4.7 Costruzione del Modello\nIl costruttore di CmdStanModel viene utilizzato per creare un modello a partire da un programma Stan presente nel file specificato. Si consiglia vivamente di utilizzare un file separato per i programmi Stan. In pratica, il processo inizia con la traduzione del programma Stan in una classe C++ utilizzando un traduttore specifico. Successivamente, il programma C++ viene compilato.\n\n\n32.4.8 Interfaccia Python\nNell‚Äôinterfaccia Python, il metodo sample() accetta i seguenti argomenti:\n\ndata: i dati letti nel blocco dati del programma Stan,\nseed: generatore di numeri pseudocasuali per la riproducibilit√†,\nchains: il numero di simulazioni da eseguire (parallel_chains indica quante eseguire in parallelo),\niter_sampling: numero di estrazioni (cio√®, dimensione del campione) da restituire,\niter_warmup: numero di iterazioni di riscaldamento per tarare i parametri dell‚Äôalgoritmo di campionamento (non necessari qui, quindi impostato a 0),\nshow_progress: se True, stampa aggiornamenti di progresso,\nshow_console: apre un monitor di progresso GUI.\n\nIl risultato della chiamata a sample() sull‚Äôistanza del modello viene assegnato alla variabile trace e contiene le 10 estrazioni richieste con l‚Äôargomento iter_sampling = 30.\nQuando si chiama model.sample(...), CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell‚Äôargomento data di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poich√© il nostro programma Stan ha solo un blocco di quantit√† generate, l‚Äôunico compito rimanente della classe C++ √® generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da iter_sampling, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.\nLa generazione di numeri casuali √® determinata dal valore seed specificato nella chiamata.\n\n\n32.4.9 Estrazione dei Risultati\nUna volta completato il campionamento, possiamo estrarre il campione di 30 valori per la variabile scalare y sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.\n\ny = trace.stan_variable('y')\nprint(\"N =\", N, \";  theta =\", theta, \";  y(0:30) =\", *y.astype(int))\n\nN = 100 ;  theta = 0.3 ;  y(0:30) = 28 34 31 29 26 25 31 28 30 36 29 36 37 27 29 23 29 34 30 42 37 29 34 28 35 31 30 31 23 28",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#integrazione-monte-carlo",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#integrazione-monte-carlo",
    "title": "32¬† Linguaggio Stan",
    "section": "32.5 Integrazione Monte Carlo",
    "text": "32.5 Integrazione Monte Carlo\nIl calcolo bayesiano si basa sulla media delle incertezze nella stima dei parametri. In generale, ci√≤ implica il calcolo di aspettative, che sono medie ponderate con pesi dati dalle densit√† di probabilit√†. In questa sezione, introdurremo i metodi Monte Carlo per calcolare un semplice integrale che corrisponde all‚Äôaspettativa di una variabile indicatrice discreta. Utilizzeremo l‚Äôesempio classico del lancio di freccette su un bersaglio per stimare la costante matematica \\(\\pi\\) ‚Äì si veda l‚ÄôAppendice L.\n\n32.5.1 Metodi Monte Carlo a Catena di Markov\nNelle sezioni precedenti, abbiamo visto come generare un campione eseguendo una serie di estrazioni indipendenti e calcolare la media dei risultati per ottenere stime delle aspettative.\nNei moderni modelli bayesiani, raramente √® possibile generare estrazioni indipendenti dalle distribuzioni di interesse. Questo rende i semplici metodi Monte Carlo non applicabili. Solo in rari casi, con modelli molto semplici, √® possibile ottenere estrazioni indipendenti, ma questi casi sono limitati (Diaconis e Ylvisaker 1979). Prima della rivoluzione dei metodi Monte Carlo a catena di Markov (MCMC) negli anni ‚Äô90, l‚Äôinferenza bayesiana era per lo pi√π limitata a questi modelli semplici.\nL‚Äôintroduzione dei metodi MCMC ha rivoluzionato l‚Äôinferenza bayesiana. Questi metodi permettono di generare campioni da distribuzioni complesse dove non √® possibile ottenere estrazioni indipendenti. Tra questi, il metodo Hamiltonian Monte Carlo (HMC) √® particolarmente efficiente e scalabile, grazie all‚Äôuso della differenziazione automatica. HMC √® implementato in Stan e ha ampliato notevolmente la gamma di modelli che possono essere analizzati in tempi ragionevoli.\n\n\n32.5.2 Catene di Markov\nNei metodi Monte Carlo a catena di Markov, ogni estrazione dipende dall‚Äôestrazione precedente. Una sequenza di variabili casuali in cui ciascuna dipende solo dalla variabile precedente √® chiamata catena di Markov. In altre parole, una catena di Markov √® una sequenza di variabili casuali dove ogni variabile √® condizionatamente indipendente dalle precedenti, dato il valore della variabile immediatamente precedente.\nIn conclusione, i metodi Monte Carlo a catena di Markov, come l‚ÄôHamiltonian Monte Carlo, hanno ampliato notevolmente le capacit√† dell‚Äôinferenza bayesiana, permettendo di affrontare modelli complessi che non possono essere analizzati con semplici estrazioni indipendenti.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#metodi-monte-carlo-a-catena-di-markov",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#metodi-monte-carlo-a-catena-di-markov",
    "title": "32¬† Linguaggio Stan",
    "section": "32.6 Metodi Monte Carlo a Catena di Markov",
    "text": "32.6 Metodi Monte Carlo a Catena di Markov\nNelle sezioni precedenti, abbiamo visto come generare un campione eseguendo una serie di estrazioni indipendenti e calcolare la media dei risultati per ottenere stime delle aspettative.\nNei moderni modelli bayesiani, raramente √® possibile generare estrazioni indipendenti dalle distribuzioni di interesse. Questo rende i semplici metodi Monte Carlo non applicabili. Solo in rari casi, con modelli molto semplici, √® possibile ottenere estrazioni indipendenti, ma questi casi sono limitati (Diaconis e Ylvisaker 1979). Prima della rivoluzione dei metodi Monte Carlo a catena di Markov (MCMC) negli anni ‚Äô90, l‚Äôinferenza bayesiana era per lo pi√π limitata a questi modelli semplici.\nL‚Äôintroduzione dei metodi MCMC ha rivoluzionato l‚Äôinferenza bayesiana. Questi metodi permettono di generare campioni da distribuzioni complesse dove non √® possibile ottenere estrazioni indipendenti. Tra questi, il metodo Hamiltonian Monte Carlo (HMC) √® particolarmente efficiente e scalabile, grazie all‚Äôuso della differenziazione automatica. HMC √® implementato in Stan e ha ampliato notevolmente la gamma di modelli che possono essere analizzati in tempi ragionevoli.\n\n32.6.1 Catene di Markov\nNei metodi Monte Carlo a catena di Markov, ogni estrazione dipende dall‚Äôestrazione precedente. Una sequenza di variabili casuali in cui ciascuna dipende solo dalla variabile precedente √® chiamata catena di Markov. In altre parole, una catena di Markov √® una sequenza di variabili casuali dove ogni variabile √® condizionatamente indipendente dalle precedenti, dato il valore della variabile immediatamente precedente.\nIn conclusione, i metodi Monte Carlo a catena di Markov, come l‚ÄôHamiltonian Monte Carlo, hanno ampliato notevolmente le capacit√† dell‚Äôinferenza bayesiana, permettendo di affrontare modelli complessi che non possono essere analizzati con semplici estrazioni indipendenti.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#il-problema-inverso-delle-nascite-di-laplace",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#il-problema-inverso-delle-nascite-di-laplace",
    "title": "32¬† Linguaggio Stan",
    "section": "32.7 Il Problema Inverso delle Nascite di Laplace",
    "text": "32.7 Il Problema Inverso delle Nascite di Laplace\n\n32.7.1 Il Problema Inverso\nIl problema inverso consiste nella stima dei parametri del modello, come la probabilit√† di successo \\(\\theta\\), dato un insieme di dati osservati. Supponiamo di avere i seguenti dati: \\(N = 100\\) soggetti e \\(y = 32\\) esiti positivi. L‚Äôobiettivo √® stimare \\(\\theta\\), la probabilit√† di successo.\nNell‚Äôapproccio bayesiano, si inizia specificando una distribuzione a priori per \\(\\theta\\). Supponiamo di utilizzare una distribuzione Beta(\\(\\alpha\\), \\(\\beta\\)) come prior per \\(\\theta\\), dove \\(\\alpha\\) e \\(\\beta\\) sono parametri scelti in base alle conoscenze precedenti. La distribuzione a posteriori di \\(\\theta\\) data l‚Äôosservazione \\(y\\) √® ancora una distribuzione Beta, ma con parametri aggiornati:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + N - y)\n\\]\nAd esempio, scegliendo una distribuzione a priori non informativa con \\(\\alpha = 1\\) e \\(\\beta = 1\\), la distribuzione a posteriori diventa:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(1 + 32, 1 + 100 - 32) = \\text{Beta}(33, 69)\n\\]\nQuesta distribuzione a posteriori fornisce una stima aggiornata della probabilit√† di successo \\(\\theta\\) considerando i dati osservati. Utilizzando Stan, √® possibile ottenere campioni da questa distribuzione a posteriori per calcolare statistiche riassuntive e effettuare previsioni.\nIn sintesi, la simulazione in avanti e il problema inverso rappresentano due approcci complementari: la simulazione in avanti genera dati simulati da parametri noti, mentre il problema inverso stima i parametri del modello dai dati osservati.\nQuando si dispone di un modello che genera dati a partire dai parametri, il problema inverso consiste nell‚Äôinferire i valori dei parametri dai dati osservati. Questo tipo di problema richiede di ragionare a ritroso dalle osservazioni, attraverso il modello di misurazione e il modello diretto, per stimare parametri come, ad esempio, la probabilit√† di successo. La risoluzione dei problemi inversi √® uno degli ambiti in cui le statistiche bayesiane eccellono.\n\n\n32.7.2 Storia e Applicazione\nUn decennio dopo la pubblicazione della regola di Bayes, Laplace utilizz√≤ la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori. In questa sezione, analizzeremo il problema di Laplace utilizzando Stan.\nLaplace raccolse dati sul sesso dei bambini nati vivi a Parigi tra il 1745 e il 1770:\n\n\n\nSesso\nNascite vive\n\n\n\n\nFemmina\n105.287\n\n\nMaschio\n110.312\n\n\n\nLaplace si chiese se, sulla base di questi dati, la probabilit√† di nascita dei maschi fosse superiore a quella delle femmine.\n\n\n32.7.3 Modello di Laplace\nLaplace adott√≤ la seguente distribuzione campionaria per modellare il numero di maschi nati su un totale di \\(N\\) nascite:\n\\[\ny \\sim \\text{binomiale}(N, \\theta),\n\\]\ndove \\(N\\) √® il numero totale di nascite, \\(\\theta\\) √® la probabilit√† di nascita di un maschio e \\(y\\) √® il numero di nascite maschili.\n\n\n32.7.4 Distribuzione a Priori\nLaplace utilizz√≤ la seguente distribuzione a priori per \\(\\theta\\):\n\\[\n\\theta \\sim \\text{beta}(1, 1),\n\\]\ndove la distribuzione \\(\\text{beta}(1, 1)\\) √® uniforme sull‚Äôintervallo \\(\\theta \\in (0, 1)\\) poich√© la densit√† √® proporzionale a una costante:\n\\[\n\\text{beta}(\\theta \\mid 1, 1) \\propto \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} = 1.\n\\]\n\n\n32.7.5 Distribuzione a Posteriori\nIl modello di Laplace √® abbastanza semplice da permettere una soluzione analitica della distribuzione a posteriori:\n\\[\n\\begin{aligned}\n    p(\\theta \\mid y, N) &\\propto p(y \\mid N, \\theta) \\cdot p(\\theta) \\\\\n    &= \\text{binomiale}(y \\mid N, \\theta) \\cdot \\text{beta}(\\theta \\mid 1, 1) \\\\\n    &\\propto \\theta^y \\cdot (1 - \\theta)^{N - y} \\cdot \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} \\\\\n    &= \\theta^{y} \\cdot (1 - \\theta)^{N - y} \\\\\n    &\\propto \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\end{aligned}\n\\]\nQuindi, possiamo concludere che:\n\\[\np(\\theta \\mid y, N) = \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\]\n\n\n32.7.6 Implementazione in Stan\nA differenza del primo modello Stan che abbiamo visto, che generava solo dati, il seguente programma Stan richiede che vengano forniti dati, specificamente il numero di nascite maschili (\\(y\\)) e il numero totale di nascite (\\(N\\)). Il modello ci permetter√† di stimare la probabilit√† di nascita di un maschio (\\(\\theta\\)) e la probabilit√† che nascano pi√π maschi che femmine (\\(\\theta &gt; 0.5\\)).\nEcco come possiamo specificare il modello Stan:\n\n# Il progetto si trova due livelli sopra la directory corrente\nproject_directory = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\nstan_file = os.path.join(project_directory, 'stan', 'sex-ratio.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che sia il numero totale di nascite (\\(N\\)) sia il numero di nascite maschili (\\(y\\)) sono forniti come dati. Poi ci sono due blocchi aggiuntivi: un blocco dei parametri, usato per dichiarare valori sconosciuti (qui, solo il tasso di nascite maschili \\(\\theta\\)), e un blocco del modello, dove specifichiamo la distribuzione a priori e la verosimiglianza. La distribuzione a posteriori viene calcolata da Stan combinando queste due componenti. Inoltre, c‚Äô√® un blocco delle quantit√† generate dove viene calcolata una variabile booleana che indica se la probabilit√† di nascita dei maschi \\(\\theta\\) √® maggiore di 0.5.\nIl modello di Laplace e la sua implementazione in Stan ci permettono di affrontare il problema inverso delle nascite, inferendo la probabilit√† di nascita di un maschio dai dati osservati. Utilizzando le tecniche bayesiane, possiamo stimare non solo la probabilit√† di nascita di un maschio, ma anche la probabilit√† che nascano pi√π maschi che femmine.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#campionare-dalla-distribuzione-a-posteriori",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#campionare-dalla-distribuzione-a-posteriori",
    "title": "32¬† Linguaggio Stan",
    "section": "32.8 Campionare dalla Distribuzione a Posteriori",
    "text": "32.8 Campionare dalla Distribuzione a Posteriori\nQuando eseguiamo un programma Stan, esso genera una serie di campioni casuali che approssimano la distribuzione a posteriori. Con il proseguire delle estrazioni, questi campioni tendono a diventare sempre pi√π simili a veri campioni della distribuzione a posteriori, fino a diventare numericamente indistinguibili da essa.\nStan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che pu√≤ introdurre autocorrelazione nei campioni della distribuzione a posteriori. In altre parole, i campioni non sono indipendenti tra loro, ma ogni campione √® correlato (o anti-correlato) con il campione precedente.\nL‚Äôautocorrelazione non introduce bias nelle stime Monte Carlo, ma i campioni positivamente autocorrelati, che si osservano nei modelli pi√π complessi, aumentano la varianza delle stime rispetto ai campioni indipendenti. Questo incremento della varianza aumenta l‚Äôerrore quadratico medio atteso, che √® una combinazione di errore dovuto al bias (qui nullo) e alla varianza. Al contrario, nei modelli molto semplici, l‚Äôautocorrelazione negativa riduce la varianza rispetto ai campioni indipendenti, riducendo quindi l‚Äôerrore quadratico medio atteso.\nPer affrontare problemi ad alta dimensionalit√†, Duane et al.¬†(1987) hanno introdotto l‚Äôalgoritmo Hamiltonian Monte Carlo (HMC) che migliora l‚Äôefficienza del campionamento. Per Stan, Hoffman e Gelman (2014) hanno sviluppato una versione adattiva dell‚ÄôHMC chiamata No-U-Turn Sampler (NUTS), successivamente migliorata da Betancourt (2017a). NUTS pu√≤ essere estremamente efficiente, generando campioni anti-correlati che possono portare a stime Monte Carlo pi√π precise rispetto ai campioni indipendenti.\n\n32.8.1 Compilazione del Codice Stan\nPer utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato model.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nInseriamo i dati in un dizionario.\n\nboys = 110312\ngirls = 105287\n\ndata = {\n    'N': boys + girls, \n    'y': boys,\n    \"alpha_prior\" : 1,\n    \"beta_prior\" : 1\n    }\n\nprint(data)\n\n{'N': 215599, 'y': 110312, 'alpha_prior': 1, 'beta_prior': 1}\n\n\nEseguiamo il campionamento MCMC con la seguente chiamata.\n\nsample = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 10_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\nIl metodo $sample() viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato model.\nAvendo assunto una distribuzione a priori per il parametro \\(\\theta\\), l‚Äôalgoritmo procede in maniera ciclica, aggiornando la distribuzione a priori di \\(\\theta\\) condizionandola ai valori gi√† generati. Dopo un certo numero di iterazioni, l‚Äôalgoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di \\(\\theta\\).\nAll‚Äôinizio del campionamento, la distribuzione dei campioni pu√≤ essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale √® chiamato ‚Äúburn-in‚Äù. Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e sono tipicamente scartati. Man mano che il numero di iterazioni aumenta, la distribuzione dei campioni si avvicina sempre pi√π alla distribuzione target.\nDopo aver eseguito il modello in Stan, otteniamo una serie di campioni \\(\\theta^{(m)}\\) dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\). Ogni campione rappresenta un possibile valore di \\(\\theta\\) compatibile con i dati osservati \\(y\\). Procediamo quindi a estrarre i campioni a posteriori per le variabili theta e boys_gt_girls.\n\ntheta_draws = sample.stan_variable('theta')\nboys_gt_girls_draws = sample.stan_variable('boys_gt_girls')\n\nTracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di \\(\\theta\\) sono pi√π probabili e comprendere meglio la forma della distribuzione a posteriori. L‚Äôistogramma ci fornisce diverse informazioni:\n\nValore pi√π probabile di \\(\\theta\\): Questo √® il valore intorno al quale i campioni sono pi√π concentrati, noto come la moda della distribuzione.\nDistribuzione dei possibili valori di \\(\\theta\\): Questo ci d√† un‚Äôidea dell‚Äôincertezza nella stima di \\(\\theta\\).\n\nSe l‚Äôistogramma √® stretto e concentrato attorno a un valore specifico, significa che c‚Äô√® poca incertezza nella stima di \\(\\theta\\). In altre parole, possiamo essere abbastanza sicuri che il valore vero di \\(\\theta\\) sia vicino a questo valore.\nSe l‚Äôistogramma √® largo e distribuito, significa che c‚Äô√® maggiore incertezza nella stima di \\(\\theta\\). Questo indica che i dati osservati non forniscono una stima precisa e che il valore di \\(\\theta\\) potrebbe variare notevolmente.\n\nplt.hist(theta_draws, bins=30, alpha=0.5, color='b', edgecolor='black', density=True)\n\n# Aggiunta di titolo e etichette agli assi\nplt.title('Istogramma della distribizione a posteriori di theta')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\n\nplt.show()",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "title": "32¬† Linguaggio Stan",
    "section": "32.7 Stime Puntuali Bayesiane",
    "text": "32.7 Stime Puntuali Bayesiane\nIn termini bayesiani, una stima puntuale per un parametro \\(\\Theta\\) condizionato sui dati osservati \\(Y = y\\) √® un singolo valore \\(\\hat{\\theta} \\in \\mathbb{R}^D\\) che riassume la distribuzione a posteriori \\(p(\\theta \\mid y)\\). La notazione \\(\\hat{\\theta}\\) √® convenzionale nella statistica per indicare una stima di un parametro \\(\\theta\\). In questa sezione definiamo tre stimatori e discutiamo come i due stimatori bayesiani minimizzino una funzione di perdita tra il valore vero e la stima. Torneremo alla funzione di perdita e alle propriet√† degli stimatori dopo averli definiti.\n\n32.7.1 Stimatore della Media Posteriori\nLa stima puntuale bayesiana pi√π comune per un parametro √® la media posteriori,\n\\[\n\\begin{align}\n\\widehat{\\theta}\n&= \\mathbb{E}[\\Theta \\mid Y = y] \\\\\n&= \\int_{\\Theta} \\theta \\cdot p(\\theta \\mid y) \\, \\textrm{d}\\theta \\\\\n&= \\lim_{M \\rightarrow \\infty} \\, \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)} \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)},\n\\end{align}\n\\]\ndove nelle ultime due righe, ogni estrazione √® distribuita approssimativamente secondo la distribuzione a posteriori,\n\\[\n\\theta^{(m)} \\sim p(\\theta \\mid y).\n\\]\nAbbiamo introdotto la notazione di aspettativa condizionale nella prima riga di questa definizione. Le aspettative sono semplicemente medie ponderate, con i pesi dati da una densit√† di probabilit√†. L‚Äôinferenza bayesiana coinvolge aspettative sulla distribuzione a posteriori, la cui notazione concisa √® quella dell‚Äôaspettativa condizionale,\n\\[\n\\mathbb{E}\\!\n\\left[ f(\\Theta) \\mid Y = y \\right]\n= \\int_{\\mathbb{R^N}} f(\\theta) \\cdot p_{\\Theta \\mid Y}(\\theta \\mid y) \\, \\textrm{d}\\theta,\n\\]\ndove \\(\\Theta\\) e \\(Y\\) sono variabili casuali, mentre \\(\\theta\\) e \\(y\\) sono variabili vincolate ordinarie.\nPer il modello di Laplace, la stima per il tasso di nascite maschili \\(\\theta\\) condizionata sui dati di nascita \\(y\\) √® calcolata come la media campionaria delle estrazioni per theta.\n\ntheta_hat = np.mean(theta_draws)\nprint(f\"estimated theta = {theta_hat:.3f}\")\n\nestimated theta = 0.512\n\n\n\n\n32.7.2 Stimatore della Mediana Posteriori, Quantili e Intervalli\nUn‚Äôalternativa popolare alla stima puntuale bayesiana √® la mediana posteriori, \\(\\theta^+\\). La mediana √® il valore tale che, per ogni dimensione \\(d \\in 1{:}D\\),\n\\[\n\\Pr[\\Theta_d \\leq \\theta^+_d] = \\frac{1}{2}.\n\\]\nIn altre parole, la mediana √® il valore che divide la distribuzione a posteriori in due parti uguali: il 50% dei campioni √® al di sotto della mediana e il 50% √® al di sopra. La mediana posteriori pu√≤ essere calcolata prendendo la mediana dei campioni dalla distribuzione a posteriori.\nEcco come calcolare la mediana posteriori utilizzando Python:\n\ntheta_plus = np.median(theta_draws)\nprint(f\"estimated (median) theta = {theta_plus:.3f}\")\n\nestimated (median) theta = 0.512\n\n\nPoich√© la distribuzione a posteriori per i dati di Laplace √® quasi simmetrica, la media posteriori e la mediana posteriori sono molto simili.\n\n\n32.7.3 Quantili e Intervalli di Credibilit√†\nOltre alla mediana, possiamo anche calcolare i quantili e gli intervalli di credibilit√† per fornire ulteriori informazioni sulla distribuzione a posteriori. I quantili sono valori che dividono la distribuzione in intervalli con una probabilit√† specificata. Gli intervalli di credibilit√† indicano l‚Äôintervallo entro il quale cade una certa percentuale della distribuzione a posteriori.\n\n32.7.3.1 Quantili\nAd esempio, se vogliamo calcolare il quantile al 95% della distribuzione a posteriori, possiamo semplicemente prendere il valore che si trova al 95¬∞ percentile nella sequenza ordinata dei campioni. Di seguito sono riportati i quantili al 5% e al 95% della distribuzione a posteriori di Laplace, calcolati utilizzando i quantili empirici.\n\nquantile_05 = np.quantile(theta_draws, 0.05)\nquantile_95 = np.quantile(theta_draws, 0.95)\nprint(f\"\"\"0.05 quantile = {quantile_05:.3f};\n0.95 quantile = {quantile_95:.3f}\"\"\")\n\n0.05 quantile = 0.510;\n0.95 quantile = 0.513\n\n\n\n\n32.7.3.2 Intervalli Posteriori\nInsieme, il quantile al 5% e al 95% ci forniscono i limiti del nostro intervallo di probabilit√† centrale al 90%. Questo intervallo √® definito come l‚Äôintervallo che contiene il 90% della massa di probabilit√† a posteriori, con il 5% della massa rimanente al di sotto dell‚Äôintervallo e il 5% al di sopra.\n\n\n\n32.7.4 Errore di Stima e Bias\nL‚Äôerrore di una stima √® la differenza tra la stima stessa e il valore vero del parametro,\n\\[\n\\textrm{err} = \\hat{\\theta} - \\theta.\n\\]\nLa nostra stima \\(\\hat{\\theta}\\) √® implicitamente una funzione dei dati \\(y\\), quindi anche l‚Äôerrore dipende dai dati. Possiamo rendere esplicita questa dipendenza scrivendo\n\\[\n\\text{err}(y) = \\hat{\\theta}(y) - \\theta.\n\\]\nIl bias di uno stimatore √® definito come l‚Äôerrore atteso, cio√® la media dell‚Äôerrore rispetto alla distribuzione dei dati per la variabile casuale \\(Y\\),\n\\[\n\\begin{align}\n\\text{bias}\n&= \\mathbb{E}[\\text{err}(Y)] \\\\\n&= \\mathbb{E}[\\hat{\\theta}(Y) - \\theta] \\\\\n&= \\int_Y (\\hat{\\theta}(y) - \\theta) \\, \\text{d}y.\n\\end{align}\n\\]\nIn altre parole, il bias misura quanto, in media, la stima \\(\\hat{\\theta}\\) si discosta dal valore vero \\(\\theta\\) considerando tutte le possibili realizzazioni dei dati \\(Y\\). Un bias nullo indica che lo stimatore √® corretto in media, cio√® non tende a sovrastimare o sottostimare il valore vero del parametro.\n\n\n32.7.5 Stimatore della Moda Posteriori\nUno stimatore popolare, sebbene non strettamente bayesiano, √® la moda a posteriori, che rappresenta il valore del parametro \\(\\theta\\) per cui la densit√† a posteriori √® massima. Formalmente, √® definita come:\n\\[\n\\theta^* = \\text{arg max}_\\theta \\ p(\\theta \\mid y).\n\\]\nLa stima \\(\\theta^*\\) √® spesso chiamata stima MAP (Maximum A Posteriori). La moda a posteriori non √® considerata un vero stimatore bayesiano perch√© non tiene conto dell‚Äôincertezza nella stessa misura in cui lo fanno altri metodi bayesiani. In altre parole, non minimizza una funzione di perdita basata sui valori veri dei parametri, ma cerca semplicemente il valore pi√π probabile dato i dati osservati.\n\n\n32.7.6 Caratteristiche della Moda Posteriori\n\nNon considera l‚Äôincertezza: La stima MAP si focalizza solo sul valore pi√π probabile della distribuzione a posteriori, senza tenere conto della variabilit√† dei dati.\nMassimo della densit√† a posteriori: La moda a posteriori rappresenta il punto in cui la densit√† a posteriori raggiunge il suo massimo.\nPossibili limitazioni: La stima MAP potrebbe non esistere in alcuni casi, come nei modelli in cui la densit√† cresce senza limiti. Questo pu√≤ accadere, ad esempio, nei modelli bayesiani gerarchici o in distribuzioni semplici come la distribuzione esponenziale con parametro 1 (\\(\\textrm{esponenziale}(1)\\)).\n\n\n\n32.7.7 Funzioni di Perdita e Propriet√† degli Stimatori\nLa media a posteriori √® uno stimatore bayesiano popolare per due ragioni principali. Primo, √® uno stimatore non distorto, il che significa che ha un bias nullo. Secondo, ha l‚Äôerrore quadratico medio atteso minimo tra tutti gli stimatori non distorti. L‚Äôerrore quadratico di una stima √® definito come:\n\\[\n\\text{err}^2(y) = \\left(\\hat{\\theta}(y) - \\theta\\right)^2.\n\\]\nQuesta √® una funzione di perdita, che misura la differenza tra una stima \\(\\hat{\\theta}\\) e il valore vero \\(\\theta\\). Tuttavia, la media a posteriori potrebbe non esistere se la distribuzione a posteriori ha code molto ampie, come accade nella distribuzione di Cauchy standard.\n\n\n32.7.8 Propriet√† della Mediana Posteriori\nLa mediana a posteriori \\(\\theta^+\\) ha tre propriet√† interessanti:\n\nSempre ben definita: La mediana a posteriori √® sempre ben definita, anche per densit√† con poli o code molto ampie.\nMinimizzazione dell‚Äôerrore assoluto atteso: La mediana minimizza l‚Äôerrore assoluto atteso, il che la rende robusta.\nRobustezza ai valori anomali: La mediana √® meno sensibile ai valori anomali rispetto alla media, perch√© minimizza l‚Äôerrore assoluto anzich√© l‚Äôerrore quadrato.\n\n\n\n32.7.9 Concentrazione sulle Medie a Posteriori\nIn questa introduzione a Stan, ci concentreremo principalmente sulle medie a posteriori. La media a posteriori non solo fornisce una stima non distorta, ma minimizza anche l‚Äôerrore quadratico medio atteso, rendendola uno strumento potente per l‚Äôinferenza bayesiana. Tuttavia, √® importante essere consapevoli delle sue limitazioni, specialmente in presenza di distribuzioni a posteriori con code molto ampie.\n\n\n32.7.10 Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo\nQuando utilizziamo un campionatore di catene di Markov per stimare parametri, otteniamo una sequenza di campioni casuali. Questa sequenza √® essa stessa una variabile casuale, perch√© √® composta da molte variabili casuali. A causa di questa natura casuale, ogni esecuzione del campionatore pu√≤ produrre risultati leggermente diversi, introducendo quello che √® noto come errore Monte Carlo.\nL‚Äôerrore Monte Carlo √® l‚Äôerrore introdotto dal fatto che utilizziamo solo un numero finito di campioni ($ M $) per stimare i parametri. Questo tipo di errore si verifica perch√©, con un numero limitato di campioni, non possiamo catturare perfettamente l‚Äôintera distribuzione a posteriori.\n\n32.7.10.1 Errore Standard di Monte Carlo (MCMC)\nStan riporta l‚Äôerrore standard di Monte Carlo (MCMC) insieme alle stime della media. L‚Äôerrore standard MCMC per un parametro scalare $ _d $ √® definito come:\n\\[\n\\text{mcmc-se} = \\frac{\\textrm{sd}[\\Theta_d \\mid Y = y]}{\\sqrt{N^{\\text{eff}}}},\n\\]\ndove: - \\(\\text{sd}[\\Theta_d \\mid Y = y]\\) √® la deviazione standard del parametro $ _d $ nella distribuzione a posteriori. - \\(N^{\\text{eff}}\\) √® la dimensione del campione effettivo, che riflette il numero di campioni indipendenti equivalenti ottenuti dal campionatore.\n\n\n32.7.10.2 Dimensione del Campione Effettivo\nNel classico teorema del limite centrale, la dimensione del campione (numero di estrazioni indipendenti) appare al posto di \\(N^{\\text{eff}}\\). Tuttavia, nel contesto delle catene di Markov, i campioni successivi sono correlati tra loro. La dimensione del campione effettivo (\\(N^{\\text{eff}}\\)) tiene conto di questa correlazione e rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle nostre estrazioni correlate.\nLa dimensione del campione effettivo per un campione di dimensione $ M $ √® definita come:\n\\[\nN^{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(\\text{IAT}\\) √® il tempo di autocorrelazione integrata. Sebbene non sia definito formalmente qui, pu√≤ essere considerato come l‚Äôintervallo tra estrazioni effettivamente indipendenti nella nostra catena di Markov. Se l‚Äôautocorrelazione √® bassa, \\(\\text{IAT}\\) sar√† vicino a 1; se l‚Äôautocorrelazione √® alta, \\(\\text{IAT}\\) sar√† molto pi√π alto.\nIn sintesi, \\(N^{\\text{eff}}\\) rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle estrazioni correlate della nostra catena di Markov.\nIn conclusione, l‚Äôerrore standard di Monte Carlo (MCMC) fornisce una misura di quanto varierebbero le nostre stime se ripetessimo il processo di campionamento pi√π volte. √à un indicatore dell‚Äôaffidabilit√† delle nostre stime, tenendo conto della casualit√† introdotta dall‚Äôutilizzo di un numero finito di campioni. Conoscere questo errore ci aiuta a valutare la precisione delle nostre stime e a comprendere meglio l‚Äôincertezza associata ai risultati ottenuti tramite il campionamento di catene di Markov.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "title": "32¬† Linguaggio Stan",
    "section": "32.8 Stima delle Probabilit√† di Evento",
    "text": "32.8 Stima delle Probabilit√† di Evento\nLaplace non cercava semplicemente un valore specifico per \\(\\theta\\). Voleva sapere qual era la probabilit√† che \\(\\theta\\) fosse maggiore di \\(\\frac{1}{2}\\) dopo aver osservato \\(y\\) nascite maschili su un totale di \\(N\\) nascite. In termini di teoria della probabilit√†, voleva stimare la probabilit√† di un evento.\nUn sottoinsieme di parametri √® noto come evento. Possiamo convertire le condizioni sui parametri in eventi. Ad esempio, la condizione \\(\\theta &gt; \\frac{1}{2}\\) pu√≤ essere espressa come l‚Äôevento:\n\\[ A = \\left\\{ \\theta \\in \\Theta : \\theta &gt; \\frac{1}{2} \\right\\}. \\]\nData una misura di probabilit√†, la probabilit√† dell‚Äôevento \\(A\\), ossia che il tasso di nascite maschili sia superiore a quello delle nascite femminili, sar√† ben definita. Poich√© possiamo convertire le condizioni in eventi, possiamo trattarle come tali. Questo ci permette di scrivere \\(\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\, \\big| \\, N, y\\right]\\) per indicare la probabilit√† dell‚Äôevento \\(\\Theta &gt; \\frac{1}{2}\\).\n\n32.8.1 Probabilit√† di Evento tramite Indicatori\nLa funzione indicatrice \\(\\textrm{I}\\) assegna il valore 1 alle proposizioni vere e 0 a quelle false. Ad esempio, \\(\\textrm{I}(\\theta &gt; \\frac{1}{2}) = 1\\) se la proposizione \\(\\theta &gt; \\frac{1}{2}\\) √® vera, cio√® quando \\(\\theta\\) √® maggiore di un mezzo.\nLe probabilit√† di evento sono definite come aspettative condizionali posteriori delle funzioni indicatrici per eventi:\n\\[\n\\begin{align}\n\\Pr[\\Theta &gt; 0.5 \\mid N, y]\n&= \\mathbb{E}\\!\\left[\\textrm{I}[\\Theta &gt; 0.5] \\mid N, y\\right] \\\\\n&= \\int_{\\Theta} \\textrm{I}(\\theta &gt; 0.5) \\cdot p(\\theta \\mid N, y) \\, \\textrm{d}\\theta \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\textrm{I}(\\theta^{(m)} &gt; 0.5),\n\\end{align}\n\\]\ndove \\(\\theta^{(m)}\\) rappresenta i campioni dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\) per \\(m = 1, 2, \\ldots, M\\).\n\n\n32.8.2 Eventi come Indicatori in Stan\nIn Stan, possiamo codificare direttamente il valore della funzione indicatrice e assegnarlo a una variabile nel blocco delle quantit√† generate.\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\nLe espressioni condizionali come theta &gt; 0.5 assumono il valore 1 se sono vere e 0 se sono false. In notazione matematica, scriveremmo \\(\\textrm{I}(\\theta &gt; 0.5)\\), che assume valore 1 se \\(\\theta &gt; 0.5\\) e 0 altrimenti. In Stan, come in C++, trattiamo &gt; come un operatore binario che restituisce 0 o 1, quindi scriviamo semplicemente theta &gt; 0.5.\n\n\n32.8.3 La Risposta alla Domanda di Laplace\nLa media a posteriori della variabile boys_gt_girls √® quindi la nostra stima per \\(\\Pr[\\theta &gt; 0.5 \\mid N, y]\\). √à essenzialmente 1. Stampando a 15 cifre decimali, vediamo\n\nPr_boy_gt_girl = np.mean(boys_gt_girls_draws)\nprint(f\"estimated Pr[boy more likely] = {Pr_boy_gt_girl:.15f}\")\n\nestimated Pr[boy more likely] = 1.000000000000000\n\n\nCome possiamo vedere di seguito, tutti i nostri campioni per \\(\\theta\\) sono maggiori di \\(\\frac{1}{2}\\), ovvero boys_gt_girls_draws √® sempre uguale a 1:\n\nnp.unique(boys_gt_girls_draws)\n\narray([1.])\n\n\nIl valore 1 restituito come stima solleva l‚Äôimportante problema della precisione numerica. Laplace calcol√≤ il risultato analiticamente, che √®\n\\[\n\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\ \\bigg| \\ N, y\\right] \\approx 1 - 10^{-27}.\n\\]\nQuindi avremmo bisogno di un numero astronomico di campioni a posteriori prima di generare un valore di \\(\\theta\\) inferiore a \\(\\frac{1}{2}\\). Come detto, la risposta di 1.0 √® molto vicina alla risposta vera e ben entro il nostro errore Monte Carlo atteso.\n\n\n32.8.4 Statistiche di riepilogo MCMC da Stan\nCon Stan, possiamo ottenere un riepilogo completo della variabile \\(\\theta\\) nella distribuzione a posteriori. Per fare ci√≤, basta chiamare la funzione .summary() sul campione. Questo riepilogo include tutte le statistiche rilevanti.\n\nsample.summary(sig_figs = 3)\n\n\n\n\n\n\n\n\n\nMean\nMCSE\nStdDev\n5%\n50%\n95%\nN_Eff\nN_Eff/s\nR_hat\n\n\n\n\nlp__\n-149000.000\n0.004770\n6.720000e-01\n-149000.00\n-149000.000\n-149000.000\n19800.0\n51300.0\n1.0\n\n\ntheta\n0.512\n0.000009\n1.090000e-03\n0.51\n0.512\n0.513\n13700.0\n35400.0\n1.0\n\n\nboys_gt_girls\n1.000\nNaN\n9.380000e-14\n1.00\n1.000\n1.000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nL‚Äôistruzione print(sample.diagnose()) in Stan viene utilizzata per eseguire una diagnosi completa del campionamento MCMC. Questa funzione fornisce una serie di statistiche diagnostiche che aiutano a valutare la qualit√† e la convergenza del campionamento.\nQuesti sono alcuni degli aspetti che possono essere diagnosticati:\n\nConvergenza: La diagnosi verifica se le catene di Markov sono convergenti, ad esempio controllando il valore di \\(\\hat{R}\\). Un valore di \\(\\hat{R}\\) vicino a 1 indica che le catene sono ben mescolate e convergenti.\nAutocorrelazione: Fornisce informazioni sull‚Äôautocorrelazione delle catene, che pu√≤ influire sull‚Äôefficienza del campionamento. Bassa autocorrelazione √® desiderabile per ottenere campioni indipendenti.\nEfficienza del campionamento: Viene calcolata la dimensione del campione effettivo (\\(N_{\\text{eff}}\\)), che indica quanti campioni indipendenti equivarrebbero ai campioni correlati ottenuti.\nVarianza e Deviazione Standard: Viene riportata la varianza e la deviazione standard dei campioni, aiutando a comprendere la distribuzione a posteriori del parametro.\n\n\nprint(sample.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nUn grafico con le tracce si ottiene nel modo seguente:\n\n_ = az.plot_trace(sample, var_names=(\"theta\"), combined=False)",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#riscaldamento",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#riscaldamento",
    "title": "32¬† Linguaggio Stan",
    "section": "33.1 Riscaldamento",
    "text": "33.1 Riscaldamento\nDurante le fasi iniziali di riscaldamento, Stan cerca di trovare la regione di alta probabilit√† da cui campionare, adattare una buona dimensione del passo e stimare la varianza a posteriori. La varianza stimata viene utilizzata per migliorare l‚Äôefficienza del campionatore, un processo chiamato ‚Äúprecondizionamento‚Äù. Precondizionare significa ridimensionare i parametri per rendere il campionamento pi√π efficiente.\nStan pu√≤ anche stimare una matrice di covarianza completa, che rappresenta le relazioni tra tutti i parametri. Utilizzando questa matrice, Stan pu√≤ effettuare rotazioni e ridimensionamenti dei parametri per campionare in modo pi√π efficace. In questo contesto, ‚Äúrotazione e scalatura‚Äù si riferiscono alla trasformazione dei parametri in una nuova base (rotazione) e alla regolazione delle loro scale (scalatura) per facilitare il campionamento, rendendolo pi√π rapido e affidabile. Per ulteriori dettagli su questi processi, si pu√≤ fare riferimento a Neal (2011).\nIl riscaldamento converge quando la dimensione del passo e le stime della covarianza a posteriori diventano stabili. Con pi√π catene, √® possibile verificare che tutte convergano verso una dimensione del passo e una stima della covarianza simili. A meno che non ci siano problemi, generalmente non misuriamo la convergenza dell‚Äôadattamento, ma piuttosto se otteniamo campioni a posteriori ragionevoli dopo il riscaldamento.\nDurante la fase di riscaldamento, Stan non produce una catena di Markov coerente perch√© utilizza la memoria per adattarsi alle condizioni del modello. Questo adattamento serve a trovare i migliori parametri di campionamento. Tuttavia, una volta terminato il riscaldamento e iniziata la fase di campionamento, Stan inizia a produrre una vera e propria catena di Markov.\nLe nostre analisi a posteriori si baseranno esclusivamente sui campioni generati durante questa fase di campionamento, non sui campioni raccolti durante il riscaldamento. √à comunque possibile salvare ed esaminare i campioni del riscaldamento per comprendere meglio come il processo di adattamento √® avvenuto e se ci sono stati problemi.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#riduzione-potenziale-della-scala-e-widehatr",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#riduzione-potenziale-della-scala-e-widehatr",
    "title": "32¬† Linguaggio Stan",
    "section": "33.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)",
    "text": "33.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)\nStan utilizza la statistica di riduzione potenziale della scala \\(\\widehat{R}\\) (pronunciata ‚ÄúR hat‚Äù). Dato un insieme di catene di Markov, Stan divide ciascuna di esse a met√† per assicurarsi che la prima met√† e la seconda met√† della catena concordino, quindi calcola le varianze all‚Äôinterno di ciascuna catena e tra tutte le catene e le confronta. La statistica \\(\\widehat{R}\\) converge a 1 quando le catene di Markov convergono alla stessa distribuzione.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#quante-catene-per-quanto-tempo",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#quante-catene-per-quanto-tempo",
    "title": "32¬† Linguaggio Stan",
    "section": "33.3 Quante catene per quanto tempo?",
    "text": "33.3 Quante catene per quanto tempo?\nUna semplice regola empirica consiste nell‚Äôeseguire quattro catene finch√© \\(\\widehat{R} \\leq 1.01\\) e la dimensione campionaria effettiva (ESS) √® superiore a 100. La raccomandazione di avere una dimensione campionaria effettiva di ‚Äúsoli‚Äù 100 √® dovuta al fatto che questo valore implica un errore standard pari a \\(\\frac{1}{10}\\) della deviazione standard. Poich√© la deviazione standard a posteriori rappresenta l‚Äôincertezza residua, calcolare le medie con una precisione maggiore √® raramente utile.\nIl modo pi√π semplice per ottenere \\(\\widehat{R} \\leq 1.01\\) e \\(N_{\\text{eff}} &gt; 100\\) √® iniziare con 100 iterazioni di riscaldamento e 100 iterazioni di campionamento. Se i valori di \\(\\widehat{R}\\) sono troppo alti o se la dimensione campionaria effettiva √® troppo bassa, raddoppiare il numero di iterazioni di riscaldamento e di campionamento e riprovare. Eseguire pi√π iterazioni di riscaldamento √® importante perch√© il campionamento non sar√† efficiente se il riscaldamento non √® convergente. Utilizzare lo stesso numero di iterazioni di riscaldamento e di campionamento pu√≤ comportare un costo massimo doppio rispetto alle impostazioni ottimali, che non sono note in anticipo.\nAnche se si utilizzano pi√π di quattro catene, √® necessario assicurarsi che la dimensione campionaria effettiva sia almeno 25 per catena. Non √® tanto per l‚Äôinferenza, quanto per garantire la fiducia nello stimatore della dimensione campionaria effettiva, che non √® affidabile se √® molto inferiore. Un modo per verificare l‚Äôadeguatezza dello stimatore ESS √® raddoppiare il numero di campioni e assicurarsi che anche l‚ÄôESS raddoppi. Se ci√≤ non accade, significa che la prima stima dell‚ÄôESS non √® affidabile.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#esecuzione-delle-catene-contemporaneamente",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#esecuzione-delle-catene-contemporaneamente",
    "title": "32¬† Linguaggio Stan",
    "section": "33.4 Esecuzione delle catene contemporaneamente",
    "text": "33.4 Esecuzione delle catene contemporaneamente\n√à possibile impostare il numero di catene da eseguire utilizzando l‚Äôargomento chains del metodo sample(). Inoltre, √® possibile controllare quante catene possono essere eseguite contemporaneamente con l‚Äôargomento parallel_cores (che per default √® impostato su 1, ovvero esecuzione sequenziale).\nSe il numero massimo di catene parallele √® impostato troppo basso, le risorse della CPU potrebbero non essere sfruttate appieno. Al contrario, se √® impostato troppo alto, la CPU o la memoria potrebbero diventare il collo di bottiglia, rallentando le prestazioni complessive rispetto all‚Äôesecuzione con un numero inferiore di catene parallele.\nIn progetti personali sul nostro hardware, l‚Äôobiettivo √® solitamente ottenere la massima dimensione campionaria effettiva nel minor tempo possibile. Tuttavia, a volte √® necessario lasciare abbastanza potenza di elaborazione per continuare a lavorare su altre attivit√† come documenti, email, ecc.\n\n33.4.1 Matrici, Vettori o Array in Stan\nStan offre vari tipi di dati per gestire operazioni di algebra lineare e per definire strutture di dati pi√π generali come gli array. Capire le differenze tra questi tipi √® fondamentale per sapere cosa possiamo fare con essi e per ottimizzare la velocit√† di esecuzione del nostro modello.\n\nTipi di base per l‚Äôalgebra lineare:\n\nvector: un vettore colonna di dimensione N.\nrow_vector: un vettore riga di dimensione N.\nmatrix: una matrice di dimensioni N1 √ó N2.\n\nArray:\n\nGli array possono essere creati con qualsiasi tipo di elemento e possono avere pi√π dimensioni. Ad esempio:\n\narray[N] real a; definisce un array unidimensionale di numeri reali.\narray[N1, N2] real m; definisce un array bidimensionale di numeri reali.\n\n\nIntercambiabilit√† e limitazioni:\n\nAnche se possiamo usare sia vector che array per contenitori unidimensionali, l‚Äôalgebra matriciale (come la moltiplicazione) √® definita solo per vettori e matrici, non per array.\nAlcune funzioni, come normal_lpdf, accettano sia vettori che array.\n\nEsempi pratici:\n\nQuando definiamo una media (mu) come somma di un parametro (alpha) e il prodotto di un vettore di carichi (c_load) con un coefficiente (beta), dobbiamo usare i vettori:\nvector[N] mu = alpha + c_load * beta;\nPer utilizzare un generatore di numeri casuali (_rng) in modo vettoriale, dobbiamo usare un array:\narray[N] real p_size_pred = normal_rng(alpha + c_load * beta, sigma);\n\n\nIn sintesi, la scelta tra vector, row_vector, matrix e array dipende dalle operazioni che si desidera eseguire e dalle specifiche esigenze del modello. Scegliere il tipo di dato appropriato permette di sfruttare appieno le funzionalit√† di Stan e ottimizzare le prestazioni del modello.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#modello-di-esecuzione-di-stan",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#modello-di-esecuzione-di-stan",
    "title": "32¬† Linguaggio Stan",
    "section": "33.5 Modello di esecuzione di Stan",
    "text": "33.5 Modello di esecuzione di Stan\nI programmi Stan sono composti da diversi blocchi. Ecco una panoramica di ciascun blocco, di quando viene eseguito e di cosa fa. Nessuno di questi blocchi √® obbligatorio, ma se presenti, devono seguire quest‚Äôordine.\n\n\n\n\n\n\n\n\nBlocco\nQuando viene eseguito\nCosa fa\n\n\n\n\nfunctions\nsecondo necessit√†\nDefinizione delle funzioni create dall‚Äôutente\n\n\ndata\nuna volta\nLettura dei dati per costruire il modello\n\n\ntransformed data\nuna volta\nDefinizione dei dati trasformati\n\n\nparameters\nuna volta / densit√† logaritmica\nDefinizione dei parametri con i relativi vincoli\n\n\ntransformed parameters\nuna volta / densit√† logaritmica\nDefinizione dei parametri trasformati\n\n\nmodel\nuna volta / densit√† logaritmica\nValutazione della densit√† logaritmica del modello\n\n\ngenerated quantities\nuna volta / per estrazione\nDefinizione delle quantit√† generate\n\n\n\n\n33.5.1 Dati e dati trasformati\nIl blocco data contiene solo le dichiarazioni delle variabili. Queste variabili vengono lette una volta durante il caricamento dei dati.\nIl blocco transformed data contiene sia dichiarazioni che definizioni delle variabili. Questo blocco serve per calcolare nuove variabili a partire dai dati originali, come predittori standardizzati o costanti per i priori. Pu√≤ anche includere la generazione pseudocasuale di numeri. Viene eseguito una volta, dopo la lettura dei dati, per definire le nuove variabili trasformate.\nIn ogni blocco, tutte le variabili devono avere il loro tipo e dimensione dichiarati (che possono dipendere dai dati). Le variabili locali all‚Äôinterno dei blocchi, invece, sono dichiarate senza specificare la dimensione.\nI vincoli sulle variabili nel blocco data vengono controllati mentre i dati vengono letti, mentre quelli nel blocco transformed data vengono verificati alla fine dell‚Äôesecuzione del blocco. Se ci sono violazioni dei vincoli nei dati o nei dati trasformati, si genera un‚Äôeccezione che interrompe l‚Äôesecuzione del programma.\nLe variabili definite nel blocco transformed data possono essere assegnate una volta, ma non possono essere riassegnate dopo l‚Äôesecuzione del blocco.\n\n\n33.5.2 Parametri e Parametri Trasformati\nIl blocco parameters serve a dichiarare le variabili su cui √® basato il modello. In pratica, si tratta di elencare i parametri che il modello utilizzer√†, specificandone le dimensioni. Quando il blocco viene eseguito, vengono forniti i valori concreti di questi parametri.\nI vincoli sui parametri sono utilizzati per trasformare le variabili vincolate in variabili non vincolate. Ad esempio, se una variabile ha un vincolo lower=0 (cio√® deve essere maggiore o uguale a zero), questa variabile viene trasformata usando il logaritmo per renderla non vincolata. √à essenziale dichiarare tutti i vincoli necessari sui parametri affinch√© il modello funzioni correttamente su tutto lo spazio dei parametri.\nIl blocco transformed parameters permette di definire nuove variabili che sono funzioni dei parametri originali e dei dati. Gli utenti possono creare le loro trasformazioni dei parametri in questo blocco. I vincoli su queste nuove variabili vengono verificati alla fine dell‚Äôesecuzione del blocco. Se questi vincoli non sono rispettati, viene generata un‚Äôeccezione che di solito porta al rifiuto della proposta corrente.\nLe variabili dichiarate nel blocco parameters sono simili agli argomenti di una funzione: la funzione di densit√† logaritmica del programma Stan prende questi parametri come input. Quindi, i valori dei parametri vengono sempre forniti dall‚Äôesterno del programma Stan.\nDopo l‚Äôesecuzione del blocco transformed parameters, le variabili dichiarate in esso non possono essere modificate ulteriormente.\nLa differenza principale tra le variabili dichiarate come locali nel blocco model e quelle nel blocco transformed parameters √® che le variabili trasformate vengono stampate e sono disponibili anche nel blocco generated quantities.\n\n\n33.5.3 Modello\nLo scopo del blocco model √® definire la funzione che calcola la densit√† logaritmica del modello. Una volta caricati i dati, il compito principale di un programma Stan √® fornire questa funzione di densit√† logaritmica non normalizzata sui parametri non vincolati. Algoritmi esterni, come ottimizzatori, campionatori o metodi di inferenza variazionale, forniranno i valori dei parametri non vincolati per la valutazione.\nIl valore della densit√† logaritmica non normalizzata calcolato dal modello viene conservato in una variabile chiamata target. Le densit√† posteriori (che ci interessano) sono calcolate moltiplicando i fattori delle funzioni di densit√† o massa di probabilit√†. In termini logaritmici, questo equivale ad aggiungere i termini delle funzioni di densit√† o massa non normalizzate alla target.\nL‚Äôaccumulatore target parte da zero e viene incrementato durante l‚Äôesecuzione del programma Stan. Come accennato prima, la prima cosa che questa funzione di densit√† logaritmica non normalizzata fa √® trasformare i parametri vincolati in non vincolati e aggiungere un aggiustamento logaritmico per il cambio di variabili alla target. Questo processo √® automatico e fornisce i valori dei parametri trasformati al codice che verr√† eseguito successivamente nel blocco model.\nLa densit√† logaritmica accumulata in target pu√≤ essere incrementata direttamente, come mostrato nell‚Äôesempio seguente:\ntarget += -0.5 * x^2;\nAnche se non √® possibile usare direttamente target come variabile, il suo valore attuale pu√≤ essere recuperato tramite la funzione target(), utile per il debugging.\nLe istruzioni di campionamento sono una scorciatoia per incrementare target. Ad esempio, l‚Äôistruzione\nx ~ normal(0, 1);\n√® equivalente a\ntarget += normal_lupdf(x | 0, 1);\nQui, _lupdf indica che si tratta di una funzione di densit√† di probabilit√† logaritmica non normalizzata.\nLa barra verticale | √® utilizzata per separare le variabili osservate dai parametri. La notazione lpdf denota una funzione di densit√† di probabilit√† logaritmica, mentre lpmf indica una funzione di massa di probabilit√† logaritmica. Le varianti lupdf e lupmf sono le loro controparti non normalizzate, che possono omettere le costanti di normalizzazione che non dipendono dai parametri. A meno che non siano necessarie, ad esempio in un componente di un modello di mescolanza, √® pi√π efficiente usare le forme lupdf e lupmf incrementando direttamente target o tramite istruzioni di campionamento.\n\n\n33.5.4 Quantit√† generate\nIl blocco generated quantities viene eseguito una volta per ogni campione generato, anzich√© ogni volta che viene calcolata la densit√† logaritmica. Con algoritmi come il campionamento Monte Carlo Hamiltoniano, ogni campione pu√≤ richiedere diverse valutazioni della densit√† logaritmica.\nUn vantaggio delle quantit√† generate √® che vengono calcolate utilizzando numeri in virgola mobile a doppia precisione, il che le rende molto efficienti. Questo blocco pu√≤ anche utilizzare numeri pseudocasuali. I vincoli sui dati generati vengono verificati alla fine del blocco, ma eventuali errori non causano il rigetto del campione, solo possibili avvertimenti o valori non definiti (NaN).\nLe quantit√† generate non influenzano il calcolo della densit√† logaritmica, ma sono comunque una parte importante del modello statistico. Sono utilizzate principalmente per fare previsioni su nuovi dati, basandosi sui parametri stimati dal modello. Questo processo √® noto come inferenza predittiva posteriore. In altre parole, ci permette di fare previsioni su nuovi dati utilizzando i valori dei parametri generati dal modello.\nEsempi di utilizzo delle quantit√† generate includono la previsione di nuovi valori o il calcolo di statistiche derivate dai parametri stimati. Le quantit√† generate offrono un modo per esplorare ulteriormente il comportamento del modello e fare inferenze utili dai dati simulati.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "title": "32¬† Linguaggio Stan",
    "section": "33.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "33.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "",
    "text": "33.1 Introduzione\nI modelli lineari sono stati utilizzati in varie forme per molto tempo. Stigler (1986) descrive come il metodo dei minimi quadrati, una tecnica per adattare una semplice regressione lineare, fosse associato a problemi fondamentali in astronomia nel 1700, come la determinazione del moto della luna e la riconciliazione del moto non periodico di Giove e Saturno. All‚Äôepoca, gli astronomi erano tra i primi a sentirsi a proprio agio nell‚Äôutilizzare questi metodi, poich√© raccoglievano personalmente le loro osservazioni e sapevano che le condizioni di raccolta dei dati erano simili, anche se i valori delle osservazioni differivano. Questo contrastava con l‚Äôapproccio pi√π cauto delle scienze sociali, dove la riluttanza a combinare dati eterogenei ritardava l‚Äôadozione dei modelli lineari (Stigler 1986).\nCome nota Alexander (2023), quando costruiamo modelli, non stiamo scoprendo ‚Äúla verit√†‚Äù. Un modello non pu√≤ essere una rappresentazione fedele della realt√†. Utilizziamo i modelli per esplorare e comprendere i nostri dati. Non esiste un modello migliore in assoluto, ma solo modelli utili che ci aiutano a imparare qualcosa sui dati che abbiamo e, si spera, qualcosa sul mondo da cui sono stati generati. Quando utilizziamo i modelli, cerchiamo di comprendere il mondo, ma ci sono limiti alla prospettiva che portiamo in questo. Non dovremmo semplicemente inserire dati in un modello sperando che risolva tutto. Non lo far√†.\nI modelli scientifici sono strumenti essenziali per comprendere la realt√† che ci circonda. Il processo di creazione, esplorazione e analisi di questi modelli √® fondamentale per approfondire la nostra conoscenza del mondo. Questo processo si pu√≤ suddividere in diverse fasi:\n√à importante sottolineare che il valore principale di questo processo non risiede nel risultato finale, cio√® nel modello stesso, ma nell‚Äôapprendimento e nella comprensione che otteniamo durante il percorso. Anche se a volte il modello finale pu√≤ effettivamente rappresentare accuratamente la realt√†, √® il processo di sviluppo e analisi che ci fornisce intuizioni preziose.\nQuando lavoriamo con i modelli, dobbiamo considerare due aspetti cruciali:\n√à fondamentale riconoscere che i dati su cui basiamo i nostri modelli spesso non sono perfettamente rappresentativi della realt√†. Questo pu√≤ essere dovuto a limitazioni nella raccolta dei dati, bias nei campioni o semplicemente alla complessit√† del mondo reale. Di conseguenza, i modelli addestrati su questi dati, sebbene utili, non sono infallibili.\nCome gi√† rilevato nel Capitolo 10, per utilizzare efficacemente i modelli, dobbiamo porci costantemente due domande chiave:\nMantenere queste domande in primo piano ci aiuta a utilizzare i modelli in modo critico e consapevole, riconoscendone sia il potenziale che i limiti. Questo approccio ci permette di sfruttare al meglio i modelli come strumenti per comprendere il mondo, pur rimanendo consapevoli delle loro imperfezioni e delle sfide nella rappresentazione della realt√† complessa.\nL‚Äôevoluzione e l‚Äôapplicazione dei metodi statistici moderni presentano un interessante caso di studio nell‚Äôadattamento degli strumenti scientifici a contesti in rapida evoluzione. Molti dei metodi statistici attualmente in uso trovano le loro radici in campi come l‚Äôastronomia e l‚Äôagricoltura. Un esempio emblematico √® rappresentato da Ronald Fisher, figura di spicco nello sviluppo della statistica moderna, le cui opere seminali furono concepite durante il suo periodo presso un istituto di ricerca agricola.\nTuttavia, il panorama scientifico e tecnologico ha subito profondi cambiamenti dall‚Äôepoca di Fisher. L‚Äôapplicazione di questi metodi statistici si √® estesa a contesti che i loro ideatori difficilmente avrebbero potuto prevedere. Questa espansione solleva interrogativi cruciali sulla validit√† delle assunzioni fondamentali di questi metodi quando applicati in ambiti cos√¨ diversi da quelli originari.\nIn conclusione, mentre la statistica rimane uno strumento di inestimabile valore, il suo utilizzo efficace richiede un equilibrio tra una solida conoscenza dei principi fondamentali e la flessibilit√† necessaria per adattarsi a scenari di ricerca in continua evoluzione. L‚Äôintegrazione di metodologie diverse √® essenziale per garantire l‚Äôaffidabilit√† e la robustezza dei modelli statistici. Solo attraverso questo approccio olistico e adattativo possiamo sperare di comprendere e interpretare adeguatamente la complessit√† del mondo contemporaneo.\nIn questo capitolo, esploreremo due modelli statistici fondamentali: la regressione lineare bivariata e la regressione lineare multipla. La prima considera una sola variabile esplicativa, mentre la seconda ne include diverse. Per ciascun modello, esamineremo due approcci distinti:\n√à importante sottolineare che i modelli statistici sono generalmente ottimizzati per uno di due scopi: l‚Äôinferenza o la previsione. La focalizzazione sulla previsione √® una caratteristica distintiva del machine learning, un campo tradizionalmente dominato da Python. Tuttavia, in R, il pacchetto tidymodels offre ora funzionalit√† simili.\nIndipendentemente dall‚Äôapproccio scelto, √® fondamentale tenere presente che l‚Äôanalisi di regressione √® essenzialmente una forma di media ponderata. Di conseguenza, i risultati ottenuti riflettono inevitabilmente i bias e le peculiarit√† del dataset utilizzato.\nInfine, una nota sulla terminologia e sulla notazione. Per ragioni storiche e specifiche del contesto, esistono vari termini usati per descrivere la stessa idea nella letteratura. Seguiamo Gelman, Hill, e Vehtari (2020) e utilizziamo i termini ‚Äúoutcome‚Äù e ‚Äúpredictor‚Äù, e la specificazione del modello bayesiano di McElreath (2020).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#introduzione",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#introduzione",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "",
    "text": "La regressione √® in effetti un oracolo, ma un oracolo crudele. Parla per enigmi e si diletta nel punirci per aver posto domande sbagliate.\nMcElreath (2020)\n\n\n\nCostruzione: Creiamo modelli basati sulle nostre attuali conoscenze e ipotesi.\nEsplorazione: Studiamo le caratteristiche e le implicazioni dei modelli creati.\nVerifica: Testiamo i modelli confrontandoli con dati reali e osservazioni.\nValutazione: Apprezziamo l‚Äôeleganza e l‚Äôefficacia dei modelli quando funzionano bene.\nAnalisi critica: Cerchiamo di comprendere i limiti e le debolezze dei nostri modelli.\nRevisione o sostituzione: Quando necessario, modifichiamo o abbandoniamo i modelli inadeguati.\n\n\n\n\nIl ‚Äúmondo del modello‚Äù: le assunzioni, le semplificazioni e le regole interne del modello stesso.\nIl ‚Äúmondo reale‚Äù: la realt√† pi√π ampia e complessa che stiamo cercando di comprendere e descrivere.\n\n\n\n\nIn che misura il modello ci insegna qualcosa sui dati che abbiamo a disposizione?\nQuanto accuratamente i dati che abbiamo riflettono il mondo reale su cui vogliamo trarre conclusioni?\n\n\n\n\n\n\n\nL‚Äôutilizzo di R base, concentrandoci sulle funzioni lm() e glm() (oppure le funzioni di pingouin in Python). Queste sono particolarmente utili per l‚Äôanalisi esplorativa dei dati (EDA) quando si necessita di risultati rapidi.\nL‚Äôapproccio bayesiano, ideale quando l‚Äôobiettivo principale √® l‚Äôinferenza statistica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.2 Modellare l‚Äôassociazione statistica tra variabili",
    "text": "33.2 Modellare l‚Äôassociazione statistica tra variabili\nPer introdurre l‚Äôapproccio bayesiano al modello di regressione, esamineremo un set di dati che riguarda la relazione tra la temperatura media e gli introiti (in dollari) di un particolare negozio di gelati. Sebbene questa possa non sembrare una questione scientifica particolarmente entusiasmante, √® un esempio semplice e intuitivo da analizzare. La relazione tra consumo di gelati e temperatura pu√≤ apparire banale, ma offre una chiara opportunit√† per comprendere i meccanismi alla base dell‚Äôassociazione tra due variabili. In questo momento, ci concentreremo esclusivamente sui metodi per stimare tale associazione.\nIn precedenza, abbiamo applicato il modello Normale ad una singola variabile. Tuttavia, di solito siamo interessati a modellare come una variabile di esito sia correlata a un‚Äôaltra variabile predittiva. Se la variabile predittiva ha una qualche associazione statistica con la variabile di esito, possiamo utilizzarla per predire il risultato. Quando la variabile predittiva √® integrata nel modello in un modo specifico, otteniamo una regressione lineare.\nI dati dell‚Äôesempio sono forniti di seguito.\n\ndata = {\n    \"temperature\": [\n        14.2,\n        16.4,\n        11.9,\n        15.2,\n        18.5,\n        22.1,\n        19.4,\n        25.1,\n        23.4,\n        18.1,\n        22.6,\n        17.2,\n    ],\n    \"icecream\": [215, 325, 185, 332, 406, 522, 412, 614, 544, 421, 445, 408],\n}\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n\n\n\n\ntemperature\nicecream\n\n\n\n\n0\n14.2\n215\n\n\n1\n16.4\n325\n\n\n2\n11.9\n185\n\n\n3\n15.2\n332\n\n\n4\n18.5\n406\n\n\n\n\n\n\n\n\nL‚Äôassociazione tra le due variabili (gli introiti derivanti dalla vendita di gelati e la temperatura) √® chiaramente visualizzata nel grafico seguente. Il grafico indica che l‚Äôassociazione tra le due variabili pu√≤ essere approssimata da una semplice funzione matematica, ovvero una retta. Tuttavia, √® evidente che una funzione lineare sia troppo semplice per rappresentare accuratamente questi dati: non √® possibile trovare una singola retta che passi per tutti i punti del diagramma di dispersione.\n\nplt.scatter(df[\"temperature\"], df[\"icecream\"], color=\"blue\")\nplt.xlabel(\"Temperature (¬∞C)\")\nplt.ylabel(\"Ice Cream Sales ($)\")\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-generativo-dei-dati",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-generativo-dei-dati",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.3 Modello Generativo dei Dati",
    "text": "33.3 Modello Generativo dei Dati\nPer descrivere la relazione tra introiti e temperatura, utilizzeremo un modello statistico lineare. Assumeremo che la relazione media tra \\(x\\) (temperatura) e \\(y\\) (introiti) possa essere rappresentata da una retta, ma influenzata da un certo grado di errore. Supponiamo che questo errore sia costante ai vari livelli di \\(x\\) e segua una distribuzione Normale. Inoltre, presupponiamo che gli errori attorno alla retta di regressione siano indipendenti tra loro.\nIn questo contesto, le nostre assunzioni delineano un modello statistico lineare, formalizzato come segue:\n\\[ y_i = \\alpha + \\beta x_i + \\epsilon_i \\]\ndove: - \\(\\alpha\\) √® l‚Äôintercetta, - \\(\\beta\\) √® il coefficiente angolare, - \\(\\epsilon_i \\sim \\text{Normale}(0, \\sigma^2)\\) rappresenta l‚Äôerrore, con media zero e varianza costante \\(\\sigma^2\\).\nQueste assunzioni ci permettono di applicare metodi di regressione lineare per stimare i parametri del modello (\\(\\alpha\\) e \\(\\beta\\)) e quantificare l‚Äôincertezza delle predizioni, considerando la variabilit√† nei dati.\nIl modello lineare descritto sopra costituisce il modello generativo dei dati (verosimiglianza):\n\\[ y_n = \\alpha + \\beta x_n + \\epsilon_n \\]\no equivalentemente\n\\[ \\epsilon_n \\sim \\text{Normale}(0, \\sigma) \\]\nQuesto modello descrive come i dati $ y_n $ sono generati. Ogni osservazione $ y_n $ √® una combinazione lineare di una costante \\(\\alpha\\) (intercetta), un coefficiente \\(\\beta\\) che moltiplica il valore della variabile $ x_n $ (temperatura), e un termine di errore \\(\\epsilon_n\\) che cattura la variabilit√† non spiegata dal modello lineare.\nIl termine di errore \\(\\epsilon_n\\) √® distribuito secondo una distribuzione normale con media 0 e deviazione standard \\(\\sigma\\). Questo implica che l‚Äôerrore √® simmetricamente distribuito attorno a zero e ha una variabilit√† definita da \\(\\sigma\\).\nL‚Äôequazione\n\\[ y_n \\sim \\text{Normale}(\\alpha + \\beta x_n, \\sigma) \\]\nmostra come il valore osservato $ y_n $ segue una distribuzione normale con media \\(\\alpha + \\beta x_n\\) e deviazione standard \\(\\sigma\\). Questo significa che, dato $ x_n $, i valori di $ y_n $ sono distribuiti normalmente attorno alla retta di regressione definita da \\(\\alpha + \\beta x_n\\).\nConsideriamo il caso in cui $ y_n $ rappresenta le vendite di gelati e $ x_n $ rappresenta la temperatura media. Secondo il nostro modello:\n\n\\(\\alpha\\) √® l‚Äôintercetta, ovvero le vendite di gelati previste quando la temperatura √® zero.\n\\(\\beta\\) √® il coefficiente che indica quanto aumentano (o diminuiscono) le vendite di gelati per ogni aumento di un grado della temperatura.\n\\(\\sigma\\) √® la deviazione standard che misura la variabilit√† delle vendite di gelati attorno alla media prevista dal modello.\n\nQuesto modello ci consente di stimare l‚Äôeffetto della temperatura sulle vendite di gelati e di quantificare l‚Äôincertezza associata a queste stime.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-bayesiano-della-regressione-bivariata",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#modello-bayesiano-della-regressione-bivariata",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.4 Modello Bayesiano della Regressione Bivariata",
    "text": "33.4 Modello Bayesiano della Regressione Bivariata\n\n33.4.1 Verosimiglianza\nAssumiamo la verosimiglianza che abbiamo descritto in precedenza:\n\\[ y \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma) \\]\nQuesto significa che i dati \\(y\\) seguono una distribuzione normale con media \\(\\alpha + \\beta x\\) e deviazione standard \\(\\sigma\\). In altre parole, il valore osservato \\(y\\) √® generato come una combinazione lineare di \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente della variabile \\(x\\)), pi√π un errore che segue una distribuzione normale con deviazione standard \\(\\sigma\\).\n\n\n33.4.2 Distribuzioni a Priori\nIn una prima versione del modello, useremo delle distribuzioni a priori uniformi per i tre parametri.\n\n\n33.4.3 Distribuzioni a Posteriori\nLe distribuzioni a priori vengono combinate con i dati osservati attraverso il teorema di Bayes per aggiornare le nostre credenze sui parametri del modello. Il risultato √® una distribuzione a posteriori per ciascun parametro che riflette sia l‚Äôinformazione contenuta nei dati che le credenze iniziali incorporate nelle distribuzioni a priori. Questo processo permette di fare inferenze pi√π robuste, specialmente quando i dati sono limitati o rumorosi.\n\n\n33.4.4 Codice Stan\nIl codice Stan che implementa il modello precedente √® contenuto nel file icecream_model_1.stan. Compiliamo e stampiamo il modello.\n\nstan_file = os.path.join(project_directory, 'stan', 'icecream_model_1.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSi noti che, non avendo specificato le distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), Stan assume distribuzioni a priori uniformi.\n\n\n33.4.5 Dizionario con i dati\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\n    \"N\": len(df[\"temperature\"]),\n    \"x\": df[\"temperature\"],\n    \"y\": df[\"icecream\"]\n}\nprint(stan_data)\n\n{'N': 12, 'x': 0     14.2\n1     16.4\n2     11.9\n3     15.2\n4     18.5\n5     22.1\n6     19.4\n7     25.1\n8     23.4\n9     18.1\n10    22.6\n11    17.2\nName: temperature, dtype: float64, 'y': 0     215\n1     325\n2     185\n3     332\n4     406\n5     522\n6     412\n7     614\n8     544\n9     421\n10    445\n11    408\nName: icecream, dtype: int64}\n\n\n\n\n33.4.6 Campionamento MCMC\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n\n\n33.4.7 Distribuzioni a posteriori\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]))\n\n\n\n\n\n\n\n\nL‚Äôoggetto fit generato da cmdstanpy appartiene alla classe cmdstanpy.stanfit.mcmc.CmdStanMCMC. Questo oggetto √® funzionalmente equivalente a un oggetto della classe InferenceData, permettendo quindi la sua manipolazione tramite le funzioni fornite da ArviZ. Esaminiamo dunque un sommario delle distribuzioni a posteriori dei parametri del modello lineare.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-158.315\n64.516\n-271.588\n-28.269\n1.429\n1.010\n2051.0\n2311.0\n1.0\n\n\nbeta\n30.032\n3.372\n23.574\n36.268\n0.074\n0.053\n2065.0\n2329.0\n1.0\n\n\nsigma\n44.162\n12.121\n25.540\n66.813\n0.270\n0.195\n2120.0\n2226.0\n1.0\n\n\n\n\n\n\n\n\nAvendo definito nel modello il predittore lineare come \\(x - \\bar{x}\\), l‚Äôintercetta corrisponder√† alla media dei valori dell‚Äôaltezza. La pendenza \\(\\beta\\) ci informa sull‚Äôincremento atteso dell‚Äôaltezza quando il peso aumenta di un‚Äôunit√†. Il parametro \\(\\sigma\\) descrive la deviazione standard della dispersione dei dati attorno alla retta di regressione.\nConfrontiamo i valori ottenuti con l‚Äôapproccio bayesiano con quelli trovati usando la procedura di massima verosimiglianza.\n\nlm = pg.linear_regression(df[\"temperature\"], df[\"icecream\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-159.47\n54.64\n-2.92\n0.02\n0.92\n0.91\n-281.22\n-37.73\n\n\n1\ntemperature\n30.09\n2.87\n10.50\n0.00\n0.92\n0.91\n23.70\n36.47\n\n\n\n\n\n\n\n\nLa somiglianza tra le due soluzioni conferma che, nel caso di modelli semplici come questo, e quando vengono usati dei prior non informativi, i due approcci producono risultati sostanzialmente equivalenti.\n\n\n33.4.8 Interpretazione\nPossiamo interpretare i parametri come segue:\n\nLa media a posteriori di \\(\\alpha = -159.47\\) indica che il valore atteso degli introiti del negozio di gelati √® di -159.47 dollari quando la temperatura √® di 0 gradi centigradi.\nLa media a posteriori di \\(\\beta = 30.09\\) suggerisce che ci aspettiamo un aumento medio di 30.09 dollari negli introiti del negozio di gelati per ogni incremento di 1 grado centigrado nella temperatura.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#predizione",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#predizione",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.5 Predizione",
    "text": "33.5 Predizione\nLa distribuzione a posteriori non contiene solo informazioni su ciascun parametro singolarmente, ma anche sulle dipendenze tra i parametri. Queste dipendenze sono riflesse nei campioni a posteriori che possono essere trasformati arbitrariamente.\nAd esempio, supponiamo che alpha e beta siano vettori di campioni a posteriori.\nCon l‚Äôistruzione seguente nel blocco generated quantities, possiamo calcolare la predizione a posteriori per 30 gradi Celsius:\npred = alpha + beta * 30;\nModifichiamo il modello Stan per aggiungere il blocco generated quantities con questa istruzione e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_2.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  real pred; // predizione\n  \n  pred = alpha + beta * 30;\n}\n\n\n\nIn questo modello Stan aggiornato, il blocco generated quantities calcola la predizione a posteriori pred per una variabile predittore con valore 30. Questa aggiunta consente di ottenere la distribuzione a posteriori della predizione per un determinato valore del predittore.\nEseguiamo il campionamento.\n\nfit2 = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la stima a posteriori dell‚Äôintroito previsto per il negozio di gelati quando la temperatura raggiunge i 30 gradi Celsius. Questa analisi fornir√† sia una stima puntuale dell‚Äôintroito che una misura dell‚Äôincertezza associata, rappresentata dall‚Äôintervallo di credibilit√† al livello di confidenza prescelto.\n\naz.summary(fit2, var_names=([\"pred\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npred\n742.651\n40.123\n664.016\n816.924\n0.818\n0.579\n2409.0\n3196.0\n1.0\n\n\n\n\n\n\n\n\n\n33.5.1 Quantificazione dell‚Äôincertezza\nPer quantificare l‚Äôincertezza nelle predizioni del modello, possiamo estendere il metodo esaminato in precedenza per calcolare la distribuzione a posteriori delle predizioni per tutti i valori di \\(x\\) considerati. Questo ci permette di ottenere non solo le stime puntuali delle predizioni, ma anche una misura dell‚Äôincertezza associata a ciascuna predizione.\nPer fare ci√≤, modifichiamo il blocco generated quantities nel seguente modo:\ngenerated quantities {\n  vector[N] y_rep; // predizioni a posteriori per ciascun valore di x\n  \n  for (n in 1:N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\nEsaminiamo nei dettagli la modifica allo script Stan.\n\nDichiarazione del vettore y_rep:\n\nvector[N] y_rep;: Questa linea dichiara un vettore y_rep di lunghezza N che conterr√† le predizioni a posteriori per ciascun valore di x.\n\nCiclo for per generare le predizioni:\n\nfor (n in 1:N): Questo ciclo iterativo va da 1 a N, cio√® copre tutte le osservazioni.\ny_rep[n] = normal_rng(alpha + beta * x[n], sigma);: Per ogni valore di x[n], questa linea genera una predizione dalla distribuzione normale con media alpha + beta * x[n] e deviazione standard sigma. La funzione normal_rng √® utilizzata per generare numeri casuali dalla distribuzione normale specificata, rappresentando cos√¨ l‚Äôincertezza nelle predizioni.\n\n\n\nQuesto approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell‚Äôincertezza associata a ciascuna predizione.\nDalla distribuzione a posteriori di y_rep, possiamo calcolare sia la stima puntuale (ad esempio, la media o la mediana delle predizioni) sia gli intervalli di credibilit√† (ad esempio, l‚Äôintervallo al 95%) per ogni valore di x. Questo offre una misura dell‚Äôincertezza delle predizioni, riflettendo la variabilit√† e l‚Äôaffidabilit√† del modello.\n\nIn sintesi, questa modifica ci permette di valutare l‚Äôincertezza delle predizioni del modello in modo robusto e dettagliato, migliorando la comprensione della performance del modello e della sua capacit√† predittiva.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_3.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // variabili predette\n  \n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\n\nfit3 = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nCostruiamo ora un grafico che rappresenta i valori osservati insieme alla linea di regressione stimata tramite il modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ciascuna orientata in base ai valori campionati casualmente dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\n\n# Extract posterior samples\nalpha_samples = fit3.stan_variable(\"alpha\")\nbeta_samples = fit3.stan_variable(\"beta\")\n\n\n# Plot y vs x\nx = df[\"temperature\"] \nplt.scatter(x, df[\"icecream\"], color=\"blue\", label=\"Data\", s=10)  # s is the size of the point\n\n# Draw lines from posterior samples\nfor i in range(300):  # assuming you have at least 300 samples\n    plt.plot(\n        x,\n        alpha_samples[i] + beta_samples[i] * x,\n        color=\"gray\",\n        linestyle=\"-\",\n        linewidth=0.5,\n        alpha=0.05,\n    )\n\n# Line using the mean of posterior estimates\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\nplt.plot(\n    x,\n    mean_alpha + mean_beta * x,\n    color=\"red\",\n    linewidth=2,\n    label=\"Mean Posterior Prediction\",\n)\n\n# Additional plot formatting\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Regression with Posterior Samples\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLe numerose linee di regressione presenti nel grafico visualizzano la nostra incertezza riguardo l‚Äôinclinazione esatta della linea di regressione principale. Tuttavia, il grafico mostra chiaramente che questa incertezza √® minima.\nPossiamo procedere in un altro modo per descrivere l‚Äôincertezza della stima. Anzich√© utilizzare le distribuzioni a posteriori di alpha e beta, possiamo utilizzare la distribuzione a posteriori di y_rep. Procedendo in questo modo otteniamo il grafico mostrato qui sotto.\nIn questo plot, la linea rossa rappresenta la media delle predizioni a posteriori, mentre l‚Äôarea grigia rappresenta l‚Äôintervallo di credibilit√† al 95%, mostrando l‚Äôincertezza delle predizioni del modello. Questo approccio fornisce una visione pi√π completa e realistica dell‚Äôincertezza nelle predizioni rispetto all‚Äôapproccio che utilizza solo alpha e beta.\n\n# Estrai i campioni posteriori di y_rep\ny_rep_samples = fit3.stan_variable(\"y_rep\")\n\n# Calcola la media e l'intervallo di credibilit√† (ad esempio, 95%) per y_rep\ny_rep_mean = np.mean(y_rep_samples, axis=0)\ny_rep_lower = np.percentile(y_rep_samples, 2.5, axis=0)\ny_rep_upper = np.percentile(y_rep_samples, 97.5, axis=0)\n\n# Plot y vs x\nx = df[\"temperature\"]\ny = df[\"icecream\"]\nplt.scatter(x, y, color=\"blue\", label=\"Dati\", s=10)\n\n# Plot della media delle predizioni a posteriori\nplt.plot(x, y_rep_mean, color=\"red\", linewidth=2, label=\"Media delle predizioni\")\n\n# Plot dell'intervallo di credibilit√†\nplt.fill_between(\n    x,\n    y_rep_lower,\n    y_rep_upper,\n    color=\"gray\",\n    alpha=0.3,\n    label=\"Intervallo di credibilit√† 95%\",\n)\n\n# Formattazione del plot\nplt.xlabel(\"Temperatura (Celsius)\")\nplt.ylabel(\"Vendite di gelati\")\nplt.title(\"Incertezza delle predizioni del modello\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNel primo approccio, calcoliamo l‚Äôincertezza delle predizioni utilizzando le distribuzioni a posteriori di alpha e beta. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di alpha e beta, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri alpha e beta. Questo metodo visualizza come l‚Äôincertezza nei parametri del modello si traduce in incertezza nelle predizioni.\nNel secondo approccio, descriviamo l‚Äôincertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di y_rep. In questo caso, generiamo predizioni per ciascun valore osservato di x nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l‚Äôincertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.\nLe due descrizioni dell‚Äôincertezza delle predizioni del modello sono diverse perch√© riflettono aspetti differenti della distribuzione a posteriori:\n\nDistribuzione a posteriori di alpha e beta: Questo approccio considera solo l‚Äôincertezza nei parametri del modello (alpha e beta). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell‚Äôincertezza residua (sigma).\nDistribuzione a posteriori di y_rep: Questo approccio include non solo l‚Äôincertezza nei parametri alpha e beta, ma anche l‚Äôincertezza residua (sigma). La distribuzione di y_rep riflette la variabilit√† totale nel modello, inclusa la variabilit√† nei dati osservati. Pertanto, l‚Äôincertezza nelle predizioni √® maggiore perch√© tiene conto di tutte le fonti di variabilit√†.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#ricodifica-dei-dati",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#ricodifica-dei-dati",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.6 Ricodifica dei dati",
    "text": "33.6 Ricodifica dei dati\nL‚Äôintercetta (\\(\\alpha\\)) corrisponde al valore atteso degli introiti quando la temperatura √® di 0 gradi centigradi. Un valore negativo dell‚Äôintercetta indica che, in tali circostanze, ci aspettiamo una perdita. Tuttavia, possiamo ricodificare i dati in modo che l‚Äôintercetta abbia un‚Äôinterpretazione pi√π utile.\n\n33.6.1 Centratura della variabile $ x $\nCentriamo la variabile \\(x\\) (temperatura), sottraendo la media della temperatura (\\(\\bar{x}\\)) da ciascun valore di \\(x\\). In questo modo otteniamo la nuova variabile \\(xc\\) la cui media √® 0. La trasformazione √® definita come:\n\\[ xc_i = x_i - \\bar{x} \\]\nDove \\(\\bar{x}\\) √® la media della temperatura.\n\n\n33.6.2 Interpretazione della nuova intercetta\nIl valore 0 di \\(xc\\) corrisponde al valore medio di \\(x\\). Dato che la retta di regressione passa per il punto \\((\\bar{x}, \\bar{y})\\), se utilizziamo \\(xc\\) al posto di \\(x\\), la nuova intercetta (\\(\\alpha\\)) ci dir√† qual √® il valore atteso degli introiti (\\(y\\)) quando la temperatura assume il suo valore medio (\\(\\bar{x}\\)).\n\n# Calcolo della temperatura media\nmean_temp = df[\"temperature\"].mean()\n\n# Creazione della variabile centrata\ndf[\"temp_c\"] = df[\"temperature\"] - mean_temp\n\n\nstan_data2 = {\"N\": len(df[\"temp_c\"]), \"x\": df[\"temp_c\"], \"y\": df[\"icecream\"]}\nprint(stan_data2)\n\n{'N': 12, 'x': 0    -4.475\n1    -2.275\n2    -6.775\n3    -3.475\n4    -0.175\n5     3.425\n6     0.725\n7     6.425\n8     4.725\n9    -0.575\n10    3.925\n11   -1.475\nName: temp_c, dtype: float64, 'y': 0     215\n1     325\n2     185\n3     332\n4     406\n5     522\n6     412\n7     614\n8     544\n9     421\n10    445\n11    408\nName: icecream, dtype: int64}\n\n\n\nfit4 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\n\naz.summary(fit4, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n402.356\n13.079\n377.577\n426.508\n0.166\n0.117\n6454.0\n4831.0\n1.0\n\n\nbeta\n30.093\n3.398\n23.867\n36.725\n0.047\n0.033\n5538.0\n4353.0\n1.0\n\n\nsigma\n43.766\n11.651\n26.153\n66.129\n0.180\n0.128\n4437.0\n5027.0\n1.0\n\n\n\n\n\n\n\n\nNotiamo che la media a posteriori di \\(\\beta\\) √® rimasta invariata. Tuttavia, la media a posteriori di \\(\\alpha\\) √® ora pari a 402,4 dollari. Questo rappresenta il valore atteso degli introiti del negozio di gelati quando la temperatura √® al suo valore medio.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#distribizioni-a-priori-sui-parametri",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#distribizioni-a-priori-sui-parametri",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.7 Distribizioni a priori sui parametri",
    "text": "33.7 Distribizioni a priori sui parametri\nSpefichiamo ora le seguenti distribuzioni a priori debolmente informative sui parametri del modello.\n\nIntercetta (\\(\\alpha\\)):\n\n\\(\\alpha \\sim \\text{Normale}(0, 100)\\)\nLa scelta di una deviazione standard ampia (100) riflette l‚Äôincertezza riguardo al valore iniziale dell‚Äôintercetta. Si crede che l‚Äôintercetta possa essere qualsiasi valore vicino a 0, ma con una variazione significativa.\n\nCoefficiente Angolare (\\(\\beta\\)):\n\n\\(\\beta \\sim \\text{Normale}(0, 50)\\)\nUn‚Äôampia deviazione standard (50) per \\(\\beta\\) permette di incorporare l‚Äôincertezza riguardo all‚Äôinfluenza della temperatura sui ricavi del gelato. Questo prior permette che \\(\\beta\\) possa essere sia positivo che negativo con una vasta gamma di valori.\n\nDeviazione Standard Residua (\\(\\sigma\\)):\n\n\\(\\sigma \\sim \\text{Cauchy}^+(0, 5)\\)\nLa distribuzione Half-Cauchy √® scelta perch√© √® debolmente informativa e adatta per i parametri di scala come la deviazione standard residua. La scala di 5 consente a \\(\\sigma\\) di assumere una vasta gamma di valori positivi, riflettendo l‚Äôincertezza riguardo alla variabilit√† residua.\n\n\n\n33.7.1 Interpretazione delle Distribuzioni a Priori\nQueste distribuzioni a priori rappresentano le credenze iniziali riguardanti i parametri del modello prima di osservare i dati. Le distribuzioni normali per \\(\\alpha\\) e \\(\\beta\\) con deviazioni standard ampie permettono una grande flessibilit√†, mentre la distribuzione Half-Cauchy per \\(\\sigma\\) √® scelta per la sua capacit√† di gestire bene i parametri di scala. Queste scelte garantiscono che il modello sia debolmente informativo, permettendo ai dati osservati di avere un‚Äôinfluenza significativa sulle stime posteriori dei parametri.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_prior.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 100);\n  beta ~ normal(0, 50);\n  sigma ~ cauchy(0, 5);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nAdattiamo il nuovo modello ai dati.\n\nfit5 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit5, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n396.790\n12.114\n373.733\n419.045\n0.187\n0.132\n4518.0\n3481.0\n1.0\n\n\nbeta\n30.015\n2.996\n24.402\n35.673\n0.039\n0.028\n6018.0\n4754.0\n1.0\n\n\nsigma\n39.558\n9.771\n24.252\n57.630\n0.164\n0.120\n4130.0\n3957.0\n1.0\n\n\n\n\n\n\n\n\nSi noti che, utilizzando distribuzioni a priori debolmente informative, le distribuzioni a posteriori dei parametri risultano molto simili a quelle ottenute usando distribuzioni uniformi. Tuttavia, le distribuzioni a priori debolmente informative sono preferibili poich√© forniscono una maggiore stabilit√† numerica e sono generalmente pi√π affidabili e robuste, specialmente quando si lavora con dati reali. L‚Äôuso di distribuzioni uniformi √® sconsigliato per via delle possibili instabilit√† numeriche che possono introdurre nei modelli.\n\n\n33.7.2 Posterior-predictive check\nGeneriamo ora un PPC plot per confrontare le predizioni del modello con i dati osservati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"icecream_model_3.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nfit6 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nPer creare un PPC plot dobbiamo creare un oggetto InferenceData nel quale i dati sono strutturati come si aspetta ArviZ:\n\nidata = az.from_cmdstanpy(\n    posterior=fit6,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": df[\"icecream\"]},\n)\n\nAvendo generato l‚Äôoggetto idata, possiamo ora creare il pp-check plot.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"})\n\n/opt/anaconda3/envs/cmdstan_env/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  func(*args, **kwargs)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.8 Commenti e considerazioni finali",
    "text": "33.8 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato la stima dei parametri di un modello di regressione bivariato utilizzando l‚Äôapproccio bayesiano.\nPer fornire un confronto con un metodo alternativo, in appendice √® presentata un‚Äôintroduzione all‚Äôapproccio frequentista per il modello di regressione lineare bivariato. Questa sezione aggiuntiva offre una panoramica degli aspetti chiave dell‚Äôapproccio frequentista, consentendo di confrontare e comprendere le differenze tra i due approcci nella stima dei parametri e nell‚Äôinterpretazione dei risultati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_03_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_03_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "title": "33¬† Modello di regressione lineare bayesiano",
    "section": "33.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "33.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Jul 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\ncmdstanpy : 1.2.4\narviz     : 0.18.0\npingouin  : 0.5.4\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nFox, John. 2015. Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nStigler, Stephen. 1986. The History of Statistics. Massachusetts: Belknap Harvard.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_04_synt_sugar.html",
    "href": "chapters/chapter_5/05_04_synt_sugar.html",
    "title": "34¬† Zucchero sintattico",
    "section": "",
    "text": "34.1 Introduzione\nI modelli lineari sono cos√¨ ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie √® bambi (BAyesian Model-Building Interface). bambi √® un pacchetto Python progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato √® un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm o brms. bambi si basa su PyMC, ma offre un‚ÄôAPI di livello superiore.\nIn questo capitolo esploreremo come condurre un‚Äôanalisi di regressione utilizzando bambi invece di cmdstan.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_04_synt_sugar.html#bayesian-model-building-interface",
    "href": "chapters/chapter_5/05_04_synt_sugar.html#bayesian-model-building-interface",
    "title": "34¬† Zucchero sintattico",
    "section": "34.2 BAyesian Model-Building Interface",
    "text": "34.2 BAyesian Model-Building Interface\nLeggiamo i dati utilizzati nel capitolo precedente.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\n\nGeneriamo un diagramma a dispersione:\n\nplt.plot(df[\"weight\"], df[\"height\"], \"x\")\nplt.xlabel(\"Weight\")\nplt.ylabel(\"Height\")\n\nText(0, 0.5, 'Height')\n\n\n\n\n\n\n\n\n\nBambi si concentra sui modelli di regressione e questa restrizione porta a una sintassi pi√π semplice, ovvero la sintassi di Wilkinson {cite:p}wilkinson1973symbolic. Inoltre, bambi implementa delle distribuzioni a priori ottimizzate, eliminando cos√¨ la necessit√† di definirle esplicitamente. Tuttavia, se si preferisce un maggiore controllo sulle distribuzioni a priori, √® possibile specificarle manualmente.\nPer replicare il modello descritto nel capitolo precedente possiamo utilizzare la seguente istruzione.\n\ndf[\"weight_c\"] = df[\"weight\"] - np.mean(df[\"weight\"])\n\nmodel = bmb.Model(\"height ~ weight_c\", df)\n\nSul lato sinistro della tilde (‚àº), abbiamo la variabile dipendente, e sul lato destro, le variabili indipendenti. Con questa sintassi, stiamo semplicemente specificando la media (Œº nel modello lm di PyMC). Per impostazione predefinita, Bambi assume che la verosimiglianza sia gaussiana; √® possibile modificarla con l‚Äôargomento family. La sintassi della formula non specifica la distribuzione delle priors, ma solo come sono associate le variabili dipendenti e indipendenti. Bambi definir√† automaticamente delle priors (molto) debolmente informative per noi. Possiamo ottenere ulteriori informazioni stampando il modello Bambi.\n\nprint(model)\n\n       Formula: height ~ weight_c\n        Family: gaussian\n          Link: mu = identity\n  Observations: 352\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 154.5971, sigma: 19.3283)\n            weight_c ~ Normal(mu: 0.0, sigma: 2.9978)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 7.7313)\n\n\nLa descrizione inizia mostrando la formula utilizzata per definire il modello, y ~ x, che indica come la variabile dipendente y √® predetta dalla variabile indipendente x in una relazione lineare. La seconda riga specifica che si sta utilizzando una distribuzione gaussiana (normale) come funzione di verosimiglianza per il modello, il che implica l‚Äôassunzione che i residui del modello (le differenze tra i valori osservati e i valori predetti) seguano una distribuzione normale.\nLa terza riga menziona la funzione di collegamento, in questo caso l‚Äôidentit√†, che non applica alcuna trasformazione al valore atteso della variabile dipendente. Questo √® caratteristico dei modelli lineari, dove il valore atteso di y √® direttamente modellato come una combinazione lineare delle variabili indipendenti (E(Y) = \\alpha + \\beta x). √à importante notare che, nei modelli lineari generalizzati, la funzione di collegamento gioca un ruolo cruciale nel collegare il valore atteso della variabile risposta alla combinazione lineare delle variabili predittive.\nSegue il numero di osservazioni utilizzate per adattare il modello, indicando la dimensione del dataset su cui il modello √® stato allenato.\nLa parte successiva dell‚Äôoutput dettaglia i priors utilizzati per i parametri del modello. In Bambi, i priors sono assunzioni a priori sui valori dei parametri prima di osservare i dati. Questi priors aiutano a guidare l‚Äôinferenza, soprattutto in presenza di dati limitati o per regolarizzare il modello. L‚Äôintercetta (Intercept) ha un prior normale con media (mu) 2.0759 e deviazione standard (sigma) 3.9401, indicando la posizione iniziale attesa della linea di regressione e quanto ci si aspetta che vari. Il coefficiente della variabile x ha anch‚Äôesso un prior normale, centrato in zero con una deviazione standard ampia (6.8159), riflettendo incertezza su quale possa essere il vero effetto di x su y senza presupporre una direzione specifica dell‚Äôeffetto.\nLa sezione finale riguarda i parametri ausiliari del modello, in questo caso il parametro sigma della distribuzione gaussiana, che rappresenta la deviazione standard dei residui del modello. Questo ha un prior HalfStudentT, che √® una distribuzione che ammette solo valori positivi (essendo la deviazione standard sempre positiva), con un grado di libert√† (nu) 4.0 e una scala (sigma) 0.791. Questo prior √® scelto per la sua flessibilit√† e la capacit√† di gestire dati con potenziali outlier.\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nEseguiamo il campionamento MCMC.\n\nidata = model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\nLe distribuzioni a posteriori dei parametri e i trace plot si ottengono con la seguente istruzione.\n\n_ = az.plot_trace(idata)\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(idata, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n154.61\n0.27\n154.09\n155.09\n0.0\n0.0\n4300.59\n2955.37\n1.0\n\n\nsigma\n5.09\n0.19\n4.76\n5.45\n0.0\n0.0\n3966.32\n2953.56\n1.0\n\n\nweight_c\n0.90\n0.04\n0.82\n0.98\n0.0\n0.0\n4327.37\n3193.28\n1.0\n\n\n\n\n\n\n\n\nI dati replicano quelli ottenuti in precedenza.\nPossiamo anche generare un grafico che descrive l‚Äôincertezza a posteriori delle predizioni del modello.\nLa funzione plot_predictions del pacchetto Bambi serve per facilitare l‚Äôinterpretazione dei modelli di regressione attraverso la visualizzazione grafica. Il metodo appartiene al sottomodulo interpret di Bambi e si concentra sulla rappresentazione delle previsioni generate dal modello.\nQuando si esegue la funzione plot_predictions con i parametri specificati (model, idata, [\"weight_c\"]), essa produce un grafico che sintetizza le previsioni del modello in relazione a una o pi√π variabili indipendenti. In questo caso, il parametro model indica il modello di regressione Bayesiana costruito con Bambi, idata rappresenta i dati inferenziali (ottenuti tramite il fit del modello), e [\"weight_c\"] specifica la variabile indipendente da considerare per il grafico.\n\nbmb.interpret.plot_predictions(model, idata, [\"weight_c\"]);\n\nDefault computed for conditional variable: weight_c\n\n\n\n\n\n\n\n\n\nIl grafico generato da questa funzione illustra due aspetti principali:\n\nMedia Posteriore di y: Il grafico include una linea che rappresenta la media posteriore della variabile dipendente (height) rispetto alla variabile indipendente specificata (weight_c). La media posteriore √® una stima centrale delle previsioni del modello, che riflette la posizione pi√π probabile dei valori di height data l‚Äôevidenza fornita dai dati.\nIntervallo di Densit√† pi√π Alta del 94%: Attorno alla retta della media posteriore, il grafico mostra anche un‚Äôarea evidenziata che rappresenta l‚Äôintervallo di densit√† pi√π alta (HDI) del 94%. Questo intervallo √® un modo per quantificare l‚Äôincertezza delle previsioni del modello. L‚ÄôHDI del 94% significa che, data la distribuzione posteriore delle previsioni di height, c‚Äô√® il 94% di probabilit√† che il valore vero di height cada all‚Äôinterno di questo intervallo per un dato valore di weight_c. Questo fornisce una misura visiva dell‚Äôincertezza associata alle stime del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "34¬† Zucchero sintattico",
    "section": "34.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "34.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nbambi     : 0.14.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\narviz     : 0.18.0\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html",
    "href": "chapters/chapter_5/05_05_two_means.html",
    "title": "35¬† Confronto tra le medie di due gruppi",
    "section": "",
    "text": "35.1 Introduzione\nNel ?sec-two-groups-comparison, abbiamo discusso come eseguire l‚Äôinferenza sulla differenza tra le medie di due campioni indipendenti attraverso un approccio bayesiano. In quella analisi, i due gruppi sono stati trattati come entit√† distinte e abbiamo calcolato la differenza tra le loro medie.\nUn‚Äôalternativa consiste nell‚Äôuso di un modello di regressione. In questo caso, non si calcola direttamente la differenza tra le medie, ma si introduce una variabile ‚Äúdummy‚Äù nel modello di regressione. La variabile ‚Äúdummy‚Äù codifica l‚Äôappartenenza ai gruppi con valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto. Il modello di regressione stima poi un coefficiente per la variabile ‚Äúdummy‚Äù, che rappresenta la differenza tra le medie dei due gruppi. Cos√¨ facendo, la variabile ‚Äúdummy‚Äù agisce come un indicatore del gruppo, permettendoci di stimare in modo efficiente la differenza tra le medie.\nEntrambi i metodi sono validi per analizzare la differenza tra le medie di due gruppi indipendenti, tuttavia il modello di regressione offre maggiore flessibilit√† e potenzialit√† di espansione. Grazie a questo modello, √® possibile includere ulteriori variabili esplicative, ampliando la nostra capacit√† di comprendere i fattori che influenzano il risultato d‚Äôinteresse. Questa versatilit√† √® particolarmente vantaggiosa per esaminare come altre variabili possano influire sulla differenza tra le medie o per analizzare pi√π variabili contemporaneamente.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/chapter_5/05_05_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "35¬† Confronto tra le medie di due gruppi",
    "section": "35.2 Regressione bayesiana per due gruppi indipendenti",
    "text": "35.2 Regressione bayesiana per due gruppi indipendenti\nNel contesto bayesiano, il modello di regressione pu√≤ essere formulato nel modo seguente:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta x_i.\n\\end{align*}\n\\]\nIn questa rappresentazione:\n\n$ $ agisce come intercetta,\n$ $ √® il coefficiente angolare o la pendenza,\n$ $ √® l‚Äôerrore standard associato alle osservazioni.\n\nNel caso specifico, la variabile $ x $ √® una variabile indicatrice che assume i valori 0 o 1. Per il gruppo identificato da $ x = 0 $, il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nQuesto implica che $ $ rappresenta la media del gruppo codificato come $ x = 0 $.\nPer il gruppo contrassegnato da $ x = 1 $, il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta.\n\\end{align*}\n\\]\nIn termini dei parametri del modello, la media per il gruppo codificato con $ x = 1 $ √® rappresentata da $ + $. In questa configurazione, $ $ indica la differenza tra la media del gruppo con $ x = 1 $ e quella del gruppo con $ x = 0 $. Di conseguenza, l‚Äôanalisi della differenza tra le medie dei due gruppi pu√≤ essere effettuata attraverso l‚Äôinferenza sul parametro $ $. In sintesi, per confrontare le medie dei due gruppi indipendenti, si pu√≤ esaminare la distribuzione a posteriori di $ $.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#un-esempio-illustrativo",
    "href": "chapters/chapter_5/05_05_two_means.html#un-esempio-illustrativo",
    "title": "35¬† Confronto tra le medie di due gruppi",
    "section": "35.3 Un esempio illustrativo",
    "text": "35.3 Un esempio illustrativo\nEsaminiamo nuovamente i dati relativi al quoziente di intelligenza dei bambini le cui madri hanno completato oppure no la scuola superiore. Ci poniamo il problema di replicare i risultati ottenuti in precedenza usando l‚Äôanalisi di regressione.\nLeggiamo i dati:\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\n\nkidiq.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nCi sono 93 bambini la cui madre non ha completato le superiori e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\nsummary_stats = [st.mean, st.stdev]\nkidiq.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\n\naz.plot_violin(\n    {\n        \"mom_hs=0\": kidiq.loc[kidiq.mom_hs == 0, \"kid_score\"],\n        \"mom_hs=1\": kidiq.loc[kidiq.mom_hs == 1, \"kid_score\"],\n    }\n);\n\n\n\n\n\n\n\n\nIniziamo l‚Äôinferenza statistica sulla differenza tra le medie dei due gruppi utilizzando bambi. Questo pacchetto offre una sintassi semplice per formulare il modello bayesiano di interesse. Un altro vantaggio √® che bambi selezioner√† automaticamente le distribuzioni a priori appropriate per i parametri del modello, rendendo il processo pi√π intuitivo.\nIl modello di regressione sopra descritto si scrive nel modo seguente.\n\nmod = bmb.Model(\"kid_score ~ mom_hs\", kidiq)\n\nEffettuiamo il campionamento.\n\nresults = mod.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nPossiamo ispezionare le propriet√† del modello nel modo seguente.\n\nmod\n\n       Formula: kid_score ~ mom_hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 86.7972, sigma: 110.1032)\n            mom_hs ~ Normal(mu: 0.0, sigma: 124.2132)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nLe distribuzioni a priori utilizzate di default dal modello possono essere visualizzate nel modo seguente.\n\n_ = mod.plot_priors()\n\nSampling: [Intercept, kid_score_sigma, mom_hs]\n\n\n\n\n\n\n\n\n\nPer ispezionare il nostro posteriore e il processo di campionamento possiamo utilizzare az.plot_trace(). L‚Äôopzione kind='rank_vlines' ci fornisce una variante del grafico di rango che utilizza linee e punti e ci aiuta a ispezionare la stazionariet√† delle catene. Poich√© non c‚Äô√® un modello chiaro o deviazioni serie dalle linee orizzontali, possiamo concludere che le catene sono stazionarie.\n\n_ = az.plot_trace(results)\n\n\n\n\n\n\n\n\n\naz.summary(results, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n77.52\n2.04\n73.72\n81.48\n0.03\n0.02\n4640.52\n3274.01\n1.0\n\n\nkid_score_sigma\n19.91\n0.67\n18.68\n21.19\n0.01\n0.01\n4231.42\n3052.91\n1.0\n\n\nmom_hs\n11.78\n2.30\n7.23\n15.86\n0.03\n0.02\n4642.76\n3108.48\n1.0\n\n\n\n\n\n\n\n\nIl parametro ‚ÄúIntercept‚Äù rappresenta la stima a posteriori del punteggio del QI per il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. La media a posteriori di questo gruppo √® di 77.6, che √® praticamente identica al valore campionario corrispondente.\nIl parametro ‚Äúmom_hs‚Äù corrisponde alla stima a posteriori della differenza nei punteggi del QI tra il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 1 e il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. Anche in questo caso, la differenza a posteriori di 11.8 tra le medie dei due gruppi √® molto simile alla differenza campionaria tra le medie dei due gruppi. La parte importante della tabella riguarda l‚Äôintervallo di credibilit√† al 94%, che √® [7.5, 16.2], e che non include lo 0. Ci√≤ significa che, con un livello di certezza soggettiva del 94%, possiamo essere sicuri che il QI dei bambini le cui madri hanno il diploma superiore sar√† maggiore (in media) di almeno 7.5 punti, e tale differenza pu√≤ arrivare fino a 16.2 punti, rispetto al QI dei bambini le cui madri non hanno completato la scuola superiore.\nSe confrontiamo questi risultati con quelli ottenuti nel capitolo {ref}two_groups_comparison_notebook, notiamo che sono quasi identici. Le piccole differenze che si osservano possono essere attribuite sia all‚Äôapprossimazione numerica sia al fatto che nel modello precedente abbiamo consentito deviazioni standard diverse per i due gruppi, mentre nel caso attuale abbiamo assumo la stessa variabilit√† per entrambi i gruppi.\nUsiamo ora l‚Äôapproccio di massima verosimiglianza.\n\nlm = pg.linear_regression(kidiq[\"mom_hs\"], kidiq[\"kid_score\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n77.55\n2.06\n37.67\n0.0\n0.06\n0.05\n73.50\n81.59\n\n\n1\nmom_hs\n11.77\n2.32\n5.07\n0.0\n0.06\n0.05\n7.21\n16.34\n\n\n\n\n\n\n\n\nI risultati sono quasi identici a quelli trovati con l‚Äôapproccio bayesiano.\nIl test bayesiano di ipotesi pu√≤ essere svolto, per esempio, calcolando la probabilit√† che \\(\\beta_{mean\\_diff} &gt; 0\\). Questa probabilit√† √® 1, per cui concludiamo che la media del gruppo codificato con ‚Äúmom_hs = 1‚Äù √® maggiore della media del gruppo codificato con ‚Äúmom_hs = 0‚Äù.\n\naz.plot_posterior(results, var_names=\"mom_hs\", ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\nUn valore numerico si ottiene nel modo seguente.\n\nresults.posterior\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104kB\nDimensions:          (chain: 4, draw: 1000)\nCoordinates:\n  * chain            (chain) int64 32B 0 1 2 3\n  * draw             (draw) int64 8kB 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\nData variables:\n    Intercept        (chain, draw) float64 32kB 78.83 79.84 ... 73.83 79.82\n    kid_score_sigma  (chain, draw) float64 32kB 19.21 20.79 ... 20.87 19.45\n    mom_hs           (chain, draw) float64 32kB 11.97 8.374 ... 15.15 10.02\nAttributes:\n    created_at:                  2024-06-13T05:14:43.527326+00:00\n    arviz_version:               0.18.0\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (3)Intercept(chain, draw)float6478.83 79.84 73.54 ... 73.83 79.82array([[78.82644605, 79.84168005, 73.54424871, ..., 78.2407767 ,\n        79.65683325, 79.50875636],\n       [80.01627206, 78.71662919, 79.20643166, ..., 77.02806443,\n        79.29123634, 77.23338073],\n       [77.29254392, 77.44678841, 77.42416296, ..., 74.46900909,\n        80.21508608, 78.984981  ],\n       [75.11589965, 75.46194695, 76.33373715, ..., 75.60413192,\n        73.83124842, 79.81667588]])kid_score_sigma(chain, draw)float6419.21 20.79 20.36 ... 20.87 19.45array([[19.20601585, 20.79313289, 20.36108383, ..., 20.97965143,\n        20.94150175, 20.43169363],\n       [20.03731499, 19.08286456, 19.52683884, ..., 19.27515939,\n        19.94139224, 19.46453797],\n       [18.38282855, 19.29950429, 20.1234451 , ..., 19.13765117,\n        19.53346331, 18.6415884 ],\n       [20.69701767, 18.03001439, 19.71130165, ..., 21.17944029,\n        20.86573599, 19.45230071]])mom_hs(chain, draw)float6411.97 8.374 14.71 ... 15.15 10.02array([[11.96777777,  8.37382352, 14.70572866, ..., 12.14492642,\n        12.5707737 , 12.86370927],\n       [ 8.24668315, 12.34781247,  9.87043598, ..., 13.43240059,\n         9.11062374, 11.95853216],\n       [13.72195497, 12.79190398, 11.57487575, ..., 14.54096709,\n         9.29889013, 11.32656956],\n       [13.01259531, 12.49687999, 13.49840034, ..., 13.1175932 ,\n        15.14621113, 10.01597991]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (4)created_at :2024-06-13T05:14:43.527326+00:00arviz_version :0.18.0modeling_interface :bambimodeling_interface_version :0.13.0\n\n\n\n# Probabiliy that posterior is &gt; 0\n(results.posterior[\"mom_hs\"] &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#parametrizzazione-alternativa",
    "href": "chapters/chapter_5/05_05_two_means.html#parametrizzazione-alternativa",
    "title": "35¬† Confronto tra le medie di due gruppi",
    "section": "35.4 Parametrizzazione alternativa",
    "text": "35.4 Parametrizzazione alternativa\nConsideriamo adesso il caso in cui, per distinguere i gruppi, anzich√© una variabile dicotomica, con valori 0 e 1, usiamo una variabile qualitativa con i nomi dei due gruppi. Introduciamo questa nuova variabile nel data frame.\n\n# Add a new column 'hs' with the categories based on 'mom_hs'\nkidiq[\"hs\"] = kidiq[\"mom_hs\"].map({0: \"not_completed\", 1: \"completed\"})\nkidiq.tail()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\nhs\n\n\n\n\n429\n94\n0.0\n84.877412\n4\n21\nnot_completed\n\n\n430\n76\n1.0\n92.990392\n4\n23\ncompleted\n\n\n431\n50\n0.0\n94.859708\n2\n24\nnot_completed\n\n\n432\n88\n1.0\n96.856624\n2\n21\ncompleted\n\n\n433\n70\n1.0\n91.253336\n2\n25\ncompleted\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati, usando questa nuova variabile e forziamo a zero l‚Äôintercetta che Bambi aggiunge di default al modello.\n\nmod_2 = bmb.Model(\"kid_score ~ 0 + hs\", kidiq)\nresults_2 = mod_2.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nIspezionare il modello e le distribuzioni a priori.\n\nmod_2\n\n       Formula: kid_score ~ 0 + hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            hs ~ Normal(mu: [0. 0.], sigma: [124.2132 124.2132])\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\n_ = mod_2.plot_priors()\n\nSampling: [hs, kid_score_sigma]\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri del modello.\n\n_ = az.plot_trace(results_2)\n\n\n\n\n\n\n\n\n\naz.summary(results_2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nhs[completed]\n89.301\n1.059\n87.267\n91.258\n0.016\n0.012\n4147.0\n3064.0\n1.0\n\n\nhs[not_completed]\n77.473\n2.048\n73.722\n81.256\n0.031\n0.022\n4308.0\n3016.0\n1.0\n\n\nkid_score_sigma\n19.881\n0.680\n18.621\n21.181\n0.011\n0.008\n3982.0\n2995.0\n1.0\n\n\n\n\n\n\n\n\nIn questo caso, notiamo che abbiamo ottenuto le distribuzioni a posteriori per i parametri hs[completed] e hs[not_completed] che corrispondono alle medie dei due gruppi. Tali distribuzioni a posteriori illustrano direttamente l‚Äôincertezza sulla media dei due gruppi, alla luce della variabilit√† campionaria e delle nostre credenze a priori.\nPossiamo svolgere il test bayesiano di ipotesi sulla differenza tra le due medie a posteriori nel modo seguente.\n\npost_group = results_2.posterior[\"hs\"]\ndiff = post_group.sel(hs_dim=\"completed\") - post_group.sel(hs_dim=\"not_completed\")\naz.plot_posterior(diff, ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\n\n# Probabiliy that posterior is &gt; 0\n(post_group &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_5/05_05_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_5/05_05_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "35¬† Confronto tra le medie di due gruppi",
    "section": "35.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "35.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nnumpy     : 1.26.4\nbambi     : 0.14.0\npandas    : 2.2.2\npingouin  : 0.5.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html",
    "href": "chapters/chapter_7/a00_installation.html",
    "title": "Online Appendix A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1 Guida all‚ÄôInstallazione Locale dei Jupyter Notebook\nPer facilitare l‚Äôapprendimento e l‚Äôapplicazione delle tecniche di analisi dei dati discusse in questo corso, utilizzeremo i Jupyter Notebook come strumento principale. I Jupyter Notebook sono documenti interattivi che consentono di combinare codice, testo narrativo, visualizzazioni grafiche e altri elementi multimediali, rendendoli ideali per documentare e condividere analisi di dati in modo trasparente e riproducibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "href": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "title": "Online Appendix A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1.1 Prerequisiti per l‚ÄôUso dei Jupyter Notebook\nPer utilizzare i Jupyter Notebook, √® necessario soddisfare alcuni prerequisiti:\n\nInstallare Python: √à il linguaggio di programmazione fondamentale per il nostro corso e deve essere installato sul vostro computer.\nGestione degli Ambienti Virtuali con conda: Utilizzeremo conda per creare e gestire ambienti virtuali, che permettono di isolare e gestire le dipendenze del progetto.\nInstallazione dei Pacchetti Python Necessari: Dovrete installare specifici pacchetti Python, inclusi PyMC per l‚Äôanalisi bayesiana, e altri pacchetti utili, all‚Äôinterno dell‚Äôambiente virtuale creato per questo corso.\nInterfaccia per l‚ÄôUso dei Jupyter Notebook: Avrete bisogno di un IDE (Integrated Development Environment) che supporti i Jupyter Notebook, come Visual Studio Code, per scrivere e eseguire i vostri notebook.\n\n\n\nA.1.2 Installazione di Anaconda\nLa maggior parte dei requisiti elencati pu√≤ essere agevolmente soddisfatta tramite l‚Äôinstallazione di Anaconda, una distribuzione di Python che include conda e facilita la gestione degli ambienti virtuali e l‚Äôinstallazione dei pacchetti.\n\n\n\n\n\n\nSe Anaconda √® gi√† stata installata, potrebbero sorgere problemi dopo l‚Äôaggiornamento del sistema operativo. In tal caso, sar√† indispensabile procedere con una nuova installazione di Anaconda.\n\n\n\n\nA.1.2.1 Per Utenti macOS\nSe lavorate su macOS, potreste trovare pi√π pratico utilizzare conda direttamente dal Terminale o da un‚Äôapplicazione terminale moderna come Warp, piuttosto che attraverso Anaconda Navigator. In questo caso, potete optare per installare una versione di Visual Studio Code indipendente da quella fornita con Anaconda, per un maggiore controllo e flessibilit√†.\n\n\nA.1.2.2 Per Utenti Windows\nPer coloro che utilizzano Windows, l‚Äôuso di Jupyter Notebook tramite Anaconda Navigator potrebbe risultare la scelta pi√π semplice e diretta, grazie all‚Äôintegrazione e alla facilit√† d‚Äôuso fornite da Anaconda in ambienti Windows.\n\n\n\nA.1.3 Creazione e Configurazione dell‚ÄôAmbiente Virtuale\nIndipendentemente dal sistema operativo, √® fondamentale installare e configurare conda, che vi permetter√† di creare {ref}appendix-virtual-env dedicati. All‚Äôinterno di questi ambienti, installerete cmdstanpy (o PyMC) e gli altri pacchetti richiesti per il corso. La strada pi√π semplice per soddisfare questi requisiti √® attraverso l‚Äôinstallazione di Anaconda, che semplifica notevolmente il processo di configurazione iniziale e gestione degli ambienti virtuali.\nQuesta guida all‚Äôinstallazione locale mira a fornirvi tutti gli strumenti necessari per iniziare a utilizzare i Jupyter Notebook nel contesto del nostro corso, facilitando un apprendimento efficiente e la condivisione dei risultati delle vostre analisi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-di-anaconda",
    "href": "chapters/chapter_7/a00_installation.html#guida-allinstallazione-di-anaconda",
    "title": "Online Appendix A ‚Äî Ambiente di lavoro",
    "section": "A.2 Guida all‚ÄôInstallazione di Anaconda",
    "text": "A.2 Guida all‚ÄôInstallazione di Anaconda\nAnaconda √® una distribuzione popolare per la programmazione in Python. Ecco una guida passo-passo per l‚Äôinstallazione:\n\nScaricare Anaconda:\n\nVisitate il sito ufficiale di Anaconda: https://www.anaconda.com/.\nScegliete la versione adatta al vostro sistema operativo (Windows, macOS o Linux).\nOptate per il download dell‚Äôultima versione disponibile, che include l‚Äôultima versione di Python.\n\nInstallare Anaconda:\n\nEseguite il file di installazione scaricato.\nSeguite le istruzioni visualizzate, mantenendo le impostazioni predefinite, a meno che non abbiate esigenze specifiche.\n\nAggiungere Anaconda al ‚ÄòPATH‚Äô del Sistema:\n\nDurante l‚Äôinstallazione, vi sar√† chiesto se desiderate aggiungere Anaconda al ‚ÄòPATH‚Äô del sistema. Questo passaggio √® cruciale poich√© consente di utilizzare Python da qualunque parte del computer.\nVi consiglio di selezionare questa opzione (altri metodi sono possibili, ma questo ha dimostrato di funzionare senza problemi).\n\nConfermare l‚ÄôInstallazione:\n\nAl termine dell‚Äôinstallazione, aprite PowerShell all‚Äôinterno di Anaconda Navigagor (Windows) o il terminale (macOS/Linux) e digitate python --version per verificare se l‚Äôinstallazione √® riuscita. Se compare la versione di Python, tutto √® andato a buon fine.\n\n\nAnaconda include il Navigator, un‚Äôinterfaccia utente grafica per gestire ambienti di sviluppo, installare librerie aggiuntive e lanciare strumenti come Jupyter Notebook, che consente (in alternativa a VS Code) di scrivere ed eseguire codice Python.\n\n\n\n\n\n\nIstruzioni Specifiche per Utenti Windows:\n\nScaricare Anaconda:\n\nScaricate la versione ‚Äú64-Bit Graphical Installer‚Äù dal sito di Anaconda.\n\nInstallare Anaconda:\n\nAvviate l‚Äôinstaller scaricato e seguite le istruzioni visualizzate.\nDurante l‚Äôinstallazione, selezionate ‚ÄúJust Me‚Äù (solo per l‚Äôutente corrente).\nMantenete il percorso di installazione predefinito.\n\nIncludere Anaconda nel ‚ÄòPATH‚Äô:\n\nIMPORTANTE: Selezionate l‚Äôopzione per aggiungere Anaconda al PATH e impostarlo come installazione di Python di default. Di default, questa opzione √® deselezionata.\n\nVerifica dell‚ÄôInstallazione:\n\nCercate ‚ÄúAnaconda Navigator‚Äù nel menu Start. Se si apre correttamente, l‚Äôinstallazione √® riuscita.\nAprite ‚ÄúAnaconda Prompt‚Äù (o ‚ÄúPowerShell‚Äù) dal menu Start di Anaconda Navigator e digitate conda --version per confermare l‚Äôinstallazione di conda.\n\n\nSeguite attentamente queste istruzioni per garantire un‚Äôinstallazione senza problemi.\nPer maggiori dettagli, consultate il tutorial su come installare Anaconda su Windows: Tutorial Installazione di Anaconda su Windows. Questo tutorial offre spiegazioni dettagliate e una guida passo-passo.\n\n\n\nUna volta installato Anaconda, potrete utilizzare Anaconda Navigator per gestire progetti Python, installare librerie necessarie e avviare strumenti come Jupyter Notebook.\n\n\n\n\n\n\n√à necessario comprendere la differenza tra applicazione (App) e installer.\nCos‚Äô√® un‚ÄôApplicazione (App)\nUn‚Äôapplicazione, comunemente chiamata ‚Äúapp‚Äù, √® un software che funziona sul vostro computer o dispositivo mobile per uno scopo specifico, come navigare in internet, inviare messaggi, elaborare testi o fare calcoli. Esempi includono browser web come Google Chrome, programmi di elaborazione testi come Microsoft Word, o sistemi come Anaconda Navigator.\nCos‚Äô√® un Installer\nUn installer √® un software che installa un‚Äôapplicazione sul vostro computer. Tipicamente, quando scaricate un‚Äôapplicazione da internet, scaricate in realt√† l‚Äôinstaller. L‚Äôinstaller ha il compito di: - Copiare i file dell‚Äôapp nella corretta cartella del computer. - Creare scorciatoie per l‚Äôapp, come icone sul desktop o voci nel menu Start. - Configurare impostazioni iniziali per il corretto funzionamento dell‚Äôapp.\nDopo l‚ÄôInstallazione\nDopo che l‚Äôinstaller ha completato il suo lavoro, l‚Äôapplicazione sar√† pronta all‚Äôuso e l‚Äôinstaller pu√≤ essere eliminato.\nIn sintesi, l‚Äôapplicazione √® il software che userete per svolgere compiti specifici, mentre l‚Äôinstaller √® lo strumento temporaneo per installare l‚Äôapplicazione sul vostro computer. Capire questa distinzione √® fondamentale nel mondo dell‚Äôinformatica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#sec-virtual-environment",
    "href": "chapters/chapter_7/a00_installation.html#sec-virtual-environment",
    "title": "Online Appendix A ‚Äî Ambiente di lavoro",
    "section": "A.3 L‚ÄôAmbiente Virtuale in Python",
    "text": "A.3 L‚ÄôAmbiente Virtuale in Python\nDopo aver installato Python tramite Anaconda, un aspetto fondamentale da considerare √® la creazione di un ambiente virtuale. Un ambiente virtuale rappresenta uno spazio dedicato sul vostro computer, dove √® possibile installare e gestire le librerie Python necessarie per il corso, inclusi quelle per l‚Äôanalisi statistica. La creazione di un ambiente virtuale √® estremamente vantaggiosa poich√© contribuisce all‚Äôorganizzazione del lavoro e previene possibili conflitti tra diverse librerie. Le istruzioni dettagliate per la configurazione di un ambiente virtuale sono disponibili nel Appendice E`.\nL‚Äôesecuzione delle fasi precedentemente delineate, ossia l‚Äôinstallazione di Anaconda, la configurazione di Visual Studio Code e la creazione di un ambiente virtuale, assicurer√† la completa preparazione di un ambiente di sviluppo locale ottimizzato per l‚Äôutilizzo dei Jupyter Notebook nelle vostre attivit√† legate alla data science all‚Äôinterno di questo corso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#la-shell",
    "href": "chapters/chapter_7/a00_installation.html#la-shell",
    "title": "Online Appendix A ‚Äî Ambiente di lavoro",
    "section": "A.4 La Shell",
    "text": "A.4 La Shell\nPer la creazione e la gestione dell‚Äôambiente di calcolo, l‚Äôuso di una shell √® indispensabile. Questa pu√≤ essere approfondita nella sezione {ref}appendix-shell. La shell permette di interagire con il sistema operativo attraverso l‚Äôuso di comandi in un terminale. Diverse soluzioni software sono disponibili per facilitare questa interazione.\n\nA.4.1 Unix (MacOS, Linux)\nIn ambienti Unix come MacOS e Linux, ci sono diverse shell tra cui scegliere. Una scelta popolare √® Bash, che √® comunemente preinstallata su molti sistemi Unix. Un‚Äôaltra opzione moderna √® Zsh, nota per la sua facilit√† di personalizzazione e funzionalit√† avanzate. Per un‚Äôesperienza di terminale migliorata, warp √® un‚Äôopzione innovativa che offre un‚Äôinterfaccia utente ricca di funzionalit√† e supporto per i comandi intelligenti.\n\n\nA.4.2 Windows\nSu Windows, la shell predefinita √® il Prompt dei Comandi, ma non √® cos√¨ potente o flessibile come le shell disponibili su Unix. PowerShell √® un‚Äôopzione pi√π avanzata disponibile su Windows, che combina la gestione della configurazione e l‚Äôautomazione delle attivit√† con un linguaggio di scripting.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#lavorare-con-visual-studio-code",
    "href": "chapters/chapter_7/a00_installation.html#lavorare-con-visual-studio-code",
    "title": "Online Appendix A ‚Äî Ambiente di lavoro",
    "section": "A.5 Lavorare con Visual Studio Code",
    "text": "A.5 Lavorare con Visual Studio Code\nPer utilizzare Visual Studio Code con Python e Jupyter Notebook, √® essenziale installare le relative estensioni. Per fare ci√≤, √® sufficiente seguire alcuni semplici passaggi:\n\nAvvia Visual Studio Code sul tuo computer.\nNella barra laterale sinistra, trova e clicca sull‚Äôicona con quattro quadrati, di cui uno disallineato. Questo √® il menu delle estensioni.\nNella barra di ricerca all‚Äôinterno del menu delle estensioni, digita ‚ÄúPython‚Äù e premi Invio. Troverai diverse estensioni relative a Python.\nTrova l‚Äôestensione ufficiale di Python sviluppata da Microsoft e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\nSuccessivamente, cerca ‚ÄúJupyter‚Äù nella barra di ricerca delle estensioni e premi Invio.\nTrova l‚Äôestensione ‚ÄúJupyter‚Äù nell‚Äôelenco dei risultati e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\n\nUna volta completati questi passaggi, avrai installato con successo le componenti aggiuntive necessarie per lavorare con Python e Jupyter Notebook all‚Äôinterno di Visual Studio Code. Potrai quindi iniziare a scrivere, eseguire e testare il tuo codice Python e i tuoi notebook Jupyter direttamente nell‚Äôambiente di sviluppo di Visual Studio Code.\nQuando apri un file con estensione .ipynb in Visual Studio Code ricorda di selezionare l‚Äôambiente virtuale che desiderate utilizzare. Puoi farlo tramite la ‚ÄúCommand Palette‚Äù (‚áß‚åòP), utilizzando l‚Äôistruzione Python: Select Interpreter. In alternativa, puoi fare clic sull‚Äôicona Select kernel di Visual Studio Code, che si trova nell‚Äôangolo in alto a destra, sotto l‚Äôicona degli ingranaggi (‚öôÔ∏è).\nxesveqg ../images/select_kernel.png :height: 300px :align: center",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a00_installation.html#google-colab",
    "href": "chapters/chapter_7/a00_installation.html#google-colab",
    "title": "Online Appendix A ‚Äî Ambiente di lavoro",
    "section": "A.6 Google Colab",
    "text": "A.6 Google Colab\nUtilizzando il link √® possibile accedere a Google Colab e iniziare a scrivere codice Python direttamente dal proprio browser, senza dover effettuare alcuna installazione. Basta selezionare l‚Äôopzione ‚ÄúNuovo notebook‚Äù per creare un nuovo ambiente di lavoro. Per avere un‚Äôintroduzione completa sulle funzionalit√† di Colab, si pu√≤ consultare la guida disponibile al seguente link. √à possibile salvare ogni notebook nella propria cartella di Google Drive per una facile gestione e condivisione dei file.\n\nA.6.1 Uso dei Comandi Speciali in Colab\nNell‚Äôambiente Google Colab, √® possibile utilizzare il comando\n!pip list -v\nper visualizzare un elenco dettagliato di tutte le librerie preinstallate. Questo comando fornisce informazioni utili per comprendere quali strumenti sono immediatamente disponibili per l‚Äôuso, comprese le versioni delle librerie e i percorsi di installazione.\nIl prefisso ! indica un comando speciale, noto anche come comando ‚Äúshell‚Äù, che consente di interagire con il sistema sottostante di Colab direttamente dalla cella del notebook, eseguendo operazioni al di fuori dell‚Äôambiente Python standard.\n\n\nA.6.2 Installazione di Librerie Supplementari\nSe necessario aggiungere ulteriori librerie all‚Äôambiente Colab, come pymc, bambi, e arviz, √® possibile farlo facilmente mediante l‚Äôuso dei comandi pip. Ad esempio, per installare queste tre librerie, si possono eseguire i seguenti comandi uno dopo l‚Äôaltro:\n!pip install bambi\n!pip install pymc\n!pip install arviz\nQuesti comandi non solo installeranno le librerie specificate ma gestiranno anche automaticamente l‚Äôinstallazione delle dipendenze necessarie, tra cui numpy, pandas, matplotlib, seaborn, scipy, e statsmodels, assicurando cos√¨ che tutto l‚Äôambiente di lavoro sia pronto per l‚Äôuso.\n\n\nA.6.3 Google Drive\n\nA.6.3.1 Collegare Google Drive a Colab\nPer accedere alla propria cartella di Google Drive durante l‚Äôutilizzo di Colab, √® possibile seguire i seguenti passaggi:\n\nDalla pagina iniziale, fare clic sull‚Äôicona a forma di cartella (Files) situata nel menu in alto a sinistra.\n\nxesveqg ../images/colab_1.png :height: 300px :align: center\n\n\nSi aprir√† un menu con diverse opzioni.\n\nxesveqg ../images/colab_2.png :height: 300px :align: center\n\n\nSelezionare la terza icona tra le quattro disposte orizzontalmente. Apparir√† l‚Äôistruzione ‚ÄúRun this cell to mount your Google Drive‚Äù. Fare clic sull‚Äôicona del triangolo contenuta in un cerchio grigio.\nA questo punto, fare clic sull‚Äôicona ‚Äúdrive‚Äù e successivamente su ‚ÄúMyDrive‚Äù per accedere alle cartelle e ai file salvati sul proprio Google Drive.\n\n√à importante tenere presente che la versione gratuita del runtime di Google Colaboratory non salva le informazioni in modo permanente, il che significa che tutto il lavoro svolto verr√† eliminato una volta terminata la sessione. Pertanto, √® necessario reinstallare le librerie utilizzate in precedenza ogni volta che ci si connette a Colab. Al contrario, i Jupyter Notebook possono essere salvati nella propria cartella di Google Drive.\nPer salvare un Jupyter Notebook su Google Drive utilizzando Colab, √® possibile seguire i seguenti passaggi:\n\nFare clic su File nella barra del menu di Colab.\nSelezionare Save a copy in Drive. Di default, Colab salver√† il Notebook nella cartella Colab Notebooks/.ipynb_checkpoints con un nome simile a Untitled7.ipynb.\nDopo aver salvato il Notebook, √® consigliabile rinominarlo facendo clic con il pulsante destro del mouse sul file nella cartella di Google Drive e selezionando Rename. In questo modo sar√† possibile assegnare un nome pi√π significativo al Notebook.\nPer organizzare i file, √® possibile trascinare il Notebook nella cartella desiderata all‚Äôinterno di Google Drive.\n\nSeguendo questi passaggi, sar√† possibile salvare e organizzare i Jupyter Notebook nella propria cartella di Google Drive, consentendo di accedervi facilmente e mantenerli in modo permanente anche dopo la sessione di Colab.\n√à possibile accedere a un breve tutorial video su come utilizzare Colab e come leggere i dati da un file esterno in un Notebook di Jupyter in Colab. Il video tutorial pu√≤ essere trovato seguendo il [link](https://drive.google.com/file/d/1s3whYnq_rLXeLT4yKiOyEQjzk6d55Ct4/view?usp=share_link) fornito.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html",
    "href": "chapters/chapter_7/a01_markdown.html",
    "title": "Online Appendix B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "B.1 Configurazione Locale per Jupyter Notebook\nPer iniziare a lavorare con i Jupyter Notebook nel proprio ambiente di sviluppo locale, √® necessario completare alcuni passaggi preliminari che assicurano una configurazione ottimale:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "href": "chapters/chapter_7/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "title": "Online Appendix B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "Installazione di Python tramite Anaconda: Anaconda √® una distribuzione di Python che include gi√† Jupyter e altre librerie utili per la data science e l‚Äôanalisi di dati. Seguendo le istruzioni dettagliate disponibili sul sito di Anaconda (e fornite in precedenza in questa dispensa), si pu√≤ facilmente installare Python e Jupyter sul proprio sistema.\nSelezione di un Ambiente di Sviluppo Integrato (IDE): Visual Studio Code (VS Code) rappresenta una scelta eccellente per chi cerca un IDE versatile e gratuito. Disponibile al download dal sito ufficiale, VS Code supporta Python tramite l‚Äôinstallazione di una specifica estensione. Dopo aver installato VS Code, √® possibile aggiungere il supporto per Python e per i Jupyter Notebook installando l‚Äôestensione ‚ÄúPython‚Äù disponibile nella sezione ‚ÄúExtensions‚Äù, identificabile dall‚Äôicona dei quattro quadrati. Per una completa integrazione dei notebook Jupyter, potrebbe essere necessario installare anche la libreria ipykernel.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#celle",
    "href": "chapters/chapter_7/a01_markdown.html#celle",
    "title": "Online Appendix B ‚Äî Jupyter Notebook",
    "section": "B.2 Celle",
    "text": "B.2 Celle\nI Jupyter Notebook sono organizzati in celle, elementi discreti che possono contenere codice o testo (markdown). La possibilit√† di cambiare il tipo di una cella tramite il menu ‚ÄúCell‚Äù o la barra degli strumenti, selezionando ‚ÄúCode‚Äù per codice Python o ‚ÄúMarkdown‚Äù per annotazioni testuali, rende i notebook estremamente versatili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#formattazione-del-testo-con-markdown",
    "href": "chapters/chapter_7/a01_markdown.html#formattazione-del-testo-con-markdown",
    "title": "Online Appendix B ‚Äî Jupyter Notebook",
    "section": "B.3 Formattazione del Testo con Markdown",
    "text": "B.3 Formattazione del Testo con Markdown\nMarkdown permette di arricchire le celle di testo con formattazioni varie, creando un documento strutturato e leggibile. Ecco alcuni esempi:\n\nTitoli: # Titolo per un titolo di primo livello, ## Sottotitolo per un secondo livello, e cos√¨ via.\nElenchi: - Elemento per elenchi puntati, 1. Elemento per elenchi numerati.\nCollegamenti: [Testo del link](URL) per inserire un link.\nEnfasi: **grassetto** per il testo in grassetto, *corsivo* per il corsivo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "href": "chapters/chapter_7/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "title": "Online Appendix B ‚Äî Jupyter Notebook",
    "section": "B.4 Comandi Magici in Jupyter Notebook",
    "text": "B.4 Comandi Magici in Jupyter Notebook\nI Jupyter Notebook supportano i ‚Äúcomandi magici‚Äù, comandi speciali che iniziano con % (per comandi su una singola riga) o %% (per comandi che occupano un‚Äôintera cella). Questi comandi offrono funzionalit√† avanzate come:\n\n%run: esegue un file Python esterno.\n%timeit: valuta il tempo di esecuzione di una singola riga di codice.\n%matplotlib inline: integra grafici Matplotlib direttamente nel notebook.\n%load: carica il codice da un file esterno in una cella.\n%reset: cancella tutte le variabili definite nel notebook.\n%pwd e %cd: gestiscono il percorso della directory di lavoro.\n\nDigitando %lsmagic in una cella, si pu√≤ accedere all‚Äôelenco completo dei comandi magici disponibili, esplorando cos√¨ ulteriori strumenti e funzionalit√† offerte da Jupyter Notebook.\nIn conclusione, i Jupyter Notebook rappresentano uno strumento indispensabile per chi lavora nel campo della programmazione e dell‚Äôanalisi dati, grazie alla loro capacit√† di unire codice, visualizzazione dei dati, e annotazioni testuali in un unico documento interattivo e facilmente condivisibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a02_shell.html",
    "href": "chapters/chapter_7/a02_shell.html",
    "title": "Online Appendix C ‚Äî La Shell",
    "section": "",
    "text": "C.1 Che cos‚Äô√® una Shell?\nUna shell √® un programma che riceve comandi dall‚Äôutente tramite tastiera (o da file) e li passa al sistema operativo per l‚Äôesecuzione. Pu√≤ essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a02_shell.html#che-cos√®-una-shell",
    "href": "chapters/chapter_7/a02_shell.html#che-cos√®-una-shell",
    "title": "Online Appendix C ‚Äî La Shell",
    "section": "",
    "text": "C.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nC.1.2 Windows vs macOS/Linux\n\nWindows 10: √à possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l‚Äôambiente preferito √® solitamente PowerShell.\nmacOS/Linux: Zsh √® la shell predefinita in entrambi i sistemi. √à consigliabile sfruttare l‚Äôapplicazione warp per un‚Äôesperienza utente moderna e ottimizzata.\n\n\n\nC.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nC.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nC.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless/more: Visualizza il contenuto dei file con possibilit√† di navigazione.\ncat: Mostra l‚Äôintero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nC.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l‚Äôutilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilit√† nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma pi√π potente perch√© pu√≤ rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nC.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nC.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilit√† di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l‚Äôintero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n```bsqcatudmjoh Suggerimenti per una Gestione Ottimale dei File e delle Cartelle\n√à cruciale familiarizzarsi con l‚Äôutilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L‚Äôimpiego dei percorsi relativi rende il processo di navigazione pi√π intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l‚Äôutilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: √à importante evitare l‚Äôinserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, ), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l‚Äôuso del trattino (-) pu√≤ causare problemi; quindi √® consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilit√† con alcuni sistemi operativi o applicazioni, rendendo pi√π complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, √® consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, √® possibile ottimizzare notevolmente l‚Äôorganizzazione e la gestione dei propri file, migliorando l‚Äôefficienza del lavoro e riducendo il rischio di errori. ```\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarit√† con la shell √® fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a03_colab_tutorial.html",
    "href": "chapters/chapter_7/a03_colab_tutorial.html",
    "title": "Online Appendix D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "D.1 Preparazione su Google Drive\nPer iniziare, √® necessario effettuare alcune operazioni preliminari su Google Drive:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a03_colab_tutorial.html#preparazione-su-google-drive",
    "href": "chapters/chapter_7/a03_colab_tutorial.html#preparazione-su-google-drive",
    "title": "Online Appendix D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "Salvataggio dei file necessari: Accedi al tuo account Google Drive e salva i file di interesse, come un dataset e un Jupyter Notebook. Per esempio, potresti creare un Jupyter Notebook con Visual Studio Code e salvarlo con l‚Äôestensione .ipynb. In questo esempio, il file STAR.csv √® stato salvato nella cartella drive/MyDrive/teaching/psicometria/2024.\nPosizionamento dei file: Assicurati di conoscere con precisione il percorso della cartella in cui hai salvato i tuoi file. √à possibile salvare il notebook in qualsiasi cartella, ma √® importante ricordare dove si trova. Nel nostro esempio, anche il notebook import_data.ipynb √® stato salvato nella stessa cartella del dataset.\n\n\nD.1.1 Collegamento a Google Colab\nPer collegare il tuo Google Drive a Colab, inserisci il seguente codice nella prima cella del tuo Jupyter Notebook su Colab:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nEsegui questa cella per iniziare il processo di autenticazione. Ti verr√† richiesto di inserire le tue credenziali (si consiglia di utilizzare l‚Äôaccount istituzionale) e di concedere i permessi necessari a Colab per accedere al tuo Drive.\n\n\nD.1.2 Verifica del file\nPrima di procedere, √® utile verificare che il file desiderato si trovi effettivamente nel percorso specificato. Usa un comando simile al seguente per elencare i file presenti nella cartella:\n!ls drive/MyDrive/teaching/psicometria/2024\nSe il comando mostra il file STAR.csv, significa che √® presente nella cartella e pronto per essere utilizzato.\n\n\nD.1.3 Importazione dei pacchetti e del dataset\nPrima di importare i dati, importa i pacchetti Python necessari per la tua analisi:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSuccessivamente, puoi importare i dati direttamente dal file CSV specificando il percorso completo:\ndf = pd.read_csv(\"drive/MyDrive/teaching/psicometria/2024/STAR.csv\")\n√à fondamentale usare il percorso completo dal punto di montaggio drive fino al nome del file. Il percorso varier√† a seconda dell‚Äôutente e della struttura del suo Drive.\n\n\nD.1.4 Visualizzazione dei dati\nCon i dati ora disponibili in df, puoi procedere con l‚Äôanalisi. Per esempio, per creare un istogramma della variabile reading, puoi usare il seguente codice:\n_ = sns.histplot(data=df, x=\"reading\", stat='density')\nQuesto ti permetter√† di visualizzare la distribuzione dei dati relativi alla lettura nel dataset STAR.csv.\nSeguendo questi passaggi, puoi facilmente lavorare con i file salvati su Google Drive direttamente all‚Äôinterno di un Jupyter Notebook su Google Colab.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html",
    "href": "chapters/chapter_7/a04_virtual_env.html",
    "title": "Online Appendix E ‚Äî Ambienti virtuali",
    "section": "",
    "text": "E.1 Concetto di Ambiente Virtuale\nUn ambiente virtuale √® uno spazio di lavoro isolato sul vostro computer, dove potete installare e utilizzare librerie Python senza interferire con il sistema principale. Questo isolamento consente di gestire le versioni delle librerie in modo efficiente, mantenendo il sistema organizzato e sicuro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "href": "chapters/chapter_7/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "title": "Online Appendix E ‚Äî Ambienti virtuali",
    "section": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali",
    "text": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali\n\nIsolamento: Permette di selezionare e mantenere versioni specifiche di Python e delle librerie, garantendo la compatibilit√† e la stabilit√† del progetto.\nOrdine e Sicurezza: Mantiene separato l‚Äôambiente virtuale dal sistema principale, evitando conflitti e assicurando che le modifiche non influenzino altri programmi.\nRiproducibilit√† del Codice: Consente di condividere il codice in modo che funzioni correttamente su altri computer, garantendo coerenza e riproducibilit√† del lavoro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "href": "chapters/chapter_7/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "title": "Online Appendix E ‚Äî Ambienti virtuali",
    "section": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda",
    "text": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda\nPer creare e gestire ambienti virtuali, √® possibile utilizzare conda, uno strumento incluso in Anaconda. Seguire i seguenti passaggi:\n\nAssicurarsi di avere Anaconda correttamente installato sul sistema.\nUtilizzare il terminale su macOS/Linux o PowerShell su Windows.\nEvitare di installare pacchetti direttamente nell‚Äôambiente base di Conda.\nCreare un nuovo ambiente virtuale usando il comando conda create.\nAttivare l‚Äôambiente virtuale appena creato utilizzando conda activate.\nInstallare i pacchetti necessari all‚Äôinterno dell‚Äôambiente virtuale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "href": "chapters/chapter_7/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "title": "Online Appendix E ‚Äî Ambienti virtuali",
    "section": "E.4 Gestione dell‚ÄôAmbiente Virtuale",
    "text": "E.4 Gestione dell‚ÄôAmbiente Virtuale\nPer una gestione pi√π efficiente degli ambienti virtuali, √® consigliabile utilizzare la linea di comando anzich√© l‚Äôinterfaccia grafica di Anaconda. Questo offre maggiore controllo e flessibilit√† nel processo di creazione e gestione degli ambienti.\nSeguendo correttamente questi passaggi, √® possibile sfruttare appieno i vantaggi degli ambienti virtuali, garantendo un ambiente di sviluppo Python pulito e ben organizzato.\n√à fondamentale **evitare l'installazione diretta di pacchetti nell'ambiente `base` di Conda**. Assicuratevi sempre di seguire attentamente i seguenti passaggi:\n\n1. Disattivate l'ambiente `base`.\n2. Create un nuovo ambiente virtuale.\n3. Attivate il nuovo ambiente appena creato.\n\nSolo dopo aver completato questi passaggi, √® sicuro procedere con l'installazione dei pacchetti necessari. √à possibile verificare l'ambiente attivo osservando il nome visualizzato all'inizio del prompt nel terminale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "href": "chapters/chapter_7/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "title": "Online Appendix E ‚Äî Ambienti virtuali",
    "section": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali",
    "text": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali\n\nDisattivare l‚ÄôAmbiente Virtuale Corrente: Se siete in un ambiente virtuale e desiderate uscirne, utilizzate il comando:\nconda deactivate\nSe non siete in un ambiente virtuale, potete procedere al passaggio successivo.\nCreare un Nuovo Ambiente Virtuale: Per utilizzare il campionatore CmdStan e il linguaggio di programmazione probabilistica Stan, adottate l‚Äôambiente virtuale cmdstan_env. Se si utilizza conda, √® possibile installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge tramite la seguente procedura:\nconda create -n cmdstan_env -c conda-forge cmdstanpy\nConda richieder√† la conferma digitando y. Questo passaggio crea l‚Äôambiente e installa cmdstanpy insieme alle dipendenze necessarie.\nAttivare il Nuovo Ambiente: Per utilizzare l‚Äôambiente appena creato, attivatelo tramite:\nconda activate cmdstan_env\nInstallare le Librerie Richieste: All‚Äôinterno dell‚Äôambiente, installate altre librerie necessarie. Ecco come installare le librerie che utilizzeremo:\nconda install -c conda-forge jax numpyro bambi arviz seaborn jupyter-book ipywidgets watermark pingouin networkx -y \nNota: Gli utenti Windows potrebbero dover utilizzare nutpie come alternativa a jax.\nComandi Utili per Gestire Ambienti e Librerie:\n\nElencare gli ambienti virtuali disponibili e verificare quello attivo:\nconda env list\nRimuovere un ambiente virtuale specifico, ad esempio my_env:\nconda env remove -n my_env\nRimuovere una libreria da un ambiente specifico, ad esempio package_name:\nconda remove -n nome_ambiente package_name\n\n\nSeguendo attentamente questi passaggi e utilizzando i comandi di gestione, sarete in grado di creare e gestire efficacemente gli ambienti virtuali con Conda, garantendo una gestione pulita e ordinata delle dipendenze dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#conda-forge",
    "href": "chapters/chapter_7/a04_virtual_env.html#conda-forge",
    "title": "Online Appendix E ‚Äî Ambienti virtuali",
    "section": "E.6 Conda Forge",
    "text": "E.6 Conda Forge\n√à consigliato aggiungere Conda Forge come canale aggiuntivo da cui Conda pu√≤ cercare e installare i pacchetti. Conda Forge √® una collezione di pacchetti gestita dalla community.\n\nE.6.1 Aggiungere Conda Forge\nPer aggiungere Conda Forge come canale, eseguire i seguenti comandi:\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\nconda config --add channels conda-forge: Aggiunge Conda Forge come canale aggiuntivo per la ricerca e l‚Äôinstallazione dei pacchetti.\nconda config --set channel_priority strict: Imposta la priorit√† dei canali su ‚Äústrict‚Äù, dando priorit√† ai pacchetti trovati nei canali elencati per primi nel file di configurazione .condarc.\n\n\n\nE.6.2 Vantaggi dell‚ÄôUso di Conda Forge\n\nAmpia Disponibilit√† di Pacchetti: Conda Forge offre un numero maggiore di pacchetti rispetto al canale predefinito di Conda, aumentando le possibilit√† di trovare il pacchetto necessario senza ricorrere ad altre soluzioni.\nAggiornamenti Frequenti: I pacchetti su Conda Forge vengono aggiornati pi√π frequentemente, rendendo pi√π probabile trovare le versioni pi√π recenti.\nCoerenza e Compatibilit√†: Utilizzando la priorit√† ‚Äústrict‚Äù e Conda Forge, si aumenta la coerenza e la compatibilit√† tra i pacchetti, riducendo il rischio di conflitti tra dipendenze.\n\nAggiungere Conda Forge come canale e impostare la priorit√† dei canali su ‚Äústrict‚Äù sono pratiche consigliate per migliorare la gestione dei pacchetti con Conda. Questo approccio aiuta a mantenere l‚Äôambiente stabile, aggiornato e compatibile con le ultime versioni dei pacchetti disponibili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "href": "chapters/chapter_7/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "title": "Online Appendix E ‚Äî Ambienti virtuali",
    "section": "E.7 Utilizzo di Graphviz (Opzionale)",
    "text": "E.7 Utilizzo di Graphviz (Opzionale)\nPer utilizzare il pacchetto Python graphviz, √® necessario installare prima Graphviz sul vostro computer. Le istruzioni specifiche per l‚Äôinstallazione variano a seconda del sistema operativo e sono disponibili sul sito ufficiale di Graphviz.\n\nE.7.1 Installazione di Graphviz\n\nInstallazione di Graphviz: Seguire le istruzioni sul sito di Graphviz per installare il software sul vostro sistema operativo (Windows, macOS, Linux).\nVerifica dell‚ÄôInstallazione: Dopo l‚Äôinstallazione, assicuratevi che Graphviz sia correttamente installato eseguendo il seguente comando nel terminale:\ndot -V\nQuesto comando dovrebbe restituire la versione di Graphviz installata.\n\n\n\nE.7.2 Installazione del Pacchetto Python graphviz\nDopo aver installato Graphviz, potete procedere con l‚Äôinstallazione del pacchetto Python graphviz nel vostro ambiente virtuale. Seguite questi passaggi:\n\nAttivare l‚ÄôAmbiente Virtuale: Attivate l‚Äôambiente virtuale in cui avete installato pymc (ad esempio, pymc_env) nella vostra console:\nconda activate pymc_env\nInstallare il Pacchetto Python graphviz: Eseguite il seguente comando per installare il pacchetto graphviz tramite Conda Forge:\nconda install -c conda-forge graphviz\n\n\n\nE.7.3 Vantaggi dell‚ÄôUtilizzo di Graphviz\nL‚Äôinstallazione di Graphviz e del relativo pacchetto Python consente di creare e visualizzare grafici e diagrammi all‚Äôinterno del vostro ambiente Python. Questo pu√≤ essere particolarmente utile per visualizzare strutture di dati complesse, flussi di lavoro o grafi probabilistici.\nSeguendo questi passaggi, sarete in grado di utilizzare le funzionalit√† di Graphviz nel vostro ambiente Python, migliorando le capacit√† di visualizzazione e analisi dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a10_math_symbols.html",
    "href": "chapters/chapter_7/a10_math_symbols.html",
    "title": "Online Appendix F ‚Äî Simbologia di base",
    "section": "",
    "text": "Per una scrittura pi√π sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL‚Äôoperatore logico booleano \\(\\land\\) significa ‚Äúe‚Äù (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa ‚Äúo‚Äù (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire ‚Äúesiste almeno un‚Äù e indica l‚Äôesistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicit√† \\(\\exists!\\) (‚Äúesiste soltanto un‚Äù) indica l‚Äôesistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l‚Äôesistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire ‚Äúper ogni.‚Äù\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) √® un elemento dell‚Äôinsieme \\(A\\).\nL‚Äôimplicazione logica ‚Äú\\(\\Rightarrow\\)‚Äù significa ‚Äúimplica‚Äù (se ‚Ä¶allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) √® condizione sufficiente per la verit√† di \\(Q\\) e che \\(Q\\) √® condizione necessaria per la verit√† di \\(P\\).\nL‚Äôequivalenza matematica ‚Äú\\(\\iff\\)‚Äù significa ‚Äúse e solo se‚Äù e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge ‚Äútale che.‚Äù\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge ‚Äúuguale per definizione.‚Äù\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge ‚Äúproporzionale a.‚Äù\nIl simbolo \\(\\approx\\) si legge ‚Äúcirca.‚Äù\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire ‚Äúappartiene‚Äù e indica l‚Äôappartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire ‚Äúnon appartiene.‚Äù\nIl simbolo \\(\\subseteq\\) si legge ‚Äú√® un sottoinsieme di‚Äù (pu√≤ coincidere con l‚Äôinsieme stesso). Il simbolo \\(\\subset\\) si legge ‚Äú√® un sottoinsieme proprio di.‚Äù\nIl simbolo \\(\\#\\) indica la cardinalit√† di un insieme.\nIl simbolo \\(\\cap\\) indica l‚Äôintersezione di due insiemi. Il simbolo \\(\\cup\\) indica l‚Äôunione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l‚Äôinsieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l‚Äôinsieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) √® l‚Äôinsieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore pi√π alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densit√† di probabilit√†.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilit√† o densit√† di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) √® una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilit√† di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilit√† di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html",
    "href": "chapters/chapter_7/a11_numbers.html",
    "title": "Online Appendix G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "",
    "text": "G.1 Numeri binari\nI numeri binari costituiscono la forma pi√π fondamentale di sistema numerico in informatica, essendo composto esclusivamente da due simboli, ovvero 0 e 1. Questo sistema √® frequentemente impiegato per rappresentare dualit√† logiche, come vero/falso o presenza/assenza, in virt√π della sua innata semplicit√† binaria. La sua applicazione √® particolarmente efficace nell‚Äôelaborazione di dati per generare statistiche sintetiche in modo efficiente e rapido.\nImmaginiamo di porre la seguente domanda a 10 studenti: ‚ÄúTi piacciono i mirtilli?‚Äù Le risposte potrebbero essere le seguenti:\nopinion = (True, False, True, True, True, False, True, True, True, False)\nopinion\n\n(True, False, True, True, True, False, True, True, True, False)\nIn questo caso, abbiamo utilizzato i numeri binari 0 e 1 per rappresentare risposte diverse, dove False indica ‚ÄúNo‚Äù e True indica ‚ÄúSi‚Äù. Questa rappresentazione binaria ci consente di ottenere facilmente una panoramica delle preferenze degli studenti riguardo i mirtilli.\nIn Python True equivale a 1 e False a zero. Possiamo dunque calcolare la proporzione di risposte positive nel modo seguente:\nsum(opinion) / len(opinion)\n\n0.7",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-interi",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-interi",
    "title": "Online Appendix G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.2 Numeri interi",
    "text": "G.2 Numeri interi\nI numeri interi sono numeri privi di decimali e comprendono sia i numeri naturali utilizzati per il conteggio, come 1, 2, ‚Ä¶, sia i numeri con il segno, necessari per rappresentare grandezze negative. L‚Äôinsieme dei numeri naturali √® indicato con il simbolo \\(\\mathbb{N}\\). L‚Äôinsieme numerico dei numeri interi relativi si rappresenta come \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-razionali",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-razionali",
    "title": "Online Appendix G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.3 Numeri razionali",
    "text": "G.3 Numeri razionali\nI numeri razionali sono numeri frazionari rappresentabili come \\(m/n\\), dove \\(m\\) e \\(n\\) sono numeri interi e \\(n\\) √® diverso da zero. Gli elementi dell‚Äôinsieme dei numeri razionali sono quindi dati da \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). √à importante notare che l‚Äôinsieme dei numeri naturali √® incluso in quello dei numeri interi, che a sua volta √® incluso in quello dei numeri razionali, ovvero \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Per rappresentare solo i numeri razionali non negativi, utilizziamo il simbolo \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-irrazionali",
    "title": "Online Appendix G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.4 Numeri irrazionali",
    "text": "G.4 Numeri irrazionali\nTuttavia, alcune grandezze non possono essere esprimibili come numeri interi o razionali. Questi numeri sono noti come numeri irrazionali e sono rappresentati dall‚Äôinsieme \\(\\mathbb{R}\\). Essi comprendono numeri illimitati e non periodici, che non possono essere scritti come frazioni. Ad esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\(\\pi = 3.141592\\ldots\\) sono esempi di numeri irrazionali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a11_numbers.html#numeri-reali",
    "href": "chapters/chapter_7/a11_numbers.html#numeri-reali",
    "title": "Online Appendix G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.5 Numeri reali",
    "text": "G.5 Numeri reali\nI numeri razionali rappresentano solo una parte dei punti sulla retta \\(r\\). Per rappresentare ogni possibile punto sulla retta, √® necessario introdurre i numeri reali. L‚Äôinsieme dei numeri reali comprende numeri positivi, negativi e nulli, e contiene come casi particolari i numeri interi, razionali e irrazionali. In statistica, il numero di decimali spesso indica il grado di precisione della misurazione.\n\nG.5.1 Intervalli\nQuesto ci porta a esplorare gli intervalli, una struttura matematica che ci aiuta a definire sottoinsiemi specifici sulla retta numerica. Gli intervalli aperti, che escludono i punti di inizio e fine. D‚Äôaltro canto, gli intervalli chiusi includono sia il punto di inizio che quello di fine, fornendo una copertura di valori senza tralasciare i confini. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\n\nIntervallo\n\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html",
    "href": "chapters/chapter_7/a13_sets.html",
    "title": "Online Appendix H ‚Äî Insiemi",
    "section": "",
    "text": "H.1 Diagrammi di Eulero-Venn\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le propriet√† delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19¬∞ secolo John Venn, anche se rappresentazioni simili erano gi√† state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, √® possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le propriet√† degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all‚Äôinterno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/chapter_7/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Online Appendix H ‚Äî Insiemi",
    "section": "H.2 Appartenenza ad un insieme",
    "text": "H.2 Appartenenza ad un insieme\nUsiamo ora Python.\n\nSet1 = {1, 2}\nprint(Set1)\nprint(type(Set1))\n\n{1, 2}\n&lt;class 'set'&gt;\n\n\n\nmy_list = [1, 2, 3, 4]\nmy_set_from_list = set(my_list)\nprint(my_set_from_list)\n\n{1, 2, 3, 4}\n\n\nL‚Äôappartenenza ad un insieme si verifica con in e not in.\n\nmy_set = set([1, 3, 5])\nprint(\"Ecco il mio insieme:\", my_set)\nprint(\"1 appartiene all'insieme:\", 1 in my_set)\nprint(\"2 non appartiene all'insieme:\", 2 in my_set)\nprint(\"4 NON appartiene all'insieme:\", 4 not in my_set)\n\nEcco il mio insieme: {1, 3, 5}\n1 appartiene all'insieme: True\n2 non appartiene all'insieme: False\n4 NON appartiene all'insieme: True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/chapter_7/a13_sets.html#relazioni-tra-insiemi",
    "title": "Online Appendix H ‚Äî Insiemi",
    "section": "H.3 Relazioni tra insiemi",
    "text": "H.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l‚Äôinsieme universo e l‚Äôinsieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv = set([x for x in range(11)])\nSuper = set([x for x in range(11) if x % 2 == 0])\nDisj = set([x for x in range(11) if x % 2 == 1])\nSub = set([4, 6])\nNull = set([x for x in range(11) if x &gt; 10])\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\", Univ)\nprint(\"Tutti gli interi positivi pari fino a 10:\", Super)\nprint(\"Tutti gli interi positivi dispari fino a 10:\", Disj)\nprint(\"Insieme di due elementi, 4 e 6:\", Sub)\nprint(\"Un isieme vuoto:\", Null)\n\nInsieme Universo (tutti gli interi positivi fino a 10): {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nTutti gli interi positivi pari fino a 10: {0, 2, 4, 6, 8, 10}\nTutti gli interi positivi dispari fino a 10: {1, 3, 5, 7, 9}\nInsieme di due elementi, 4 e 6: {4, 6}\nUn isieme vuoto: set()\n\n\n\nprint('√à \"Super\" un sovrainsieme di \"Sub\"?', Super.issuperset(Sub))\nprint('√à \"Super\" un sottoinsieme di \"Univ\"?', Super.issubset(Univ))\nprint('√à \"Sub\" un sovrainsieme di \"Super\"?', Sub.issuperset(Super))\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?', Sub.isdisjoint(Disj))\n\n√à \"Super\" un sovrainsieme di \"Sub\"? True\n√à \"Super\" un sottoinsieme di \"Univ\"? True\n√à \"Sub\" un sovrainsieme di \"Super\"? False\nSono \"Super\" e \"Disj\" insiemi disgiunti? True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/chapter_7/a13_sets.html#operazioni-tra-insiemi",
    "title": "Online Appendix H ‚Äî Insiemi",
    "section": "H.4 Operazioni tra insiemi",
    "text": "H.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cio√®\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l‚Äôinsieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l‚Äôinsieme differenza \\(A \\setminus B\\) √® detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) √® una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare √® data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) √® la regione delimitata dal rettangolo, \\(L\\) √® la regione all‚Äôinterno del cerchio di sinistra e \\(R\\) √® la regione all‚Äôinterno del cerchio di destra. La regione evidenziata mostra l‚Äôinsieme indicato sotto ciascuna figura.\n\n\n\nDiagrammi di Venn\n\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\n\nLeggi di DeMorgan\n\n\nVediamo ora come si eseguono le operazioni tra insiemi con Python.\nEguaglianza e differenza.\n\nS1 = {1, 2}\nS2 = {2, 2, 1, 1, 2}\nprint(\n    \"S1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\nS1==S2: True\n\n\n\nS1 = {1, 2, 3, 4, 5, 6}\nS2 = {1, 2, 3, 4, 0, 6}\nprint(\n    \"S1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\nS1==S2: False\n\n\nIntersezione. Si noti che il connettivo logico & corrisponde all‚Äôintersezione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\n\nS1: {9, 3, 6}\n\n\n\nS2 = set([x for x in range(1, 7)])\nprint(\"S2:\", S2)\n\nS2: {1, 2, 3, 4, 5, 6}\n\n\n\nS_intersection = S1.intersection(S2)\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nS_intersection = S1 & S2\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\n\n\n\nS3 = set([x for x in range(6, 10)])\nprint(\"S3:\", S3)\nS1_S2_S3 = S1.intersection(S2).intersection(S3)\nprint(\"Intersection of S1, S2, and S3:\", S1_S2_S3)\n\nS3: {8, 9, 6, 7}\nIntersection of S1, S2, and S3: {6}\n\n\nUnione. Si noti che il connettivo logico | corrisponde all‚Äôunione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\nS2 = set([x for x in range(1, 5)])\nprint(\"S2:\", S2)\n\nS_union = S1.union(S2)\nprint(\"Unione di S1 e S2:\", S_union)\nS_union = S1 | S2\nprint(\"Unione di S1 e S2:\", S_union)\n\nS1: {9, 3, 6}\nS2: {1, 2, 3, 4}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\n\n\nInsieme complementare.\n\nS = set([x for x in range(21) if x % 2 == 0])\nprint(\"S √® l'insieme dei numeri interi pari tra 0 e 20:\", S)\n\nS √® l'insieme dei numeri interi pari tra 0 e 20: {0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20}\n\n\n\nS_complement = set([x for x in range(21) if x % 2 != 0])\nprint(\"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\", S_complement)\n\nS_complement √® l'insieme dei numeri interi dispari tra 0 e 20: {1, 3, 5, 7, 9, 11, 13, 15, 17, 19}\n\n\n\nprint(\n    \"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\",\n    S.union(S_complement) == set([x for x in range(21)]),\n)\n\n√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20? True\n\n\nDifferenza tra insiemi.\n\nS1 = set([x for x in range(31) if x % 3 == 0])\nprint(\"Set S1:\", S1)\n\nSet S1: {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\n\n\n\nS2 = set([x for x in range(31) if x % 5 == 0])\nprint(\"Set S2:\", S2)\n\nSet S2: {0, 5, 10, 15, 20, 25, 30}\n\n\n\nS_difference = S2 - S1\nprint(\"Differenza tra S2 e S1, i.e. S2\\S1:\", S_difference)\n\nS_difference = S1.difference(S2)\nprint(\"Differenza tra S1 e S2, i.e. S1\\S2:\", S_difference)\n\nDifferenza tra S1 e S2 i.e. S2\\S1: {25, 10, 20, 5}\nDifferenza tra S2 e S1 i.e. S1\\S2: {3, 6, 9, 12, 18, 21, 24, 27}\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Œî, √® un‚Äôoperazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all‚Äôunione tra i due insiemi meno la loro intersezione.\n\nprint(\"S1\", S1)\nprint(\"S2\", S2)\nprint(\"Differenza simmetrica\", S1 ^ S2)\nprint(\"Differenza simmetrica\", S2.symmetric_difference(S1))\n\nS1 {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\nS2 {0, 5, 10, 15, 20, 25, 30}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/chapter_7/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Online Appendix H ‚Äî Insiemi",
    "section": "H.5 Coppie ordinate e prodotto cartesiano",
    "text": "H.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) √® l‚Äôinsieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) √® la prima componente (o prima coordinata) e \\(y\\) la seconda. L‚Äôinsieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPi√π in generale, un prodotto cartesiano di \\(n\\) insiemi pu√≤ essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento √® una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non √® dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento √® possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all‚Äôn-esimo. Il prodotto cartesiano prende il nome da Ren√© Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA = set([\"a\", \"b\", \"c\"])\nS = {1, 2, 3}\n\n\ndef cartesian_product(S1, S2):\n    result = set()\n    for i in S1:\n        for j in S2:\n            result.add(tuple([i, j]))\n    return result\n\n\nC = cartesian_product(A, S)\nprint(f\"Prodotto cartesiano di A e S\\n{A} x {S} = {C}\")\n\nProdotto cartesiano di A e S\n{'Head', 'Tail'} x {1, 2, 3} = {('Tail', 1), ('Head', 2), ('Head', 1), ('Tail', 3), ('Tail', 2), ('Head', 3)}\n\n\nSi definisce cardinalit√† (o potenza) di un insieme finito il numero degli elementi dell‚Äôinsieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalit√† dell'insieme prodotto cartesiano √®:\", len(C))\n\nLa cardinalit√† dell'insieme prodotto cartesiano √®: 9\n\n\nInvece di scrivere funzioni noi stessi, √® possibile usare la libreria itertools di Python. Si ricordi di trasformare l‚Äôoggetto risultante in una lista per la visualizzazione e la successiva elaborazione.\n\nfrom itertools import product as prod\n\n\nA = set([x for x in range(1, 7)])\nB = set([x for x in range(1, 7)])\np = list(prod(A, B))\n\nprint(\"A √® l'insieme di tutti i possibili lanci di un dado:\", A)\nprint(\"B √® l'insieme di tutti i possibili lanci di un dado:\", B)\nprint(\n    \"\\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\\n\",\n    p,\n)\n\nA √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\nB √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\n\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\n [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLa cardinalit√† (cio√® il numero di elementi) del prodotto cartesiano tra due o pi√π insiemi √® uguale al prodotto delle cardinalit√† degli insiemi considerati: card(A √ó B) = card(A) ¬∑ card(B).\nUsando itertools √® facile calcolare la cardinalit√† del prodotto cartesiano di un insieme per se stesso. Consideriamo il quadrato dell‚Äôinsieme costituito dai risultati del lancio di una moneta. L‚Äôinsieme risultante avr√† cardinalit√† \\(2 \\cdot 2 = 4\\).\n\nA = {\"Head\", \"Tail\"} \np2 = list(prod(A, repeat=2))  \nprint(f\"Il quadrato dell'insieme A √® un insieme che contiene {len(p2)} elementi: {p2}\")\n\nIl quadrato dell'insieme A √® un insieme che contiene 4 elementi: [('Head', 'Head'), ('Head', 'Tail'), ('Tail', 'Head'), ('Tail', 'Tail')]\n\n\nL‚Äôinsieme \\(A\\) elevato alla terza potenza produce un insieme la cui cardinalit√† √®\n\np3 = list(prod(A, repeat=3))  \nprint(f\"L'insieme A elevato alla terza potenza √® costituito da {len(p3)} elementi: {p3}\")\n\nL'insieme A elevato alla terza potenza √® costituito da 8 elementi: [('Head', 'Head', 'Head'), ('Head', 'Head', 'Tail'), ('Head', 'Tail', 'Head'), ('Head', 'Tail', 'Tail'), ('Tail', 'Head', 'Head'), ('Tail', 'Head', 'Tail'), ('Tail', 'Tail', 'Head'), ('Tail', 'Tail', 'Tail')]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13_sets.html#watermark",
    "href": "chapters/chapter_7/a13_sets.html#watermark",
    "title": "Online Appendix H ‚Äî Insiemi",
    "section": "H.6 Watermark",
    "text": "H.6 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html",
    "href": "chapters/chapter_7/a13a_probability.html",
    "title": "Online Appendix I ‚Äî Sigma algebra",
    "section": "",
    "text": "I.1 Spiegazione\nUna \\(\\sigma\\)-algebra (o \\(\\sigma\\)-campo) √® un insieme di sottoinsiemi di uno spazio campionario \\(\\Omega\\) che soddisfa specifiche propriet√†. Queste propriet√† permettono di definire una struttura matematica per assegnare e calcolare le probabilit√† in modo consistente. Le propriet√† fondamentali di una \\(\\sigma\\)-algebra sono:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html#spiegazione",
    "href": "chapters/chapter_7/a13a_probability.html#spiegazione",
    "title": "Online Appendix I ‚Äî Sigma algebra",
    "section": "",
    "text": "Insieme Vuoto: L‚Äôinsieme vuoto \\(\\varnothing\\) deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{A}\\). Questo garantisce che anche l‚Äôassenza di qualsiasi evento sia considerata.\nChiusura rispetto all‚ÄôUnione: Se una sequenza infinita di insiemi \\(A_1, A_2, \\dots\\) appartiene a \\(\\mathcal{A}\\), allora anche la loro unione \\(\\cup_{i=1}^\\infty A_i\\) deve appartenere a \\(\\mathcal{A}\\). Questa propriet√† permette di costruire nuovi eventi a partire da unione di eventi gi√† considerati misurabili.\nChiusura rispetto al Complemento: Se un insieme \\(A\\) appartiene a \\(\\mathcal{A}\\), allora anche il suo complemento \\(A^c\\) deve appartenere a \\(\\mathcal{A}\\). Questa propriet√† assicura che, se possiamo misurare un evento, possiamo anche misurare l‚Äôevento opposto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html#spazi-misurabili-e-di-probabilit√†",
    "href": "chapters/chapter_7/a13a_probability.html#spazi-misurabili-e-di-probabilit√†",
    "title": "Online Appendix I ‚Äî Sigma algebra",
    "section": "I.2 Spazi Misurabili e di Probabilit√†",
    "text": "I.2 Spazi Misurabili e di Probabilit√†\n\nSpazio Misurabile: Una coppia \\((\\Omega, \\mathcal{A})\\), dove \\(\\Omega\\) √® lo spazio campionario e \\(\\mathcal{A}\\) √® una \\(\\sigma\\)-algebra su \\(\\Omega\\), √® chiamata spazio misurabile. In questo contesto, gli insiemi misurabili sono quelli a cui possiamo assegnare una misura, come la probabilit√†.\nSpazio di Probabilit√†: Se aggiungiamo una misura di probabilit√† \\(\\mathbb{P}\\) a uno spazio misurabile \\((\\Omega, \\mathcal{A})\\), otteniamo uno spazio di probabilit√† \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\). La misura di probabilit√† \\(\\mathbb{P}\\) assegna valori di probabilit√† a ciascuno degli insiemi in \\(\\mathcal{A}\\) in modo che le propriet√† assiomatiche della probabilit√† siano soddisfatte.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a13a_probability.html#sigma-campo-di-borel",
    "href": "chapters/chapter_7/a13a_probability.html#sigma-campo-di-borel",
    "title": "Online Appendix I ‚Äî Sigma algebra",
    "section": "I.3 \\(\\sigma\\)-campo di Borel",
    "text": "I.3 \\(\\sigma\\)-campo di Borel\nQuando lo spazio campionario \\(\\Omega\\) √® la retta reale, si usa spesso il \\(\\sigma\\)-campo di Borel. Questo √® il pi√π piccolo \\(\\sigma\\)-campo che contiene tutti gli insiemi aperti della retta reale. √à fondamentale per definire la misurabilit√† e le probabilit√† su \\(\\mathbb{R}\\), poich√© contiene tutti gli insiemi che possiamo considerare ‚Äúmisurabili‚Äù nella pratica.\n\nI.3.1 Conclusione\nLe \\(\\sigma\\)-algebre permettono di gestire insiemi e misure in modo strutturato e coerente, formando la base matematica per la teoria della probabilit√† e altre aree dell‚Äôanalisi matematica. Utilizzando \\(\\sigma\\)-algebre, possiamo definire spazi di probabilit√† che sono essenziali per modellare e analizzare fenomeni aleatori in maniera rigorosa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Sigma algebra</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html",
    "href": "chapters/chapter_7/a14_combinatorics.html",
    "title": "Online Appendix J ‚Äî Calcolo combinatorio",
    "section": "",
    "text": "J.1 Principio del prodotto\nI metodi di base del calcolo combinatorio applicano due principi: la regola del prodotto e la regola della somma. Consideriamo il principio del prodotto.\nIn generale, una scelta pu√≤ essere effettuata in pi√π fasi, ad esempio \\(k\\). Supponiamo che per ogni \\(i = 1, \\dots, k\\) la scelta da compiere al \\(i\\)-esimo stadio possa essere effettuata in \\(n_i\\) modi. Secondo il principio del prodotto, il numero totale di possibili scelte √® dato dal prodotto dei singoli numeri, ovvero:\n\\[\nn_{\\text{tot}} = n_1 \\cdot  n_2 \\cdots n_{k-1} \\cdot n_k.\n\\]\nEsempio 1. Ho a disposizione 2 paia di scarpe, 3 paia di pantaloni e 5 magliette. In quanti modi diversi mi posso vestire?\n\\[\n2 \\cdot 3 \\cdot 5 = 30\n\\]\nEsempio 2. In Minnesota le targhe delle automobili sono costituite da tre lettere (da A a Z) seguite da tre numeri (da 0 a 9). Qual √® la proporzione di targhe che iniziano con GZN?\nLa soluzione √® data dal numero di targhe che iniziano con GZN diviso per il numero totale di targhe possibili.\nIl numero totale di targe √® \\(26 \\cdot 26 \\cdot 26 \\cdot 10 \\cdot 10 \\cdot 10 = 17,576,000\\). Per calcolare il numero di targhe che iniziano con GZN, consideriamo le targhe che hanno la forma GZN _ _ _. Per i tre simboli mancanti ci sono \\(10 \\cdot 10 \\cdot 10\\) possibilit√†. Dunque la proporzione cercata √®\n\\[\n10^3/(26^3 \\cdot 10^3) = 1/26^3 = 0.0000569.\n\\]\n10**3 / (26**3 * 10**3)\n\n5.689576695493855e-05",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/chapter_7/a14_combinatorics.html#principio-della-somma",
    "title": "Online Appendix J ‚Äî Calcolo combinatorio",
    "section": "J.2 Principio della somma",
    "text": "J.2 Principio della somma\nIl principio della somma afferma che se un insieme pu√≤ essere suddiviso in due o pi√π sottoinsiemi disgiunti, allora il numero totale di elementi nell‚Äôinsieme √® dato dalla somma dei numeri di elementi in ciascun sottoinsieme.\nIn altre parole, se si vuole determinare il numero totale di modi in cui √® possibile realizzare un certo evento, e questo evento pu√≤ essere realizzato in modo esclusivo in modo A oppure B, allora il numero totale di modi in cui √® possibile realizzare l‚Äôevento √® dato dalla somma dei modi in cui pu√≤ essere realizzato in modo A e dei modi in cui pu√≤ essere realizzato in modo B.\nAd esempio, se si vuole determinare il numero totale di modi in cui √® possibile scegliere un dolce da una tavola con due tipi di dolci (ad esempio torta e biscotti), il principio della somma afferma che il numero totale di modi √® dato dalla somma del numero di modi in cui √® possibile scegliere la torta e del numero di modi in cui √® possibile scegliere i biscotti.\nEsempio 3. L‚Äôurna \\(A\\) contiene \\(5\\) palline numerate da \\(1\\) a \\(5\\), l‚Äôurna \\(B\\) contiene \\(6\\) palline numerate da \\(6\\) a \\(11\\), l‚Äôurna \\(C\\) contiene \\(3\\) palline numerate da \\(12\\) a \\(14\\) e l‚Äôurna \\(D\\) contiene \\(2\\) palline numerate \\(15\\) e \\(16\\). Quanti insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, si possono formare?\nIl numero di insiemi di tipo \\(AB\\) √® dato dal prodotto delle palline che possono essere estratte dall‚Äôurna \\(A\\) (5) e da quelle che possono essere estratte dall‚Äôurna \\(B\\) (6), ovvero \\(5 \\cdot 6 = 30\\). In modo analogo, si ottengono 15 insiemi di tipo \\(AC\\), 10 di tipo \\(AD\\), 18 di tipo \\(BC\\), 12 di tipo \\(BD\\), 6 di tipo \\(CD\\). Quindi, per la regola della somma, il numero totale di insiemi distinti che si possono formare con due palline provenienti dalle quattro urne √® dato dalla somma di questi valori, ovvero \\(30 + 15 + 10 + 18 + 12 + 6 = 91\\). Pertanto, ci sono 91 insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, che si possono formare.\nIn conclusione, il principio del prodotto e il principio della somma sono due concetti fondamentali del calcolo combinatorio. In generale, il principio del prodotto si applica quando si tratta di eventi indipendenti che si verificano in successione, mentre il principio della somma si applica quando si tratta di eventi mutuamente esclusivi (cio√® non possono accadere contemporaneamente) e si cerca di calcolare il numero totale di possibili risultati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#il-modello-dellurna",
    "href": "chapters/chapter_7/a14_combinatorics.html#il-modello-dellurna",
    "title": "Online Appendix J ‚Äî Calcolo combinatorio",
    "section": "J.3 Il modello dell‚Äôurna",
    "text": "J.3 Il modello dell‚Äôurna\nI problemi di combinatoria spesso coinvolgono l‚Äôestrazione di palline da urne, le quali rappresentano dei modelli delle corrispondenti situazioni considerate. Una procedura comune per rappresentare queste situazioni √® il modello dell‚Äôurna, che consiste nell‚Äôestrazione di \\(k\\) palline da un‚Äôurna contenente \\(n\\) palline. Le palline possono essere tutte diverse, oppure alcune palline possono essere indistinguibili tra loro. Tra le possibili modalit√† di estrazione, sono particolarmente importanti:\n\nL‚Äôestrazione Bernoulliana di \\(k\\) palline, che si ottiene estraendo una pallina alla volta e rimettendola nell‚Äôurna dopo ogni estrazione;\nL‚Äôestrazione senza ripetizione di \\(k\\) palline, che si ottiene estraendo una pallina alla volta senza rimetterla nell‚Äôurna dopo l‚Äôestrazione;\nL‚Äôestrazione in blocco di \\(k\\) palline, che si ottiene estraendo \\(k\\) palline contemporaneamente.\n\nPer esempio, nel caso di campioni di ampiezza 2 estratti da un‚Äôurna con tre elementi \\(\\{1, 2, 3\\}\\), abbiamo i seguenti quattro casi:\n\ncampionamento con reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{2,  1\\}, \\{3,  1\\}, \\{1,  2\\}, \\{2,  2\\}, \\{3,  2\\}, \\{1,  3\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento con reimmissione senza tenere conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{1,  2\\}, \\{1,  3\\}, \\{2,  2\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento senza reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  2\\}, \\{2,  1\\}, \\{1,  3\\}, \\{3,  1\\}, \\{2,  3\\}, \\{3,  2\\}\\);\ncampionamento senza reimmissione e senza tenere conto dell‚Äôordine di estrazione: \\(\\{1 , 2\\}, \\{1,  3\\}, \\{2, 3\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#permutazioni-semplici",
    "href": "chapters/chapter_7/a14_combinatorics.html#permutazioni-semplici",
    "title": "Online Appendix J ‚Äî Calcolo combinatorio",
    "section": "J.4 Permutazioni semplici",
    "text": "J.4 Permutazioni semplici\nLe permutazioni semplici sono il risultato di uno scambio dell‚Äôordine degli elementi di un insieme che contiene elementi distinti tra loro. Queste permutazioni sono indicate con il simbolo \\(P_n\\), e il numero di permutazioni semplici di \\(n\\) elementi distinti √® pari al fattoriale di \\(n\\), cio√® \\(n!\\), come espresso dall‚Äôeq. {eq}eq-permsem:\n\\[\nP_n = n!\n\\] (eq-permsem)\ndove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed √® uguale al prodotto di \\(n\\) numeri interi decrescenti da \\(n\\) fino a 1. Per definizione, il fattoriale di 0 √® 1.\nIl numero di permutazioni di \\(n\\) elementi distinti pu√≤ essere visto come l‚Äôestrazione senza rimessa di \\(n\\) elementi diversi da un‚Äôurna contenente gli \\(n\\) oggetti. Questo ci consente di applicare il principio del prodotto, il quale afferma che il numero di modi in cui √® possibile combinare o disporre un insieme di oggetti √® dato dal prodotto del numero di scelte possibili per ciascuna categoria di oggetti. Nel caso delle permutazioni, il principio del prodotto si applica nel seguente modo: se abbiamo \\(n\\) oggetti distinti da disporre in un ordine particolare, il numero di permutazioni possibili √® dato dal prodotto del numero di scelte possibili per la prima posizione, per la seconda posizione, per la terza posizione, e cos√¨ via, fino alla \\(n\\)-esima posizione.\nEsempio 4. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Calcoliamo il numero di permutazioni semplici.\nLe permutazioni semplici di \\(A\\) sono: \\(\\{a, b, c\\}\\), \\(\\{a, c, b\\}\\), \\(\\{b, c, a\\}\\), \\(\\{b, a, c\\}\\), \\(\\{c, a, b\\}\\), \\(\\{c, b, a\\}\\), ovvero 6. Applichiamo l‚Äôeq. {ref}eq-permsem:\n\\[\nP_n = P_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6.\n\\]\nLo strumento principale che usiamo in Python per trovare le permutazioni di un insieme √® una libreria specificamente progettata per iterare sugli oggetti in modi diversi, ovvero itertools. Con itertools.permutations() generiamo le permutazioni.\n\nA = {\"A\", \"B\", \"C\"}\nprint(A)\n\n{'A', 'B', 'C'}\n\n\n\npermutations = it.permutations(A)\n\nPer visualizzare il risultato dobbiamo trasformarlo in una tupla:\n\ntuple(permutations)\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nLo stesso risultato si ottiene con\n\npermutations = it.permutations(\"ABC\")\npermutations = tuple(permutations)\npermutations\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nPossiamo ora contare quanti elementi ci sono nella tupla usando la funzione len():\n\nlen(permutations)\n\n6\n\n\nOppure, possiamo appliare la formula {eq}eq-permsem mediante la funzione factorial() contenuta nella libreria math di Numpy:\n\nmath.factorial(3)\n\n6\n\n\nEsempio 5. Gli anagrammi sono le permutazioni che si ottengono da una parola variando l‚Äôordine delle lettere. Le permutazioni semplici si applicano al caso di parole costituite da lettere tutte diverse tra loro. Ad esempio, con la parola NUMERO si ottengono \\(P_6 = 6! = 6\\cdot5\\cdot4\\cdot3\\cdot2\\cdot1 = 720\\) anagrammi.\n\npermutations = it.permutations(\"NUMERO\")\npermutations = tuple(permutations)\npermutations[1:10]\n\n(('N', 'U', 'M', 'E', 'O', 'R'),\n ('N', 'U', 'M', 'R', 'E', 'O'),\n ('N', 'U', 'M', 'R', 'O', 'E'),\n ('N', 'U', 'M', 'O', 'E', 'R'),\n ('N', 'U', 'M', 'O', 'R', 'E'),\n ('N', 'U', 'E', 'M', 'R', 'O'),\n ('N', 'U', 'E', 'M', 'O', 'R'),\n ('N', 'U', 'E', 'R', 'M', 'O'),\n ('N', 'U', 'E', 'R', 'O', 'M'))\n\n\n\nlen(permutations)\n\n720\n\n\n\nmath.factorial(6)\n\n720\n\n\nEsempio 6. Un altro esempio riguarda i giochi di carte. Ci sono 52! \\(\\approx 8 \\times 10^{67}\\) modi di ordinare un mazzo di carte da poker; questo numero √® ‚Äúquasi‚Äù grande come il numero di atomi dell‚Äôuniverso che si stima essere uguale a circa \\(10^{80}\\).\n\nmath.factorial(52)\n\n80658175170943878571660636856403766975289505440883277824000000000000\n\n\n\nprint(\"{:.2e}\".format(math.factorial(52)))\n\n8.07e+67\n\n\nEsempio 7. Le cifre 1, 2, 3, 4 e 5 sono disposte in ordine casuale per formare un numero di cinque cifre.\n\nQuanti diversi numeri di cinque cifre possono essere formati?\nQuanti diversi numeri di cinque cifre sono dispari?\n\nIniziamo a creare una tupla con le cinque cifre:\n\ntuple(range(1, 6))\n\n(1, 2, 3, 4, 5)\n\n\nCome in precedenza, possiamo usare it.permutations():\n\npermutations = it.permutations(range(1, 6))\npermutations = tuple(permutations)\npermutations[1:10]\n\n((1, 2, 3, 5, 4),\n (1, 2, 4, 3, 5),\n (1, 2, 4, 5, 3),\n (1, 2, 5, 3, 4),\n (1, 2, 5, 4, 3),\n (1, 3, 2, 4, 5),\n (1, 3, 2, 5, 4),\n (1, 3, 4, 2, 5),\n (1, 3, 4, 5, 2))\n\n\nCi sono 120 permutazioni.\n\nlen(permutations)\n\n120\n\n\nPer trovare i numeri dispari tra queste 120 permutazioni utilizziamo la funzione sum() in Python abbinato alle espressioni for e in. Accediamo al quinto elemento di una permutazione utilizzando la notazione [4] (il primo elemento √® indicato con 0, quindi il quinto √® 4):\n\nsum(permutation[4] % 2 for permutation in permutations)\n\n72\n\n\nPossiamo controllare questo teoricamente: nel caso presente, ci sono tre possibili cifre dispari per l‚Äôultima posizione di un numero di cinque cifre: 1, 3 e 5. Dopo aver scelto una di queste, le cifre rimanenti nelle prime quattro posizioni possono essere formate in 4! modi. Pertanto:\n\nmath.factorial(4) * 3\n\n72",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#disposizioni-semplici",
    "href": "chapters/chapter_7/a14_combinatorics.html#disposizioni-semplici",
    "title": "Online Appendix J ‚Äî Calcolo combinatorio",
    "section": "J.5 Disposizioni semplici",
    "text": "J.5 Disposizioni semplici\nLe disposizioni semplici rappresentano tutti i modi in cui un insieme di oggetti pu√≤ essere disposto in sequenza, tenendo conto dell‚Äôordine in cui gli oggetti vengono scelti e senza permettere la scelta di un oggetto pi√π di una volta.\nQuindi, se abbiamo un insieme di \\(n\\) oggetti distinti e vogliamo selezionarne \\(k\\) per formare una sequenza, le disposizioni semplici rappresentano tutti i sottoinsiemi di \\(k\\) oggetti distinti che possono essere selezionati dall‚Äôinsieme di \\(n\\) oggetti distinti in modo tale che l‚Äôordine in cui vengono selezionati sia importante.\nAd esempio, se abbiamo l‚Äôinsieme di oggetti \\({a,b,c}\\) e vogliamo selezionare due oggetti per formare una sequenza, le disposizioni semplici sarebbero: \\(ab\\), \\(ba\\), \\(ac\\), \\(ca\\), \\(bc\\), \\(cb\\). Nota che, in questo caso, l‚Äôordine in cui gli oggetti vengono scelti √® importante e ogni oggetto viene scelto una sola volta.\nIl numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® indicato con \\(D_{n,k}\\) e pu√≤ essere calcolato dividendo il numero di permutazioni di \\(n\\) oggetti distinti per il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti, poich√© ogni disposizione semplice pu√≤ essere ottenuta come una permutazione di un sottoinsieme di \\(k\\) oggetti distinti.\nQuindi, il numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® dato da\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!},\n\\] (eq_disp_simple)\ndove \\(n!\\) rappresenta il numero di permutazioni di \\(n\\) oggetti distinti e \\((n-k)!\\) rappresenta il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti.\nEsempio 8. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Qual √® il numero di disposizioni semplici di classe 2? Come abbiamo visto sopra, le disposizioni semplici di classe 2 sono \\(\\{a, b\\}\\), \\(\\{b, a\\}\\), \\(\\{a, c\\}\\), \\(\\{c, a\\}\\), \\(\\{b, c\\}\\), \\(\\{c, b\\}\\), ovvero 6.\nApplichiamo l‚Äôeq. {eq}eq_disp_simple:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} = 3 \\cdot 2 = 6.\n\\]\nIn maniera equivalente possiamo trovare il risultato usando itertools.permutations(iterable, k). Tale istruzione ci consente di trovare il numero di permutazioni possibili di tutti i sottoinsiemi di \\(k\\) elementi distinti, ovvero il numero di diverse sequenze ordinate che possiamo ottenere scegliendo \\(k\\) oggetti dall‚Äôinsieme.\n\ntuple(it.permutations(\"ABC\", 2))\n\n(('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B'))\n\n\n\nres = tuple(it.permutations(\"ABC\", 2))\nlen(res)\n\n6\n\n\nOppure possiamo implementare l‚Äôeq. {eq}eq_disp_simple:\n\ndef simple_disp(n, k):\n    return math.factorial(n) / math.factorial(n - k)\n\n\nsimple_disp(3, 2)\n\n6.0\n\n\n(combinazione-semplice-section)= ## Combinazioni semplici\nLe combinazioni semplici rappresentano il numero di modi in cui \\(k\\) oggetti diversi possono essere scelti tra \\(n\\) oggetti distinti, ma a differenza delle disposizioni semplici, non tiene conto dell‚Äôordine in cui vengono scelti. In altre parole, le combinazioni semplici rappresentano tutti i possibili sottoinsiemi di \\(k\\) elementi distinti scelti tra \\(n\\) elementi distinti, senza considerare l‚Äôordine di estrazione.\nQuesto concetto pu√≤ essere modellato attraverso l‚Äôestrazione senza reimmissione di \\(k\\) oggetti da un‚Äôurna contenente \\(n\\) oggetti differenti. Tuttavia, a differenza delle disposizioni semplici, le combinazioni semplici considerano distinti solo i raggruppamenti che differiscono almeno per un elemento.\nGli elementi di ciascuna combinazione di \\(k\\) oggetti possono essere ordinati tra loro in \\(k!\\) modi diversi. Pertanto, il numero di combinazioni semplici √® dato dal numero di disposizioni semplici \\(D_{n,k}\\) diviso per il numero di permutazioni \\(P_k\\) dei \\(k\\) elementi.\nIl numero di combinazioni semplici \\(C_{n,k}\\) √® espresso dall‚Äôequazione\n\\[\nC_{n,k} = \\frac{D_{n,k}}{P_k} = \\frac{n!}{k!(n-k)!},\n\\] (eq_combsemp)\nche √® spesso indicata con il simbolo \\(\\binom{n}{k}\\) e viene chiamato ‚Äúcoefficiente binomiale‚Äù. In sintesi, le combinazioni semplici rappresentano il numero di sottoinsiemi di \\(k\\) elementi distinti scelti da un insieme di \\(n\\) elementi distinti senza considerare l‚Äôordine di estrazione, e il numero di combinazioni semplici √® dato dalla formula \\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\).\nEsempio 9. Per l‚Äôinsieme \\(A = \\{a, b, c\\}\\) si trovino le combinazioni semplici di classe 2.\nLe combinazioni semplici dell‚Äôinsieme \\(A\\) sono \\(\\{a, b\\}\\), \\(\\{a, c\\}\\), \\(\\{b, c\\}\\), ovvero 3. Applichiamo l‚Äôeq. {eq}eq_combsemp:\n\\[\nC_{n,k} = \\binom{n}{k} = \\binom{3}{2} = 3.\n\\]\nUsiamo itertools:\n\nc_nk = tuple(it.combinations(\"ABC\", 2))\nc_nk\n\n(('A', 'B'), ('A', 'C'), ('B', 'C'))\n\n\n\nlen(c_nk)\n\n3\n\n\nLa soluzione si trova anche usando la funzione comb() della libreria math.\n\nmath.comb(3, 2)\n\n3\n\n\nOppure usando la funzione comb() della libreria scipy.special.\n\nimport scipy.special as sp\n\nsp.comb(3, 2)\n\n3.0\n\n\nEsempio 10. Quanti gruppi di 2 si possono formare con 5 individui?\n\nc_nk = tuple(it.combinations(range(5), 2))\nc_nk\n\n((0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (1, 2),\n (1, 3),\n (1, 4),\n (2, 3),\n (2, 4),\n (3, 4))\n\n\n\nlen(c_nk)\n\n10\n\n\novvero\n\nmath.comb(5, 2)\n\n10\n\n\nEsempio 11. Ho un‚Äôassociazione con 50 soci. Devo scegliere 5 membri che compongano il comitato direttivo. Quante possibili scelte?\n\nmath.comb(50, 5)\n\n2118760\n\n\nEsempio 12. Una gelateria offre 15 gusti di gelato differenti. Quante coppe diverse posso formare se ognuna contiene 3 gusti di gelato differenti tra loro?\n\nmath.comb(15, 3)\n\n455\n\n\nEsempio 13. Uno studente deve rispondere a 5 domande su 10. Solo 5 su 10. Quante possibili scelte ha?\n\nmath.comb(10, 5)\n\n252",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a14_combinatorics.html#watermark",
    "href": "chapters/chapter_7/a14_combinatorics.html#watermark",
    "title": "Online Appendix J ‚Äî Calcolo combinatorio",
    "section": "J.6 Watermark",
    "text": "J.6 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Feb 06 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.1.4\nmatplotlib: 3.8.2\nscipy     : 1.11.4\nnumpy     : 1.26.2\narviz     : 0.17.0\nseaborn   : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a15_calculus.html",
    "href": "chapters/chapter_7/a15_calculus.html",
    "title": "Online Appendix K ‚Äî Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "K.1 Introduzione ai logaritmi\nIl logaritmo √® una funzione matematica che risponde alla domanda: ‚Äúquante volte devo moltiplicare un certo numero (chiamato‚Äùbase‚Äù) per ottenere un altro numero?‚Äù Matematicamente, questo √® espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perch√© \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano pi√π grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo √® utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio: - \\(\\log(1) = 0\\) - \\(\\log(0.1) = -1\\) - \\(\\log(0.01) = -2\\) - \\(\\log(0.001) = -3\\)\nCome si pu√≤ vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle propriet√† pi√π utili dei logaritmi √® che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta propriet√† √® estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilit√† potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn‚Äôaltra propriet√† utile dei logaritmi √® che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa propriet√† √® molto utilizzata in matematica, specialmente in situazioni in cui √® necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare pi√π agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli pi√π gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a15_calculus.html#watermark",
    "href": "chapters/chapter_7/a15_calculus.html#watermark",
    "title": "Online Appendix K ‚Äî Per liberarvi dai terrori preliminari",
    "section": "K.2 Watermark",
    "text": "K.2 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Feb 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\nnumpy     : 1.26.4\narviz     : 0.17.0\nscipy     : 1.12.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a44_montecarlo.html",
    "href": "chapters/chapter_7/a44_montecarlo.html",
    "title": "Online Appendix L ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "L.1 Stima dell‚Äôintegrale di un cerchio\nImmaginiamo un quadrato di lato 2 centrato sull‚Äôorigine. Genereremo punti casuali uniformemente distribuiti all‚Äôinterno di questo quadrato. Per ogni punto \\((x, y)\\), verificheremo se cade all‚Äôinterno del cerchio di raggio unitario inscritto nel quadrato, cio√® se la distanza dall‚Äôorigine √® minore di 1:\n\\[\n\\sqrt{x^2 + y^2} &lt; 1,\n\\]\nche si semplifica a:\n\\[\nx^2 + y^2 &lt; 1.\n\\]\nLa proporzione di tali punti rappresenta la proporzione dell‚Äôarea del quadrato occupata dal cerchio. Poich√© il quadrato ha un‚Äôarea di 4, l‚Äôarea del cerchio √® pari a 4 volte la proporzione dei punti che cadono all‚Äôinterno del cerchio.\nQuindi, se generiamo un numero sufficiente di punti casuali e contiamo quanti di essi cadono all‚Äôinterno del cerchio, possiamo stimare \\(\\pi\\) come:\n\\[\n\\pi \\approx 4 \\times \\frac{\\text{numero di punti dentro il cerchio}}{\\text{numero totale di punti}}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "href": "chapters/chapter_7/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "title": "Online Appendix L ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "L.1.1 Codice Stan\nEsaminiamo il corrispondente codice Stan.\ngenerated quantities {\n  real&lt;lower=-1, upper=1&gt; x = uniform_rng(-1, 1);\n  real&lt;lower=-1, upper=1&gt; y = uniform_rng(-1, 1);\n  int&lt;lower=0, upper=1&gt; inside = x^2 + y^2 &lt; 1;\n  real&lt;lower=0, upper=4&gt; pi = 4 * inside;\n}\n\nVariabili x e y:\n\nVengono generate casualmente e uniformemente nell‚Äôintervallo \\((-1, 1)\\). Questo significa che stiamo campionando punti all‚Äôinterno di un quadrato di lato 2 centrato sull‚Äôorigine.\n\nVariabile inside:\n\n√à un indicatore che verifica se il punto \\((x, y)\\) cade all‚Äôinterno del cerchio unitario. La condizione \\(x^2 + y^2 &lt; 1\\) √® vera se il punto \\((x, y)\\) √® all‚Äôinterno del cerchio di raggio 1 centrato sull‚Äôorigine, e falsa altrimenti.\nSe la condizione √® vera, inside √® impostato a 1, altrimenti a 0.\n\nVariabile pi:\n\npi viene calcolata come 4 volte il valore di inside.\n\n\nIl programma Stan genera punti casuali, verifica se cadono all‚Äôinterno del cerchio e usa la proporzione di punti che cadono all‚Äôinterno del cerchio per stimare \\(\\pi\\). Moltiplicando il valore indicatore per 4, otteniamo una stima di \\(\\pi\\) basata su ciascun punto generato. La stima finale di \\(\\pi\\) sar√† la media di queste stime su molti punti campionati.\n\n\nL.1.2 Media Campionaria dell‚ÄôIndicatore\nDopo aver generato un numero sufficiente di punti casuali e aver verificato quanti di essi cadono all‚Äôinterno del cerchio, calcoliamo la media campionaria dell‚Äôindicatore inside. Questo indicatore √® uguale a 1 se il punto √® dentro il cerchio e a 0 se √® fuori. La media di questi valori ci d√† la proporzione dei punti che cadono dentro il cerchio.\nQuesta proporzione √® una stima della probabilit√† che un punto casuale sia all‚Äôinterno del cerchio. Moltiplicando questa proporzione per 4, otteniamo una stima di \\(\\pi\\).\nMatematicamente, possiamo scrivere questo processo come segue:\n\\[\n\\mathbb{E}[4 \\cdot \\textrm{I}(\\sqrt{X^2 + Y^2} \\leq 1)] = \\int_{-1}^1 \\int_{-1}^1 4 \\cdot \\textrm{I}(x^2 + y^2 &lt; 1) \\, \\textrm{d}x \\, \\textrm{d}y = \\pi,\n\\]\ndove \\(\\textrm{I}()\\) √® l‚Äôindicatore che ritorna 1 se il suo argomento √® vero e 0 altrimenti.\nIn altre parole, stiamo calcolando l‚Äôaspettativa di 4 volte l‚Äôindicatore che un punto casuale \\((x, y)\\) cade dentro il cerchio unitario. Questo valore atteso √® uguale a \\(\\pi\\), il che ci permette di stimare \\(\\pi\\) usando i metodi Monte Carlo.\n\n\nL.1.3 Compilazione e Campionamento\nCompiliamo e poi campioniamo dal modello, prendendo un campione di dimensione \\(M = 10,000\\) estrazioni.\n\nM = 10_000\nmodel = CmdStanModel(stan_file=\"../../stan/monte-carlo-pi.stan\")\n\nsample = model.sample(\n    chains=1,\n    iter_warmup=1,\n    iter_sampling=M,\n    show_progress=False,\n    show_console=False,\n    seed=123,\n)\n\nx_draws = sample.stan_variable(\"x\")\ny_draws = sample.stan_variable(\"y\")\ninside_draws = sample.stan_variable(\"inside\")\npi_draws = sample.stan_variable(\"pi\")\n\ndf = pd.DataFrame({\"N\": 1000, \"x\": x_draws, \"y\": y_draws, \"inside\": inside_draws})\n\nplt.figure(figsize=(5, 5))\nplt.scatter(df[\"x\"], df[\"y\"], c=df[\"inside\"], cmap=\"coolwarm\", s=1)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Monte Carlo Simulation of Pi Estimation\")\nplt.gca().set_aspect(\"equal\", adjustable=\"box\")\nplt.show()\n\n\n\n\n\n\n\n\nSuccessivamente, calcoliamo la media campionaria dell‚Äôindicatore dentro-il-cerchio, che produce una stima della probabilit√† che un punto sia dentro il cerchio:\n\nPr_is_inside = np.mean(inside_draws)\npi_hat = np.mean(pi_draws)\nprint(f\"Pr[Y is inside circle] = {Pr_is_inside:.3f};\")\nprint(f\"estimate for pi = {pi_hat:.3f}\")\n\nPr[Y is inside circle] = 0.786;\nestimate for pi = 3.144\n\n\nIl valore esatto di \\(\\pi\\) fino a tre cifre decimali √® \\(3.142\\). Con il nostro metodo, ci avviciniamo a questo valore, ma non lo raggiungiamo esattamente, il che √® tipico dei metodi Monte Carlo. Aumentando il numero di estrazioni, l‚Äôerrore diminuisce. Teoricamente, con un numero sufficiente di estrazioni, possiamo ottenere qualsiasi precisione desiderata; tuttavia, in pratica, dobbiamo accontentarci di pochi decimali di accuratezza nelle nostre stime Monte Carlo. Questo di solito non √® un problema, poich√© l‚Äôincertezza statistica tende a dominare rispetto all‚Äôimprecisione numerica nella maggior parte delle applicazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html",
    "href": "chapters/chapter_7/a46_stan.html",
    "title": "Online Appendix M ‚Äî Linguaggio Stan",
    "section": "",
    "text": "M.1 Interfacce e pacchetti\n√à possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html#interfacce-e-pacchetti",
    "href": "chapters/chapter_7/a46_stan.html#interfacce-e-pacchetti",
    "title": "Online Appendix M ‚Äî Linguaggio Stan",
    "section": "",
    "text": "CmdStanPy - integrazione con il linguaggio di programmazione Python;\nPyStan - integrazione con il linguaggio di programmazione Python;\nCmdStan - eseguibile da riga di comando,\nRStan - integrazione con il linguaggio \\(\\mathsf{R}\\);\nMatlabStan - integrazione con MATLAB;\nStan.jl - integrazione con il linguaggio di programmazione Julia;\nStataStan - integrazione con Stata.\nScalaStan - integrazione con Scala.\n\n\n\nArviz - ArviZ √® una libreria Python per l‚Äôanalisi esplorativa dei modelli bayesiani. Essa funge da strumento indipendente dal backend per diagnosticare e visualizzare l‚Äôinferenza bayesiana.\nshinystan - interfaccia grafica interattiva per l‚Äôanalisi della distribuzione a posteriori e le diagnostiche MCMC in \\(\\mathsf{R}\\);\nbayesplot - insieme di funzioni utilizzabili per creare grafici relativi all‚Äôanalisi della distribuzione a posteriori, ai test del modello e alle diagnostiche MCMC in \\(\\mathsf{R}\\);\nbrms - fornisce un‚Äôampia gamma di modelli lineari e non lineari specificando i modelli statistici mediante la sintassi usata in \\(\\mathsf{R}\\);\nrstanarm - fornisce un sostituto per i modelli frequentisti forniti da base \\(\\mathsf{R}\\) e lme4 utilizzando la sintassi usata in \\(\\mathsf{R}\\) per la specificazione dei modelli statistici;\ncmdstanr - un‚Äôinterfaccia \\(\\mathsf{R}\\) per CmdStan.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html#interfaccia-cmdstanpy",
    "href": "chapters/chapter_7/a46_stan.html#interfaccia-cmdstanpy",
    "title": "Online Appendix M ‚Äî Linguaggio Stan",
    "section": "M.2 Interfaccia cmdstanpy",
    "text": "M.2 Interfaccia cmdstanpy\nNegli esempi di questa dispensa verr√† utilizzata l‚Äôinterfaccia cmdstanpy. CmdStanPy √® una interfaccia di Stan per gli utenti Python, che fornisce gli oggetti e le funzioni necessarie per condurre l‚Äôinferenza bayesiana su un modello di probabilit√† e dei dati. Essa racchiude l‚Äôinterfaccia a riga di comando di CmdStan in un piccolo insieme di classi Python, le quali offrono metodi per analizzare e gestire l‚Äôinsieme risultante di modello, dati e stime a posteriori.\nPer l‚Äôinstallazione di CmdStanPy, si segua il link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_7/a46_stan.html#codice-stan",
    "href": "chapters/chapter_7/a46_stan.html#codice-stan",
    "title": "Online Appendix M ‚Äî Linguaggio Stan",
    "section": "M.3 Codice Stan",
    "text": "M.3 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina √® stato generato), l‚Äôutente pu√≤ utilizzare l‚Äôinterfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan √® costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono: data, transformed data, parameters, transformed parameters, model, e generated quantities.\n\nM.3.1 Blocco data\nNel blocco data vengono specificate le variabili di input che saranno utilizzate nel modello Stan. Per ciascuna variabile, √® necessario definire il tipo di dato e le dimensioni, oltre a eventuali vincoli sui valori che le variabili possono assumere.\nPer esempio\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y; // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior; // Parametro beta per il prior Beta\n}\nEcco una sintesi dei tipi di dati e delle specifiche che possono essere dichiarate:\n\nint: rappresenta numeri interi.\nreal: designa numeri reali, inclusi quelli con parte decimale.\nvector: si riferisce a un vettore unidimensionale di numeri reali.\nmatrix: indica una matrice bidimensionale di numeri reali.\narray: descrive una sequenza ordinata di elementi che possono essere di qualsiasi tipo specificato, e pu√≤ avere pi√π di una dimensione.\n\n√à importante dichiarare le dimensioni di ciascuna variabile e, se necessario, applicare vincoli sui valori che queste possono assumere (ad esempio, specificando lower=0 e upper=1 per vincolare i valori tra 0 e 1). Questi vincoli sono utili per ottimizzare la stima dei parametri e garantire che il modello sia ben definito.\n\nM.3.1.1 Interi\nGli interi non vincolati vengono dichiarati utilizzando la parola chiave int. Ad esempio, la variabile N viene dichiarata come un intero nel seguente modo.\nint N;\nI tipi di dati interi possono essere vincolati per consentire valori solo in un intervallo specificato fornendo un limite inferiore, un limite superiore o entrambi. Ad esempio, per dichiarare N come un intero positivo, si utilizza quanto segue.\nint&lt;lower=1&gt; N;\n\n\nM.3.1.2 Reali\nLe variabili reali non vincolate vengono dichiarate utilizzando la parola chiave real. Ad esempio,\nreal theta;\nLe variabili reali possono essere limitate utilizzando la stessa sintassi degli interi. Per esempio, la variabile sigma pu√≤ essere dichiarata come non negativa come segue.\nreal&lt;lower=0&gt; sigma;\n\n\nM.3.1.3 Tipi di dati vettoriali e matriciali\nStan fornisce tre tipi di oggetti contenitore: array, vettori e matrici. I vettori e le matrici sono tipi di strutture dati pi√π limitati rispetto agli array. I vettori sono collezioni intrinsecamente unidimensionali di valori reali o complessi, mentre le matrici sono intrinsecamente bidimensionali. I vettori, le matrici e gli array non sono assegnabili tra loro, anche se le loro dimensioni sono identiche. Una matrice 3√ó4 √® un tipo di oggetto diverso in Stan rispetto a un array 3√ó4.\nI vettori e le matrici non possono essere tipizzati per restituire valori interi. Sono limitati a valori reali e complessi.\n\n\nM.3.1.4 Indicizzazione da 1\nVettori e matrici, cos√¨ come gli array, sono indicizzati a partire da uno (1) in Stan.\n\n\nM.3.1.5 Tipi di dati array\nStan supporta array di dimensioni arbitrarie. I valori in un array possono essere di qualsiasi tipo, in modo che gli array possano contenere valori che sono semplici reali o interi, vettori, matrici o altri array. Gli array sono l‚Äôunico modo per memorizzare sequenze di interi, e alcune funzioni in Stan, come le distribuzioni discrete, richiedono argomenti interi.\nUn array bidimensionale √® semplicemente un array di array. Quando viene fornito un indice a un array, restituisce il valore in quell‚Äôindice. Quando vengono forniti pi√π di un indice, questa operazione di indicizzazione √® concatenata. Ad esempio, se a √® un array bidimensionale, allora a[m, n] √® solo una abbreviazione per a[m][n].\n\n\nM.3.1.6 Dichiarazione di variabili array\nGli array sono dichiarati con la parola chiave array seguita dalle dimensioni racchiuse tra parentesi quadre, il tipo di elemento e il nome della variabile.\nPer esempio, la variabile n viene dichiarata come un array di cinque interi come segue.\narray[5] int n;\nUn array bidimensionale di valori interi con tre righe e quattro colonne viene dichiarato come segue.\narray[3, 4] int a;\nUn array di N numeri reali vincolati tra 0 e 1 viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] real&lt;lower=0, upper=1&gt; y;\nUn array di N interi positivi viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] int&lt;lower=0&gt; x;\n\n\nM.3.1.7 Vettori\nI vettori in Stan sono vettori colonna. I vettori sono dichiarati con una dimensione (cio√®, una dimensionalit√†). Ad esempio, un vettore reale tridimensionale di dimensione 3 viene dichiarato con la parola chiave vector, come segue.\nvector[3] u;\n\nM.3.1.7.1 Matrici\nLe matrici sono dichiarate con la parola chiave matrix insieme a un numero di righe e un numero di colonne. Ad esempio,\nmatrix[3, 3] A;\nmatrix[M, N] B;\ndichiara A come una matrice 3√ó3 e B come una matrice M√óN. Perch√© la seconda dichiarazione sia ben formata, le variabili M e N devono essere dichiarate come interi nel blocco dati o dati trasformati e prima della dichiarazione della matrice.\n\n\nM.3.1.7.2 Miscelazione di tipi di array, vettore e matrice\nArray, vettori riga, vettori colonna e matrici non sono interscambiabili in Stan. Quindi una variabile di uno qualsiasi di questi tipi fondamentali non √® assegnabile a nessuno degli altri, anche se le loro dimensioni sono identiche, n√© pu√≤ essere utilizzata come argomento dove √® richiesto l‚Äôaltro.\n\n\nM.3.1.7.3 Dizionari\n√à fondamentale che i dati forniti a Stan tramite CmdStanPy siano organizzati in un oggetto di tipo dizionario. In Python, un dizionario √® una collezione di coppie chiave-valore che permette di associare a ogni chiave (unica) un valore specifico. Quando si preparano i dati per un modello Stan utilizzando CmdStanPy, si crea un dizionario dove:\n\nOgni chiave corrisponde al nome di una variabile dichiarata nel blocco data del modello Stan.\nIl valore associato a ciascuna chiave rappresenta i dati effettivi da passare al modello per quella variabile.\n\nQuesta struttura consente di mappare direttamente le variabili definite nel modello Stan ai dati che si desidera analizzare, facilitando il processo di assegnazione dei dati e assicurando che ogni variabile riceva i dati corretti.\n\n\n\n\nM.3.2 Blocco parameters\nI parametri da stimare sono definiti all‚Äôinterno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilit√†. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell‚Äôintervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\nCerto, ecco il testo corretto e migliorato:\n\n\nM.3.3 Sezione model\nNella sezione model, vengono definite le relazioni tra i dati osservati e i parametri del modello, insieme alle distribuzioni a priori di tali parametri.\nA titolo di esempio, il seguente codice assegna una distribuzione a priori Beta ai parametri alpha_prior e beta_prior per il parametro theta. La verosimiglianza specifica che il meccanismo generatore dei dati osservati y √® binomiale, con parametri ntrials e theta.\nmodel {\n  // Prior\n  theta ~ beta(alpha_prior, beta_prior);\n  \n  // Likelihood\n  y ~ binomial(ntrials, theta);\n}\nIl simbolo ~ √® chiamato tilde. In generale, possiamo leggerlo come ‚Äú√® distribuito come‚Äù, e questa notazione viene utilizzata come abbreviazione per definire distribuzioni. Pertanto, l‚Äôesempio sopra pu√≤ essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta)\n\\]\nQuesta notazione compatta facilita la definizione delle relazioni probabilistiche nel modello.\nSe non specificata, Stan utilizza una distribuzione a priori uniforme tra meno infinito e pi√π infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, √® possibile consultare questo link.\n\n\nM.3.4 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. √à possibile trasformare i parametri del modello; solitamente ci√≤ viene fatto nel caso dei modelli pi√π avanzati per consentire un campionamento MCMC pi√π efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantit√† che non fa parte del modello ma pu√≤ essere calcolata a partire dai parametri del modello, per ogni iterazione dell‚Äôalgoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\nM.3.5 Sintassi\nSi noti che il codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos‚Äôaltro. I punti e virgola non sono invece richiesti all‚Äôinizio di un ciclo o di un‚Äôistruzione condizionale, dove non viene assegnato nulla.\nIn STAN, qualsiasi stringa che segue // denota un commento e viene ignorata dal programma.\nUna descrizione dettagliata della sintassi del linguaggio Stan √® disponibile al seguente link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "References",
    "section": "",
    "text": "Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian\nModeling. Boca Raton, Florida: CRC Press.\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications\nin r. Chapman; Hall/CRC.\n\n\nBaribault, Beth, and Anne GE Collins. 2023. ‚ÄúTroubleshooting\nBayesian Cognitive Models.‚Äù Psychological Methods.\n\n\nBox, G. E., A. Luceno, and M. del Carmen Paniagua-Quinones. 2011.\nStatistical Control by Monitoring and Adjustment. John Wiley;\nSons.\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and\nthe Crisis of Modern Science. Columbia University Press.\n\n\nComtois, Katherine Anne, Karin E Hendricks, Christopher R DeCou,\nSamantha A Chalker, Amanda H Kerbrat, Jennifer Crumlish, Tierney K\nHuppert, and David Jobes. 2023. ‚ÄúReducing Short Term Suicide Risk\nAfter Hospitalization: A Randomized Controlled Trial of the\nCollaborative Assessment and Management of Suicidality.‚Äù\nJournal of Affective Disorders 320: 656‚Äì66.\n\n\nDagan, Noa, Noam Barda, Eldad Kepten, Oren Miron, Shay Perchik, Mark\nKatz, Miguel Hern√°n, Marc Lipsitch, Ben Reis, and Ran Balicer. 2021.\n‚ÄúBNT162b2 mRNA Covid-19 Vaccine in a Nationwide Mass Vaccination\nSetting.‚Äù New England Journal of Medicine 384 (15):\n1412‚Äì23. https://doi.org/10.1056/NEJMoa2101765.\n\n\nDe Finetti, Bruno. 2017. Theory of Probability: A Critical\nIntroductory Treatment. Vol. 6. John Wiley & Sons.\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth.\n1987. ‚ÄúHybrid Monte Carlo.‚Äù Physics Letters B 195\n(2): 216‚Äì22.\n\n\nFishburn, Peter C. 1986. ‚ÄúThe Axioms of Subjective\nProbability.‚Äù Statistical Science 1 (3): 335‚Äì45.\n\n\nFox, John. 2015. Applied Regression Analysis and Generalized Linear\nModels. Sage publications.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and\nOther Stories. Cambridge University Press.\n\n\nGeman, Stuart, and Donald Geman. 1984. ‚ÄúStochastic Relaxation,\nGibbs Distributions, and the Bayesian\nRestoration of Images.‚Äù IEEE Transactions on Pattern Analysis\nand Machine Intelligence 6: 721‚Äì41.\n\n\nHastings, W. Keith. 1970. ‚ÄúMonte Carlo\nSampling Methods Using Markov Chains and Their\nApplications.‚Äù Biometrika 57 (1): 97‚Äì109.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ‚ÄúThe No-u-Turn\nSampler: Adaptively Setting Path Lengths in Hamiltonian Monte\nCarlo.‚Äù Journal of Machine Learning Research 15 (1):\n1593‚Äì623.\n\n\nHowson, Colin, and Peter Urbach. 2006. Scientific Reasoning: The\nBayesian Approach. Open Court Publishing.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. 1st ed. Chapman & Hall. https://theeffectbook.net.\n\n\nIoannidis, John PA. 2005. ‚ÄúWhy Most Published Research Findings\nAre False.‚Äù PLoS Medicine 2 (8): e124.\n\n\nJohnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with\nR. CRC Press.\n\n\nKaplan, David. 2023. Bayesian Statistics for the Social\nSciences. Guilford Publications.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A\nTutorial with R, JAGS, and Stan. Academic\nPress.\n\n\nLindley, Dennis V. 2013. Understanding Uncertainty. John Wiley\n& Sons.\n\n\nMartin, Osvaldo. 2024. Bayesian Analysis with Python. Packt\nPublishing Ltd.\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and\nR. 1st Edition. New York, NY: Manning Publications.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth,\nAugusta H. Teller, and Edward Teller. 1953. ‚ÄúEquation of State\nCalculations by Fast Computing Machines.‚Äù The Journal of\nChemical Physics 21 (6): 1087‚Äì92.\n\n\nPearl, Judea. 2009. Causality. Cambridge University Press.\n\n\nPress, S James. 2009. Subjective and Objective Bayesian Statistics:\nPrinciples, Models, and Applications. John Wiley & Sons.\n\n\nRamsey, Frank P. 1926. ‚ÄúTruth and Probability.‚Äù In\nReadings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.\n\n\nRiederer, Emily. 2021. ‚ÄúCausal Design Patterns for Data\nAnalysts,‚Äù January. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nRohrer, Julia M. 2018. ‚ÄúThinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational Data.‚Äù\nAdvances in Methods and Practices in Psychological Science 1\n(1): 27‚Äì42.\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, and Marek McGann.\n2024. ‚ÄúMost Psychological Researchers Assume Their Samples Are\nErgodic: Evidence from a Year of Articles in Three Major\nJournals.‚Äù Collabra: Psychology 10 (1).\n\n\nStevens, Stanley Smith. 1946. ‚ÄúOn the Theory of Scales of\nMeasurement.‚Äù Science 103 (2684): 677‚Äì80.\n\n\nStigler, Stephen. 1986. The History of Statistics.\nMassachusetts: Belknap Harvard.\n\n\nVasishth, Shravan, and Andrew Gelman. 2021. ‚ÄúHow to Embrace\nVariation and Accept Uncertainty in Linguistic and Psycholinguistic Data\nAnalysis.‚Äù Linguistics 59 (5): 1311‚Äì42.\n\n\nWard, Andrew, and Traci Mann. 2022. ‚ÄúControl Yourself: Broad\nImplications of Narrowed Attention.‚Äù Perspectives on\nPsychological Science 17 (6): 1692‚Äì1703.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, and Babette Renneberg. 2019.\n‚ÄúFuture Expectations in Clinical Depression: Biased or\nRealistic?‚Äù Journal of Abnormal Psychology 128 (7): 678.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon\nSchwab, and Steven N Goodman. 2023. ‚ÄúA New Look at p Values for\nRandomized Clinical Trials.‚Äù NEJM Evidence 3 (1):\nEVIDoa2300003.",
    "crumbs": [
      "Appendici",
      "References"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#simulazione-in-avanti",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#simulazione-in-avanti",
    "title": "32¬† Linguaggio Stan",
    "section": "32.4 Simulazione in Avanti",
    "text": "32.4 Simulazione in Avanti\nLa simulazione in avanti consiste nella generazione di dati simulati a partire da un insieme di parametri noti di un modello probabilistico. In altri termini, date determinate assunzioni sui parametri di un modello, si utilizza la simulazione in avanti per prevedere i possibili risultati.\nAd esempio, consideriamo uno studio clinico con \\(N\\) soggetti e una probabilit√† \\(\\theta\\) di esito positivo per ciascun soggetto. Conoscendo il valore di \\(\\theta\\) e il numero di soggetti \\(N\\), possiamo impiegare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci consente di generare dati che riflettono le nostre assunzioni sui parametri del modello.\nIn notazione statistica, questo si esprime come:\n\\[\nY \\sim \\text{Binomiale}(N, \\theta)\n\\]\ndove \\(Y\\) rappresenta il numero di esiti positivi su \\(N\\) pazienti, con probabilit√† \\(\\theta\\) di esito positivo per ciascun paziente.\n\n32.4.0.1 Esempio di Simulazione in Avanti\nSupponiamo di avere \\(N = 100\\) soggetti in uno studio clinico e un tasso di successo \\(\\theta = 0.3\\). Possiamo simulare un risultato \\(Y\\) generando casualmente il numero di soggetti con esito positivo. Utilizzando una distribuzione binomiale, possiamo calcolare la probabilit√† di ottenere esattamente \\(y\\) esiti positivi su \\(N\\) tentativi:\n\\[\np(Y = y \\mid N, \\theta) = \\binom{N}{y} \\cdot \\theta^y \\cdot (1 - \\theta)^{N - y}\n\\]\nQuesta espressione ci permette di calcolare la probabilit√† di ottenere un certo numero di successi, dato il numero di soggetti e la probabilit√† di successo.\n\n\n32.4.1 Un Primo Programma in Stan: Generazione di Dati Casuali\nSupponiamo di voler generare dei valori casuali \\(Y\\) da una distribuzione binomiale con parametri \\(N\\) e \\(\\theta\\). Ad esempio, possiamo impostare \\(\\theta = 0.3\\), per rappresentare una probabilit√† del 30% di un esito positivo (in statistica, il termine ‚Äòsuccesso‚Äô indica un esito positivo), e possiamo impostare \\(N = 100\\). Il seguente programma Stan pu√≤ essere utilizzato per generare valori di \\(Y\\) compresi tra 0 e 100.\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\n\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;\n  y = binomial_rng(N, theta);\n}\n\n\n32.4.2 Organizzazione di un Programma Stan\nLa prima cosa da notare √® che un programma Stan √® organizzato in blocchi. Qui abbiamo due blocchi: un blocco dei dati (data)contenente le dichiarazioni delle variabili che devono essere fornite come dati e un blocco delle quantit√† generate (generated quantities), che non solo dichiara variabili ma assegna loro un valore. In questo programma Stan, la variabile y viene assegnata come risultato di una singola estrazione da una distribuzione \\(\\textrm{binomiale}(N, \\theta)\\), che Stan fornisce attraverso la funzione binomial_rng.\n\n\n32.4.3 Tipi di Variabili in Stan\nLa seconda cosa da notare √® che tutte le variabili in un programma Stan sono dichiarate con tipi specifici. Stan utilizza la tipizzazione statica, il che significa che, a differenza di Python o R, il tipo di una variabile √® dichiarato nel programma prima del suo utilizzo, piuttosto che essere determinato al momento dell‚Äôesecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile non cambia mai.\nIl programma in esame dichiara tre variabili: N e y di tipo int (interi) e theta di tipo real (numeri reali). Nei computer, gli interi hanno limiti precisi e i numeri reali possono avere errori di calcolo. Stan utilizza numeri reali con precisione doppia (64 bit) secondo lo standard IEEE 754, tranne in alcune operazioni ottimizzate che possono perdere un po‚Äô di precisione.\n\n\n32.4.4 Vincoli sui Tipi\nUn tipo di variabile pu√≤ avere dei vincoli. Poich√© N √® un conteggio, deve essere maggiore o uguale a zero, cosa che indichiamo con il vincolo lower=0. Allo stesso modo, la variabile y, che rappresenta il numero di esiti positivi su N, deve essere compresa tra 0 e N (inclusi); questo √® indicato con il vincolo lower=0, upper=N. Infine, la variabile theta √® un numero reale e deve essere compresa tra 0 e 1, cosa che indichiamo con il vincolo lower=0, upper=1. Anche se tecnicamente i limiti per i numeri reali sono aperti, in pratica possiamo ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.\n\n\n32.4.5 Esecuzione del Programma Stan\nLa funzione cmdstan_model() crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan. In background, CmdStan traduce un programma Stan in C++ e creare un eseguibile compilato.\n\nmodel = CmdStanModel(stan_file='../../stan/binomial-rng.stan')\n\nDurante l‚Äôesecuzione, il programma Stan compilato richiede i valori di N e theta. Ad ogni iterazione, il programma campiona un valore di y utilizzando il suo generatore di numeri pseudocasuali integrato. I valori di N e theta devono essere forniti in un dizionario Python.\n\nN = 100\ntheta = 0.3\ndata = {\n    'N': N, \n    'theta': theta\n}\n\nInfine campioniamo dal modello utilizzando il metodo sample di CmdStanModel.\n\ntrace = model.sample(\n    data=data, \n    seed=123, \n    chains=1,\n    iter_sampling=30, \n    iter_warmup=1,\n    show_progress=False, \n    show_console=False\n)\n\n\n\n32.4.6 Costruzione del Modello\nIl costruttore di CmdStanModel viene utilizzato per creare un modello a partire da un programma Stan presente nel file specificato. Si consiglia vivamente di utilizzare un file separato per i programmi Stan. In pratica, il processo inizia con la traduzione del programma Stan in una classe C++ utilizzando un traduttore specifico. Successivamente, il programma C++ viene compilato.\n\n\n32.4.7 Interfaccia Python\nNell‚Äôinterfaccia Python, il metodo sample() accetta i seguenti argomenti:\n\ndata: i dati letti nel blocco dati del programma Stan,\nseed: generatore di numeri pseudocasuali per la riproducibilit√†,\nchains: il numero di simulazioni da eseguire (parallel_chains indica quante eseguire in parallelo),\niter_sampling: numero di estrazioni (cio√®, dimensione del campione) da restituire,\niter_warmup: numero di iterazioni di riscaldamento per tarare i parametri dell‚Äôalgoritmo di campionamento (non necessari qui, quindi impostato a 0),\nshow_progress: se True, stampa aggiornamenti di progresso,\nshow_console: apre un monitor di progresso GUI.\n\nIl risultato della chiamata a sample() sull‚Äôistanza del modello viene assegnato alla variabile trace e contiene le 10 estrazioni richieste con l‚Äôargomento iter_sampling = 30.\nQuando si chiama model.sample(...), CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell‚Äôargomento data di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poich√© il nostro programma Stan ha solo un blocco di quantit√† generate, l‚Äôunico compito rimanente della classe C++ √® generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da iter_sampling, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.\nLa generazione di numeri casuali √® determinata dal valore seed specificato nella chiamata.\n\n\n32.4.8 Estrazione dei Risultati\nUna volta completato il campionamento, possiamo estrarre il campione di 30 valori per la variabile scalare y sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.\n\ny = trace.stan_variable('y')\nprint(\"N =\", N, \";  theta =\", theta, \";  y(0:30) =\", *y.astype(int))\n\nN = 100 ;  theta = 0.3 ;  y(0:30) = 28 34 31 29 26 25 31 28 30 36 29 36 37 27 29 23 29 34 30 42 37 29 34 28 35 31 30 31 23 28",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/15_stan_beta_binomial.html#il-problema-inverso",
    "href": "chapters/chapter_4/15_stan_beta_binomial.html#il-problema-inverso",
    "title": "32¬† Linguaggio Stan",
    "section": "32.6 Il Problema Inverso",
    "text": "32.6 Il Problema Inverso\nIl problema inverso consiste nella stima dei parametri del modello, come la probabilit√† di successo \\(\\theta\\), dato un insieme di dati osservati. Supponiamo di avere i seguenti dati: \\(N = 100\\) soggetti e \\(y = 32\\) esiti positivi. L‚Äôobiettivo √® stimare \\(\\theta\\), la probabilit√† di successo.\nNell‚Äôapproccio bayesiano, si inizia specificando una distribuzione a priori per \\(\\theta\\). Supponiamo di utilizzare una distribuzione Beta(\\(\\alpha\\), \\(\\beta\\)) come prior per \\(\\theta\\), dove \\(\\alpha\\) e \\(\\beta\\) sono parametri scelti in base alle conoscenze precedenti. La distribuzione a posteriori di \\(\\theta\\) data l‚Äôosservazione \\(y\\) √® ancora una distribuzione Beta, ma con parametri aggiornati:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + N - y)\n\\]\nAd esempio, scegliendo una distribuzione a priori non informativa con \\(\\alpha = 1\\) e \\(\\beta = 1\\), la distribuzione a posteriori diventa:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(1 + 32, 1 + 100 - 32) = \\text{Beta}(33, 69)\n\\]\nQuesta distribuzione a posteriori fornisce una stima aggiornata della probabilit√† di successo \\(\\theta\\) considerando i dati osservati. Utilizzando Stan, √® possibile ottenere campioni da questa distribuzione a posteriori per calcolare statistiche riassuntive e effettuare previsioni.\nIn sintesi, la simulazione in avanti e il problema inverso rappresentano due approcci complementari: la simulazione in avanti genera dati simulati da parametri noti, mentre il problema inverso stima i parametri del modello dai dati osservati.\nQuando si dispone di un modello che genera dati a partire dai parametri, il problema inverso consiste nell‚Äôinferire i valori dei parametri dai dati osservati. Questo tipo di problema richiede di ragionare a ritroso dalle osservazioni, attraverso il modello di misurazione e il modello diretto, per stimare parametri come, ad esempio, la probabilit√† di successo. La risoluzione dei problemi inversi √® uno degli ambiti in cui le statistiche bayesiane eccellono.\n\n32.6.1 Storia e Applicazione\nUn decennio dopo la pubblicazione della regola di Bayes, Laplace utilizz√≤ la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori. In questa sezione, analizzeremo il problema di Laplace utilizzando Stan.\nLaplace raccolse dati sul sesso dei bambini nati vivi a Parigi tra il 1745 e il 1770:\n\n\n\nSesso\nNascite vive\n\n\n\n\nFemmina\n105.287\n\n\nMaschio\n110.312\n\n\n\nLaplace si chiese se, sulla base di questi dati, la probabilit√† di nascita dei maschi fosse superiore a quella delle femmine.\n\n\n32.6.2 Modello di Laplace\nLaplace adott√≤ la seguente distribuzione campionaria per modellare il numero di maschi nati su un totale di \\(N\\) nascite:\n\\[\ny \\sim \\text{binomiale}(N, \\theta),\n\\]\ndove \\(N\\) √® il numero totale di nascite, \\(\\theta\\) √® la probabilit√† di nascita di un maschio e \\(y\\) √® il numero di nascite maschili.\n\n\n32.6.3 Distribuzione a Priori\nLaplace utilizz√≤ la seguente distribuzione a priori per \\(\\theta\\):\n\\[\n\\theta \\sim \\text{beta}(1, 1),\n\\]\ndove la distribuzione \\(\\text{beta}(1, 1)\\) √® uniforme sull‚Äôintervallo \\(\\theta \\in (0, 1)\\) poich√© la densit√† √® proporzionale a una costante:\n\\[\n\\text{beta}(\\theta \\mid 1, 1) \\propto \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} = 1.\n\\]\n\n\n32.6.4 Distribuzione a Posteriori\nIl modello di Laplace √® abbastanza semplice da permettere una soluzione analitica della distribuzione a posteriori:\n\\[\n\\begin{aligned}\n    p(\\theta \\mid y, N) &\\propto p(y \\mid N, \\theta) \\cdot p(\\theta) \\\\\n    &= \\text{binomiale}(y \\mid N, \\theta) \\cdot \\text{beta}(\\theta \\mid 1, 1) \\\\\n    &\\propto \\theta^y \\cdot (1 - \\theta)^{N - y} \\cdot \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} \\\\\n    &= \\theta^{y} \\cdot (1 - \\theta)^{N - y} \\\\\n    &\\propto \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\end{aligned}\n\\]\nQuindi, possiamo concludere che:\n\\[\np(\\theta \\mid y, N) = \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\]\n\n\n32.6.5 Implementazione in Stan\nA differenza del primo modello Stan che abbiamo visto, che generava solo dati, il seguente programma Stan richiede che vengano forniti dati, specificamente il numero di nascite maschili (\\(y\\)) e il numero totale di nascite (\\(N\\)). Il modello ci permetter√† di stimare la probabilit√† di nascita di un maschio (\\(\\theta\\)) e la probabilit√† che nascano pi√π maschi che femmine (\\(\\theta &gt; 0.5\\)).\nEcco come possiamo specificare il modello Stan:\n\nstan_file = os.path.join(project_directory, 'stan', 'sex-ratio.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che sia il numero totale di nascite (\\(N\\)) sia il numero di nascite maschili (\\(y\\)) sono forniti come dati. Poi ci sono due blocchi aggiuntivi: un blocco dei parametri, usato per dichiarare valori sconosciuti (qui, solo il tasso di nascite maschili \\(\\theta\\)), e un blocco del modello, dove specifichiamo la distribuzione a priori e la verosimiglianza. La distribuzione a posteriori viene calcolata da Stan combinando queste due componenti. Inoltre, c‚Äô√® un blocco delle quantit√† generate dove viene calcolata una variabile booleana che indica se la probabilit√† di nascita dei maschi \\(\\theta\\) √® maggiore di 0.5.\nIl modello di Laplace e la sua implementazione in Stan ci permettono di affrontare il problema inverso delle nascite, inferendo la probabilit√† di nascita di un maschio dai dati osservati. Utilizzando le tecniche bayesiane, possiamo stimare non solo la probabilit√† di nascita di un maschio, ma anche la probabilit√† che nascano pi√π maschi che femmine.\n\n\n32.6.6 Campionare dalla Distribuzione a Posteriori\nQuando eseguiamo un programma Stan, esso genera una serie di campioni casuali che approssimano la distribuzione a posteriori. Con il proseguire delle estrazioni, questi campioni tendono a diventare sempre pi√π simili a veri campioni della distribuzione a posteriori, fino a diventare numericamente indistinguibili da essa.\nStan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che pu√≤ introdurre autocorrelazione nei campioni della distribuzione a posteriori. In altre parole, i campioni non sono indipendenti tra loro, ma ogni campione √® correlato (o anti-correlato) con il campione precedente.\nL‚Äôautocorrelazione non introduce bias nelle stime Monte Carlo, ma i campioni positivamente autocorrelati, che si osservano nei modelli pi√π complessi, aumentano la varianza delle stime rispetto ai campioni indipendenti. Questo incremento della varianza aumenta l‚Äôerrore quadratico medio atteso, che √® una combinazione di errore dovuto al bias (qui nullo) e alla varianza. Al contrario, nei modelli molto semplici, l‚Äôautocorrelazione negativa riduce la varianza rispetto ai campioni indipendenti, riducendo quindi l‚Äôerrore quadratico medio atteso.\nPer affrontare problemi ad alta dimensionalit√†, Duane et al.¬†(1987) hanno introdotto l‚Äôalgoritmo Hamiltonian Monte Carlo (HMC) che migliora l‚Äôefficienza del campionamento. Per Stan, Hoffman e Gelman (2014) hanno sviluppato una versione adattiva dell‚ÄôHMC chiamata No-U-Turn Sampler (NUTS), successivamente migliorata da Betancourt (2017a). NUTS pu√≤ essere estremamente efficiente, generando campioni anti-correlati che possono portare a stime Monte Carlo pi√π precise rispetto ai campioni indipendenti.\n\n\n32.6.7 Compilazione del Codice Stan\nPer utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato model.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nInseriamo i dati in un dizionario.\n\nboys = 110312\ngirls = 105287\n\ndata = {\n    'N': boys + girls, \n    'y': boys,\n    \"alpha_prior\" : 1,\n    \"beta_prior\" : 1\n    }\n\nprint(data)\n\n{'N': 215599, 'y': 110312, 'alpha_prior': 1, 'beta_prior': 1}\n\n\nEseguiamo il campionamento MCMC con la seguente chiamata.\n\nsample = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 10_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\nIl metodo $sample() viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato model.\nAvendo assunto una distribuzione a priori per il parametro \\(\\theta\\), l‚Äôalgoritmo procede in maniera ciclica, aggiornando la distribuzione a priori di \\(\\theta\\) condizionandola ai valori gi√† generati. Dopo un certo numero di iterazioni, l‚Äôalgoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di \\(\\theta\\).\nAll‚Äôinizio del campionamento, la distribuzione dei campioni pu√≤ essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale √® chiamato ‚Äúburn-in‚Äù. Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e sono tipicamente scartati. Man mano che il numero di iterazioni aumenta, la distribuzione dei campioni si avvicina sempre pi√π alla distribuzione target.\nDopo aver eseguito il modello in Stan, otteniamo una serie di campioni \\(\\theta^{(m)}\\) dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\). Ogni campione rappresenta un possibile valore di \\(\\theta\\) compatibile con i dati osservati \\(y\\). Procediamo quindi a estrarre i campioni a posteriori per le variabili theta e boys_gt_girls.\n\ntheta_draws = sample.stan_variable('theta')\nboys_gt_girls_draws = sample.stan_variable('boys_gt_girls')\n\nTracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di \\(\\theta\\) sono pi√π probabili e comprendere meglio la forma della distribuzione a posteriori. L‚Äôistogramma ci fornisce diverse informazioni:\n\nValore pi√π probabile di \\(\\theta\\): Questo √® il valore intorno al quale i campioni sono pi√π concentrati, noto come la moda della distribuzione.\nDistribuzione dei possibili valori di \\(\\theta\\): Questo ci d√† un‚Äôidea dell‚Äôincertezza nella stima di \\(\\theta\\).\n\nSe l‚Äôistogramma √® stretto e concentrato attorno a un valore specifico, significa che c‚Äô√® poca incertezza nella stima di \\(\\theta\\). In altre parole, possiamo essere abbastanza sicuri che il valore vero di \\(\\theta\\) sia vicino a questo valore.\nSe l‚Äôistogramma √® largo e distribuito, significa che c‚Äô√® maggiore incertezza nella stima di \\(\\theta\\). Questo indica che i dati osservati non forniscono una stima precisa e che il valore di \\(\\theta\\) potrebbe variare notevolmente.\n\nplt.hist(theta_draws, bins=30, alpha=0.5, color='b', edgecolor='black', density=True)\n\n# Aggiunta di titolo e etichette agli assi\nplt.title('Istogramma della distribizione a posteriori di theta')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\n\nplt.show()",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo l‚Äôapplicazione degli strumenti statistici descritti nei capitoli precedenti all‚Äôanalisi bayesiana di due proporzioni. Inizieremo definendo i concetti di odds, odds ratio e logit. Successivamente, mostreremo come effettuare l‚Äôanalisi bayesiana per il confronto tra due proporzioni.\nUn rapporto di odds (OR) √® una misura di associazione tra un‚Äôesposizione (o un certo gruppo o una certa conditione) e un risultato. L‚ÄôOR rappresenta gli odds che si verifichi un risultato dato un‚Äôesposizione particolare, confrontate con gli odds del risultato che si verifica in assenza di tale esposizione.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#odds",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#odds",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "33.1 Odds",
    "text": "33.1 Odds\nIl termine ‚Äúodds‚Äù rappresenta il rapporto tra la probabilit√† che un evento si verifichi e la probabilit√† che l‚Äôevento opposto si verifichi. Matematicamente, l‚Äôodds pu√≤ essere calcolato come:\n\\[ \\text{odds} = \\frac{\\pi}{1-\\pi}, \\]\ndove \\(\\pi\\) rappresenta la probabilit√† dell‚Äôevento di interesse.\nMentre una probabilit√† \\(\\pi\\) √® sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilit√† di un evento.\nSe la probabilit√† di un evento √® \\(\\pi = \\frac{2}{3}\\), allora la probabilit√† che l‚Äôevento non si verifichi √® \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell‚Äôevento sono:\n\\[ \\text{odds} = \\frac{2/3}{1-2/3} = 2. \\]\nQuesto significa che la probabilit√† che l‚Äôevento si verifichi √® il doppio della probabilit√† che non si verifichi.\nSe, invece, la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{3}\\), allora gli odds che l‚Äôevento si verifichi sono la met√† rispetto agli odds che non si verifichi:\n\\[ \\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}. \\]\nInfine, se la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{2}\\), allora gli odds dell‚Äôevento sono pari a 1:\n\\[ \\text{odds} = \\frac{1/2}{1-1/2} = 1. \\]\n\n33.1.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilit√† \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull‚Äôincertezza dell‚Äôevento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilit√† dell‚Äôevento sono inferiori al 50-50, cio√® \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilit√† dell‚Äôevento sono del 50-50, cio√® \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilit√† dell‚Äôevento sono superiori al 50-50, cio√® \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l‚Äôuso dell‚Äôodds rispetto alla probabilit√†, nonostante quest‚Äôultima sia un concetto pi√π intuitivo, risiede nel fatto che quando le probabilit√† si avvicinano ai valori estremi (cio√® 0 o 1), √® pi√π facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilit√†.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#odds-ratio",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#odds-ratio",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "33.2 Odds Ratio",
    "text": "33.2 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l‚Äôodds ratio. L‚Äôodds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[ OR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}. \\]\nInterpretazione:\n\nOR = 1: l‚Äôappartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR aumenta la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR riduce la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore.\n\nL‚Äôodds ratio √® particolarmente utile quando vogliamo confrontare due gruppi e vedere come l‚Äôappartenenza a uno di essi influenza la probabilit√† di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l‚Äôefficacia di una terapia comportamentale per ridurre l‚Äôansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l‚Äôodds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilit√† di riduzione dell‚Äôansia. Se l‚Äôodds ratio √® maggiore di 1, significa che la terapia ha aumentato le probabilit√† di riduzione dell‚Äôansia; se √® inferiore a 1, significa che il trattamento ha ridotto le probabilit√† di riduzione dell‚Äôansia. L‚Äôodds ratio ci fornisce quindi una misura dell‚Äôeffetto della terapia rispetto al controllo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "33.3 Logaritmo dell‚ÄôOdds Ratio",
    "text": "33.3 Logaritmo dell‚ÄôOdds Ratio\nIl logaritmo dell‚Äôodds ratio √® una trasformazione matematica molto utilizzata nell‚Äôanalisi statistica, specialmente nella regressione logistica. Essa permette di rendere l‚Äôodds ratio interpretabile su una scala lineare, semplificando l‚Äôanalisi e l‚Äôinterpretazione dei risultati.\nLa formula per calcolare il logaritmo dell‚Äôodds ratio √® la seguente:\n\\[ \\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right). \\]\nIn altre parole, il logaritmo dell‚Äôodds ratio √® il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n33.3.1 Interpretazione\nL‚Äôinterpretazione del logaritmo dell‚Äôodds ratio √® pi√π intuitiva rispetto all‚Äôodds ratio stesso. Una variazione di una unit√† nel logaritmo dell‚Äôodds ratio corrisponde a un cambiamento costante nell‚Äôodds ratio stesso.\nSe il logaritmo dell‚Äôodds ratio √® positivo, significa che l‚Äôodds dell‚Äôevento nel primo gruppo √® maggiore rispetto al secondo gruppo. Pi√π il valore del logaritmo dell‚Äôodds ratio si avvicina a zero, pi√π l‚Äôodds dell‚Äôevento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell‚Äôodds ratio √® negativo, l‚Äôodds dell‚Äôevento nel primo gruppo √® inferiore rispetto al secondo gruppo. Un valore di logaritmo dell‚Äôodds ratio vicino a zero indica che l‚Äôodds dell‚Äôevento √® simile nei due gruppi.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "33.4 Analisi bayesiana delle proporzioni",
    "text": "33.4 Analisi bayesiana delle proporzioni\nUna volta compresi i concetti di odds, odds ratio e logit, possiamo procedere all‚Äôanalisi bayesiana delle proporzioni. Questo approccio consente di confrontare le proporzioni di due gruppi, ottenendo stime delle probabilit√† a posteriori e degli intervalli di credibilit√†.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nIn questo capitolo, analizzeremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Hoffmann, Hofman, e Wagenmakers (2022). Von Frisch (1914) ha voluto verificare se le api possiedono la visione dei colori confrontando il comportamento di due gruppi di api. L‚Äôesperimento si compone di una fase di addestramento e di una fase di test.\nNella fase di addestramento, le api del gruppo sperimentale vengono esposte a un disco blu e a un disco verde. Solo il disco blu √® ricoperto di una soluzione zuccherina, molto appetita dalle api. Il gruppo di controllo, invece, non riceve alcun addestramento.\nNella fase di test, la soluzione zuccherina viene rimossa dal disco blu e si osserva il comportamento di entrambi i gruppi. Se le api del gruppo sperimentale hanno appreso che solo il disco blu contiene la soluzione zuccherina e sono in grado di distinguere tra il blu e il verde, dovrebbero preferire esplorare il disco blu piuttosto che quello verde durante la fase di test.\nIl ricercatore osserva che in 130 casi su 200, le api del gruppo sperimentale continuano ad avvicinarsi al disco blu dopo la rimozione della soluzione zuccherina. Le api del gruppo di controllo, che non sono state addestrate, si avvicinano al disco blu 100 volte su 200.\nPer confrontare il comportamento delle api nelle due condizioni, useremo l‚Äôodds ratio, cos√¨ da confrontare le probabilit√† dell‚Äôevento critico (scelta del disco blu) tra i due gruppi.\nCalcoliamo la proporzione delle api che scelgono il disco blu nella condizione sperimentale:\n\\[ p_e = \\frac{130}{200} = 0.65 \\]\nCalcoliamo gli odds nella condizione sperimentale:\n\\[ \\text{odds}_e = \\frac{p_e}{1 - p_e} \\approx 1.86 \\]\nQuesto ci indica che, nel gruppo sperimentale, ci sono circa 1.86 ‚Äúsuccessi‚Äù (ossia la scelta del disco blu) per ogni ‚Äúinsuccesso‚Äù (scelta del disco verde).\nProcediamo calcolando gli odds nella condizione di controllo:\n\\[ p_c = \\frac{100}{200} = 0.5 \\]\n\\[ \\text{odds}_c = \\frac{p_c}{1 - p_c} = 1.0 \\]\nQuesto ci indica che, nel gruppo di controllo, il numero di ‚Äúsuccessi‚Äù e ‚Äúinsuccessi‚Äù √® uguale.\nInfine, confrontiamo gli odds tra la condizione sperimentale e la condizione di controllo per calcolare l‚Äôodds ratio (OR):\n\\[ \\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = 1.86 \\]\nGli odds di scelta del disco blu aumentano di circa 1.86 volte nel gruppo sperimentale rispetto al gruppo di controllo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "33.5 Analisi Bayesiana dell‚ÄôOdds Ratio",
    "text": "33.5 Analisi Bayesiana dell‚ÄôOdds Ratio\nNella nostra analisi, ci focalizziamo sull‚ÄôOdds Ratio (OR) per valutare la differenza nel comportamento di scelta delle api nelle due condizioni dell‚Äôesperimento discusso. L‚ÄôOR fornisce una stima puntuale della differenza basata sul nostro campione specifico. Tuttavia, per realizzare un‚Äôinferenza statistica robusta, √® essenziale considerare l‚Äôincertezza nelle nostre stime, caratterizzata attraverso la distribuzione a posteriori.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le nostre conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo ci permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nPer affrontare questa questione, adottiamo un approccio bayesiano, costruendo la distribuzione a posteriori dell‚ÄôOR. A partire da questa distribuzione, determiniamo un intervallo di credibilit√† del 90%, che rappresenta l‚Äôintervallo entro il quale, con il 90% di confidenza, possiamo aspettarci che ricada il vero valore dell‚ÄôOR della popolazione.\nSe questo intervallo non include il valore 1, disponiamo di una solida evidenza (con un livello di credibilit√† del 90%) che la differenza tra le due condizioni esaminate corrisponde a una differenza reale nella popolazione, il che suggerisce che non si tratta di un artefatto generato dalla nostra incertezza. In altre parole, possiamo affermare con ragionevole certezza che le api dispongono di una visione cromatica.\nD‚Äôaltro canto, se l‚Äôintervallo di credibilit√† includesse il valore 1, ci√≤ indicherebbe che la differenza osservata nel nostro campione potrebbe non riflettere una differenza significativa nella popolazione generale, suggerendo che potrebbe essere una peculiarit√† del nostro campione specifico.\nL‚Äôanalisi bayesiana e il calcolo dell‚Äôintervallo di credibilit√† verranno condotti utilizzando cmdstanpy, che ci permette di implementare modelli bayesiani in modo efficiente e rigoroso. Utilizzeremo una distribuzione a priori debolmente informativa per l‚ÄôOR, in modo da non influenzare eccessivamente i risultati con assunzioni preliminari.\nUna volta ottenuta la distribuzione a posteriori dell‚ÄôOR, possiamo calcolare il nostro intervallo di credibilit√† del 90%. Questo intervallo fornir√† una rappresentazione della nostra incertezza riguardo il vero valore dell‚ÄôOR nella popolazione. Se il nostro intervallo di credibilit√† esclude il valore 1, possiamo concludere che esiste una differenza significativa tra i due gruppi, confermando che le api possono distinguere i colori e preferire il disco blu.\nIn sintesi, l‚Äôapproccio bayesiano non solo ci permette di stimare l‚ÄôOR, ma anche di quantificare la nostra incertezza e fare inferenze pi√π solide e informative sulla capacit√† delle api di distinguere tra colori.\n\n33.5.1 Likelihood\nLa likelihood del modello descrive la probabilit√† di osservare i dati dati i parametri del modello. Nel nostro caso, abbiamo due gruppi con eventi binomiali.\nPer il gruppo 1:\n\\[ y_1 \\sim \\text{Binomiale}(N_1, \\theta_1) .\\]\nPer il gruppo 2:\n\\[ y_2 \\sim \\text{Binomiale}(N_2, \\theta_2) .\\]\n\n\n33.5.2 Priors\nI priors del modello descrivono le nostre convinzioni iniziali sui parametri prima di osservare i dati. Nel nostro caso, i parametri \\(\\theta_1\\) e \\(\\theta_2\\) seguono una distribuzione Beta(2, 2).\nPer \\(\\theta_1\\):\n\\[ \\theta_1 \\sim \\text{Beta}(2, 2) .\\]\nPer \\(\\theta_2\\):\n\\[ \\theta_2 \\sim \\text{Beta}(2, 2) .\\]\nCompiliamo e stampiamo il modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'odds-ratio.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n//  Comparison of two groups with Binomial\ndata {\n  int&lt;lower=0&gt; N1; // number of experiments in group 1\n  int&lt;lower=0&gt; y1; // number of events in group 1\n  int&lt;lower=0&gt; N2; // number of experiments in group 2\n  int&lt;lower=0&gt; y2; // number of events in group 2\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta1; // probability of event in group 1\n  real&lt;lower=0, upper=1&gt; theta2; // probability of event in group 2\n}\nmodel {\n  // model block creates the log density to be sampled\n  theta1 ~ beta(2, 2); // prior\n  theta2 ~ beta(2, 2); // prior\n  y1 ~ binomial(N1, theta1); // observation model / likelihood\n  y2 ~ binomial(N2, theta2); // observation model / likelihood\n}\ngenerated quantities {\n  real oddsratio = (theta1 / (1 - theta1)) / (theta2 / (1 - theta2));\n}\n\n\n\nNel blocco generated quantities, calcoliamo l‚Äôodds ratio:\n\\[ \\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}. \\]\nQuesto rapporto delle odds ci d√† una misura della forza dell‚Äôassociazione tra l‚Äôevento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.\nCreiamo un dizionario che contiene i dati.\n\nn1 = 200\ny1 = 130\nn2 = 200\ny2 = 100\n\nstan_data = {\n    'N1': n1,\n    'y1': y1,\n    'N2': n2,\n    'y2': y2\n}\n\nprint(stan_data)\n\n{'N1': 200, 'y1': 130, 'N2': 200, 'y2': 100}\n\n\nEseguiamo il campionamento.\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEstraiamo la distribuzione a posteriori dell‚Äôodds ratio e generiamo un istogramma.\n\nor_draws = trace.stan_variable('oddsratio')\n\n\nplt.hist(or_draws, bins=30, alpha=0.5, color='b', edgecolor='black', density=True)\nplt.title('Istogramma della distribizione a posteriori di OR')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds √® il modo pi√π semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi √® un‚Äôelevata probabilit√† che la differenza tra i due gruppi sia affidabile e relativamente grande.\nUn sommario della distribuzione a posteriori dell‚Äôodds ratio si ottine nel modo seguente.\n\naz.summary(trace, var_names=['oddsratio'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.88\n0.39\n1.2\n2.6\n0.0\n0.0\n6936.86\n5183.54\n1.0\n\n\n\n\n\n\n\n\nPossiamo determinare la probabilit√† che il rapporto di probabilit√† (odds ratio) superi 1. Per farlo, √® sufficiente analizzare gli 8000 campioni della distribuzione posteriore dell‚Äôodds ratio\n\nlen(or_draws)\n\n8000\n\n\ne calcolare la proporzione di questi che presenta un valore maggiore di 1:\n\nnp.mean(or_draws &gt; 1.0)\n\n0.9985",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "33.6 Diagnostica delle catene markoviane",
    "text": "33.6 Diagnostica delle catene markoviane\nPrima di esaminare i risultati, eseguiamo la diagnostica delle catene markoviane.\n\n33.6.1 Mixing\nIl trace plot precedente dimostra un buon mixing. Questo √® evidenza che il campionamento MCMC ha raggiunto uno stato stazionario.\n\n_ = az.plot_trace(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n33.6.2 NumerositaÃÄ campionaria effettiva\nQuando si utilizzano metodi di campionamento MCMC, √® ragionevole chiedersi se un particolare campione estratto dalla distribuzione a posteriori sia sufficientemente grande per calcolare con sicurezza le quantit√† di interesse, come una media o un HDI. Questo non √® qualcosa che possiamo rispondere direttamente guardando solo il numero di punti della catena MCMC, e il motivo √® che i campioni ottenuti dai metodi MCMC hanno un certo grado di autocorrelazione, quindi la quantit√† effettiva di informazioni contenute in quel campione sar√† inferiore a quella che otterremmo da un campione iid della stessa dimensione. Possiamo pensare alla dimensione del campione effettivo (ESS) come a un stimatore che tiene conto dell‚Äôautocorrelazione e fornisce il numero di estrazioni che avremmo se il nostro campione fosse effettivamente iid.\nPer le catene buone, solitamente, il valore della dimensione del campione effettivo sar√† inferiore al numero di campioni. Ma l‚ÄôESS pu√≤ essere in realt√† pi√π grande del numero di campioni estratti. Quando si utilizza il campionatore NUTS, valori di ESS maggiori del numero totale di campioni possono verificarsi per parametri le cui distribuzioni posteriori sono vicine alla Gaussiana e che sono quasi indipendenti da altri parametri nel modello.\nNell‚Äôoutput di PyCM si considera ESS_BULK. Un euristica √® che deve essere almeno uguale a 400. Nel caso presente questo si verifica, quindi il valore ESS_BULK non fornisce alcuna evidenza di cattivo mixing.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.881\n0.386\n1.198\n2.597\n0.005\n0.003\n6937.0\n5184.0\n1.0\n\n\ntheta1\n0.647\n0.033\n0.585\n0.710\n0.000\n0.000\n6865.0\n5296.0\n1.0\n\n\ntheta2\n0.499\n0.035\n0.434\n0.564\n0.000\n0.000\n7465.0\n5391.0\n1.0\n\n\n\n\n\n\n\n\n\n\n33.6.3 R hat\nIn condizioni molto generali, i metodi di Markov chain Monte Carlo hanno garanzie teoriche che otterranno la risposta corretta indipendentemente dal punto di partenza. Sfortunatamente, tali garanzie sono valide solo per campioni infiniti. Quindi, nella pratica, abbiamo bisogno di modi per stimare la convergenza per campioni finiti. Un‚Äôidea diffusa √® quella di generare pi√π di una catena, partendo da punti molto diversi e quindi controllare le catene risultanti per vedere se sembrano simili tra loro. Questa nozione intuitiva pu√≤ essere formalizzata in un indicatore numerico noto come R-hat. Esistono molte versioni di questo stimatore, poich√© √® stato perfezionato nel corso degli anni. In origine il R-hat veniva interpretato come la sovrastima della varianza dovuta al campionamento MCMC finito. Ci√≤ significa che se si continua a campionare all‚Äôinfinito si dovrebbe ottenere una riduzione della varianza della stima di un fattore R-hat. E quindi il nome ‚Äúfattore di riduzione potenziale della scala‚Äù (potential scale reduction factor), con il valore target di 1 che significa che aumentare il numero di campioni non ridurr√† ulteriormente la varianza della stima. Tuttavia, nella pratica √® meglio pensarlo solo come uno strumento diagnostico senza cercare di sovra-interpretarlo.\nL‚ÄôR-hat per il parametro theta viene calcolato come la deviazione standard di tutti i campioni di theta, ovvero includendo tutte le catene insieme, diviso per la radice quadratica media delle deviazioni standard separate all‚Äôinterno della catena. Il calcolo effettivo √® un po‚Äô pi√π complesso ma l‚Äôidea generale √® questa. Idealmente dovremmo ottenere un valore di 1, poich√© la varianza tra le catene dovrebbe essere la stessa della varianza all‚Äôinterno della catena. Da un punto di vista pratico, valori di R-hat inferiori a 1.1 sono considerati sicuri.\nNel caso presente questo si verifica. Possiamo ottenere R hat con Arviz:\n\naz.rhat(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 1.0\n    theta1     float64 8B 1.001\n    theta2     float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float641.0array(1.00038283)theta1()float641.001array(1.00052497)theta2()float641.001array(1.00059406)Indexes: (0)Attributes: (0)\n\n\nIl valore di \\(\\hat{R}\\), al massimo, raggiunge il valore di 1.001. Essendo il valore molto simile a 1 nel caso presente, possiamo dire che non ci sono evidenza di assenza di convergenza.\n\n\n33.6.4 Errore standard di Monte Carlo\nQuando si utilizzano metodi MCMC introduciamo un ulteriore livello di incertezza poich√© stiamo approssimando la posteriore con un numero finito di campioni. Possiamo stimare la quantit√† di errore introdotta utilizzando l‚Äôerrore standard di Monte Carlo (MCSE). L‚ÄôMCSE tiene conto del fatto che i campioni non sono veramente indipendenti l‚Äôuno dall‚Äôaltro e sono in realt√† calcolati dall‚ÄôESS. Mentre i valori di ESS e R-hat sono indipendenti dalla scala dei parametri, la statistica MCSE non lo √®. Se vogliamo riportare il valore di un parametro stimato al secondo decimale, dobbiamo essere sicuri che MCSE sia al di sotto del secondo decimale altrimenti, finiremo, erroneamente, per riportare una precisione superiore a quella che abbiamo realmente. Dovremmo controllare MCSE solo una volta che siamo sicuri che ESS sia abbastanza alto e R-hat sia abbastanza basso; altrimenti, MCSE non √® utile.\nNel nostro caso il MCSE √® sufficientemente piccolo.\n\naz.mcse(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 0.004636\n    theta1     float64 8B 0.0004029\n    theta2     float64 8B 0.0004034xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float640.004636array(0.00463567)theta1()float640.0004029array(0.00040294)theta2()float640.0004034array(0.00040337)Indexes: (0)Attributes: (0)\n\n\nCome per l‚ÄôESS, l‚ÄôMCSE varia nello spazio dei parametri e quindi potremmo anche volerlo valutare per diverse regioni dello spazio dei parametri.\n\n_ = az.plot_mcse(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nL‚Äôerrore standard di Monte Carlo ci informa della precisione della stima ottenuta usando il metodo MCMC. Non possiamo riportare una precisione dei risultati maggiore di quella indicata dalla MCSE. Pertanto, per il caso presente relativo all‚ÄôOdds Ratio (OR), possiamo affermare che la precisione massima raggiungibile √® limitata a due decimali.\n\n\n33.6.5 Autocorrelazione\nL‚Äôautocorrelazione riduce la quantit√† effettiva di informazioni contenute in un campione e quindi √® qualcosa che vogliamo mantenere al minimo. Possiamo ispezionare direttamente l‚Äôautocorrelazione con az.plot_autocorr.\n\n_ = az.plot_autocorr(trace, combined=True, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n33.6.6 Rank Plots\nI grafici dei ranghi sono un altro strumento diagnostico visivo che possiamo utilizzare per confrontare il comportamento del campionamento sia all‚Äôinterno che tra le catene. I grafici dei ranghi, in parole semplici, sono istogrammi dei campioni della distribuzione a posteriori espressi in termini di ranghi. Nei grafici dei ranghi, i ranghi sono calcolati combinando prima tutte le catene ma poi rappresentando i risultati separatamente per ogni catena. Se tutte le catene stimano la stessa distribuzione, ci aspettiamo che i ranghi abbiano una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ci√≤ indica un buon mix delle catene.\nPossiamo ottenere i grafici dei ranghi con az.plot_rank.\n\n_ = az.plot_rank(trace, kind=\"bars\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa √® la seguente.\n\n_ = az.plot_rank(trace, kind=\"vlines\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nPossiamo vedere nella figura che i ranghi sono molto simili ad una distribuzione uniforme e che tutte le catene sono simili tra loro senza alcuno scostamento distintivo.\n\n\n33.6.7 Divergenza\nFinora abbiamo diagnosticato il funzionamento di un campionatore esaminando i campioni generati. Un altro modo per eseguire una diagnosi √® monitorare il comportamento dei meccanismi interni del metodo di campionamento. Un esempio importante di tali diagnosi √® il concetto di divergenza presente in alcuni metodi Hamiltonian Monte Carlo (HMC). Le divergenze (o transizioni divergenti) sono un modo potente e sensibile per diagnosticare i campioni e funzionano come complemento alle diagnosi che abbiamo visto nelle sezioni precedenti.\nPyMC riporta il numero di transizioni divergenti. Se non viene riportato alcun messaggio che informa della presenza di transizioni divergenti, questo vuol dire che la distribuzione a posteriori √® stata stimata correttamente.\n\n\n33.6.8 BFMI\nIl BFMI (Fraction of Missing Information) serve a valutare quanto bene il processo di campionamento si allinea con la distribuzione della ‚Äúenergia‚Äù associata a ciascun campione. Nel contesto del campionamento Hamiltoniano, il termine ‚Äúenergia‚Äù si riferisce a una quantit√† calcolata durante il processo di campionamento che aiuta a valutare quanto √® probabile un certo set di parametri alla luce dei dati osservati e del modello statistico in esame.\nIl BFMI √® uno strumento che ci aiuta a valutare se il processo di campionamento sta ‚Äúesplorando‚Äù adeguatamente lo spazio dei parametri possibili. In altre parole, ci dice se il nostro processo di campionamento sta dando un‚Äôimmagine accurata delle regioni dello spazio dei parametri che sono realmente plausibili dati i nostri dati e il nostro modello. Un valore BFMI basso indica che il campionamento non √® riuscito a esplorare adeguatamente alcune regioni dello spazio dei parametri che dovrebbero essere state esplorate, e quindi i risultati del campionamento potrebbero non essere affidabili.\nGeneralmente, un valore inferiore a 0.3 indica un campionamento insufficiente.\nNel caso presente, dal momento che i valori BFMI sono superiori a 0.3 per tutte le catene, sembra che il processo di campionamento sia riuscito a esplorare adeguatamente lo spazio dei parametri.\n\naz.bfmi(trace)\n\narray([1.14346921, 1.11602384, 1.1467078 , 1.03197001])\n\n\nLa validazione del processo di campionamento pu√≤ essere efficacemente eseguita analizzando graficamente le quantit√† note come ‚Äúenergy transition‚Äù e ‚Äúmarginal energy‚Äù. Queste metriche sono strettamente legate alla funzione obiettivo che l‚Äôalgoritmo di campionamento intende ottimizzare e giocano un ruolo cruciale nel rilevare potenziali problematiche che possono emergere durante il campionamento.\n\nEnergy transition: questa metrica illustra l‚Äô‚Äúenergia‚Äù calcolata in ogni singolo passo dell‚Äôalgoritmo di campionamento, offrendo una visione dettagliata delle fluttuazioni che intervengono ad ogni iterazione. Facilita l‚Äôidentificazione delle aree dello spazio dei parametri dove l‚Äôalgoritmo potrebbe incontrare difficolt√† nel campionare in modo corretto.\nMarginal energy: fornisce un profilo dell‚Äô‚Äúenergia‚Äù marginale per l‚Äôintero set di campioni, riflettendo l‚Äô‚Äúenergia‚Äù media in ogni punto del campione. √à una rappresentazione grafica dell‚Äô‚Äúenergia‚Äù associata alla distribuzione a posteriori che si intende campionare.\n\nPer un‚Äôanalisi diagnostica efficace, √® auspicabile che il tracciato dell‚Äô‚Äúenergy transition‚Äù coincida sostanzialmente con quello della ‚Äúmarginal energy‚Äù. Tale congruenza √® indicativa di una esplorazione ben riuscita dello spazio dei parametri, assicurando che le regioni ad alta probabilit√† nella distribuzione a posteriori siano state correttamente campionate. Pertanto, una buona sovrapposizione tra i grafici delle due metriche attesterebbe un funzionamento ottimale del modello, conferendo un grado di affidabilit√† elevato alle stime dei parametri derivanti dal processo di campionamento.\n\n_ = az.plot_energy(trace)\n\n\n\n\n\n\n\n\n\n\n33.6.9 Conclusione\nIn questo capitolo abbiamo approfondito l‚Äôanalisi bayesiana focalizzandoci sulla stima dell‚Äôodds ratio (OR). I risultati della diagnosi delle catene Markoviane non evidenziano problematiche relative alla convergenza dell‚Äôalgoritmo n√© discrepanze nel modello statistico adottato, permettendoci di procedere con l‚Äôanalisi dei risultati ottenuti.\nL‚Äôanalisi ha determinato un valore a posteriori per l‚ÄôOR di 1.88, accompagnato da un intervallo di credibilit√† del 94% compreso tra 1.20 e 2.60. Poich√© questo intervallo non include il valore 1, possiamo affermare, con un grado di certezza del 94%, che il comportamento delle api differisce nelle due condizioni sperimentali. Questo fornisce evidenza a supporto dell‚Äôipotesi che le api dispongano di una visione cromatica.\nL‚Äôapproccio bayesiano adottato ci ha permesso di integrare le conoscenze a priori con i dati ottenuti dall‚Äôanalisi, risultando in una stima dell‚Äôodds ratio pi√π affidabile e accurata.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/19_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/19_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "33¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jul 14 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\ncmdstanpy : 1.2.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHoffmann, Tabea, Abe Hofman, e Eric-Jan Wagenmakers. 2022. ¬´Bayesian tests of two proportions: A tutorial with R and JASP¬ª. Methodology 18 (4): 239‚Äì77.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html",
    "href": "chapters/chapter_4/22_stan_normal_normal.html",
    "title": "34¬† Inferenza bayesiana su una media",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo principale di questo capitolo √® esaminare un contesto che abbiamo gi√† preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione √® stato estratto. Tuttavia, anzich√© procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo i metodi MCMC con Stan.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#il-modello-normale",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#il-modello-normale",
    "title": "34¬† Inferenza bayesiana su una media",
    "section": "34.1 Il modello Normale",
    "text": "34.1 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l‚Äôapprossimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l‚Äôesercizio descritto nel capitolo {ref}distr-coniugate-2-notebook usando Stan.\n\n34.1.1 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell‚Äôarea di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ‚Äô60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un‚Äôeconomia basata su caccia e raccolta. Riprodurremo l‚Äôanalisi descritta da {cite:t}McElreath_rethinking, esaminando unicamente i valori di altezza per individui di et√† superiore ai 18 anni.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\ndf.head()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\n\nlen(df[\"height\"])\n\n352\n\n\n\nsns.kdeplot(df[\"height\"], bw_adjust=0.5, fill=True)  # Adjust bw_adjust for smoothing\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\nLa media dei valori dell‚Äôaltezza nel campione √®:\n\nnp.mean(df[\"height\"])\n\n154.5970926136364\n\n\ncon una deviazione standard pari a:\n\nnp.std(df[\"height\"], ddof=1)\n\n7.742332137351995\n\n\n\n\n34.1.2 Modello di Base\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo {cite:t}McElreath_rethinking, ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell‚Äôaltezza.\nPertanto, il modello Normale si definisce nel seguente modo:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilit√†, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l‚Äôoggetto dell‚Äôinferenza.\n\nstan_file = os.path.join(project_directory, 'stan', 'gaussian_height.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\nparameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  sigma ~ normal(0, 20);\n  mu ~ normal(181, 30);\n}\n\n\n\nCreaiamo un dizionario con i dati in formato appropriato per Stan:\n\nstan_data = {'N': len(df[\"height\"]), 'y': df[\"height\"]}\nprint(stan_data)\n\n{'N': 352, 'y': 0      151.765\n1      139.700\n2      136.525\n3      156.845\n4      145.415\n        ...   \n347    162.560\n348    142.875\n349    162.560\n350    156.210\n351    158.750\nName: height, Length: 352, dtype: float64}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\mu\\) e \\(\\sigma\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\nUna sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente.\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.60\n0.42\n153.84\n155.39\n0.0\n0.0\n7864.52\n5825.33\n1.0\n\n\nsigma\n7.77\n0.30\n7.21\n8.34\n0.0\n0.0\n6655.48\n5167.04\n1.0",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#parametrizzazione-non-centrata",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#parametrizzazione-non-centrata",
    "title": "34¬† Inferenza bayesiana su una media",
    "section": "34.2 Parametrizzazione Non Centrata",
    "text": "34.2 Parametrizzazione Non Centrata\nNella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell‚Äôinferenza (\\(\\mu\\) e \\(\\sigma\\)) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro \\(\\mu\\) abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro \\(\\sigma\\) abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare.\n√à possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura √® chiamata ‚Äúparametrizzazione non centrata‚Äù (non-centered parametrization). In questo modello, utilizziamo variabili latenti \\(\\mu_{\\text{raw}}\\) e \\(\\sigma_{\\text{raw}}\\), che seguono una distribuzione normale standard:\n\\[\n\\begin{align}\n\\mu_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\\\\\n\\sigma_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\n\\end{align}\n\\]\nQueste variabili vengono poi trasformate per ottenere i parametri \\(\\mu\\) e \\(\\sigma\\) sulla scala originale:\n\\[\n\\begin{align}\n\\mu &= y_{\\text{mean}} + y_{\\text{sd}} \\cdot \\mu_{\\text{raw}} \\notag\\\\\n\\sigma &= y_{\\text{sd}} \\cdot \\sigma_{\\text{raw}} \\notag\n\\end{align}\n\\]\nDove: - \\(y_{\\text{mean}}\\) √® la media dei dati osservati \\(y\\). - \\(y_{\\text{sd}}\\) √® la deviazione standard dei dati osservati \\(y\\).\n\nstan_ncp_file = os.path.join(project_directory, 'stan', 'gaussian_ncp.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\n\nDi seguito √® riportato il codice Stan per questo modello con la parametrizzazione non centrata:\n\nprint(model_ncp.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\ntransformed data {\n    real y_mean = mean(y);\n    real y_sd = sd(y);\n}\nparameters {\n    real mu_raw;\n    real&lt;lower=0&gt; sigma_raw;\n}\ntransformed parameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Priors:\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    // Likelihood:\n    y ~ normal(mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\n\n\nEcco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.\n\nBlocco Dati:\n\nint&lt;lower=1&gt; N;: Il numero totale di prove o osservazioni.\nvector[N] y;: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.\n\nBlocco Dati Trasformati:\n\nreal y_mean = mean(y);: La media dei dati osservati y.\nreal y_sd = sd(y);: La deviazione standard dei dati osservati y.\n\nBlocco Parametri:\n\nreal mu_raw;: Un parametro latente che segue una distribuzione normale standard.\nreal&lt;lower=0&gt; sigma_raw;: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.\n\nBlocco Parametri Trasformati:\n\nreal mu;: La media della distribuzione normale per y sulla sua scala originale.\nreal&lt;lower=0&gt; sigma;: La deviazione standard della distribuzione normale per y sulla sua scala originale.\nQuesti parametri trasformati sono definiti come:\nmu = y_mean + y_sd * mu_raw;\nsigma = y_sd * sigma_raw;\n\n\nLa parametrizzazione non centrata comporta la riparametrizzazione del modello in termini di variabili standardizzate (mu_raw e sigma_raw) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e propriet√† di convergenza, specialmente nei modelli gerarchici.\n\nParametri Latenti (mu_raw e sigma_raw):\n\nmu_raw ~ normal(0, 1);: mu_raw √® una variabile normale standardizzata.\nsigma_raw ~ normal(0, 1);: sigma_raw √® una variabile normale standardizzata vincolata a essere positiva.\n\nTrasformazione alla Scala Originale:\n\nmu = y_mean + y_sd * mu_raw;: Questo scala e trasla mu_raw alla posizione e scala dei dati osservati y.\nsigma = y_sd * sigma_raw;: Questo scala sigma_raw alla scala dei dati osservati y.\n\n\nLa dichiarazione della verosimiglianza y ~ normal(mu, sigma); indica che i dati osservati y seguono una distribuzione normale con media mu e deviazione standard sigma. Ecco perch√© ha senso anche se y √® sulla sua scala originale:\n\nDati Osservati sulla Scala Originale: I dati osservati y sono sulla loro scala originale.\nParametri sulla Scala Originale: I parametri mu e sigma, dopo la trasformazione nel blocco transformed parameters, sono anch‚Äôessi sulla scala originale di y.\n\nQuindi, la dichiarazione y ~ normal(mu, sigma); specifica correttamente che i dati osservati y (sulla loro scala originale) sono modellati da una distribuzione normale con media mu e deviazione standard sigma, entrambe sulla scala originale di y.\nInfine, il blocco generated quantities viene utilizzato per i controlli predittivi posteriori generando nuovi dati (y_rep) dalla distribuzione posteriore dei parametri (mu e sigma):\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\ny_rep: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore mu e la deviazione standard posteriore sigma. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.\n\nEseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\n_ = az.plot_trace(trace_ncp, var_names=['mu', 'sigma'])\n\n\n\n\n\n\n\n\nOtteniamo una sintesi delle distribuzioni a posteriori dei parametri:\n\nsummary = az.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\nprint(summary)\n\n         mean    sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nmu     154.61  0.42  153.83   155.39       0.01      0.0   6329.64   5029.29   \nsigma    7.76  0.29    7.20     8.30       0.00      0.0   7836.78   5829.76   \n\n       r_hat  \nmu       1.0  \nsigma    1.0  \n\n\nI risultati sono molto simili a quelli ottenuti in precedenza.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#posterior-predictive-check",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#posterior-predictive-check",
    "title": "34¬† Inferenza bayesiana su una media",
    "section": "34.3 Posterior predictive check",
    "text": "34.3 Posterior predictive check\nUno dei vantaggi del toolkit bayesiano √® che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(Œ∏|Y) √® possibile utilizzarla per generare le previsioni p(·ª∏). Matematicamente, questo pu√≤ essere fatto calcolando:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta distribuzione √® nota come distribuzione predittiva posteriore. √à predittiva perch√© viene utilizzata per fare previsioni e posteriore perch√© √® calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.\nUtilizzando Stan √® facile per ottenere campioni predittivi posteriori: non √® necessario calcolare alcun integrale. Dobbiamo convertire l‚Äôoggetto creato dalla funzione sample() nel formato ArviZ InferenceData:\n\n# Convert to ArviZ InferenceData object\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nUn uso comune della distribuzione predittiva posteriore √® quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello √® una buona rappresentazione dei dati. Possiamo utilizzare la funzione plot_ppc di ArviZ per visualizzare la distribuzione predittiva posteriore e i dati osservati. Il codice √®:\n\n# Plot the posterior predictive check\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nNella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee blu sono KDE calcolate da ciascuno dei 500 campioni predittivi posteriori. Le linee blu riflettono l‚Äôincertezza associata alla distribuzione dei dati previsti.\nDi default, in ArviZ le KDE vengono stimati all‚Äôinterno dell‚Äôintervallo effettivo dei dati e si assume che siano zero al di fuori di questo intervallo.\nDato che il tracciato del KDE plot √® contenuto nell‚Äôinsieme di profili dei KDE plot dei campioni predittivi a posteriori, si pu√≤ concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed √® utile per la maggior parte delle analisi. Tuttavia, √® importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all‚Äôintero dataset. Esploreremo ora come poter sviluppare un modello alternativo.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#modello-robusto",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#modello-robusto",
    "title": "34¬† Inferenza bayesiana su una media",
    "section": "34.4 Modello ‚Äúrobusto‚Äù",
    "text": "34.4 Modello ‚Äúrobusto‚Äù\nNon √® necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianit√† possono essere considerate attraverso l‚Äôutilizzo della distribuzione t di Student, che √® particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello ‚Äòrobusto‚Äô, maggiormente adatto a gestire osservazioni che si discostano dalla normalit√† nelle code della distribuzione.\nLa distribuzione t di Student √® caratterizzata dal parametro \\(\\nu\\), noto come ‚Äògradi di libert√†‚Äô. Quando \\(\\nu\\) √® pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale.\n\nnu_values = [1, 2, 10]\n\nfig, ax = plt.subplots()\n\nfor nu in nu_values:\n    x = np.linspace(-5, 5, 1000)\n    y = stats.t.pdf(x, df=nu, loc=0, scale=1)\n    ax.plot(x, y, label=f\"ŒΩ={nu}\")\n\nx = np.linspace(-5, 5, 1000)\ny = stats.t.pdf(x, df=np.inf, loc=0, scale=1)\nax.plot(x, y, linestyle=\"--\", color=\"k\", label=\"ŒΩ=‚àû\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTuttavia, le code della distribuzione t di Student risultano pi√π pesanti rispetto a quelle della normale quando \\(\\nu\\) √® basso. Pertanto, proponiamo di assegnare a \\(\\nu\\) una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.\n\n# Define the rate parameter for the exponential distribution\nrate = 1 / 30\n\n# Generate samples from the exponential distribution\nsamples = np.random.exponential(scale=1 / rate, size=10000)\n\n# Create the histogram plot of the samples\nplt.hist(samples, bins=50, density=True, alpha=0.75, label=\"Sampled Distribution\")\nplt.title(\"Exponential Distribution (Œª = 1/30)\")\nplt.xlabel(\"Values\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nstan_student_file = os.path.join(project_directory, 'stan', 'student-model.stan')\nmodel_student = CmdStanModel(stan_file=stan_student_file)\nprint(model_student.code())\n\ndata {\n    int&lt;lower=1&gt; N;  // Numero totale di prove\n    vector[N] y;  // Punteggio in ciascuna prova\n}\ntransformed data {\n    real y_mean = mean(y);  // Media dei dati osservati\n    real y_sd = sd(y);  // Deviazione standard dei dati osservati\n}\nparameters {\n    real mu_raw;  // Parametro latente standardizzato per mu\n    real&lt;lower=0&gt; sigma_raw;  // Parametro latente standardizzato per sigma\n    real&lt;lower=1&gt; nu;  // Gradi di libert√† per la distribuzione t di Student\n}\ntransformed parameters {\n    real mu;  // Media sulla scala originale\n    real&lt;lower=0&gt; sigma;  // Deviazione standard sulla scala originale\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Distribuzioni a priori non centrate\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    nu ~ exponential(1.0 / 30.0);  // Prior esponenziale per i gradi di libert√†\n    // Verosimiglianza\n    y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = student_t_rng(nu, mu, sigma);\n    }\n}\n\n\n\n\ntrace_student = model_student.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori e le tracce dei parametri del nuovo modello.\n\n_ = az.plot_trace(trace_student, var_names=['mu', 'sigma', 'nu'])\n\n\n\n\n\n\n\n\nConvertiamo i risultati in un oggetto InferenceData di ArviZ.\n\nidata = az.from_cmdstanpy(\n    posterior=trace_student,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nGeneriamo la distribuzione predittiva a posteriori.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nLa figura illustra che la situazione √® analoga a quella del caso gaussiano. Questo non √® sorprendente, dato che i dati relativi all‚Äôaltezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l‚Äôimpiego della distribuzione t di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto.\n\naz.summary(trace_student, var_names=['mu', 'sigma', 'nu'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.57\n0.42\n153.85\n155.40\n0.00\n0.00\n8798.72\n6040.50\n1.0\n\n\nsigma\n7.63\n0.30\n7.08\n8.21\n0.00\n0.00\n7145.94\n6226.65\n1.0\n\n\nnu\n62.39\n36.10\n11.40\n129.62\n0.41\n0.31\n7870.31\n5565.90\n1.0",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "title": "34¬† Inferenza bayesiana su una media",
    "section": "34.5 Commenti e considerazioni finali",
    "text": "34.5 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato il metodo per calcolare l‚Äôintervallo di credibilit√† per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l‚Äôinferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/chapter_4/22_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/chapter_4/22_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "title": "34¬† Inferenza bayesiana su una media",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\narviz     : 0.18.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza Bayesiana",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  }
]