[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science per Psicologi",
    "section": "",
    "text": "Benvenuti\nQuesto sito web √® dedicato al materiale didattico dell‚Äôinsegnamento di Psicometria (A.A. 2024/2025), rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell‚ÄôUniversit√† degli Studi di Firenze.\nIl corso √® strutturato per fornire agli studenti una formazione teorica e pratica approfondita nell‚Äôinferenza statistica, enfatizzando particolarmente le applicazioni pratiche attraverso la programmazione. Attraverso esercitazioni guidate, gli studenti impareranno a manipolare e analizzare dati psicologici utilizzando Python, acquisendo cos√¨ le competenze necessarie per prendere decisioni informate e realizzare interpretazioni precise nei loro progetti di modellazione.\nIl programma copre un ampio spettro di tecniche, partendo dall‚Äôanalisi descrittiva per arrivare fino ai modelli gerarchici avanzati. Si pone un forte accento sull‚Äôinferenza causale, approcciata da una prospettiva bayesiana, includendo l‚Äôuso di Grafi Aciclici Diretti (DAG) per esplorare in modo approfondito le relazioni causali. L‚Äôintento √® di andare oltre i limiti della modellazione lineare tradizionale, mostrando come integrare efficacemente i modelli psicologici avanzati nell‚Äôanalisi statistica.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#informazioni-sullinsegnamento",
    "href": "index.html#informazioni-sullinsegnamento",
    "title": "Data Science per Psicologi",
    "section": "Informazioni sull‚Äôinsegnamento",
    "text": "Informazioni sull‚Äôinsegnamento\n\n\nCodice: B000286 - PSICOMETRIA \n\nModulo: B000286 - PSICOMETRIA (Cognomi L-Z) \n\nCorso di laurea: Scienze e Tecniche Psicologiche \n\nAnno Accademico: 2024-2025 \n\nMateriali didattici: √à sufficiente disporre di un laptop/computer funzionante. Tutti i materiali didattici e il software necessario sono forniti gratuitamente a tutti gli studenti, senza richiedere alcun acquisto.\n\nCalendario: Il corso si terr√† dal 3 marzo al 31 maggio 2025.\n\nOrario delle lezioni: Le lezioni si svolgeranno il luned√¨ e il marted√¨ dalle 8:30 alle 10:30 e il gioved√¨ dalle 11:30 alle 13:30.\n\nLuogo: Le lezioni si terranno presso il Plesso didattico La Torretta.\n\nModalit√† di svolgimento della didattica: Le lezioni ed esercitazioni saranno svolte in modalit√† frontale.\n\n\n\n\n\n\n\nIl presente sito web costituisce l‚Äôunica fonte ufficiale da consultare per ottenere informazioni sul programma dell‚Äôinsegnamento B000286 - PSICOMETRIA (Cognomi L-Z) A.A. 2024-2025 e sulle modalit√† d‚Äôesame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Data Science per Psicologi",
    "section": "Syllabus",
    "text": "Syllabus\nIl Syllabus pu√≤ essere scaricato utilizzando questo link.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "chapters/python/introduction_python.html",
    "href": "chapters/python/introduction_python.html",
    "title": "1¬† Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa verranno presentati alcuni concetti fondamentali per l‚Äôanalisi dei dati utilizzando Python come linguaggio di programmazione e Jupyter come ambiente di sviluppo. Tuttavia, saranno trattati solo in modo conciso, poich√© esistono numerose risorse online che approfondiscono questo argomento. Per coloro che preferiscono una trattazione pi√π completa, si consiglia il libro A Beginners Guide to Python 3 Programming di John Hunt (disponibile gratuitamente alla comunit√† UniFi). Il tutorial ufficiale della documentazione Python, in italiano, √® fornito qui.\nPrima di procedere con il presente capitolo, √® indispensabile leggere l‚ÄôAppendice A, l‚ÄôAppendice C e l‚ÄôAppendice I.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html",
    "href": "chapters/python/00_prelims.html",
    "title": "2¬† Preliminari",
    "section": "",
    "text": "2.1 Iniziare ad Usare Python üêç\nIn questo corso, utilizzeremo Python all‚Äôinterno di un ambiente Jupyter Notebook. L‚Äôappendice Appendice A fornisce le istruzioni per installare Jupyter Notebook sul vostro computer.\nIn alternativa, √® possibile scrivere uno script Python in un file con estensione .py, il quale pu√≤ essere eseguito tramite il comando python nome_file.py dalla linea di comando.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#jupyter-notebook",
    "href": "chapters/python/00_prelims.html#jupyter-notebook",
    "title": "2¬† Preliminari",
    "section": "2.2 Jupyter Notebook",
    "text": "2.2 Jupyter Notebook\nI Jupyter Notebook offrono un ambiente interattivo in cui √® possibile eseguire il codice suddiviso in celle. Sebbene sia possibile eseguire il codice nelle celle in qualsiasi ordine, √® considerata una pratica consigliata eseguirle in sequenza al fine di prevenire errori e garantire una corretta esecuzione del codice.\nI Jupyter Notebook supportano due tipi di celle:\n\nCelle di Testo: Queste celle consentono di scrivere testo formattato utilizzando la sintassi Markdown. Questo permette agli autori di inserire del testo descrittivo, comprese immagini, formule in formato \\(\\LaTeX\\), tabelle e altro ancora. Le celle di testo facilitano la documentazione del processo di analisi dei dati in modo chiaro e comprensibile.\nCelle di Codice: Le celle di codice consentono di scrivere e eseguire codice Python. Il codice pu√≤ essere eseguito facendo clic sul triangolo situato a sinistra di ogni cella. Diverse celle possono contenere istruzioni diverse e possono essere eseguite in sequenza. √à importante notare che una funzione definita in una cella precedente pu√≤ essere utilizzata solo se la cella precedente √® stata eseguita.\n\nQui sotto abbiamo una cella di codice.\n\n# Make plot\n%matplotlib inline\nimport math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntheta = np.arange(0, 4 * math.pi, 0.1)\neight = plt.figure()\naxes = eight.add_axes([0, 0, 1, 1])\naxes.plot(0.5 * np.sin(theta), np.cos(theta / 2))\n\n\n\n\n\n\n\n\nQuando lavori con il notebook, puoi essere all‚Äôinterno di una cella, digitando i suoi contenuti, oppure al di fuori delle celle, muovendoti nel notebook.\nQuando sei all‚Äôinterno di una cella, premi Esc per uscirne. Quando ti muovi al di fuori delle celle, premi Invio per entrare.\n\nFuori da una cella:\n\nUsa i tasti freccia per muoverti.\nPremi Shift+Invio per eseguire il codice nel blocco.\n\nAll‚Äôinterno di una cella:\n\nPremi Tab per suggerire completamenti delle variabili.\n\n\nIl nome \"Jupyter\" deriva dalle tre principali lingue di programmazione supportate: Julia, Python e R. Tuttavia, √® possibile utilizzare i Jupyter Notebook con molte altre lingue di programmazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#esecuzione-locale-o-su-colab",
    "href": "chapters/python/00_prelims.html#esecuzione-locale-o-su-colab",
    "title": "2¬† Preliminari",
    "section": "2.3 Esecuzione Locale o su Colab",
    "text": "2.3 Esecuzione Locale o su Colab\nI Jupyter Notebook possono essere eseguiti sia in locale, sul vostro computer, che su un server remoto, come Google Colab. Questa flessibilit√† permette agli utenti di accedere ai propri notebook da qualsiasi dispositivo connesso a Internet e di condividere agevolmente il proprio lavoro con altri.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#kernel-nei-jupyter-notebook",
    "href": "chapters/python/00_prelims.html#kernel-nei-jupyter-notebook",
    "title": "2¬† Preliminari",
    "section": "2.4 Kernel nei Jupyter Notebook",
    "text": "2.4 Kernel nei Jupyter Notebook\nI Jupyter Notebook sono strumenti che agevolano la programmazione in Python grazie a un componente essenziale: il kernel. Quest‚Äôultimo funge da motore di esecuzione per il codice Python presente nelle celle dei notebook. Ogni volta che eseguite una cella, il suo contenuto viene processato dal kernel. La caratteristica pi√π significativa del kernel √® la sua capacit√† di preservare lo stato delle variabili e delle funzioni tra le diverse celle. In pratica, ci√≤ significa che potete definire variabili o funzioni in una cella e poi riutilizzarle in celle successive. Questa interattivit√† facilita l‚Äôesecuzione iterativa del codice e offre un modo dinamico per esplorare i dati.\nDurante l‚Äôinstallazione di Jupyter Notebook, di norma ricevete anche IPython, un kernel ottimizzato per Python.\nSi noti che il kernel Python deve essere installato all‚Äôinterno di un ambiente di sviluppo dedicato noto come ‚Äúambiente virtuale‚Äù (per ulteriori dettagli, si veda {ref}sec-virtual-environment). Questo ambiente svolge un ruolo fondamentale nel separare e isolare le librerie e le dipendenze necessarie per il kernel. Ci√≤ aiuta a evitare conflitti tra diverse configurazioni e garantisce il corretto funzionamento del codice nel contesto desiderato. L‚Äôutilizzo di ambienti specifici risulta particolarmente vantaggioso nei progetti che richiedono versioni particolari di librerie.\nIn questo insegnamento, faremo ampio uso della funzionalit√† conda, inclusa nell‚Äôinstallazione di Anaconda, per la gestione di questi ambienti. conda mette a disposizione funzioni utili per la creazione, la gestione e l‚Äôattivazione di ambienti separati, ciascuno con le sue configurazioni e dipendenze uniche. Questa capacit√† semplifica notevolmente la transizione tra diversi ambienti, garantendo che ogni progetto o kernel disponga delle risorse necessarie per operare in modo efficiente e senza interferenze.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#visual-studio-code",
    "href": "chapters/python/00_prelims.html#visual-studio-code",
    "title": "2¬† Preliminari",
    "section": "2.5 Visual Studio Code",
    "text": "2.5 Visual Studio Code\nIl modo pi√π semplice di usare un Jupyter Notebook √® all‚Äôinterno di Visual Studio Code. Dopo aver installato Visual Studio Code, √® necessario installare l‚Äôestensione Python per sfruttare le funzionalit√† specifiche per Python, inclusa la capacit√† di lavorare con Jupyter Notebook.\n\nIn Visual Studio Code, si clicca sull‚Äôicona delle estensioni (quadrati che si intersecano) nella barra laterale a sinistra.\nSi cerca ‚ÄúPython‚Äù nella barra di ricerca e si seleziona l‚Äôestensione ufficiale offerta da Microsoft.\nSi clicca su ‚ÄúInstall‚Äù.\n\nUna volta completate le installazioni, siete pronti per creare il vostro primo Jupyter Notebook in VS Code.\n\nSi apre Visual Studio Code.\nSi clicca su File &gt; New File.\nSi preme Ctrl+Shift+P per aprire la Palette dei Comandi.\nSi digita ‚ÄúJupyter‚Äù e si seleziona Jupyter: Create New Blank Notebook.\nSi aprir√† un nuovo notebook dove si pu√≤ iniziare a scrivere il codice Python nelle celle.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html",
    "href": "chapters/python/01_python_1.html",
    "title": "3¬† Python (1)",
    "section": "",
    "text": "3.1 Scrivere Codice con il Supporto dei LLM\nI Large Language Models (LLM), come GPT-4, stanno rivoluzionando non solo molte applicazioni legate alla creazione di testi in linguaggio naturale, ma stanno anche aprendo nuove e interessanti potenzialit√† nel campo della programmazione e dell‚Äôanalisi dei dati. La programmazione, con le sue regole esplicite e la sintassi strutturata, si adatta particolarmente bene alle capacit√† di riconoscimento dei pattern degli LLM. A differenza dei linguaggi umani, ricchi di significati ambigui ed espressioni idiomatiche, i linguaggi di programmazione sono rigorosi e precisi.\nNel contesto dell‚Äôanalisi dei dati, √® naturale unire le capacit√† degli LLM con la potenza computazionale dei linguaggi statistici come R o di programmazione come Python. Sono gi√† stati pubblicati libri su come integrare le capacit√† degli LLM con l‚Äôanalisi dei dati Matter (2025), e sta emergendo una nuova branca dell‚Äôingegneria dedicata allo sviluppo dei prompt pi√π efficaci per l‚Äôuso con gli LLM. Pertanto, il problema non √® se utilizzare gli LLM a supporto della programmazione, ma come farlo nel modo pi√π efficace.\nUn principio fondamentale √® che, maggiore √® la conoscenza delle regole sintattiche di un linguaggio di programmazione, maggiore sar√† l‚Äôefficacia dell‚Äôuso degli LLM per scopi di analisi dei dati. Quindi, anche se i problemi di programmazione richiesti in questo corso di analisi dei dati sono relativamente semplici rispetto alle capacit√† degli LLM, gli utenti che utilizzeranno gli LLM a supporto delle proprie attivit√† di programmazione trarranno certamente beneficio dalla conoscenza delle regole sintattiche del linguaggio di programmazione utilizzato, che nel nostro caso sar√† principalmente Python (esamineremo anche degli esempi in R).\nGli LLM si basano sul concetto di ‚Äúpredizione del prossimo token‚Äù. Questo significa che sono addestrati per prevedere la parola o il carattere successivo in una sequenza, basandosi su quelli precedenti. Questo principio √® fondamentale per la capacit√† degli LLM di generare codice e per il loro utilizzo nel migliorare i flussi di lavoro di analisi dei dati in Python o R. Oltre a miliardi di parole provenienti da testi comuni (siti web, libri, articoli di riviste), gli LLM di OpenAI, come GPT-4, sono stati addestrati su un vasto corpus di codice open-source e discussioni sul codice presenti su piattaforme come Stack Overflow. Questo consente loro di generare codice sintatticamente e semanticamente corretto in molte situazioni.\nGli LLM possono assistere in diversi compiti di programmazione in Python e R, tra cui l‚Äôidentificazione degli errori negli script, la scrittura di codice a partire da descrizioni in linguaggio naturale, l‚Äôottimizzazione del codice, la generazione di documentazione e la creazione di casi di test.\nAcquisire conoscenze sull‚Äôuso pratico dell‚ÄôAI/LLM nelle attivit√† di programmazione e analisi √® pi√π di una tendenza: √® una necessit√† nel mercato del lavoro attuale. I professionisti che possono utilizzare efficacemente l‚ÄôAI/LLM per migliorare le loro competenze di programmazione e integrare questi strumenti in Python e R avranno un vantaggio competitivo. Man mano che l‚ÄôAI e gli LLM diventano sempre pi√π diffusi nell‚Äôindustria e nel mondo accademico, la domanda per queste competenze continuer√† a crescere.\nL‚Äôobiettivo di questo capitolo √® fornire una panoramica della sintassi di Python e delle principali funzioni di pacchetti come Pandas, Numpy e Matplotlib, utili per la data science. Python √® un linguaggio di programmazione versatile e di facile lettura, adatto a numerosi usi. Anche se il suo nome √® un omaggio al gruppo comico Monty Python, apprendere Python richiede tempo, pratica e impegno.\nQuesta guida si concentra sull‚Äôinsegnamento dei principi di base della programmazione, piuttosto che sui dettagli tecnici. Con questa conoscenza, gli studenti saranno pi√π capaci di risolvere problemi specifici e di cercare autonomamente la sintassi appropriata per il problema da risolvere.\nNel mondo attuale, in cui l‚Äôintelligenza artificiale riveste un ruolo sempre pi√π centrale, √® fondamentale sviluppare la capacit√† di pensare in modo algoritmico. Questa competenza va oltre la mera programmazione e offre un approccio strutturato per risolvere problemi complessi. Sebbene gli LLM siano in grado di risolvere molti dei problemi di programmazione che affronteremo in questo corso, una comprensione approfondita dei principi della programmazione rimane essenziale per interpretare, modificare o migliorare le soluzioni proposte da tali sistemi.\nIn conclusione, anche nell‚Äôera dell‚ÄôIA, una solida comprensione dei fondamenti della programmazione √® indispensabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#espressioni-e-operatori",
    "href": "chapters/python/01_python_1.html#espressioni-e-operatori",
    "title": "3¬† Python (1)",
    "section": "3.2 Espressioni e Operatori",
    "text": "3.2 Espressioni e Operatori\nI programmi sono insiemi di espressioni che elaborano dati per fornire istruzioni specifiche al computer. Ad esempio, in Python, l‚Äôoperazione di moltiplicazione si esegue utilizzando l‚Äôasterisco (*) tra due numeri. Quando si incontra un‚Äôespressione come 3 * 4, il computer la valuta e produce il risultato, che pu√≤ essere visualizzato in una cella successiva di un notebook Jupyter.\nLe regole sintattiche in un linguaggio di programmazione come Python sono stringenti. Ad esempio, non √® consentito inserire due simboli asterisco in sequenza senza un operando intermedio. Qualora un‚Äôespressione violi queste norme sintattiche, il sistema ritorner√† un ‚ÄúSyntaxError‚Äù, un errore che indica la non conformit√† alle regole del linguaggio. Per esempio\n3 * * 4\nrestituisce:\n Cell In[3], line 1\n    3 * * 4\n        ^\nSyntaxError: invalid syntax\nAnche piccole modifiche in un‚Äôespressione possono cambiarne completamente il significato. Nell‚Äôesempio successivo, lo spazio tra i due asterischi * √® stato rimosso. Tuttavia, poich√© gli asterischi compaiono tra due espressioni numeriche, l‚Äôespressione √® corretta e indica l‚Äôelevamento a potenza del primo numero al secondo: 3 elevato alla quarta potenza (\\(3 \\times 3 \\times 3 \\times 3\\)). In programmazione, simboli come * e ** sono noti come ‚Äúoperatori‚Äù, mentre i valori su cui agiscono sono denominati ‚Äúoperandi‚Äù.\n\n3 ** 4\n\n81\n\n\nLa tabella seguente elenca i principali operatori binari utilizzati in Python, chiamati cos√¨ perch√© agiscono su due operandi.\n\n\n\nOperazione\nOperatore\n\n\n\n\naddizione\n+\n\n\nsottrazione\n-\n\n\nmoltiplicazione\n*\n\n\ndivisione (reale)\n/\n\n\ndivisione (intera; rimuove il resto)\n//\n\n\nresto (modulo)\n%\n\n\nelevamento a potenza\n**\n\n\n\nLe due operazioni che potrebbero essere meno familiari sono % (trova il resto di una divisione) e // (esegui una divisione scartando il resto).\nPer esempio, la divisione intera (scartando il resto) di 11/2 produce 5.\n\n11 // 2\n\n5\n\n\nIl resto di 11/2 √® 1.\n\n11 % 2\n\n1\n\n\nUsando gli operatori che abbiamo elencato in precedenza possiamo usare Python come un calcolatore.\n\nprint(\"4 + 2 √®\", 4 + 2)\nprint(\"4 - 2 √®\", 4 - 2)\nprint(\"4 * 2 √®\", 4 * 2)\nprint(\"4 / 2 √®\", 4 / 2)\nprint(\"4 ** 2 √®\", 4**2)\nprint(\"9 % 4 √®\", 9 % 4)\nprint(\"9 // 4 √®\", 9 // 4)\n\n4 + 2 √® 6\n4 - 2 √® 2\n4 * 2 √® 8\n4 / 2 √® 2.0\n4 ** 2 √® 16\n9 % 4 √® 1\n9 // 4 √® 2\n\n\nL‚Äôapplicazione degli operatori aritmetici in Python dipende dalle seguenti regole di precedenza degli operatori, che sono analoghe a quelle usate in algebra.\n\nLe espressioni tra parentesi vengono valutate per prime.\nSuccessivamente si valutano gli elevamenti a potenza.\nIn seguito, si valutano moltiplicazioni, divisioni e moduli.\nPer ultime vengono valutate somme e sottrazioni.\n\n\n1 + 2 * 3 * 4 * 5 / 6 ** 3 + 7 + 8 - 9 + 10\n\n17.555555555555557\n\n\n\n1 + 2 * (3 * 4 * 5 / 6) ** 3 + 7 + 8 - 9 + 10\n\n2017.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#variabili",
    "href": "chapters/python/01_python_1.html#variabili",
    "title": "3¬† Python (1)",
    "section": "3.3 Variabili",
    "text": "3.3 Variabili\nQuando generiamo un risultato, la risposta viene visualizzata ma non viene memorizzata da nessuna parte, come abbiamo visto negli esempi precedenti. Se vogliamo recuperare quel risultato, dobbiamo memorizzarlo. Lo mettiamo in un oggetto, e diamo un nome a quell‚Äôoggetto. Questa √® una variabile.\nPer creare una variabile facciamo uso di un‚Äôistruzione di assegnazione. In un‚Äôistruzione di assegnazione, si specifica un nome seguito dal simbolo di uguale (=) e dall‚Äôespressione che si desidera assegnare a tale nome. L‚Äôoperazione di assegnazione consiste nell‚Äôassociare il valore dell‚Äôespressione a destra del simbolo di uguale al nome a sinistra. Da quel momento in poi, ogni volta che il nome viene utilizzato in un‚Äôespressione, il valore associato durante l‚Äôassegnazione viene utilizzato al suo posto.\n\na = 10\nb = 20\na + b\n\n30\n\n\n\na = 1/4\nb = 2 * a\nb\n\n0.5\n\n\n\nmy_var = 100\nconst = 3\n\nmy_var * const\n\n300\n\n\nIn Python, ogni ‚Äúoggetto‚Äù √® un‚Äôarea di memoria nel computer. Una ‚Äúvariabile‚Äù funge da etichetta che fa riferimento a quest‚Äôarea. Se un oggetto non ha pi√π etichette (ovvero, non ci sono pi√π variabili che lo referenziano), i dati contenuti nell‚Äôoggetto diventano inaccessibili. Il Garbage Collector del linguaggio si occuper√† di rilevare questi oggetti non referenziati e liberare la memoria, permettendo che venga riutilizzata per nuovi dati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#nomi-delle-variabili",
    "href": "chapters/python/01_python_1.html#nomi-delle-variabili",
    "title": "3¬† Python (1)",
    "section": "3.4 Nomi delle Variabili",
    "text": "3.4 Nomi delle Variabili\nI nomi delle variabili in Python possono contenere caratteri alfanumerici da a-z, A-Z, 0-9 e alcuni caratteri speciali come _. I nomi delle variabili normali devono iniziare con una lettera. I nomi delle variabili non possono contenere uno spazio; invece, √® comune utilizzare il carattere _ per sostituire ogni spazio. Sta al programmatore scegliere nomi facili da interpretare.\nPer convenzione, i nomi delle variabili iniziano con una lettera minuscola, mentre i nomi delle classi iniziano con una lettera maiuscola.\nInoltre, ci sono una serie di parole chiave (keyword) in Python che non possono essere utilizzate come nomi di variabili. Queste parole chiave sono:\n\nimport keyword\nprint(*keyword.kwlist, sep=\"\\n\")\n\nFalse\nNone\nTrue\nand\nas\nassert\nasync\nawait\nbreak\nclass\ncontinue\ndef\ndel\nelif\nelse\nexcept\nfinally\nfor\nfrom\nglobal\nif\nimport\nin\nis\nlambda\nnonlocal\nnot\nor\npass\nraise\nreturn\ntry\nwhile\nwith\nyield\n\n\nSi presti attenzione alla parola chiave ‚Äúlambda‚Äù, che potrebbe facilmente essere un nome di variabile naturale in un programma scientifico. Tuttavia, essendo una parola chiave, non pu√≤ essere utilizzata come nome di variabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#tipologie-di-dati-in-python",
    "href": "chapters/python/01_python_1.html#tipologie-di-dati-in-python",
    "title": "3¬† Python (1)",
    "section": "3.5 Tipologie di Dati in Python",
    "text": "3.5 Tipologie di Dati in Python\nIn Python, le variabili possono appartenere a diverse tipologie di dati, ciascuna con caratteristiche e utilizzi specifici.\n\n3.5.1 Stringhe (String)\nLe stringhe sono sequenze di caratteri, utilizzate per rappresentare testo. In Python, le stringhe possono essere create utilizzando apici singoli (' '), doppi (\" \") o tripli (''' ''' oppure \"\"\" \"\"\") per delimitare il testo. Esempi di stringhe sono:\n\"Hello, world!\"\n'Beyonce-Lemonade.txt'\n\"lemonade\"\nSi noti il risultato ottenuto quando si applica l‚Äôoperatore + a due stringhe.\n\n\"data\" + \"science\"\n\n'datascience'\n\n\n\n\"data\" + \" \" + \"science\"\n\n'data science'\n\n\nSia le virgolette singole che doppie possono essere utilizzate per creare le stringhe: ‚Äúciao‚Äù e ‚Äòciao‚Äô sono espressioni equivalenti. Tuttavia, le virgolette doppie sono spesso preferite poich√© consentono di includere virgolette singole all‚Äôinterno delle stringhe.\n\n\"Che cos'√® una parola?\"\n\n\"Che cos'√® una parola?\"\n\n\nL‚Äôespressione precedente avrebbe prodotto un SyntaxError se fosse stata racchiusa da virgolette singole.\n\n3.5.1.1 Parsing strings\nIn Python, una stringa √® concepita come una sequenza ordinata di caratteri. Grazie all‚Äôoperatore di indicizzazione, rappresentato dalle parentesi quadre [], √® possibile accedere a singoli elementi della stringa.\n√à importante ricordare che l‚Äôindicizzazione in Python parte da zero.\nL‚Äôindice del primo carattere √® [0], quello del secondo √® [1], del terzo [2], e cos√¨ via. Questa funzionalit√† consente di manipolare o consultare specifici segmenti della stringa, piuttosto che gestirla come un blocco unico.\nConsideriamo questo verso di Eugenio Montale:\n\nmy_string = \"Tendono alla chiarit√† le cose oscure\"\nprint(my_string)\n\nTendono alla chiarit√† le cose oscure\n\n\n\nmy_string[0]\n\n'T'\n\n\n\nmy_string[3]\n\n'd'\n\n\n\nlen(my_string)\n\n36\n\n\nLa stringa ‚Äúmy_string‚Äù conta 36 caratteri. Pertanto, gli indici validi per questa stringa vanno da 0 a 35. Per accedere all‚Äôultimo carattere, √® necessario utilizzare l‚Äôindice 35, che corrisponde a 36 meno 1.\n\nmy_string[35]\n\n'e'\n\n\nUn modo efficiente per ottenere l‚Äôultimo carattere √® ricorrere alla funzione len, sottraendo 1 al risultato:\n\nmy_string[len(my_string) - 1]\n\n'e'\n\n\nSi noti che len() √® una funzione. Una funzione √® un blocco di codice che esegue un‚Äôoperazione specifica. I programmatori chiamano anche gli input delle funzioni ‚Äúparametri‚Äù o ‚Äúargomenti‚Äù.\nLa funzione len prende un input e restituisce un output. L‚Äôoutput √® la lunghezza di ci√≤ che √® stato passato come input.\n\n\n3.5.1.2 Slicing strings\nOltre a estrarre caratteri individuali da una stringa, Python offre la possibilit√† di selezionare segmenti di testo attraverso la tecnica dello ‚Äúslicing‚Äù. Questo meccanismo √® simile all‚Äôindicizzazione, ma utilizza due indici separati da un carattere a due punti (:). Il primo indice indica la posizione di partenza dello ‚Äúslicing‚Äù nella stringa, mentre il secondo indice segnala il punto in cui terminare l‚Äôestrazione del segmento.\n\nmy_string[2:4]\n\n'nd'\n\n\nSe si omette il primo indice, Python utilizzer√† l‚Äôinizio della stringa; se si omette il secondo, utilizzer√† la fine della stringa.\n\nmy_string[:4]\n\n'Tend'\n\n\n\nmy_string[4:]\n\n'ono alla chiarit√† le cose oscure'\n\n\n\n\n3.5.1.3 Metodi\nA partire da una stringa esistente, si possono generare nuove stringhe mediante l‚Äôutilizzo di metodi specifici per le stringhe. Questi metodi sono essenzialmente funzioni che agiscono direttamente sull‚Äôoggetto stringa. Per invocare un metodo, basta posizionare un punto subito dopo la stringa e seguire con il nome del metodo desiderato. Ad esempio, il metodo successivo converte tutti i caratteri della stringa in maiuscole.\n\nmy_string.upper()\n\n'TENDONO ALLA CHIARIT√Ä LE COSE OSCURE'\n\n\nIl metodo my_string.title() √® utilizzato per convertire la prima lettera di ogni parola nella stringa my_string in maiuscolo, mentre rende tutte le altre lettere minuscole. In pratica, trasforma la stringa in una forma ‚Äúa titolo‚Äù, in cui ogni parola inizia con una lettera maiuscola.\n\nmy_string.title()\n\n'Tendono Alla Chiarit√† Le Cose Oscure'\n\n\n\n\n\n3.5.2 Numeri Interi (Integer)\nI numeri interi rappresentano numeri senza una componente decimale. In Python, possono essere creati assegnando un valore senza parte decimale a una variabile. Esempio di un numero intero √®:\n\nage = 20\n\n\n\n3.5.3 Numeri in Virgola Mobile (Float)\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, rappresentano numeri che hanno una componente decimale. Sono creati assegnando un valore con una parte decimale a una variabile. Esempio di un numero float √®:\n\ntemperature = 36.4\n\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, hanno una precisione limitata a circa 15-16 cifre decimali; oltre questo limite, la precisione viene persa. Nonostante questa limitazione, sono sufficienti per la maggior parte delle applicazioni.\nInoltre, √® possibile utilizzare la notazione scientifica per rappresentare numeri molto grandi o molto piccoli. In questa notazione, m * 10^n viene comunemente abbreviato come mEn, dove ‚ÄúE‚Äù rappresenta l‚Äôesponente dieci. Ad esempio, 1E9 equivale a un miliardo (\\(1 \\times 10^9\\)) e 1E-9 rappresenta un miliardesimo (\\(1 \\times 10^{-9}\\)).\n\n\n3.5.4 Valori Booleani (Boolean)\nI valori booleani possono assumere solo due stati: vero (True) o falso (False). Sono utilizzati per rappresentare le condizioni logiche e sono ottenuti attraverso espressioni di confronto. Esempio di un valore booleano √®:\n\nis_raining = False\n\nNel contesto delle operazioni aritmetiche, True √® equivalente al numero intero 1, mentre False corrisponde a 0. Questo permette di includere valori booleani in calcoli matematici. Per esempio:\n\nTrue + True + False\n\n2\n\n\nUn valore booleano viene ritornato quando si valuta un confronto. Per esempio:\n\n3 &gt; 1 + 1\n\nIl valore True indica che il confronto √® valido; Python ha confermato questo semplice fatto sulla relazione tra 3 e 1+1.\nSi noti la regola di precedenza: gli operatori &gt;, &lt;, &gt;=, &lt;=, ==, != hanno la precedenza pi√π bassa (vengono valutati per ultimi), il che significa che nell‚Äôespressione precedente viene prima valutato (1 + 1) e poi (3 &gt; 2).\n\n\n3.5.5 Operatori di confronto\nUn operatore di confronto √® un operatore che esegue un qualche tipo di confronto e restituisce un valore booleano (True oppure False). Per esempio, l‚Äôoperatore == confronta le espressioni su entrambi i lati e restituisce True se hanno gli stessi valori e False altrimenti. L‚Äôopposto di == √® !=, che si pu√≤ leggere come ‚Äònon uguale al valore di‚Äô. Gli operatori di confronto sono elencati qui sotto:\n\n\n\nConfronto\nOperatore\n\n\n\n\nMinore\n&lt;\n\n\nMaggiore\n&gt;\n\n\nMinore o uguale\n&lt;=\n\n\nMaggiore o uguale\n&gt;=\n\n\nUguale\n==\n\n\nNon uguale\n!=\n\n\n\nAd esempio:\n\na = 4\nb = 2\n\nprint(\"a &gt; b\", \"is\", a &gt; b)\nprint(\"a &lt; b\", \"is\", a &lt; b)\nprint(\"a == b\", \"is\", a == b)\nprint(\"a &gt;= b\", \"is\", a &gt;= b)\nprint(\"a &lt;= b\", \"is\", a &lt;= b)\n\nNella cella seguente si presti attenzione all‚Äôuso di = e di ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nL‚Äôoperatore = √® un‚Äôistruzione di assegnazione. Ovvero, crea un nuovo oggetto. L‚Äôoperatore == valuta invece una condizione logica e ritorna un valore booleano.\nUn‚Äôespressione pu√≤ contenere pi√π confronti e tutti devono essere veri affinch√© l‚Äôintera espressione sia vera. Ad esempio:\n\n1 &lt; 1 + 1 &lt; 3\n\n\n\n3.5.6 Tipizzazione Dinamica in Python\nPython √® un linguaggio con tipizzazione dinamica, il che significa che il tipo di una variabile √® determinato dal valore che le viene assegnato durante l‚Äôesecuzione del programma e non necessita di essere dichiarato esplicitamente.\nPer identificare il tipo di una variabile o del risultato di un‚Äôespressione, Python mette a disposizione la funzione type(). Questa funzione, quando chiamata con una variabile o un‚Äôespressione come argomento, restituisce il tipo di dati corrispondente.\nNell‚Äôesempio seguente il programma stamper√† &lt;class 'str'&gt;, indicando che x √® una variabile di tipo ‚Äústringa‚Äù.\n\nx = \"hello\"\nprint(type(x))\n\n&lt;class 'str'&gt;\n\n\nApplichiamo la funzione type() alle altre variabili che abbiamo definito in precedenza.\n\nage = 20\nprint(type(age))\n\n&lt;class 'int'&gt;\n\n\n\ntemperature = 36.4\nprint(type(temperature))\n\n&lt;class 'float'&gt;\n\n\n\nis_raining = False\nprint(type(is_raining))\n\n&lt;class 'bool'&gt;\n\n\n\n\n3.5.7 Operatori Booleani\nGli operatori booleani (o operatori logici) confrontano espressioni (non valori) e ritornano un valore booleano. Python ha tre operatori logici:\n\nand ‚Äì Ritorna True solo se entrambi le espressioni sono vere, altrimenti ritorna False\nor ‚Äì Ritorna True se almeno una delle due espressioni √® vera, altrimenti ritorna False.\nnot ‚Äì Ritorna True se l‚Äôespressione √® falsa, altrimenti ritorna False.\n\nAd esempio:\n\na = 2\nb = 3\n\n(a + b &gt; a) and (a + b &gt; b)\n\nTrue\n\n\nNella cella sopra le parentesi tonde sono opzionali ma facilitano la lettura.\nL‚Äôoperatore and restituisce True solo se entrambe le condizioni booleane sono vere. Ad esempio, True and False restituir√† False perch√© una delle condizioni √® falsa:\n\nTrue and False\n\nFalse\n\n\nL‚Äôoperatore or restituisce True se almeno una delle due condizioni booleane √® vera. Ad esempio, True or False restituir√† True perch√© almeno una delle condizioni √® vera.\n\nTrue or False\n\nTrue\n\n\nL‚Äôoperatore not viene utilizzato per invertire il valore di verit√† di una condizione booleana. Ad esempio, not True restituir√† False e not False restituir√† True.\n\nnot True\n\nFalse\n\n\nAlcuni esempi sono i seguenti (si noti l‚Äôuso della funzione len()):\n\nprint(3 &gt; 2)  # True, because 3 is greater than 2\nprint(3 &gt;= 2)  # True, because 3 is greater than 2\nprint(3 &lt; 2)  # False,  because 3 is greater than 2\nprint(2 &lt; 3)  # True, because 2 is less than 3\nprint(2 &lt;= 3)  # True, because 2 is less than 3\nprint(3 == 2)  # False, because 3 is not equal to 2\nprint(3 != 2)  # True, because 3 is not equal to 2\nprint(len(\"mango\") == len(\"avocado\"))  # False\nprint(len(\"mango\") != len(\"avocado\"))  # True\nprint(len(\"mango\") &lt; len(\"avocado\"))  # True\nprint(len(\"milk\") != len(\"meat\"))  # False\nprint(len(\"milk\") == len(\"meat\"))  # True\nprint(len(\"tomato\") == len(\"potato\"))  # True\nprint(len(\"python\") &gt; len(\"dragon\"))  # False\n\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\nAltri esempi di come questi operatori possono essere utilizzati sono i seguenti:\n\nprint(3 &gt; 2 and 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 and 4 &lt; 3)  # False - because the second statement is false\nprint(3 &lt; 2 and 4 &lt; 3)  # False - because both statements are false\nprint(\"True and True: \", True and True)\nprint(3 &gt; 2 or 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 or 4 &lt; 3)  # True - because one of the statements is true\nprint(3 &lt; 2 or 4 &lt; 3)  # False - because both statements are false\nprint(\"True or False:\", True or False)\nprint(not 3 &gt; 2)  # False - because 3 &gt; 2 is true, then not True gives False\nprint(not True)  # False - Negation, the not operator turns true to false\nprint(not False)  # True\nprint(not not True)  # True\nprint(not not False)  # False\n\nTrue\nFalse\nFalse\nTrue and True:  True\nTrue\nTrue\nFalse\nTrue or False: True\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\nAbbiamo tralasciato alcuni operatori in Python. Due di quelli che abbiamo omesso sono gli operatori di appartenenza, in e not in. Gli altri operatori che abbiamo tralasciato sono gli operatori bitwise e gli operatori sugli insiemi, che verranno trattati in seguito.\n\n\n3.5.8 Valori Numerici di True e False\n√à fondamentale comprendere i valori numerici associati alle parole chiave True e False. Queste due parole chiave hanno i valori numerici di 1 e 0, rispettivamente.\n\nTrue == 1\n\nTrue\n\n\n\nFalse == 0\n\nTrue\n\n\n\nTrue + False\n\n1\n\n\n\ntype(True + False)\n\nint",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#sequenze",
    "href": "chapters/python/01_python_1.html#sequenze",
    "title": "3¬† Python (1)",
    "section": "3.6 Sequenze",
    "text": "3.6 Sequenze\nOltre ai numeri e ai valori booleani, Python supporta anche un insieme di ‚Äúcontenitori‚Äù, ovvero i seguenti tipi strutturati:\n\nle liste,\nle tuple,\ngli insiemi,\ni dizionari.\n\n\n3.6.1 Le tuple\nUna tupla √® una collezione di diversi tipi di dati che √® ordinata e immutabile (non modificabile). Le tuple sono scritte tra parentesi tonde, (). Una volta creata una tupla, non √® possibile modificarne i contenuti.\n\ncolors = (\"Rosso\", \"Nero\", \"Bianco\")\ncolors\n\n('Rosso', 'Nero', 'Bianco')\n\n\n\ntype(colors)\n\ntuple\n\n\nLe stringhe sono tuple di caratteri. Pertanto non sono modificabili.\n\n\n3.6.2 Le liste\nGli oggetti di tipo lista sono simili alle tuple, ma con alcune differenze. La lista √® un oggetto mutabile, il che significa che possiamo aggiungere o rimuovere elementi dalla lista anche dopo la sua creazione. Una lista viene creata separando i suoi elementi tramite virgola e racchiudendo il tutto tra parentesi quadre.\nSi noti che una lista √® una struttura dati eterogenea contentente una sequenza di elementi che possono essere di tipo diverso.\n\nmy_list = [\"Pippo\", 3, -2.953, [1, 2, 3]]\nmy_list\n\n['Pippo', 3, -2.953, [1, 2, 3]]\n\n\n\ntype(my_list)\n\nlist\n\n\nLa lista my_list √® composta da diversi elementi: una stringa (‚ÄúPippo‚Äù), un numero intero (3), un numero decimale (-2.953) e un‚Äôaltra lista ([1, 2, 3]).\nGli elementi nella lista sono ordinati in base all‚Äôindice, il quale rappresenta la loro posizione all‚Äôinterno della lista. Gli indici delle liste partono da 0 e aumentano di uno. Per accedere a un elemento della lista tramite il suo indice, si utilizza la notazione delle parentesi quadre: nome_lista[indice]. Ad esempio:\n\nmy_list[1]\n\n3\n\n\n\nmy_list[0]\n\n'Pippo'\n\n\nPython prevede alcune funzioni che elaborano liste, come per esempio len che restituisce il numero di elementi contenuti in una lista:\n\nlen(my_list)\n\n4\n\n\nBench√© questa lista contenga come elemento un‚Äôaltra lista, tale lista nidificata conta comunque come un singolo elemento. La lunghezza di di my_list √® quattro.\nUna lista vuota si crea nel modo seguente:\n\nempty_list = []\nlen(empty_list)\n\n0\n\n\nEcco alcuni esempi.\n\nfruits = [\"banana\", \"orange\", \"mango\", \"lemon\"]  # list of fruits\nvegetables = [\"Tomato\", \"Potato\", \"Cabbage\", \"Onion\", \"Carrot\"]  # list of vegetables\n\nprint(\"Fruits:\", fruits)\nprint(\"Number of fruits:\", len(fruits))\nprint(\"Vegetables:\", vegetables)\nprint(\"Number of vegetables:\", len(vegetables))\n\nFruits: ['banana', 'orange', 'mango', 'lemon']\nNumber of fruits: 4\nVegetables: ['Tomato', 'Potato', 'Cabbage', 'Onion', 'Carrot']\nNumber of vegetables: 5\n\n\nSupponiamo di voler ordinare in ordine alfabetico i nomi presenti nella lista. Per fare ci√≤, √® necessario utilizzare il metodo sort sulla lista utilizzando la notazione con il punto (dot notation):\n\nnames = [\"Carlo\", \"Giovanni\", \"Giacomo\"]\nnames.sort()\n\nTale metodo per√≤ non restituisce alcun valore, in quanto l‚Äôordinamento √® eseguito in place: dopo l‚Äôinvocazione, gli elementi della lista saranno stati riposizionati nell‚Äôordine richiesto. Visualizziamo la listra trasformata:\n\nnames\n\n['Carlo', 'Giacomo', 'Giovanni']\n\n\nL‚Äôinvocazione di metodi (e di funzioni) prevede anche la possibilit√† di specificare degli argomenti opzionali. Per esempio:\n\nnames.sort(reverse=True)\nnames\n\n['Giovanni', 'Giacomo', 'Carlo']\n\n\nIl metodo remove() pu√≤ essere usato per rimuovere elementi da una lista.\n\nprint(fruits)\nfruits.remove(\"banana\")\nprint(fruits)\n\n['banana', 'orange', 'mango', 'lemon']\n['orange', 'mango', 'lemon']\n\n\nIl metodo insert() pu√≤ essere usato per aggiungere elementi ad una lista.\n\nprint(fruits)\nfruits.insert(2, \"watermelon\")\nprint(fruits)\n\n['orange', 'mango', 'lemon']\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n√à possibile copiare una lista in una nuova variabile:\n\nprint(fruits)\nnew_fruits = fruits.copy()\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\nprint(new_fruits)\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\n\n3.6.3 Operazioni su liste\nL‚Äôoperatore + concatena liste:\n\na = [1, 2, 3]\nb = [4, 5, 6]\nc = a + b\nprint(c)\n\n[1, 2, 3, 4, 5, 6]\n\n\nIn maniera simile, l‚Äôoperatore * ripete una lista un certo numero di volte:\n\n[0] * 4\n\n[0, 0, 0, 0]\n\n\n\n[1, 2, 3] * 3\n\n[1, 2, 3, 1, 2, 3, 1, 2, 3]\n\n\nL‚Äôaspetto importante da considerare √® che, essendo una sequenza di elementi eterogenei, √® difficile eseguire operazioni algebriche sulle liste in Python puro. Ad esempio, consideriamo la seguente lista:\n\nx = [1, 2, 3]\nx\n\n[1, 2, 3]\n\n\nSe desideriamo calcolare una semplice operazione, come la media di x, √® necessario seguire una procedura abbastanza articolata. Ad esempio:\n\ntotal = 0\ncounter = 0\n\nfor num in x:\n    counter += 1\n    total += num\n\navg = total / counter\n\nprint(avg)\n\n2.0\n\n\nIndubbiamente, sarebbe preferibile ottenere questo risultato con un approccio pi√π semplice. In seguito, vedremo che se utilizziamo una sequenza di elementi omogenei, il problema pu√≤ essere risolto in modo molto pi√π agevole. Ad esempio,\n\nimport numpy as np\n\nx = np.array([1, 2, 3])\nnp.mean(x)\n\n2.0\n\n\nPossiamo contare il numero degli elementi specificati che sono contenuti in una lista usando count().\n\nages = [22, 19, 24, 25, 26, 24, 25, 24]\nprint(ages.count(24))         \n\n3\n\n\nPossiamo trovare l‚Äôindice di un elemento in una lista con index().\n\nages.index(24)  # index of the first occurrence\n\n2\n\n\n\n\n3.6.4 Operatore slice\nL‚Äôoperatore di slice (:) applicato alle liste in Python consente di estrarre una porzione specifica di elementi dalla lista. L‚Äôoperatore di slice ha la seguente sintassi: lista[inizio:fine:passo].\n\ninizio rappresenta l‚Äôindice di partenza dell‚Äôintervallo (inclusivo).\nfine rappresenta l‚Äôindice di fine dell‚Äôintervallo (esclusivo).\npasso rappresenta il passo o l‚Äôincremento tra gli indici degli elementi selezionati (facoltativo).\n\nEcco alcuni esempi per illustrare l‚Äôutilizzo dell‚Äôoperatore di slice:\n\nlista = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# Estrarre una porzione della lista\nporzione = lista[2:6]  # [3, 4, 5, 6]\n\n# Estrarre una porzione con un passo specifico\nporzione_passo = lista[1:9:2]  # [2, 4, 6, 8]\n\n# Estrarre una porzione dalla fine della lista\nporzione_fine = lista[6:]  # [7, 8, 9, 10]\n\n# Estrarre una porzione dall'inizio della lista\nporzione_inizio = lista[:5]  # [1, 2, 3, 4, 5]\n\n\n\n3.6.5 Gli insiemi\nGli insiemi sono collezioni finite di elementi distinti e non memorizzati in un ordine specifico. Un insieme non pu√≤ contenere pi√π di un‚Äôistanza dello stesso elemento. Per creare un insieme si utilizzano le parentesi graffe {}. Ad esempio:\n\nmy_set = {\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"}\nmy_set\n\n{'A', 'B', 'C', 'D', 'E', 'F'}\n\n\n\ntype(my_set)\n\nset\n\n\nGli oggetti di tipo ‚Äúset‚Äù sono utili per eseguire operazioni matematiche sugli insiemi.\nPer verificare se un elemento esiste in un insieme usiamo l‚Äôoperatore in.\n\nprint(\"Does set my_set contain D? \", \"D\" in my_set)\n\nDoes set my_set contain D?  True\n\n\nL‚Äôunione di due insieme si ottiene con union().\n\nfruits = {\"banana\", \"orange\", \"mango\", \"lemon\"}\nvegetables = {\"tomato\", \"potato\", \"cabbage\", \"onion\", \"carrot\"}\nprint(fruits.union(vegetables))\n\n{'carrot', 'onion', 'lemon', 'mango', 'tomato', 'potato', 'banana', 'cabbage', 'orange'}\n\n\nL‚Äôintersezione di due insieme si trova con intersection().\n\npython = {\"p\", \"y\", \"t\", \"h\", \"o\", \"n\"}\ndragon = {\"d\", \"r\", \"a\", \"g\", \"o\", \"n\"}\npython.intersection(dragon)\n\n{'n', 'o'}\n\n\nUn insieme pu√≤ essere un sottoinsieme o un sovrainsieme di altri insiemi.\nPer verificare se un insieme √® un sottoinsieme di un altro, si utilizza il metodo issubset(). Per verificare se un insieme √® un sovrainsieme di un altro, si utilizza il metodo issuperset().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.issubset(st1)\n\nTrue\n\n\n\nst1.issuperset(st2) \n\nTrue\n\n\nLa differenza tra due insiemi si ottiene con difference().\n\nwhole_numbers = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\neven_numbers = {0, 2, 4, 6, 8, 10}\nwhole_numbers.difference(even_numbers)\n\n{1, 3, 5, 7, 9}\n\n\nPossiamo verificare se due insiemi sono disgiunti, ovvero non hanno elementi in comune, utilizzando il metodo isdisjoint().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.isdisjoint(st1)\n\nFalse\n\n\n\n\n3.6.6 I dizionari\nGli oggetti di tipo ‚Äúdizionario‚Äù vengono utilizzati per creare coppie chiave-valore, dove ogni chiave √® unica. Un dizionario viene creato specificando ogni coppia come chiave : valore, separando le diverse coppie con una virgola e racchiudendo il tutto tra parentesi graffe. Ad esempio:\n\nmusic = {\n    \"blues\": \"Betty Smith\",\n    \"classical\": \"Gustav Mahler\",\n    \"pop\": \"David Bowie\",\n    \"jazz\": \"John Coltrane\",\n}\n\nL‚Äôaccesso agli elementi di un dizionario viene fatto specificando all‚Äôinterno di parentesi quadre la chiave per ottenere o modificare il valore corrispondente:\n\nmusic[\"pop\"]\n\n'David Bowie'\n\n\nPer trovare il numero di coppie key: value nel dizionario usiamo len().\n\nprint(len(music))\n\n4\n\n\n\nmusic[\"new music\"] = \"Missy Mazzoli\"\nprint(music)\n\n{'blues': 'Betty Smith', 'classical': 'Gustav Mahler', 'pop': 'David Bowie', 'jazz': 'John Coltrane', 'new music': 'Missy Mazzoli'}\n\n\n\n\n3.6.7 Contenitori vuoti\nA volte √® utile creare dei contenitori vuoti. I comandi per creare liste vuote, tuple vuote, dizionari vuoti e insiemi vuoti sono rispettivamente lst = [], tup=(), dic={} e st = set().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "3¬† Python (1)",
    "section": "3.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "3.7 Informazioni sull‚ÄôAmbiente di Sviluppo\nAlla fine di ogni capitolo e, in effetti, alla fine (o all‚Äôinizio) di qualsiasi notebook che creiamo, √® utile includere informazioni sull‚Äôambiente di calcolo, compresi i numeri di versione di tutti i pacchetti che utilizziamo. Il pacchetto watermark pu√≤ essere usato per questo scopo. Il pacchetto watermark contiene comandi speciali ed √® un‚Äôestensione di IPython. In generale, per utilizzare tali comandi speciali, li precediamo con il segno % o %% in una cella. Utilizziamo la funzione speciale built-in %load_ext per caricare watermark, e quindi utilizziamo %watermark per invocarlo.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 24 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\nEcco una spiegazione dettagliata delle opzioni che sono state utilizzate nell‚Äôistruzione precedente.\n\n-n o --datename: Aggiunge la data e l‚Äôora correnti al watermark. Questo pu√≤ essere utile per mantenere una cronologia delle modifiche o delle esecuzioni del notebook.\n-u o --updated: Mostra l‚Äôultima volta in cui il notebook √® stato salvato. √à utile per tenere traccia delle modifiche recenti apportate al notebook.\n-v o --python: Mostra la versione di Python utilizzata nel kernel del notebook. Questo √® importante per garantire la compatibilit√† del codice e replicare gli ambienti di lavoro.\n-iv o --iversions: Visualizza le versioni delle librerie importate nel notebook. √à fondamentale per la replicabilit√† degli esperimenti e degli analisi, dato che diverse versioni delle librerie possono comportare risultati diversi.\n-w o --watermark: Aggiunge il watermark stesso, che √® semplicemente il logo ‚Äúwatermark‚Äù. √à pi√π una questione estetica che funzionale.\n-m o --machine: Fornisce informazioni sulla macchina su cui viene eseguito il Jupyter Notebook, come il tipo di sistema operativo e l‚Äôarchitettura della macchina (ad esempio, x86_64). Questo pu√≤ essere utile per documentare l‚Äôambiente hardware in cui vengono eseguiti gli esperimenti.\n\nQueste opzioni forniscono un modo semplice e immediato per documentare e tracciare importanti metadati nei notebook Jupyter.\n\n\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and R. 1st Edition. New York, NY: Manning Publications.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html",
    "href": "chapters/python/02_python_2.html",
    "title": "4¬† Python (2)",
    "section": "",
    "text": "4.1 Funzioni\nLo scopo delle funzioni √® raggruppare il codice in un formato organizzato, leggibile e riutilizzabile, contribuendo cos√¨ a ridurre la ridondanza del codice.\nUna regola generale per le funzioni √® che dovrebbero essere di piccole dimensioni e svolgere un‚Äôunica operazione.\nNella programmazione, una funzione accetta un input, esegue operazioni su di esso e pu√≤ restituire un output. Python mette a disposizione un‚Äôampia gamma di funzioni integrate, e si pu√≤ anche importare funzioni da pacchetti aggiuntivi o definirne di nuove.\nPer definire una nuova funzione in Python, si utilizza la parola chiave def, seguita dal nome della funzione e dai nomi simbolici dei suoi argomenti, separati da virgole e racchiusi tra parentesi. La definizione continua con i due punti (:) e il corpo della funzione, le cui istruzioni devono essere indentate. Il valore restituito dalla funzione viene specificato tramite la parola chiave return, generalmente nella riga finale del corpo della funzione.\ndef add_numbers(a, b):\n    \"\"\"\n    returns the sum of the two numeric arguments\n    \"\"\"\n    the_sum = a + b\n    return the_sum\nUna volta definita una funzione, √® possibile eseguirla chiamandola e passando gli argomenti appropriati. Ad esempio, possiamo chiamare la funzione add_numbers per sommare due numeri, come ad esempio 20 e 10:\nadd_numbers(20, 10)\n\n30\nConsideriamo la funzione roll_die():\nimport random\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return random.choice([1, 2, 3, 4, 5, 6])\nIl corpo della funzione √® composto da una singola riga di codice che utilizza la funzione choice() della libreria random, a cui viene passata una lista. Questo significa che una funzione pu√≤ utilizzare altre funzioni che sono gi√† state definite. In questo caso, la funzione si limita a specificare l‚Äôargomento da passare a choice(). La funzione choice() restituir√† un numero casuale tra quelli specificati in input. Pertanto, la funzione roll_die() simula il lancio di un dado:\nroll_die()\n\n6\nroll_die()\n\n5\nSi noti inoltre la docstring, cio√® una stringa (in genere racchiusa tra ‚Äú‚Äú‚Äú‚Ä¶‚Äù‚Äú‚Äú) che si trova come prima istruzione all‚Äôinterno di una funzione. La docstring contiene informazioni sullo scopo e sulle modalit√† d‚Äôuso della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#funzioni",
    "href": "chapters/python/02_python_2.html#funzioni",
    "title": "4¬† Python (2)",
    "section": "",
    "text": "4.1.1 Introspection\nUsando un punto interrogativo (?) prima o dopo una variabile √® possibile visualizzare alcune informazioni generale su quell‚Äôoggetto. Nel caso di una funzione viene stampata la doc string.\n\nroll_die?\n\nSignature: roll_die()\nDocstring: returns a random int between 1 and 6\nFile:      /var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_13125/63164766.py\nType:      function\n\n\n\n\n4.1.2 Metodi\nLe funzioni definite all‚Äôinterno di una classe, chiamate ‚Äúmetodi‚Äù, rappresentano operazioni specifiche che possono essere eseguite sugli oggetti di quella classe. Una classe √® una struttura concettuale che rappresenta un concetto o un oggetto nel contesto del problema che stiamo affrontando. Ad esempio, nel capitolo sull‚Äôintroduzione a Pandas, lavorando con dati organizzati in una tabella, utilizziamo un oggetto chiamato DataFrame, appartenente alla classe ‚Äúpandas.DataFrame‚Äù. Un DataFrame √® una struttura tabellare che contiene dati disposti in righe e colonne.\nI metodi specifici della classe DataFrame offrono funzionalit√† per manipolare e analizzare i dati in questa struttura. Per esempio, il metodo ‚Äúhist()‚Äù genera istogrammi dei valori presenti in una colonna specifica del DataFrame. Per invocare un metodo su un oggetto DataFrame, come ‚Äúdf‚Äù, utilizziamo la sintassi ‚Äúnome_oggetto.nome_metodo()‚Äù e possiamo passare eventuali parametri richiesti tra parentesi.\nD‚Äôaltra parte, gli attributi rappresentano le caratteristiche o le propriet√† degli oggetti di una classe. Gli attributi possono essere richiamati utilizzando la sintassi ‚Äúnome_oggetto.nome_attributo‚Äù e restituiscono un valore specifico associato a quell‚Äôoggetto. Per esempio, l‚Äôattributo ‚Äú.shape‚Äù applicato a un DataFrame come ‚Äúdf.shape‚Äù restituisce il numero di righe e colonne presenti nel DataFrame.\nIn sintesi, una classe definisce un tipo di oggetto che ha attributi che ne descrivono le caratteristiche e metodi che rappresentano le azioni eseguibili su di esso. Gli attributi forniscono informazioni specifiche sull‚Äôoggetto, mentre i metodi consentono di effettuare operazioni e manipolazioni sui dati contenuti nell‚Äôoggetto stesso.\n\n\n4.1.3 La funzione lambda\nPython offre una sintassi alternativa che consente di definire funzioni ‚Äúinline‚Äù, cio√® in una singola linea di codice. Queste funzioni, chiamate funzioni anonime, non richiedono una definizione esplicita poich√© vengono utilizzate solo nel punto in cui sono dichiarate. Per creare una funzione anonima, utilizziamo la parola chiave lambda, seguita da un elenco di argomenti separati da virgole, due punti ‚Äú:‚Äù e l‚Äôespressione che definisce il comportamento della funzione basandosi sugli argomenti forniti.\nlambda argomento1, argomento2, ... : espressione\nQuesta sintassi permette di creare funzioni semplici ed espressive in modo conciso.\nNell‚Äôesempio seguente, la funzione somma 1 al valore passato come input:\n\n(lambda x : x + 1)(2)\n\n3\n\n\nQuando eseguiamo (lambda x : x + 1)(2), avviene quanto segue:\n\nL‚Äôinterprete Python definisce la funzione lambda lambda x : x + 1.\nLa funzione lambda viene immediatamente chiamata con l‚Äôargomento 2.\nAll‚Äôinterno della funzione lambda, x viene sostituito da 2, quindi l‚Äôespressione x + 1 diventa 2 + 1.\nLa funzione lambda restituisce 3.\n\nQuindi, il risultato dell‚Äôespressione (lambda x : x + 1)(2) √® 3.\nIn sintesi, la funzione lambda (lambda x : x + 1) definisce una funzione che aggiunge 1 al suo argomento. Quando la chiamiamo con l‚Äôargomento 2, otteniamo 3 come risultato.\nIn questo secondo esempio sommiamo i due numeri in entrata:\n\n(lambda x, y: x + y)(2, 3)\n\n5\n\n\nLa sintassi seguente √® valida in quanto, per l‚Äôinterprete, il carattere _ corrisponde all‚Äôultima funzione che √® stata valutata:\n\nlambda x, y: x + y\n\n&lt;function __main__.&lt;lambda&gt;(x, y)&gt;\n\n\n\n_(20, 10)\n\n30\n\n\nSi noti che abbiamo valutato la funzione lambda x, y: x + y in una cella precedente a quella che contiene _(20, 10); inserendo le due espressioni in una singola cella si ottiene un SyntaxError.\n\n\n4.1.4 Le funzioni map() e filter()\nPer gli esercizi che svolgeremo in seguito, risultano utili le funzioni map() e filter().\nLa funzione map() prende come input una funzione e una lista, e restituisce il risultato dell‚Äôapplicazione della funzione a ciascun elemento della lista (√® anche possibile usare qualsiasi oggetto iterabile al posto della lista). La lista stessa rimane invariata. Ad esempio, la seguente linea di codice eleva al quadrato ciascuno degli elementi della lista a e salva il risultato nella lista b:\n\na = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nb = list(map(lambda x: x * x, a))\nb\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n\n\nUn‚Äôaltra funzione molto utile per manipolare gli oggetti iterabili √® la funzione filter(). Questa funzione filtra un oggetto iterabile selezionando solo gli elementi che rispondono ad un determinato predicato. (Il predicato √® una funzione che restituisce un booleano). Per esempio\n\nc = list(filter(lambda x: x &gt; 50, b))\nc\n\n[64, 81, 100]\n\n\nSia map() che filter() restituiscono risultati che non sono ancora stati calcolati.\n\nfilter(lambda x: x &gt; 50, b)\n\n&lt;filter at 0x171da9720&gt;\n\n\nPossiamo visualizzare il risultato convertendolo in una lista:\n\nlist(filter(lambda x: x &gt; 50, b))\n\n[64, 81, 100]\n\n\n\n\n4.1.5 La funzione zip()\nLa funzione zip() crea una lista di tuple dagli elementi di due contenitori. Come nel caso delle operazioni precedenti, gli elementi vengono calcolati solo quando viene richiesto. Per esempio:\n\na = list(range(4))\na\n\n[0, 1, 2, 3]\n\n\n\nb = list(range(4, 8))\nb\n\n[4, 5, 6, 7]\n\n\n\nb = zip(a, b)\nb\n\n&lt;zip at 0x172034f80&gt;\n\n\n\nlist(b)\n\n[(0, 4), (1, 5), (2, 6), (3, 7)]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#il-flusso-di-esecuzione",
    "href": "chapters/python/02_python_2.html#il-flusso-di-esecuzione",
    "title": "4¬† Python (2)",
    "section": "4.2 Il flusso di esecuzione",
    "text": "4.2 Il flusso di esecuzione\nIn Python il codice viene eseguito sequenzialmente, partendo dalla prima riga fino a quando non c‚Äô√® pi√π nulla da eseguire. L‚Äôordine di esecuzione delle varie istruzioni √® detto flusso di esecuzione.\nPer esempio la cella seguente prima memorizza la lista names, poi la lista born e infine la lista dead.\n\nnames = [\"Sigmund Freud\", \"Jean Piaget\", \"Burrhus Frederic Skinner\", \"Albert Bandura\"]\nborn = [1856, 1896, 1904, 1925]\ndead = [1939, 1980, 1990, None]\n\nHo usato il valore speciale None in quanto non risulta disponibile l‚Äôanno. In queste situazioni si parla di valori mancanti (missing values) che, di norma, vengono indicati con la sigla NA (not available).\nLa cella seguente include le istruzioni condizionali che specificano se e quando devono essere eseguiti determinati blocchi di codice. La pi√π semplice istruzione di controllo √® l‚Äôistruzione if. Per esempio:\n\nname = \"Maria\"\ngrade = 29\n\nif name == \"Maria\" and grade &gt; 28:\n    print(\"Maria, hai ottenuto un ottimo voto all'esame!\")\n\nif name == \"Giovanna\" or grade &gt; 28:\n    print(\n        \"Tu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\"\n    )\n\nif name != \"Giovanna\" and grade &gt; 28:\n    print(\"Tu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\")\n\nMaria, hai ottenuto un ottimo voto all'esame!\nTu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\nTu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\n\n\nTutte e tre le condizioni precedenti ritornano True, quindi vengono stampati tutti e tre i messaggi.\nSi noti che == e != confrontano valori, mentre is e not confrontano oggetti. Per esempio,\n\nname_list = [\"Maria\", \"Giovanna\"]\nname_list_two = [\"Marco\", \"Francesco\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nFalse\nFalse\n\n\nUna delle parole chiave condizionali pi√π utili √® in. Un esempio √® il seguente:\n\nname_list = [\"Maria\", \"Giovanna\", \"Marco\", \"Francesco\"]\n\nprint(\"Giovanna\" in name_list)\nprint(\"Luca\" in name_list)\n\nTrue\nFalse\n\n\nLa condizione opposta √® not in.\n\nprint(\"Luca\" not in name_list)\n\nTrue\n\n\nFacciamo un altro esempio.\n\nage = 26\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\n\nSei maggiorenne\n\n\nPython dispone di un‚Äôespressione ternaria che introduce la potenza dell‚Äôistruzione ‚Äòelse‚Äô in una sintassi concisa:\n\nage = 26\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei maggiorenne\n\n\n\nage = 16\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei minorenne\n\n\nUna struttura di selezione leggermente pi√π complessa √® ‚Äúif-else‚Äù. La sintassi di questa struttura √® la seguente:\nif &lt;condizione&gt;:\n    &lt;istruzione_se_condizione_vera&gt;\nelse:\n    &lt;istruzione_se_condizione_falsa&gt;\nLa semantica di ‚Äúif-else‚Äù √® quella che ci si aspetta: la condizione tra la parola chiave if e il carattere di due punti viene valutata: se risulta vera viene eseguita l‚Äôistruzione alla linea seguente, altrimenti viene eseguita l‚Äôistruzione dopo la parola chiave else. Anche in questo caso l‚Äôindentazione permette di identificare quali istruzioni devono essere eseguite nei due rami della selezione. Per esempio:\n\nage = 16\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\nelse:\n    print(\"Sei minorenne\")\n\nSei minorenne\n\n\nIn presenza di pi√π di due possibilit√† mutuamente esclusive ed esaustive possiamo usare l‚Äôistruzione elif. Per esempio:\n\ncfu = 36\nthesis_defense = False\n\nif cfu &gt;= 180 and thesis_defense == True:\n    print(\"Puoi andare a festeggiare!\")\nelif cfu &gt;= 180 and thesis_defense == False:\n    print(\"Devi ancora superare la prova finale!\")\nelse:\n    print(\"Ripassa tra qualche anno!\")\n\nRipassa tra qualche anno!\n\n\n\n4.2.1 Commenti\nIn Python √® possibile usare il carattere # per aggiungere commenti al codice. Ogni riga di commento deve essere preceduta da un #. I commenti non devono spiegare il metodo (cosa fa il codice: quello si vede), ma bens√¨ lo scopo: quello che noi intendiamo ottenere. I primi destinatari dei commenti siamo noi stessi tra un po‚Äô di tempo, ovvero quando ci saremo dimenticati cosa avevamo in mente quando abbiamo scritto il codice.\n\n# This is a comment and will not be executed.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#cicli",
    "href": "chapters/python/02_python_2.html#cicli",
    "title": "4¬† Python (2)",
    "section": "4.3 Cicli",
    "text": "4.3 Cicli\nUn ciclo √® un modo per eseguire una porzione di codice pi√π di una volta. I cicli sono fondamentali nei linguaggi di programmazione. Come molti altri linguaggi di programmazione, Python ha due tipi di cicli per gestire tutte le proprie necessit√† di iterazione: il ciclo ‚Äúwhile‚Äù e il ciclo ‚Äúfor‚Äù.\n\n4.3.1 Il ciclo while\nil ciclo while permette l‚Äôesecuzione di un blocco di codice finch√© una determinata condizione √® True. Per esempio:\n\ncounter = 0\n\nwhile counter &lt;= 10:\n    print(counter)\n    counter += 1\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nIl codice counter += 1 √® equivalente a counter = counter + 1 e, ogni qualvolta viene eseguito il ciclo, riassegna alla variabile counter il valore che aveva in precedenza + 1.\nL‚Äôistruzione while controlla se alla variabile counter √® associato un valore minore o uguale a 10. Nel primo passo del ciclo la condizione √® soddisfatta, avendo noi definito counter = 0, pertanto il programma entra nel loop, stampa il valore della variabile counter e incrementa counter di un‚Äôunit√†.\nQuesto comportamento si ripete finch√© la condizione counter &lt;= 10 risulta True. Quando il contatore counter assume il valore 11 il ciclo while si interrompe e il blocco di codice del ciclo non viene pi√π eseguito.\n\n\n4.3.2 Il ciclo for\nIl ciclo for √® un costrutto di controllo di flusso che viene utilizzato per iterare su una sequenza di valori, come ad esempio una lista, una tupla, una stringa o un dizionario.\nLa sintassi generale di un ciclo for in Python √® la seguente:\nfor element in sequence:\n    # codice da eseguire\nDove element √® una variabile temporanea che assume il valore di ciascun elemento della sequenza ad ogni iterazione del ciclo, e sequence √® la sequenza di valori su cui iterare.\nDurante l‚Äôesecuzione del ciclo, il blocco di codice indentato sotto la linea for viene eseguito una volta per ogni elemento della sequenza. Ad ogni iterazione, la variabile elemento assume il valore dell‚Äôelemento corrente della sequenza e il codice all‚Äôinterno del blocco viene eseguito con questo valore.\nIl ciclo for √® spesso utilizzato per eseguire operazioni su ciascun elemento di una sequenza, come ad esempio la somma degli elementi di una lista o la stampa di ciascun carattere di una stringa. Per esempio\n\nnumbers = [0, 1, 2, 3, 4, 5]\nfor number in numbers: # number is temporary name to refer to the list's items, valid only inside this loop\n    print(number)\n\n0\n1\n2\n3\n4\n5\n\n\n\nlanguage = \"Python\"\nfor letter in language:\n    print(letter)\n\nP\ny\nt\nh\no\nn\n\n\nLa funzione range() √® spesso usata nei cicli for e permette di impostare un intervallo di esecuzione tanto ampio quanto il numero che le passiamo come parametro meno uno.\nLa funzione range() prende tre parametri: start (default 0), stop e step (default 1), ovvero un punto di inizio dell‚Äôintervallo, un punto di fine e un passo di avanzamento. L‚Äôindicizzazione Python parte da 0; quindi range(0, 11, 1) una lista di 11 elementi, da 0 a 10 inclusi.\n\nprint(list(range(0, 11, 1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nAd esempio, impostiamo un punto di inizio a 3, il punto di fine a 11 e un passo di 2:\n\nprint(list(range(3, 12, 2)))\n\n[3, 5, 7, 9, 11]\n\n\nIn un ciclo for, l‚Äôintervallo di range() corrisponde al numero di iterazioni che verranno eseguite, ovvero al numero di volte che il ciclo verr√† processato. Nel caso seguente, l‚Äôindice del ciclo (qui chiamato number) assume il valore 0 la prima volta che il ciclo viene eseguito e il valore 10 nell‚Äôultima esecuzione del ciclo.\n\nfor number in range(11):\n    print(number)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nfor number in range(3, 12, 2):\n    print(number)\n\n3\n5\n7\n9\n11\n\n\n\n4.3.2.1 Cicli for annidati\nSono possibili i cicli for annidati, vale a dire un ciclo posto all‚Äôinterno del corpo di un altro (chiamato ciclo esterno). Al suo primo passo, il ciclo esterno mette in esecuzione quello interno che esegue il proprio blocco di codice fino alla conclusione. Quindi, al secondo passo, il ciclo esterno rimette in esecuzione quello interno. Questo si ripete finch√© il ciclo esterno non termina. Per esempio:\n\nfor i in range(4):\n    for j in range(4):\n        print((i, j))\n\n(0, 0)\n(0, 1)\n(0, 2)\n(0, 3)\n(1, 0)\n(1, 1)\n(1, 2)\n(1, 3)\n(2, 0)\n(2, 1)\n(2, 2)\n(2, 3)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)\n\n\n\n\n4.3.2.2 Modificare gli elementi di una lista\nIl ciclo for √® il modo pi√π comune per scorrere gli elementi di una lista, come abbiamo visto in precedenza.\n\nfor name in name_list:\n    print(name)\n\nMaria\nGiovanna\nMarco\nFrancesco\n\n\nQuesto approccio pu√≤ essere usato se abbiamo solo bisogno di leggere gli elementi della lista. Nel ciclo seguente, ad esempio, leggiamo gli elementi d una lista per incrementare una variabile cos√¨ da calcolare una somma.\n\nnumbers = [2, -4, 1, 6, 3]\n\ntotal = 0\nfor num in numbers:\n    total += num\n\nprint(total)\n\n8\n\n\nMa se vogliamo cambiare gli elementi di una lista l‚Äôapproccio precedente non funziona e dobbiamo usare gli indici. Nell‚Äôesempio seguente, questo risultato viene ottenuto utilizzando le funzioni range e len:\n\nnumbers = [2, -4, 1, 6, 3]\n\nfor i in range(len(numbers)):\n    numbers[i] = numbers[i] * 2\n\nprint(numbers)\n\n[4, -8, 2, 12, 6]\n\n\nNel codice seguente, la funzione len() ritorna 5.\n\nnumbers = [2, -4, 1, 6, 3]\nlen(numbers)\n\n5\n\n\nQuindi, range(5) produce la seguente sequenza iterabile:\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]\n\n\nQuesti sono gli indici che verranno usati nelle iterazioni del ciclo for.\n\nLa prima volta che il ciclo viene eseguito, l‚Äôindice i vale 0 e numbers[i] si riferisce al primo elemento della lista;\nla seconda volta che il ciclo viene eseguito, i vale 1 e numbers[i] si riferisce al secondo elemento della lista;\ne cos√¨ via.\n\nL‚Äôistruzione di assegnazione nel corpo del ciclo for usa i per leggere il valore i-esimo della lista originale (a destra dell‚Äôuguale) e per assegnargli un nuovo valore (a sinistra dell‚Äôuguale).\n\n\n\n4.3.3 List comprehension\nUna list comprehension √® un modo conciso di creare una lista. √à un modo compatto per creare una nuova lista. Accade speso di dover creare una lista dove ciascun elemento √® il risultato di un‚Äôoperazione condotta sugli elementi di un‚Äôaltra lista o di un iterabile; oppure, di dover estrarre gli elementi che soddisfano una certa condizione. Per esempio, supponiamo di volere sommare una costante ad una lista di numeri. Usando un ciclo for possiamo procedere nel modo seguente (si noti l‚Äôuso della funzione append):\n\nnew_list = []\nk = 10\nfor x in range(10):\n    new_list.append(x + k)\n\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nOppure, in maniera pi√π semplice, possiamo usare una list comprehension:\n\nnew_list = [x + k for x in range(10)]\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nUna list comprehension √® racchiusa tra parentesi quadre; contiene un‚Äôespressione, seguita da una clausola for, seguita da zero o pi√π clausole for o if. La sintassi √® la seguente:\n[ &lt;expression&gt; for item in iterable &lt;if optional_condition&gt; ]\nIl risultato √® una nuova lista costruita valutando l‚Äôespressione nel contesto delle clausole for e if che la seguono. Una list comprehension combina dunque un ciclo for e (se necessario) una o pi√π condizioni logiche in una singola riga di codice. Esaminiamo una variante dell‚Äôesempio precedente.\n\nlist1 = [1, 2, 3, 4, 5, 6]\nprint(\"list1:\", list1)\n\nlist1: [1, 2, 3, 4, 5, 6]\n\n\n\nlist2 = [item + 1 for item in list1]\nprint(\"list2:\", list2)\n\nlist2: [2, 3, 4, 5, 6, 7]\n\n\nSi noti che la parola item avrebbe potuto essere quasi qualsiasi stringa (in precedenza abbiamo usato x). La possiamo immaginare con la seguente definizione: ...per ogni elemento in .... Nel seguente esempio, sommiamo 1 agli elementi di list1 solo se sono pari:\n\nlist3 = [item + 1 for item in list1 if item % 2 == 0] \nprint('list3:', list3)\n\nlist3: [3, 5, 7]\n\n\nFacciamo un altro esempio usando range():\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nQui selezioniamo solo i numeri pari (oltre allo zero):\n\n[i for i in range(11) if i % 2 == 0]\n\n[0, 2, 4, 6, 8, 10]\n\n\nSpecificando una condizione, possiamo cambiare il segno solo dei numeri dispari nella lista:\n\n[-i if i % 2 else i for i in range(11)]\n\n[0, -1, 2, -3, 4, -5, 6, -7, 8, -9, 10]\n\n\nPossiamo anche eseguire pi√π iterazioni simultaneamente:\n\n[(i, j) for i in range(3) for j in range(4)]\n\n[(0, 0),\n (0, 1),\n (0, 2),\n (0, 3),\n (1, 0),\n (1, 1),\n (1, 2),\n (1, 3),\n (2, 0),\n (2, 1),\n (2, 2),\n (2, 3)]\n\n\nIn questo esempio vengono selezionati solo i nomi inclusi nella lista female_names:\n\nfirst_names = [\"Maria\", \"Marco\", \"Francesco\", \"Giovanna\"]\nfemale_names = [\"Alice\", \"Maria\", \"Giovanna\", \"Lisa\"]\nfemale_list = [name for name in first_names if name in female_names]\nprint(female_list)\n\n['Maria', 'Giovanna']\n\n\nNel seguente esempio vengono estratte le prime tre lettere di ciascuno dei nomi che compongono una lista:\n\nletters = [name[0:3] for name in first_names] \nletters\n\n['Mar', 'Mar', 'Fra', 'Gio']\n\n\nPer estrarre l‚Äôultimo carattere di una stringa usiamo [-1]:\n\nmy_string = \"barbabl√π\"\nmy_string[-1]\n\n'√π'\n\n\nPossiamo dunque usare seguente list comprehension estrae gli ultimi tre caratteri di ciascun elemento della lista first_names.\n\nletters = [name[-3:] for name in first_names] \nletters\n\n['ria', 'rco', 'sco', 'nna']\n\n\n√à possibile impiegare un‚Äôespressione ternaria all‚Äôinterno di una list comprehension per sfruttare la versatilit√† dell‚Äôistruzione ‚Äòelse‚Äô in modo sintatticamente efficace. Ad esempio, possiamo sostituire tutti i numeri dispari di una lista (un un NumPy array) con il valore 99.\n\nnum = np.array([4, 7, 2, 6, 3, 9])  # pu√≤ anche essere una lista Python\n[e if e % 2 == 0 else 99 for e in num]\n\n[4, 99, 2, 6, 99, 99]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#librerie-e-moduli",
    "href": "chapters/python/02_python_2.html#librerie-e-moduli",
    "title": "4¬† Python (2)",
    "section": "4.4 Librerie e moduli",
    "text": "4.4 Librerie e moduli\n\n4.4.1 Importare moduli\nI moduli (anche conosciuti come librerie in altri linguaggi) sono dei file usati per raggruppare funzioni e altri oggetti. Python include una lista estensiva di moduli standard (anche conosciuti come Standard Library), ma √® anche possibile scaricarne o definirne di nuovi. Prima di potere utilizzare le funzioni non presenti nella Standard Library all‚Äôinterno dei nostri programmi dobbiamo importare dei moduli aggiuntivi, e per fare ci√≤ usiamo il comando import.\nL‚Äôimportazione pu√≤ riguardare un intero modulo oppure solo uno (o pi√π) dei suoi elementi. Consideriamo per esempio la funzione mean. Essa √® disponibile nel modulo numpy. L‚Äôistruzione import numpy importa tutto il modulo numpy. Dopo che un modulo √® stato importato, √® possibile accedere a un suo generico elemento usando il nome del modulo, seguito da un punto e dal nome dell‚Äôelemento in questione. Ad esempio, numpy.mean().\nIndicare il nome di un modulo per poter accedere ai suoi elementi ha spesso l‚Äôeffetto di allungare il codice, diminuendone al contempo la leggibilit√†. √à per questo motivo che √® possibile importare un modulo specificando un nome alternativo, pi√π corto. √à quello che succede quando scriviamo l‚Äôistruzione import numpy as np. In questo caso, l‚Äôistruzione precedente diventa np.mean().\nI moduli pi√π complessi sono organizzati in strutture gerarchiche chiamate package. La seguente cella importa il modulo pyplot che √® contenuto nel package matplotlib (matplotlib √® la libreria di riferimento in Python per la creazione di grafici).\n\nimport matplotlib.pyplot as plt\n\nQui di seguito sono descritte tutte le possibilit√†:\n\n# import everything from library\nimport random\n# call function by\nrandom.random()\n\n0.16777284588756924\n\n\n\n#import everything, but change name\nimport random as rnd\n# call function by\nrnd.random()\n\n0.05690270000491682\n\n\n\n# select what to import from library\nfrom random import random\n#call function by\nrandom()\n\n0.037974565142151695\n\n\n\n# import everything from library\nfrom random import *\n# call function by\nrandom()\n\n0.20988431417194764\n\n\nNella cella seguente importiamo seaborn con il nome sns e usiamo le sue funzionalit√† per impostare uno stile e una palette di colori per la visualizzazione dei grafici.\n\nimport seaborn as sns\nsns.set_theme()\nsns.set_palette(\"colorblind\")\n\nNell‚Äôesempio seguente calcoliamo la somma degli elementi della lista numerica primes usando funzione sum() contenuta nella libreria NumPy che abbiamo importato con il nome di np:\n\nimport numpy as np\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nnp.sum(primes)\n\n42\n\n\nCalcolo la media di primes:\n\nnp.mean(primes)\n\n6.0\n\n\nScriviamo una nuova funzione per la media, \\(\\bar{x} = n^{-1}\\sum_{i=1}^n x_i\\):\n\ndef my_mean(x):\n    res = np.sum(x) / len(x)\n    return res\n\n\nmy_mean(primes)\n\n6.0\n\n\nSi noti che, nel corpo di una funzione, √® possibile usare altre funzioni: qui, np.sum() e len().\n√à sempre possibile usare la funzione di help su una funzione:\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n    \n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nIn Visual Studio Code √® sufficiente posizionare il cursore sul nome della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#formattazione-del-codice",
    "href": "chapters/python/02_python_2.html#formattazione-del-codice",
    "title": "4¬† Python (2)",
    "section": "4.5 Formattazione del codice",
    "text": "4.5 Formattazione del codice\n\nanczcbx ../images/code_quality_2x.png :align: center",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "4¬† Python (2)",
    "section": "4.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "4.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.1.4\nnumpy     : 1.26.2\nseaborn   : 0.13.0\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html",
    "href": "chapters/python/03_numpy.html",
    "title": "5¬† NumPy",
    "section": "",
    "text": "5.1 Preparazione del Notebook\nimport numpy as np",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "href": "chapters/python/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "title": "5¬† NumPy",
    "section": "5.2 Utilizzo degli Array nel Modulo NumPy",
    "text": "5.2 Utilizzo degli Array nel Modulo NumPy\nIn Python standard, abbiamo a disposizione tipi di dati numerici (come numeri interi e decimali) e strutture come liste, dizionari e insiemi. NumPy, d‚Äôaltro canto, introduce un nuovo tipo di struttura dati: l‚Äôarray N-dimensionale, noto come ndarray. Questi array hanno alcune caratteristiche distintive:\n\nDimensioni: Gli ndarray possono variare nel numero di dimensioni, definite come ‚Äúassi‚Äù. Ad esempio, un array pu√≤ essere unidimensionale (simile a un vettore lineare), bidimensionale (come una matrice o una tabella), tridimensionale (simile a un cubo), e cos√¨ via.\nTipo di Dato: A differenza delle liste in Python standard che possono contenere diversi tipi di dati, ogni elemento all‚Äôinterno di un ndarray deve essere dello stesso tipo, come numeri interi, decimali, booleani o stringhe.\nForma: La ‚Äúforma‚Äù di un ndarray si riferisce alle sue dimensioni, ovvero quante righe, colonne o altri livelli di profondit√† ha. Per esempio, la forma (3, 4) indica un array con 3 righe e 4 colonne.\nIndicizzazione: Gli ndarray possono essere indicizzati in modo simile agli array standard di Python, ma offrono anche opzioni pi√π avanzate per l‚Äôindicizzazione.\n\nGli ndarray sono potenti per manipolare e analizzare i dati, grazie alle loro funzioni e metodi che includono operazioni matematiche e statistiche, trasformazioni e altre manipolazioni dei dati.\nTerminologia Importante: - Size: Indica il numero totale di elementi in un array. - Rank: Si riferisce al numero di dimensioni, o assi, di un array. - Shape: Denota le dimensioni specifiche dell‚Äôarray, ovvero una sequenza di numeri che rappresentano il conteggio degli elementi in ogni dimensione.\nCome Creare un ndarray: Il modo pi√π diretto per creare un ndarray √® attraverso la conversione di una lista Python. Ad esempio, √® possibile creare un array unidimensionale (1-D) a partire da una lista standard di Python.\n\nx = np.array([1, 2, 3, 4, 5, 6])\n\nL‚Äôistruzione precedente crea un array in NumPy, assegnandolo alla variabile x. Questo array √® un vettore unidimensionale contenente sei elementi, che sono i numeri interi specificati all‚Äôinterno delle parentesi quadre.\n\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nIndicizzazione\nSe vogliamo estrarre un singolo elemento del vettore lo indicizziamo con la sua posizione (si ricordi che l‚Äôindice inizia da 0):\n\nx[0]\n\n1\n\n\n\nx[2]\n\n3\n\n\nUn array 2-D si crea nel modo seguente:\n\ny = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nEstraiamo un singolo elemento dall‚Äôarray:\n\ny[0, 2]\n\n3\n\n\nEstraiamo la seconda riga dall‚Äôarray:\n\ny[1]\n\narray([5, 6, 7, 8])\n\n\nEstraiamo la seconda colonna dall‚Äôarray:\n\ny[:, 1] \n\narray([ 2,  6, 10])\n\n\nLa sintassi con i due punti √® chiamata ‚Äúslicing‚Äù dell‚Äôarray.\n\n# Display the first row of the array\nprint(\"Displaying the first row:\")\nprint(y[0, :])\n\nDisplaying the first row:\n[1 2 3 4]\n\n\n\n# Show the last two elements in the first row\nprint(\"Showing the last two elements in the first row:\")\nprint(y[0, -2:])\n\nShowing the last two elements in the first row:\n[3 4]\n\n\n\n# Retrieve every second element in the first row\nprint(\"Retrieving every second element in the first row:\")\nprint(y[0, ::2])\n\nRetrieving every second element in the first row:\n[1 3]\n\n\n\n# Extract a submatrix from the original array\nprint(\"Extracting a submatrix:\")\nprint(y[:2, 1:3])\n\nExtracting a submatrix:\n[[2 3]\n [6 7]]\n\n\n\n5.2.1 Funzioni per ndarray\nNumpy offre varie funzioni per creare ndarray. Per esempio, √® possibile creare un array 1-D con la funzione .arange(start, stop, incr, dtype=..) che fornisce l‚Äôintervallo di numeri compreso fra start, stop, al passo incr:\n\nz = np.arange(2, 9, 2)\nprint(z)\n\n[2 4 6 8]\n\n\nSi usa spesso .arange per creare sequenze a incrementi unitari:\n\nw = np.arange(11)\nprint(w)\n\n[ 0  1  2  3  4  5  6  7  8  9 10]\n\n\nUn‚Äôaltra funzione molto utile √® .linspace:\n\nx = np.linspace(0, 10, num=20)\nprint(x)\n\n[ 0.          0.52631579  1.05263158  1.57894737  2.10526316  2.63157895\n  3.15789474  3.68421053  4.21052632  4.73684211  5.26315789  5.78947368\n  6.31578947  6.84210526  7.36842105  7.89473684  8.42105263  8.94736842\n  9.47368421 10.        ]\n\n\nFissati gli estremi (qui 0, 10) e il numero di elementi desiderati, .linspace determina in maniera automatica l‚Äôincremento.\nUna propriet√† molto utile dei ndarray √® la possibilit√† di filtrare gli elementi di un array che rispondono come True ad un criterio. Per esempio:\n\nprint(x[x &gt; 7])\n\n[ 7.36842105  7.89473684  8.42105263  8.94736842  9.47368421 10.        ]\n\n\nperch√© solo gli ultimi sei elementi di x rispondono True al criterio \\(x &gt; 7\\).\nLe dimensioni (‚Äúassi‚Äù) di un ndarray vengono ritornate dal metodo .dim. Per esempio:\n\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\ny.ndim\n\n2\n\n\n\nprint(y.max(axis=1))\n\n[ 4  8 12]\n\n\n\nprint(y.max(axis=0))\n\n[ 9 10 11 12]\n\n\nIl numero di elementi per ciascun asse viene ritornato dal metodo .shape:\n\ny.shape\n\n(3, 4)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#manipolazione-di-array-con-numpy",
    "href": "chapters/python/03_numpy.html#manipolazione-di-array-con-numpy",
    "title": "5¬† NumPy",
    "section": "5.3 Manipolazione di Array con NumPy",
    "text": "5.3 Manipolazione di Array con NumPy\nNumPy rende pi√π agevole lavorare con grandi quantit√† di dati. Un concetto fondamentale in NumPy sono gli array monodimensionali, spesso utilizzati per rappresentare vettori, ovvero sequenze di numeri che possono rappresentare, ad esempio, le misurazioni di una variabile specifica. Grazie a NumPy, possiamo eseguire operazioni aritmetiche su questi vettori in modo semplice, applicando la stessa operazione a tutti gli elementi dell‚Äôarray contemporaneamente.\n\n5.3.1 Cosa Significa Vettorizzare un‚ÄôOperazione\nLa vettorizzazione √® una delle funzionalit√† pi√π efficaci di NumPy. Quando diciamo che un‚Äôoperazione √® vettorizzata, significa che questa operazione viene applicata in un colpo solo a tutti gli elementi dell‚Äôarray, invece di dover agire su ciascun elemento individualmente. Questo approccio rende la manipolazione di grandi insiemi di dati non solo pi√π veloce ma anche pi√π intuitiva, poich√© consente di trattare l‚Äôintero insieme di dati come un‚Äôunica entit√† anzich√© come una serie di punti dati individuali.\nSupponiamo di avere raccolto i dati di 4 individui\n\nm = np.array([1.62, 1.75, 1.55, 1.74])\nkg = np.array([55.4, 73.6, 57.1, 59.5])\n\nprint(m)\nprint(kg)\n\n[1.62 1.75 1.55 1.74]\n[55.4 73.6 57.1 59.5]\n\n\ndove m √® l‚Äôarray che contiene i dati relativi all‚Äôaltezza in metri dei quattro individui e kg √® l‚Äôarray che contiene i dati relativi al peso in kg. I dati sono organizzati in modo tale che il primo elemento di entrambi i vettori si riferisce alle misure del primo individuo, il secondo elemento dei due vettori si riferisce alle misure del secondo individuo, ecc.\nSupponiamo di volere calcolare l‚Äôindice BMI:\n\\[\nBMI = \\frac{kg}{m^2}.\n\\]\nPer il primo individuo del campione, l‚Äôindice di massa corporea √®\n\n55.4 / 1.62**2\n\n21.109586953208346\n\n\nSi noti che non abbiamo bisogno di scrivere 55.4 / (1.62**2) in quanto, in Python, l‚Äôelevazione a potenza viene eseguita prima della somma e della divisione (come in tutti i linguaggi). Usando i dati immagazzinati nei due vettori, lo stesso risultato si ottiene nel modo seguente:\n\nkg[0] / m[0]**2\n\n21.109586953208346\n\n\nSe ora non specifichiamo l‚Äôindice (per esempio, [0]), le operazioni aritmetiche indicate verranno eseguite per ciascuna coppia di elementi corrispondenti nei due vettori:\n\nbmi = kg / m**2\n\nOtteniamo cos√¨, con una sola istruzione, l‚Äôindice BMI dei quattro individui:\n\nbmi.round(1)\n\narray([21.1, 24. , 23.8, 19.7])\n\n\nQuesto esempio illustra come le operazioni aritmetiche standard vengano eseguite elemento per elemento negli array, grazie al processo di vettorizzazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#broadcasting",
    "href": "chapters/python/03_numpy.html#broadcasting",
    "title": "5¬† NumPy",
    "section": "5.4 Broadcasting",
    "text": "5.4 Broadcasting\nIl broadcasting √® una caratteristica distintiva di NumPy che facilita l‚Äôesecuzione di operazioni tra array di dimensioni diverse o tra un array e uno scalare, anche se le loro dimensioni non sono direttamente compatibili. Grazie al broadcasting, NumPy √® in grado di ‚Äúespandere‚Äù automaticamente le dimensioni di uno degli operandi per rendere possibile l‚Äôoperazione.\nQuesto significa che possiamo, per esempio, eseguire un‚Äôoperazione tra un array e un numero singolo (un vettore e uno scalare) o tra due array di dimensioni differenti, senza la necessit√† di modificare manualmente le dimensioni di questi array. Il broadcasting si occupa di adattare le dimensioni in modo coerente per consentire l‚Äôoperazione desiderata. Ci√≤ rende il codice pi√π snello e leggibile, eliminando la necessit√† di espandere gli array manualmente.\nIn breve, il broadcasting in NumPy √® un potente strumento che semplifica l‚Äôesecuzione di operazioni su array di dimensioni diverse o tra array e scalari, automatizzando l‚Äôallineamento delle dimensioni.\n\n5.4.1 Esempio di Broadcasting\nImmaginiamo di avere un array A con dimensioni 3x3 e un numero scalare B. Senza broadcasting, dovremmo espandere B in un array 3x3 riempiendo ogni cella con il valore di B per eseguire un‚Äôoperazione come l‚Äôaddizione su ciascun elemento di A. Grazie al broadcasting, possiamo semplicemente scrivere A + B, e NumPy si occuper√† automaticamente di ‚Äúespandere‚Äù B durante l‚Äôoperazione, applicando il valore scalare a ogni elemento di A.\n\n# Creiamo un array 3x3\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Definiamo uno scalare\nB = 5\n\n# Applichiamo il broadcasting per aggiungere lo scalare a ogni elemento dell'array\nC = A + B\n\nprint(C)\n\n[[ 6  7  8]\n [ 9 10 11]\n [12 13 14]]\n\n\nIn questo esempio, C conterr√† l‚Äôarray originale A con ogni elemento incrementato di 5, dimostrando come il broadcasting semplifichi operazioni che altrimenti richiederebbero passaggi aggiuntivi.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#altre-operazioni-sugli-array",
    "href": "chapters/python/03_numpy.html#altre-operazioni-sugli-array",
    "title": "5¬† NumPy",
    "section": "5.5 Altre operazioni sugli array",
    "text": "5.5 Altre operazioni sugli array\nC‚Äô√® un numero enorme di funzioni predefinite in NumPy che calcolano automaticamente diverse quantit√† sugli ndarray. Ad esempio:\n\nmean(): calcola la media di un vettore o matrice;\nsum(): calcola la somma di un vettore o matrice;\nstd(): calcola la deviazione standard;\nmin(): trova il minimo nel vettore o matrice;\nmax(): trova il massimo;\nndim: dimensione del vettore o matrice;\nshape: restituisce una tupla con la ‚Äúforma‚Äù del vettore o matrice;\nsize: restituisce la dimensione totale del vettore (=ndim) o della matrice;\ndtype: scrive il tipo numpy del dato;\nzeros(num): scrive un vettore di num elementi inizializzati a zero;\narange(start,stop,step): genera un intervallo di valori (interi o reali, a seconda dei valori di start, ecc.) intervallati di step. Nota che i dati vengono generati nell‚Äôintervallo aperto [start,stop)!\nlinstep(start,stop,num): genera un intervallo di num valori interi o reali a partire da start fino a stop (incluso!);\nastype(tipo): converte l‚Äôndarray nel tipo specificato\n\nPer esempio:\n\nx = np.array([1, 2, 3])\nprint(x)\n\n[1 2 3]\n\n\n\n[x.min(), x.max(), x.sum(), x.mean(), x.std()]\n\n[1, 3, 6, 2.0, 0.816496580927726]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#lavorare-con-formule-matematiche",
    "href": "chapters/python/03_numpy.html#lavorare-con-formule-matematiche",
    "title": "5¬† NumPy",
    "section": "5.6 Lavorare con formule matematiche",
    "text": "5.6 Lavorare con formule matematiche\nL‚Äôimplementazione delle formule matematiche sugli array √® un processo molto semplice con Numpy. Possiamo prendere ad esempio la formula della deviazione standard che discuteremo nel capitolo {ref}loc-scale-notebook:\n\\[\ns = \\sqrt{\\sum_{i=1}^n\\frac{(x_i - \\bar{x})^2}{n}}\n\\]\nL‚Äôimplementazione su un array NumPy √® la seguente:\n\nprint(x)\n\n[1 2 3]\n\n\n\nnp.sqrt(np.sum((x - np.mean(x)) ** 2) / np.size(x))\n\n0.816496580927726\n\n\nQuesta implementazione funziona nello stesso modo sia che x contenga 3 elementi (come nel caso presente) sia che x contenga migliaia di elementi. √à importante notare l‚Äôutilizzo delle parentesi tonde per specificare l‚Äôordine di esecuzione delle operazioni. In particolare, nel codice fornito, si inizia calcolando la media degli elementi del vettore x per mezzo della funzione np.mean(x). Questa operazione produce uno scalare, ovvero un singolo valore numerico che rappresenta la media degli elementi del vettore. L‚Äôutilizzo delle parentesi tonde √® fondamentale per garantire l‚Äôordine corretto delle operazioni. In questo caso, la funzione np.mean() viene applicata al vettore x prima di qualsiasi altra operazione matematica. Senza le parentesi tonde, le operazioni verrebbero eseguite in un ordine diverso e il risultato potrebbe essere errato.\n\nnp.mean(x)\n\n2.0\n\n\nSuccessivamente, eseguiamo la sottrazione dei singoli elementi del vettore x per la media del vettore stesso, ovvero \\(x_i - \\bar{x}\\), utilizzando il meccanismo del broadcasting.\n\nx - np.mean(x)\n\narray([-1.,  0.,  1.])\n\n\nEleviamo poi al quadrato gli elementi del vettore che abbiamo ottenuto:\n\n(x - np.mean(x)) ** 2\n\narray([1., 0., 1.])\n\n\nSommiamo gli elementi del vettore:\n\nnp.sum((x - np.mean(x)) ** 2)\n\n2.0\n\n\nDividiamo il numero ottenuto per \\(n\\). Questa √® la varianza di \\(x\\):\n\nres = np.sum((x - np.mean(x)) ** 2) / np.size(x)\nres\n\n0.6666666666666666\n\n\nInfine, per ottenere la deviazione standard, prendiamo la radice quadrata:\n\nnp.sqrt(res)\n\n0.816496580927726\n\n\nIl risultato ottenuto coincide con quello che si trova applicando la funzione np.std():\n\nnp.std(x)\n\n0.816496580927726",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#slicing",
    "href": "chapters/python/03_numpy.html#slicing",
    "title": "5¬† NumPy",
    "section": "5.7 Slicing",
    "text": "5.7 Slicing\nPer concludere, spendiamo ancora alcune parole sull‚Äôindicizzazione degli ndarray.\nSlicing in Numpy √® un meccanismo che consente di selezionare una porzione di un array multidimensionale, ovvero una sotto-matrice o un sotto-vettore. Per selezionare una porzione di un array, si utilizza la sintassi [start:stop:step], dove start indica l‚Äôindice di partenza della porzione, stop indica l‚Äôindice di fine e step indica il passo da utilizzare per la selezione. Se uno o pi√π di questi valori vengono omessi, vengono utilizzati dei valori di default.\nAd esempio, se abbiamo un array arr di dimensione (3, 4) e vogliamo selezionare la seconda colonna, possiamo usare la sintassi arr[:, 1]. In questo caso, il simbolo : indica che vogliamo selezionare tutte le righe, mentre il numero 1 indica che vogliamo selezionare la seconda colonna.\nInoltre, possiamo utilizzare il meccanismo di slicing anche per selezionare porzioni di array multidimensionali. Ad esempio, se abbiamo un array arr di dimensione (3, 4, 5) e vogliamo selezionare la prima riga di ciascuna matrice 4x5, possiamo usare la sintassi arr[:, 0, :].\nPer esempio, creiamo l‚Äôarray x di rango 2 con shape (3, 4):\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nUtilizziamo il meccanismo di slicing per estrarre la sottomatrice composta dalle prime 2 righe e dalle colonne 1 e 2. y √® l‚Äôarray risultante di dimensione (2, 2):\n\ny = x[:2, 1:3]\nprint(y)\n\n[[2 3]\n [6 7]]\n\n\n√à importante sapere che uno slice di un array in Numpy √® una vista degli stessi dati, il che significa che modificarlo implica la modifica dell‚Äôarray originale. In pratica, quando si modifica uno slice di un array, si sta modificando direttamente l‚Äôarray originale e tutte le altre visualizzazioni dell‚Äôarray vedranno la stessa modifica. Questo avviene perch√© Numpy √® progettato per gestire enormi quantit√† di dati, pertanto cerca di evitare il pi√π possibile di effettuare copie dei dati.\nQuesto comportamento deve essere preso in considerazione durante la modifica degli array in Numpy, al fine di evitare modifiche accidentali o indesiderate. In alcuni casi, √® possibile utilizzare il metodo copy() per creare una copia indipendente di un array e lavorare sulla copia senza modificare l‚Äôoriginale. Vediamo un esempio.\n\nprint(x[0, 1])   \n\n2\n\n\n\ny[0, 0] = 77     \n\n\nprint(x)\n\n[[ 1 77  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nz = x.copy()\nprint(z)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nz[0, 1] = 33\nprint(z)\n\n[[ 1 33  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#copia-e-copia-profonda-in-python",
    "href": "chapters/python/03_numpy.html#copia-e-copia-profonda-in-python",
    "title": "5¬† NumPy",
    "section": "5.8 Copia e ‚ÄúCopia Profonda‚Äù in Python",
    "text": "5.8 Copia e ‚ÄúCopia Profonda‚Äù in Python\nIn Python, per ottimizzare le prestazioni, le assegnazioni di solito non copiano gli oggetti sottostanti. Questo √® particolarmente importante, ad esempio, quando gli oggetti vengono passati tra funzioni, per evitare una quantit√† eccessiva di copie in memoria quando non sono necessarie (questo approccio √® noto tecnicamente come ‚Äúpassaggio per riferimento‚Äù).\nConsideriamo il seguente esempio con un array A:\n\nA = np.array([[1, 2], [3, 4]])\n\nSe creiamo un nuovo riferimento B a A:\n\nB = A\n\nOra B si riferisce allo stesso insieme di dati di A. Se modifichiamo B, anche A viene modificato di conseguenza:\n\nB[0,0] = 10\n\nDopo questa modifica, sia B che A saranno:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nSe desideriamo evitare questo comportamento, in modo tale che B diventi un oggetto completamente indipendente da A, dobbiamo effettuare una cosiddetta ‚Äúcopia profonda‚Äù utilizzando la funzione copy:\n\nB = np.copy(A)\n\nOra, se modificassimo B, A non subirebbe alcuna modifica. Ad esempio:\n\nB[0,0] = -5\n\nA questo punto, B sar√†:\n\nprint(B)\n\n[[-5  2]\n [ 3  4]]\n\n\nMa A rimarr√† invariato:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nQuesto esempio mostra chiaramente la differenza tra una semplice assegnazione, che crea un riferimento all‚Äôoggetto originale, e una ‚Äúcopia profonda‚Äù, che crea un nuovo oggetto indipendente.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "title": "5¬† NumPy",
    "section": "5.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "5.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy: 1.26.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html",
    "href": "chapters/python/04_pandas.html",
    "title": "6¬† Pandas (1)",
    "section": "",
    "text": "6.1 Preparazione del NoteBook\nimport pandas as pd\nimport numpy as np\n\n# Di default, Pandas mostrer√† 60 righe e 20 colonne. \n# Modifichiamo qui le impostazioni di visualizzazione predefinite di Pandas per mostrare pi√π righe.\npd.options.display.max_rows = 100",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#series",
    "href": "chapters/python/04_pandas.html#series",
    "title": "6¬† Pandas (1)",
    "section": "6.2 Series",
    "text": "6.2 Series\nIn Pandas, una Series √® un array unidimensionale composto da una sequenza di valori omogenei, simile ad un ndarray, accompagnato da un array di etichette chiamato ‚Äúindex‚Äù. A differenza degli indici degli array Numpy, che sono sempre interi e partono da zero, gli oggetti Series supportano etichette personalizzate che possono essere, ad esempio, delle stringhe. Inoltre, gli oggetti Series possono contenere dati mancanti che vengono ignorati da molte delle operazioni della classe.\nIl modo pi√π semplice di creare un oggetto Series √® di convertire una lista. Per esempio:\n\ngrades = pd.Series([27, 30, 24, 18, 22, 20, 29])\n\n√à possibile ottenere la rappresentazione dell‚Äôarray dell‚Äôoggetto e dell‚Äôindice dell‚Äôoggetto Series tramite i suoi attributi array e index, rispettivamente.\n\ngrades.array\n\n&lt;NumpyExtensionArray&gt;\n[27, 30, 24, 18, 22, 20, 29]\nLength: 7, dtype: int64\n\n\n\ngrades.index\n\nRangeIndex(start=0, stop=7, step=1)\n\n\nOppure, possiamo semplicemente stampare i contenuti dell‚Äôoggetto Series direttamente:\n\nprint(grades)\n\n0    27\n1    30\n2    24\n3    18\n4    22\n5    20\n6    29\ndtype: int64\n\n\nPer accedere agli elementi di un oggetto Series si usano le parentesi quadre contenenti un indice:\n\ngrades[0]\n\n27\n\n\n\ngrades[0:3]\n\n0    27\n1    30\n2    24\ndtype: int64\n\n\n√à possibile filtrare gli elementi di un oggetto Series con un array booleano:\n\ngrades &gt; 24\n\n0     True\n1     True\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: bool\n\n\n\ngrades[grades &gt; 24]\n\n0    27\n1    30\n6    29\ndtype: int64\n\n\n√à possibile manipolare gli elementi di un oggetto Series con le normali operazioni aritmetiche mediante la vettorializzazione:\n\ngrades / 10\n\n0    2.7\n1    3.0\n2    2.4\n3    1.8\n4    2.2\n5    2.0\n6    2.9\ndtype: float64\n\n\n\nnp.sqrt(grades)\n\n0    5.196152\n1    5.477226\n2    4.898979\n3    4.242641\n4    4.690416\n5    4.472136\n6    5.385165\ndtype: float64\n\n\nGli oggetti Series hanno diversi metodi per svolgere varie operazioni, per esempio per ricavare alcune statistiche descrittive:\n\n[grades.count(), grades.mean(), grades.min(), grades.max(), grades.std(), grades.sum()]\n\n[7, 24.285714285714285, 18, 30, 4.572172558506722, 170]\n\n\nMolto utile √® il metodo .describe():\n\ngrades.describe()\n\ncount     7.000000\nmean     24.285714\nstd       4.572173\nmin      18.000000\n25%      21.000000\n50%      24.000000\n75%      28.000000\nmax      30.000000\ndtype: float64",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#dataframe",
    "href": "chapters/python/04_pandas.html#dataframe",
    "title": "6¬† Pandas (1)",
    "section": "6.3 DataFrame",
    "text": "6.3 DataFrame\nUn pandas.DataFrame √® composto da righe e colonne. Ogni colonna di un dataframe √® un oggetto pandas.Series: quindi, un dataframe √® una collezione di serie. A differenza di un array NumPy, un dataframe pu√≤ combinare pi√π tipi di dati, come numeri e testo, ma i dati in ogni colonna sono dello stesso tipo.\nEsistono molti modi per costruire un DataFrame. Un primo metodo √® quello di utilizzare un dizionario che include una o pi√π liste o array Numpy di uguale lunghezza. Per esempio:\n\ndata = {\n    \"name\": [\n        \"Maria\",\n        \"Anna\",\n        \"Francesco\",\n        \"Cristina\",\n        \"Gianni\",\n        \"Gabriella\",\n        \"Stefano\",\n    ],\n    \"sex\": [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"],\n    \"group\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"],\n    \"x\": [1, 2, 3, 4, 5, 6, 7],\n    \"y\": [8, 9, 10, 11, 12, 13, 14],\n    \"z\": [15, 16, 17, 18, 19, 20, 21],\n}\nframe = pd.DataFrame(data)\nframe\n\n\n\n\n\n\n\n\n\nname\nsex\ngroup\nx\ny\nz\n\n\n\n\n0\nMaria\nf\na\n1\n8\n15\n\n\n1\nAnna\nf\nb\n2\n9\n16\n\n\n2\nFrancesco\nm\na\n3\n10\n17\n\n\n3\nCristina\nf\nb\n4\n11\n18\n\n\n4\nGianni\nm\nb\n5\n12\n19\n\n\n5\nGabriella\nf\nc\n6\n13\n20\n\n\n6\nStefano\nm\na\n7\n14\n21\n\n\n\n\n\n\n\n\nOppure possiamo procedere nel modo seguente:\n\ndf = pd.DataFrame()\n\ndf[\"x\"] = [1, 2, 3, 4, 5, 6, 7]\ndf[\"y\"] = [8, 9, 10, 11, 12, 13, 14]\ndf[\"z\"] = [14.4, 15.1, 16.7, 17.3, 18.9, 19.3, 20.2]\ndf[\"group\"] = [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"]\ndf[\"sex\"] = [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"]\ndf[\"name\"] = [\n    \"Maria\",\n    \"Anna\",\n    \"Francesco\",\n    \"Cristina\",\n    \"Gianni\",\n    \"Gabriella\",\n    \"Stefano\",\n]\n\nprint(df)\n\n   x   y     z group sex       name\n0  1   8  14.4     a   f      Maria\n1  2   9  15.1     b   f       Anna\n2  3  10  16.7     a   m  Francesco\n3  4  11  17.3     b   f   Cristina\n4  5  12  18.9     b   m     Gianni\n5  6  13  19.3     c   f  Gabriella\n6  7  14  20.2     a   m    Stefano\n\n\nMolto spesso un DataFrame viene creato dal caricamento di dati da file.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#lettura-di-dati-da-file",
    "href": "chapters/python/04_pandas.html#lettura-di-dati-da-file",
    "title": "6¬† Pandas (1)",
    "section": "6.4 Lettura di dati da file",
    "text": "6.4 Lettura di dati da file\nDi solito la quantit√† di dati da analizzare √® tale che non √® pensabile di poterli immettere manualmente in una o pi√π liste. Normalmente i dati sono memorizzati su un file ed √® necessario importarli. La lettura (importazione) dei file √® il primo fondamentale passo nel processo pi√π generale di analisi dei dati.\nIn un primo esempio, importiamo i dati da un repository remoto.\n\nurl = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\ntitanic = pd.read_csv(url, index_col=\"Name\")\n\n√à possibile usare il metodo .head() per visualizzare le prime cinque righe.\n\ntitanic.head()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBraund, Mr. Owen Harris\n1\n0\n3\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\n2\n1\n1\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\nHeikkinen, Miss. Laina\n3\n1\n3\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n4\n1\n1\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\nAllen, Mr. William Henry\n5\n0\n3\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\nLe statistiche descrittive per ciascuna colonna si ottengono con il metodo describe.\n\ntitanic.describe()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.000000\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.486592\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n0.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n0.000000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n0.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n1.000000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n1.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n\n\n\nIn questo modo possiamo ottenere informazioni sui nomi dei passeggeri, la sopravvivenza (0 o 1), l‚Äôet√†, il prezzo del biglietto, ecc. Con le statistiche riassuntive vediamo che l‚Äôet√† media √® di 29,7 anni, il prezzo massimo del biglietto √® di 512 USD, il 38% dei passeggeri √® sopravvissuto, ecc.\nPer fare un secondo esempio, importo i dati dal file penguins.csv situato nella directory ‚Äúdata‚Äù del mio computer. I dati relativi ai pinguini di Palmer sono resi disponibili da Kristen Gorman e dalla Palmer station, Antarctica LTER. La seguente cella legge il contenuto del file penguins.csv e lo inserisce nell‚Äôoggetto df utilizzando la funzione read_csv() di Pandas.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nPer il DataFrame df il significato delle colonne √® il seguente:\n\nspecies: a factor denoting penguin type (Ad√©lie, Chinstrap and Gentoo)\nisland: a factor denoting island in Palmer Archipelago, Antarctica (Biscoe, Dream or Torgersen)\nbill_length_mm: a number denoting bill length (millimeters)\nbill_depth_mm: a number denoting bill depth (millimeters)\nflipper_length_mm: an integer denoting flipper length (millimeters)\nbody_mass_g: an integer denoting body mass (grams)\nsex: a factor denoting sexuality (female, male)\nyear: the year of the study\n\nUsiamo il metodo .head() per visualizzare le prime cinque righe.\n\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nA volte potrebbero esserci dati estranei alla fine del file, quindi √® importante anche controllare le ultime righe:\n\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n\n\n\n\nUn breve tutorial in formato video √® disponibile tramite il seguente [collegamento](https://drive.google.com/file/d/12y7jZ0McvZBXThg6yjFgWx2ljQKrhoYR/view?usp=share_link), il quale illustra come effettuare la lettura dei dati da un file esterno in Visual Studio Code. \nL‚Äôattributo .dtypes restituisce il tipo dei dati:\n\ndf.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\nGli attributi pi√π comunemente usati sono elencati di seguito:\n\n\n\n\n\n\n\nAttributo\nRitorna\n\n\n\n\ndtypes\nIl tipo di dati in ogni colonna\n\n\nshape\nUna tupla con le dimensioni del DataFrame object (numero di righe, numero di colonne)\n\n\nindex\nL‚Äôoggetto Index lungo le righe del DataFrame\n\n\ncolumns\nIl nome delle colonne\n\n\nvalues\nI dati contenuti nel DataFrame\n\n\nempty\nCheck if the DataFrame object is empty\n\n\n\nPer esempio, l‚Äôistruzione della cella seguente restituisce l‚Äôelenco con i nomi delle colonne del DataFrame df:\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')\n\n\nLe dimensioni del Data Frame si ottengono con l‚Äôattributo .shape, che ritorna il numero di righe e di colonne. Nel caso presente, ci sono 344 righe e 8 colonne.\n\ndf.shape\n\n(344, 8)\n\n\nCome abbiamo gi√† visto in precedenza, un sommario dei dati si ottiene con il metodo .describe():\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\n\nUna descrizione del DataFrame si ottiene con il metodo .info().\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nSi noti che, alle volte, abbiamo utilizzato la sintassi `df.word` e talvolta la sintassi `df.word()`. Tecnicamente, la classe Pandas Dataframe ha sia attributi che metodi. Gli attributi sono `.word`, mentre i metodi sono `.word()` o `.word(arg1, arg2, ecc.)`. Per sapere se qualcosa √® un metodo o un attributo √® necessario leggere la documentazione.\nAbbiamo visto in precedenza come possiamo leggere i dati in un dataframe utilizzando la funzione read_csv(). Pandas comprende anche molti altri formati, ad esempio utilizzando le funzioni read_excel(), read_hdf(), read_json(), ecc. (e i corrispondenti metodi per scrivere su file: to_csv(), to_excel(), to_hdf(), to_json(), ecc.).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#gestione-dei-dati-mancanti",
    "href": "chapters/python/04_pandas.html#gestione-dei-dati-mancanti",
    "title": "6¬† Pandas (1)",
    "section": "6.5 Gestione dei dati mancanti",
    "text": "6.5 Gestione dei dati mancanti\nNell‚Äôoutput di .info() troviamo la colonna ‚ÄúNon-Null Count‚Äù, ovvero il numero di dati non mancanti per ciascuna colonna del DataFrame. Da questo si nota che le colonne del DataFrame df contengono alcuni dati mancanti. La gestione dei dati mancanti √® un argomento complesso. Per ora ci limitiamo ad escludere tutte le righe che, in qualche colonna, contengono dei dati mancanti.\nOttengo il numero di dati per ciascuna colonna del DataFrame:\n\ndf.isnull().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\nRimuovo i dati mancanti con il metodo .dropna(). L‚Äôargomento inplace=True specifica il DataFrame viene trasformato in maniera permanente.\n\ndf.dropna(inplace=True)\n\nVerifico che i dati mancanti siano stati rimossi.\n\ndf.shape\n\n(333, 8)\n\n\nIn alternativa, possiamo rimuovere solo le righe del DataFrame per le quali ci sono dei dati mancanti rispetto a specifiche colonne. Per esempio\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf0 = df.copy()\n\nmissing_data = df0.isnull()[[\"bill_length_mm\", \"body_mass_g\"]].any(axis=1)\n# Drop rows with any missing data\ndf0_cleaned = df0.loc[~missing_data]\ndf0_cleaned.shape\n\n(342, 8)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#rinominare-le-colonne",
    "href": "chapters/python/04_pandas.html#rinominare-le-colonne",
    "title": "6¬† Pandas (1)",
    "section": "6.6 Rinominare le colonne",
    "text": "6.6 Rinominare le colonne\n√à possibile rinominare tutte le colonne passando al metodo .rename() un dizionario che specifica quali colonne devono essere mappate a cosa. Nella cella seguente facciamo prima una copia del DataFrame con il metodo copy() e poi rinominiamo sex che diventa gender e year che diventa year_of_the_study:\n\ndf1 = df.copy()\n\n# rename(columns={\"OLD_NAME\": \"NEW_NAME\"})\ndf1.rename(columns={\n    \"sex\": \"gender\", \n    \"year\": \"year_of_the_study\"\n    }, \n           inplace=True)\ndf1.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\ngender\nyear_of_the_study\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python valgono le seguenti regole.\n\n- Il nome di una variabile deve iniziare con una lettera o con il trattino basso (*underscore*) `_`.\n- Il nome di una variabile non pu√≤ iniziare con un numero.\n- Un nome di variabile pu√≤ contenere solo caratteri alfanumerici e il trattino basso (A-z, 0-9 e _).\n- I nomi delle variabili fanno distinzione tra maiuscole e minuscole (`age`, `Age` e `AGE` sono tre variabili diverse).\n\nGli spazi non sono consentiti nel nome delle variabili: come separatore usate il trattino basso.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "href": "chapters/python/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "title": "6¬† Pandas (1)",
    "section": "6.7 Estrarre i dati dal DataFrame",
    "text": "6.7 Estrarre i dati dal DataFrame\nUna parte cruciale del lavoro con i DataFrame √® l‚Äôestrazione di sottoinsiemi di dati: vogliamo trovare le righe che soddisfano un determinato insieme di criteri, vogliamo isolare le colonne/righe di interesse, ecc. Per rispondere alle domande di interesse dell‚Äôanalisi dei dati, molto spesso √® necessario selezionare un sottoinsieme del DataFrame.\n\n6.7.1 Colonne\n√à possibile estrarre una colonna da un DataFrame usando una notazione simile a quella che si usa per il dizionario (DataFrame['word']) o utilizzando la notazione DataFrame.word. Per esempio:\n\ndf[\"bill_length_mm\"]\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\n\ndf.bill_length_mm\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\nSe tra parentesi quadre indichiamo una lista di colonne, come nel caso di df[['bill_length_mm','species']], otteniamo un nuovo DataFrame costituito unicamente dalle colonne selezionate:\n\ndf[[\"bill_length_mm\", \"species\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nspecies\n\n\n\n\n0\n39.1\nAdelie\n\n\n1\n39.5\nAdelie\n\n\n2\n40.3\nAdelie\n\n\n4\n36.7\nAdelie\n\n\n5\n39.3\nAdelie\n\n\n...\n...\n...\n\n\n339\n55.8\nChinstrap\n\n\n340\n43.5\nChinstrap\n\n\n341\n49.6\nChinstrap\n\n\n342\n50.8\nChinstrap\n\n\n343\n50.2\nChinstrap\n\n\n\n\n333 rows √ó 2 columns\n\n\n\n\n\n\n6.7.2 Righe\nIn un pandas.DataFrame, anche le righe hanno un nome. I nomi delle righe sono chiamati index:\n\ndf.index\n\nInt64Index([  0,   1,   2,   4,   5,   6,   7,  12,  13,  14,\n            ...\n            334, 335, 336, 337, 338, 339, 340, 341, 342, 343],\n           dtype='int64', length=333)\n\n\nCi sono vari metodi per estrarre sottoinsimi di righe da un DataFrame. √à possibile fare riferimento ad un intervallo di righe mediante un indice di slice. Per esempio, possiamo ottenere le prime 3 righe del DataFrame df nel modo seguente:\n\ndf[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python una sequenza √® determinata dal valore iniziale e quello finale ma si interrompe ad n-1. Pertanto, per selezionare una singola riga (per esempio, la prima) dobbiamo procedere nel modo seguente:\n\ndf[0:1]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n\n\n\n\n\n\n\n\n6.7.3 Indicizzazione, selezione e filtraggio\nPoich√© l‚Äôoggetto DataFrame √® bidimensionale, √® possibile selezionare un sottoinsieme di righe e colonne utilizzando le etichette degli assi (loc) o gli indici delle righe (iloc).\nPer esempio, usando l‚Äôattributo iloc posso selezionare la prima riga del DataFrame:\n\ndf.iloc[0]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            39.1\nbill_depth_mm             18.7\nflipper_length_mm        181.0\nbody_mass_g             3750.0\nsex                       male\nyear                      2007\nName: 0, dtype: object\n\n\nLa cella seguene seleziona le prime tre righe del DataFrame:\n\ndf.iloc[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nL‚Äôattributo loc consente di selezionare simultaneamente righe e colonne per ‚Äúnome‚Äù. Il ‚Äúnome‚Äù delle righe √® l‚Äôindice di riga. Per esempio, visualizzo il quinto valore della colonna body_mass_g:\n\ndf.loc[4, \"body_mass_g\"]\n\n3450.0\n\n\noppure, il quinto valore delle colonne bill_length_mm, bill_depth_mm, flipper_length_mm:\n\ndf.loc[4, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\nbill_length_mm        36.7\nbill_depth_mm         19.3\nflipper_length_mm    193.0\nName: 4, dtype: object\n\n\nVisualizzo ora le prime tre righe sulle tre colonne precedenti. Si noti l‚Äôuso di : per definire un intervallo di valori sull‚Äôindice di riga.\n\ndf.loc[0:2, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n39.1\n18.7\n181.0\n\n\n1\n39.5\n17.4\n186.0\n\n\n2\n40.3\n18.0\n195.0\n\n\n\n\n\n\n\n\nUna piccola variante della sintassi precedente si rivela molto utile. Qui, il segno di due punti (:) signfica ‚Äútutte le righe‚Äù:\n\nkeep_cols = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\nprint(df.loc[:, keep_cols])\n\n     bill_length_mm  bill_depth_mm  flipper_length_mm\n0              39.1           18.7              181.0\n1              39.5           17.4              186.0\n2              40.3           18.0              195.0\n4              36.7           19.3              193.0\n5              39.3           20.6              190.0\n..              ...            ...                ...\n339            55.8           19.8              207.0\n340            43.5           18.1              202.0\n341            49.6           18.2              193.0\n342            50.8           19.0              210.0\n343            50.2           18.7              198.0\n\n[333 rows x 3 columns]\n\n\n\n\n6.7.4 Filtrare righe in maniera condizionale\nIn precedenza abbiamo utilizzato la selezione delle righe in un DataFrame in base alla loro posizione. Tuttavia, √® pi√π comune selezionare le righe del DataFrame utilizzando una condizione logica, cio√® tramite l‚Äôindicizzazione booleana.\nIniziamo con un esempio relativo ad una condizione specificata sui valori di una sola colonna. Quando applichiamo un operatore logico come &gt;, &lt;, ==, != ai valori di una colonna del DataFrame, il risultato √® una sequenza di valori booleani (True, False), uno per ogni riga nel DataFrame, i quali indicano se, per quella riga, la condizione √® vera o falsa. Ad esempio:\n\ndf[\"island\"] == \"Torgersen\"\n\n0       True\n1       True\n2       True\n4       True\n5       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: island, Length: 333, dtype: bool\n\n\nUtilizzando i valori booleani che sono stati ottenuti in questo modo √® possibile filtrare le righe del DataFrame, ovvero, ottenere un nuovo DataFrame nel quale la condizione logica specificata √® vera su tutte le righe. Per esempio, nella cella seguente selezioniamo solo le osservazioni relative all‚Äôisola Torgersen, ovvero tutte le righe del DataFrame nelle quali la colonna island assume il valore Torgersen.\n\nonly_torgersen = df[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo scrivere:\n\nonly_torgersen = df.loc[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\n√à possibile combinare pi√π condizioni logiche usando gli operatori & (e), | (oppure). Si presti attenzione all‚Äôuso delle parentesi.\n\ndf.loc[(df[\"island\"] == \"Torgersen\") & (df[\"sex\"] == \"female\")].head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n12\nAdelie\nTorgersen\n41.1\n17.6\n182.0\n3200.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n\n6.7.5 Metodo .query\n√à anche possibile filtrare le righe del DataFrame usando il metodo query(). Ci sono diversi modi per generare sottoinsiemi con Pandas. I metodi loc e iloc consentono di recuperare sottoinsiemi in base alle etichette di riga e colonna o all‚Äôindice intero delle righe e delle colonne. E Pandas ha una notazione a parentesi quadre che consente di utilizzare condizioni logiche per recuperare righe di dati specifiche. Ma la sintassi di questi metodi non √® la pi√π trasparente. Inoltre, tali metodi sono difficili da usare insieme ad altri metodi di manipolazione dei dati in modo organico.\nIl metodo .query di Pandas cerca di risolve questi problemi. Il metodo .query consente di ‚Äúinterrogare‚Äù un DataFrame e recuperare sottoinsiemi basati su condizioni logiche. La sintassi √® un po‚Äô pi√π snella rispetto alla notazione a parentesi quadre di Pandas. Inoltre, il metodo .query pu√≤ essere utilizzato con altri metodi di Pandas in modo snello e semplice, rendendo la manipolazione dei dati maggiormente fluida e diretta.\nLa sintassi √® la seguente:\nyour_data_frame.query(expression, inplace = False)\nL‚Äôespressione utilizzata nella query √® una sorta di espressione logica che descrive quali righe restituire in output. Se l‚Äôespressione √® vera per una particolare riga, la riga verr√† inclusa nell‚Äôoutput. Se l‚Äôespressione √® falsa per una particolare riga, quella riga verr√† esclusa dall‚Äôoutput.\nIl parametro inplace consente di specificare se si desidera modificare direttamente il DataFrame con cui si sta lavorando.\nPer esempio:\n\neval_string = \"island == 'Torgersen' & sex == 'female' & year != 2009\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n6\n17.8\n181.0\n\n\n12\n17.6\n182.0\n\n\n15\n17.8\n185.0\n\n\n16\n19.0\n195.0\n\n\n18\n18.4\n184.0\n\n\n68\n16.6\n190.0\n\n\n70\n19.0\n190.0\n\n\n72\n17.2\n196.0\n\n\n74\n17.5\n190.0\n\n\n76\n16.8\n191.0\n\n\n78\n16.1\n187.0\n\n\n80\n17.2\n189.0\n\n\n82\n18.8\n187.0\n\n\n\n\n\n\n\n\nUn altro esempio usa la keyword in per selezionare solo le righe relative alle due isole specificate.\n\neval_string = \"island in ['Torgersen', 'Dream']\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n18.7\n181.0\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n5\n20.6\n190.0\n\n\n...\n...\n...\n\n\n339\n19.8\n207.0\n\n\n340\n18.1\n202.0\n\n\n341\n18.2\n193.0\n\n\n342\n19.0\n210.0\n\n\n343\n18.7\n198.0\n\n\n\n\n170 rows √ó 2 columns\n\n\n\n\nIl metodo query() pu√≤ anche essere utilizzato per selezionare le righe di un DataFrame in base alle relazioni tra le colonne. Ad esempio,\n\ndf.query(\"bill_length_mm &gt; 3*bill_depth_mm\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n152\n13.2\n211.0\n\n\n153\n16.3\n230.0\n\n\n154\n14.1\n210.0\n\n\n155\n15.2\n218.0\n\n\n156\n14.5\n215.0\n\n\n...\n...\n...\n\n\n272\n14.3\n215.0\n\n\n273\n15.7\n222.0\n\n\n274\n14.8\n212.0\n\n\n275\n16.1\n213.0\n\n\n293\n17.8\n181.0\n\n\n\n\n106 rows √ó 2 columns\n\n\n\n\n√à anche possibile fare riferimento a variabili non contenute nel DataFrame usando il carattere @.\n\noutside_var = 21\ndf.query(\"bill_depth_mm &gt; @outside_var\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n13\n21.2\n191.0\n\n\n14\n21.1\n198.0\n\n\n19\n21.5\n194.0\n\n\n35\n21.1\n196.0\n\n\n49\n21.2\n191.0\n\n\n61\n21.1\n195.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "href": "chapters/python/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "title": "6¬† Pandas (1)",
    "section": "6.8 Selezione casuale di un sottoinsieme di righe",
    "text": "6.8 Selezione casuale di un sottoinsieme di righe\nIl metodo sample() viene usato per ottenere un sottoinsieme casuale di righe del DataFrame. L‚Äôargomento replace=False indica l‚Äôestrazione senza rimessa (default); se specifichiamo replace=True otteniamo un‚Äôestrazione con rimessa. L‚Äôargomento n specifica il numero di righe che vogliamo ottenere. Ad esempio\n\ndf_sample = df.sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n204\nGentoo\nBiscoe\n45.1\n14.4\n210.0\n4400.0\nfemale\n2008\n\n\n69\nAdelie\nTorgersen\n41.8\n19.4\n198.0\n4450.0\nmale\n2008\n\n\n296\nChinstrap\nDream\n42.4\n17.3\n181.0\n3600.0\nfemale\n2007\n\n\n208\nGentoo\nBiscoe\n43.8\n13.9\n208.0\n4300.0\nfemale\n2008\n\n\n\n\n\n\n\n\n\ndf_sample = df[[\"bill_length_mm\", \"bill_depth_mm\"]].sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\n\n\n175\n46.3\n15.8\n\n\n133\n37.5\n18.5\n\n\n182\n47.3\n15.3\n\n\n251\n51.1\n16.5",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#selezione-di-colonne",
    "href": "chapters/python/04_pandas.html#selezione-di-colonne",
    "title": "6¬† Pandas (1)",
    "section": "6.9 Selezione di colonne",
    "text": "6.9 Selezione di colonne\nIl metodo drop() prende in input una lista con i nomi di colonne che vogliamo escludere dal DataFrame e pu√≤ essere usato per creare un nuovo DataFrame o per sovrascrivere quello di partenza. √à possibile usare le espressioni regolari (regex) per semplificare la ricerca dei nomi delle colonne.\nIn *regex* il simbolo `$` significa \"la stringa finisce con\"; il simbolo `^` significa \"la stringa inizia con\". L'espressione `regex` pu√≤ contenere (senza spazi) il simbolo `|` che significa \"oppure\". \nNel codice della cella seguente, alla funzione .columns.str.contains() viene passata l‚Äôespressione regolare mm$|year che significa: tutte le stringhe (in questo caso, nomi di colonne) che finiscono con mm oppure la stringa (nome di colonna) year.\n\nmask = df.columns.str.contains(\"mm$|year\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'year'], dtype='object')\n\n\n\ndf_new = df.drop(columns=columns_to_drop)\ndf_new.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n3750.0\nmale\n\n\n1\nAdelie\nTorgersen\n3800.0\nfemale\n\n\n2\nAdelie\nTorgersen\n3250.0\nfemale\n\n\n4\nAdelie\nTorgersen\n3450.0\nfemale\n\n\n5\nAdelie\nTorgersen\n3650.0\nmale\n\n\n\n\n\n\n\n\nIn un altro esempio, creaiamo l‚Äôelenco delle colonne che iniziano con la lettera ‚Äúb‚Äù, insieme a year e sex.\n\nmask = df.columns.str.contains(\"^b|year|sex\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'body_mass_g', 'sex', 'year'], dtype='object')\n\n\nOppure l‚Äôelenco delle colonne che contengono il patten ‚Äúlength‚Äù.\n\nmask = df.columns.str.contains(\"length\")\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'flipper_length_mm'], dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#creare-nuove-colonne",
    "href": "chapters/python/04_pandas.html#creare-nuove-colonne",
    "title": "6¬† Pandas (1)",
    "section": "6.10 Creare nuove colonne",
    "text": "6.10 Creare nuove colonne\nPer ciascuna riga, calcoliamo\n\nbill_length_mm - bill_depth_mm\nbill_length_mm / (body_mass_g / 1000)\n\nPer ottenere questo risultato possiamo usare una lambda function.\n\ndf = df.assign(\n    bill_difference=lambda x: x.bill_length_mm - x.bill_depth_mm,\n    bill_ratio=lambda x: x.bill_length_mm / (x.body_mass_g / 1000),\n)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n\n\n\n\n\n\n\n\nIn maniera pi√π semplice possiamo procedere nel modo seguente:\n\ndf[\"bill_ratio2\"] = df[\"bill_length_mm\"] / (df[\"body_mass_g\"] / 1000)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\nbill_ratio2\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n10.767123\n\n\n\n\n\n\n\n\nUn‚Äôutile funzionalit√† √® quella che consente di aggiungere una colonna ad un DataFrame (o di mofificare una colonna gi√† esistente) sulla base di una condizione True/False. Questo risultato pu√≤ essere raggiunto usando np.where(), con la seguente sintassi:\nnp.where(condition, value if condition is true, value if condition is false)\nSupponiamo di avere un DataFrame df con due colonne, A e B, e vogliamo creare una nuova colonna C che contenga il valore di A quando questo √® maggiore di 0, e il valore di B altrimenti. Possiamo utilizzare la funzione where() per ottenere ci√≤ come segue:\n\n# Creiamo un DataFrame di esempio\ndf = pd.DataFrame({\"A\": [-1, 2, 3, -4], \"B\": [5, 6, 0, 8]})\n\n# Creiamo una nuova colonna 'C' usando la funzione where()\ndf[\"C\"] = df[\"A\"].where(df[\"A\"] &gt; 0, df[\"B\"])\n\nprint(df)\n\n   A  B  C\n0 -1  5  5\n1  2  6  2\n2  3  0  3\n3 -4  8  8",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#formato-long-e-wide",
    "href": "chapters/python/04_pandas.html#formato-long-e-wide",
    "title": "6¬† Pandas (1)",
    "section": "6.11 Formato long e wide",
    "text": "6.11 Formato long e wide\nNella data analysis, i termini ‚Äúformato long‚Äù e ‚Äúformato wide‚Äù sono usati per descrivere la struttura di un set di dati. l formato wide (in inglese ‚Äúwide format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni variabile √® rappresentata da pi√π colonne. Un esempio √® il seguente, nel quale per ciascun partecipante, identificato da Name e ID abbiamo i punteggi di un ipotetico test per 6 anni consecutivi.\n\nscores = {\n    \"Name\": [\"Maria\", \"Carlo\", \"Giovanna\", \"Irene\"],\n    \"ID\": [1, 2, 3, 4],\n    \"2017\": [85, 87, 89, 91],\n    \"2018\": [96, 98, 100, 102],\n    \"2019\": [100, 102, 106, 106],\n    \"2020\": [89, 95, 98, 100],\n    \"2021\": [94, 96, 98, 100],\n    \"2022\": [100, 104, 104, 107],\n}\n\nwide_data = pd.DataFrame(scores)\nwide_data\n\n\n\n\n\n\n\n\n\nName\nID\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\n0\nMaria\n1\n85\n96\n100\n89\n94\n100\n\n\n1\nCarlo\n2\n87\n98\n102\n95\n96\n104\n\n\n2\nGiovanna\n3\n89\n100\n106\n98\n98\n104\n\n\n3\nIrene\n4\n91\n102\n106\n100\n100\n107\n\n\n\n\n\n\n\n\nIl formato long (in inglese ‚Äúlong format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni colonna rappresenta una singola variabile. Questo formato √® quello che viene richiesto per molte analisi statistiche. In Pandas √® possibile usare la funzione melt per trasformare i dati dal formato wide al formato long. Un esempio √® riportato qui sotto. Sono state mantenute le due colonne che identificano ciascun partecipante, ma i dati del test, che prima erano distribuiti su sei colonne, ora sono presenti in una singola colonna. Al DataFrame, inoltre, √® stata aggiunta una colonna che riporta l‚Äôanno.\n\nlong_data = wide_data.melt(id_vars=[\"Name\", \"ID\"], var_name=\"Year\", value_name=\"Score\")\nlong_data\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n1\nCarlo\n2\n2017\n87\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n3\nIrene\n4\n2017\n91\n\n\n4\nMaria\n1\n2018\n96\n\n\n5\nCarlo\n2\n2018\n98\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n7\nIrene\n4\n2018\n102\n\n\n8\nMaria\n1\n2019\n100\n\n\n9\nCarlo\n2\n2019\n102\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n11\nIrene\n4\n2019\n106\n\n\n12\nMaria\n1\n2020\n89\n\n\n13\nCarlo\n2\n2020\n95\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n15\nIrene\n4\n2020\n100\n\n\n16\nMaria\n1\n2021\n94\n\n\n17\nCarlo\n2\n2021\n96\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n19\nIrene\n4\n2021\n100\n\n\n20\nMaria\n1\n2022\n100\n\n\n21\nCarlo\n2\n2022\n104\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n23\nIrene\n4\n2022\n107\n\n\n\n\n\n\n\n\nPer migliorare la leggibilit√† dei dati, √® possibile riordinare le righe del set di dati utilizzando la funzione sort_values. In questo modo, le informazioni saranno presentate in un ordine specifico, che pu√≤ rendere pi√π facile la lettura dei dati.\n\nlong_data.sort_values(by=[\"ID\", \"Year\"])\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n4\nMaria\n1\n2018\n96\n\n\n8\nMaria\n1\n2019\n100\n\n\n12\nMaria\n1\n2020\n89\n\n\n16\nMaria\n1\n2021\n94\n\n\n20\nMaria\n1\n2022\n100\n\n\n1\nCarlo\n2\n2017\n87\n\n\n5\nCarlo\n2\n2018\n98\n\n\n9\nCarlo\n2\n2019\n102\n\n\n13\nCarlo\n2\n2020\n95\n\n\n17\nCarlo\n2\n2021\n96\n\n\n21\nCarlo\n2\n2022\n104\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n3\nIrene\n4\n2017\n91\n\n\n7\nIrene\n4\n2018\n102\n\n\n11\nIrene\n4\n2019\n106\n\n\n15\nIrene\n4\n2020\n100\n\n\n19\nIrene\n4\n2021\n100\n\n\n23\nIrene\n4\n2022\n107",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#copia-di-un-data-frame",
    "href": "chapters/python/04_pandas.html#copia-di-un-data-frame",
    "title": "6¬† Pandas (1)",
    "section": "6.12 Copia di un data frame",
    "text": "6.12 Copia di un data frame\nQuando in Python definiamo un nuovo data frame basandoci su un data frame esistente con l‚Äôistruzione new_df = old_df, √® importante essere consapevoli del fatto che non stiamo creando un nuovo data frame indipendente. In realt√†, new_df diventa solamente un riferimento all‚Äôoggetto originale old_df nell‚Äôambiente corrente. Questo significa che qualsiasi modifica apportata a new_df si rifletter√† automaticamente anche in old_df. In pratica, abbiamo un unico oggetto data frame accessibile attraverso due nomi diversi.\nPer creare effettivamente una copia indipendente di old_df, in modo che le modifiche apportate a questa copia non influiscano sull‚Äôoriginale, dobbiamo utilizzare il metodo .copy(). Questo metodo crea un nuovo oggetto data frame che √® una copia del data frame originale. L‚Äôistruzione corretta per fare ci√≤ in Python √® la seguente:\nnew_df = old_df.copy()\nUtilizzando old_df.copy(), otteniamo due data frame completamente indipendenti. Modifiche apportate a new_df non avranno alcun impatto su old_df, permettendoci di lavorare con i dati in modo sicuro e senza rischi di sovrascrittura o alterazione involontaria dei dati originali. Questa pratica √® fondamentale per mantenere l‚Äôintegrit√† dei dati e per gestire correttamente le variabili all‚Äôinterno di un programma Python.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "title": "6¬† Pandas (1)",
    "section": "6.13 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "6.13 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.2\npandas: 2.1.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html",
    "href": "chapters/python/05_pandas_aggregate.html",
    "title": "7¬† Pandas (2)",
    "section": "",
    "text": "7.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport arviz as az\nimport seaborn as sns\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nsns.set_theme(palette=\"colorblind\")\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = 'retina'",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "href": "chapters/python/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "title": "7¬† Pandas (2)",
    "section": "7.2 Calcolo delle statistiche descrittive",
    "text": "7.2 Calcolo delle statistiche descrittive\nAgli oggetti Pandas possono essere applicati vari metodi matematici e statistici. La maggior parte di questi rientra nella categoria della riduzione di dati o delle statistiche descrittive. Rispetto ai metodi degli array NumPy, i metodi Pandas consentono la gestione dei dati mancanti. Alcuni dei metodi disponibili per gli oggetti Pandas sono elencati di seguito.\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncount\nNumber of non-NA values\n\n\ndescribe\nCompute set of summary statistics\n\n\nmin, max\nCompute minimum and maximum values\n\n\nargmin, argmax\nCompute index locations (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects\n\n\nidxmin, idxmax\nCompute index labels at which minimum or maximum value is obtained, respectively\n\n\nquantile\nCompute sample quantile ranging from 0 to 1 (default: 0.5)\n\n\nsum\nSum of values\n\n\nmean\nMean of values\n\n\nmedian\nArithmetic median (50% quantile) of values\n\n\nmad\nMean absolute deviation from mean value\n\n\nprod\nProduct of all values\n\n\nvar\nSample variance of values\n\n\nstd\nSample standard deviation of values\n\n\nskew\nSample skewness (third moment) of values\n\n\nkurt\nSample kurtosis (fourth moment) of values\n\n\ncumsum\nCumulative sum of values\n\n\ncummin, cummax\nCumulative minimum or maximum of values, respectively\n\n\ncumprod\nCumulative product of values\n\n\ndiff\nCompute first arithmetic difference (useful for time series)\n\n\npct_change\nCompute percent changes\n\n\n\nTali metodi possono essere applicati a tutto il DataFrame, oppure soltanto ad una o pi√π colonne.\nPer fare un esempio, esamineremo nuovamente i dati penguins.csv. Come in precedenza, dopo avere caricato i dati, rimuoviamo i dati mancanti.\n\ndf = pd.read_csv(\"../../data/penguins.csv\")\ndf.dropna(inplace=True)\n\nUsiamo il metodo describe() su tutto il DataFrame:\n\ndf.describe(include=\"all\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\ncount\n333\n333\n333.000000\n333.000000\n333.000000\n333.000000\n333\n333.000000\n\n\nunique\n3\n3\nNaN\nNaN\nNaN\nNaN\n2\nNaN\n\n\ntop\nAdelie\nBiscoe\nNaN\nNaN\nNaN\nNaN\nmale\nNaN\n\n\nfreq\n146\n163\nNaN\nNaN\nNaN\nNaN\n168\nNaN\n\n\nmean\nNaN\nNaN\n43.992793\n17.164865\n200.966967\n4207.057057\nNaN\n2008.042042\n\n\nstd\nNaN\nNaN\n5.468668\n1.969235\n14.015765\n805.215802\nNaN\n0.812944\n\n\nmin\nNaN\nNaN\n32.100000\n13.100000\n172.000000\n2700.000000\nNaN\n2007.000000\n\n\n25%\nNaN\nNaN\n39.500000\n15.600000\n190.000000\n3550.000000\nNaN\n2007.000000\n\n\n50%\nNaN\nNaN\n44.500000\n17.300000\n197.000000\n4050.000000\nNaN\n2008.000000\n\n\n75%\nNaN\nNaN\n48.600000\n18.700000\n213.000000\n4775.000000\nNaN\n2009.000000\n\n\nmax\nNaN\nNaN\n59.600000\n21.500000\n231.000000\n6300.000000\nNaN\n2009.000000\n\n\n\n\n\n\n\n\nSe desideriamo solo le informazioni relative alle variabili qualitative, usiamo l‚Äôargomento include='object'.\n\ndf.describe(include=\"object\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nsex\n\n\n\n\ncount\n333\n333\n333\n\n\nunique\n3\n3\n2\n\n\ntop\nAdelie\nBiscoe\nmale\n\n\nfreq\n146\n163\n168\n\n\n\n\n\n\n\n\nI valori NaN indicano dati mancanti. Ad esempio, la colonna species contiene stringhe, quindi non esiste alcun valore per mean; allo stesso modo, bill_length_mm √® una variabile numerica, quindi non vengono calcolate le statistiche riassuntive per le variabili categoriali (unique, top, freq).\nEsaminimiamo le colonne singolarmente. Ad esempio, troviamo la media della colonna bill_depth_mm.\n\ndf[\"bill_depth_mm\"].mean()\n\n17.164864864864867\n\n\nPer la deviazione standard usiamo il metodo std(). Si noti l‚Äôargomento opzionale ddof:\n\ndf[\"bill_length_mm\"].std(ddof=1)\n\n5.46866834264756\n\n\nLa cella seguente fornisce l‚Äôindice della riga nella quale la colonna bill_length_mm assume il suo valore massimo:\n\ndf[\"bill_length_mm\"].idxmax()\n\n185\n\n\nLa colonna species nel DataFrame df √® una variabile a livello nominale. Elenchiamo le modalit√† di tale variabile.\n\ndf[\"species\"].unique()\n\narray(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n\nIl metodo value_counts ritorna la distribuzione di frequenza assoluta:\n\ndf[\"species\"].value_counts()\n\nspecies\nAdelie       146\nGentoo       119\nChinstrap     68\nName: count, dtype: int64\n\n\nPer le frequenze relative si imposta l‚Äôargomento normalize=True:\n\nprint(df[\"species\"].value_counts(normalize=True))\n\nspecies\nAdelie       0.438438\nGentoo       0.357357\nChinstrap    0.204204\nName: proportion, dtype: float64\n\n\nConsideriamo la lunghezza del becco dei pinguini suddivisa per ciascuna specie. Con l‚Äôistruzione seguente, possiamo generare gli istogrammi corrispondenti che rappresentano la distribuzione della lunghezza del becco in ciascun gruppo.\n\ncolor_fill = \"#b97c7c\"\n_ = df.hist(\n    column=\"bill_length_mm\",\n    by=[\"species\"],\n    bins=20,\n    figsize=(12, 4),\n    layout=(1, 3),\n    rwidth=0.9,\n    color=color_fill\n)\n\n\n\n\n\n\n\n\n\ndf\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n333 rows √ó 8 columns\n\n\n\n\n\n7.2.1 Aggregazione dei dati\nIl riepilogo di pi√π valori in un unico indice va sotto il nome di ‚Äúaggregazione‚Äù dei dati. Il metodo aggregate() pu√≤ essere applicato ai DataFrame e restituisce un nuovo DataFrame pi√π breve contenente solo i valori aggregati. Il primo argomento di aggregate() specifica quale funzione o quali funzioni devono essere utilizzate per aggregare i dati. Molte comuni funzioni di aggregazione sono disponibili nel modulo statistics. Ad esempio:\n\nmedian(): la mediana;\nmean(): la media;\nstdev(): la deviazione standard;\n\nSe vogliamo applicare pi√π funzioni di aggregazione, allora possiamo raccogliere prima le funzioni in una lista e poi passare la lista ad aggregate().\n\n# Lista delle funzioni statistiche di riepilogo come stringhe\nsummary_stats = [\"min\", \"median\", \"mean\", \"std\", \"max\"]\n\n# Calcola le statistiche di riepilogo per le colonne numeriche usando aggregate\nresult = df[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n].aggregate(summary_stats)\n\nprint(result)\n\n        bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\nmin          32.100000      13.100000         172.000000  2700.000000\nmedian       44.500000      17.300000         197.000000  4050.000000\nmean         43.992793      17.164865         200.966967  4207.057057\nstd           5.468668       1.969235          14.015765   805.215802\nmax          59.600000      21.500000         231.000000  6300.000000\n\n\nSi noti che Pandas ha applicato le funzioni di riepilogo a ogni colonna, ma, per alcune colonne, le statistiche riassuntive non si possono calcolare, ovvero tutte le colonne che contengono stringhe anzich√© numeri. Di conseguenza, vediamo che alcuni dei risultati per tali colonne sono contrassegnati con ‚ÄúNaN‚Äù. Questa √® un‚Äôabbreviazione di ‚ÄúNot a Number‚Äù, talvolta utilizzata nell‚Äôanalisi dei dati per rappresentare valori mancanti o non definiti.\nMolto spesso vogliamo calcolare le statistiche descrittive separatamente per ciascun gruppo di osservazioni ‚Äì per esempio, nel caso presente, potremmo volere distinguere le statistiche descrittive in base alla specie dei pinguini. Questo risultato si ottiene con il metodo .groupby().\nIl nome ‚Äúgroup by‚Äù deriva da un comando nel linguaggio del database SQL, ma forse √® pi√π semplice pensarlo nei termini coniati da Hadley Wickham: split, apply, combine. Un esempio canonico di questa operazione di split-apply-combine, in cui ‚Äúapply‚Äù √® un‚Äôaggregazione di sommatoria, √® illustrato nella figura seguente:\n\n\n\n\n\n\nFigura¬†7.1: Split, apply, combine.\n\n\n\nLa figura rende chiaro ci√≤ che si ottiene con groupby:\n\nla fase ‚Äúsplit‚Äù prevede la suddivisione e il raggruppamento di un DataFrame in base al valore della chiave specificata;\nla fase ‚Äúapply‚Äù implica il calcolo di alcune funzioni, solitamente un‚Äôaggregazione, una trasformazione o un filtro, all‚Äôinterno dei singoli gruppi;\nla fase ‚Äúcombine‚Äù unisce i risultati di queste operazioni in una matrice di output.\n\nPer esempio, ragruppiamo le osservazioni body_mass_g in funzione delle modalit√† della variabile species.\n\ngrouped = df[\"body_mass_g\"].groupby(df[\"species\"])\n\nCalcoliamo ora la media della variabile body_mass_g separatamente per ciascun gruppo di osservazioni.\n\ngrouped.mean()\n\nspecies\nAdelie       3706.164384\nChinstrap    3733.088235\nGentoo       5092.436975\nName: body_mass_g, dtype: float64\n\n\n√à possibile applicare criteri di classificazione multipli. Per fare un altro esempio, contiamo il numero di pinguini presenti sulle tre isole, distinguendoli per specie e genere.\n\ndf.groupby([\"island\", \"species\", \"sex\"]).size()\n\nisland     species    sex   \nBiscoe     Adelie     female    22\n                      male      22\n           Gentoo     female    58\n                      male      61\nDream      Adelie     female    27\n                      male      28\n           Chinstrap  female    34\n                      male      34\nTorgersen  Adelie     female    24\n                      male      23\ndtype: int64\n\n\nCon il metodo aggregate() possiamo applicare diverse funzioni di aggregazione alle osservazioni ragruppate. Ad esempio\n\nsummary_stats = [np.mean, np.std]\n# Group by \"species\" and calculate summary statistics for numeric columns\nresult = df.groupby(\"species\").agg(\n    {col: summary_stats for col in df.columns if pd.api.types.is_numeric_dtype(df[col])}\n)\n\nprint(result)\n\n          bill_length_mm           bill_depth_mm           flipper_length_mm  \\\n                    mean       std          mean       std              mean   \nspecies                                                                        \nAdelie         38.823973  2.662597     18.347260  1.219338        190.102740   \nChinstrap      48.833824  3.339256     18.420588  1.135395        195.823529   \nGentoo         47.568067  3.106116     14.996639  0.985998        217.235294   \n\n                     body_mass_g                     year            \n                std         mean         std         mean       std  \nspecies                                                              \nAdelie     6.521825  3706.164384  458.620135  2008.054795  0.811816  \nChinstrap  7.131894  3733.088235  384.335081  2007.970588  0.863360  \nGentoo     6.585431  5092.436975  501.476154  2008.067227  0.789025  \n\n\nNella cella seguente troviamo la media di body_mass_g e flipper_length_mm separatamente per ciascuna isola e ciascuna specie:\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].mean()\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n188.795455\n\n\nGentoo\n5092.436975\n217.235294\n\n\nDream\nAdelie\n3701.363636\n189.927273\n\n\nChinstrap\n3733.088235\n195.823529\n\n\nTorgersen\nAdelie\n3708.510638\n191.531915\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per la deviazione standard.\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].std(ddof=1)\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n487.733722\n6.729247\n\n\nGentoo\n501.476154\n6.585431\n\n\nDream\nAdelie\n448.774519\n6.480325\n\n\nChinstrap\n384.335081\n7.131894\n\n\nTorgersen\nAdelie\n451.846351\n6.220062\n\n\n\n\n\n\n\n\nPrestiamo attenzione alla seguente sintassi:\n\nsummary_stats = (\n    df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]\n    .groupby([\"island\", \"species\"])\n    .aggregate([\"mean\", \"std\", \"count\"])\n)\nsummary_stats\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\n\n\nmean\nstd\ncount\nmean\nstd\ncount\n\n\nisland\nspecies\n\n\n\n\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n487.733722\n44\n188.795455\n6.729247\n44\n\n\nGentoo\n5092.436975\n501.476154\n119\n217.235294\n6.585431\n119\n\n\nDream\nAdelie\n3701.363636\n448.774519\n55\n189.927273\n6.480325\n55\n\n\nChinstrap\n3733.088235\n384.335081\n68\n195.823529\n7.131894\n68\n\n\nTorgersen\nAdelie\n3708.510638\n451.846351\n47\n191.531915\n6.220062\n47\n\n\n\n\n\n\n\n\nNell‚Äôistruzione precedente selezioniamo tutte le righe (:) di tre colonne di interesse: df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]. L‚Äôistruzione .groupby([\"island\", \"species\"]) ragruppa le osservazioni (righe) secondo le modalit√† delle variabili island e species. Infine .aggregate([\"mean\", \"std\", \"count\"]) applica i metodi statistici specificati a ciascun gruppo di osservazioni. Con questa sintassi la sequenza delle operazioni da eseguire diventa molto intuitiva.\n√à possibile approfondire questo argomento consultanto il capitolo 10 del testo Python for Data Analysis di McKinney (2022).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "title": "7¬† Pandas (2)",
    "section": "7.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "7.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.11.4\nseaborn   : 0.13.0\nnumpy     : 1.26.2\npandas    : 2.1.4\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html",
    "href": "chapters/python/06_pandas_functions.html",
    "title": "8¬† Pandas (3)",
    "section": "",
    "text": "8.1 pd.read_csv, pd.read_excel\nLa prima funzione da menzionare √® read_csv o read_excel. Le funzioni vengono utilizzate per leggere un file CSV o un file Excel in formato DataFrame di Pandas. Qui stiamo utilizzando la funzione read_csv per leggere il dataset penguins. In precedenza abbiamo anche visto come la funzione dropna viene utilizzata per rimuovere tutte le righe del DataFrame che includono dati mancanti.\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#columns",
    "href": "chapters/python/06_pandas_functions.html#columns",
    "title": "8¬† Pandas (3)",
    "section": "8.2 .columns",
    "text": "8.2 .columns\nQuando si dispone di un grande dataset, pu√≤ essere difficile visualizzare tutte le colonne. Utilizzando la funzione columns, √® possibile stampare tutte le colonne del dataset.\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#drop",
    "href": "chapters/python/06_pandas_functions.html#drop",
    "title": "8¬† Pandas (3)",
    "section": "8.3 .drop()",
    "text": "8.3 .drop()\n√à possibile eliminare alcune colonne non necessarie utilizzando drop.\n\ndf = df.drop(columns=[\"year\"])\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#len",
    "href": "chapters/python/06_pandas_functions.html#len",
    "title": "8¬† Pandas (3)",
    "section": "8.4 len()",
    "text": "8.4 len()\nFornisce il numero di righe di un DataFrame.\n\nlen(df)\n\n333",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#query",
    "href": "chapters/python/06_pandas_functions.html#query",
    "title": "8¬† Pandas (3)",
    "section": "8.5 .query()",
    "text": "8.5 .query()\n√à possibile filtrare un DataFrame utilizzando un‚Äôespressione booleana.\n\ndf1 = df.query(\"species == 'Chinstrap' & island == 'Dream'\")\nlen(df1)\n\n68",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#iloc",
    "href": "chapters/python/06_pandas_functions.html#iloc",
    "title": "8¬† Pandas (3)",
    "section": "8.6 .iloc[]",
    "text": "8.6 .iloc[]\nQuesta funzione accetta come parametri gli indici delle righe e delle colonne, fornendo una selezione del DataFrame in base a questi. In questo caso, stiamo selezionando le prime 3 righe di dati e le colonne con indice 2, 3 e 5.\n\ndf2 = df.iloc[:3, [2, 3, 5]]\ndf2\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nbody_mass_g\n\n\n\n\n0\n39.1\n18.7\n3750.0\n\n\n1\n39.5\n17.4\n3800.0\n\n\n2\n40.3\n18.0\n3250.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#loc",
    "href": "chapters/python/06_pandas_functions.html#loc",
    "title": "8¬† Pandas (3)",
    "section": "8.7 .loc[]",
    "text": "8.7 .loc[]\nQuesta funzione compie un‚Äôoperazione molto simile a quella della funzione .iloc. Tuttavia, in questo caso, abbiamo la possibilit√† di specificare gli indici delle righe che desideriamo, insieme ai nomi delle colonne che vogliamo includere nella nostra selezione.\n\ndf3 = df.loc[[2, 4, 6], [\"island\", \"flipper_length_mm\", \"sex\"]]\ndf3\n\n\n\n\n\n\n\n\n\nisland\nflipper_length_mm\nsex\n\n\n\n\n2\nTorgersen\n195.0\nfemale\n\n\n4\nTorgersen\n193.0\nfemale\n\n\n6\nTorgersen\n181.0\nfemale",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "title": "8¬† Pandas (3)",
    "section": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.0\nnumpy     : 1.26.2\narviz     : 0.17.0\npandas    : 2.1.4\nmatplotlib: 3.8.2\nscipy     : 1.11.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html",
    "href": "chapters/python/07_matplotlib.html",
    "title": "9¬† Matplotlib",
    "section": "",
    "text": "9.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\n# Questa istruzione consente di visualizzare i grafici generati dai comandi di \n# plot direttamente all'interno del notebook.\n%config InlineBackend.figure_format = 'retina'\n\n# Questo valore viene usato come seed per il random number generator.\nRANDOM_SEED = 42\n\n# In questa riga, stai utilizzando il generatore di numeri casuali di NumPy per \n# creare una nuova istanza denominata rng. La funzione np.random.default_rng() viene \n# utilizzata per inizializzare un generatore di numeri casuali con un seme specifico, \n# che in questo caso √® RANDOM_SEED.\nrng = np.random.default_rng(RANDOM_SEED)\n\n# Queste due righe di codice sono spesso utilizzate per personalizzare l'aspetto dei \n# grafici in Python utilizzando le librerie ArviZ e Seaborn.\n# Questa riga di codice utilizza il metodo use() della libreria ArviZ per impostare uno \n# stile specifico per i tuoi grafici. In particolare, sta impostando lo stile chiamato \n# \"arviz-darkgrid\". Gli stili in ArviZ determinano come saranno visualizzati i grafici, inclusi colori, linee di griglia e altri dettagli estetici.\naz.style.use(\"arviz-darkgrid\")\n\n# Questa riga di codice utilizza la libreria Seaborn per impostare il tema dei grafici. \n# In questo caso, il tema viene impostato utilizzando set_theme() con il parametro palette \n# impostato su \"colorblind\". Questo significa che i colori utilizzati nei grafici saranno \n# scelti in modo da essere adatti alle persone con deficit visivi dei colori, rendendo i \n# grafici pi√π accessibili.\nsns.set_theme(palette=\"colorblind\")",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "href": "chapters/python/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "title": "9¬† Matplotlib",
    "section": "9.2 L‚ÄôInterfaccia pyplot per Creare Grafici",
    "text": "9.2 L‚ÄôInterfaccia pyplot per Creare Grafici\nMatplotlib √® una libreria in Python famosa per la creazione di grafici, e la sua interfaccia pyplot √® particolarmente apprezzata per la sua semplicit√†. Vediamo in dettaglio come funzionano le sue funzioni principali. Per comprendere meglio come funzionano le sue funzioni principali, possiamo fare un parallelo con il disegno su un supporto fisico.\n\nPrepariamo la Tela: Iniziamo con plt.figure(), che √® analogo a ottenere una tela bianca pronta per essere dipinta. √à il punto di partenza, una superficie vuota su cui creeremo il nostro grafico.\nDefiniamo le Aree di Disegno: Successivamente, utilizzando plt.subplot() o plt.axes(), creiamo delle aree specifiche o ‚Äúassi‚Äù sulla nostra tela. Questi assi corrispondono a diverse sezioni in cui posizioneremo vari elementi del nostro grafico, come se suddividessimo la tela fisica in diverse parti.\nAggiungiamo Elementi al Grafico: Una volta definiti gli assi, entriamo nel processo di creazione. Usandando funzioni come plt.plot() per tracciare linee o plt.scatter() per punti, aggiungiamo elementi grafici alla nostra area di disegno. √à simile a disegnare direttamente sulla tela fisica.\nRendiamo il Grafico Comprensibile: Per garantire che il grafico sia chiaro e informativo, aggiungiamo etichette e titoli con plt.xlabel(), plt.ylabel() e plt.title().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "href": "chapters/python/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "title": "9¬† Matplotlib",
    "section": "9.3 Principi Fondamentali di Pyplot",
    "text": "9.3 Principi Fondamentali di Pyplot\nEsploriamo le funzionalit√† essenziali di pyplot di Matplotlib:\n\nCreazione di Grafici Lineari: Utilizzando plt.plot(x, y), √® possibile generare grafici lineari. Questa funzione necessita delle coordinate x e y per disegnare il grafico, semplificando cos√¨ la rappresentazione visiva dei dati.\nDenominazione degli Assi: √à fondamentale assegnare un‚Äôetichetta appropriata agli assi per migliorare la comprensione del grafico. Si possono denominare gli assi tramite plt.xlabel('Nome') per l‚Äôasse X e plt.ylabel('Nome') per l‚Äôasse Y, facilitando l‚Äôinterpretazione dei dati visualizzati.\nInserimento del Titolo: Un titolo descrittivo clarifica lo scopo o il contesto del grafico. Aggiungere un titolo √® semplice con plt.title('Titolo'), che aiuta a comunicare il messaggio principale del grafico in modo efficace.\nInserimento di Legende: Per grafici che includono pi√π serie di dati o elementi distinti, l‚Äôaggiunta di una legenda √® cruciale per la distinzione tra questi. La funzione plt.legend() permette di integrare una legenda, migliorando la leggibilit√† del grafico.\nEsposizione del Grafico: Una volta completata la composizione del grafico, il passo finale √® la sua visualizzazione. Attraverso plt.show(), √® possibile mostrare il grafico elaborato, offrendo una visione complessiva dei dati analizzati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "href": "chapters/python/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "title": "9¬† Matplotlib",
    "section": "9.4 Esempio 1: Grafico lineare semplice",
    "text": "9.4 Esempio 1: Grafico lineare semplice\n\nx = [1, 2, 3, 4]\ny = [10, 20, 30, 40]\n\nplt.plot(x, y)\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico Lineare Semplice\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "href": "chapters/python/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "title": "9¬† Matplotlib",
    "section": "9.5 Esempio 2: Grafico con legenda e stile",
    "text": "9.5 Esempio 2: Grafico con legenda e stile\n\nx = [1, 2, 3, 4]\ny1 = [10, 20, 30, 40]\ny2 = [5, 15, 25, 35]\n\nplt.plot(x, y1, label=\"Linea 1\", color=\"C0\", linestyle=\"--\")\nplt.plot(x, y2, label=\"Linea 2\", color=\"C3\", linestyle=\"-\")\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico con Legenda\")\nplt.legend();",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-3-istogramma",
    "href": "chapters/python/07_matplotlib.html#esempio-3-istogramma",
    "title": "9¬† Matplotlib",
    "section": "9.6 Esempio 3: Istogramma",
    "text": "9.6 Esempio 3: Istogramma\n\ndata = rng.normal(100, 15, 1000)\n\nplt.hist(data, bins=20)\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Istogramma\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-4-pannelli-multipli",
    "href": "chapters/python/07_matplotlib.html#esempio-4-pannelli-multipli",
    "title": "9¬† Matplotlib",
    "section": "9.7 Esempio 4: pannelli multipli",
    "text": "9.7 Esempio 4: pannelli multipli\nFacciamo un altro esempio usando i dati penguins.csv.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\n\n\nplt.figure(figsize=(9, 8))\n\nplt.subplot(2, 2, 1)\nplt.hist(df[\"bill_depth_mm\"], 10, density=True, color=\"C3\")\nplt.title(\"Bill depth (mm)\");\n\nplt.subplot(2, 2, 2)\nsns.kdeplot(df[\"bill_length_mm\"], fill=True)\nplt.title(\"KDE of Bill length (mm)\");\n\nplt.subplot(2, 2, 3)\nplt.scatter(x=df[\"bill_length_mm\"], y=df[\"bill_depth_mm\"], alpha=0.4)\nplt.title(\"Bill depth as a function of bill length\");\n\nplt.subplot(2, 2, 4)\nplt.boxplot(df[\"bill_length_mm\"])\nplt.title(\"Boxplot of Bill Length (mm)\")\n\nplt.tight_layout()\n\n/var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_55046/1324325854.py:19: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nGli indici in plt.subplot() sono utilizzati per specificare come dividere una figura in diverse aree di tracciamento, chiamate ‚Äúsubplots‚Äù. La funzione plt.subplot(nrows, ncols, index) prende tre argomenti principali:\n\nnrows: Numero di righe in cui la figura sar√† suddivisa.\nncols: Numero di colonne in cui la figura sar√† suddivisa.\nindex: Indice del subplot su cui operare, partendo dall‚Äôangolo in alto a sinistra e proseguendo da sinistra a destra e dall‚Äôalto in basso.\n\nNel codice precedente, plt.subplot(2, 2, 1) indica che la figura sar√† divisa in una griglia 2x2 (2 righe e 2 colonne) e che la funzione plt.hist() agir√† sul primo subplot, che si trover√† nell‚Äôangolo in alto a sinistra.\nGli altri indici (2, 3, 4) selezionano rispettivamente il secondo subplot (in alto a destra), il terzo subplot (in basso a sinistra) e il quarto subplot (in basso a destra) della griglia 2x2.\nEcco come i subplot sono organizzati sulla figura:\n+---------------------+----------------------+\n|  plt.subplot(2,2,1) |  plt.subplot(2,2,2)  |\n+---------------------+----------------------+\n|  plt.subplot(2,2,3) |  plt.subplot(2,2,4)  |\n+---------------------+----------------------+\nOgni volta che si chiama plt.subplot() con un nuovo indice, il ‚Äúcurrent axes‚Äù cambia per puntare al subplot specificato. Quindi, le funzioni di tracciamento come plt.hist(), sns.kdeplot(), plt.scatter() e plt.boxplot() saranno applicate al subplot attualmente selezionato.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "title": "9¬† Matplotlib",
    "section": "9.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "9.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\narviz     : 0.17.0\nmatplotlib: 3.8.2\npandas    : 2.1.4\nseaborn   : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html",
    "href": "chapters/python/08_seaborn.html",
    "title": "10¬† Seaborn",
    "section": "",
    "text": "10.1 Elevare la Visualizzazione dei Dati con Seaborn\nNel capitolo precedente, abbiamo esaminato Matplotlib, una libreria estremamente versatile per la visualizzazione dei dati in Python. Ora esamineremo le funzionalit√† di Seabonrn. Seaborn, che si basa su Matplotlib, arricchisce l‚Äôesperienza di visualizzazione dei dati offrendo una gamma pi√π ampia e specializzata di opzioni grafiche, particolarmente utili nel campo della data science.\nIl vero punto di forza di Seaborn √® la sua capacit√† di migliorare non solo l‚Äôaspetto estetico dei grafici ma anche di facilitare la creazione di visualizzazioni pi√π complesse. Questo rende il processo pi√π diretto e intuitivo. La libreria √® dotata di un‚Äôampia variet√† di strumenti, dalle mappe di calore ai grafici a violino, permettendo agli utenti di esplorare e rappresentare i dati in modi innovativi e informativi.\nPer chi vuole approfondire ulteriormente, i tutorial presenti sul sito ufficiale di Seaborn sono una risorsa preziosa e facilmente accessibile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#preparazione-del-notebook",
    "href": "chapters/python/08_seaborn.html#preparazione-del-notebook",
    "title": "10¬† Seaborn",
    "section": "10.2 Preparazione del Notebook",
    "text": "10.2 Preparazione del Notebook\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport arviz as az\n\n\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"seaborn\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "href": "chapters/python/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "title": "10¬† Seaborn",
    "section": "10.3 Visualizzare la distribuzione dei dati",
    "text": "10.3 Visualizzare la distribuzione dei dati\nVediamo alcuni esempi pratici per scoprire come Seaborn possa trasformare il modo in cui visualizziamo i dati.\nConsideriamo nuovamente i dati Palmer penguin.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nUna delle forme di visualizzazione pi√π comuni e informative nel campo dell‚Äôanalisi dei dati √® l‚Äôistogramma, e la sua variante pi√π sofisticata, l‚Äôistogramma lisciato. Vediamo dunque come generare istogrammi che, per il DataFrame df, sono stratificati sia in base alla specie che al genere dei pinguini.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n);\n\nGeneriamo la stessa figura usando questa volta gli istogrammi lisciati.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    height=3, kind=\"kde\", facet_kws=dict(margin_titles=True),\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "href": "chapters/python/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "title": "10¬† Seaborn",
    "section": "10.4 Visualizzazione di dati categoriali",
    "text": "10.4 Visualizzazione di dati categoriali\nConsideriamo ora il caso in cui si vuole rappresentare la relazione tra una variabile numerica e una o pi√π variabili categoriali.\nConsideriamo, ad esempio, la massa corporea in relazione alla specie, differenziando le osservazioni per genere. Creiamo il grafico utilizzando i boxplot.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"box\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\n\n\n\nDai diagrammi risulta evidente che i pinguini maschi hanno un peso maggiore rispetto alle femmine in tutte le specie, e che i pinguini Gentoo hanno un peso superiore rispetto ad Adelie e Chinstrap.\nCome alternativa, possiamo utilizzare il violinplot per la rappresentazione grafica dei dati.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"violin\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#relazioni-tra-variabili",
    "href": "chapters/python/08_seaborn.html#relazioni-tra-variabili",
    "title": "10¬† Seaborn",
    "section": "10.5 Relazioni tra variabili",
    "text": "10.5 Relazioni tra variabili\nCalcoliamo la correlazione tra le variabili.\n\nvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\ncorr_matrix = df[vars].corr().round(2)\ncorr_matrix\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.00\n-0.24\n0.66\n0.60\n\n\nbill_depth_mm\n-0.24\n1.00\n-0.58\n-0.47\n\n\nflipper_length_mm\n0.66\n-0.58\n1.00\n0.87\n\n\nbody_mass_g\n0.60\n-0.47\n0.87\n1.00\n\n\n\n\n\n\n\n\nQueste informazioni possono essere comunicate in forma pi√π diretta se usiamo una rappresentazione grafica.\n\nsns.heatmap(corr_matrix, annot=True, linecolor=\"white\", linewidths=5);\n\n\n\n\n\n\n\n\nLa lunghezza della pinna e la massa corporea mostrano un forte legame, con una correlazione di 0.87. Ci√≤ indica che i pinguini con pinne pi√π lunghe tendono a pesare di pi√π.\nDi seguito √® riportato un esempio di diagramma a dispersione che illustra questa relazione.\n\nsns.scatterplot(df, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\");\n\n\n\n\n\n\n\n\nEvidentemente, le osservazioni delle tre specie formano cluster distinti. Per ciascuna specie, la lunghezza e la larghezza del becco presentano un intervallo specifico.\nSpesso √® vantaggioso creare grafici separati in base a diverse dimensioni dei dati; nell‚Äôesempio seguente, suddividiamo i dati in base all‚Äôisola di appartenenza.\n\ng = sns.relplot(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    row=\"sex\",\n    col=\"island\",\n    height=3,\n    facet_kws=dict(margin_titles=True),\n)\ng.set_axis_labels(\n    \"Bill length (mm)\",\n    \"Bill depth (mm)\",\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "title": "10¬† Seaborn",
    "section": "10.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "10.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\narviz     : 0.18.0\npandas    : 2.2.2\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "11¬† Introduzione",
    "section": "",
    "text": "La data science √® un campo che si sviluppa all‚Äôintersezione tra la statistica e l‚Äôinformatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l‚Äôinformatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell‚Äôanalisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html",
    "href": "chapters/key_notions/01_key_notions.html",
    "title": "12¬† Concetti chiave",
    "section": "",
    "text": "Introduzione\nL‚Äôanalisi dei dati si colloca all‚Äôintersezione tra statistica, teoria della probabilit√† e informatica. Questa disciplina multidisciplinare richiede una solida comprensione dei concetti fondamentali provenienti da ciascuna di queste tre aree.\nLa statistica fornisce gli strumenti e le tecniche per raccogliere, analizzare e interpretare i dati. Attraverso metodi descrittivi e inferenziali, permette di trarre conclusioni dai dati e di prendere decisioni informate.\nLa statistica fornisce gli strumenti e le tecniche per raccogliere, analizzare e interpretare i dati. Attraverso metodi descrittivi e inferenziali, la statistica permette di trarre conclusioni dai dati e di prendere decisioni informate.\nLa teoria della probabilit√† costituisce la base matematica della statistica, modellando l‚Äôincertezza e comprendendo i fenomeni aleatori, fornendo i fondamenti per sviluppare metodi statistici rigorosi.\nL‚Äôinformatica gioca un ruolo cruciale nell‚Äôanalisi dei dati, offrendo gli strumenti necessari per la gestione, l‚Äôelaborazione e la visualizzazione dei dati su larga scala. Conoscere i principi dell‚Äôinformatica √® essenziale per sfruttare appieno tecnologie moderne come il machine learning e l‚Äôintelligenza artificiale. L‚Äôuso di linguaggi di programmazione come Python e R, insieme a librerie specializzate, permette di eseguire analisi complesse e di visualizzare i dati in modo efficace.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#introduzione",
    "href": "chapters/key_notions/01_key_notions.html#introduzione",
    "title": "12¬† Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine ‚Äústatistica‚Äù pu√≤ assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica √® una scienza e una disciplina che si occupa dello studio e dell‚Äôapplicazione di metodi e tecniche per la raccolta, l‚Äôorganizzazione, l‚Äôanalisi, l‚Äôinterpretazione e la presentazione di dati.\nNel secondo senso, il termine ‚Äústatistica‚Äù si riferisce a una singola misura o un valore numerico che √® stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/01_key_notions.html#popolazioni-e-campioni",
    "title": "12¬† Concetti chiave",
    "section": "12.1 Popolazioni e Campioni",
    "text": "12.1 Popolazioni e Campioni\nPer iniziare l‚Äôanalisi dei dati, √® fondamentale individuare le unit√† che contengono le informazioni rilevanti per il fenomeno di interesse. Questo insieme di unit√† costituisce la popolazione o universo, rappresentando l‚Äôinsieme completo di entit√† capaci di fornire informazioni per l‚Äôindagine statistica in questione. Le singole unit√† dell‚Äôinsieme sono chiamate unit√† statistiche.\nNella ricerca psicologica, sia nelle ricerche sperimentali che in quelle osservazionali, l‚Äôobiettivo principale √® studiare i fenomeni psicologici all‚Äôinterno di una specifica popolazione. √à essenziale definire con chiarezza la popolazione di interesse, ovvero l‚Äôinsieme di individui ai quali verranno applicati i risultati della ricerca. Tale popolazione pu√≤ essere reale, come tutte le persone sopravvissute per un anno dopo il bombardamento atomico di Hiroshima, o ipotetica, come tutte le persone depresse che potrebbero beneficiare di un intervento psicologico.\n\n12.1.1 Sotto-popolazioni e Campioni\nUna sotto-popolazione √® un sottoinsieme di individui che possiedono propriet√† specifiche ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione degli uomini di et√† inferiore ai 30 anni o dei pazienti depressi che hanno ricevuto uno specifico intervento psicologico. Il campione √® un sottoinsieme della popolazione composto da elementi che rappresentano unit√† statistiche (u.s.) portatrici delle informazioni rilevate tramite misurazione. Il campione viene utilizzato per ottenere informazioni sulla popolazione di riferimento.\n\n\n12.1.2 Metodi di Campionamento\nIl campionamento pu√≤ avvenire in diversi modi. Il campionamento casuale consente al ricercatore di trarre conclusioni sulla popolazione e di quantificare l‚Äôincertezza dei risultati, come avviene in un sondaggio. Tuttavia, esistono anche altre forme di campionamento, come il campione di convenienza o il campionamento stratificato.\nIl ricercatore deve sempre considerare la rappresentativit√† statistica del campione, ovvero se il campione scelto riflette accuratamente le caratteristiche di interesse della popolazione. In molti casi, soprattutto in psicologia, possono essere usati metodi di campionamento diversi dal casuale a seconda delle risorse disponibili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#i-bias-nella-raccolta-dati",
    "href": "chapters/key_notions/01_key_notions.html#i-bias-nella-raccolta-dati",
    "title": "12¬† Concetti chiave",
    "section": "12.2 I Bias nella Raccolta Dati",
    "text": "12.2 I Bias nella Raccolta Dati\n√à importante tenere presenti i bias che governano la raccolta dei dati. I dati non sono mai ‚Äúneutri‚Äù e il contenuto dei dati raccolti, insieme alle intenzioni che guidano la raccolta, spesso dettano i parametri della nostra comprensione (Nobles 2000).\nAd esempio, Johnson (2021) confronta due modalit√† di raccolta dati riguardanti le persone incarcerate negli Stati Uniti: quella statale e quella comunitaria. La raccolta dati statale si concentra su informazioni demografiche e statistiche di base, perpetuando una comprensione limitata e spesso distorta del sistema carcerario. Al contrario, la raccolta dati comunitaria include dettagli pi√π specifici sulle condizioni di vita e gli effetti della detenzione, offrendo una visione pi√π completa e umana della realt√† carceraria.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#variabili-e-costanti",
    "href": "chapters/key_notions/01_key_notions.html#variabili-e-costanti",
    "title": "12¬† Concetti chiave",
    "section": "12.3 Variabili e Costanti",
    "text": "12.3 Variabili e Costanti\nNell‚Äôanalisi statistica, le variabili denotano le caratteristiche che possono assumere diversi valori, sia numerici che categoriali. Le costanti, al contrario, sono valori che non variano tra le unit√† di osservazione. Le variabili indipendenti (o predittive) rappresentano i fattori che si ipotizza influenzino l‚Äôesito di interesse, mentre le variabili dipendenti rappresentano l‚Äôesito che si cerca di spiegare o prevedere.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#effetto",
    "href": "chapters/key_notions/01_key_notions.html#effetto",
    "title": "12¬† Concetti chiave",
    "section": "12.4 Effetto",
    "text": "12.4 Effetto\nIl concetto di ‚Äúeffetto‚Äù misura il cambiamento o l‚Äôinfluenza tra le variabili. Ad esempio, consideriamo uno studio che indaga l‚Äôeffetto delle mnemotecniche sul miglioramento della memoria. Se il gruppo che ha seguito un workshop mnemonico mostra un punteggio medio superiore, si pu√≤ affermare che le mnemotecniche hanno un effetto positivo sulla memoria. L‚Äôeffetto viene misurato attraverso diverse statistiche, come la differenza di medie o il rapporto di probabilit√† (Huntington-Klein 2021).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#variabili-casuali",
    "href": "chapters/key_notions/01_key_notions.html#variabili-casuali",
    "title": "12¬† Concetti chiave",
    "section": "12.5 Variabili Casuali",
    "text": "12.5 Variabili Casuali\nNel contesto della teoria delle probabilit√†, una variabile casuale rappresenta una quantit√† che pu√≤ assumere diversi valori con una certa probabilit√†. Dopo l‚Äôosservazione e la misurazione, una variabile casuale diventa una variabile statistica, trasformando un‚Äôincertezza teorica in una certezza empirica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#stima-e-inferenza",
    "href": "chapters/key_notions/01_key_notions.html#stima-e-inferenza",
    "title": "12¬† Concetti chiave",
    "section": "12.6 Stima e Inferenza",
    "text": "12.6 Stima e Inferenza\n\n12.6.1 Stima\nLa stima statistica permette di dedurre le caratteristiche di un‚Äôintera popolazione partendo dall‚Äôanalisi di un campione rappresentativo. Gli elementi chiave della stima statistica sono i seguenti.\n\nParametri della popolazione:\n\nsono le caratteristiche numeriche che descrivono la popolazione;\nesempi includono la media (Œº), la varianza (œÉ¬≤), la proporzione (p), ecc.;\ngeneralmente non sono noti e devono essere stimati.\n\nStatistiche campionarie:\n\nsono calcolate dai dati del campione;\nfungono da stimatori dei parametri della popolazione;\nesempi: media campionaria (xÃÑ), varianza campionaria (s¬≤), proporzione campionaria (pÃÇ).\n\nTipi di stime:\n\npuntuale: fornisce un singolo valore come miglior stima del parametro;\nintervallare: offre un range di valori plausibili per il parametro, con un certo livello di credibilit√† o confidenza.\n\nPropriet√† degli stimatori:\n\nconsistenza: la stima converge al vero valore del parametro all‚Äôaumentare della dimensione del campione;\nnon distorsione: il valore atteso dello stimatore √® uguale al vero valore del parametro;\nefficienza: lo stimatore ha la minor varianza possibile.\n\n\nL‚Äôaccuratezza della stima dipende da vari fattori, tra cui la dimensione e la rappresentativit√† del campione, la variabilit√† nella popolazione e il metodo di campionamento utilizzato.\n\n\n12.6.2 Inferenza Statistica\nDopo aver ottenuto queste stime, si passa al passaggio successivo: l‚Äôinferenza statistica. Questo processo va oltre la semplice stima e ci permette di trarre conclusioni pi√π ampie sulla popolazione. L‚Äôinferenza statistica riguarda la valutazione di specifiche ipotesi o risposte a domande di ricerca relative alla popolazione, utilizzando le stime ottenute dal campione.\nAd esempio, se abbiamo stimato la media dei redditi in un campione di famiglie, possiamo utilizzare l‚Äôinferenza statistica per testare se c‚Äô√® una differenza significativa nei redditi tra diverse regioni o gruppi demografici all‚Äôinterno della popolazione. In questo modo, l‚Äôinferenza statistica ci fornisce gli strumenti per fare previsioni e trarre conclusioni riguardanti la popolazione intera.\nEsistono vari approcci e metodologie per condurre l‚Äôinferenza statistica, tra cui due dei pi√π comuni sono l‚Äôinferenza bayesiana e l‚Äôapproccio frequentista.\nL‚Äôinferenza bayesiana:\n\nsi fonda sul teorema di Bayes;\nutilizza probabilit√† a priori, che rappresentano le conoscenze o le credenze iniziali su un fenomeno;\naggiorna queste probabilit√† con nuovi dati per ottenere probabilit√† a posteriori;\noffre una interpretazione diretta delle probabilit√† come gradi di credenza.\n\nL‚Äôapproccio frequentista:\n\nsi basa sulla frequenza relativa di eventi in esperimenti ripetuti;\nutilizza tecniche come il test dell‚Äôipotesi nulla e gli intervalli di confidenza;\nnon fa uso di probabilit√† a priori.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "title": "12¬† Concetti chiave",
    "section": "12.7 Modelli Psicologici",
    "text": "12.7 Modelli Psicologici\nUn ‚Äúmodello‚Äù rappresenta una formulazione matematica semplificata di un fenomeno reale che si desidera studiare. Si tratta di un insieme di equazioni e ipotesi che delineano la struttura probabilistica e le relazioni tra le variabili, cercando di catturare gli aspetti essenziali del fenomeno senza rappresentarlo in ogni dettaglio. Poich√© spesso esistono diversi modelli che possono essere applicati allo stesso problema, la data science si occupa dell‚Äôidentificazione del modello che meglio si adatta ai dati e che soddisfa specifici criteri di validit√† e accuratezza.\nI modelli psicologici sono strumenti concettuali utilizzati per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello psicologico robusto e valido deve soddisfare diverse caratteristiche essenziali:\n\nCoerenza descrittiva: Il modello deve fornire una rappresentazione logica e internamente coerente del fenomeno studiato. Deve catturare gli elementi essenziali del processo psicologico in esame, offrendo una struttura concettuale che organizzi le osservazioni in modo significativo e comprensibile.\nCapacit√† predittiva: Un aspetto cruciale di un modello psicologico efficace √® la sua abilit√† di formulare predizioni accurate sulle manifestazioni future del fenomeno. Questa caratteristica non solo aumenta l‚Äôutilit√† pratica del modello, ma fornisce anche un mezzo per testarne la validit√†.\nSupporto empirico: Il modello deve essere ancorato a solide prove empiriche. Ci√≤ implica che le sue assunzioni e previsioni devono essere confermate da dati osservabili raccolti attraverso ricerche sistematiche e metodologicamente rigorose.\nFalsificabilit√†: Forse la caratteristica pi√π critica, la falsificabilit√†, richiede che il modello sia costruito in modo da poter essere sottoposto a verifica o confutazione attraverso l‚Äôosservazione e l‚Äôesperimento. Questo principio, fondamentale per il metodo scientifico, assicura che il modello rimanga aperto al scrutinio critico e alla revisione basata su nuove evidenze.\nParsimonia: Un buon modello psicologico dovrebbe essere parsimonioso. Dovrebbe spiegare il fenomeno nel modo pi√π semplice possibile, evitando complessit√† non necessarie.\nGeneralizzabilit√†: Il modello dovrebbe essere applicabile a una vasta gamma di situazioni e contesti, non solo a specifici casi o condizioni sperimentali.\nUtilit√† pratica: Infine, un modello psicologico efficace dovrebbe avere implicazioni pratiche, fornendo insights utili per interventi, terapie o applicazioni nel mondo reale.\n\nLa modellazione in psicologia si trova spesso di fronte a sfide uniche dovute alla natura soggettiva e variabile dell‚Äôesperienza umana. I ricercatori devono bilanciare la necessit√† di precisione scientifica con la flessibilit√† richiesta per catturare la ricchezza e la complessit√† dei fenomeni psicologici. Inoltre, devono essere consapevoli dei limiti etici nella sperimentazione e delle potenziali implicazioni sociali dei loro modelli.\nLa creazione e l‚Äôutilizzo di modelli in psicologia √® un processo dinamico e iterativo. I modelli sono costantemente raffinati, testati e, se necessario, rivisti o sostituiti man mano che emergono nuove evidenze.\nL‚Äôanalisi dei dati, attraverso l‚Äôapplicazione di tecniche statistiche, √® il mezzo attraverso il quale un modello psicologico viene valutato. Oltre a determinare se il modello √® in grado di spiegare i dati osservati, l‚Äôanalisi pu√≤ anche verificare la capacit√† del modello di fare previsioni accurate su dati non ancora osservati. In questo modo, la modellazione diventa uno strumento potente non solo per comprendere i fenomeni psicologici ma anche per prevedere e, in alcuni casi, influenzare il comportamento e le dinamiche mentali.\nIn sintesi, un modello, sia in statistica che in psicologia, √® uno strumento teorico che cerca di rappresentare un fenomeno complesso in una forma semplificata ma informativa, guidando la comprensione, la previsione e, in ultima analisi, l‚Äôintervento efficace su quel fenomeno. La scelta e la valutazione del modello giusto sono fondamentali per garantire che le conclusioni derivanti dall‚Äôanalisi siano valide e utili nel contesto specifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/key_notions/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "title": "12¬† Concetti chiave",
    "section": "12.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "12.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHuntington-Klein, Nick. 2021. The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, Kaneesha R. 2021. ¬´Two regimes of prison data collection¬ª. Harvard Data Science Review 3 (3): 10‚Äì1162.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nNobles, Melissa. 2000. Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html",
    "href": "chapters/key_notions/02_measurement.html",
    "title": "13¬† La misurazione in psicologia",
    "section": "",
    "text": "13.1 Introduzione\nIn questo capitolo verranno introdotte alcune nozioni di base relative ai temi della misurazione quantitativa delle caratteristiche psicologiche. Verr√† presentata la teoria delle scale di misura di Stevens (1946), ma prima di procedere, √® indispensabile leggere l‚ÄôAppendice G.\nIl problema dello scaling psicologico riguarda la trasformazione dei dati osservati in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche misurate. Quando conduciamo ricerche in psicologia, spesso vogliamo assegnare numeri ai comportamenti o alle risposte degli individui per analizzarli in modo oggettivo. Tuttavia, questa trasformazione √® complessa e richiede attenzione a diverse considerazioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#introduzione",
    "href": "chapters/key_notions/02_measurement.html#introduzione",
    "title": "13¬† La misurazione in psicologia",
    "section": "",
    "text": "13.1.1 Scaling di Guttman\nUno dei metodi di scaling pi√π noti √® il ¬´Scaling di Guttman¬ª, utilizzato per rappresentare relazioni ordinate tra elementi di una scala. Per esempio, in un questionario sui sintomi di ansia, le domande sono ordinate per intensit√† crescente. Se un partecipante risponde ‚Äús√¨‚Äù a una domanda pi√π intensa, dovrebbe aver risposto ‚Äús√¨‚Äù anche a tutte le domande meno intense precedenti, creando una scala ordinata di gravit√† dei sintomi.\n\n\n13.1.2 Scaling Thurstoniano\nLo ¬´Scaling Thurstoniano¬ª misura le preferenze o i giudizi soggettivi. Ad esempio, per valutare la preferenza per diversi tipi di cibi, i partecipanti confrontano due cibi alla volta e esprimono una preferenza. Queste risposte vengono usate per assegnare punteggi basati sulla preferenza media.\n\n\n13.1.3 Questionari Likert\nI questionari Likert richiedono ai partecipanti di esprimere il grado di accordo con affermazioni su una scala a pi√π livelli (da ¬´fortemente in disaccordo¬ª a ¬´fortemente d‚Äôaccordo¬ª). I punteggi ottenuti vengono sommati per rappresentare la posizione dell‚Äôindividuo rispetto all‚Äôoggetto di studio.\n\n\n13.1.4 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le propriet√† delle scale psicologiche, si utilizzano vari metodi. Ad esempio, l‚Äôaffidabilit√† delle misure pu√≤ essere analizzata con il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, che misurano la coerenza interna delle risposte ai vari item del questionario. Inoltre, la validit√† delle scale pu√≤ essere esaminata confrontando i risultati con misure simili o utilizzando analisi statistiche per verificare se la scala cattura accuratamente il costrutto che si intende misurare. La validit√† di costrutto √® cruciale, poich√© riguarda la capacit√† della scala di misurare effettivamente il concetto psicologico che si intende esaminare.\n\n\n13.1.5 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si √® arricchito di nuove prospettive, grazie all‚Äôavvento di tecnologie avanzate e all‚Äôintegrazione di approcci interdisciplinari. Ecco alcune delle tendenze pi√π rilevanti:\n\n13.1.5.1 Teoria della Risposta agli Item (IRT)\nLa Teoria della Risposta agli Item (IRT) ha guadagnato popolarit√† per la sua capacit√† di fornire stime pi√π precise delle abilit√† latenti rispetto ai modelli classici. La IRT considera la probabilit√† che un individuo risponda correttamente a un item in funzione della sua abilit√† e delle caratteristiche dell‚Äôitem stesso, offrendo una visione pi√π dettagliata delle propriet√† psicometriche degli strumenti di misurazione.\n\n\n13.1.5.2 Approcci Bayesiani\nGli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessit√† e l‚Äôincertezza inerenti alla misurazione psicologica.\n\n\n13.1.5.3 Analisi di Rete\nL‚Äôanalisi di rete √® un‚Äôaltra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio pu√≤ offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "title": "13¬† La misurazione in psicologia",
    "section": "13.2 Le scale di misurazione",
    "text": "13.2 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le propriet√† psicologiche. La teoria delle scale di Stevens {cite:p}stevens_46 identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poich√© ciascuna di esse √® in grado di ‚Äúcatturare‚Äù solo alcune delle propriet√† dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n13.2.1 Scala nominale\nILa scala nominale √® il livello di misurazione pi√π semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica √® uguale o diversa da un‚Äôaltra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unit√† di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL‚Äôunica operazione algebrica consentita dalla scala nominale √® quella di contare le unit√† di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale √® possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unit√† di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n13.2.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unit√† di misura all‚Äôinterno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) √® uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale √® quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed √® scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto √® considerato pi√π duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearit√† della scala di Mohs (Burchard, 2004).\n\n\n\n\n13.2.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le propriet√† della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unit√† statistiche in termini di un intervallo costante, chiamato ‚Äúunit√† di misura‚Äù, a cui viene attribuito il valore ‚Äú1‚Äù. L‚Äôorigine della scala, ovvero il punto zero, √® scelta arbitrariamente e non indica l‚Äôassenza della propriet√† che si sta misurando. Ci√≤ significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all‚Äôunit√† statistica in cui la propriet√† risulta assente.\nLa scala ad intervalli equivalenti consente l‚Äôesecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli √® che non consente di calcolare il rapporto tra coppie di misure. √à possibile affermare la differenza tra \\(a\\) e \\(b\\) come la met√† della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non √® possibile affermare che \\(a\\) abbia una propriet√† misurata in quantit√† doppia rispetto a \\(b\\). In altre parole, non √® possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalit√† permettono tutte le operazioni aritmetiche, come la somma, l‚Äôelevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l‚Äôunit√† di misura √® arbitraria e pu√≤ essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l‚Äôaggiunta di una costante a tutti i valori della scala, √® ammessa poich√© non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l‚Äôuguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli √® la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, √® possibile stabilire se due modalit√† sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale √® possibile mettere due modalit√† in una relazione d‚Äôordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, per√≤, √® possibile definire una unit√† di misura per cui √® possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c‚Äô√® una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l‚Äôintensit√† del fenomeno, godono della propriet√† che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli √® quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non √® il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione ‚Äúil doppio di‚Äù che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla propriet√† misurata (cio√® la temperatura). La decisione di che scala usare (Centigrada vs.¬†Fahrenheit) √® arbitraria. Ma questa arbitrariet√† non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realt√† empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l‚Äôaspetto invariante di una trasformazione lineare, ovvero l‚Äôuguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\n√à facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall‚Äôunit√† di misura che √® stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n13.2.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non √® arbitrario e rappresenta l‚Äôelemento che ha intensit√† nulla rispetto alla propriet√† misurata. Per costruire questa scala, si associa il numero 0 all‚Äôelemento con intensit√† nulla e si sceglie un‚Äôunit√† di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall‚Äôorigine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensit√† della propriet√† misurata.\nIn questa scala, √® possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L‚Äôunica scelta arbitraria √® l‚Äôunit√† di misura, ma lo zero deve sempre rappresentare l‚Äôintensit√† nulla della propriet√† considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarit√† e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "13¬† La misurazione in psicologia",
    "section": "13.3 Gerarchia dei livelli delle scale di misurazione",
    "text": "13.3 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati ‚Äúlivelli di scala‚Äù. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello pi√π basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello pi√π alto. - La scala nominale √® il livello pi√π elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine. - Al livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualit√† o caratteristica. Qui, √® possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non √® possibile quantificare la differenza tra di esse in modo preciso. - La scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse √® quantificabile in modo preciso. In questa scala, √® possibile effettuare operazioni matematiche come l‚Äôaddizione e la sottrazione tra i valori, ma non √® possibile stabilire un vero e proprio punto zero significativo. - Infine, la scala a rapporti equivalenti rappresenta il livello pi√π alto. In questa scala, le categorie sono ordinate, la differenza tra di esse √® quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l‚Äôassenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\nPassando da un livello di misurazione ad uno pi√π alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ci√≤ che riguarda le trasformazioni ammissibili, pi√π il livello di scala √® basso, pi√π le funzioni sono generali (sono minori cio√® i vincoli per passare da una rappresentazione numerica ad un‚Äôaltra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa pi√π restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "title": "13¬† La misurazione in psicologia",
    "section": "13.4 Variabili discrete o continue",
    "text": "13.4 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nLe variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l‚Äôelenco dei valori accettabili √® stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti.\nD‚Äôaltra parte, le variabili continue possono assumere qualsiasi valore all‚Äôinterno di un intervallo specificato. Teoricamente, ci√≤ significa che √® possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "13¬† La misurazione in psicologia",
    "section": "13.5 Comprendere gli errori nella misurazione",
    "text": "13.5 Comprendere gli errori nella misurazione\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\n\n13.5.1 Precisione e Accuratezza\nLa precisione indica la coerenza tra misurazioni ripetute, mentre l‚Äôaccuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l‚Äôassessment psicometrico.\nUtilizzando l‚Äôanalogia del tiro al bersaglio, si pu√≤ avere una serie di colpi vicini tra loro ma lontani dal centro (precisione senza accuratezza) oppure colpi distribuiti in modo sparso ma in media vicini al centro (accuratezza senza precisione).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "href": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "title": "13¬† La misurazione in psicologia",
    "section": "13.6 Assessment psicometrico",
    "text": "13.6 Assessment psicometrico\nL‚Äôassessment psicometrico valuta la qualit√† delle misurazioni psicologiche, considerando la validit√† e l‚Äôaffidabilit√†.\n\n13.6.1 Validit√† nella Misurazione Psicologica\nLa validit√† √® una propriet√† psicometrica fondamentale dei test psicologici. Secondo gli Standards for Educational and Psychological Testing (2014), la validit√† si riferisce al grado in cui evidenza e teoria supportano le interpretazioni dei punteggi dei test per gli usi proposti. Questo concetto evidenzia che la validit√† riguarda sia il significato dei punteggi sia il loro utilizzo, rendendola ‚Äúla considerazione pi√π fondamentale nello sviluppo e nella valutazione dei test‚Äù.\n\n\n13.6.2 Evoluzione del Concetto di Validit√†\nTradizionalmente, la validit√† era suddivisa in tre categorie:\n\nValidit√† di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell‚Äôattributo psicologico che il test intende misurare. √à importante che gli item siano pertinenti e rappresentativi dell‚Äôattributo misurato.\nValidit√† di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validit√† concorrente e predittiva.\nValidit√† di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validit√† convergente (accordo con strumenti che misurano lo stesso costrutto) e validit√† divergente (capacit√† di discriminare tra costrutti diversi).\n\nLa moderna teoria della validit√† non adotta pi√π questa visione tripartita. Gli Standards del 2014 descrivono la validit√† come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l‚Äôinterpretazione dei punteggi del test per il loro utilizzo previsto.\n\n\n13.6.3 Tipologie di Prove di Validit√†\nGli Standards del 2014 identificano cinque categorie principali di prove di validit√†:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L‚Äôanalisi fattoriale √® uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validit√† convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell‚Äôuso del test, sia intenzionali che non intenzionali.\n\n\n\n13.6.4 Minacce alla Validit√†\nLa validit√† pu√≤ essere compromessa quando un test non misura integralmente il costrutto di interesse (sotto-rappresentazione del costrutto) o quando include varianza estranea al costrutto. Inoltre, fattori esterni come l‚Äôansia o la bassa motivazione degli esaminandi, e deviazioni nelle procedure di amministrazione e valutazione, possono influenzare negativamente la validit√† delle interpretazioni dei risultati.\n\n\n13.6.5 Integrazione delle Prove di Validit√†\nLa validit√† di un test si costruisce attraverso l‚Äôintegrazione di diverse linee di evidenza. Ogni interpretazione o uso di un test deve essere validato specificamente, richiedendo una valutazione continua e accurata delle prove disponibili. Questo processo implica la costruzione di un argomento di validit√† che consideri attentamente la qualit√† tecnica del test e l‚Äôadeguatezza delle sue interpretazioni per gli scopi previsti.\nIn conclusione, la validit√† √® un concetto complesso e integrato che richiede un‚Äôanalisi continua e multidimensionale delle evidenze. La moderna teoria della validit√† enfatizza l‚Äôimportanza di considerare diverse forme di evidenza per supportare le interpretazioni dei punteggi dei test, garantendo che siano utilizzati in modo appropriato e significativo. Gli sviluppatori e gli utilizzatori di test devono impegnarsi a valutare costantemente la validit√† per assicurare misurazioni psicologiche accurate e affidabili.\n\n\n13.6.6 Affidabilit√†\nL‚Äôaffidabilit√† concerne la consistenza e stabilit√† delle misurazioni, verificata attraverso metodi come l‚Äôaffidabilit√† test-retest, inter-rater, intra-rater e l‚Äôaffidabilit√† interna.\n\nAffidabilit√† Test-Retest: Questa forma di affidabilit√† verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilit√† Inter-rater: In questo caso, l‚Äôaffidabilit√† √® determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se pi√π psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilit√† Intra-rater: Questa misura dell‚Äôaffidabilit√† si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilit√† Interna: Si riferisce alla coerenza delle risposte all‚Äôinterno dello stesso test. Ad esempio, se un test misura un costrutto come l‚Äôansia, gli item che misurano l‚Äôansia dovrebbero correlare positivamente l‚Äôuno con l‚Äôaltro. Un modo comune per valutare l‚Äôaffidabilit√† interna √® utilizzare il coefficiente \\(\\omega\\) di McDonald.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "href": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "title": "13¬† La misurazione in psicologia",
    "section": "13.7 Commenti e considerazioni finali",
    "text": "13.7 Commenti e considerazioni finali\nLa teoria della misurazione √® fondamentale nella ricerca empirica per valutare l‚Äôattendibilit√† e la validit√† delle misurazioni. √à cruciale valutare l‚Äôerrore nella misurazione per garantire la precisione e l‚Äôaccuratezza delle misure. L‚Äôassessment psicometrico si occupa di valutare la qualit√† delle misurazioni psicologiche, considerando l‚Äôaffidabilit√† e la validit√† per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre pi√π raffinati per la comprensione delle caratteristiche psicologiche.\n\n\n\n\nLilienfeld, Scott O, e Adele N Strother. 2020. ¬´Psychological measurement and the replication crisis: Four sacred cows.¬ª Canadian Psychology/Psychologie Canadienne 61 (4): 281‚Äì288.\n\n\nMaul, Andrew, David Torres Irribarra, e Mark Wilson. 2016. ¬´On the philosophical foundations of psychological measurement¬ª. Measurement 79: 311‚Äì20.\n\n\nStevens, Stanley Smith. 1946. ¬´On the theory of scales of measurement¬ª. Science 103 (2684): 677‚Äì80.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html",
    "href": "chapters/key_notions/03_data_analysis.html",
    "title": "14¬† L‚Äôanalisi dei dati psicologici",
    "section": "",
    "text": "Introduzione\nNel panorama contemporaneo delle scienze sociali e della psicologia, gli ultimi due decenni hanno visto l‚Äôemergere di una profonda trasformazione metodologica ed epistemologica. Questo movimento, caratterizzato da concetti chiave quali ‚ÄúCredibility Revolution‚Äù (Angrist e Pischke 2010), ‚ÄúCausal Revolution‚Äù (Pearl e Mackenzie 2018) e ‚ÄúReplication Crisis‚Äù (Collaboration 2015), ha determinato un cambiamento paradigmatico nelle pratiche delle scienze sociali e, in particolare, della psicologia (Korbmacher et al. 2023). Questa transizione verso quella che Munger (2023) definisce ‚ÄúScience versione 2‚Äù √® stata motivata dalle lacune metodologiche precedenti e ha catalizzato l‚Äôadozione di approcci pi√π rigorosi e replicabili.\nLa genesi di questa Riforma √® radicata nella constatazione di problematiche metodologiche pervasive, tra cui la proliferazione di falsi positivi (Simmons, Nelson, e Simonsohn 2011), l‚Äôabuso dei ‚Äúgradi di libert√† dei ricercatori‚Äù (Gelman e Loken 2013), e l‚Äôinadeguatezza delle pratiche statistiche tradizionali (Gelman e Loken 2014). Fenomeni come il p-hacking, l‚Äôuso di campioni sottodimensionati (Button et al. 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilit√† delle scoperte psicologiche (Ioannidis 2005; Meehl 1967), portando alla cosiddetta ‚ÄúReplication Crisis‚Äù (Baker 2016; Bishop 2019) ‚Äì si veda il Capitolo 83.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "title": "14¬† L‚Äôanalisi dei dati psicologici",
    "section": "14.1 L‚ÄôApproccio Bayesiano",
    "text": "14.1 L‚ÄôApproccio Bayesiano\nIn risposta a queste sfide, l‚Äôapproccio bayesiano √® emerso come un paradigma statistico fondamentale nella ‚ÄúCredibility Revolution‚Äù. Contrariamente all‚Äôinferenza frequentista basata sul Test dell‚ÄôIpotesi Nulla, la statistica bayesiana offre un framework pi√π flessibile e intuitivo per l‚Äôanalisi dei dati e l‚Äôinferenza causale. Il principio cardine dell‚Äôapproccio bayesiano, l‚Äôaggiornamento delle distribuzioni di probabilit√† a priori (priors) alla luce di nuove evidenze, si allinea perfettamente con l‚Äôobiettivo di una scienza cumulativa e auto-correttiva.\nL‚Äôadozione di metodi bayesiani in psicologia comporta diversi vantaggi significativi:\n\nQuantificazione dell‚Äôincertezza: L‚Äôinferenza bayesiana fornisce distribuzioni di probabilit√† posteriori complete per i parametri di interesse, offrendo una rappresentazione pi√π ricca e sfumata dell‚Äôincertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane consentono l‚Äôintegrazione formale di conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poich√© l‚Äôinferenza si basa sull‚Äôintera distribuzione posteriore piuttosto che su soglie arbitrarie di significativit√†.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "href": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "title": "14¬† L‚Äôanalisi dei dati psicologici",
    "section": "14.2 Modellazione Formale",
    "text": "14.2 Modellazione Formale\nLa ‚ÄúCredibility Revolution‚Äù ha catalizzato l‚Äôintegrazione della Data Science nelle pratiche di ricerca psicologica. L‚Äôadozione di pipeline di analisi dei dati riproducibili, l‚Äôuso di controllo di versione, e la condivisione di dati e codice sono diventati standard de facto nella comunit√† scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilit√† della ricerca, ma facilitano anche la collaborazione e l‚Äôaccumulo di conoscenze nel campo.\nParallelamente, si √® osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer e Lewandowsky 2019; Van Dongen et al. 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, che era tipica della pratica dominante dell‚ÄôANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l‚Äôincorporazione di incertezza parametrica, e la valutazione dell‚Äôevidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l‚Äôanalisi di sensibilit√†, i ricercatori possono valutare rigorosamente la plausibilit√† relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "title": "14¬† L‚Äôanalisi dei dati psicologici",
    "section": "14.3 Riflessioni Epistemologiche",
    "text": "14.3 Riflessioni Epistemologiche\nL‚Äôadozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box\n\ntutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL‚Äôapproccio bayesiano, con la sua enfasi sull‚Äôaggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verit√† assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l‚Äôutilit√† euristica e predittiva (si veda la discussione nella Sezione 27.5).\nIn particolare, McElreath (2020) sottolinea l‚Äôimportanza di riconoscere la dualit√† tra il ‚Äúmondo del modello‚Äù e il mondo reale pi√π ampio che cerchiamo di comprendere. Questa consapevolezza √® cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#conclusione",
    "href": "chapters/key_notions/03_data_analysis.html#conclusione",
    "title": "14¬† L‚Äôanalisi dei dati psicologici",
    "section": "14.4 Conclusione",
    "text": "14.4 Conclusione\nL‚Äôintegrazione dell‚Äôapproccio bayesiano e della data science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla ‚ÄúReplication Crisis‚Äù. Offrendo un framework coerente per la modellazione formale, l‚Äôinferenza statistica e l‚Äôincorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilit√† della ricerca psicologica. Tuttavia, √® fondamentale che l‚Äôadozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica ‚Äì si veda, ad esempio, il Capitolo 62.\n\n\n\n\nAngrist, Joshua D, e J√∂rn-Steffen Pischke. 2010. ¬´The credibility revolution in empirical economics: How better research design is taking the con out of econometrics¬ª. Journal of economic perspectives 24 (2): 3‚Äì30.\n\n\nBaker, Monya. 2016. ¬´1,500 scientists lift the lid on reproducibility¬ª. Nature 533 (7604).\n\n\nBishop, Dorothy. 2019. ¬´The psychology of experimental psychologists: Overcoming cognitive constraints to improve research¬ª.\n\n\nButton, Katherine S, John PA Ioannidis, Claire Mokrysz, Brian A Nosek, Jonathan Flint, Emma SJ Robinson, e Marcus R Munaf√≤. 2013. ¬´Power failure: why small sample size undermines the reliability of neuroscience¬ª. Nature Reviews Neuroscience 14 (5): 365‚Äì76.\n\n\nCollaboration, Open Science. 2015. ¬´Estimating the reproducibility of psychological science¬ª. Science 349 (6251): aac4716.\n\n\nGelman, Andrew, e Eric Loken. 2013. ¬´The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ‚Äúfishing expedition‚Äù or ‚Äúp-hacking‚Äù and the research hypothesis was posited ahead of time¬ª. Department of Statistics, Columbia University 348 (1-17): 3.\n\n\n‚Äî‚Äî‚Äî. 2014. ¬´The statistical crisis in science¬ª. American scientist 102 (6): 460‚Äì65.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nKorbmacher, Max, Flavio Azevedo, Charlotte R Pennington, Helena Hartmann, Madeleine Pownall, Kathleen Schmidt, Mahmoud Elsherif, et al. 2023. ¬´The replication crisis has led to positive structural, procedural, and community changes¬ª. Communications Psychology 1 (1): 3.\n\n\nLabatut, Benjamƒ±ÃÅn. 2021. Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nMeehl, Paul E. 1967. ¬´Theory-testing in psychology and physics: A methodological paradox¬ª. Philosophy of science 34 (2): 103‚Äì15.\n\n\nMunger, Kevin. 2023. ¬´Temporal validity as meta-science¬ª. Research & Politics 10 (3): 20531680231187271.\n\n\nOberauer, Klaus, e Stephan Lewandowsky. 2019. ¬´Addressing the theory crisis in psychology¬ª. Psychonomic bulletin & review 26: 1596‚Äì1618.\n\n\nPearl, Judea, e Dana Mackenzie. 2018. The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, Joseph P, Leif D Nelson, e Uri Simonsohn. 2011. ¬´False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant¬ª. Psychological science 22 (11): 1359‚Äì66.\n\n\nVan Dongen, Noah, Riet van Bork, Adam Finnemann, Jonas Haslbeck, Han LJ van der Maas, Donald J Robinaugh, Jill de Ron, Jan Sprenger, e Denny Borsboom. 2024. ¬´Productive explanation: A framework for evaluating explanations in psychological science.¬ª Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "15¬† Introduzione",
    "section": "",
    "text": "L‚Äôanalisi esplorativa dei dati rappresenta la prima fase di un progetto di analisi dei dati. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica descrittiva. Oltre alle definizioni teoriche, verranno fornite istruzioni in Python per condurre analisi statistiche su dati reali. Il capitolo si concluder√† con alcune considerazioni sui limiti di un approccio epistemologico basato esclusivamente sull‚Äôanalisi delle associazioni tra variabili, sottolineando l‚Äôimportanza dello studio delle cause dei fenomeni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "16.1 Introduzione\nSecondo Yu e Barter (2024), ogni progetto di analisi dei dati segue una combinazione delle seguenti fasi:\nMentre quasi tutti i progetti di data science attraversano le fasi 1-2 e 4-5, non tutti includono la fase 3.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#introduzione",
    "href": "chapters/eda/01_project_structure.html#introduzione",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "Formulazione del problema e raccolta dei dati.\nPulizia dei dati, preprocessing e analisi esplorativa.\nAnalisi predittiva e/o inferenziale.\nValutazione dei risultati.\nComunicazione dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-1-formulazione-del-problema-e-raccolta-dei-dati",
    "href": "chapters/eda/01_project_structure.html#fase-1-formulazione-del-problema-e-raccolta-dei-dati",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "16.2 Fase 1: Formulazione del Problema e Raccolta dei Dati",
    "text": "16.2 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa prima fase del ciclo di vita di un progetto di data science (DSLC) implica la formulazione di una domanda di ricerca che possa essere risolta utilizzando i dati disponibili. Questo potrebbe sembrare semplice, ma spesso la domanda iniziale √® troppo vaga o non risolvibile. L‚Äôobiettivo √® riformulare la domanda in modo tale che possa trovare una risposta utilizzando i dati a disposizione.\n\n16.2.1 Raccolta dei Dati\nAlcuni progetti utilizzano dati esistenti (da repository pubblici, database interni o esperimenti passati), mentre altri richiedono la raccolta di nuovi dati. Ogni volta che √® possibile, √® necessario avere ben chiaro quali analisi statistiche verranno svolte prima di aver raccolto i dati. Se questo non viene fatto, pu√≤ succedere che i dati raccolti non siano adeguati per rispondere alle domande di interesse, in quanto mancano informazioni cruciali, o vengono violate assunzioni richieste dai modelli statistici che si vogliono impiegare.\n√à importante sviluppare una comprensione dettagliata di come i dati sono stati raccolti e cosa significano i valori al loro interno. √à altrettanto importante essere consapevoli degli strumenti e delle procedure utilizzate per la raccolta dei dati.\n\n\n16.2.2 Terminologia dei Dati\nOgni colonna di una tabella di dati (spesso chiamata semplicemente ‚Äúdati‚Äù o ‚Äúdataset‚Äù) corrisponde a un diverso tipo di misurazione e viene denominata variabile, caratteristica, attributo o covariata dei dati.\nOgni variabile in un dataset ha tipicamente uno dei seguenti tipi:\n\nNumerica: Un valore continuo (ad es. l‚Äôimporto di spesa), una durata (ad es. il numero di secondi che un paziente pu√≤ stare in equilibrio su un piede, o il tempo che un visitatore trascorre sul tuo sito web), un conteggio (ad es. il numero di visitatori del tuo sito web in un periodo specificato, il numero di animali osservati in una determinata localit√†), ecc.\nCategorica: Un insieme di gruppi o categorie finite/fisse con un insieme di opzioni predeterminate, come partito politico, dipartimento ospedaliero, paese, genere, ecc.\nDate e orari: Date e orari possono avere vari formati, come ‚Äú01/01/2020 23:00:05‚Äù o ‚Äú1 gen 2020‚Äù.\nTesto strutturato (breve): Testo con una struttura o lunghezza prestabilita, come il nome di una persona, un indirizzo postale, un indirizzo email, ecc.\nTesto non strutturato (lungo): Un corpo di testo pi√π ampio che non ha una struttura predefinita, come voci nei rapporti di patologia o note del medico, recensioni di film, tweet, post su Reddit, ecc.\n\nLa dimensione dei dati si riferisce al numero di variabili (colonne) che contiene (e talvolta anche al numero di righe che contiene). Pertanto, i ‚Äúdati ad alta dimensione‚Äù si riferiscono tipicamente a dati con molte variabili (generalmente pi√π di 100, anche se non esiste una soglia fissa oltre la quale i dati diventano ‚Äúad alta dimensione‚Äù).\nOgni riga corrisponde a una particolare osservazione, unit√† osservazionale, unit√† di dati o punto dati (usiamo questi termini in modo intercambiabile). Queste sono le entit√† per cui vengono raccolte le misurazioni.\nQuesto formato, in cui i dati sono disposti in colonne (caratteristiche/variabili) e righe (unit√† osservazionali), √® chiamato dati rettangolari o tabellari.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-2-pulizia-dei-dati-e-analisi-esplorativa",
    "href": "chapters/eda/01_project_structure.html#fase-2-pulizia-dei-dati-e-analisi-esplorativa",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "16.3 Fase 2: Pulizia dei Dati e Analisi Esplorativa",
    "text": "16.3 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n16.3.1 Pulizia dei Dati\nDopo aver definito una domanda e raccolto alcuni dati rilevanti, √® il momento di pulire i dati. Un dataset pulito √® ordinato, formattato in modo appropriato e ha voci non ambigue. La fase iniziale di pulizia dei dati consiste nell‚Äôidentificare problemi con i dati (come formattazioni strane e valori non validi) e modificarli in modo che i valori siano validi e formattati in modo comprensibile sia per il computer che per noi. La pulizia dei dati √® una fase incredibilmente importante di un progetto di data science perch√© non solo aiuta a garantire che i dati siano interpretati correttamente dal computer, ma aiuta anche a sviluppare una comprensione dettagliata delle informazioni contenute nei dati e delle loro limitazioni.\nL‚Äôobiettivo della pulizia dei dati √® creare una versione dei dati che rifletta nella maniera pi√π fedele possibile la realt√† e che sia interpretata correttamente dal computer. Per garantire che il computer utilizzi fedelmente le informazioni contenute nei dati, √® necessario modificare i dati (scrivendo codice, non modificando il file dati grezzo stesso) in modo che siano in linea con ci√≤ che il computer ‚Äúsi aspetta‚Äù. Tuttavia, il processo di pulizia dei dati √® necessariamente soggettivo e comporta fare assunzioni sulle quantit√† reali sottostanti misurate e decisioni su quali modifiche siano le pi√π sensate.\n\n\n16.3.2 Preprocessing\nIl preprocessing si riferisce al processo di modifica dei dati puliti per soddisfare i requisiti di un algoritmo specifico che si desidera applicare. Ad esempio, se si utilizza un algoritmo che richiede che le variabili siano sulla stessa scala, potrebbe essere necessario trasformarle, oppure, se si utilizza un algoritmo che non consente valori mancanti, potrebbe essere necessario imputarli o rimuoverli. Durante il preprocessing, potrebbe essere utile anche definire nuove caratteristiche/variabili utilizzando le informazioni esistenti nei dati, se si ritiene che queste possano essere utili per l‚Äôanalisi.\nCome per la pulizia dei dati, non esiste un unico modo corretto per pre-elaborare un dataset, e la procedura finale comporta tipicamente una serie di decisioni che dovrebbero essere documentate nel codice e nei file di documentazione.\n\n\n16.3.3 Analisi Esplorativa dei Dati\nLa fase successiva prevede un esame pi√π approfondito dei dati mediante la creazione di tabelle informative, il calcolo di statistiche riassuntive come medie e mediane, e la produzione di visualizzazioni informative. Questa fase ha tipicamente due sottofasi. La prima sottofase, l‚Äôanalisi esplorativa dei dati (EDA), implica lo sviluppo di riassunti numerici e visivi dei dati per comprendere meglio i dati e i modelli che contengono. La seconda sottofase, l‚Äôanalisi esplicativa dei dati, consiste nel perfezionare le tabelle e i grafici esplorativi pi√π informativi per comunicarli a un pubblico esterno.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-3-analisi-predittiva-eo-inferenziale",
    "href": "chapters/eda/01_project_structure.html#fase-3-analisi-predittiva-eo-inferenziale",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "16.4 Fase 3: Analisi Predittiva e/o Inferenziale",
    "text": "16.4 Fase 3: Analisi Predittiva e/o Inferenziale\nMolte domande di data science sono formulate come problemi di previsione, dove l‚Äôobiettivo √® utilizzare dati osservabili passati o presenti per prevedere qualcosa su dati futuri non visti, solitamente per aiutare a prendere decisioni nel mondo reale.\n\n16.4.1 Inferenza Basata sui Dati\nUn altro tipo di problema basato sui dati che si pu√≤ incontrare √® quello dell‚Äôinferenza, che comporta l‚Äôapprendimento su una popolazione pi√π ampia quantificando l‚Äôincertezza associata a una stima del parametro (come la ‚Äúmedia del campione‚Äù, che √® una stima della ‚Äúmedia della popolazione‚Äù). Le tecniche tradizionali di inferenza statistica includono il test delle ipotesi e gli intervalli di confidenza.\nLa maggior parte di questo corso √® dedicata a fornire un‚Äôintroduzione a come il problema dell‚Äôinferenza possa essere affrontato usando una prospettiva bayesiana.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-4-valutazione-dei-risultati",
    "href": "chapters/eda/01_project_structure.html#fase-4-valutazione-dei-risultati",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "16.5 Fase 4: Valutazione dei Risultati",
    "text": "16.5 Fase 4: Valutazione dei Risultati\nL‚Äôinterpretazione dei risultati alla luce della domanda che ha motivato l‚Äôanalisi √® un passaggio cruciale. √à necessario valutare qualitativamente i risultati utilizzando il pensiero critico e quantitativamente utilizzando gli standard correnti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-5-comunicazione-dei-risultati",
    "href": "chapters/eda/01_project_structure.html#fase-5-comunicazione-dei-risultati",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "16.6 Fase 5: Comunicazione dei Risultati",
    "text": "16.6 Fase 5: Comunicazione dei Risultati\nL‚Äôultima fase del ciclo di un progetto di data science implica la comunicazione dei risultati affinch√© possano essere utilizzati per prendere decisioni nel mondo reale. Questo potrebbe implicare la scrittura di un articolo di ricerca, la creazione di un report per un gruppo di lavoro, o la preparazione di alcune diapositive. La capacit√† di comunicare efficacemente i risultati dell‚Äôanalisi alle persone che potrebbero utilizzarli √® cruciale. Dopotutto, se hai condotto un‚Äôanalisi approfondita ma non riesci a spiegare i risultati a nessuno, qual √® stato il senso di condurre l‚Äôanalisi in primo luogo?\nLa comunicazione deve essere personalizzata per il pubblico di riferimento. Piuttosto che presumere che il pubblico sia gi√† familiare con il progetto, √® necessario spiegare l‚Äôanalisi e le figure in modo molto accurato e chiaro. Anche se il messaggio principale di una figura o diapositiva pu√≤ essere ovvio per te, √® buona pratica spiegare esplicitamente al pubblico come interpretarlo (senza usare gergo complesso).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#lorganizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#lorganizzazione-del-progetto",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "16.7 L‚Äôorganizzazione del Progetto",
    "text": "16.7 L‚Äôorganizzazione del Progetto\nIl primo requisito di un progetto di analisi dei dati √® organizzare in maniera efficiente i vari file che verranno utilizzati: i file dei dati, i file di codice e la documentazione del progetto. Tutti i file relativi a un progetto di analisi dei dati devono essere contenuti in una singola cartella. Yu e Barter (2024) propongono il seguente template per la struttura di un progetto:\n\nLe due cartelle principali sono:\n\ndata/: contiene il dataset grezzo (ad esempio, data.csv) e una sottocartella con informazioni sulla documentazione dei dati (ad esempio, metainformazioni e definizioni dei dati sotto forma di codebook).\ndslc_documentation/: contiene file .qmd di Quarto (per R) o .ipynb di Jupyter Notebook (per Python) per condurre e documentare le esplorazioni e analisi basate su codice in ogni fase del progetto DSLC. Ogni nome di file ha un prefisso numerico per garantire che i file appaiano nell‚Äôordine corretto. C‚Äô√® anche una sottocartella functions/ con script .R (R) o .py (Python) che contengono funzioni utilizzate in vari file di analisi.\n\nIl file README.md riassume la struttura del progetto e descrive il contenuto di ogni file.\nUna struttura di progetto come quella proposta da Yu e Barter (2024), in cui tutti i file sono contenuti in una singola cartella, offre un vantaggio significativo: la specificazione di tutti i percorsi dei file, ad esempio quelli necessari per la lettura dei dati, pu√≤ essere fatta in maniera relativa, utilizzando come root la cartella del progetto. Questo assicura la portabilit√† del progetto tra diversi computer o utenti.\n\n16.7.1 I dati sulle aspettative negative nella depressione\nPer illustrare gli aspetti dell‚Äôarchiviazione dei dati sul computer e dell‚Äôimportazione dei dati in Python, consideriamo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento della depressione. I ricercatori hanno confrontato 30 soggetti con episodi depressivi con un gruppo di controllo di 37 individui sani, utilizzando il Beck Depression Inventory (BDI-II) per misurare la depressione.\nQuesto file CSV, cos√¨ come tutti gli altri file di dati utilizzati in questa dispensa, √® contenuto nella cartella data all‚Äôinterno della cartella psicometria, che √® la directory principale dell‚Äôintero progetto.\nCon le seguenti istruzioni, specifico il percorso della directory principale del progetto in relazione alla mia directory personale:\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\nprint(project_directory)\n\n/Users/corradocaudek/_repositories/psicometria\n\n\nAvendo definito project_directory come root, diventa possibile specificare il percorso del file CSV che contiene i dati in relazione a project_directory.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"data.mood.csv\")\nprint(file_path)\n\n/Users/corradocaudek/_repositories/psicometria/data/data.mood.csv\n\n\nCon la seguente istruzione posso dunque leggere i dati del file data.mood.csv in un DataFrame pandas.\n\ndf = pd.read_csv(file_path)\n\n\n\n16.7.2 Esaminare i dati\nPer conoscere le dimensioni del DataFrame utilizziamo il metodo .shape.\n\ndf.shape\n\n(1188, 44)\n\n\nIl DataFrame ha 1188 righe e 44 colonne. Visualizziamo il nome delle colonne con il metodo .columns.\n\ndf.columns\n\nIndex(['Unnamed: 0', 'vpn_nr', 'esm_id', 'group', 'bildung', 'bdi',\n       'nr_of_episodes', 'nobs_mood', 'trigger_counter', 'form', 'traurig_re',\n       'niedergeschlagen_re', 'unsicher_re', 'nervos_re', 'glucklich_re',\n       'frohlich_re', 'mood_sad.5', 'mood_fearful.5', 'mood_neg.5',\n       'mood_happy.5', 'cesd_sum', 'rrs_sum', 'rrs_brood', 'rrs_reflect',\n       'forecast_sad', 'forecast_fear', 'forecast_neg', 'forecast_happy',\n       'recall_sad', 'recall_fear', 'recall_neg', 'recall_happy',\n       'diff_neg.fore.5', 'diff_sad.fore.5', 'diff_fear.fore.5',\n       'diff_happy.fore.5', 'diff_neg.retro.5', 'diff_sad.retro.5',\n       'diff_fear.retro.5', 'diff_happy.retro.5', 'mood_sad5_tm1',\n       'mood_neg5_tm1', 'mood_fearful5_tm1', 'mood_happy5_tm1'],\n      dtype='object')\n\n\nDato che il DataFrame √® troppo grande (1188 righe e 44 colonne), stampiamo sullo schermo le prime 5 righe.\n\ndf.head()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nvpn_nr\nesm_id\ngroup\nbildung\nbdi\nnr_of_episodes\nnobs_mood\ntrigger_counter\nform\n...\ndiff_fear.fore.5\ndiff_happy.fore.5\ndiff_neg.retro.5\ndiff_sad.retro.5\ndiff_fear.retro.5\ndiff_happy.retro.5\nmood_sad5_tm1\nmood_neg5_tm1\nmood_fearful5_tm1\nmood_happy5_tm1\n\n\n\n\n0\n1\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n5\nForecasting\n...\n0.333333\n-1.000000\n0.250000\n0.166667\n0.333333\n-1.000000\nNaN\nNaN\nNaN\nNaN\n\n\n1\n2\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n6\nForecasting\n...\n-0.666667\n-0.333333\n-0.416667\n-0.166667\n-0.666667\n-0.333333\n3.333333\n3.000000\n2.666667\n3.000000\n\n\n2\n3\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n7\nForecasting\n...\n0.666667\n-0.666667\n1.250000\n1.833333\n0.666667\n-0.666667\n3.666667\n3.666667\n3.666667\n2.333333\n\n\n3\n4\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n8\nForecasting\n...\n-0.333333\n-0.666667\n0.083333\n0.500000\n-0.333333\n-0.666667\n1.666667\n2.000000\n2.333333\n2.666667\n\n\n4\n5\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n10\nForecasting\n...\n0.333333\n-1.000000\n0.416667\n0.500000\n0.333333\n-1.000000\n3.000000\n3.166667\n3.333333\n2.666667\n\n\n\n\n5 rows √ó 44 columns",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "16¬† Le fasi del progetto di analisi dei dati",
    "section": "16.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "16.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Aug 01 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nYu, Bin, e Rebecca L Barter. 2024. Veridical data science: The practice of responsible data analysis and decision making. MIT Press.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html",
    "href": "chapters/eda/02_freq_distr.html",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "",
    "text": "17.1 Introduzione\nUn aspetto cruciale del lavoro di un data scientist √® la capacit√† di presentare in modo chiaro ed efficace le intuizioni derivanti dall‚Äôanalisi dei dati. Questo √® fondamentale sia per la comprensione personale sia per la comunicazione con altri, in particolare con coloro che potrebbero utilizzare tali informazioni per prendere decisioni concrete nel mondo reale.\nLa comunicazione efficace dei dati e dei risultati derivati raramente avviene attraverso la semplice presentazione dei dati grezzi o degli output di codice. Questi formati non permettono di rilevare facilmente pattern significativi. Invece, i dati e i risultati vengono generalmente presentati in due modi principali:\nIn questo capitolo, esploreremo le strategie per sintetizzare grandi volumi di dati, concentrandoci su concetti chiave come le distribuzioni di frequenza, i quantili e le tecniche di visualizzazione. Esamineremo sia gli aspetti computazionali sia quelli interpretativi di queste misure, fornendo gli strumenti necessari per rappresentare graficamente le sintesi dei dati in modo efficace.\nIn particolare, ci focalizzeremo sull‚Äôuso della visualizzazione dei dati per condurre l‚Äôanalisi esplorativa dei dati (EDA). L‚ÄôEDA consiste nel riassumere visivamente e numericamente i pattern, le tendenze e le relazioni presenti in un dataset, nel contesto del problema di dominio che stiamo cercando di risolvere. L‚Äôobiettivo delle esplorazioni EDA √® comprendere le tendenze e i pattern che risponderanno alla domanda che motiva l‚Äôanalisi dei dati. In questo capitolo esamineremo tre metodi per rappresentare graficamente una distribuzione di frequenze:",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#introduzione",
    "href": "chapters/eda/02_freq_distr.html#introduzione",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "",
    "text": "Sintesi statistiche: Utilizzando medie o altri valori rappresentativi, spesso organizzati in tabelle concise.\nRappresentazioni visive: Attraverso grafici, dove elementi come forme, distanze, colori e dimensioni illustrano le grandezze e le relazioni tra i valori contenuti nei dati.\n\n\n\n\nl‚Äôistogramma,\nl‚Äôistogramma lisciato,\nil box-plot.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/02_freq_distr.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.2 I dati sulle aspettative negative nella depressione",
    "text": "17.2 I dati sulle aspettative negative nella depressione\nPer illustrare i principali strumenti dell‚ÄôEDA, analizzeremo i dati sulle aspettative negative come meccanismo chiave nel mantenimento della depressione (Zetsche, Buerkner, e Renneberg 2019). Come abbiamo visto nel cam√¨pitolo precedente, avendo definito project_directory come root\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\n\n√® possibile specificare il percorso del file CSV che contiene i dati in relazione a project_directory:\n\nfile_path = os.path.join(project_directory, \"data\", \"data.mood.csv\")\n\nLeggiamo i dati grezzi del file data.mood.csv in un DataFrame pandas:\n\ndf = pd.read_csv(file_path)\n\nPer questo esercizio, ci concentriamo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf = df[[\"esm_id\", \"group\", \"bdi\"]]\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n1\n10\nmdd\n25.0\n\n\n2\n10\nmdd\n25.0\n\n\n3\n10\nmdd\n25.0\n\n\n4\n10\nmdd\n25.0\n\n\n\n\n\n\n\n\nUna delle prime cose da fare, quando esaminiamo un dataset, √® capire che tipo di variabili sono incluse.\n\ndf.dtypes\n\nesm_id      int64\ngroup      object\nbdi       float64\ndtype: object\n\n\nNel caso specifico, notiamo che la variabile group √® di tipo object, quindi √® una variabile qualitativa, mentre le altre variabili sono numeriche, rappresentate come numeri interi (int64) o a virgola mobile (bdi).\nSe elenchiamo le modalit√† presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf[\"group\"].unique()\n\narray(['mdd', 'ctl'], dtype=object)\n\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf = df.drop_duplicates(keep=\"first\")\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndf.shape\n\n(67, 3)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n14\n9\nmdd\n30.0\n\n\n29\n6\nmdd\n26.0\n\n\n45\n7\nmdd\n35.0\n\n\n64\n12\nmdd\n44.0\n\n\n\n\n\n\n\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il ‚Äúnome‚Äù delle righe (ovvero, l‚Äôindice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga √® 15. Questo non ha nessuna conseguenza perch√© non useremo l‚Äôindice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf = df[pd.notnull(df[\"bdi\"])]\n\nOtteniamo cos√¨ il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndf.shape\n\n(66, 3)\n\n\nStampiamo i valori BDI-II presentandoli ordinati dal pi√π piccolo al pi√π grande:\n\nprint(df[\"bdi\"].sort_values())\n\n682     0.0\n455     0.0\n465     0.0\n485     0.0\n540     0.0\n       ... \n190    39.0\n810    41.0\n150    43.0\n135    43.0\n64     44.0\nName: bdi, Length: 66, dtype: float64\n\n\nNella terminologia statistica, l‚Äôosservazione √® l‚Äôinformazione raccolta da un individuo o un‚Äôentit√† specifica che partecipa allo studio. Considerando il dataset di Zetsche, Buerkner, e Renneberg (2019), l‚Äôunit√† di osservazione √® costituita dai partecipanti allo studio. Pertanto, nel DataFrame denominato df, ogni riga simboleggia un individuo distinto coinvolto nell‚Äôindagine.\nLe variabili, d‚Äôaltro canto, sono espressioni delle diverse caratteristiche degli individui o delle entit√† analizzate. Nel contesto del progetto STAR, questo concetto si traduce in:\n\nOgni colonna di df rappresenta una variabile che incarna una particolare propriet√† condivisa dai partecipanti.\nLe variabili sono identificate attraverso etichette collegate alle colonne, come esa_id (il codice identificativo dei soggetti), mdd (il gruppo di appartenza), e bdi (il valore del test BDI-II).\n\nPer rappresentare un‚Äôosservazione singola della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l‚Äôindice dell‚Äôosservazione. Questo indice significa che abbiamo un valore differente di \\(X\\) per ogni valore distinto di \\(i\\). Ad esempio, nel caso di 67 osservazioni, \\(i\\) pu√≤ variare da 1 a 67. Pertanto, per simboleggiare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\). √à fondamentale tener presente che, mentre in Python gli indici iniziano da 0, nella notazione matematica tradizionale, come quella rappresentata da \\(X_i\\), l‚Äôindice ha inizio da 1.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#distribuzioni-di-frequenze",
    "href": "chapters/eda/02_freq_distr.html#distribuzioni-di-frequenze",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.3 Distribuzioni di frequenze",
    "text": "17.3 Distribuzioni di frequenze\n√à chiaro dall‚Äôoutput esaminato nella sezione precedente che i dati grezzi non sono molto informativi. Ci porremo ora l‚Äôobiettivo di creare una rappresentazione sintetica e comprensibile di questi dati.\nUna distribuzione di frequenze rappresenta il conteggio delle volte in cui i valori di una variabile si verificano all‚Äôinterno di un intervallo. Per i nostri dati BDI-II, categorizziamo i punteggi in quattro classi:\n\n0‚Äì13: depressione minima\n14‚Äì19: depressione lieve-moderata\n20‚Äì28: depressione moderata-severa\n29‚Äì63: depressione severa\n\nOgni classe \\(\\Delta_i\\) rappresenta un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\), con limiti inferiori e superiori \\(a_i\\) e \\(b_i\\), vengono associati un‚Äôampiezza \\(b_i - a_i\\) (che non √® necessariamente uguale per ogni classe) e un valore centrale \\(\\bar{x}_i\\). Poich√© ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), √® possibile calcolare le seguenti quantit√†.\n\nLa frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\n\nPropriet√†: \\(n_1 + n_2 + \\dots + n_m = n\\).\n\nLa frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.\n\nPropriet√†: \\(f_1+f_2+\\dots+f_m =1\\).\n\nLa frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\)\nLa frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\)\n\n\n17.3.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, √® necessario prima aggiungere al DataFrame df una colonna che contenga una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravit√† della depressione. Questo risultato si ottiene con il metodo pandas.cut().\nIn pandas.cut(), il primo argomento x √® un array unidimensionale (lista python, numpy.ndarray o pandas.Series) che contiene i dati e il secondo argomento bins specifica gli intervalli delle classi. La funzione restituisce un array che specifica la classe di appartenenza di ogni elemento dell‚Äôarray x. L‚Äôargomento include_lowest=True specifica classi chiuse a destra (nel nostro caso √® irrilevante dato che nessuna osservazione coincide con il limite di una classe).\n\n17.3.1.1 Frequenze assolute\n\ndf[\"bdi_class\"] = pd.cut(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], include_lowest=True)\ndf[\"bdi_class\"].value_counts()\n\nbdi_class\n(-0.001, 13.5]    36\n(28.5, 63.0]      17\n(19.5, 28.5]      12\n(13.5, 19.5]       1\nName: count, dtype: int64\n\n\n\n\n17.3.1.2 Frequenze relative\n\nabs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=[\"Abs. freq.\"])\nrel_freq = abs_freq / abs_freq.sum()\nrel_freq = rel_freq.round(2)\nrel_freq\n\n\n\n\n\n\n\n\ncol_0\nAbs. freq.\n\n\nbdi_class\n\n\n\n\n\n(-0.001, 13.5]\n0.55\n\n\n(13.5, 19.5]\n0.02\n\n\n(19.5, 28.5]\n0.18\n\n\n(28.5, 63.0]\n0.26\n\n\n\n\n\n\n\n\nControlliamo\n\nrel_freq.sum()\n\ncol_0\nAbs. freq.    1.01\ndtype: float64\n\n\n\ngrp_freq = pd.crosstab(index=df[\"group\"], columns=[\"Abs. freq.\"], colnames=[\"\"])\ngrp_freq\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nctl\n36\n\n\nmdd\n30\n\n\n\n\n\n\n\n\nVolendo modificare tale ordine √® possibile accedere al DataFrame tramite loc e specificando come secondo argomento una lista dei valori nell‚Äôordine desiderato:\n\ngrp_freq.loc[[\"mdd\", \"ctl\"], :]\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nmdd\n30\n\n\nctl\n36\n\n\n\n\n\n\n\n\nIn Python, il simbolo : utilizzato all‚Äôinterno delle parentesi quadre permette di ottenere uno slicing corrispondente all‚Äôintera lista.\n\n\n\n17.3.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l‚Äôinsieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l‚Äôinsieme di variabili \\(V\\) √® composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali pu√≤ assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell‚Äôesempio precedente, la funzione pd.crosstab pu√≤ essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti index e columns.\n\nbdi_group_abs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"])\nbdi_group_abs_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n36\n0\n\n\n(13.5, 19.5]\n0\n1\n\n\n(19.5, 28.5]\n0\n12\n\n\n(28.5, 63.0]\n0\n17\n\n\n\n\n\n\n\n\nOppure:\n\nbdi_group_rel_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"], normalize=True)\nbdi_group_rel_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n0.545455\n0.000000\n\n\n(13.5, 19.5]\n0.000000\n0.015152\n\n\n(19.5, 28.5]\n0.000000\n0.181818\n\n\n(28.5, 63.0]\n0.000000\n0.257576\n\n\n\n\n\n\n\n\nInvocando il metodo plot.bar sulla tabella, otteniamo un grafico a barre nel quale le barre relative a uno stesso valore bdi_class risultino affiancate. Nel caso presente, le due distribuzioni sono completamente separate, quindi non abbiamo mai due barre affiancate:\n\nbdi_group_rel_freq.plot.bar();",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#istogramma",
    "href": "chapters/eda/02_freq_distr.html#istogramma",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.4 Istogramma",
    "text": "17.4 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densit√† della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densit√† della frequenza relativa √® misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) √® la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l‚Äôampiezza della classe. In questo modo, l‚Äôarea del rettangolo associato alla classe \\(\\Delta_i\\) sull‚Äôistogramma sar√† proporzionale alla frequenza relativa \\(f_i\\). √à importante notare che l‚Äôarea totale dell‚Äôistogramma delle frequenze relative √® uguale a 1.0, poich√© rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche, Buerkner, e Renneberg (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell‚Äôistogramma ‚Äì si notino le frequenze assolute sull‚Äôasse delle ordinate.\n\ncolor_fill = \"#b97c7c\"\nplt.hist(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], density=True, color=color_fill)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()\n\n\n\n\n\n\n\n\nAnche se nel caso presente √® sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un‚Äôampiezza uguale.\n\nplt.hist(df[\"bdi\"], density=True, color=color_fill)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#kernel-density-plot",
    "href": "chapters/eda/02_freq_distr.html#kernel-density-plot",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.5 Kernel density plot",
    "text": "17.5 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell‚Äôistogramma: la sua forma dipende dall‚Äôarbitrariet√† con cui vengono scelti il numero e l‚Äôampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficolt√†, possiamo utilizzare una tecnica alternativa chiamata stima della densit√† kernel (KDE) ‚Äì si veda l‚ÄôAppendice L. Mentre l‚Äôistogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione pi√π continua e meno dipendente dall‚Äôarbitrariet√† delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo √® ci√≤ che fa la KDE: smussa il profilo dell‚Äôistogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un‚Äôaltezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densit√† dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L‚Äôarea sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell‚Äôintervallo. Per esempio, se un intervallo ha un‚Äôarea maggiore sotto la curva rispetto ad altri, significa che in quell‚Äôintervallo c‚Äô√® una maggiore concentrazione di dati.\nLa curva di densit√† ottenuta tramite KDE fornisce dunque un‚Äôidea chiara di come i dati sono distribuiti senza dipendere dall‚Äôarbitrariet√† della scelta delle classi dell‚Äôistogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da {cite:t}zetsche_2019future.\n\nsns.kdeplot(data=df, x=\"bdi\", hue=\"group\", common_norm=False)\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI-II Scores\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/02_freq_distr.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.6 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "17.6 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualit√† adatta alle presentazioni:\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, ‚ÄúIl livello di benessere psicologico dei partecipanti aumenta nel tempo‚Äù).\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell‚Äôuso dei colori solo perch√© √® possibile farlo.\nLimita l‚Äôuso a non pi√π di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l‚Äôuso contemporaneo di rosso e verde nello stesso grafico, poich√© queste tonalit√† sono difficili da distinguere per le persone daltoniche.\n\nGuidare l‚Äôattenzione:\n\nUtilizza dimensioni, colori e testo per guidare l‚Äôattenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il ‚Äúsovrapplotting‚Äù (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica √® particolarmente utile quando si visualizza una grande quantit√† di dati.\nSe il dataset √® molto ampio e l‚Äôaggiunta di trasparenza non √® sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica √® nota come sottocampionamento.\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#forma-di-una-distribuzione",
    "href": "chapters/eda/02_freq_distr.html#forma-di-una-distribuzione",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.7 Forma di una Distribuzione",
    "text": "17.7 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un‚Äôillustrazione grafica √® fornita nella figura seguente. Nel pannello 1, la distribuzione √® unimodale con asimmetria negativa; nel pannello 2, la distribuzione √® unimodale con asimmetria positiva; nel pannello 3, la distribuzione √® simmetrica e unimodale; nel pannello 4, la distribuzione √® bimodale.\n\n\n\nDistribuzioni\n\n\nIl grafico della densit√† di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche, Buerkner, e Renneberg (2019) √® bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l‚Äôaltro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche, Buerkner, e Renneberg (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#indici-di-posizione",
    "href": "chapters/eda/02_freq_distr.html#indici-di-posizione",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.8 Indici di posizione",
    "text": "17.8 Indici di posizione\n\n17.8.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche, Buerkner, e Renneberg (2019) pu√≤ essere sintetizzata attraverso l‚Äôuso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) √® la dimensione del campione e \\(p\\) √® l‚Äôordine del quantile. Se \\(np\\) non √® un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) √® un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) √® la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che √® molto popolare e pu√≤ essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche, Buerkner, e Renneberg (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non √® un intero. Pertanto, il valore del secondo quartile √® pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che √® un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo numpy per trovare la soluzione dell‚Äôesercizio precedente.\n\nx = [19, 26, 27, 28, 28, 33, 33, 41, 43]\nnp.quantile(x, 2 / 3)\n\n33.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#mostrare-i-dati",
    "href": "chapters/eda/02_freq_distr.html#mostrare-i-dati",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.9 Mostrare i dati",
    "text": "17.9 Mostrare i dati\n\n17.9.1 Diagramma a scatola\nIl box plot √® uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la ‚Äúscatola‚Äù) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) √® rappresentata da una linea all‚Äôinterno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti ‚Äúbaffi‚Äù, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore √® il valore pi√π basso tra le osservazioni che √® maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore √® il valore pi√π alto tra le osservazioni che √® minore o uguale al terzo quartile pi√π 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati ‚Äúvalori anomali‚Äù e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nsns.boxplot(x=\"group\", y=\"bdi\", data=df, color=color_fill)\nplt.xlabel(\"Group\")\nplt.ylabel(\"BDI-II\")\nplt.title(\"Boxplot of BDI-II Scores by Group\")\nplt.show()\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n\n17.9.2 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densit√† di kernel (KDE plot) per offrire una rappresentazione pi√π dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nsns.violinplot(x=\"group\", y=\"bdi\", data=df, color=\"lightgray\")\nsns.stripplot(x=\"group\", y=\"bdi\", data=df, color=\"black\", size=5, jitter=True, alpha=0.3)\nplt.ylabel(\"BDI-II\")\nplt.xlabel(\"Group\")\nplt.title(\"Violin Plot with Overlay of Individual Data Points of BDI-II Scores by Group\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/02_freq_distr.html#commenti-e-considerazioni-finali",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.10 Commenti e considerazioni finali",
    "text": "17.10 Commenti e considerazioni finali\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densit√†. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "17¬† Analisi esplorativa dei dati",
    "section": "17.11 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "17.11 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHealy, Kieran. 2018. Data visualization: a practical introduction. Princeton University Press.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, e Garrett Grolemund. 2023. R for data science. \" O‚ÄôReilly Media, Inc.\".\n\n\nWilke, Claus O. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. O‚ÄôReilly Media.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_loc_scale.html",
    "href": "chapters/eda/03_loc_scale.html",
    "title": "18¬† Indici di posizione e di scala",
    "section": "",
    "text": "18.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, √® possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l‚Äôasimmetria, nonch√© la presenza di una o pi√π mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l‚Äôutilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/03_loc_scale.html#indici-di-tendenza-centrale",
    "title": "18¬† Indici di posizione e di scala",
    "section": "18.2 Indici di tendenza centrale",
    "text": "18.2 Indici di tendenza centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all‚Äôinterno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l‚Äôintero insieme. Gli indici di tendenza centrale sono fondamentali nell‚Äôanalisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media √® la somma di tutti i valori divisa per il numero totale di valori. √à spesso utilizzata come misura generale di tendenza centrale, ma √® sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana √® il valore che divide l‚Äôinsieme di dati in due parti uguali. A differenza della media, non √® influenzata da valori estremi ed √® quindi pi√π robusta in presenza di outlier.\nModa: La moda √® il valore che appare pi√π frequentemente in un insieme di dati. In alcuni casi, pu√≤ non essere presente o esserci pi√π di una moda.\n\nLa scelta dell‚Äôindice di tendenza centrale appropriato dipende dalla natura dei dati e dall‚Äôobiettivo dell‚Äôanalisi. Ad esempio, la mediana potrebbe essere preferita alla media se l‚Äôinsieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l‚Äôapplicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n18.2.1 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. √à calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed √® espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{18.1}\\]\ndove \\(x_i\\) rappresenta i valori nell‚Äôinsieme, \\(n\\) √® il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n18.2.1.1 Propriet√† della media\nUna propriet√† fondamentale della media √® che la somma degli scarti di ciascun valore dalla media √® zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{18.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta propriet√† implica che i dati sono equamente distribuiti intorno alla media.\n\n\n18.2.1.2 La media come centro di gravit√† dell‚Äôistogramma\nLa media aritmetica pu√≤ essere interpretata come il centro di gravit√† o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravit√† √® il punto in cui la massa di un sistema √® equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati √® in equilibrio. Ogni valore dell‚Äôinsieme di dati pu√≤ essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori pi√π grandi a destra e pi√π piccoli a sinistra, la media corrisponder√† esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n18.2.1.3 Principio dei minimi quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come ‚Äúmetodo dei minimi quadrati‚Äù. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media √® minima. Questo principio √® alla base dell‚Äôanalisi statistica dei modelli di regressione e conferma l‚Äôinterpretazione della media come centro di gravit√† dell‚Äôistogramma.\n\n\n18.2.1.4 Calcolo della media con NumPy\nPer calcolare la media di un piccolo numero di valori in Python, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n\n32.6\n\n\novvero\n\nx = np.array([12, 44, 21, 62, 24])\nnp.mean(x)\n\n32.6\n\n\n\nnp.average(x)\n\n32.6\n\n\n\n\n18.2.1.5 Le proporzioni sono medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione √® il numero di uni in essa, e la media della collezione √® la proporzione di uni.\n\nzero_one = np.array([1, 1, 1, 0])\nresult = sum(zero_one)\nprint(result) \n\n3\n\n\n\nnp.mean(zero_one)\n\n0.75\n\n\n√à possibile sostituire 1 con il valore booleano True e 0 con False:\n\nnp.mean(np.array([(True, True, True, False)]))\n\n0.75\n\n\n\n\n18.2.1.6 Limiti della media aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre √® l‚Äôindice pi√π adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, √® pi√π indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n18.2.1.7 Medie per gruppi\nMolto spesso per√≤ i nostri dati sono contenuti in file e inserire i dati manualmente non √® fattibile. Per fare un esempio, considereremo i dati del Progetto STAR, contenuti nel file STAR.csv, che rappresentano un‚Äôimportante indagine sulle prestazioni degli studenti in relazione alla dimensione delle classi. Negli anni ‚Äô80, i legislatori del Tennessee considerarono la possibilit√† di ridurre le dimensioni delle classi per migliorare il rendimento degli studenti. Al fine di prendere decisioni informate, commissionarono lo studio multimilionario ‚ÄúProgetto Student-Teacher Achievement Ratio‚Äù (Project STAR). Lo studio coinvolgeva bambini della scuola materna assegnati casualmente a classi piccole, con 13-17 studenti, o classi di dimensioni regolari, con 22-25 studenti, fino alla fine della terza elementare. I ricercatori hanno seguito il progresso degli studenti nel tempo, concentrandosi su variabili di risultato, come i punteggi dei test standardizzati di lettura (reading) e matematica (math) alla terza elementare, oltre ai tassi di diploma di scuola superiore (graduated, con valore 1 per s√¨ e 0 per no).\nPoniamoci il problema di calcolare la media dei punteggi math calcolata separatamente per i due gruppi di studenti: coloro che hanno completato la scuola superiore e coloro che non l‚Äôhanno completata.\nProcediamo all‚Äôimportazione dei dati per iniziare l‚Äôanalisi.\n\ndf = pd.read_csv(\"../../data/STAR.csv\")\ndf.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nEsaminiamo la numerosit√† di ciascun gruppo.\n\ndf.groupby(\"graduated\").size()\n\ngraduated\n0     166\n1    1108\ndtype: int64\n\n\nOra procediamo al calcolo delle medie dei punteggi math all‚Äôinterno dei due gruppi. Per rendere la risposta pi√π concisa, useremo la funzione round() per stampare solo 2 valori decimali.\n\ndf.groupby(\"graduated\")[\"math\"].mean().round(2)\n\ngraduated\n0    606.64\n1    635.33\nName: math, dtype: float64\n\n\nIn alternativa, possiamo usare il metodo .describe():\n\ndf.groupby(\"graduated\")[\"math\"].describe().round(1)\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\ngraduated\n\n\n\n\n\n\n\n\n\n\n\n\n0\n166.0\n606.6\n34.1\n526.0\n580.5\n606.0\n629.0\n711.0\n\n\n1\n1108.0\n635.3\n38.1\n515.0\n609.5\n634.0\n659.0\n774.0\n\n\n\n\n\n\n\n\n\n\n\n18.2.2 Media spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, √® un metodo di calcolo della media che prevede l‚Äôeliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all‚Äôinizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l‚Äôultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata √® calcolata come la media aritmetica dei dati rimanenti. Questo approccio √® utile quando ci sono valori anomali o quando la distribuzione √® asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\nA titolo di esempio, procediamo al calcolo della media spuntata dei valori math per i due gruppi definiti dalla variabile graduated, escludendo il 10% dei valori pi√π estremi.\n\nnot_graduated = df[df[\"graduated\"] == 0].math\nstats.trim_mean(not_graduated, 0.10)\n\n605.6492537313433\n\n\n\ngraduated = df[df[\"graduated\"] == 1].math\nstats.trim_mean(graduated, 0.10)\n\n634.4403153153153\n\n\n\n\n18.2.3 Quantili\nIl quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\) rappresenta il valore che divide la distribuzione dei dati in modo tale che una frazione \\(p\\) dei dati si trovi al di sotto di esso.\nLa formula per calcolare il quantile non interpolato √® la seguente:\n\\[\n    q_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) √® l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme di dati ordinato in modo crescente, e \\(k\\) √® calcolato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) √® il numero totale di dati nel campione, e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all‚Äôintero successivo. In questa definizione, il quantile non interpolato corrisponde al valore effettivo nell‚Äôinsieme di dati, senza effettuare alcuna interpolazione tra i valori circostanti.\nAd esempio, consideriamo il seguente insieme di dati: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}\\). Supponiamo di voler calcolare il quantile non interpolato di ordine \\(p = 0.3\\) (cio√® il 30¬∞ percentile).\nOrdiniamo i dati in modo crescente: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\\) Calcoliamo \\(k\\) utilizzando la formula \\(k = \\lceil p \\cdot n \\rceil\\), dove \\(n\\) √® il numero totale di dati nel campione. Nel nostro caso, \\(n = 10\\) e \\(p = 0.3\\):\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\nIl quantile non interpolato corrisponde al valore \\(x_{(k)}\\), ovvero l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme ordinato: \\(q_{0.3} = x_{(3)} = 23.\\)\nOltre al quantile non interpolato, esiste anche il concetto di quantile interpolato. A differenza del quantile non interpolato, il quantile interpolato pu√≤ essere calcolato anche per percentili che non corrispondono esattamente a valori presenti nell‚Äôinsieme di dati. Per ottenere il valore del quantile interpolato, viene utilizzato un procedimento di interpolazione lineare tra i valori adiacenti. In genere, il calcolo del quantile interpolato viene eseguito mediante l‚Äôuso di software dedicati.\nOra, procediamo al calcolo dei quantili di ordine 0.10 e 0.90 per i valori math all‚Äôinterno dei due gruppi. I quantili sono dei valori che dividono la distribuzione dei dati in parti specifiche. Ad esempio, il quantile di ordine 0.10 corrisponde al valore al di sotto del quale si trova il 10% dei dati, mentre il quantile di ordine 0.90 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\nCalcoliamo i quantili di ordine 0.1 e 0.9 della distribuzione dei punteggi math nei due gruppi definiti dalla variabile graduated.\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.1), \n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.9)\n]\n\n[588.0, 684.0]\n\n\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che non hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.1),\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.9),\n]\n\n[564.5, 651.0]\n\n\n\n\n18.2.4 Moda e mediana\nIn precedenza abbiamo gi√† incontrato altri due popolari indici di tendenza centrale: la moda (Mo), che rappresenta il valore centrale della classe con la frequenza massima (in alcune distribuzioni pu√≤ esserci pi√π di una moda, rendendola multimodale e facendo perdere a questo indice il suo significato di indicatore di tendenza centrale); e la mediana (\\(\\tilde{x}\\)), che rappresenta il valore corrispondente al quantile di ordine 0.5 della distribuzione.\n\n\n18.2.5 Quando usare media, moda, mediana\nLa moda pu√≤ essere utilizzata per dati a livello nominale o ordinale ed √® l‚Äôunica tra le tre statistiche che pu√≤ essere calcolata in questi casi.\nLa media, d‚Äôaltra parte, √® una buona misura di tendenza centrale solo se la distribuzione dei dati √® simmetrica, ossia se i valori sono distribuiti uniformemente a sinistra e a destra della media. Tuttavia, se ci sono valori anomali o se la distribuzione √® asimmetrica, la media pu√≤ essere influenzata in modo significativo e, pertanto, potrebbe non essere la scelta migliore come misura di tendenza centrale.\nIn queste situazioni, la mediana pu√≤ fornire una misura migliore di tendenza centrale rispetto alla media poich√© √® meno influenzata dai valori anomali e si basa esclusivamente sul valore centrale dell‚Äôinsieme di dati. Di conseguenza, la scelta tra media e mediana dipende dal tipo di distribuzione dei dati e dagli obiettivi dell‚Äôanalisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_loc_scale.html#indici-di-dispersione",
    "href": "chapters/eda/03_loc_scale.html#indici-di-dispersione",
    "title": "18¬† Indici di posizione e di scala",
    "section": "18.3 Indici di dispersione",
    "text": "18.3 Indici di dispersione\nLe misure di posizione descritte in precedenza, come le medie e gli indici di posizione, offrono una sintesi dei dati mettendo in evidenza la tendenza centrale delle osservazioni. Tuttavia, trascurano un aspetto importante della distribuzione dei dati: la variabilit√† dei valori numerici della variabile statistica. Pertanto, √® essenziale completare la descrizione della distribuzione di una variabile statistica utilizzando anche indicatori che valutino la dispersione delle unit√† statistiche. In questo modo, otterremo una visione pi√π completa e approfondita delle caratteristiche del campione analizzato.\n\n18.3.1 Indici basati sull‚Äôordinamento dei dati\nPer valutare la variabilit√† dei dati, √® possibile utilizzare indici basati sull‚Äôordinamento dei dati. L‚Äôindice pi√π semplice √® l‚Äôintervallo di variazione, che corrisponde alla differenza tra il valore massimo e il valore minimo di una distribuzione di dati. Tuttavia, questo indice ha il limite di essere calcolato basandosi solo su due valori della distribuzione, e non tiene conto di tutte le informazioni disponibili. Inoltre, l‚Äôintervallo di variazione pu√≤ essere fortemente influenzato dalla presenza di valori anomali.\nUn altro indice basato sull‚Äôordinamento dei dati √® la differenza interquartile, gi√† incontrata in precedenza. Anche se questo indice utilizza pi√π informazioni rispetto all‚Äôintervallo di variazione, presenta comunque il limite di essere calcolato basandosi solo su due valori della distribuzione, ossia il primo quartile \\(Q_1\\) e il terzo quartile \\(Q_3\\).\nPer valutare la variabilit√† in modo pi√π completo, √® necessario utilizzare altri indici di variabilit√† che tengano conto di tutti i dati disponibili. In questo modo, si otterr√† una valutazione pi√π accurata della dispersione dei valori nella distribuzione e si potranno individuare eventuali pattern o tendenze nascoste.\n\n\n18.3.2 Varianza\nDate le limitazioni delle statistiche descritte in precedenza, √® pi√π comune utilizzare una misura di variabilit√† che tenga conto della dispersione dei dati rispetto a un indice di tendenza centrale. La varianza √® la misura di variabilit√† pi√π utilizzata per valutare la variabilit√† di una variabile statistica. Essa √® definita come la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione, come segue:\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\end{equation}\n\\tag{18.3}\\]\nLa varianza √® una misura di dispersione pi√π completa rispetto a quelle descritte in precedenza. Tuttavia, √® appropriata solo nel caso di distribuzioni simmetriche ed √® fortemente influenzata dai valori anomali, come altre misure di dispersione. Inoltre, la varianza √® espressa in un‚Äôunit√† di misura che √® il quadrato dell‚Äôunit√† di misura dei dati originali, pertanto, potrebbe non essere facilmente interpretata in modo intuitivo.\nCalcoliamo la varianza dei valori math per i dati del progetto STAR. Applicando l‚Äôequazione della varianza, otteniamo:\n\nsum((df[\"math\"] - np.mean(df[\"math\"])) ** 2) / len(df[\"math\"])\n\n1507.2328523125227\n\n\nPi√π semplicemente, possiamo usare la funzione np.var():\n\nnp.var(df[\"math\"])\n\n1507.2328523125227\n\n\n\n18.3.2.1 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell‚ÄôEquazione¬†18.3, ho utilizzato \\(n\\) come denominatore (l‚Äôampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, √® possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{18.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si pu√≤ dimostrare che l‚ÄôEquazione¬†18.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l‚ÄôEquazione¬†18.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione √® illustrata nella figura seguente.\n\nx = np.arange(100 - 4 * 15, 100 + 4 * 15, 0.001)\n\nmu = 100\nsigma = 15\n\ncolor_edge = \"#8f2727\"\npdf = stats.norm.pdf(x, mu, sigma)\nplt.plot(x, pdf, color=color_edge)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()\n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza ‚Äì in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nx = rng.normal(loc=100, scale=15, size=4)\nprint(x)\n\n[ 96.66036673 119.88488115  91.43544977 110.02373805]\n\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza √® \\(15^2\\) = 225.\n\nnp.var(x)\n\n134.65656223872708\n\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nIl primo campione √®\n\nrandom_samples[0]\n\narray([133.75543403, 101.43900843,  94.59994101,  92.23138768])\n\n\nIl decimo campione √®\n\nrandom_samples[9]\n\narray([ 89.06126415, 109.72357033, 119.31191461, 125.38475089])\n\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs = np.array(random_samples)\nrs\n\narray([[133.75543403, 101.43900843,  94.59994101,  92.23138768],\n       [105.84924945, 124.12259109,  95.58010071,  76.35634967],\n       [ 80.23586783, 114.3021062 ,  98.54492676,  91.47149307],\n       [114.26794026,  86.66403178,  79.74954446, 102.23174837],\n       [110.22926012,  80.75554712, 100.93634803,  83.44336602],\n       [ 80.68461566, 122.39378237, 115.0707391 ,  85.53365763],\n       [ 82.42398628,  99.06628072,  95.40790879,  95.03682044],\n       [ 86.56471564,  97.82411638,  98.28650923,  99.23388255],\n       [120.24780337,  94.92211176,  87.6421954 ,  89.48037814],\n       [ 89.06126415, 109.72357033, 119.31191461, 125.38475089]])\n\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo cos√¨ 10 stime della varianza della popolazione del QI.\n\nx_var = np.var(rs, axis=1)  # applichiamo la funzione su ciascuna riga\nprint(x_var)\n\n[277.43209934 298.44010918 152.5955359  180.87367224 149.56472568\n 326.89426388  39.64935846  26.73631903 171.07120901 189.71979388]\n\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno √® noto con il nome di variabilit√† campionaria;\nin media le stime sembrano troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=0, axis=1)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(x_var, bins=10, color=color_fill, edgecolor=color_edge)\nplt.xlabel(\"Varianza\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Varianza del QI in campioni di n = 4\")\nplt.show()\n\n\n\n\n\n\n\n\nLa stima pi√π verosimile della varianza del QI √® dato dalla media di questa distribuzione.\n\nnp.mean(x_var)\n\n170.04960311858687\n\n\nSi noti che il nostro spospetto √® stato confermato: il valore medio della stima della varianza ottenuta con l‚ÄôEquazione¬†18.3 √® troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=1, axis=1)\n\nnp.mean(x_var)\n\n226.57872540048734\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima √® molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilit√† di un particolare campione di osservazioni. D‚Äôaltro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione √® stato estratto.\n\n\n\n18.3.3 Deviazione standard\nPer interpretare la varianza in modo pi√π intuitivo, si pu√≤ calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard √® espressa nell‚Äôunit√† di misura originaria dei dati, a differenza della varianza che √® espressa nel quadrato dell‚Äôunit√† di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo pi√π facile la comprensione della variabilit√† dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) √® definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{18.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation √® stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano ‚Äúdeviazione standard‚Äù ne √® la traduzione pi√π utilizzata nel linguaggio comune; il termine dell‚ÄôEnte Nazionale Italiano di Unificazione √® tuttavia ‚Äúscarto tipo‚Äù, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media √® una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, √® importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard pu√≤ risultare ingannevole e non rappresentare accuratamente la variabilit√† complessiva della distribuzione. Pertanto, √® fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere pi√π appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilit√† dei dati in modo pi√π accurato e affidabile.\nPer fare un esempio, calcoliamo la deviazione standard per i valori math del campione di dati del progetto STAR. Applicando l‚ÄôEquazione¬†18.5, per tutto il campione abbiamo\n\nnp.std(df.math)\n\n38.82309689234648\n\n\nPer ciascun gruppo, abbiamo:\n\ndf.groupby(\"graduated\")[\"math\"].std()\n\ngraduated\n0    34.105746\n1    38.130136\nName: math, dtype: float64\n\n\n\n18.3.3.1 Interpretazione\nLa deviazione standard pu√≤ essere interpretata in modo semplice: essa rappresenta la dispersione dei dati rispetto alla media aritmetica. √à simile allo scarto semplice medio campionario, cio√® alla media aritmetica dei valori assoluti degli scarti tra ciascuna osservazione e la media, anche se non √® identica. La deviazione standard ci fornisce un‚Äôindicazione di quanto, in media, le singole osservazioni si discostino dal centro della distribuzione.\nPer verificare l‚Äôinterpretazione della deviazione standard, utilizziamo i valori math del campione di dati del progetto STAR.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nLa deviazione standard calcolata per questi dati √® \\(\\approx 38.8\\). Questo valore ci indica che, in media, ogni osservazione si discosta di circa 38.8 punti dalla media aritmetica dei punteggi math. Maggiore √® il valore della deviazione standard, maggiore √® la dispersione dei dati attorno alla media, mentre un valore pi√π piccolo indica che i dati sono pi√π concentrati vicino alla media. La deviazione standard ci offre quindi una misura quantitativa della variabilit√† dei dati nella distribuzione.\nPer questi dati, lo scarto semplice medio campionario √®\n\nnp.mean(np.abs(df.math - np.mean(df.math)))\n\n30.9682664274501\n\n\nSi noti che i due valori sono simili, ma non identici.\n\n\n\n18.3.4 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione √® la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana. Matematicamente, la formula per calcolare la MAD √®:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{18.6}\\]\nLa deviazione mediana assoluta √® particolarmente utile quando si affrontano distribuzioni con presenza di dati anomali o asimmetrie, poich√© √® meno influenzata da questi valori estremi rispetto alla deviazione standard.\nQuando i dati seguono una distribuzione gaussiana (normale), esiste una relazione specifica tra MAD e la deviazione standard (si veda il Capitolo {ref}cont-rv-distr-notebook). In una distribuzione normale, la MAD √® proporzionale alla deviazione standard. La costante di proporzionalit√† dipende dalla forma esatta della distribuzione normale, ma in generale, la relazione √® data da:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\\(\\sigma\\) √® la deviazione standard.\nMAD √® la Mediana della Deviazione Assoluta.\n\\(k\\) √® una costante che, per una distribuzione normale, √® tipicamente presa come circa 1.4826.\n\nQuesta costante di 1.4826 √® derivata dal fatto che, in una distribuzione normale, circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media. Quindi, per convertire la MAD (basata sulla mediana) nella deviazione standard (basata sulla media), si usa il reciproco di 0.6745, che √® approssimativamente 1.4826.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale √®:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione √® utile per stimare la deviazione standard in modo pi√π robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un‚Äôindicazione pi√π intuitiva della variabilit√† dei dati. Tuttavia, √® importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilit√† dei dati.\nPer verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori math del campione di dati del progetto STAR.\n\n1.4826 * np.median(np.abs(df[\"math\"] - np.median(df[\"math\"])))\n\n41.5128\n\n\nIn questo caso, la MAD per i punteggi di matematica √® simile alla deviazione standard.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nInfatti, la distribuzione dei punteggi math √® approssimativamente gaussiana.\n\nplt.hist(df[\"math\"], bins=10, color=color_fill, edgecolor=color_edge)\nplt.xlabel(\"math\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione dei Punteggi di Matematica\")\nplt.show()\n\n\n\n\n\n\n\n\nVerifichiamo nuovamente il principio usando un campione di dati estratto da una popolazione normale. Usiamo, ad esempio, la distribuzione \\(\\mathcal{N}(100, 15)\\):\n\nx = np.random.normal(loc=100, scale=15, size=10000)\n1.4826 * np.median(np.abs(x - np.median(x)))\n\n15.152283592574692\n\n\n\n\n18.3.5 Quando usare la deviazione standard e MAD\nLa deviazione standard e la MAD sono entrambe misure di dispersione che forniscono informazioni su quanto i dati in un insieme si discostano dalla tendenza centrale. Tuttavia, ci sono alcune differenze tra le due misure e situazioni in cui pu√≤ essere pi√π appropriato utilizzare una rispetto all‚Äôaltra.\n\nDeviazione standard: Questa misura √® particolarmente utile per descrivere la dispersione dei dati in una distribuzione normale. La deviazione standard √® una scelta appropriata se si vuole sapere quanto i dati sono distribuiti intorno alla media, o se si vuole confrontare la dispersione di due o pi√π set di dati. Tuttavia, la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, e questo pu√≤ rappresentare una limitazione in casi in cui sono presenti valori estremi nell‚Äôinsieme di dati.\nDeviazione mediana assoluta (MAD): La MAD √® meno sensibile ai valori anomali rispetto alla deviazione standard, il che la rende una scelta migliore quando ci sono valori anomali nell‚Äôinsieme di dati. Inoltre, la MAD pu√≤ essere una buona scelta quando si lavora con dati non normalmente distribuiti, poich√© non assume una distribuzione specifica dei dati. La MAD √® calcolata utilizzando la mediana e i valori assoluti delle deviazioni dei dati dalla mediana, il che la rende una misura robusta di dispersione.\n\nIn sintesi, se si sta lavorando con dati normalmente distribuiti, la deviazione standard √® la misura di dispersione pi√π appropriata. Se si lavora con dati non normalmente distribuiti o si hanno valori anomali nell‚Äôinsieme di dati, la MAD pu√≤ essere una scelta migliore. In ogni caso, la scelta tra le due misure dipende dal tipo di dati che si sta analizzando e dall‚Äôobiettivo dell‚Äôanalisi.\n\n\n18.3.6 Indici di variabilit√† relativi\nA volte pu√≤ essere necessario confrontare la variabilit√† di grandezze incommensurabili, ovvero di caratteri misurati con differenti unit√† di misura. In queste situazioni, le misure di variabilit√† descritte in precedenza diventano inadeguate poich√© dipendono dall‚Äôunit√† di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilit√†.\nIl pi√π importante di questi indici √® il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{18.7}\\]\nIl coefficiente di variazione √® un numero puro e permette di confrontare la variabilit√† di distribuzioni con unit√† di misura diverse.\nUn altro indice relativo di variabilit√† √® la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice √® definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilit√† forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unit√† di misura e facilitando l‚Äôanalisi delle differenze di variabilit√† tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/03_loc_scale.html#la-fallacia-ergodica",
    "title": "18¬† Indici di posizione e di scala",
    "section": "18.4 La fallacia ergodica",
    "text": "18.4 La fallacia ergodica\nSebbene il concetto di ‚Äúmedia‚Äù possa sembrare chiaro, ci√≤ non implica che il suo utilizzo non presenti delle problematiche nell‚Äôambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi √® ci√≤ che viene definito ‚Äúfallacia ergodica‚Äù.\nIl concetto di ‚Äúfallacia ergodica‚Äù (Speelman et al. 2024) si riferisce all‚Äôerrore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all‚Äôinterno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio √® che l‚Äôuso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo √® ingiustificato, poich√© le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull‚Äôassunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere cos√¨ simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all‚Äôinterno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di pi√π individui non descrivono accuratamente nessuno di quegli individui in un dato momento, n√© possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell‚Äôassumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_loc_scale.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/03_loc_scale.html#commenti-e-considerazioni-finali",
    "title": "18¬† Indici di posizione e di scala",
    "section": "18.5 Commenti e considerazioni finali",
    "text": "18.5 Commenti e considerazioni finali\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un‚Äôidea della variabilit√† dei dati. In sintesi, le statistiche descrittive ci offrono un quadro chiaro e sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilit√†.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/03_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "18¬† Indici di posizione e di scala",
    "section": "18.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "18.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, e Marek McGann. 2024. ¬´Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals¬ª. Collabra: Psychology 10 (1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html",
    "href": "chapters/eda/04_correlation.html",
    "title": "19¬† Le relazioni tra variabili",
    "section": "",
    "text": "Introduzione\nNonostante sia un‚Äôoperazione di base, l‚Äôanalisi delle associazioni tra variabili rappresenta uno degli aspetti pi√π controversi nell‚Äôambito dell‚Äôanalisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l‚Äôanalisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l‚Äôanalisi delle associazioni tra variabili √® stata considerata come l‚Äôobiettivo finale del processo di ricerca. Questa visione si basa sull‚Äôidea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, √® altres√¨ evidente che la nostra comprensione di un fenomeno non pu√≤ dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la ‚ÄúCausal Revolution‚Äù propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l‚Äôobiettivo principale della ricerca √® l‚Äôidentificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici √® essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sar√† trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. √à importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all‚Äôutilizzo di indici lineari.\nNel linguaggio comune, termini come ‚Äúdipendenza‚Äù, ‚Äúassociazione‚Äù e ‚Äúcorrelazione‚Äù vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, √® importante distinguere questi concetti:\n√à cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalit√†. Questa distinzione √® fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell‚Äôassociazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#introduzione",
    "href": "chapters/eda/04_correlation.html#introduzione",
    "title": "19¬† Le relazioni tra variabili",
    "section": "",
    "text": "Quanto spesso, quando √® stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‚Äòqual √® la sua causa?‚Äô. Questa √® una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, pu√≤ essere pi√π facile rispondere alla domanda: ‚Äòin che misura altri fenomeni sono associati con esso?‚Äô. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un‚Äôaltra.\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), √® probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l‚Äôintensit√† di una relazione lineare.\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/04_correlation.html#i-dati-grezzi",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.1 I dati grezzi",
    "text": "19.1 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione √® stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II √® uno strumento di autovalutazione utilizzato per valutare la gravit√† della depressione in adulti e adolescenti. Il test √® stato sviluppato per identificare e misurare l‚Äôintensit√† dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado pi√π basso e 3 il grado pi√π elevato di sintomatologia depressiva.\nNell‚Äôesercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche, Buerkner, e Renneberg (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/04_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.2 Definizione delle relazioni tra variabili",
    "text": "19.2 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o pi√π variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ci√≤, prendiamo ad esempio l‚Äôaltezza e l‚Äôet√† tra un gruppo di bambini. In generale, √® possibile notare che all‚Äôaumentare dell‚Äôet√† di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l‚Äôet√† di un bambino, ad esempio tredici anni, e l‚Äôet√† di un altro, sei anni, ci fornisce un‚Äôindicazione su quale dei due bambini sia pi√π alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e et√† come positiva, il che significa che all‚Äôaumentare dei valori di una delle variabili (in questo caso, l‚Äôet√†), ci aspettiamo di vedere valori pi√π elevati anche nell‚Äôaltra variabile (l‚Äôaltezza). Tuttavia, esistono anche relazioni negative, in cui l‚Äôaumento di una variabile √® associato a un diminuzione dell‚Äôaltra (ad esempio, pi√π et√† √® correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo cos√¨ una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili pu√≤ essere categorica, rendendo difficile parlare di ‚Äúmaggioranza‚Äù o ‚Äúminoranza‚Äù ma piuttosto di ‚Äúdifferente‚Äù (ad esempio, i bambini pi√π grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini pi√π piccoli, senza necessariamente essere ‚Äúmigliori‚Äù o ‚Äúpeggiori‚Äù).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/04_correlation.html#sec-scatter-plot",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.3 Grafico a dispersione",
    "text": "19.3 Grafico a dispersione\nIl metodo pi√π diretto per visualizzare la relazione tra due variabili continue √® tramite un grafico a dispersione, comunemente noto come ‚Äúscatterplot‚Äù. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull‚Äôasse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l‚Äôidea pi√π chiara, consideriamo i dati dello studio condotto da Zetsche, Buerkner, e Renneberg (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II √® uno strumento di autovalutazione che valuta la presenza e l‚Äôintensit√† dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D √® una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poich√© entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf = pd.read_csv(\"../../data/data.mood.csv\", index_col=0)\n\n# Seleziona le colonne di interesse\ndf = df[[\"esm_id\", \"group\", \"bdi\", \"cesd_sum\"]]\n\n# Rimuovi le righe duplicate\ndf = df.drop_duplicates(keep=\"first\")\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf = df.dropna(subset=[\"bdi\"])\n\nPosizionando i valori del BDI-II sull‚Äôasse delle ascisse e quelli del CES-D sull‚Äôasse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. √à evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l‚Äôutilizzo di unit√† di misura arbitrarie per le due variabili. L‚Äôerrore di misurazione √® una componente inevitabile che influisce in parte su qualsiasi misurazione, ed √® particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione √® generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici √® che l‚Äôunit√† di misura della depressione √® una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all‚Äôuso di unit√† di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di ‚Äúassociazione lineare‚Äù, √® possibile esaminare i dati attraverso l‚Äôutilizzo di un diagramma a dispersione.\n\n# Crea uno scatterplot con colori diversi per i due gruppi\nplt.scatter(df[df[\"group\"] == \"mdd\"][\"bdi\"], df[df[\"group\"] == \"mdd\"][\"cesd_sum\"], label=\"Pazienti\", c=\"C0\")\nplt.scatter(df[df[\"group\"] == \"ctl\"][\"bdi\"], df[df[\"group\"] == \"ctl\"][\"cesd_sum\"], label=\"Controlli\", c=\"C2\")\n\n# Calcola i coefficienti della retta dei minimi quadrati\ncoeff_combined = np.polyfit(df[\"bdi\"], df[\"cesd_sum\"], 1)\n\n# Calcola la retta dei minimi quadrati\nline_combined = np.poly1d(coeff_combined)\n\n# Disegna la retta dei minimi quadrati\nx_values = np.linspace(df[\"bdi\"].min(), df[\"bdi\"].max(), 100)\nplt.plot(x_values, line_combined(x_values), linestyle='--', color='C3')\n\n# Etichette degli assi\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"CESD\")\n\n# Linee verticali ed orizzontali per le medie\nplt.axvline(np.mean(df[df[\"group\"] == \"mdd\"][\"bdi\"]), alpha=0.2, color=\"blue\")\nplt.axvline(np.mean(df[df[\"group\"] == \"ctl\"][\"bdi\"]), alpha=0.2, color=\"red\")\nplt.axhline(np.mean(df[df[\"group\"] == \"mdd\"][\"cesd_sum\"]), alpha=0.2, color=\"blue\")\nplt.axhline(np.mean(df[df[\"group\"] == \"ctl\"][\"cesd_sum\"]), alpha=0.2, color=\"red\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, √® evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ci√≤ suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, √® importante notare che la relazione lineare tra le due variabili √® lontana dall‚Äôessere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realt√†, la dispersione dei punti dal comportamento lineare ideale √® evidente.\nDi conseguenza, sorge la necessit√† di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#covarianza",
    "href": "chapters/eda/04_correlation.html#covarianza",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.4 Covarianza",
    "text": "19.4 Covarianza\nIniziamo a considerare il pi√π importante di tali indici, chiamato covarianza. In realt√† la definizione di questo indice non ci sorprender√† pi√π di tanto in quanto, in una forma solo apparentemente diversa, l‚Äôabbiamo gi√† incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) √® definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la ‚Äúcovarianza di una variabile con s√© stessa‚Äù. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) ‚Äúvariano insieme‚Äù (co-variano). √à facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{19.1}\\]\nL‚ÄôEquazione¬†19.1 ci fornisce la definizione della covarianza.\n\n19.4.1 Interpretazione\nPer capire il significato dell‚ÄôEquazione¬†19.1, supponiamo di dividere il grafico riportato nella Sezione 19.3 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avr√† un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avr√† segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avr√† un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avr√† segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l‚Äôassociazione lineare si dice positiva se la covarianza √® positiva, negativa se la covarianza √® negativa.\nEsercizio. Implemento l‚ÄôEquazione¬†19.1 in Python.\n\ndef cov_value(x, y):\n\n    mean_x = sum(x) / float(len(x))\n    mean_y = sum(y) / float(len(y))\n\n    sub_x = [i - mean_x for i in x]\n    sub_y = [i - mean_y for i in y]\n\n    sum_value = sum([sub_y[i] * sub_x[i] for i in range(len(x))])\n    denom = float(len(x))\n\n    cov = sum_value / denom\n    return cov\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD √® 207.4\n\nx = df[\"bdi\"]\ny = df[\"cesd_sum\"]\n\ncov_value(x, y)\n\n207.42653810835637\n\n\nOppure, in maniera pi√π semplice:\n\nnp.mean((x - np.mean(x)) * (y - np.mean(y)))\n\n207.42653810835628\n\n\nLo stesso risultato si ottiene con la funzione cov di NumPy.\n\nnp.cov(x, y, ddof=0)\n\narray([[236.23875115, 207.42653811],\n       [207.42653811, 222.83379247]])\n\n\nLa funzione np.cov(x, y, ddof=0) in Python, utilizzata tramite la libreria NumPy, calcola la covarianza tra due array, x e y. L‚Äôargomento ddof (Delta Degrees of Freedom) specifica il ‚Äúcorrettore‚Äù da applicare al denominatore della formula di covarianza.\nQuando si imposta ddof=0, la formula utilizzata per il calcolo della covarianza divide la somma dei prodotti delle deviazioni dalla media per n, dove n √® il numero totale degli elementi nel campione (ovvero, la dimensione del campione). Questo approccio assume che i dati forniti rappresentino l‚Äôintera popolazione da cui si vuole stimare la covarianza, producendo una stima non corretta (bias) se i dati sono effettivamente un campione di una popolazione pi√π ampia. Il ‚Äúbias‚Äù in questo contesto si riferisce al fatto che la stima tende sistematicamente a essere pi√π piccola rispetto alla vera covarianza della popolazione da cui il campione √® stato estratto.\nPer correggere questo errore sistematico e ottenere una stima non distorta (unbiased) della covarianza di una popolazione pi√π ampia basandosi su un campione, si utilizza ddof=1. Questo significa che al denominatore della formula si sottrae 1 a n, dividendo quindi per n-1. Il correttore n-1 √® noto come correttore di Bessel, e l‚Äôuso di ddof=1 rende la stima della covarianza non distorta nel contesto di un campione prelevato da una popolazione. La correzione √® importante in statistica perch√© fornisce una stima pi√π accurata delle propriet√† della popolazione, soprattutto quando la dimensione del campione √® piccola.\nIn sintesi: - Con ddof=0, si divide per n, assumendo che i dati rappresentino l‚Äôintera popolazione. Questo pu√≤ introdurre un bias nella stima della covarianza se i dati sono in realt√† un campione. - Con ddof=1, si divide per n-1, correggendo il bias e ottenendo una stima non distorta (unbiased) della covarianza se i dati rappresentano un campione di una popolazione pi√π grande. Questo approccio √® generalmente preferito per la stima delle propriet√† della popolazione basata su campioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#correlazione",
    "href": "chapters/eda/04_correlation.html#correlazione",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.5 Correlazione",
    "text": "19.5 Correlazione\nLa direzione della relazione tra le variabili √® indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poich√© dipende dall‚Äôunit√† di misura delle variabili. Ad esempio, considerando l‚Äôaltezza e il peso delle persone, la covarianza sar√† pi√π grande se l‚Äôaltezza √® misurata in millimetri e il peso in grammi, rispetto al caso in cui l‚Äôaltezza √® in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l‚Äôindice di correlazione.\nLa correlazione √® ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr_{XY} = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{19.2}\\]\nLa quantit√† che si ottiene dall‚ÄôEquazione¬†19.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l‚Äôuno dall‚Äôaltro, l‚Äôhanno introdotta).\n\n19.5.1 Propriet√†\nIl coefficiente di correlazione ha le seguenti propriet√†:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\n√® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n19.5.2 Interpretazione\nAll‚Äôindice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensit√† diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza √® 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c‚Äô√® un‚Äôassociazione lineare positiva. Per capire quale sia l‚Äôintensit√† della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore √® prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\nnp.corrcoef(x, y)\n\narray([[1.        , 0.90406202],\n       [0.90406202, 1.        ]])\n\n\nReplichiamo il risultato implementando l‚Äôeq. {eq}eq-cor-def:\n\ns_xy = np.mean((x - np.mean(x)) * (y - np.mean(y)))\ns_x = x.std(ddof=0)\ns_y = y.std(ddof=0)\nr_xy = s_xy / (s_x * s_y)\nprint(r_xy)\n\n0.9040620189474861\n\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD √® quello di standardizzare le due variabili per poi applicare la formula della covarianza:\n\nz_x = (x - np.mean(x)) / np.std(x, ddof=0)\nz_y = (y - np.mean(y)) / np.std(y, ddof=0)\nnp.mean(z_x * z_y)\n\n0.9040620189474862\n\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al.¬†(2024). Il concetto di ‚Äúgender bias‚Äù si riferisce alla tendenza sistematica di favorire un sesso rispetto all‚Äôaltro, spesso a scapito delle donne. Lo studio di Guilbeault et al.¬†(2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralit√† di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella societ√†. Il lavoro di Guilbeault et al.¬†(2024) evidenzia che il preconcetto di genere √® molto pi√π evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto pu√≤ essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al.¬†(2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura √® vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi √® alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralit√† di genere. In sostanza, questa misura di frequenza pu√≤ essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell‚Äôaltro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere √® pi√π prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell‚Äôassociazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione √® stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al.¬†(2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/04_correlation.html#correlazione-di-spearman",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.6 Correlazione di Spearman",
    "text": "19.6 Correlazione di Spearman\nUn‚Äôalternativa per valutare la relazione lineare tra due variabili √® il coefficiente di correlazione di Spearman, che si basa esclusivamente sull‚Äôordine dei dati e non sugli specifici valori. Questo indice di associazione √® particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalit√† di risposta dei soggetti, ma non l‚Äôintensit√† della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come ‚Äúordinali‚Äù.\n\n\n\n\n\n\n√à importante ricordare che, nel caso di una variabile ordinale, non √® possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, √® possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalit√† di risposta. Come abbiamo appena visto, la direzione e l‚Äôintensit√† dell‚Äôassociazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\nstats.spearmanr([1, 2, 3, 4, 5], [5, 6, 7, 8, 7])\n\nSignificanceResult(statistic=0.8207826816681233, pvalue=0.08858700531354381)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#correlazione-nulla",
    "href": "chapters/eda/04_correlation.html#correlazione-nulla",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.7 Correlazione nulla",
    "text": "19.7 Correlazione nulla\nUn aspetto finale da sottolineare riguardo alla correlazione √® che essa descrive la direzione e l‚Äôintensit√† della relazione lineare tra due variabili. Tuttavia, la correlazione non cattura relazioni non lineari tra le variabili, anche se possono essere molto forti. √à fondamentale comprendere che una correlazione pari a zero non implica l‚Äôassenza di una relazione tra le due variabili, ma indica solamente l‚Äôassenza di una relazione lineare tra di esse.\nLa figura seguente fornisce tredici esempi di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili. In questi tredici insiemi di dati i coefficienti di correlazione di Pearson sono sempre uguali a 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n\ndatasaurus_data = pd.read_csv(\"../../data/datasaurus.csv\")\ndatasaurus_data.groupby(\"dataset\").agg(\n    {\"x\": [\"count\", \"mean\", \"std\"], \"y\": [\"count\", \"mean\", \"std\"]}\n)\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\ncount\nmean\nstd\ncount\nmean\nstd\n\n\ndataset\n\n\n\n\n\n\n\n\n\n\naway\n142\n54.266100\n16.769825\n142\n47.834721\n26.939743\n\n\nbullseye\n142\n54.268730\n16.769239\n142\n47.830823\n26.935727\n\n\ncircle\n142\n54.267320\n16.760013\n142\n47.837717\n26.930036\n\n\ndino\n142\n54.263273\n16.765142\n142\n47.832253\n26.935403\n\n\ndots\n142\n54.260303\n16.767735\n142\n47.839829\n26.930192\n\n\nh_lines\n142\n54.261442\n16.765898\n142\n47.830252\n26.939876\n\n\nhigh_lines\n142\n54.268805\n16.766704\n142\n47.835450\n26.939998\n\n\nslant_down\n142\n54.267849\n16.766759\n142\n47.835896\n26.936105\n\n\nslant_up\n142\n54.265882\n16.768853\n142\n47.831496\n26.938608\n\n\nstar\n142\n54.267341\n16.768959\n142\n47.839545\n26.930275\n\n\nv_lines\n142\n54.269927\n16.769959\n142\n47.836988\n26.937684\n\n\nwide_lines\n142\n54.266916\n16.770000\n142\n47.831602\n26.937902\n\n\nx_shape\n142\n54.260150\n16.769958\n142\n47.839717\n26.930002\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(4, 4, figsize=(15, 15))\ndatasets = datasaurus_data[\"dataset\"].unique()\n\nfor i, dataset in enumerate(datasets):\n    row = i // 4\n    col = i % 4\n    ax = axs[row, col]\n    subset = datasaurus_data[datasaurus_data[\"dataset\"] == dataset]\n    ax.scatter(subset[\"x\"], subset[\"y\"], alpha=0.7)\n    ax.set_title(dataset)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61607/188333220.py:14: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#due-paradossi-comuni",
    "href": "chapters/eda/04_correlation.html#due-paradossi-comuni",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.8 Due Paradossi Comuni",
    "text": "19.8 Due Paradossi Comuni\nEsistono due situazioni comuni in cui le associazioni tra variabili possono ingannarci, e che vale la pena esaminare esplicitamente: il paradosso di Simpson e il paradosso di Berkson.\n\n19.8.1 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando stimiamo una relazione per sottoinsiemi dei nostri dati, ma otteniamo una relazione diversa considerando l‚Äôintero dataset (Simpson 1951). √à un caso particolare della fallacia ecologica, che si verifica quando cerchiamo di fare affermazioni sugli individui basandoci sui loro gruppi. Ad esempio, potrebbe esserci una relazione positiva tra i voti universitari e la performance alla scuola di specializzazione in due dipartimenti considerati individualmente. Tuttavia, se i voti universitari tendono a essere pi√π alti in un dipartimento rispetto all‚Äôaltro, mentre la performance alla scuola di specializzazione tende a essere opposta, potremmo trovare una relazione negativa tra i voti universitari e la performance alla scuola di specializzazione.\n\n\n19.8.2 Paradosso di Berkson\nIl paradosso di Berkson si verifica quando stimiamo una relazione basandoci sul dataset che abbiamo, ma a causa della selezione del dataset, la relazione risulta diversa in un dataset pi√π generale (Berkson 1946). Ad esempio, se abbiamo un dataset di ciclisti professionisti, potremmo non trovare una relazione tra il loro VO2 max e la possibilit√† di vincere una gara di ciclismo (Coyle et al.¬†1988; Podlogar, Leo, and Spragg 2022). Tuttavia, se avessimo un dataset della popolazione generale, potremmo trovare una relazione tra queste due variabili. Il dataset professionale √® cos√¨ selezionato che la relazione scompare; non si pu√≤ diventare ciclisti professionisti senza avere un VO2 max adeguato, ma tra i ciclisti professionisti, tutti hanno un VO2 max sufficiente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#considerazioni-conclusive",
    "href": "chapters/eda/04_correlation.html#considerazioni-conclusive",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.9 Considerazioni conclusive",
    "text": "19.9 Considerazioni conclusive\nIn questo capitolo, abbiamo esplorato i concetti fondamentali di correlazione e covarianza, strumenti essenziali per quantificare le relazioni tra variabili nei fenomeni psicologici. Tuttavia, √® cruciale sottolineare che le associazioni osservate non sono necessariamente indicative dei meccanismi causali sottostanti.\nLe relazioni tra variabili possono manifestarsi in diversi scenari:\n\nCausalit√† Diretta: Quando una variabile \\(X\\) influenza causalmente una variabile \\(Y\\), si osserver√† un‚Äôassociazione tra le due. In un contesto ideale, con un effetto causale lineare e isolato, la correlazione rifletter√† direttamente l‚Äôentit√† e la direzione dell‚Äôeffetto causale.\nInterferenza di Altre Variabili: La realt√† √® spesso pi√π complessa. Anche in presenza di una relazione causale diretta tra \\(X\\) e \\(Y\\), l‚Äôintervento di altre variabili pu√≤ alterare significativamente l‚Äôassociazione osservata. Come vedremo nel capitolo successivo, a seconda della struttura delle relazioni causali, possiamo riscontrare associazioni positive, nulle o addirittura negative, pur in presenza di un effetto causale positivo.\nAssociazioni Spurie: √à possibile osservare associazioni tra variabili anche in assenza di qualsiasi relazione causale diretta. Questo fenomeno sottolinea l‚Äôimportanza di non confondere correlazione e causalit√†.\n\nQuesti scenari evidenziano un principio fondamentale: l‚Äôosservazione di un‚Äôassociazione tra due variabili, in assenza di ulteriori informazioni, non permette di trarre conclusioni definitive sulle relazioni causali sottostanti. Le associazioni, prese singolarmente, non forniscono informazioni utili sul fenomeno in esame.\nNonostante questi limiti, le associazioni tra variabili non perdono il loro valore. Quando integrate in un contesto pi√π ampio, che include:\n\nla misurazione di molteplici variabili,\nla conoscenza approfondita del dominio di studio,\nl‚Äôapplicazione di metodi statistici avanzati,\n\nle associazioni possono diventare strumenti preziosi per descrivere le caratteristiche dei meccanismi che governano i fenomeni psicologici di interesse.\nNel prossimo capitolo approfondiremo queste tematiche, esplorando metodi e approcci che ci permetteranno di andare oltre la semplice osservazione delle associazioni, verso una comprensione causale dei fenomeni psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "19¬† Le relazioni tra variabili",
    "section": "19.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "19.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 31 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html",
    "href": "chapters/eda/05_causality.html",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "",
    "text": "Introduzione\nLa pura osservazione dei dati pu√≤ rivelare correlazioni e pattern nei dati, ma senza un‚Äôindagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro ‚ÄúStatistical Rethinking‚Äù (McElreath 2020), utilizza l‚Äôanalogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che √® stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull‚Äôanalisi delle associazioni statistiche tra variabili, trascurando considerazioni pi√π profonde sulla causalit√†.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione √® evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\n√à importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica √® stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilit√† nella ricerca psicologica, come approfondito nel Capitolo 83. L‚Äôapproccio descritto, pur essendo potente nell‚Äôindividuare correlazioni, manca della ‚Äúsaggezza‚Äù necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) √® che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull‚Äôanalisi delle associazioni mediante il test dell‚Äôipotesi nulla non √® in grado di distinguere tra questi diversi scenari, come spiegato nel Capitolo 62.\nL‚Äôapproccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacit√† di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al. 2023). √à invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull‚Äôintroduzione dei concetti fondamentali dell‚Äôanalisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#introduzione",
    "href": "chapters/eda/05_causality.html#introduzione",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall‚Äôalto, l‚Äôutente risponde a una serie di domande riguardanti la misurazione e l‚Äôintento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#cos√®-la-causalit√†",
    "href": "chapters/eda/05_causality.html#cos√®-la-causalit√†",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.1 Cos‚Äô√® la causalit√†?",
    "text": "20.1 Cos‚Äô√® la causalit√†?\nQuando parliamo di ‚Äúcausalit√†‚Äù, ci riferiamo a un concetto fondamentale nella ricerca scientifica. Ma cosa significa esattamente affermare che qualcosa √® ‚Äúcausale‚Äù? E perch√© √® cos√¨ importante comprendere la causalit√†?\nMolte delle domande di ricerca che ci interessano sono di natura causale. Ad esempio:\n\nNon ci basta sapere se le persone che praticano regolarmente attivit√† fisica soffrono meno d‚Äôansia; vogliamo capire se l‚Äôattivit√† fisica effettivamente riduce i livelli d‚Äôansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT realmente diminuisce questi sintomi.\nNon ci limitiamo a constatare che l‚Äôuso frequente dei social media √® associato a un calo del benessere mentale; vogliamo determinare se l‚Äôuso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nSebbene non esista una definizione univoca di causalit√†, possiamo concettualizzarla cos√¨: diciamo che A causa B se, intervenendo e modificando il valore di A, anche la distribuzione di B cambia di conseguenza.\nPrendiamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l‚Äôansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d‚Äôansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando cos√¨ il valore di A), i livelli d‚Äôansia nel gruppo diminuiranno (cambiando quindi il valore di B). Questa definizione ci permette di distinguere tra semplice correlazione e vera causalit√†.\nPossiamo applicare questa definizione anche per collegare variabili apparentemente distanti. Ad esempio, l‚Äôautoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l‚Äôautoefficacia attraverso interventi mirati, probabilmente osserveremo un miglioramento nell‚Äôimpegno allo studio. Quindi, l‚Äôaumento dell‚Äôautoefficacia causa un incremento dell‚Äôimpegno nello studio. E se aumentiamo l‚Äôimpegno nello studio, questo migliorer√† le prestazioni accademiche. Di conseguenza, indirettamente, l‚Äôautoefficacia influisce sulle prestazioni accademiche.\n√à importante precisare che affermiamo che A causa B anche quando modificare A non porta sempre direttamente a un cambiamento in B, ma altera solo la probabilit√† che B si verifichi. In altre parole, modifica la distribuzione di B.\nUn‚Äôulteriore precisazione riguarda le variabili non manipolabili, come i tratti di personalit√†. Anche queste variabili possono avere effetti causali. √à possibile indagare cosa sarebbe accaduto se il tratto di personalit√† di un individuo fosse stato diverso, effettuando una sorta di manipolazione teorica.\nIn sintesi, la causalit√† implica che un cambiamento in A provoca un cambiamento in B, anche se non sempre in modo diretto e certo, ma alterando la probabilit√† che B si verifichi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#variabili-confondenti",
    "href": "chapters/eda/05_causality.html#variabili-confondenti",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.2 Variabili confondenti",
    "text": "20.2 Variabili confondenti\nI fenomeni psicologici sono intrinsecamente complessi. Questa complessit√† si manifesta nella presenza di numerose variabili confondenti, ovvero variabili che influenzano sia una causa che un effetto di interesse.\nA differenza delle variabili che influenzano solo l‚Äôeffetto, le variabili confondenti complicano notevolmente l‚Äôanalisi causale. Queste variabili possono portare a stime errate degli effetti causali se non vengono misurate e controllate nelle analisi statistiche. La mancata considerazione delle variabili confondenti introduce un bias nei nostri stimatori statistici, portando a stime che non riflettono il vero valore dell‚Äôeffetto.\nUna soluzione apparentemente semplice sarebbe quella di controllare statisticamente tutte le variabili confondenti. Tuttavia, questo approccio presenta due sfide insormontabili:\n\nrichiede la conoscenza di tutte le possibili variabili confondenti;\nnecessita di misurare ciascuna di queste variabili, cosa che spesso risulta impraticabile.\n\n\n\n\n\n\n\nControllo sperimentale e controllo statistico\n\n\n\nIl controllo √® un elemento fondamentale per stabilire relazioni causali, in quanto consente l‚Äôisolamento degli effetti delle variabili indipendenti da potenziali confondenti che potrebbero influenzare le variabili dipendenti. Si distinguono due principali metodologie di controllo.\n\nIl controllo sperimentale √® implementato attraverso il disegno sperimentale e si basa principalmente sulla randomizzazione. L‚Äôassegnazione casuale dei soggetti ai gruppi sperimentali e di controllo ha lo scopo di distribuire equamente le variabili confondenti tra i gruppi, garantendo che le differenze osservate siano attribuibili alla manipolazione sperimentale.\nIl controllo statistico √® applicato durante l‚Äôanalisi dei dati e mira a neutralizzare o quantificare l‚Äôinfluenza di variabili estranee. Questo si realizza mediante tecniche statistiche e modelli che consentono di isolare l‚Äôeffetto delle variabili indipendenti sulle variabili dipendenti.\n\n\n\nA causa di queste difficolt√†, l‚Äôinferenza causale basata su dati osservazionali viene spesso considerata impossibile, dando origine al famoso detto ‚Äúcorrelazione non implica causazione‚Äù.\nTuttavia, in alcune condizioni, √® possibile trarre inferenze causali dai dati osservazionali. L‚Äôobiettivo di questo capitolo √® introdurre i concetti di base dell‚Äôanalisi causale che permettono di raggiungere tale obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#inferenza-causale",
    "href": "chapters/eda/05_causality.html#inferenza-causale",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.3 Inferenza Causale",
    "text": "20.3 Inferenza Causale\nL‚Äôinferenza causale mira a rappresentare il processo sottostante a un fenomeno, consentendo di prevedere gli effetti di un intervento. Oltre a anticipare le conseguenze di una causa, permette di esplorare scenari controfattuali, immaginando gli esiti alternativi che si sarebbero verificati con decisioni diverse. Questo tipo di ragionamento √® fondamentale sia in contesti descrittivi che inferenziali.\nNonostante gli esperimenti offrano un elevato grado di certezza nella determinazione delle relazioni causali, i disegni osservazionali presentano vantaggi in termini di flessibilit√† e applicabilit√† in situazioni in cui gli esperimenti non possono essere condotti per ragioni etiche o pratiche. L‚Äôobiettivo della ‚ÄúRivoluzione Causale‚Äù √® quello di riuscire a trarre delle conclusioni di tipo causale da dati di natura osservazionale.\nSecondo McElreath (2020), per condurre un‚Äôanalisi causale √® necessario seguire una serie di passaggi chiave:\n\nComprendere il concetto teorico del fenomeno oggetto dell‚Äôanalisi.\nSviluppare modelli causali che descrivano accuratamente le relazioni tra le variabili coinvolte nel problema di ricerca, basandosi sulla teoria sottostante.\nFormulare modelli statistici appropriati che riflettano fedelmente il contesto scientifico e le relazioni causali identificate.\nEseguire simulazioni basate sui modelli causali per verificare se i modelli statistici sviluppati siano in grado di stimare correttamente ci√≤ che √® teoricamente atteso. Questa fase di verifica √® cruciale per garantire la validit√† dei modelli.\nCondurre l‚Äôanalisi dei dati effettivi utilizzando i modelli statistici sviluppati, avendo la fiducia che riflettano accuratamente le teorie sottostanti e le relazioni causali.\n\nIn questo schema, un aspetto chiave √® rappresentato dalla conoscenza del dominio. Senza una tale conoscenza, l‚Äôinferenza causale non √® possibile, e questo rappresenta certamente la difficolt√† maggiore da superare. In presenza di adeguate conoscenze del dominio, secondo McElreath (2020), due strumenti cruciali per l‚Äôinferenza causale sono i Grafi Aciclici Direzionati (DAG) (Rohrer 2018) e l‚Äôuso di modelli statistici avanzati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/05_causality.html#bias-da-variabile-omessa",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.4 Bias da Variabile Omessa",
    "text": "20.4 Bias da Variabile Omessa\nPossiamo introdurre le difficolt√† dell‚Äôinferenza causale facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes e Dee (2024), l‚Äôomissione dall‚Äôanalisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, pu√≤ portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione √® fornita nella Figura¬†20.1 (ispirata da Byrnes e Dee (2024)). La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) √® causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non √® una variabile confondente. Nel pannello centrale, la variabile non osservata (U) √® una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura¬†20.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l‚Äôerrore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell‚Äôeffetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell‚Äôeffetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte.\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell‚Äôinferenza causale dai dati osservazionali. A differenza dell‚Äôerrore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e pu√≤ essere corretto o modellato (McElreath 2020; Schennach 2016), con l‚ÄôOVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non √® necessario abbandonare l‚Äôuso dei dati osservazionali per l‚Äôinferenza causale in psicologia. √à invece necessario ricorrere all‚Äôadozione di di tecniche ben consolidate provenienti da altri campi, quali l‚Äôeconomia, per potere comunque svolgere l‚Äôinferenza causale.\n√à evidente che questo approccio porter√† a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il ‚Äúmodello generativo dei dati‚Äù, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un‚Äôevoluzione della conoscenza scientifica. Tale sviluppo √® reso possibile proprio perch√© le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione pi√π profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/05_causality.html#grafi-aciclici-diretti",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.5 Grafi Aciclici Diretti",
    "text": "20.5 Grafi Aciclici Diretti\nI Grafi Aciclici Diretti (DAG) rappresentano uno strumento essenziale per l‚Äôinferenza causale, offrendo una rappresentazione grafica delle relazioni causali ipotizzate tra le variabili. Sono chiamati ‚Äúdiretti‚Äù perch√© le variabili (nodi) sono collegate da frecce anzich√© semplici linee, e ‚Äúaciclici‚Äù perch√© non √® possibile ritornare a un nodo seguendo il percorso delle frecce.\nIn un DAG, una freccia da X a Y indica che X influenza Y su base probabilistica. I nodi collegati da una freccia sono definiti ‚Äúgenitore‚Äù (origine) e ‚Äúfiglio‚Äù (destinazione). Se si pu√≤ raggiungere B da A seguendo una successione di frecce, A √® detto ‚Äúantenato‚Äù e B ‚Äúdiscendente‚Äù.\nI DAG consentono di identificare le variabili confondenti basandosi sulla teoria di Judea Pearl (Pearl 2009). √à cruciale rappresentare tutte le possibili relazioni, poich√© l‚Äôassenza di una freccia implica la certezza dell‚Äôassenza di relazione.\nDue concetti fondamentali nella teoria dei DAG sono la d-separazione e il criterio del back-door.\n\nLa d-separazione\nLa d-separazione ci aiuta a comprendere come l‚Äôinformazione o l‚Äôinfluenza si propaga tra le variabili in un modello causale. In sostanza, la d-separazione ci dice quando un insieme di variabili (che chiamiamo Œõ) pu√≤ ‚Äúbloccare‚Äù il flusso di informazioni tra due altre variabili.\nImmaginiamo un modello causale come una rete di variabili interconnesse. Alcune variabili influenzano direttamente altre, creando dei percorsi attraverso i quali l‚Äôinformazione pu√≤ fluire. La d-separazione ci aiuta a identificare quali percorsi sono ‚Äúaperti‚Äù (permettono il passaggio di informazioni) e quali sono ‚Äúchiusi‚Äù (bloccano il passaggio di informazioni).\nConsideriamo le tre situazioni principali:\n\nCatena (X ‚Üí Z ‚Üí Y): In questo caso, Z √® un mediatore tra X e Y. Se Z appartiene all‚Äôinsieme Œõ (cio√®, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso.\n\nEsempio 20.1 Se X √® ‚Äúesercizio fisico‚Äù, Z √® ‚Äúpressione sanguigna‚Äù e Y √® ‚Äúrischio di malattie cardiache‚Äù, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l‚Äôesercizio fisico influenza il rischio di malattie cardiache.\n\nFork (X ‚Üê Z ‚Üí Y): Qui, Z √® una causa comune sia di X che di Y. Se Z appartiene a Œõ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune.\n\nEsempio 20.2 Se Z √® ‚Äústatus socioeconomico‚Äù, X √® ‚Äúlivello di istruzione‚Äù e Y √® ‚Äústato di salute‚Äù, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\n\nCollider (X ‚Üí Z ‚Üê Y): In questa situazione, Z √® un effetto comune di X e Y. Sorprendentemente, se n√© Z n√© i suoi discendenti appartengono a Œõ, il percorso √® gi√† bloccato. Controllare per Z (o i suoi discendenti) in realt√† aprirebbe un percorso tra X e Y, creando una correlazione spuria.\n\nEsempio 20.3 Se X √® ‚Äúintelligenza‚Äù, Y √® ‚Äúbellezza‚Äù e Z √® ‚Äúsuccesso in una carriera di attore‚Äù, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\n\nIn sintesi, la d-separazione ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte. Ci permette di ‚Äúbloccare‚Äù i percorsi non causali e di mantenere aperti solo i percorsi causali di interesse, facilitando cos√¨ l‚Äôinferenza causale corretta.\n\n\nIl criterio del back-door\nIl criterio del back-door √® uno strumento potente nella teoria dei Grafi Aciclici Diretti (DAG) per identificare quali variabili devono essere controllate per ottenere stime causali non distorte. L‚Äôobiettivo √® ‚Äúchiudere‚Äù tutti i percorsi non causali (back-door paths) tra la variabile di esposizione e l‚Äôoutcome, lasciando aperto solo il percorso causale diretto.\nPer applicare il criterio del back-door √® necessario seguire i seguenti passaggi:\n\nEliminare le frecce dirette dall‚Äôesposizione all‚Äôoutcome: Questo passaggio ci permette di concentrarci sui percorsi non causali (back-door paths) che potrebbero creare confondimento. Rimuovendo la freccia diretta, possiamo vedere chiaramente tutti gli altri percorsi che collegano l‚Äôesposizione all‚Äôoutcome.\n\nEsempio 20.4 In un DAG dove ‚ÄúEsercizio fisico‚Äù ‚Üí ‚ÄúSalute cardiovascolare‚Äù, e abbiamo anche ‚ÄúDieta‚Äù ‚Üí ‚ÄúEsercizio fisico‚Äù e ‚ÄúDieta‚Äù ‚Üí ‚ÄúSalute cardiovascolare‚Äù, rimuoveremmo temporaneamente la freccia da ‚ÄúEsercizio fisico‚Äù a ‚ÄúSalute cardiovascolare‚Äù.\n\nVerificare i percorsi non bloccati tra esposizione e outcome: Dopo aver rimosso la freccia diretta, esaminiamo tutti i percorsi rimanenti che collegano l‚Äôesposizione all‚Äôoutcome. Questi sono i potenziali percorsi di confondimento.\n\nEsempio 20.5 Nel nostro esempio, rimarrebbe il percorso: ‚ÄúEsercizio fisico‚Äù ‚Üê ‚ÄúDieta‚Äù ‚Üí ‚ÄúSalute cardiovascolare‚Äù.\n\nIdentificare le variabili necessarie per bloccare questi percorsi: Utilizzando i principi della d-separazione, determiniamo quali variabili, se controllate, bloccherebbero tutti i percorsi non causali.\n\nEsempio 20.6 Nel nostro esempio, controllando per ‚ÄúDieta‚Äù bloccheremmo l‚Äôunico percorso non causale rimanente.\n\n\nL‚Äôapplicazione di questi passaggi ci permette di identificare un set di variabili che, se controllate (ad esempio, includendole in un modello di regressione o stratificando su di esse), ci consentir√† di stimare l‚Äôeffetto causale dell‚Äôesposizione sull‚Äôoutcome senza distorsioni da confondimento.\n\n\nPunti chiave:\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all‚Äôesposizione che all‚Äôoutcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l‚Äôeffetto causale non pu√≤ essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte pi√π informate su quali variabili includere nelle loro analisi, migliorando cos√¨ la validit√† delle loro inferenze causali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#variabili-da-includere-nellanalisi",
    "href": "chapters/eda/05_causality.html#variabili-da-includere-nellanalisi",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.6 Variabili da includere nell‚Äôanalisi",
    "text": "20.6 Variabili da includere nell‚Äôanalisi\nLa procedura per identificare il set minimo di variabili necessarie per ottenere una stima causale non distorta √® un‚Äôestensione del criterio del back-door.\n\nRimuovere le frecce che partono dalla variabile di esposizione: Questo passo √® simile al primo passo del criterio del back-door, ma pi√π ampio. Qui, rimuoviamo tutte le frecce che partono dalla variabile di esposizione, non solo quella diretta all‚Äôoutcome. Questo ci permette di concentrarci sui percorsi che potrebbero creare confondimento, eliminando temporaneamente gli effetti dell‚Äôesposizione su altre variabili.\n\nEsempio 20.7 Se abbiamo un DAG dove ‚ÄúEsercizio fisico‚Äù (esposizione) ‚Üí ‚ÄúSalute cardiovascolare‚Äù (outcome), ‚ÄúEsercizio fisico‚Äù ‚Üí ‚ÄúPeso corporeo‚Äù, e ‚ÄúPeso corporeo‚Äù ‚Üí ‚ÄúSalute cardiovascolare‚Äù, rimuoveremmo entrambe le frecce che partono da ‚ÄúEsercizio fisico‚Äù.\n\nAggiungere gli archi di controllo generati dall‚Äôinsieme considerato: Questo passo simula l‚Äôeffetto di controllare per le variabili nell‚Äôinsieme che stiamo considerando. Per ogni variabile nell‚Äôinsieme, aggiungiamo archi non diretti (linee senza frecce) tra quella variabile e tutte le altre variabili ad essa adiacenti nel grafo originale.\n\nEsempio 20.8 Nel nostro esempio, se stiamo considerando di controllare per ‚ÄúPeso corporeo‚Äù, aggiungeremmo un arco non diretto tra ‚ÄúPeso corporeo‚Äù e ‚ÄúEsercizio fisico‚Äù, e tra ‚ÄúPeso corporeo‚Äù e ‚ÄúSalute cardiovascolare‚Äù.\n\nVerificare se tutti i percorsi non bloccati contengono almeno una variabile dell‚Äôinsieme: Ora esaminiamo tutti i percorsi rimanenti tra l‚Äôesposizione e l‚Äôoutcome. Un insieme di variabili √® sufficiente per l‚Äôaggiustamento se tutti questi percorsi contengono almeno una variabile dell‚Äôinsieme che stiamo considerando.\n\nEsempio 20.9 Nel nostro esempio, l‚Äôunico percorso rimanente sarebbe ‚ÄúEsercizio fisico‚Äù ‚Äì ‚ÄúPeso corporeo‚Äù ‚Äì ‚ÄúSalute cardiovascolare‚Äù. Poich√© ‚ÄúPeso corporeo‚Äù √® nella nostra serie di variabili di controllo e appare in questo percorso, l‚Äôinsieme sarebbe sufficiente per l‚Äôaggiustamento.\n\n\n\nPunti chiave:\n\nQuesta procedura ci aiuta a identificare non solo se un insieme di variabili √® sufficiente, ma anche se √® minimale. Un insieme minimale sufficiente non contiene variabili superflue.\nA volte, ci possono essere pi√π insiemi minimali sufficienti. In questi casi, la scelta tra di essi pu√≤ dipendere da considerazioni pratiche come la facilit√† di misurazione o la precisione delle variabili.\nSe non esiste un insieme sufficiente tra le variabili osservate, significa che non possiamo identificare l‚Äôeffetto causale con i dati a nostra disposizione.\nQuesta procedura pu√≤ essere applicata iterativamente, iniziando con un insieme vuoto e aggiungendo variabili fino a trovare un insieme sufficiente.\n\nUtilizzando questa procedura, i ricercatori possono identificare in modo sistematico quali variabili includere nelle loro analisi per ottenere stime causali non distorte, evitando al contempo l‚Äôinclusione di variabili non necessarie che potrebbero ridurre la precisione delle stime o introdurre altri problemi nell‚Äôanalisi. Questo √® particolarmente utile in psicologia, dove le variabili confondenti sono spesso numerose e complesse.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#dag-e-ovb",
    "href": "chapters/eda/05_causality.html#dag-e-ovb",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.7 DAG e OVB",
    "text": "20.7 DAG e OVB\nI DAG differiscono dai modelli di percorso o altri modelli grafici comuni in psicologia (come i Modelli di Equazioni Strutturali) in quanto: 1. Rappresentano solo relazioni causali. 2. Devono includere tutte le cause comuni della variabile causale di interesse e della risposta. 3. Sono non parametrici e non legati a un approccio di stima specifico. 4. Sono aciclici, non includendo feedback o cicli.\nI DAG aiutano a identificare dove le variabili confondenti potrebbero causare bias da variabili omesse e a determinare soluzioni in termini di campionamento e disegni statistici. Sono utili per chiarire il pensiero e la comunicazione sui sistemi ecologici e possono essere utilizzati per identificare potenziali fonti di confondimento anche quando teorie diverse suggeriscono DAG diversi.\nIn sintesi, i DAG forniscono una rappresentazione visiva chiara delle relazioni tra variabili, rendendo trasparenti le assunzioni alla base dell‚Äôanalisi e creando una connessione evidente tra le teorie sottostanti e l‚Äôanalisi statistica. Questo approccio contrasta con quello frequentista, caratterizzato dall‚Äôassenza di ipotesi sulle relazioni sottostanti tra le variabili, che rende difficile comprendere e interpretare le implicazioni dei risultati ottenuti.\n\n20.7.1 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura¬†20.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, √® possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una ‚Äúback-door‚Äù permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl 2009). In altre parole, omettere una variabile confondente come U nella Figura¬†20.1 (pannello centrale) in un‚Äôanalisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La figura Figura¬†20.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella figura Figura¬†20.2 bi, l‚Äôeffetto stimato di X su Y √® positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella figura Figura¬†20.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l‚Äôerrore e X, come illustrato nella figura Figura¬†20.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un‚Äôassunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura¬†20.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l‚Äôinferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cio√® non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un‚Äôanalisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e √® la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realt√†, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realt√† sta adattando il modello in (Biii), dove il termine di errore non √® solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ci√≤, c‚Äô√® un percorso diretto dal termine di errore del modello a X (e quindi X √® endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa √® la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poich√© non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes e Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#approfondimento-delle-strutture-causali-elementari",
    "href": "chapters/eda/05_causality.html#approfondimento-delle-strutture-causali-elementari",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.8 Approfondimento delle Strutture Causali Elementari",
    "text": "20.8 Approfondimento delle Strutture Causali Elementari\nNei DAG causali, si distinguono quattro tipologie fondamentali di strutture: confondente, catena, collider e discendenti (McElreath 2020). Comprendere queste strutture di base √® essenziale per analizzare percorsi causali pi√π complessi. In questa sezione approfondiremo la discussione di questi concetti che sono gi√† stati introdotti in precedenza.\n\n\n\nI quattro confondenti di base. (Figura tratta da McElreath (2020)).\n\n\n\n20.8.1 Confondente (Fork)\nUn confondente √® una variabile che influenza sia la variabile indipendente (X) che la variabile dipendente (Y), creando una relazione spuria tra X e Y.\nStruttura: Z ‚Üí X, Z ‚Üí Y.\nCaratteristiche:\n\nZ influenza sia X che Y.\nX e Y sono associati, ma non causalmente.\nControllando per Z, l‚Äôassociazione tra X e Y scompare o si riduce significativamente.\n\n\nEsempio 20.10 L‚Äôet√† (Z) pu√≤ influenzare sia il consumo di caff√® (X) che il rischio di malattie cardiache (Y), creando una falsa associazione tra consumo di caff√® e malattie cardiache.\n\n\n\n20.8.2 Catena (Pipe)\nLa catena descrive una sequenza in cui X influenza Y attraverso una variabile intermedia Z.\nStruttura: X ‚Üí Z ‚Üí Y.\nCaratteristiche:\n\nZ agisce come mediatore tra X e Y.\nX e Y sono associati.\nControllando per Z, l‚Äôassociazione tra X e Y scompare.\n\n\nEsempio 20.11 Il livello di educazione (X) influenza l‚Äôoccupabilit√† (Y) attraverso le competenze acquisite (Z).\n\n\n\n20.8.3 Collider\nUn collider √® una variabile influenzata da due o pi√π altre variabili. Controllare per un collider pu√≤ creare una falsa associazione tra le variabili che lo influenzano.\nStruttura: X ‚Üí Z ‚Üê Y.\nCaratteristiche:\n\nX e Y influenzano Z indipendentemente.\nX e Y non sono associati inizialmente.\nControllando per Z, si crea una falsa associazione tra X e Y.\n\n\nEsempio 20.12 Talento (X) e fortuna (Y) influenzano il successo (Z). Controllando per il successo, si potrebbe erroneamente concludere che talento e fortuna sono negativamente correlati.\n\n\n\n20.8.4 Discendenti\nI discendenti sono variabili influenzate dalla variabile di interesse o da altre variabili nel percorso causale.\nStruttura: X ‚Üí Z ‚Üí Y, con Z ‚Üí A.\nCaratteristiche: - Z agisce come mediatore tra X e Y e influenza direttamente A. - X e Y sono associati causalmente attraverso Z. - A fornisce informazioni su Z. - Controllare per A pu√≤ distorcere la stima dell‚Äôeffetto di X su Y.\n\nEsempio 20.13 Consideriamo l‚Äôeffetto del supporto sociale sulla felicit√† attraverso l‚Äôautostima con le seguenti variabili. X: Supporto Sociale, Z: Autostima, Y: Felicit√†, A: Livello di Stress. La vera relazione causale √® quella per cui il supporto sociale (X) migliora l‚Äôautostima (Z), che influenza sia la felicit√† (Y) che il livello di stress (A).\nAnalisi:\n\nSenza considerare A: Concentrandosi sul percorso X ‚Üí Z ‚Üí Y, si pu√≤ isolare l‚Äôeffetto del supporto sociale sulla felicit√† attraverso l‚Äôautostima.\nConsiderando A: L‚Äôinclusione di A introduce complessit√†. Se A ha un discendente D che funge da collider (influenzato da A e da una causa comune non osservata U con Y), condizionare su D pu√≤ introdurre bias aprendo un percorso non causale (A ‚Üí D ‚Üê U ‚Üí Y).\n\nImplicazioni:\n\nX e Y sono associati causalmente: X ‚´´Ã∏ Y.\nStratificando per A, l‚Äôassociazione tra X e Y pu√≤ indebolirsi o scomparire: X ‚´´ Y | A.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#inferenza-causale-da-studi-osservazionali",
    "href": "chapters/eda/05_causality.html#inferenza-causale-da-studi-osservazionali",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.9 Inferenza Causale da Studi Osservazionali",
    "text": "20.9 Inferenza Causale da Studi Osservazionali\nI diagrammi causali sono uno dei primi strumenti per identificare il bias da variabili omesse (Pearl 1995; Pearl, Glymour, e Jewell 2016). I diagrammi causali, sotto forma di DAG, visualizzano la nostra comprensione delle relazioni causali e delle variabili confondenti all‚Äôinterno di un sistema. In questo modo, i DAG chiariscono in modo trasparente le assunzioni dietro le affermazioni causali derivate dai dati e mostrano le potenziali fonti di bias derivanti da variabili confondenti.\n√à fondamentale che i DAG includano tutte le cause comuni di un predittore e della risposta di interesse, comprendendo tutte le variabili confondenti misurate e non misurate. Questo significa che l‚Äôinferenza causale √® possibile solo quando il ricercatore dispone di adeguate conoscenze del dominio.\nDopo aver costruito un DAG, √® possibile determinare le potenziali fonti di bias da variabili omesse, incluse quelle derivanti da variabili confondenti non misurate (es., U nella figura fig-byrnes-dee-1, pannello centrale). Non controllare le variabili confondenti apre una ‚Äúback-door‚Äù per la variazione confondente, permettendo a quest‚Äôultima di fluire tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl 2009).\nPertanto, un diagramma causale √® un primo passo fondamentale per identificare potenziali bias da variabili omesse. I DAG giustificano anche la scelta delle variabili di controllo, rendendo trasparenti le assunzioni che un ricercatore fa su come funziona il sistema oggetto di studio.\n√à importante notare che i DAG possono essere incorretti o non includere variabili confondenti sconosciute. Infatti, un DAG rappresenta solo la comprensione attuale e le assunzioni del ricercatore riguardo alle relazioni causali all‚Äôinterno di un sistema.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/05_causality.html#commenti-e-considerazioni-finali",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "20.10 Commenti e Considerazioni Finali",
    "text": "20.10 Commenti e Considerazioni Finali\nL‚Äôinferenza causale negli studi osservazionali rappresenta una sfida complessa ma essenziale nella ricerca scientifica. Questo capitolo ha esplorato le sfide e le opportunit√† presentate da questo campo, evidenziando l‚Äôimportanza di un approccio metodologico rigoroso e di una comprensione approfondita delle relazioni causali.\n\nPunti chiave:\n\nImportanza dei DAG: I Directed Acyclic Graphs (DAG) emergono come strumenti fondamentali per visualizzare e comprendere le relazioni causali. Consentono ai ricercatori di esplicitare le loro ipotesi e guidano l‚Äôidentificazione corretta delle variabili confondenti.\nGestione delle variabili confondenti: L‚Äôidentificazione e il trattamento appropriato delle variabili confondenti sono cruciali. Un controllo insufficiente o eccessivo pu√≤ portare a conclusioni errate, sottolineando la necessit√† di un approccio equilibrato.\nMediatori e collider: L‚Äôanalisi dei mediatori richiede attenzione per non perdere di vista l‚Äôeffetto causale d‚Äôinteresse. Allo stesso tempo, √® fondamentale evitare il controllo indiscriminato dei collider per prevenire correlazioni spurie.\nLimiti dei dati osservazionali: Mentre i dati osservazionali sono preziosi per generare ipotesi e guidare la ricerca futura, √® essenziale riconoscere che la causalit√† non pu√≤ essere stabilita esclusivamente sulla base di correlazioni. La conoscenza preliminare delle possibili relazioni causali √® indispensabile.\nBilanciamento tra validit√† interna ed esterna: Gli studi sperimentali offrono una forte validit√† interna, ma la loro generalizzabilit√† (validit√† esterna) pu√≤ essere limitata. Un approccio che integra metodi diversi pu√≤ fornire una comprensione pi√π completa.\nTrasparenza e comunicazione: La chiave per una ricerca rigorosa sta nella capacit√† di riconoscere, articolare e comunicare chiaramente le premesse su cui si basano le conclusioni. Questo approccio facilita la valutazione critica e promuove il progresso scientifico.\n\n\n\nRiflessioni finali:\nL‚Äôinferenza causale da dati osservazionali rimane una sfida significativa, ma non insormontabile. Richiede una combinazione di rigore metodologico, comprensione profonda dei fenomeni studiati e onest√† intellettuale nel riconoscere i limiti delle proprie conclusioni.\nLa diversit√† metodologica, che abbraccia sia gli studi sperimentali che quelli osservazionali, offre la prospettiva pi√π promettente per affrontare domande di ricerca complesse. Integrando diverse fonti di evidenza e approcci analitici, i ricercatori possono costruire una comprensione pi√π robusta e sfumata delle relazioni causali.\nIn definitiva, il progresso nella comprensione causale dipende non solo dall‚Äôanalisi accurata dei dati, ma anche dalla riflessione critica sulle strutture causali sottostanti e dalla collaborazione trasparente all‚Äôinterno della comunit√† scientifica.\nUn sommario ironico di questi concetti √® fornito nella vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_causality.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_causality.html#informazioni-sullambiente-di-sviluppo",
    "title": "20¬† Causalit√† dai dati osservazionali",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\nseaborn   : 0.13.0\nscipy     : 1.11.4\nmatplotlib: 3.8.2\narviz     : 0.17.0\ngraphviz  : 0.20.1\npandas    : 2.1.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, Jarrett EK, e Laura E Dee. 2024. ¬´Causal inference with observational data and unobserved confounding variables¬ª. bioRxiv, 2024‚Äì02.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nPearl, Judea. 1995. ¬´Causal diagrams for empirical research¬ª. Biometrika 82 (4): 669‚Äì88.\n\n\n‚Äî‚Äî‚Äî. 2009. Causality. Cambridge University Press.\n\n\nPearl, Judea, Madelyn Glymour, e Nicholas P. Jewell. 2016. Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, Emily. 2021. ¬´Causal design patterns for data analysts¬ª, gennaio. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nRohrer, Julia M. 2018. ¬´Thinking clearly about correlations and causation: Graphical causal models for observational data¬ª. Advances in methods and practices in psychological science 1 (1): 27‚Äì42.\n\n\nSchennach, Susanne M. 2016. ¬´Recent advances in the measurement error literature¬ª. Annual Review of Economics 8 (1): 341‚Äì77.\n\n\nWilms, Rafael, E M√§thner, Lothar Winnen, e Ralf Lanwehr. 2021. ¬´Omitted variable bias: A threat to estimating causal relationships¬ª. Methods in Psychology 5: 100075.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon Schwab, e Steven N Goodman. 2023. ¬´A New Look at P Values for Randomized Clinical Trials¬ª. NEJM Evidence 3 (1): EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "21¬† Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilit√†, una componente essenziale per la ricerca scientifica. Nell‚Äôambito della scienza, l‚Äôinferenza induttiva √® di fondamentale importanza, e la probabilit√† svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicit√† di un‚Äôipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L‚Äôapproccio bayesiano utilizza la probabilit√† per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL‚Äôinferenza statistica bayesiana mira a quantificare la fiducia nell‚Äôipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l‚Äôinferenza statistica bayesiana, √® quindi essenziale avere una solida comprensione della teoria delle probabilit√†, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilit√†, la probabilit√† condizionale e il teorema di Bayes. Approfondiremo inoltre le propriet√† delle variabili casuali e le principali distribuzioni di massa e densit√† di probabilit√†. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell‚Äôinferenza bayesiana sia nell‚Äôinferenza frequentista.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "22¬† Interpretazione della probabilit√†",
    "section": "",
    "text": "Introduzione\nNel corso di questo capitolo, esploreremo varie concezioni della probabilit√†, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con Python per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell‚Äôambito della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "href": "chapters/probability/01_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "title": "22¬† Interpretazione della probabilit√†",
    "section": "22.1 Storia e definizioni della probabilit√†",
    "text": "22.1 Storia e definizioni della probabilit√†\nLa probabilit√† √® un modo formale di quantificare l‚Äôincertezza, assegnando plausibilit√† o credibilit√† a un insieme di possibilit√† mutuamente esclusive o risultati di un esperimento o osservazione.\n\n22.1.1 Che cos‚Äô√® la probabilit√†?\nCi sono due modi principali per interpretare la probabilit√†:\n\nFrequentista: Secondo il framework frequentista, la probabilit√† rappresenta il limite della frequenza relativa con cui un evento di interesse si verifica quando il numero di esperimenti condotti ripetutamente nelle stesse condizioni tende all‚Äôinfinito. In questa visione, chiamata ‚Äúontologica‚Äù, la probabilit√† √® considerata una propriet√† intrinseca del mondo, indipendente dalla nostra esperienza. La probabilit√† √® quindi vista come una caratteristica oggettiva della realt√†.\nBayesiana: Al contrario, il framework bayesiano interpreta la probabilit√† come una credenza soggettiva riguardo alla probabilit√† di accadimento di un evento. In questa prospettiva ‚Äúepistemica‚Äù, la probabilit√† √® una misura della nostra conoscenza del mondo piuttosto che una propriet√† oggettiva. Questa visione soggettiva della probabilit√† dipende dalle informazioni disponibili e dal punto di vista dell‚Äôosservatore.\n\n\n\n22.1.2 Storia della probabilit√†\nLa storia della probabilit√† √® lunga e complessa, come illustrato in varie opere (Tabak 2004, Stigler 1986, Weisberg 2014). L‚Äôorigine della probabilit√† moderna risale a una domanda posta da Antoine Gombaud (Chevalier de M√©r√©) a Blaise Pascal (1623‚Äì1662) su come dividere equamente le puntate di un gioco di carte interrotto.\n\n22.1.2.1 Problema dei punti\nIl problema pu√≤ essere formulato cos√¨:\n\nImmaginiamo due persone che partecipano a un gioco a pi√π round. In ogni round, entrambe le persone hanno la stessa probabilit√† di vincere. La prima persona che vince sei round consecutivi si aggiudicher√† un ricco premio in denaro. Supponiamo che A e B abbiano gi√† disputato sei round, con A che ha vinto cinque volte e B una volta. In quel momento, il gioco √® interrotto. Poich√© n√© A n√© B hanno raggiunto le sei vittorie, hanno deciso di dividere il premio. Ma qual √® il modo pi√π equo per farlo?\n\nLa discussione tra Pierre de Fermat (1607‚Äì1665) e Pascal ha portato alla formalizzazione dell‚Äôutilizzo della matematica per risolvere questo problema, proponendo di considerare le probabilit√† di vincita di ciascun giocatore. Ad esempio, se A ha una probabilit√† del 97% di vincere il premio e B ha una probabilit√† del 3%, sembrerebbe equo assegnare ad A il 97% del premio. L‚Äôinteresse pubblico per la loro corrispondenza √® sopravvissuto grazie al libro di Christian Huygens del 1657 ‚ÄúDe Ratiociniis in Ludo Aleae‚Äù (Sul Ragionamento nei Giochi di Dadi), che √® rimasto il riferimento per la probabilit√† per circa 50 anni.\n\n\n22.1.2.2 Sviluppi successivi\nIl libro postumo di Jacob Bernoulli, ‚ÄúL‚ÄôArte della Congettura‚Äù (1713), ha segnato una svolta nella storia della probabilit√†. Bernoulli ha definito la probabilit√† come un indice di incertezza compreso tra 0 e 1 e ha collegato il calcolo della probabilit√† ai dati e alla frequenza a lungo termine di un evento, noto come legge dei grandi numeri. Bernoulli ha applicato la probabilit√† anche a settori diversi dal gioco d‚Äôazzardo, come la mortalit√† umana e la giustizia penale, creando la cosiddetta ‚Äúprobabilit√† soggettiva‚Äù.\n\n\n\n22.1.3 Interpretazione ‚Äúclassica‚Äù\nStoricamente, la prima definizione di probabilit√† √® stata proposta da Pierre-Simon Laplace (1749-1827), che si √® avvalso del calcolo combinatorio. Secondo Laplace, la probabilit√†\\(P\\)di un evento √® definita come il rapporto tra il numero di casi in cui l‚Äôevento si verifica e il numero totale di casi possibili. In questa definizione, un evento √® qualcosa a cui √® possibile assegnare un valore di verit√†, ovvero qualcosa che pu√≤ essere vero o falso. Ad esempio, la probabilit√† di ottenere un 3 in un lancio di un singolo dado √® 1/6 ‚âÉ 0.17, poich√© c‚Äô√® un solo caso favorevole (il lancio ha prodotto un 3) su sei casi possibili (i numeri da 1 a 6). Tuttavia, questa definizione √® insoddisfacente in quanto si basa sull‚Äôassunzione che ogni evento sia equiprobabile, il che non √® sempre vero. Inoltre, questa definizione √® circolare poich√© per definire il concetto di probabilit√†, √® necessario prima definire cosa significa che gli eventi siano equiprobabili, e quindi si deve gi√† conoscere il concetto di probabilit√†.\n\n\n22.1.4 Interpretazione frequentista\nUn secondo tentativo di definire la probabilit√† (dopo quello ‚Äúclassico‚Äù di Laplace) si basa sull‚Äôapproccio frequentista, che pu√≤ essere attribuito a molti autori. In questo approccio, la probabilit√† √® definita sulla base delle frequenze osservate dell‚Äôoccorrenza di un evento. Questo approccio nasce dalla difficolt√† di assegnare una probabilit√† agli eventi assumendo il principio di equiprobabilit√†, come nel caso delle monete, dei dadi o delle carte di un mazzo. Sebbene la probabilit√† di ottenere testa come risultato del lancio di un dado sia 1/2 se crediamo che la moneta sia bilanciata, se cos√¨ non fosse non potremmo assegnare la stessa probabilit√† a tutti i risultati possibili. Tuttavia, possiamo stimare le probabilit√† come la frequenza\\(f_t\\), definita come il rapporto tra il numero di volte in cui un lancio ha prodotto ‚Äútesta‚Äù e il numero totale di lanci.\nSi osservi che l‚Äôosservazione della frequenza \\(f_t\\) √® solo un‚Äô approssimazione della probabilit√†, ma l‚Äôaccuratezza migliora all‚Äôaumentare del numero totale di lanci, \\(N\\). In linea di principio, la probabilit√† di ottenere ‚Äútesta‚Äù, \\(P(T)\\), √® il limite della frequenza \\(f_t\\) quando il numero totale di lanci \\(N\\) tende all‚Äôinfinito. Tuttavia, questa definizione richiede l‚Äôinfinita ripetizione di un esperimento, il che pu√≤ essere impraticabile o impossibile in molti casi. Inoltre, questa definizione assume che gli eventi futuri siano simili agli eventi passati, il che non √® sempre garantito.\n\ndef coin_flips(n, run_label):\n    # Genera un array di 0 e 1 dove 1 rappresenta 'testa' e 0 'croce'\n    # usando una distribuzione binomiale.\n    heads = np.random.binomial(1, 0.5, n)\n    \n    # Calcola la proporzione cumulativa di teste.\n    flips = np.arange(1, n + 1) \n    proportion_heads = np.cumsum(heads) / flips\n    \n    # Crea un DataFrame per un facile accesso e visualizzazione dei dati.\n    df = pd.DataFrame({'flips': flips, 'proportion_heads': proportion_heads, 'run': run_label})\n\n    return df\n\nn = 1000\n\ndf = pd.concat([coin_flips(n, f'run{i+1}') for i in range(4)], axis=0)\nax = sns.lineplot(data = df, x = 'flips', y = 'proportion_heads', hue = 'run')\n\n\n\n\n\n\n\n\n\n\n22.1.5 La Legge dei Grandi Numeri\nLa simulazione precedente fornisce un esempio della Legge dei grandi numeri. La Legge dei Grandi Numeri afferma che, man mano che il numero di esperimenti casuali ripetuti aumenta, la stima della probabilit√† di un evento \\(P(Y=y)\\) diventa sempre pi√π accurata.\nIl teorema sostiene che, con l‚Äôaumento del numero di ripetizioni di un esperimento casuale, la media dei risultati osservati tende a convergere al valore atteso teorico della variabile casuale. In altre parole, la media empirica dei risultati osservati si avvicina sempre di pi√π al valore medio teorico.\nQuesta legge √® cruciale perch√© garantisce che, con un numero sufficientemente grande di prove, la stima empirica della probabilit√† di un evento si avvicina al valore reale. Questo rende le stime probabilistiche pi√π precise e affidabili.\nDal punto di vista pratico, la Legge dei Grandi Numeri consente di utilizzare modelli probabilistici per interpretare fenomeni reali. Anche se le osservazioni singole possono variare in modo casuale, la media delle osservazioni su un ampio numero di ripetizioni rifletter√† fedelmente le probabilit√† teoriche.\nFormalmente, data una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), ciascuna con media \\(\\mu\\), la Legge dei Grandi Numeri √® espressa come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{X_1 + X_2 + \\ldots + X_n}{n} - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) √® un valore positivo arbitrariamente piccolo e \\(P(\\cdot)\\) indica la probabilit√†. Questo significa che, con un numero molto grande di ripetizioni, la media campionaria osservata sar√† vicina alla media teorica attesa, permettendo inferenze affidabili sulla probabilit√† degli eventi.\nIn sintesi, la Legge dei Grandi Numeri assicura che, aumentando il numero di prove, le stime empiriche delle probabilit√† diventano sempre pi√π precise, allineandosi con i valori teorici attesi.\n\n22.1.5.1 Problema del caso singolo\nNell‚Äôambito dell‚Äôapproccio frequentista alla probabilit√†, basato sulla concezione delle frequenze relative di eventi osservati su lunghe serie di ripetizioni, emerge un limite concettuale nel trattare la probabilit√† di eventi singolari e non ripetibili. Secondo questa prospettiva, infatti, non risulta rigorosamente appropriato discutere di probabilit√† relative a eventi unici e non replicabili nel tempo. Esempi emblematici di tali eventi includono la possibilit√† che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023 o che si verifichi pioggia a Firenze il giorno di Ferragosto del 2024. Questi scenari, essendo unici e circoscritti a un preciso momento storico, sfuggono alla logica frequentista che richiede, per definizione, la possibilit√† di osservazione ripetuta degli eventi per valutarne la probabilit√†. Nonostante ci√≤, nel linguaggio comune non specialistico, √® comune l‚Äôuso del termine ‚Äúprobabilit√†‚Äù per riferirsi anche a tali eventi specifici e non ripetibili, evidenziando cos√¨ una discrepanza tra l‚Äôuso tecnico e quello colloquiale del concetto di probabilit√†.\n\n\n\n22.1.6 Collegamento tra probabilit√† e statistica\nDurante gli anni ‚Äô20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l‚Äôinferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significativit√†, i metodi di campionamento, l‚Äôanalisi della varianza e il disegno sperimentale.\nNegli anni ‚Äô30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull‚Äôinterpretazione frequentista della probabilit√†. Definirono due tipologie di errori decisionali e utilizzarono il test di significativit√† di Fisher, interpretando i valori\\(p\\)come indicatori dei tassi di errore a lungo termine.\n\n\n22.1.7 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della ‚Äúprobabilit√† inversa‚Äù (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l‚Äôinferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell‚Äôutilizzo dell‚Äôinferenza basata sul metodo della probabilit√† inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato ‚ÄúTheory of Probability‚Äù rappresent√≤ una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ‚Äô80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell‚Äôapproccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n22.1.8 Interpretazione soggettivista\nUna visione alternativa della probabilit√† la considera come una credenza soggettiva. Finetti (1970) ha proposto un‚Äôinterpretazione in cui la probabilit√† non √® vista come una caratteristica oggettiva degli eventi, ma piuttosto come una misura della credenza soggettiva, suggerendo di trattare \\(p(¬∑)\\) come una probabilit√† soggettiva. √à interessante notare che de Finetti era un soggettivista radicale. Infatti, la frase di apertura del suo trattato in due volumi sulla probabilit√† afferma che ‚ÄúLa probabilit√† non esiste‚Äù, intendendo che la probabilit√† non ha uno status oggettivo, ma rappresenta piuttosto la quantificazione della nostra esperienza di incertezza. Riteneva che l‚Äôidea di una probabilit√† esterna all‚Äôindividuo, con uno status oggettivo, fosse pura superstizione, paragonabile al credere in ‚ÄúEtere cosmico, Spazio e Tempo assoluti, ‚Ä¶, o Fate e Streghe‚Ä¶‚Äù. Secondo de Finetti, ‚Äú‚Ä¶ esistono solo probabilit√† soggettive - cio√®, il grado di credenza nell‚Äôoccorrenza di un evento attribuito da una determinata persona in un dato momento con un dato insieme di informazioni.‚Äù\nCome sottolineato da Press (2009), la prima menzione della probabilit√† come grado di credenza soggettiva fu fatta da Ramsey (1926), ed √® questa nozione di probabilit√† come credenza soggettiva che ha portato a una notevole resistenza alle idee bayesiane. Una trattazione dettagliata degli assiomi della probabilit√† soggettiva si trova in Fishburn (1986).\nLa denominazione ‚Äúsoggettivo‚Äù legata alla probabilit√† potrebbe risultare infelice, poich√© potrebbe suggerire un ragionamento vago o non scientifico. Lindley (2013) condivide queste riserve, proponendo l‚Äôalternativa ‚Äúprobabilit√† personale‚Äù rispetto a ‚Äúprobabilit√† soggettiva‚Äù. Analogamente, Howson e Urbach (2006) preferiscono utilizzare l‚Äôespressione ‚Äúprobabilit√† epistemica‚Äù, che riflette il grado di incertezza di un individuo di fronte al problema trattato. In sostanza, la probabilit√† epistemica si riferisce all‚Äôincertezza personale riguardo a variabili sconosciute. Questa terminologia viene adottata anche nel testo di Kaplan (2023), fornendo un linguaggio pi√π neutro per discutere di questi concetti.\nVa inoltre notato che l‚Äôinterpretazione soggettiva si adatta bene a eventi singoli, permettendo di esprimere una convinzione su eventi specifici, come la probabilit√† di pioggia in un dato giorno o l‚Äôesito di una competizione sportiva.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli‚Äôs Fallacy (Clayton 2021) offre un‚Äôintroduzione molto leggibile alle tematiche della definizione della probabilit√† nella storia della scienza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "title": "22¬† Interpretazione della probabilit√†",
    "section": "22.2 Commenti e Considerazioni Finali",
    "text": "22.2 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato il significato filosofico della nozione di probabilit√† e introdotto la simulazione come metodo per approssimare le probabilit√† empiriche quando non √® possibile ottenere soluzioni analitiche.\nNel prossimo capitolo, esamineremo la probabilit√† dal punto di vista matematico.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "22¬† Interpretazione della probabilit√†",
    "section": "22.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "22.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFinetti, Bruno de. 1970. Teoria delle probabilit√†. Torino: G. Einaudi.\n\n\nFishburn, Peter C. 1986. ¬´The axioms of subjective probability¬ª. Statistical Science 1 (3): 335‚Äì45.\n\n\nHowson, Colin, e Peter Urbach. 2006. Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, David. 2023. Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, Dennis V. 2013. Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S James. 2009. Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, Frank P. 1926. ¬´Truth and probability¬ª. In Readings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html",
    "href": "chapters/probability/02_prob_spaces.html",
    "title": "23¬† Misura di Probabilit√†",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#introduzione",
    "href": "chapters/probability/02_prob_spaces.html#introduzione",
    "title": "23¬† Misura di Probabilit√†",
    "section": "",
    "text": "23.0.1 Introduzione alle Probabilit√†: Origine e Definizione\nDal punto di vista matematico, da dove derivano i numeri che chiamiamo ‚Äúprobabilit√†‚Äù? Per rispondere a questa domanda, ci baseremo sulla trattazione proposta da Michael Betancourt, che ha l‚Äôobiettivo di spiegare in maniera chiara e precisa cosa sia una distribuzione di probabilit√†. Questo capitolo presenta una versione leggermente semplificata del suo lavoro, mantenendone per√≤ la notazione e le figure originali, per garantire coerenza con la trattazione originale.\nBetancourt sostiene che le basi della teoria della probabilit√† siano piuttosto semplici. Le difficolt√† matematiche emergono principalmente quando si applica la teoria della probabilit√† a insiemi complessi, come i numeri reali. Per evitare queste complicazioni, Betancourt introduce i fondamenti della teoria della probabilit√† astratta utilizzando uno spazio campionario semplice, costituito da una collezione di un numero finito di elementi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "title": "23¬† Misura di Probabilit√†",
    "section": "23.1 Insiemi Finiti",
    "text": "23.1 Insiemi Finiti\nUn insieme finito √® costituito da un numero finito di elementi distinti, \\[\nX = \\{x_1, ..., x_N\\}.\n\\] Qui, l‚Äôindice numerico serve a distinguere gli \\(N\\) elementi individuali, senza implicare necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, Betancourt utilizza un insieme di cinque elementi come esempio: \\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura¬†23.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilit√†, gli elementi astratti \\(x_{n}\\) rappresentano oggetti concreti e significativi. Tuttavia, in questo capitolo, ci si concentrer√† esclusivamente sui concetti matematici, evitando qualsiasi interpretazione particolare. Quando \\(X\\) √® inteso a rappresentare tutti gli oggetti di interesse in una data applicazione, viene denominato spazio campionario.\nUna volta definito lo spazio campionario, possiamo organizzare e manipolare i suoi elementi in vari modi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "title": "23¬† Misura di Probabilit√†",
    "section": "23.2 Sottoinsiemi",
    "text": "23.2 Sottoinsiemi\nUn sottoinsieme di \\(X\\) √® qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguit√†, user√≤ esclusivamente lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) √® un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicit√†, solo di appartenenza: un sottoinsieme pu√≤ includere un elemento \\(x_{n}\\) ma non pu√≤ includerlo pi√π volte.\n\n\n\n\n\n\nFigura¬†23.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) √® qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) √® un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) potrebbe contenere tutti gli elementi di \\(X\\), nel qual caso \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L‚Äôinsieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D‚Äôaltra parte, l‚Äôintero insieme stesso pu√≤ essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento √® denotato \\(\\{ x_{n} \\}\\) e chiamato insieme atomico.\nCi sono \\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\] modi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene elementi, \\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\] che √® solo l‚Äôinsieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi, \\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\] che √® solo l‚Äôinsieme completo stesso. D‚Äôaltra parte, ci sono \\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\] insiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene \\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\] sottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi √® essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "23¬† Misura di Probabilit√†",
    "section": "23.3 Operazioni sui Sottoinsiemi",
    "text": "23.3 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono gi√† in \\(\\mathsf{x}\\). L‚Äôinsieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l‚Äôunico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell‚Äôinsieme vuoto √® l‚Äôintero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell‚Äôinsieme completo √® l‚Äôinsieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura¬†23.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) √® il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l‚Äôoperatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da pi√π di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi √® essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] cos√¨ come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura¬†23.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura¬†23.5: L‚Äôunione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), √® un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D‚Äôaltra parte, l‚Äôintersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), √® un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione √® l‚Äôinsieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L‚Äôunione e l‚Äôintersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poich√© l‚Äôinsieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l‚Äôinsieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l‚Äôunione di un sottoinsieme con l‚Äôinsieme completo restituisce l‚Äôinsieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l‚Äôintersezione di un sottoinsieme con l‚Äôinsieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "title": "23¬† Misura di Probabilit√†",
    "section": "23.4 Misura e Probabilit√† sugli Elementi",
    "text": "23.4 Misura e Probabilit√† sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l‚Äôallocazione coerente di una qualche quantit√† astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe ‚Äúmisura totale‚Äù o ‚Äúmassa totale‚Äù) di una qualche quantit√† positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poich√© \\(M\\) √® conservato, qualsiasi quantit√† \\(m_{n}\\) che viene allocata all‚Äôelemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) √® infinito. In questo scenario, possiamo allocare una quantit√† infinita dal serbatoio pur avendo ancora una quantit√† infinita rimanente. Allo stesso tempo, allocare una quantit√† infinita pu√≤ esaurire completamente il serbatoio o lasciare qualsiasi quantit√† finita residua. L‚Äôinfinito √® un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura¬†23.6: La teoria della misura riguarda l‚Äôallocazione di una qualche quantit√† continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn‚Äôallocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l‚Äôintero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione pu√≤ essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ci√≤ che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l‚Äôammontare finale allocato a \\(\\spadesuit\\) sar√†:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantit√† distribuite sia esattamente uguale a \\(M\\), svuotando cos√¨ completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n¬†\n\n\n\n\nFigura¬†23.7: Poich√© la quantit√† totale \\(M\\) √® conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantit√† disponibile per l‚Äôallocazione agli altri elementi. Un‚Äôallocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura √® qualsiasi allocazione coerente della quantit√† \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito pu√≤ essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell‚Äôinsieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) √® specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura¬†23.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) √® qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura pu√≤ essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPi√π grande √® \\(m_{n}\\), pi√π di \\(M\\) viene allocato all‚Äôelemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) √® un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poich√© richiede considerazioni pi√π complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) pu√≤ essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) √® lo spazio campionario,\n\\(x_n\\) √® un elemento di \\(X\\),\n\\(m_n\\) √® la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\n√à importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L‚Äôinsieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll‚Äôinterno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D‚Äôaltra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura¬†23.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) √® un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL‚Äôimportanza delle misure finite risiede nella possibilit√† di esprimere le allocazioni in termini relativi anzich√© assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all‚Äôintervallo unitario \\([0, 1]\\). Come per qualsiasi quantit√† che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l‚Äôimportanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull‚Äôintero spazio campionario e consente di normalizzare misure diverse, rendendo pi√π semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione ‚Äúassoluta‚Äù a una ‚Äúrelativa‚Äù della distribuzione della misura, offrendo una prospettiva pi√π intuitiva e utile per l‚Äôanalisi.\n\n\n\n\n\n\nFigura¬†23.10: Ogni misura finita pu√≤ essere caratterizzata da un‚Äôallocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste propriet√† √® chiamata simplex.\n\n\n\n\n\n\nFigura¬†23.11: Un‚Äôallocazione proporzionale √® anche conosciuta come distribuzione di probabilit√†.\n\n\n\nPi√π importante, una misura proporzionale \\(\\pi\\) √® anche conosciuta come distribuzione di probabilit√†, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilit√†. Sebbene il termine ‚Äúprobabilit√†‚Äù sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica √® piuttosto semplice: su un insieme finito, una probabilit√† rappresenta semplicemente la proporzione di una quantit√† finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "title": "23¬† Misura di Probabilit√†",
    "section": "23.5 Misura e Probabilit√† sui Sottoinsiemi",
    "text": "23.5 Misura e Probabilit√† sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un‚Äôallocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme √® semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) √® \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura¬†23.12: Su un insieme finito, un‚Äôallocazione sugli elementi individuali definisce anche un‚Äôallocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilit√† soddisfano una serie di propriet√† utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilit√† abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poich√© i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione √® solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPi√π in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi pi√π piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa propriet√† di coerenza √® chiamata additivit√†.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l‚Äôintero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l‚Äôadditivit√† implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme √® la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilit√†, questo concetto √® ancora pi√π evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l‚Äôunione include l‚Äôelemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL‚Äôelemento che viene contato due volte √® esattamente l‚Äôunico elemento nell‚Äôintersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura¬†23.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste propriet√† dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali pu√≤ essere utile in circostanze diverse. Questa flessibilit√† √® molto comoda quando si applica la teoria della misura e la teoria della probabilit√† nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l‚Äôintero insieme fin dall‚Äôinizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura¬†23.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura¬†23.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non √® sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre pi√π piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura¬†23.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre pi√π piccoli.\n\n\n\nQuesta flessibilit√† nelle modalit√† di costruzione delle misure √® particolarmente utile perch√© permette di adattare l‚Äôapproccio alle specifiche necessit√† del problema in questione. Ad esempio, nella pratica, potremmo trovare pi√π semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) √® cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione √® necessaria per definire misure in modo coerente su insiemi matematicamente pi√π complessi, come la retta reale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/02_prob_spaces.html#commenti-e-considerazioni-finali",
    "title": "23¬† Misura di Probabilit√†",
    "section": "23.6 Commenti e considerazioni finali",
    "text": "23.6 Commenti e considerazioni finali\nIl significato applicativo delle nozioni di misura e distribuzione di probabilit√† √® centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale √® capire cosa rappresenta \\(M\\), la ‚Äúmisura totale‚Äù. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilit√†, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilit√† √® quindi l‚Äôallocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilit√† individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la ‚Äúmisura totale‚Äù \\(M\\) √® interpretata come la somma totale delle probabilit√†, che √® sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificher√†.\nQuando creiamo una distribuzione di probabilit√†, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l‚Äôintera certezza (pari a 1) tra questi esiti. Ogni valore di probabilit√† \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nLe nozioni di misura e distribuzione di probabilit√† trovano numerose applicazioni pratiche. Ad esempio:\n\nInferenza bayesiana: Utilizziamo distribuzioni di probabilit√† per rappresentare le nostre incertezze sui parametri di interesse. Dopo aver osservato i dati, aggiorniamo queste distribuzioni tramite il teorema di Bayes.\nModellizzazione probabilistica: Costruiamo modelli che descrivono il comportamento di sistemi complessi assegnando probabilit√† agli eventi possibili. Questo ci permette di fare previsioni e prendere decisioni informate basate sulle probabilit√† assegnate.\n\nIn conclusione, le nozioni di misura e distribuzione di probabilit√† sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti √® fondamentale per comprendere le applicazioni della teoria della probabilit√† e della statistica bayesiana. La ‚Äúmisura totale‚Äù \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilit√† ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html",
    "href": "chapters/probability/03_prob_on_general_spaces.html",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "",
    "text": "Introduzione\nNel Capitolo 23 abbiamo introdotto la teoria della misura e della probabilit√† su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilit√† a spazi pi√π generali come questi non √® sempre semplice.\nSenza entrare nei dettagli, √® stato dimostrato che la forma pi√π generale della teoria della misura e della probabilit√† applicabile a qualsiasi spazio matematico √® chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un‚Äôintroduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilit√† e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilit√† e la misura possono essere utilizzate in contesti pi√π complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.1 \\(\\sigma\\)-Algebra",
    "text": "24.1 \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra √® una struttura matematica che permette di definire in modo coerente quali sottoinsiemi di un insieme sono ‚Äúmisurabili‚Äù.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.2 Definizione di \\(\\sigma\\)-Algebra",
    "text": "24.2 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra √® una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti propriet√†:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l‚Äôunione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l‚Äôintero insieme \\(X\\) √® considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) √® stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all‚Äôinterno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non ‚Äúperda‚Äù elementi a causa di queste operazioni, mantenendo cos√¨ la coerenza e la completezza della collezione di sottoinsiemi.\n\n24.2.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), √® detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili √® cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.3 Gli Assiomi di Kolmogorov",
    "text": "24.3 Gli Assiomi di Kolmogorov\nI tre assiomi di Kolmogorov definiscono le propriet√† fondamentali di una misura di probabilit√† e richiedono l‚Äôesistenza di una \\(\\sigma\\)-algebra.\n\nNon negativit√†: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilit√† di \\(A\\) √® non negativa. \\[\nP(A) \\geq 0.\n\\]\nNormalizzazione: La probabilit√† dell‚Äôintero spazio campionario \\(\\Omega\\) √® 1. \\[\nP(\\Omega) = 1.\n\\]\nAdditivit√† numerabile: Per qualsiasi sequenza numerabile di eventi mutuamente esclusivi \\(A_1, A_2, A_3, \\ldots\\), la probabilit√† della loro unione √® la somma delle loro probabilit√†. \\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n24.3.1 Connessione tra gli Assiomi di Kolmogorov e le \\(\\sigma\\)-Algebre\nGli assiomi di Kolmogorov sono definiti rispetto a una misura di probabilit√† \\(P\\) su uno spazio campionario \\(\\Omega\\) e implicano l‚Äôesistenza di una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). La \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) √® la collezione di eventi (sottoinsiemi di \\(\\Omega\\)) per i quali la misura di probabilit√† \\(P\\) √® definita.\n\nNon negativit√† garantisce che \\(P\\) assegni un valore non negativo a ogni evento nella \\(\\sigma\\)-algebra.\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), assicurando che \\(\\Omega\\) sia un elemento della \\(\\sigma\\)-algebra.\nAdditivit√† numerabile garantisce che la \\(\\sigma\\)-algebra sia chiusa rispetto alle unioni numerabili di insiemi disgiunti.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all‚Äôinterno della quale queste propriet√† valgono. La \\(\\sigma\\)-algebra √® quindi la collezione di eventi per i quali la misura di probabilit√† √® ben definita e coerente con gli assiomi di Kolmogorov.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.4 Probabilit√†",
    "text": "24.4 Probabilit√†\nUna volta definiti gli assiomi di Kolmogorov, √® possibile introdurre la definizione di probabilit√†.\nLa probabilit√† di un evento √® una misura numerica che indica la possibilit√† che tale evento si verifichi, in accordo con gli assiomi di Kolmogorov.\n\nSe \\(P(A) = 0\\), l‚Äôevento \\(A\\) √® impossibile.\nSe \\(P(A) = 1\\), l‚Äôevento \\(A\\) √® certo.\n\nPer denotare la probabilit√† che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove: \\[\nP(A^c) = 1 - P(A).\n\\]\n\n24.4.1 Propriet√† Derivate dagli Assiomi di Kolmogorov\nAlcune propriet√† importanti derivate dagli assiomi includono:\n\n\\(P(\\varnothing) = 0\\),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\),\n\\(0 \\leq P(A) \\leq 1\\),\n\\(P(A^c) = 1 - P(A)\\),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\).\n\n\n\n24.4.2 Regole di Addizione per Eventi\nPer eventi non mutuamente esclusivi, la probabilit√† della loro unione √® data da: \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\]\nUtilizzando il terzo assioma della probabilit√†, si ottiene: \\[\nP(A \\cup B) = P(A \\cap B^c) + P(B \\cap A^c) + P(A \\cap B).\n\\]\nQuando \\(A\\) e \\(B\\) sono mutuamente esclusivi, \\(P(A \\cap B) = 0\\), e quindi: \\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nLa legge della probabilit√† totale permette di scrivere: \\[\nP(A) = P(A \\cap B) + P(A \\cap B^c),\n\\] e analogamente per \\(B\\): \\[\nP(B) = P(B \\cap A) + P(B \\cap A^c).\n\\]\nIn conclusione, gli assiomi di Kolmogorov forniscono la base per definire la probabilit√† su una \\(\\sigma\\)-algebra, garantendo che le propriet√† fondamentali della probabilit√† siano rispettate e che la probabilit√† sia ben definita per una collezione coerente di sottoinsiemi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†-e-calcolo-combinatorio",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†-e-calcolo-combinatorio",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.5 Probabilit√† e Calcolo Combinatorio",
    "text": "24.5 Probabilit√† e Calcolo Combinatorio\nI problemi scolastici pi√π comuni sulle probabilit√† richiedono l‚Äôuso del calcolo combinatorio. La struttura generale di questi problemi √® sempre la stessa: dobbiamo contare il numero di modi in cui un evento compatibile con l‚Äôevento di ‚Äúsuccesso‚Äù definito dal problema si realizza e poi trovare la proporzione di tali eventi rispetto a tutti gli eventi possibili (inclusi quelli di ‚Äúinsuccesso‚Äù) che possono verificarsi nello spazio campionario. Questi problemi presentano due difficolt√† principali:\n\nTraduzione del problema: Trasformare la descrizione verbale del problema in una formulazione matematica chiara, suddividendo gli eventi possibili nello spazio campionario in base alle condizioni di successo e insuccesso definite dal problema.\nConteggio delle possibilit√†: Contare il numero di successi e il numero totale di eventi.\n\nPer risolvere questi problemi, dobbiamo utilizzare tecniche del calcolo combinatorio, come le permutazioni e le combinazioni, che ci permettono di contare in modo preciso il numero di possibilit√†.\nConsideriamo un esempio semplice e intuitivo per chiarire il concetto. Supponiamo di avere una scatola con 10 palline numerate da 1 a 10. Vogliamo calcolare la probabilit√† di estrarre una pallina con un numero pari.\n\nDefinizione degli eventi: In questo caso, l‚Äôevento di ‚Äúsuccesso‚Äù √® l‚Äôestrazione di una pallina con un numero pari.\n\nEventi di successo: {2, 4, 6, 8, 10}\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\nConteggio delle possibilit√†:\n\nNumero di eventi di successo: 5\nNumero totale di eventi: 10\n\nCalcolo della probabilit√†: \\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5\n\\]\n\nPer problemi pi√π complessi, come il calcolo della probabilit√† di ottenere una determinata combinazione di carte da un mazzo o di formare un particolare gruppo di persone da una popolazione pi√π grande, utilizziamo strumenti del calcolo combinatorio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "href": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.6 Il Problema dei Fratelli Bernoulli",
    "text": "24.6 Il Problema dei Fratelli Bernoulli\nLa soluzione dei problemi di probabilit√† non √® sempre semplice e nella storia della matematica ci sono molti esempi di celebri matematici che hanno commesso errori. Uno di questi aneddoti riguarda Jakob Bernoulli, uno dei pionieri della teoria della probabilit√†.\nJakob Bernoulli si interess√≤ al calcolo delle probabilit√† mentre cercava di formalizzare le leggi del caso nel suo libro ‚ÄúArs Conjectandi‚Äù, pubblicato postumo nel 1713. Uno dei problemi che affront√≤ riguardava il calcolo della probabilit√† di ottenere almeno una testa in 8 lanci di una moneta equa. Nonostante il suo approccio iniziale fosse corretto, Bernoulli commise un errore nel calcolo combinatorio durante il processo.\nPer risolvere il problema di calcolare la probabilit√† di ottenere almeno una testa in 8 lanci, bisogna considerare la probabilit√† complementare, ovvero la probabilit√† di non ottenere alcuna testa (ottenere solo croci) in 8 lanci, e poi sottrarla da 1:\n\nCalcolo della probabilit√† complementare: La probabilit√† di ottenere solo croci in un singolo lancio √® \\(\\frac{1}{2}\\). La probabilit√† di ottenere solo croci in 8 lanci consecutivi √®: \\[\n\\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\nCalcolo della probabilit√† di ottenere almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{nessuna testa}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nJakob Bernoulli commise un errore nel calcolo combinatorio che lo port√≤ a una soluzione errata. Egli sottostim√≤ la probabilit√† di ottenere almeno una testa, probabilmente a causa di un errore nel conteggio delle possibili combinazioni di successi e insuccessi.\nQuesto errore fu successivamente corretto da altri matematici, tra cui suo nipote Daniel Bernoulli, che dimostrarono il metodo corretto per risolvere tali problemi utilizzando il calcolo combinatorio in modo appropriato.\nLa storia del calcolo combinatorio e della probabilit√† √® ricca di aneddoti come quello di Jakob Bernoulli. Questi episodi evidenziano come i problemi di probabilit√† possano essere estremamente controintuitivi, anche per i grandi matematici. Oggi siamo in grado di risolvere molti di questi problemi grazie al lavoro e alle correzioni apportate dai matematici che ci hanno preceduto. La teoria della probabilit√†, come molte altre discipline scientifiche, √® il frutto di un lungo processo di sviluppo e comprensione che ha richiesto tempo e sforzi considerevoli.\n\nEsempio 24.1 Il problema dei compleanni, generalmente attribuito a Richard von Mises, √® un noto esempio controintuitivo di calcolo delle probabilit√† che utilizza il calcolo combinatorio, in particolare le permutazioni. Il problema chiede quanti individui sono necessari affinch√© la probabilit√† che almeno due persone abbiano lo stesso compleanno superi il 50%, assumendo che ogni giorno dell‚Äôanno sia ugualmente probabile come compleanno. Sorprendentemente, la risposta √® solo 23 persone, molto meno di quanto la maggior parte delle persone immagina.\nPer risolvere il problema dei compleanni utilizzando le permutazioni, consideriamo la seguente relazione:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - P(\\text{nessuno ha lo stesso compleanno}).\n\\]\nQuesta uguaglianza √® valida perch√© l‚Äôevento ‚Äúnessuno ha lo stesso compleanno‚Äù √® il complemento dell‚Äôevento ‚Äúalmeno due persone hanno lo stesso compleanno‚Äù. Pertanto, dobbiamo calcolare la probabilit√† che nessuno abbia lo stesso compleanno.\nSia \\(k\\) il numero di persone. Per calcolare la probabilit√† che nessuno abbia lo stesso compleanno, dobbiamo contare il numero di modi in cui \\(k\\) persone possono avere compleanni diversi. Poich√© ogni compleanno √® ugualmente probabile, possiamo usare le permutazioni per contare il numero di modi in cui \\(k\\) compleanni unici possono essere disposti su 365 giorni:\n\\[\n365P_k = \\frac{365!}{(365 - k)!}.\n\\]\nDividiamo questo numero per il numero totale di elementi nello spazio campionario, che √® il numero totale di modi in cui \\(k\\) compleanni possono essere disposti su 365 giorni:\n\\[\n365^k.\n\\]\nQuindi, la probabilit√† che nessuno abbia lo stesso compleanno √®:\n\\[\nP(\\text{nessuno ha lo stesso compleanno}) = \\frac{365P_k}{365^k} = \\frac{365!}{365^k (365 - k)!}.\n\\]\nUsando questa formula, la probabilit√† che almeno due persone abbiano lo stesso compleanno √®:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - \\frac{365!}{365^k (365 - k)!}.\n\\]\nIn sintesi, calcolando questa probabilit√†, si scopre che bastano solo 23 persone affinch√© la probabilit√† che almeno due di loro abbiano lo stesso compleanno superi il 50%, un risultato sorprendente rispetto all‚Äôintuizione comune.\n\ndef birthday(k):\n    logdenom = k * math.log(365) + math.lgamma(365 - k + 1) # log denominatore\n    lognumer = math.lgamma(366) # log numeratore\n    pr = 1 - np.exp(lognumer - logdenom) # trasformazione inversa\n    return pr\n\nk = np.arange(1, 51)\nbday = [birthday(i) for i in k]\n\ncolor_fill = \"#B17F7D\"\ncolor_edge = \"#832F2B\"\n\nplt.plot(k, bday, marker=\"o\", color=color_fill)\nplt.xlabel('Numero di persone')\nplt.ylabel('Probabilit√† che almeno due persone\\nabbiano lo stesso compleanno')\nplt.axhline(\n    y=0.5,\n    color=color_edge,\n    linestyle=\"-\"\n)\nplt.xlim(0, 50)\nplt.ylim(0, 1)\nplt.grid(True)\nplt.title('Probabilit√† del Problema dei Compleanni')\nplt.show()\n\nprint(\"Probabilit√† per 20-25 persone:\", bday[19:25])\n\n\n\n\n\n\n\n\nProbabilit√† per 20-25 persone: [0.41143838358049944, 0.44368833516523465, 0.47569530766240553, 0.507297234324024, 0.5383442579144757, 0.5686997039694264]\n\n\nOsserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno supera 0.5. Quando il numero di persone √® pi√π di 50, questa probabilit√† √® quasi 1.\n\n\nEsempio 24.2 Abbiamo derivato una soluzione analitica esatta per il problema dei compleanni, ma possiamo anche produrre una soluzione approssimata utilizzando il metodo della simulazione Monte Carlo. Il nome deriva dal Casin√≤ di Monte Carlo a Monaco, ma possiamo semplicemente chiamarlo metodo di simulazione. La simulazione Monte Carlo √® una classe generale di metodi stocastici (contrariamente ai metodi deterministici) che possono essere utilizzati per risolvere approssimativamente problemi analitici generando casualmente le quantit√† di interesse.\nPer il problema dei compleanni, campioniamo \\(k\\)compleanni potenzialmente non unici su 365 giorni e verifichiamo se i \\(k\\)compleanni campionati sono tutti diversi. Utilizziamo il campionamento con reinserimento perch√© ad ogni estrazione ogni giorno dei 365 √® ugualmente probabile, indipendentemente dai giorni estratti in precedenza. In altre parole, il fatto che una persona sia nata in un certo giorno dell‚Äôanno non esclude che qualcun altro possa essere nato lo stesso giorno. Dopo aver ripetuto questa procedura di campionamento molte volte, calcoliamo la frazione di prove di simulazione in cui almeno due compleanni sono uguali, e questa frazione serve come stima della probabilit√† corrispondente. Questa procedura di simulazione √® intuitiva perch√© emula il processo di generazione dei dati descritto nel problema dei compleanni.\nPer implementare il campionamento con o senza reinserimento in Python, utilizziamo la funzione numpy.random.choice. Nel caso del campionamento con reinserimento, impostiamo l‚Äôargomento replace su True. Il campionamento senza reinserimento significa che, una volta campionato un elemento, questo non sar√† disponibile per estrazioni successive.\n\nk = 23  # numero di persone\nsims = 1000  # numero di simulazioni\nevent = 0  # contatore eventi\n\nfor _ in range(sims):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event += 1\n\n# frazione di prove in cui almeno due compleanni sono uguali\nanswer = event / sims\nprint(f\"Stima della probabilit√†: {answer}\")\n\n# Aumentare il numero di simulazioni a un milione per maggiore accuratezza\nsims_large = 1000000\nevent_large = 0\n\nfor _ in range(sims_large):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event_large += 1\n\nanswer_large = event_large / sims_large\nprint(f\"Stima con un milione di simulazioni: {answer_large}\")\n\nStima della probabilit√†: 0.486\nStima con un milione di simulazioni: 0.507198\n\n\nNel codice sopra, abbiamo impostato il numero di simulazioni a 1000. Aumentando il numero di simulazioni a un milione, otteniamo una stima pi√π accurata. Osserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno √® superiore a 0.5. Quando il numero di persone supera 50, questa probabilit√† √® vicina a 1.\nLa simulazione Monte Carlo √® una classe generale di procedure di campionamento casuale ripetuto utilizzate per risolvere approssimativamente problemi analitici. I metodi comunemente utilizzati includono il campionamento con reinserimento, in cui la stessa unit√† pu√≤ essere campionata ripetutamente, e il campionamento senza reinserimento, in cui ogni unit√† pu√≤ essere campionata al massimo una volta.\n\n\nEsempio 24.3 Supponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual √® la probabilit√† che almeno 2 psicologi clinici siano nella commissione? Per calcolare questa probabilit√†, utilizziamo la seguente uguaglianza:\n\\[\nP(\\text{almeno 2 psicologi clinici}) = 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}).\n\\]\nIl numero totale di modi per selezionare 5 persone dal gruppo di 20 √® dato da:\n\\[\n\\binom{20}{5} = \\frac{20!}{5!(15!)} = 15,504.\n\\]\nIl numero di modi per avere nessun psicologo clinico nella commissione (ovvero, selezionare solo psicologi del lavoro) √®:\n\\[\n\\binom{10}{0} \\times \\binom{10}{5} = 1 \\times 252 = 252.\n\\]\nQuindi, la probabilit√† di avere nessun psicologo clinico √®:\n\\[\nP(\\text{nessun psicologo clinico}) = \\frac{252}{15,504} \\approx 0.016.\n\\]\nIl numero di modi per avere esattamente 1 psicologo clinico nella commissione √®:\n\\[\n\\binom{10}{1} \\times \\binom{10}{4} = 10 \\times 210 = 2,100.\n\\]\nQuindi, la probabilit√† di avere esattamente 1 psicologo clinico √®:\n\\[\nP(\\text{1 psicologo clinico}) = \\frac{2,100}{15,504} \\approx 0.135.\n\\]\nLa probabilit√† di avere almeno 2 psicologi clinici nella commissione √® quindi:\n\\[\n\\begin{align}\nP(\\text{almeno 2 psicologi clinici}) &= 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}) \\notag\\\\\n&= 1 - 0.016 - 0.135 \\notag\\\\\n&= 0.849.\\notag\n\\end{align}\n\\]\nQuindi, la probabilit√† che almeno 2 psicologi clinici siano nella commissione √® circa 0.849 o 84.9%.\nSvolgiamo il problema in Python.\n\n# Funzione per calcolare le combinazioni\ndef nCk(n, k):\n    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n\n# Calcolo delle probabilit√† per il problema della commissione\ntotal_ways = nCk(20, 5)\nno_clinical = nCk(10, 0) * nCk(10, 5)\none_clinical = nCk(10, 1) * nCk(10, 4)\n\np_no_clinical = no_clinical / total_ways\np_one_clinical = one_clinical / total_ways\n\np_at_least_two_clinical = 1 - p_no_clinical - p_one_clinical\n\nprint(f\"Probabilit√† di almeno 2 psicologi clinici: {p_at_least_two_clinical:.3f}\")\n\nProbabilit√† di almeno 2 psicologi clinici: 0.848",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.7 Commenti e considerazioni finali",
    "text": "24.7 Commenti e considerazioni finali\nLa teoria delle probabilit√† √® fondamentale per la statistica e ha numerose applicazioni pratiche, tra cui la psicologia. Comprendere le probabilit√† ci permette di prendere decisioni informate in situazioni incerte e di sviluppare previsioni affidabili. Una solida comprensione delle nozioni di base della probabilit√† ci consente di affrontare una vasta gamma di problemi e di prendere decisioni basate sulla probabilit√† dei risultati possibili. Tuttavia, √® essenziale ricordare che i modelli probabilistici sono solo approssimazioni della realt√† e possono essere influenzati da semplificazioni e limitazioni dei dati disponibili. Pertanto, √® importante esercitare cautela nell‚Äôinterpretazione dei risultati e comprendere le assunzioni alla base delle analisi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "24¬† Distribuzioni di probabilit√†",
    "section": "24.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "24.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\narviz     : 0.18.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "25¬† Probabilit√† condizionata",
    "section": "",
    "text": "Introduzione\nUn principio fondamentale nel campo della probabilit√† √® il concetto di condizionamento. Il condizionamento si verifica quando, all‚Äôinterno di un esperimento aleatorio, le probabilit√† vengono calcolate focalizzandosi esclusivamente su un sottoinsieme specifico dei risultati possibili. In pratica, questo significa che la probabilit√† viene determinata tenendo conto solo di quei risultati che rientrano in un certo criterio o condizione predefinita.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "25¬† Probabilit√† condizionata",
    "section": "25.1 Indipendenza Stocastica",
    "text": "25.1 Indipendenza Stocastica\nNel contesto della probabilit√† condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilit√† in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull‚Äôaltro.\n\n25.1.1 Indipendenza di Due Eventi\nDue eventi \\(A\\) e \\(B\\) sono detti indipendenti se il verificarsi di uno non influenza la probabilit√† di verificarsi dell‚Äôaltro. Formalmente, questa condizione √® espressa come:\n\\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B),\\]\ndove \\(\\mathbb{P}(A \\cap B)\\) rappresenta la probabilit√† che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino simultaneamente.\nSe questa condizione √® soddisfatta, scriviamo \\(A \\text{ ‚´´ } B\\), il che significa ‚ÄúA √® indipendente da B‚Äù.\n\n\n25.1.2 Indipendenza di un Insieme di Eventi\nL‚Äôindipendenza stocastica √® un concetto fondamentale nell‚Äôapplicazione della probabilit√† in campo statistico. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) √® detto indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilit√† dell‚Äôintersezione degli eventi nel sottoinsieme \\(J\\) √® uguale al prodotto delle loro singole probabilit√†. Formalmente:\n\\[\\mathbb{P} \\left( \\cap_{i \\in J} A_i \\right) = \\prod_{i \\in J} \\mathbb{P}(A_i).\\]\nQuesto significa che ogni combinazione finita di eventi nell‚Äôinsieme √® indipendente.\nL‚Äôindipendenza pu√≤ essere assunta o derivata a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perch√© questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l‚Äôindipendenza pu√≤ essere derivata dai dati o da altre propriet√† del modello.\n\n\n25.1.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cio√® \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno una probabilit√† positiva di verificarsi, allora non possono essere indipendenti. Questo perch√© per eventi disgiunti con \\(\\mathbb{P}(A) &gt; 0\\) e \\(\\mathbb{P}(B) &gt; 0\\), l‚Äôequazione di indipendenza \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) non pu√≤ essere soddisfatta, dato che \\(\\mathbb{P}(A \\cap B) = 0\\) e \\(\\mathbb{P}(A) \\mathbb{P}(B) &gt; 0\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#sec-v",
    "href": "chapters/probability/04_conditional_prob.html#sec-v",
    "title": "25¬† Probabilit√† condizionata",
    "section": "25.2 Probabilit√† condizionata su altri eventi",
    "text": "25.2 Probabilit√† condizionata su altri eventi\nLa probabilit√† di un evento √® intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilit√† specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilit√† associata all‚Äôevento verr√† corrispondentemente aggiornata.\nIn realt√†, tutte le probabilit√† possono essere intese come probabilit√† condizionate, anche quando la variabile o l‚Äôevento condizionante non √® esplicitamente specificato. Ci√≤ implica che le probabilit√† sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.\nQuesto quadro concettuale ci induce a considerare le probabilit√† come una ‚Äòmisura di plausibilit√†‚Äô che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell‚Äôacquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilit√†, e quindi la probabilit√† attribuita agli eventi, pu√≤ essere rivista.\n\nTeorema 25.1 Siano \\(A\\) e \\(B\\) due eventi definiti su uno spazio campionario \\(S\\). Supponendo che l‚Äôevento \\(B\\) si verifichi, la probabilit√† condizionata di \\(A\\) dato \\(B\\) √® data da\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{per}\\, P(B) &gt; 0,\n\\tag{25.1}\\]\ndove \\(P(A \\cap B)\\) rappresenta la probabilit√† congiunta dei due eventi, ovvero la probabilit√† che entrambi si verifichino.\n\nNell‚ÄôEquazione¬†25.1, \\(P(A \\cap B)\\) √® la probabilit√† congiunta che entrambi gli eventi si verifichino, mentre \\(P(B)\\) √® la probabilit√† marginale dell‚Äôevento \\(B\\). Riorganizzando i termini, otteniamo la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nUtilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilit√† totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c).\n\\]\nDove \\(B^c\\) rappresenta il complemento dell‚Äôevento \\(B\\).\n√à importante notare che \\(P(A \\mid B)\\) non √® definita se \\(P(B) = 0\\).\nLa probabilit√† condizionata pu√≤ essere interpretata come una ricalibrazione dello spazio campionario da \\(S\\) a \\(B\\). Per spazi campionari discreti, la probabilit√† condizionata √® espressa come\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\n\nEsempio 25.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilit√† che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilit√† in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poich√© ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilit√† di ottenere una somma minore di 8 √® 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma √® minore di 8. Quindi, la probabilit√† di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l‚Äôinformazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in Python.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nevent = [roll for roll in sample if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample)}\")\n\n21 / 36\n\n\n\nsample_odd = [roll for roll in sample if (sum(roll) % 2) != 0]\nsample_odd\n\n[(1, 2),\n (1, 4),\n (1, 6),\n (2, 1),\n (2, 3),\n (2, 5),\n (3, 2),\n (3, 4),\n (3, 6),\n (4, 1),\n (4, 3),\n (4, 5),\n (5, 2),\n (5, 4),\n (5, 6),\n (6, 1),\n (6, 3),\n (6, 5)]\n\n\n\nevent = [roll for roll in sample_odd if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample_odd)}\")\n\n12 / 18\n\n\nSe applichiamo l‚ÄôEquazione¬†25.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilit√† di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l‚Äôinformazione che la somma √® dispari, la probabilit√† di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 25.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilit√† del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificit√† del test: 90%. Ci√≤ indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo √® il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne √® affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual √® la probabilit√† che una donna scelta a caso ottenga una mammografia positiva? Poich√© il 1% delle donne ha il cancro al seno, la probabilit√† di ottenere una mammografia positiva (test positivo) √® pari alla sensibilit√† del test, ovvero 0.90 (cio√® 90%).\nSe la mammografia √® positiva, qual √® la probabilit√† che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test dar√† un risultato positivo (vera positivit√†) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test dar√† un risultato positivo (falsa positivit√†) in 99 casi (10%).\n\nQuesta situazione pu√≤ essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura¬†25.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test d√† un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilit√† di ottenere un risultato positivo al test √® \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilit√† di avere il cancro al seno, dato un risultato positivo al test, √® pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all‚Äô8.3%.\nIn questo esempio, la probabilit√† dell‚Äôevento ‚Äúottenere un risultato positivo al test‚Äù √® una probabilit√† non condizionata, poich√© calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D‚Äôaltra parte, la probabilit√† dell‚Äôevento ‚Äúavere il cancro al seno, dato che il test ha prodotto un risultato positivo‚Äù √® una probabilit√† condizionata, poich√© calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) pu√≤ influenzare la probabilit√† di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilit√† condizionate e non condizionate.\n\n\nEsempio 25.3 Il paradosso di Monty Hall rappresenta un curioso esempio di come l‚Äôintroduzione di nuove informazioni possa influenzare l‚Äôesito di una situazione probabilistica. Questo famoso problema trae origine dal popolare programma televisivo americano ‚ÄúLet‚Äôs Make a Deal‚Äù e deve la sua notoriet√† al conduttore Monty Hall.\nNel gioco ci sono tre porte chiuse: dietro una si nasconde un‚Äôautomobile, mentre dietro le altre due ci sono delle capre. Inizialmente, il concorrente sceglie una delle tre porte senza aprirla. Successivamente, Monty Hall apre una delle due porte rimaste, rivelando una capra. A questo punto, offre al concorrente la possibilit√† di cambiare la sua scelta iniziale e optare per l‚Äôaltra porta ancora chiusa. Il paradosso si presenta quando si scopre che cambiando la scelta in questa fase, il concorrente aumenta le sue probabilit√† di vincere l‚Äôautomobile, passando da 1/3 a 2/3.\nPer confermare questo risultato inaspettato, √® possibile eseguire una simulazione in Python. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilit√† del concorrente di vincere l‚Äôautomobile.\nDi seguito √® riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nporte = [\n    \"capra1\",\n    \"capra2\",\n    \"macchina\",\n]  # definisco il gioco, scelgo una porta a caso per n volte\ncounter = 0\ncontatore_cambio = 0\nn = 10000\nporta_vincente = \"macchina\"\nfor i in range(n):\n    scelta_casuale = random.choice(porte)\n    porte_rimaste = [x for x in porte if x != scelta_casuale]\n    porta_rivelata = random.choice([x for x in porte_rimaste if x != porta_vincente])\n    porta_alternativa = [\n        x for x in porte if x != scelta_casuale and x != porta_rivelata\n    ]\n    if \"macchina\" in porta_alternativa:\n        contatore_cambio += 1\n    if scelta_casuale == \"macchina\":\n        counter += 1\n\nprint(counter / n)  # quante volte vinco non cambiando porta\nprint(contatore_cambio / n)  # quante volte vinco cambiando porta\n\nQuesto script Python √® stato creato da un gruppo di studenti di Psicometria nell‚ÄôAA 2023-2023. La simulazione mostra che, effettivamente, la probabilit√† di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\nEcco una spiegazione del paradosso:\n\nFase Iniziale: Nel gioco, il concorrente deve scegliere una delle tre porte (A, B, C), dietro una delle quali si trova una macchina. Inizialmente, la probabilit√† che la macchina si trovi dietro la porta scelta √® \\(1/3\\), dato che esistono tre possibilit√† ugualmente probabili e solo una contiene la macchina.\nAggiunta di Informazioni: Dopo la scelta iniziale, Monty Hall, che conosce il contenuto dietro ogni porta, apre una delle due porte non scelte, rivelando sempre una capra. Questo passaggio √® fondamentale: non cambia la probabilit√† \\(1/3\\) che la macchina sia dietro la porta originariamente scelta dal concorrente, ma la probabilit√† che la macchina si trovi dietro l‚Äôaltra porta non scelta aumenta ora a \\(2/3\\). Questo aumento di probabilit√† deriva dal fatto che Monty ha scelto deliberatamente una porta con una capra, basando la sua scelta sulla posizione della macchina.\n\nConsideriamo i tre possibili scenari dopo che il concorrente ha scelto la porta A:\n\nLa macchina √® dietro la porta A: La probabilit√† di questo scenario √® \\(1/3\\). Monty pu√≤ aprire sia la porta B che la porta C, poich√© entrambe nascondono una capra. Se il concorrente cambia la sua scelta, perder√†.\nLa macchina √® dietro la porta B: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta C, perch√© sa che la macchina √® dietro la porta B e non pu√≤ rivelarla. Se il concorrente cambia la sua scelta da A a B, vincer√†.\nLa macchina √® dietro la porta C: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta B. Se il concorrente cambia la sua scelta da A a C, vincer√†.\n\nIn conclusione, cambiare la scelta originale porta alla vittoria in due dei tre scenari possibili. Pertanto, la probabilit√† complessiva di vincere cambiando la scelta √® \\(2/3\\).\nQuesto paradosso evidenzia come, in presenza di informazioni aggiuntive, le probabilit√† iniziali possano essere riviste significativamente. √à un classico esempio di come l‚Äôintuizione umana spesso si scontri con i principi della teoria delle probabilit√†, sottolineando l‚Äôimportanza della revisione bayesiana delle probabilit√† alla luce di nuove informazioni.\n\n\n25.2.1 Il paradosso di Simpson\nNel campo della probabilit√† condizionata, uno dei fenomeni pi√π interessanti e, nel contempo, pi√π controintuitivi, √® rappresentato dal paradosso di Simpson. Il paradosso di Simpson √® un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l‚Äôimportanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 25.4 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d‚Äôansia e coaching per migliorare le prestazioni lavorative. Ogni terapia pu√≤ avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d‚Äôansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi √® efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno √® un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere pi√π precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo √® che Rossi, presumibilmente a causa della sua reputazione come terapeuta pi√π esperto, sta effettuando un numero maggiore di terapie per disturbi d‚Äôansia, che sono intrinsecamente pi√π complesse e con una probabilit√† di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale √® inferiore non a causa di una minore abilit√† in un particolare tipo di terapia, ma perch√© una frazione maggiore delle sue terapie riguarda casi pi√π complessi.\nL‚Äôaggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilit√† dei terapeuti perch√© perdiamo l‚Äôinformazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, √® fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilit√†-composta",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilit√†-composta",
    "title": "25¬† Probabilit√† condizionata",
    "section": "25.3 Teorema della probabilit√† composta",
    "text": "25.3 Teorema della probabilit√† composta\n√à possibile scrivere l‚ÄôEquazione¬†25.1 nella forma:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{25.2}\\]\nQuesto secondo modo di scrivere l‚ÄôEquazione¬†25.1 √® chiamato teorema della probabilit√† composta (o regola moltiplicativa, o regola della catena). La legge della probabilit√† composta ci dice che la probabilit√† che si verifichino contemporaneamente due eventi \\(A\\) e \\(B\\) √® pari alla probabilit√† di uno dei due eventi moltiplicata per la probabilit√† dell‚Äôaltro evento condizionata al verificarsi del primo.\nL‚Äôl‚ÄôEquazione¬†25.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{25.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 25.5 Per fare un esempio, consideriamo il problema seguente. Da un‚Äôurna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell‚Äôurna. Indichiamo con \\(B_i\\) l‚Äôevento: ‚Äúesce una pallina bianca alla \\(i\\)-esima estrazione‚Äù e con \\(N_i\\) l‚Äôestrazione di una pallina nera. L‚Äôevento: ‚Äúescono due palline bianche nelle prime due estrazioni‚Äù √® rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l‚ÄôEquazione¬†25.2, la sua probabilit√† vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perch√© nella prima estrazione \\(\\Omega\\) √® costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilit√† condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perch√© nella seconda estrazione, se √® verificato l‚Äôevento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l‚Äôesperimento consiste nell‚Äôestrazione successiva di 3 palline, la probabilit√† che queste siano tutte bianche, per l‚ÄôEquazione¬†25.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilit√† dell‚Äôestrazione di tre palline nere √® invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "href": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "title": "25¬† Probabilit√† condizionata",
    "section": "25.4 Il teorema della probabilit√† totale",
    "text": "25.4 Il teorema della probabilit√† totale\nIl teorema della probabilit√† totale (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario \\(\\Omega\\) in \\(n\\) eventi mutualmente esclusivi e tali che la loro unione formi \\(\\Omega\\), allora la probabilit√† di un qualsiasi evento in \\(\\Omega\\) pu√≤ essere calcolata sommando la probabilit√† dell‚Äôevento su ciascun sottoinsieme della partizione, pesata in base alla probabilit√† del sottoinsieme.\nIn altre parole, se \\(H_1, H_2, \\dots, H_n\\) sono eventi mutualmente esclusivi e tali che \\(\\bigcup_{i=1}^n H_i = \\Omega\\), allora per ogni evento \\(E \\subseteq \\Omega\\), la probabilit√† di \\(E\\) √® data dalla formula:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{25.4}\\]\ndove \\(P(E \\mid H_i)\\) rappresenta la probabilit√† condizionata di \\(E\\) dato che si √® verificato l‚Äôevento \\(H_i\\), e \\(P(H_i)\\) √® la probabilit√† dell‚Äôevento \\(H_i\\).\nIl teorema della probabilit√† totale riveste un ruolo fondamentale in quanto fornisce il denominatore nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione √® di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilit√† valida. Per ulteriori dettagli e approfondimenti, √® possibile fare riferimento al Capitolo 38.\nNell‚Äôambito della probabilit√† discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilit√† di un evento, sfruttando le probabilit√† dei singoli eventi della partizione. Il caso pi√π semplice √® quello di una partizione dello spazio campione in due sottoinsiemi: \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\).\n\n\n\n\n\n\nFigura¬†25.2: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nIn tali circostanza abbiamo che\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nL‚ÄôEquazione¬†25.4 √® utile per calcolare \\(P(E)\\), se \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono facili da trovare.\n\nEsempio 25.6 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un‚Äôurna anch‚Äôessa scelta a caso. Qual √® la probabilit√† che la pallina estratta sia di colore rosso?\nSia \\(R\\) l‚Äôevento ‚Äúla pallina estratta √® rossa‚Äù e sia \\(U_i\\) l‚Äôevento che corrisponde alla scelta dell‚Äô\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilit√† totale, la probabilit√† di estrarre una pallina rossa √® dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]\n\n\n25.4.1 Indipendenza e probabilit√† condizionata\nL‚Äôindipendenza tra due eventi \\(A\\) e \\(B\\) pu√≤ essere espressa in modo intuitivo utilizzando la probabilit√† condizionata. Se \\(A\\) e \\(B\\) sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilit√† del verificarsi dell‚Äôaltro. In altre parole, la probabilit√† che \\(A\\) accada non cambia se sappiamo che \\(B\\) √® avvenuto, e viceversa.\nPossiamo esprimere questa idea con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nQuindi, due eventi \\(A\\) e \\(B\\) sono indipendenti se soddisfano le condizioni:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQuesto significa che la probabilit√† di \\(A\\) rimane invariata indipendentemente dal fatto che \\(B\\) sia accaduto o meno, e lo stesso vale per \\(B\\).\n\n25.4.1.1 Indipendenza di Tre Eventi\nTre eventi \\(A\\), \\(B\\) e \\(C\\) sono indipendenti se soddisfano le seguenti condizioni:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C), \\\\\nP(A \\cap B \\cap C) &= P(A) P(B) P(C).\n\\end{align}\n\\]\nLe prime tre condizioni verificano l‚Äôindipendenza a due a due, ovvero l‚Äôindipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l‚Äôultima condizione, che riguarda l‚Äôintersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che \\(A\\), \\(B\\) e \\(C\\) sono completamente indipendenti.\nIn sintesi, l‚Äôindipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilit√† del verificarsi degli altri.\n\nEsempio 25.7 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilit√† con un mazzo completo\nIn un mazzo completo, la probabilit√† di pescare una carta di picche (\\(P(A)\\)) √® \\(\\frac{13}{52} = \\frac{1}{4}\\), poich√© ci sono 13 picche su 52 carte totali. La probabilit√† di pescare una regina (\\(P(B)\\)) √® \\(\\frac{4}{52} = \\frac{1}{13}\\), poich√© ci sono 4 regine su 52 carte.\nOra consideriamo la probabilit√† congiunta di pescare la regina di picche (\\(P(AB)\\)). Poich√© esiste solo una regina di picche nel mazzo, la probabilit√† di pescare questa specifica carta √® \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoich√© \\(P(AB) = \\frac{1}{52}\\) √® uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilit√† dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilit√† con questo mazzo ridotto:\nLa probabilit√† di pescare la regina di picche (\\(P(AB)\\)) √® ora \\(\\frac{1}{51}\\), poich√© ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poich√© ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poich√© ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilit√†:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoich√© \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono pi√π indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l‚Äôindipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilit√† cambiano e gli eventi non sono pi√π indipendenti. Questo evidenzia l‚Äôimportanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilit√† e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilit√†, influenzando le relazioni di indipendenza tra eventi specifici.\nIn generale, l‚Äôindipendenza tra due eventi significa che la probabilit√† di uno non √® influenzata dal verificarsi dell‚Äôaltro. Questo concetto √® cruciale per analisi probabilistiche e modelli statistici pi√π complessi.\n\n\nEsempio 25.8 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = ‚Äúesce un 1 o un 2 nel primo lancio‚Äù e \\(B\\) = ‚Äúil punteggio totale √® 8‚Äù. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nCalcoliamo \\(P(A)\\):\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nA = [roll for roll in sample if roll[0] == 1 or roll[0] == 2]\nprint(A)\nprint(f\"{len(A)} / {len(sample)}\")\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n12 / 36\n\n\nCalcoliamo \\(P(B)\\):\n\nB = [roll for roll in sample if roll[0] + roll[1] == 8]\nprint(B)\nprint(f\"{len(B)} / {len(sample)}\")\n\n[(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)]\n5 / 36\n\n\nCalcoliamo \\(P(A \\cap B)\\):\n\nI = [\n    roll\n    for roll in sample\n    if (roll[0] == 1 or roll[0] == 2) and (roll[0] + roll[1] == 8)\n]\nprint(I)\nprint(f\"{len(I)} / {len(sample)}\")\n\n[(2, 6)]\n1 / 36\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti dato che \\(P(A \\cap B) \\neq P(A)P(B)\\):\n\n12/36 * 5/36 == 1/36\n\nFalse",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/04_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "25¬† Probabilit√† condizionata",
    "section": "25.5 Commenti e considerazioni finali",
    "text": "25.5 Commenti e considerazioni finali\nLa probabilit√† condizionata riveste un ruolo fondamentale poich√© ci permette di definire in modo preciso il concetto di indipendenza statistica. Uno degli aspetti cruciali dell‚Äôanalisi statistica riguarda la valutazione dell‚Äôassociazione tra due variabili. Nel capitolo attuale, ci siamo concentrati sul concetto di indipendenza, che indica l‚Äôassenza di relazione tra le variabili. Tuttavia, in futuro, esploreremo come fare inferenze sulla correlazione tra variabili, ovvero come determinare se le variabili sono associate tra loro o se esiste una relazione statistica credibile tra di esse.\nNell‚Äôambito dell‚Äôinferenza bayesiana, il condizionamento emerge come uno strumento essenziale. L‚Äôinferenza bayesiana √® un approccio statistico che sfrutta proprio il condizionamento per rivedere e aggiornare le credenze o le incertezze relative a determinate ipotesi, basandosi sull‚Äôintroduzione di nuove informazioni.\nIl processo inizia stabilendo una probabilit√† iniziale, denominata probabilit√† a priori, \\(P(A)\\)), che esprime la nostra convinzione o supposizione iniziale riguardo all‚Äôipotesi \\(A\\), prima di ricevere qualsiasi dato aggiuntivo. Questa probabilit√† a priori si fonda su conoscenze gi√† acquisite o su supposizioni precedentemente formulate.\nIl cuore dell‚Äôinferenza bayesiana si trova nell‚Äôaggiornamento di questa credenza iniziale in risposta all‚Äôacquisizione di nuove informazioni, rappresentate dalla variabile \\(E\\). L‚Äôaggiornamento avviene mediante il condizionamento, culminando nella determinazione di una probabilit√† a posteriori \\(P(A | E)\\). Questa nuova probabilit√† rappresenta la nostra credenza aggiornata sull‚Äôipotesi \\(A\\) dopo aver preso in esame l‚Äôevidenza \\(E\\) appena acquisita. In questo modo, l‚Äôinferenza bayesiana permette di affinare le nostre supposizioni e le nostre previsioni su determinati fenomeni, incorporando sistematicamente nuove prove nel nostro quadro di conoscenza.\nLa formula di Bayes governa questo processo di aggiornamento:\n\\[\nP(A | E) = \\frac{P(E | A) \\times P(A)}{P(E)}\n\\]\nIn questa formula, troviamo:\n\n\\(P(A | E)\\): la probabilit√† a posteriori, che √® la probabilit√† dell‚Äôipotesi \\(A\\) date le nuove prove \\(E\\).\n\\(P(E | A)\\): la verosimiglianza, ovvero la probabilit√† di osservare le prove \\(E\\) se l‚Äôipotesi \\(A\\) fosse vera.\n\\(P(A)\\): la probabilit√† a priori, che indica il nostro livello di convinzione iniziale nell‚Äôipotesi \\(A\\).\n\\(P(E)\\): la probabilit√† di osservare le prove \\(E\\), tenendo conto di tutte le ipotesi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "25¬† Probabilit√† condizionata",
    "section": "25.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "25.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Feb 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas: 2.2.0\nnumpy : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html",
    "href": "chapters/probability/05_bayes_theorem.html",
    "title": "26¬† Il teorema di Bayes",
    "section": "",
    "text": "Introduzione\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall‚Äôidentificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all‚Äôinferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ci√≤, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l‚Äôuniverso fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non √® paragonabile a una partita di scacchi, un gioco con informazioni perfette che pu√≤ essere ‚Äúrisolto‚Äù in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull‚Äôequazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un‚Äôipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo √® noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall‚Äôincertezza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#spiegazione-del-teorema-di-bayes",
    "href": "chapters/probability/05_bayes_theorem.html#spiegazione-del-teorema-di-bayes",
    "title": "26¬† Il teorema di Bayes",
    "section": "27.1 Spiegazione del Teorema di Bayes",
    "text": "27.1 Spiegazione del Teorema di Bayes\nPrima di approfondire gli aspetti matematici del teorema di Bayes, consideriamone il significato. Sebbene il teorema di Bayes sia un risultato apparentemente semplice della teoria della probabilit√† (la sua derivazione sar√† trattata nella sezione successiva), l‚Äôinterpretazione soggettiva della probabilit√† proposta da Bayes e Price eleva questa semplice formula di probabilit√† condizionata a un potente metodo per descrivere come un agente razionale aggiorni le proprie convinzioni su un‚Äôipotesi alla luce di nuovi dati.\nConsideriamo un‚Äôipotesi \\(H_i\\) all‚Äôinterno di un insieme di ipotesi \\(\\mathcal{H}\\). Il grado di convinzione attribuito all‚Äôipotesi prima di osservare qualsiasi dato √® indicato come \\(P(H_i)\\), noto come probabilit√† a priori. Dopo aver osservato i dati \\(O\\), il grado di convinzione aggiornato √® \\(P(H_i \\mid O)\\), chiamato probabilit√† a posteriori, che rappresenta la probabilit√† di \\(H_i\\) tenendo conto delle informazioni fornite da \\(O\\). Il teorema di Bayes applica la definizione di probabilit√† condizionata per fornire:\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(O \\mid H_j)P(H_j)},\n\\]\ndove \\(P(O \\mid H_i)\\) √® la probabilit√† di osservare \\(O\\) se \\(H_i\\) fosse vera, nota come verosimiglianza. La somma al denominatore aggrega lo stesso prodotto (la probabilit√† a priori e la verosimiglianza) su tutte le ipotesi in \\(\\mathcal{H}\\), garantendo che la probabilit√† a posteriori \\(P(H_i \\mid O)\\) sommi a 1 su tutte le ipotesi. Il numeratore √® cruciale nel teorema di Bayes, indicando che la nostra convinzione in un‚Äôipotesi dopo aver osservato i dati dovrebbe riflettere il prodotto della probabilit√† a priori di quell‚Äôipotesi e della probabilit√† dei dati se quell‚Äôipotesi fosse vera.\nIntuitivamente, il teorema di Bayes afferma che le nostre convinzioni sulle ipotesi dovrebbero basarsi su due fattori: la plausibilit√† delle ipotesi (rappresentata dalla probabilit√† a priori) e la loro compatibilit√† con i dati osservati (rappresentata dalla verosimiglianza). Questi due fattori contribuiscono in modo uguale e moltiplicativo: se uno dei due √® molto piccolo, l‚Äôaltro deve essere molto grande per compensare.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#derivazione",
    "href": "chapters/probability/05_bayes_theorem.html#derivazione",
    "title": "26¬† Il teorema di Bayes",
    "section": "27.2 Derivazione",
    "text": "27.2 Derivazione\nDeriviamo il teorema di Bayes nella situazione pi√π semplice, ovvero quella in cui lo spazio di tutte le ipotesi possibili \\(\\mathcal{H}\\) √® costituito da sole due ipotesi, che possiamo concepire come eventi distinti e mutualmente esclusivi che costituiscono una partizione di \\(\\mathcal{H}\\), denominate ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo di avere gi√† una certa comprensione di queste ipotesi, espressa attraverso le loro probabilit√† a priori \\(P(H_1)\\) e \\(P(H_2)\\). A questo punto, introduciamo un nuovo evento, l‚Äôosservazione \\(O\\), la cui occorrenza √® accompagnata da una probabilit√† non nulla e per il quale conosciamo le probabilit√† condizionate \\(P(O \\mid H_1)\\) e \\(P(O \\mid H_2)\\), che indicano quanto sia probabile osservare \\(O\\) assumendo che una delle due ipotesi sia vera. Se \\(O\\) si verifica, siamo interessati a determinare le probabilit√† a posteriori \\(P(H_1 \\mid O)\\) e \\(P(H_2 \\mid O)\\) delle nostre ipotesi alla luce di questa nuova evidenza.\nLa seguente illustrazione rappresenta la suddivisione dello spazio totale delle ipotesi \\(\\mathcal{H}\\) nelle ipotesi \\(H_1\\) e \\(H_2\\), con l‚Äôevento corrispondente all‚Äôosservazione \\(O\\) posizionata all‚Äôinterno di questo spazio.\n\n\n\n\n\n\n\n\n\nPer calcolare la probabilit√† a posteriori dell‚Äôipotesi \\(H_1\\) data l‚Äôosservazione di \\(O\\), utilizziamo la formula:\n\\[\nP(H_1 \\mid O) = \\frac{P(O \\cap H_1)}{P(O)}.\n\\]\nQuesto calcolo pu√≤ essere semplificato sfruttando la definizione di probabilit√† condizionata, che ci permette di sostituire \\(P(O \\cap H_1)\\) con \\(P(O \\mid H_1)P(H_1)\\). Applicando questa sostituzione, otteniamo:\n\\[\nP(H_1 \\mid O) = \\frac{P(O \\mid H_1) P(H_1)}{P(O)}.\n\\]\nDato che \\(H_1\\) e \\(H_2\\) si escludono a vicenda, la probabilit√† totale di \\(O\\) pu√≤ essere espressa come la somma delle probabilit√† di \\(O\\) occorrente in concomitanza con ciascuna ipotesi, utilizzando il teorema della probabilit√† totale:\n\\[\nP(O) = P(O \\mid H_1)P(H_1) + P(O \\mid H_2)P(H_2).\n\\]\nIncorporando questi valori nella formula di Bayes, giungiamo a:\n\\[\nP(H_1 \\mid O) = \\frac{P(O \\mid H_1)P(H_1)}{P(O \\mid H_1)P(H_1) + P(O \\mid H_2)P(H_2)}.\n\\tag{27.1}\\]\nQuesta espressione costituisce l‚Äôessenza della formula di Bayes per il caso semplificato in cui le ipotesi si limitano a due eventi mutualmente esclusivi, \\(H_1\\) e \\(H_2\\).\nNel quadro delle probabilit√† discrete, questa formula pu√≤ essere generalizzata per accogliere un insieme pi√π ampio di ipotesi che formano una partizione completa dello spazio degli eventi \\(\\mathcal{H}\\), dove ogni \\(O\\) rappresenta un evento con probabilit√† maggiore di zero. Per ogni ipotesi \\(H_i\\) all‚Äôinterno di un insieme numerabile, la formula di Bayes si estende come segue:\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(O \\mid H_j)P(H_j)}.\n\\tag{27.2}\\]\nQui, il denominatore agisce come un fattore di normalizzazione che integra i prodotti delle probabilit√† a priori e delle verosimiglianze associate a ogni ipotesi considerata.\nPer variabili continue, la formula di Bayes assume una forma integrale, adattandosi a situazioni in cui le ipotesi \\(H_i\\) rappresentano valori in un continuum. In questo contesto, la formula diventa\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i) \\cdot P(H_i)}{\\int P(O \\mid H) \\cdot P(H) \\, dH}\n\\tag{27.3}\\]\ne consente di aggiornare le probabilit√† a posteriori di ipotesi continue basate su nuove evidenze.\nIn sintesi, la formula di Bayes si articola in tre elementi fondamentali:\n\nProbabilit√† a Priori, \\(P(H_i)\\): Questa componente riflette la nostra valutazione preliminare riguardo la verosimiglianza dell‚Äôipotesi \\(H_i\\) prima di prendere in esame nuove evidenze \\(O\\). Essa incarna il livello di credibilit√† o fiducia attribuita all‚Äôipotesi, basandosi su conoscenze preesistenti. In sostanza, la probabilit√† a priori quantifica le nostre convinzioni pregresse o le aspettative iniziali su quanto sia probabile che l‚Äôipotesi \\(H_i\\) sia vera.\nProbabilit√† a Posteriori, \\(P(H_i \\mid O)\\): Questo valore aggiorna la nostra fiducia nell‚Äôipotesi \\(H_i\\) in seguito all‚Äôosservazione dell‚Äôevidenza \\(O\\). Rappresenta il livello di convinzione ricalibrato in \\(H_i\\) dopo aver considerato l‚Äôevidenza \\(O\\). La formula di Bayes ci offre un metodo per modulare questa probabilit√† alla luce delle nuove informazioni ricevute.\nVerosimiglianza, \\(P(O \\mid H_i)\\): La verosimiglianza esprime la probabilit√† di rilevare l‚Äôevidenza \\(O\\) dato che l‚Äôipotesi \\(H_i\\) sia vera. √à un indice di quanto l‚Äôevidenza supporti o confermi l‚Äôipotesi \\(H_i\\). Un valore elevato di verosimiglianza indica che l‚Äôevidenza √® fortemente in linea o prevista dalla veridicit√† dell‚Äôipotesi.\n\nGrazie alla formula di Bayes, possiamo adottare un processo di aggiornamento continuo delle nostre credenze in base a nuove informazioni, promuovendo un metodo dinamico per navigare tra conoscenza e incertezza. Questa metodologia ci fornisce un approccio strutturato per rivedere e adattare le nostre convinzioni riguardo l‚Äôipotesi \\(H_i\\) di fronte a nuove evidenze \\(O\\). La capacit√† di rielaborare costantemente le nostre aspettative in funzione di informazioni aggiuntive ci consente di prendere decisioni pi√π informate, di interpretare con maggiore precisione i dati disponibili e di affinare le nostre previsioni e comprensioni del mondo circostante.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#alcuni-esempi",
    "href": "chapters/probability/05_bayes_theorem.html#alcuni-esempi",
    "title": "26¬† Il teorema di Bayes",
    "section": "27.3 Alcuni esempi",
    "text": "27.3 Alcuni esempi\n\nEsempio 27.1 Il modo pi√π comune per spiegare il teorema di Bayes √® attraverso i test medici. Prendiamo come esempio la mammografia e la diagnosi del cancro al seno.\nSupponiamo di avere un test di mammografia con una sensibilit√† del 90% e una specificit√† del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilit√† che il test lo rilevi correttamente √® del 90%.\nIn assenza di cancro al seno, la probabilit√† che il test confermi correttamente l‚Äôassenza della malattia √® del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch‚Äôesso del 10%.\nDefiniamo due ipotesi:\n\n\\(M^+\\): presenza della malattia\n\\(M^-\\): assenza della malattia\n\nL‚Äôevidenza √® rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilit√† di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) √® la probabilit√† di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilit√† del test, ovvero la probabilit√† che il test risulti positivo in presenza effettiva del cancro. In questo caso, √® pari a 0.90.\n\\(P(M^+)\\) √® la probabilit√† a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\\(P(T^+ \\mid M^-)\\) indica la probabilit√† di un falso positivo, cio√® la probabilit√† che il test risulti positivo in assenza di cancro. Con una specificit√† del 90%, questa probabilit√† si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificit√†} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c‚Äô√® una probabilit√† del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\\(P(M^-)\\) √® la probabilit√† a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilit√† effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilit√† e specificit√† del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nQuesto calcolo dimostra che, considerando una mammografia con risultato positivo ottenuto tramite un test con una sensibilit√† del 90% e una specificit√† del 90%, la probabilit√† che il paziente sia effettivamente affetto da cancro al seno √® solo dell‚Äô8.3%.\n\n\n27.3.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicit√†, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ci√≤ che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi √® fondamentale per questo calcolo: la prevalenza della malattia, la sensibilit√† e la specificit√† del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilit√†: Indica la capacit√† del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilit√† (\\(Sens\\)) √® la seguente:\n\\[ \\text{Sensibilit√†} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilit√† misura la probabilit√† che il test risulti positivo se la malattia √® effettivamente presente.\nSpecificit√†: Misura la capacit√† del test di riconoscere gli individui sani, producendo un risultato negativo per chi non √® affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificit√† (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificit√†} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Cos√¨, la specificit√† rappresenta la probabilit√† che il test risulti negativo in assenza della malattia.\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilit√†)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilit√†)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificit√†)\n\\(P(T^- \\cap M^-)\\)  (Specificit√†)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilit√† totale di avere la malattia (\\(P(M^+)\\)) e la probabilit√† totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilit√† totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilit√† totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilit√†, che per definizione √® 1, rappresentando l‚Äôintera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilit√† post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cio√® la probabilit√† post-test che un individuo sia malato dato un risultato positivo del test, √® calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che √® la probabilit√† che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilit√†}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 27.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in Python e usiamo gli stessi dati dell‚Äôesercizio precedente.\n\ndef positive_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n\n\ndef negative_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilit√†\nspec = 0.9  # specificit√†\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo √®:\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.083\n\n\nIl valore predittivo del test negativo √®:\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\n\n\nEsempio 27.3 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test pu√≤ essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L‚ÄôIstituto Superiore di Sanit√†, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilit√† varia tra il 70% e l‚Äô86%, mentre la specificit√† si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus √® stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n\n0.002349135593220339\n\n\nL‚Äôobiettivo √® determinare la probabilit√† di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2 # specificit√†\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.044\n\n\nPertanto, se il risultato del tampone √® positivo, la probabilit√† di essere effettivamente affetti da Covid-19 √® solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cio√®, pari al 23.5%), la probabilit√† di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l‚Äô86%.\n\nprev = 138599 / 59000000 * 100\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.857\n\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilit√† di non essere infetto sarebbe del 99.9%.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2  # specificit√†\nprev = 138599 / 59000000  # prevalenza\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\nTuttavia, un‚Äôesito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia √® molto bassa; in altre parole, il risultato negativo conferma una situazione gi√† presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell‚Äôasserire l‚Äôassenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 27.4 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell‚Äôinterpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un‚Äôaccuratezza del 99%, la sua affidabilit√† varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\nSensibilit√†:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\nSpecificit√†: circa 99.9% per tutte le condizioni citate\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\nNonostante l‚Äôalta sensibilit√† e specificit√†, il VPP pu√≤ essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni pi√π rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilit√† che un risultato positivo sia effettivamente corretto dipende non solo dall‚Äôaccuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta pi√π affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT √® uno strumento prezioso per lo screening prenatale, √® fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.\n\n\nEsempio 27.5 Il teorema di Bayes non √® rilevante solo in medicina. In ambito legale √® presente un fenomeno noto come la Fallacia del Procuratore. La ‚Äúfallacia del procuratore‚Äù √® un errore logico che si verifica quando si confonde la probabilit√† di un evento dato un certo risultato con la probabilit√† di quel risultato dato l‚Äôevento. In ambito legale, si tratta spesso di confondere la probabilit√† di ottenere un risultato di un test (ad esempio, una corrispondenza del DNA) se una persona √® innocente, con la probabilit√† che una persona sia innocente dato che il test ha mostrato una corrispondenza.\nSupponiamo di avere i seguenti parametri per un test del DNA:\n\nSensibilit√†: 99% (probabilit√† di identificare correttamente il colpevole).\nSpecificit√†: 99.99997% (probabilit√† di identificare correttamente un innocente).\nPrevalenza: 1 su 65 milioni (probabilit√† a priori che una persona qualsiasi sia il colpevole, data una popolazione di 65 milioni).\n\nImmaginiamo che ci sia stato un crimine e che un campione di DNA sia stato trovato sulla scena del crimine. Il campione √® confrontato con il DNA di una persona nel database.\nSvolgiamo i calcoli:\n\nProbabilit√† a Priori (Prevalenza):\n\nLa prevalenza \\(P(C)\\) che una persona casuale sia il colpevole √® \\(\\frac{1}{65.000.000}\\).\n\nSensibilit√† e Specificit√†:\n\nSensibilit√† \\(P(T+|C) = 0.99\\).\nSpecificit√† \\(P(T-|I) = 0.9999997\\).\n\nProbabilit√† del Test Positivo:\n\nProbabilit√† di ottenere un test positivo \\(P(T+)\\) √® la somma della probabilit√† di ottenere un positivo dai veri colpevoli e dai falsi positivi:\n\n\n\\[ P(T+) = P(T+|C) \\cdot P(C) + P(T+|I) \\cdot P(I), \\]\n\ndove \\(P(T+|I)\\) √® \\(1 - \\text{Specificit√†}\\) e \\(P(I)\\) √® la probabilit√† di essere innocente (\\(1 - P(C)\\)).\n\n\\[ P(T+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000} \\]\n\\[ P(T+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999 \\]\n\\[ P(T+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7} \\]\n\\[ P(T+) \\approx 3.1523 \\times 10^{-7} \\]\n\nProbabilit√† Condizionale che il Sospetto sia Colpevole Dato un Test Positivo:\n\nUtilizzando il teorema di Bayes:\n\n\n\\[ P(C|T+) = \\frac{P(T+|C) \\cdot P(C)}{P(T+)} \\]\n\\[ P(C|T+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) = \\frac{0.99 \\times 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) \\approx 0.0483 \\]\nQuindi, la probabilit√† che il sospetto sia effettivamente il colpevole, dato che il test del DNA √® positivo, √® circa 4.83%, nonostante l‚Äôalta specificit√† del test.\nIn sintesi, quando si afferma che c‚Äô√® solo una probabilit√† su 3 milioni che il sospetto sia innocente (ovvero la specificit√†), si commette la fallacia del procuratore. In realt√†, la probabilit√† che il sospetto sia colpevole, data una corrispondenza del DNA, √® molto inferiore, come dimostrato nell‚Äôesempio numerico (circa 4.83%).\nQuesta fallacia pu√≤ portare a errori giudiziari perch√© non si considera la bassa prevalenza del colpevole nella popolazione generale e si confonde la specificit√† del test con la probabilit√† condizionale di colpevolezza. In altre parole, non si riconosce che le due domande ‚ÄòQuanto √® probabile che il DNA di una persona corrisponda al campione, se √® innocente?‚Äô e ‚ÄòQuanto √® probabile che qualcuno sia innocente, dato che il suo DNA corrisponde al campione?‚Äô non sono equivalenti. √à come confondere ‚ÄòQuanto √® probabile che un determinato essere umano sia il papa?‚Äô con ‚ÄòQuanto √® probabile che il papa sia un essere umano?‚Äô.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#probabilit√†-inversa",
    "href": "chapters/probability/05_bayes_theorem.html#probabilit√†-inversa",
    "title": "26¬† Il teorema di Bayes",
    "section": "27.4 Probabilit√† Inversa",
    "text": "27.4 Probabilit√† Inversa\nGli esempi precedenti mettono in luce che possiamo distinguere due domande diverse. La prima domanda √®: ‚ÄúQual √® la probabilit√† dell‚Äôevidenza, data l‚Äôipotesi?‚Äù La seconda domanda √®: ‚ÄúQual √® la probabilit√† che l‚Äôipotesi sia vera, data l‚Äôevidenza?‚Äù\nUn esempio per rispondere alla prima domanda √® il seguente: Supponiamo che la probabilit√† di ottenere testa nel lancio di una moneta sia 0.5 (questa √® l‚Äôipotesi). Qual √® la probabilit√† di ottenere 0 volte testa in cinque lanci?\nUn esempio per rispondere alla seconda domanda √® il seguente: Supponiamo di avere ottenuto 0 volte testa in 5 lanci di una moneta (questa √® l‚Äôevidenza). Ci chiediamo: qual √® la probabilit√† che la moneta sia bilanciata, alla luce delle nostre osservazioni?\nPer molto tempo, la storia della probabilit√† si √® concentrata sulla prima domanda. Ma dopo che il reverendo Thomas Bayes ha iniziato a porsi la seconda domanda nel XVIII secolo, questa √® diventata nota come probabilit√† inversa.\nQuesto modo di pensare ha suscitato molte controversie nel corso della storia della statistica, forse perch√© influisce su tutto. In particolare, ci si pu√≤ chiedere la seguente domanda: quanto √® probabile che un‚Äôipotesi scientifica sia vera, dato il risultato di uno studio? Per stimare questa probabilit√†, e un numero crescente di scienziati sostiene che √® esattamente ci√≤ che dovrebbero fare le statistiche, abbiamo bisogno di Bayes e delle probabilit√† a priori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#sec-poetic-validity",
    "href": "chapters/probability/05_bayes_theorem.html#sec-poetic-validity",
    "title": "26¬† Il teorema di Bayes",
    "section": "27.5 Validit√† Poetica",
    "text": "27.5 Validit√† Poetica\nIn questo capitolo abbiamo esaminato una serie di esempi in campo medico e forense, dimostrando come il teorema di Bayes permetta di combinare le informazioni fornite dalle osservazioni con le nostre conoscenze precedenti (prior), per produrre una conoscenza a posteriori. Il teorema di Bayes offre un meccanismo razionale‚Äînoto come ‚Äúaggiornamento bayesiano‚Äù‚Äîper ricalibrare le nostre convinzioni iniziali in risposta a nuove informazioni o evidenze.\nIl teorema di Bayes ci fa comprendere che nella ricerca scientifica, cos√¨ come nella vita quotidiana, non siamo tanto interessati a conoscere la probabilit√† che qualcosa accada assumendo vera un‚Äôipotesi. Siamo invece interessati alla domanda opposta: qual √® la probabilit√† che un‚Äôipotesi sia vera, dato che abbiamo osservato una certa evidenza?\nNel contesto di questo capitolo, abbiamo focalizzato la nostra analisi sul teorema di Bayes utilizzando probabilit√† puntuali. Tuttavia, vedremo successivamente che il teorema di Bayes esprime pienamente il suo potenziale esplicativo quando l‚Äôevidenza e le conoscenze a priori sono rappresentate in termini di gradi di certezza, ossia attraverso distribuzioni di probabilit√† continue.\nAbbiamo discusso il teorema di Bayes come un metodo per verificare la plausibilit√† di un‚Äôipotesi, il che costituisce uno dei motivi chiave della sua importanza. Tuttavia, √® essenziale comprendere che la quantificazione della plausibilit√† di un‚Äôipotesi non risolve il problema scientifico dell‚Äôinferenza.\nPaul Meehl ha articolato questo problema distinguendo tre piani: la teoria sostanziale (\\(\\mathcal{T}\\)), l‚Äôipotesi statistica testabile (\\(H\\)) e le osservazioni (\\(O\\)). L‚Äôarticolazione tra questi tre piani della riflessione scientifica solleva importanti difficolt√†:\n\nThe map from substantive theory \\(\\mathcal{T}\\) to testable statistical hypothesis \\(H\\) goes through a derivation chain involving auxiliary theories, instruments, ceteris paribus assertions, and experimental conditions. The map from hypothesis to observation is through the statistical model manufactured by the derivation chain.\nStatistical theory provides a variety of means to infer the veracity of \\(H\\) from \\(O\\). Usually this goes through Bayes‚Äô Rule‚Ä¶.This seems all well and good. But let‚Äôs say we now infer that H has high probability given all of our evidence. Then what? We cared about \\(\\mathcal{T}\\)! How do we compute the probability of \\(\\mathcal{T}\\) from \\(O\\)?\n\nNei primi anni ‚Äô90, Paul Meehl, nelle sue lezioni, sosteneva l‚Äôassenza di una procedura formale in grado di tradurre rigorosamente tra le osservazioni empiriche (\\(O\\)) e la teoria scientifica (\\(\\mathcal{T}\\)).\n\nIl modello statistico, costruito attraverso una catena di derivazione, mappa l‚Äôipotesi (\\(H\\)) sulle osservazioni (\\(O\\)).\nL‚Äôinferenza statistica, tipicamente basata sul teorema di Bayes, permette di valutare la probabilit√† di \\(H\\) dato \\(O\\).\n\nTuttavia, il passaggio cruciale da \\(H\\) a \\(\\mathcal{T}\\) rimane problematico. Secondo Meehl il passaggio da \\(\\mathcal{T}\\) a \\(H\\) coinvolge una catena di derivazione che include teorie ausiliarie, strumenti, assunzioni ceteris paribus e condizioni sperimentali (Hardt e Recht 2022). Il passaggio inverso da \\(H\\) a \\(\\mathcal{T}\\) rimane dunque problematico e non caratterizzato da propriet√† formali rigide.\nQuesta disconnessione tra \\(\\mathcal{T}\\) e \\(H\\) √® stata descritta come una forma di ‚Äúvalidit√† poetica‚Äù. Questo concetto si riferisce alla capacit√† di un‚Äôidea di risuonare con l‚Äôintelletto e l‚Äôesperienza umana attraverso il linguaggio, anche quando non pu√≤ essere rigorosamente validata in termini scientifici o statistici. La validit√† poetica sottolinea l‚Äôimportanza dell‚Äôintuizione e della comprensione qualitativa nel processo di teorizzazione scientifica, complementando l‚Äôapproccio puramente quantitativo e formale (Hardt e Recht 2022).\nLa dicotomia tra concetti teorici e concetti empirici, manifestata nel processo di operazionalizzazione, chiarisce ulteriormente questa problematica (Hempel 1970).\nL‚Äôoperazionalizzazione dei concetti teorici in concetti empirici √® un processo arbitrario e uno-a-molti, che comporta diverse implicazioni:\n\nLa sottodeterminazione delle teorie: Nessun test di ipotesi pu√≤ essere considerato un test diretto di una teoria, dato che l‚Äôoperazionalizzazione introduce un elemento di arbitrariet√†.\nLa flessibilit√† teorica: La relazione uno-a-molti tra concetti teorici ed empirici permette un raffinamento progressivo delle teorie.\nL‚Äôambiguit√† empirica: Operazionalizzazioni diverse possono portare a risultati contraddittori rispetto alla stessa teoria.\nLa necessit√† di formalizzazione: le teorie psicologiche devono essere espresse in termini formali per consentire predizioni quantitative.\n\nIn conclusione, il problema della demarcazione tra teoria e osservazione in psicologia rimane un tema aperto e fondamentale. La consapevolezza di queste limitazioni epistemologiche dovrebbe informare sia la pratica della ricerca empirica che l‚Äôinterpretazione dei suoi risultati, promuovendo un approccio pi√π critico alla costruzione, validazione e interpretazione delle teorie psicologiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "26¬† Il teorema di Bayes",
    "section": "27.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "27.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\narviz     : 0.17.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html",
    "href": "chapters/probability/06_random_var.html",
    "title": "27¬† Variabili casuali",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, introdurremo il concetto di variabili casuali e delle loro distribuzioni di probabilit√†, ampliando ulteriormente l‚Äôambito delle analisi matematiche degli eventi considerati finora.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#variabili-aleatorie-e-spazi-di-probabilit√†",
    "href": "chapters/probability/06_random_var.html#variabili-aleatorie-e-spazi-di-probabilit√†",
    "title": "27¬† Variabili casuali",
    "section": "27.1 Variabili Aleatorie e Spazi di Probabilit√†",
    "text": "27.1 Variabili Aleatorie e Spazi di Probabilit√†\nLe variabili aleatorie sono uno strumento fondamentale nella teoria della probabilit√†. Esse ci permettono di passare da risultati qualitativi (come \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\)) a valori numerici, facilitando l‚Äôanalisi matematica.\n\nDefinizione 27.1 Una variabile aleatoria reale \\(V\\) √® definita come una funzione misurabile che mappa uno spazio di probabilit√† \\((\\Omega, \\mathcal{F}_\\Omega, {\\Pr}_V)\\) nell‚Äôinsieme dei numeri reali \\(\\mathbb{R}\\), dotato di una \\(\\sigma\\)-algebra \\(\\mathcal{A}\\). In formula:\n\\[\nV: (\\Omega, \\mathcal{F}_\\Omega, {\\Pr}_V) \\rightarrow (\\mathbb{R}, \\mathcal{A}),\n\\]\ndove\n\n\\(\\Omega\\) √® lo spazio campionario, ovvero l‚Äôinsieme di tutti i possibili risultati dell‚Äôesperimento.\n\\(\\mathcal{F}_\\Omega\\) √® una \\(\\sigma\\)-algebra su \\(\\Omega\\), cio√® una collezione di sottoinsiemi di \\(\\Omega\\) che rispetta certe propriet√† matematiche.\n\\({\\Pr}_V\\) √® la misura di probabilit√†, che assegna una probabilit√† a ciascun evento in \\(\\mathcal{F}_\\Omega\\).\n\\(\\mathbb{R}\\) √® l‚Äôinsieme dei numeri reali.\n\\(\\mathcal{A}\\) √® una \\(\\sigma\\)-algebra su \\(\\mathbb{R}\\), che include tutti gli insiemi aperti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#misurabilit√†",
    "href": "chapters/probability/06_random_var.html#misurabilit√†",
    "title": "27¬† Variabili casuali",
    "section": "27.2 Misurabilit√†",
    "text": "27.2 Misurabilit√†\nLa misurabilit√† √® una propriet√† fondamentale delle variabili aleatorie. Una variabile aleatoria \\(V\\) √® detta \\((\\mathcal{F}_\\Omega, \\mathcal{A})\\)-misurabile se soddisfa la seguente condizione:\n\nPer ogni insieme \\(B\\) in \\(\\mathcal{A}\\), l‚Äôinsieme \\(\\{\\omega \\in \\Omega : V(\\omega) \\in B\\}\\) appartiene a \\(\\mathcal{F}_\\Omega\\).\n\nIn termini pi√π semplici, questo significa che possiamo calcolare la probabilit√† di qualsiasi evento definito in termini della variabile aleatoria \\(V\\).\n\n\n\nVariabile aleatoria. Tre elementi di \\(\\Omega\\) etichettati come \\(\\omega_a\\), \\(\\omega_b\\) e \\(\\omega_c\\) sono assegnati a quantit√† numeriche reali sotto la variabile aleatoria \\(V\\).\n\n\nQuesta figura illustra come una variabile aleatoria \\(V\\) associa valori numerici reali a elementi dello spazio campionario \\(\\Omega\\).\nLe variabili aleatorie forniscono un ponte tra il mondo degli eventi casuali e quello dei numeri. Questo processo di assegnazione di numeri a stati semplifica notevolmente l‚Äôanalisi dei dati, permettendoci di applicare concetti matematici e statistici agli eventi del mondo reale. In generale, le variabili aleatorie vengono utilizzate principalmente in due modi:\n\nModellazione delle conoscenze (osservazioni): Le variabili aleatorie aiutano a quantificare e strutturare le informazioni raccolte da esperimenti o studi.\nModellazione delle incognite (variabili latenti, parametri, predizioni): Le variabili aleatorie rappresentano ci√≤ che non sappiamo o che vogliamo prevedere, come i parametri nascosti di un modello o i futuri esiti di un esperimento.\n\n\nEsempio 27.1 Consideriamo l‚Äôesperimento casuale del lancio di una moneta. Ogni volta che lanciamo la moneta, otteniamo un risultato specifico: testa o croce. Questi risultati sono gli esiti reali che possiamo osservare. In matematica e statistica, ci interessa analizzare tutti i possibili risultati in modo strutturato. Le variabili aleatorie ci permettono di trasformare questi esiti in valori numerici utilizzabili nei calcoli; per esempio, possiamo assegnare il numero 1 a testa e il numero 0 a croce.\n\n\nEsempio 27.2 Un altro esempio √® la variabile aleatoria \\(Y\\) che rappresenta il risultato di un lancio di dado. Se definiamo \\(Y = 1\\) per indicare che il risultato del lancio √® un numero dispari (1, 3 o 5) e \\(Y = 0\\) per indicare che il risultato del lancio √® un numero pari (2, 4 o 6), abbiamo trasformato un‚Äôosservazione fisica (il lancio del dado) in un valore numerico che rappresenta un certo tipo di evento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#tipologie-di-variabili-aleatorie",
    "href": "chapters/probability/06_random_var.html#tipologie-di-variabili-aleatorie",
    "title": "27¬† Variabili casuali",
    "section": "27.3 Tipologie di Variabili Aleatorie",
    "text": "27.3 Tipologie di Variabili Aleatorie\nLe variabili aleatorie si dividono in due categorie principali:\n\nDiscrete: Queste variabili possono assumere solo un numero limitato di valori distinti e contabili. Un esempio √® il numero di libri letti in un mese.\nContinue: Queste variabili possono assumere qualsiasi valore in un intervallo. Un esempio √® la temperatura di un giorno, che pu√≤ variare continuamente e assumere un numero infinito di valori all‚Äôinterno di un dato range.\n\nIn sintesi, le variabili aleatorie ci permettono di modellare e analizzare matematicamente la complessit√† e l‚Äôincertezza del mondo reale, fornendo un ponte tra le osservazioni empiriche e la teoria statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#convenzioni-notazionali",
    "href": "chapters/probability/06_random_var.html#convenzioni-notazionali",
    "title": "27¬† Variabili casuali",
    "section": "27.4 Convenzioni Notazionali",
    "text": "27.4 Convenzioni Notazionali\nNella teoria della probabilit√†, √® usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come ‚ÄòX‚Äô, per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D‚Äôaltro canto, la corrispondente lettera minuscola, ‚Äòx‚Äô nel nostro esempio, √® impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale pu√≤ assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (X) o di un suo specifico valore (x).\nUlteriori convenzioni di notazione includono:\n\n‚ÄòX‚Äô √® spesso usata per rappresentare variabili casuali non osservate, come parametri sconosciuti o variabili latenti di un modello.\n‚ÄòY‚Äô, al contrario, √® generalmente riservata a variabili casuali osservate, ovvero dati che sono stati effettivamente raccolti o misurati in un esperimento",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "title": "27¬† Variabili casuali",
    "section": "27.5 Variabili casuali multiple",
    "text": "27.5 Variabili casuali multiple\nNella teoria della probabilit√†, le variabili casuali spesso non operano in isolamento ma in contesti dove interagiscono o si combinano tra loro. Per esemplificare, immaginiamo di avere una moneta perfettamente bilanciata e di decidere di lanciarla tre volte. Ogni lancio di questa moneta pu√≤ essere descritto da una variabile casuale separata: \\(Y_1\\), \\(Y_2\\), e \\(Y_3\\). Queste variabili rappresentano i risultati dei lanci individuali, e ogni lancio √® considerato indipendente dagli altri. Ci√≤ significa che l‚Äôesito di un lancio non influisce sugli esiti degli altri. Poich√© la moneta √® bilanciata, la probabilit√† di ottenere testa (che possiamo rappresentare come 1) o croce (rappresentata come 0) in ogni lancio √® del 50%, dunque abbiamo \\(P(Y_n = 1) = 0.5\\) e \\(P(Y_n = 0) = 0.5\\), per \\(n\\) uguale a 1, 2 o 3.\nQuando combiniamo variabili casuali attraverso operazioni aritmetiche, possiamo creare nuove variabili che offrono ulteriori insight. Prendiamo, per esempio, i tre lanci della moneta bilanciata menzionati prima. Se definiamo \\(Y_1\\), \\(Y_2\\), e \\(Y_3\\) come i risultati di questi lanci, possiamo introdurre una nuova variabile casuale \\(Z\\) che rappresenta la somma dei risultati:\n\\[\nZ = Y_1 + Y_2 + Y_3.\n\\]\nLa variabile \\(Z\\) √® un esempio di variabile casuale discreta, il che significa che pu√≤ assumere solo valori interi specifici. A differenza delle variabili continue che possono assumere qualsiasi valore in un intervallo, \\(Z\\) pu√≤ solo risultare in una serie limitata di numeri interi, che nel contesto dei nostri lanci di moneta sono i possibili totali di testa ottenuti nei tre tentativi. La notazione \\(\\mathbb{Z}\\) qui √® un po‚Äô fuorviante poich√© sembra riferirsi all‚Äôinsieme di tutti i numeri interi, ma nel contesto specifico di \\(Z\\) come somma dei risultati di tre lanci di moneta, i valori possibili di \\(Z\\) vanno da 0 (nessun testa in tre lanci) a 3 (testa in tutti e tre i lanci), rendendo \\(Z\\) una variabile che riflette il numero totale di testa ottenuti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#sec-fun-mass-prob",
    "href": "chapters/probability/06_random_var.html#sec-fun-mass-prob",
    "title": "27¬† Variabili casuali",
    "section": "27.6 Distribuzione di Probabilit√†",
    "text": "27.6 Distribuzione di Probabilit√†\nIl concetto di distribuzione di probabilit√† √® fondamentale per analizzare come le probabilit√† si distribuiscono tra i vari esiti possibili di una variabile casuale. Questo concetto varia a seconda che stiamo considerando variabili casuali discrete o continue.\n\n27.6.1 Variabili Casuali Discrete\nPer le variabili casuali discrete, che assumono valori specifici e contabili (come il lancio di un dado), la distribuzione di probabilit√† √® rappresentata dalla cosiddetta funzione di massa di probabilit√†, spesso abbreviata come \\(P(\\cdot)\\). Questa funzione attribuisce una probabilit√† precisa a ciascun esito possibile della variabile.\nMentre nel Capitolo 23 abbiamo discusso la distribuzione di probabilit√† in relazione agli eventi di uno spazio campionario, nel caso delle variabili casuali discrete l‚Äôintera probabilit√† (pari a 1) viene distribuita tra i valori numerici che la variabile casuale discreta pu√≤ assumere.\nPrendendo come esempio il lancio di un dado equilibrato, se ci concentriamo sul risultato ‚Äú1‚Äù, la funzione di massa di probabilit√† potrebbe essere espressa come \\(P(Y = 1) = \\frac{1}{6}\\). Questo indica che, in una serie di lanci indipendenti, il risultato ‚Äú1‚Äù si verificherebbe circa una volta su sei.\n\n27.6.1.1 Istogrammi\nLa visualizzazione dell‚Äôallocazione delle probabilit√† tra i valori di una variabile casuale discreta viene realizzata mediante un istogramma. Gli istogrammi sono estremamente utili per comunicare rapidamente alcune delle caratteristiche chiave di una distribuzione di probabilit√†. Ad esempio, gli istogrammi ci permettono di differenziare tra allocazioni che si concentrano attorno a un punto, chiamate misure unimodali, o allocazioni che si concentrano attorno a pi√π punti, chiamate misure multimodali. Allo stesso tempo, possiamo vedere come una misura si concentra attorno a un punto, ad esempio se la concentrazione √® simmetrica o asimmetrica verso valori pi√π piccoli o pi√π grandi.\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n¬†\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n¬†\n\n\n\n\nFigura¬†27.1: Gli istogrammi sono estremamente efficaci nel comunicare le caratteristiche di base di una misura. La misura in (a) √® diffusa ma decrescente, allocando pi√π probabilit√† ai punti pi√π piccoli rispetto ai punti pi√π grandi. Al contrario, la misura in (b) si concentra attorno a un singolo punto mentre la misura in (c) si concentra attorno a pi√π punti distinti. Infine, la misura in (d) si concentra attorno a un singolo punto, ma quella concentrazione √® fortemente asimmetrica, a differenza della concentrazione in (b).\n\n\n\nPer le variabili casuali discrete possiamo sempre regolare i bin di un istogramma in modo che ciascun bin copra un singolo valore della variabile casuale. In questo caso, l‚Äôaltezza di ciascun bin corrisponde a \\(\\mu(\\{ x \\})\\) e l‚Äôistogramma risultante √® una rappresentazione visiva della funzione di massa di probabilit√†.\n\n\n\n27.6.2 Variabili Casuali Continue\nNel caso delle variabili casuali continue, che possono assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo, si utilizza la funzione di densit√† di probabilit√†, indicata con \\(p(\\cdot)\\). Questa funzione non assegna probabilit√† a valori puntuali (poich√© la probabilit√† di un singolo valore esatto √® zero), ma determina la probabilit√† che la variabile si collochi entro un certo intervallo di valori.\nAnche per una variabile casuale continua possiamo rappresentare visivamente la distribuzione di probabilit√† con un istogramma. In questo caso, per√≤, i bin dell‚Äôistogramma devono sempre contenere intervalli di valori della variabile casuale. Un istogramma con bin pi√π piccoli comunica maggiori dettagli sulla funzione di densit√† di probabilit√†. Se rendiamo i bin infinitamente piccoli, il profilo dell‚Äôistogramma tende a coincidere con la funzione di densit√† di probabilit√† della variabile casuale.\n\n\n\n\n\n\nFigura¬†27.2: Istogrammi di una variabile casuale continua con bin di dimensioni progressivamente ridotte. Al limite, il profilo dell‚Äôistogramma tende a diventare una linea continua.\n\n\n\n\n\n27.6.3 Supporto della Variabile Casuale\nIl concetto di supporto di una variabile casuale si riferisce all‚Äôinsieme di tutti i valori che la variabile pu√≤ effettivamente assumere. Per esempio, il supporto di un dado standard a sei facce √® l‚Äôinsieme \\(\\{1, 2, 3, 4, 5, 6\\}\\), mentre per una variabile casuale che segue una distribuzione continua, come quella gaussiana, il supporto potrebbe essere l‚Äôintero insieme dei numeri reali.\n\n\n27.6.4 Assegnazione di Probabilit√†\nPer le variabili casuali discrete, √® essenziale specificare la probabilit√† di ogni valore possibile per definire la loro distribuzione di probabilit√† in modo completo. Per le variabili continue, invece, ci affidiamo alla densit√† di probabilit√† per capire la probabilit√† che la variabile rientri in specifici intervalli di valori.\nIn conclusione, la distribuzione di probabilit√†, rappresentata attraverso la funzione di massa di probabilit√† per le variabili discrete o la densit√† di probabilit√† per quelle continue, √® cruciale per descrivere il modo in cui le probabilit√† si distribuiscono tra i diversi esiti possibili di una variabile casuale, offrendo una visione completa del suo comportamento.\n\nEsempio 27.3 Supponiamo che la variabile casuale discreta \\(X\\) per il tipo di sangue sia definita esplicitamente come segue:\n\\[\nX =\n\\begin{cases}\n1 & \\text{se la persona ha il tipo di sangue A} \\\\\n2 & \\text{se la persona ha il tipo di sangue B} \\\\\n3 & \\text{se la persona ha il tipo di sangue AB} \\\\\n4 & \\text{se la persona ha il tipo di sangue O}\n\\end{cases}\n\\]\nPertanto, \\(X\\) √® una variabile casuale discreta con quattro possibili esiti. Possiamo anche trovare la distribuzione di probabilit√† che descrive la probabilit√† dei diversi valori possibili della variabile casuale \\(X\\). Notiamo che gli assiomi e le propriet√† delle probabilit√† che abbiamo discusso in precedenza si applicano anche alle variabili casuali (ad esempio, la probabilit√† totale per tutti i valori possibili di una variabile casuale √® pari a uno).\nLe distribuzioni di probabilit√† sono spesso presentate utilizzando tabelle di probabilit√† o grafici. Ad esempio, supponiamo che le probabilit√† individuali per i diversi tipi di sangue in una popolazione siano \\(P(A) = 0.41\\), \\(P(B) = 0.10\\), \\(P(AB) = 0.04\\), e \\(P(O) = 0.45\\). Notiamo che:\n\\[ P(A) + P(B) + P(AB) + P(O) = 0.41 + 0.10 + 0.04 + 0.45 = 1. \\]\n\n\n\nTipo di sangue\nA\nB\nAB\nO\n\n\n\n\n\\(X\\)\n1\n2\n3\n4\n\n\n\\(P(X)\\)\n0.41\n0.10\n0.04\n0.45\n\n\n\nQui, \\(x\\) denota un valore specifico (cio√® 1, 2, 3 o 4) della variabile casuale \\(X\\). Quindi, invece di dire \\(P(A) = 0.41\\), cio√® il tipo di sangue √® A con probabilit√† 0.41, possiamo dire che \\(P(X = 1) = 0.41\\), cio√® \\(X\\) √® uguale a 1 con probabilit√† 0.41.\nPossiamo usare la distribuzione di probabilit√† per rispondere a domande di probabilit√†. Ad esempio, qual √® la probabilit√† che una persona selezionata a caso dalla popolazione possa donare sangue a qualcuno con tipo di sangue B?\nSappiamo che le persone con tipo di sangue B o O possono donare a una persona con tipo di sangue B.\nPertanto, dobbiamo trovare la probabilit√† \\(P(\\text{tipo di sangue B} \\cup \\text{tipo di sangue O})\\). Poich√© gli eventi tipo di sangue B e tipo di sangue O sono mutuamente esclusivi, possiamo usare la regola dell‚Äôaddizione per eventi mutuamente esclusivi per ottenere:\n\\[ P(\\text{B} \\cup \\text{O}) = P(B) + P(O) = 0.10 + 0.45 = 0.55 \\]\nQuindi, c‚Äô√® una probabilit√† del 55% che una persona selezionata a caso nella nostra popolazione possa donare sangue a qualcuno con tipo di sangue B.\n\n\nEsempio 27.4 Immaginiamo di lanciare due dadi equilibrati, ciascuno con sei facce. Definiamo una variabile casuale discreta \\(Z\\), che rappresenta la somma dei valori ottenuti in ciascun lancio dei dadi. Indichiamo con \\(D_1\\) il risultato del primo dado e con \\(D_2\\) quello del secondo dado, quindi \\(Z = D_1 + D_2\\).\nPer analizzare questa variabile casuale, dobbiamo prima costruire lo spazio campionario associato all‚Äôesperimento. Lo spazio campionario in questo caso √® l‚Äôinsieme di tutte le possibili combinazioni dei risultati dei due lanci di dado. Dato che ogni dado ha sei facce, ci sono in totale \\(6 \\times 6 = 36\\) possibili esiti.\nOgni esito pu√≤ essere rappresentato come una coppia ordinata (i, j), dove i e j sono i risultati dei dadi \\(D_1\\) e \\(D_2\\), rispettivamente. Quindi, lo spazio campionario pu√≤ essere descritto come \\({(1,1), (1,2), (1,3), \\dots, (6,4), (6,5), (6,6)}\\).\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nprint(sample)\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\n\nelements_per_row = 6\n\nfor i in range(0, len(sample), elements_per_row):\n    print(sample[i:i+elements_per_row])\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)]\n[(2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n[(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)]\n[(4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6)]\n[(5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6)]\n[(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLe sequenze come (1, 1), (1, 2), ecc. sono gli eventi elementari di questo esperimento casuale. Lo spazio campione di questo esperimento casuale √® costituito da 36 eventi elementari:\n\nlen(sample)\n\n36\n\n\nPer ogni possibile combinazione (i, j) risultante dal lancio dei due dadi, la variabile casuale \\(Z\\) assume un valore che corrisponde alla somma dei numeri i e j. Ad esempio, se i risultati dei dadi sono 3 e 4, allora \\(Z = 3 + 4 = 7\\). Pertanto, il valore di \\(Z\\) pu√≤ variare da un minimo di 2 (ottenuto dal lancio di due 1) fino a un massimo di 12 (ottenuto dal lancio di due 6), coprendo cos√¨ tutti i possibili risultati della somma dei due dadi. La distribuzione di \\(Z\\) ci offre una panoramica sulle probabilit√† associate a ogni possibile somma risultante.\n√à importante sottolineare che l‚Äôevento \\(Z = u\\), dove \\(u\\) √® un valore compreso tra 2 e 12, rappresenta un ‚Äúevento composto‚Äù. Ci√≤ significa che pu√≤ essere formato da pi√π di un ‚Äúevento elementare‚Äù. Ad esempio, l‚Äôevento \\(Z = 2\\) corrisponde esclusivamente all‚Äôevento elementare (1, 1), mentre l‚Äôevento \\(Z = 3\\) √® il risultato di due eventi elementari differenti: (1, 2) e (2, 1). La stessa logica si applica agli altri valori di \\(Z\\), dove il numero di eventi elementari che contribuiscono a un dato evento composto \\(Z = u\\) aumenta all‚Äôaumentare del valore di \\(u\\). Questa caratteristica della distribuzione di \\(Z\\) √® fondamentale per comprendere e calcolare le probabilit√† associate ai diversi totali possibili nella somma dei due dadi.\nNel nostro esempio costruito usando Python, ogni elemento della lista sample √® una lista di due elementi. Per trovare il valore della variabile casuale \\(Z\\), quindi, dobbiamo sommare i due elementi di ciascuna lista. Nel primo punto campione (1, 1), il valore di \\(Z\\) √® 2:\n\nsum(sample[0])\n\n2\n\n\nIn corrispondenza dell‚Äôultimo punto dello spazio campione (6, 6), il valore di \\(Z\\) √® 12:\n\nsum(sample[35])\n\n12\n\n\nCreiamo ora la lista z che memorizza il valore assunto dalla variabile casuale \\(Z\\) in corrispondenza di ciascun punto dello spazio campione:\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nz = [sum(point) for point in sample]\n\n# Arrange and print `z` in a format with 6 elements per row to reflect a 6x6 sample space\nelements_per_row = 6\nformatted_output = [z[i:i+elements_per_row] for i in range(0, len(z), elements_per_row)]\n\nformatted_output\n\n[[2, 3, 4, 5, 6, 7],\n [3, 4, 5, 6, 7, 8],\n [4, 5, 6, 7, 8, 9],\n [5, 6, 7, 8, 9, 10],\n [6, 7, 8, 9, 10, 11],\n [7, 8, 9, 10, 11, 12]]\n\n\nContiamo dunque quante volte si presenta ciascun possibile valore \\(Z\\) nello spazio campione.\n\n# Inizializzo un dizionario per memorizzare le frequenze di ciascun valore di Z\nfrequenze_z = {}\n\n# Calcolo le frequenze per ciascun valore di Z\nfor valore in z:\n    if valore in frequenze_z:\n        frequenze_z[valore] += 1\n    else:\n        frequenze_z[valore] = 1\n\nfrequenze_z\n\n{2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}\n\n\nI valori di probabilit√† per ciascun valore di \\(z\\) sono calcolati in base alla frequenza con cui quel particolare valore di \\(z\\) emerge all‚Äôinterno dell‚Äôintero insieme dei risultati. In altre parole, per ogni valore \\(z\\), la probabilit√† corrispondente √® determinata dalla proporzione di occorrenze di quel valore \\(z\\) nell‚Äôelenco dei risultati prodotti dall‚Äôesperimento casuale. Questo elenco rappresenta tutti i possibili valori che la variabile casuale \\(Z\\) pu√≤ assumere, calcolati per ogni combinazione di punti nello spazio campionario dell‚Äôesperimento.\nCostruiamo ora la distribuzione di massa di probabilit√† per la variabile casuale \\(Z\\). La probabilit√† di ciascun valore di \\(Z\\) si trova dividendo la sua frequenza per il numero totale di esiti nello spazio campione.\n\n# Calcoliamo il numero totale di esiti nello spazio campione\nnumero_totale_esiti = len(z)\n\n# Inizializzo un dizionario per memorizzare la distribuzione di massa di probabilit√† di Z\ndistribuzione_massa_probabilita = {}\n\n# Calcolo della distribuzione di massa di probabilit√† per ciascun valore di Z\nfor valore, frequenza in frequenze_z.items():\n    distribuzione_massa_probabilita[valore] = frequenza / numero_totale_esiti\n\ndistribuzione_massa_probabilita\n\n{2: 0.027777777777777776,\n 3: 0.05555555555555555,\n 4: 0.08333333333333333,\n 5: 0.1111111111111111,\n 6: 0.1388888888888889,\n 7: 0.16666666666666666,\n 8: 0.1388888888888889,\n 9: 0.1111111111111111,\n 10: 0.08333333333333333,\n 11: 0.05555555555555555,\n 12: 0.027777777777777776}\n\n\nCreiamo un DataFrame con due colonne: i valori di Z e le associate probabilit√†.\n\ndf_distribuzione = pd.DataFrame(list(distribuzione_massa_probabilita.items()), columns=['Valore di Z', 'Probabilit√†'])\ndf_distribuzione\n\n\n\n\n\n\n\n\n\nValore di Z\nProbabilit√†\n\n\n\n\n0\n2\n0.027778\n\n\n1\n3\n0.055556\n\n\n2\n4\n0.083333\n\n\n3\n5\n0.111111\n\n\n4\n6\n0.138889\n\n\n5\n7\n0.166667\n\n\n6\n8\n0.138889\n\n\n7\n9\n0.111111\n\n\n8\n10\n0.083333\n\n\n9\n11\n0.055556\n\n\n10\n12\n0.027778\n\n\n\n\n\n\n\n\nPossiamo usare un un grafico a barre per rappresentare la distribuzione di probabilit√† di \\(Z\\).\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.bar(\n    df_distribuzione[\"Valore di Z\"],\n    df_distribuzione[\"Probabilit√†\"],\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.xlabel('Valore Z')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione di Probabilit√† di Z')\nplt.xticks(range(2, 13))  # Per mostrare tutte le etichette sull'asse x\nplt.show()\n\n\n\n\n\n\n\n\nNel corso di questo esercizio, abbiamo calcolato le probabilit√† determinando il numero di casi favorevoli, cio√® le occorrenze di ogni possibile somma \\(D_1 + D_2\\), all‚Äôinterno dello spazio campionario dell‚Äôesperimento di lancio di due dadi. Queste probabilit√† si ottengono dividendo il numero di tali occorrenze per il numero totale di combinazioni possibili nello spazio campionario. In termini formali, la probabilit√† di ogni valore specifico di $ Z $ √® indicata come \\(P_Z(z) = P(Z = z)\\), dove \\(P_Z(z)\\) rappresenta ‚Äúla probabilit√† che la variabile casuale \\(Z\\) assuma il valore \\(z\\)‚Äù. La funzione che associa a ogni valore $ u $ di \\(Z\\) la probabilit√† dell‚Äôevento \\(Z = u\\) √® nota come funzione di massa di probabilit√† della variabile casuale \\(Z\\).\nQuesta funzione, $ p_Z $, √® definita per ciascun valore possibile di $ Z $ come segue:\n\\[\n\\begin{array}{rclll}\np_Z(2) & = & 1/36, \\\\\np_Z(3) & = & 2/36, \\\\\np_Z(4) & = & 3/36, \\\\\np_Z(5) & = & 4/36, \\\\\np_Z(6) & = & 5/36, \\\\\np_Z(7) & = & 6/36, \\\\\np_Z(8) & = & 5/36, \\\\\np_Z(9) & = & 4/36, \\\\\np_Z(10) & = & 3/36, \\\\\np_Z(11) & = & 2/36, \\\\\np_Z(12) & = & 1/36. \\\\\n\\end{array}\n\\]\n\n\n\n27.6.5 Propriet√† della funzione di massa di probabilit√†\nOgni variabile casuale discreta possiede una funzione di massa di probabilit√† unica che rispetta le seguenti propriet√†:\n\nLa probabilit√† di ogni evento singolo √® compresa tra 0 e 1, ovvero \\(0 \\leq P(Z=z) \\leq 1\\).\nLa somma delle probabilit√† di tutti gli eventi possibili √® pari a 1, cio√® \\(\\sum_{z \\in Z} P(Z=z) = 1\\).\n\nSe consideriamo un sottoinsieme \\(A\\) della variabile casuale \\(Z\\), la probabilit√† associata a \\(A\\) dalla distribuzione \\(P_Z\\) √® data da:\n\\[\nP_Z(A) = \\sum_{z \\in A} P(Z = z).\n\\]\nPer esempio, per la variabile casuale \\(Z\\) relativa al lancio di due dadi, la probabilit√† che \\(Z\\) sia un numero dispari si calcola sommando le probabilit√† dei valori dispari:\n\\[\n\\begin{align}\nP(\\text{\"Z √® un numero dispari\"}) &= P_Z(3) + P_Z(5) + P_Z(7) + P_Z(9) + P_Z(11) \\\\\n&= \\frac{2}{36} + \\frac{4}{36} + \\frac{6}{36} + \\frac{4}{36} + \\frac{2}{36} \\\\\n&= \\frac{18}{36} \\\\\n&= \\frac{1}{2}.\n\\end{align}\n\\]\nQuesta formula ci permette di calcolare la probabilit√† di qualsiasi sottoinsieme di $ Z $ utilizzando la distribuzione di probabilit√† \\(P_Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#funzioni-di-distribuzione-cumulativa-cdf",
    "href": "chapters/probability/06_random_var.html#funzioni-di-distribuzione-cumulativa-cdf",
    "title": "27¬† Variabili casuali",
    "section": "27.7 Funzioni di Distribuzione Cumulativa (CDF)",
    "text": "27.7 Funzioni di Distribuzione Cumulativa (CDF)\nIn uno spazio ordinato, possiamo utilizzare sottoinsiemi intervallari per analizzare come la misura totale si distribuisce da valori inferiori a valori superiori. Definiamo il sottoinsieme intervallare costituito da tutti i punti minori o uguali a un dato punto \\(x\\):\n\\[\n\\mathsf{I}_{x} = \\{ x' \\in X \\mid x' \\le x \\}\n\\]\nLa misura assegnata a questi sottoinsiemi intervallari quantifica l‚Äôaccumulo della misura attraverso lo spazio. Formalizziamo questo concetto definendo la funzione di distribuzione cumulativa \\(F\\):\n\\[\nF(x) = P(X \\le x),\n\\]\ndove:\n\n\\(X\\) √® lo spazio ordinato.\n\\(P\\) rappresenta la misura di probabilit√† assegnata agli intervalli.\n\\(P(X \\le x)\\) indica la probabilit√† che la variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\n\n27.7.1 Propriet√† della Funzione di Distribuzione Cumulativa\nLa funzione \\(F\\), denominata funzione di distribuzione cumulativa (CDF), ha le seguenti propriet√†:\n\nMonotonia non decrescente: Se \\(x_1 &lt; x_2\\), allora \\(F(x_1) \\leq F(x_2)\\). Ci√≤ significa che la probabilit√† cumulativa non diminuisce mai mentre ci si sposta lungo la linea dei numeri reali.\nNormalizzazione: La CDF deve partire da 0 all‚Äôestremo inferiore dello spazio e arrivare a 1 all‚Äôestremo superiore: \\[\n\\lim_{x \\to -\\infty} F(x) = 0 \\quad \\text{e} \\quad \\lim_{x \\to \\infty} F(x) = 1.\n\\]\nContinuit√† a destra: La CDF √® continua da destra in ogni punto \\(x\\). Matematicamente, \\(F(x) = \\lim_{y \\to x^+} F(y)\\), il che significa che non ci sono salti improvvisi nella funzione.\n\n\n\n\n\n\n\nFigura¬†27.3: Una funzione di distribuzione cumulativa quantifica come la misura viene allocata agli intervalli crescenti in uno spazio ordinato. Al limite inferiore dello spazio, l‚Äôintervallo non contiene punti e la funzione di distribuzione cumulativa restituisce zero. Man mano che ci spostiamo verso valori pi√π grandi, l‚Äôintervallo si espande accumulando sempre pi√π misura. Infine, al limite superiore dello spazio, l‚Äôintervallo tende alla misura totale.\n\n\n\n\n\n27.7.2 Funzione di Distribuzione Cumulativa per Variabili Casuali Discrete\nNel contesto delle variabili casuali discrete, la funzione di distribuzione cumulativa viene spesso chiamata funzione di ripartizione. Per una variabile casuale discreta $ X $, la funzione di ripartizione, denotata \\(F(x)\\), √® definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(x_i).\n\\]\nIn questa formula, \\(F(x)\\) rappresenta la probabilit√† che la variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\). La funzione di ripartizione cumula le probabilit√† dei singoli valori fino a \\(x\\).\n\n\n27.7.3 Importanza della Funzione di Distribuzione Cumulativa\nLa CDF √® uno strumento fondamentale per comprendere come le probabilit√† si accumulano lungo uno spazio ordinato. Essa permette di visualizzare la distribuzione delle probabilit√† in modo cumulativo e fornisce informazioni essenziali sulla probabilit√† totale associata a un intervallo di valori.\n\nEsempio 27.5 Per il caso del lancio di due dadi e la variabile casuale \\(Z\\) definita come la loro somma, la funzione di ripartizione di \\(Z\\) pu√≤ essere illustrata come segue:\n\n\n\nz\np(z)\nF(z)\n\n\n\n\n2\n1/36\n1/36\n\n\n3\n2/36\n3/36\n\n\n4\n3/36\n6/36\n\n\n5\n4/36\n10/36\n\n\n6\n5/36\n15/36\n\n\n7\n6/36\n21/36\n\n\n8\n5/36\n26/36\n\n\n9\n4/36\n30/36\n\n\n10\n3/36\n33/36\n\n\n11\n2/36\n35/36\n\n\n12\n1/36\n36/36\n\n\n\nIn questa tabella, \\(F(z)\\) rappresenta la funzione di ripartizione cumulativa per ciascun valore \\(z\\). Questo aiuta a comprendere la distribuzione cumulativa delle probabilit√† per la variabile casuale \\(Z\\) nel contesto del lancio dei due dadi.\n\n\n27.7.3.1 Trovare la distribuzione di probabilit√† con una simulazione\nLa distribuzione di probabilit√† che abbiamo precedentemente calcolato per il lancio dei due dadi √® corretta, ma esiste un altro metodo per ottenere un risultato molto simile attraverso la simulazione. Questo metodo implica la generazione di un elevato numero di ripetizioni dell‚Äôesperimento casuale e l‚Äôanalisi delle frequenze relative dei risultati ottenuti. In altre parole, simulando l‚Äôesperimento numerose volte, possiamo approssimare la distribuzione di probabilit√† empirica, che si avvicina sempre di pi√π alla distribuzione teorica man mano che il numero di ripetizioni aumenta. Questo approccio √® comune in statistica ed √® particolarmente utile quando la distribuzione di probabilit√† teorica non √® facilmente calcolabile o √® troppo complessa per essere gestita in modo analitico.\n\nEsempio 27.6 Nel Capitolo 3 abbiamo visto come creare una funzione che ritorna il risultato del lancio di un dado:\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return rng.choice([1, 2, 3, 4, 5, 6])\n\nPossiamo ora definire una funzione che ritorna la somma dei punti prodotti dal lancio di due dadi. La funzione ha come argomento il numero di ripetizioni di questo esperimento casuale.\n\ndef roll_two_dice(n):\n    \"\"\"\n    returns a random int between 2 and 12\n    \"\"\"\n    rolls = []\n    for i in range(n):\n        two_dice = roll_die() + roll_die()\n        rolls.append(two_dice)\n    \n    return rolls\n\nEseguiamo 100,000 ripetizioni dell‚Äôesperimento casuale e memorizzo i risultati ottenuti.\n\nnrolls = 100000\nres = roll_two_dice(nrolls)\nprint(*res[1:20])\n\n12 10 7 10 7 9 8 7 5 9 8 7 4 9 7 2 10 10 5\n\n\nCreiamo un DataFrame che contiene la variabile y corrispondente ai risultati delle 10,000 ripetizioni dell‚Äôesperimento casuale.\n\ndf = pd.DataFrame()\ndf[\"y\"] = res \n\nUtilizziamo dunque il metodo value_counts(), che pu√≤ essere applicato a un DataFrame, come abbiamo visto nel Capitolo 17, per trovare le frequenze assolute di ciascuno dei possibili risultati dell‚Äôesperimento casuale (cio√®, 2, 3, ‚Ä¶, 12). Dividendo per il numero totale delle ripetizioni, otterremo una stima empirica della probabilit√†. Si noti che i risultati saranno simili a quelli teorici ottenuti in precedenza.\n\nabs_freqs = df[\"y\"].value_counts().sort_index()\npx = abs_freqs / nrolls\nlist(zip(list(range(2, 13)), px))\n\n[(2, 0.02775),\n (3, 0.05625),\n (4, 0.08331),\n (5, 0.11109),\n (6, 0.13915),\n (7, 0.16824),\n (8, 0.13751),\n (9, 0.11167),\n (10, 0.08238),\n (11, 0.05567),\n (12, 0.02698)]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "27¬† Variabili casuali",
    "section": "27.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "27.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html",
    "href": "chapters/probability/07_expval_var.html",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "Introduzione\nUna variabile casuale rappresenta un elemento centrale nella teoria della probabilit√† e nelle sue applicazioni statistiche. Dal punto di vista formale, una variabile casuale √® definita come una funzione che associa elementi di uno spazio campionario \\(S\\) a valori in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di quantificare numericamente gli esiti di un fenomeno aleatorio, attribuendo un valore specifico ad ogni possibile risultato.\nLe variabili casuali possono essere classificate in due categorie principali: le variabili casuali discrete e quelle continue. Le variabili casuali discrete sono caratterizzate dal fatto di assumere valori in un insieme finito o al pi√π numerabile, mentre le variabili casuali continue si distinguono per la loro capacit√† di assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo continuo.\nCon il concetto di variabile casuale ben definito, emergono questioni relative alla descrizione dell‚Äôinsieme completo dei possibili esiti e delle probabilit√† associate a ciascun esito. Queste considerazioni portano alla nozione di ‚Äúdistribuzione‚Äù di una variabile casuale. Per le variabili casuali discrete, la distribuzione √® una funzione che elenca tutti i possibili valori che la variabile pu√≤ assumere, insieme alle probabilit√† corrispondenti a ciascun valore. In questo modo, la distribuzione di una variabile casuale fornisce un quadro completo delle sue caratteristiche probabilistiche, consentendo analisi e inferenze statistiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#valore-atteso",
    "href": "chapters/probability/07_expval_var.html#valore-atteso",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.1 Valore atteso",
    "text": "28.1 Valore atteso\nSpesso √® utile sintetizzare la distribuzione di una variabile casuale tramite indicatori caratteristici. Questi indicatori permettono di cogliere le caratteristiche principali della distribuzione, come la posizione (cio√® il baricentro) e la variabilit√† (cio√® la dispersione attorno ad un centro). In questo modo, si pu√≤ avere una descrizione sintetica della distribuzione di probabilit√† della variabile casuale. In questo capitolo introdurremo i concetti di valore atteso e di varianza di una variabile casule.\nQuando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual √® il suo ‚Äúvalore tipico‚Äù. La nozione di ‚Äúvalore tipico‚Äù, tuttavia, √® ambigua. Infatti, essa pu√≤ essere definita in almeno tre modi diversi:\n\nla media (somma dei valori divisa per il numero dei valori),\nla mediana (il valore centrale della distribuzione, quando la variabile √® ordinata in senso crescente o decrescente),\nla moda (il valore che ricorre pi√π spesso).\n\nPer esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) √® \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana √® \\(3\\) e la moda √® \\(1\\). Tuttavia, la teoria delle probabilit√† si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per ‚Äúvalore tipico‚Äù quando facciamo riferimento alle variabili casuali. Giungiamo cos√¨ alla seguente definizione.\n\nDefinizione 28.1 Sia \\(Y\\) √® una variabile casuale discreta che assume i valori \\(y_1, \\dots, y_n\\) con distribuzione \\(P(Y = y_i) = p(y_i)\\). Per definizione il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), √®\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^n y_i \\cdot p(y_i).\n\\tag{28.1}\\]\n\nA parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale √® definito come la somma di tutti i valori che la variabile casuale pu√≤ prendere, ciascuno pesato dalla probabilit√† con cui il valore √® preso.\n\nEsempio 28.1 Calcoliamo il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0).\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5.\n\\]\n\n\nEsempio 28.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente alla somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nAbbiamo visto nel Capitolo 22 che \\(X\\) pu√≤ assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con distribuzione di massa di probabilit√† pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando l‚ÄôEquazione¬†28.1 otteniamo:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n\\]\nSvolgiamo ora l‚Äôesercizio in Python.\nDefinisco i valori della variabile casuale \\(X\\) e li trasformiamo in un array NumPy:\n\nx = np.array(list(range(2, 13)))\nx\n\narray([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n\n\nPer trovare la distribuzione di massa della variabile \\(X\\) ripeto qui il codice che abbiamo usato nel Capitolo 22.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\n\npx = []\n\nfor i in range(2, 13):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n\npx = np.array(px)\npx\n\narray([0.02777778, 0.05555556, 0.08333333, 0.11111111, 0.13888889,\n       0.16666667, 0.13888889, 0.11111111, 0.08333333, 0.05555556,\n       0.02777778])\n\n\nCalcolo ora il valore atteso della \\(X\\) usando l‚Äôeq. {eq}eq-expval-discr:\n\nex = np.sum(x * px)\nex.round(3)\n\n7.0\n\n\nIn alternativa, posso usare le funzioni del modulo rv_discrete della libreria stats:\n\nx = np.arange(2, 13)\npx = np.array([1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36])\nX = stats.rv_discrete(values=(x, px))\n\nUna volta definito l‚Äôoggetto \\(X\\) con rv_discrete(), il valore atteso viene ritornato dalla funzione expect():\n\nx_ev = X.expect()\nround(x_ev, 3)\n\n7.0\n\n\n\n\n28.1.1 Interpretazione\nIl valore atteso corrisponde alla media aritmetica di un grande numero di realizzazioni indipendenti della variabile casuale.\nPer fare un esempio, ritorniamo all‚Äôesempio precedente relativo al lancio di due dadi bilanciati a sei facce nel quale \\(X\\) rappresenta la ‚Äúsomma dei due dadi‚Äù. Per interpretare il valore atteso, simuliamo un grande numero di realizzazioni indipendenti della \\(X\\) mediante la funzione random.choice() della libreria NumPy. Tale funzione prende come argomenti i valori della variabile casuale, il numero di ripetizioni indipedenti (qui 1,000,000) e la distribuzione di massa di probabilit√†:\n\nx_samples = np.random.choice(x, size=1000000, p=px)\n\nL‚Äôistruzione np.random.choice(x, size=1000000, p=px) utilizza la libreria NumPy per generare un array di 1.000.000 di elementi (parametro size), scelti casualmente dall‚Äôarray x con le probabilit√† specificate nell‚Äôarray px. In particolare, x √® l‚Äôarray di cui si vuole effettuare una scelta casuale e px √® un array che contiene le probabilit√† associate ad ogni elemento di x.\nCome ci aspettavamo, per un grande numero di realizzazioni indipendenti della \\(X\\), la media aritmetica approssima il valore atteso:\n\nnp.mean(x_samples).round(3)\n\n7.002\n\n\n\n\n28.1.2 Propriet√† del valore atteso\nLa propriet√† pi√π importante del valore atteso √® la linearit√†: il valore atteso di una somma di variabili casuali √® uguale alla somma dei lori rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{28.2}\\]\nL‚ÄôEquazione¬†28.2 sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma √® anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{28.3}\\]\nL‚ÄôEquazione¬†28.3 ci dice che possiamo estrarre una costante dall‚Äôoperatore di valore atteso. Tale propriet√† si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che\n\\[\n\\mathbb{E}(X Y) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{28.4}\\]\nLa media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione di media \\(\\mu\\) ha valore atteso\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\mathbb{E}(X_1)+ \\dots \\mathbb{E}(X_n) = \\frac{1}{n} n \\mathbb{E}(X) = \\mu.\n\\]\n\nEsempio 28.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell‚Äôesperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado √® indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avr√† la stessa probabilit√† di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) √® dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l‚ÄôEquazione¬†28.2:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\nSvolgiamo ora l‚Äôesercizio in Python.\n\ncoin = range(0, 2)\ndie = range(1, 7)\n\nsample = [(c, d) for c in coin for d in die]\nlist(sample)\n\n[(0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (0, 5),\n (0, 6),\n (1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6)]\n\n\n\npx = []\nfor i in range(1, 8):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n    print(f\"P(X + Y = {i}) = {len(event)} / {len(sample)}\")\n\nP(X + Y = 1) = 1 / 12\nP(X + Y = 2) = 2 / 12\nP(X + Y = 3) = 2 / 12\nP(X + Y = 4) = 2 / 12\nP(X + Y = 5) = 2 / 12\nP(X + Y = 6) = 2 / 12\nP(X + Y = 7) = 1 / 12\n\n\n\nx = np.arange(1, 8)\nsum(x * px)\n\n4.0\n\n\n\n\nEsempio 28.4 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilit√† congiunta \\(P(X, Y)\\) √® fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l‚ÄôEquazione¬†28.4. Infatti, il valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerci√≤\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\nSvolgiamo l‚Äôesercizio in Python.\n\nr = range(0, 2)\nsample = [(i, j, w) for i in r for j in r for w in r]\n\nfor i in range(0, 4):\n    event = [toss for toss in sample if sum(toss) * toss[0] == i]\n    print(f\"P(Z = {i}) : {len(event)} / {len(sample)}\")\n\nP(Z = 0) : 4 / 8\nP(Z = 1) : 1 / 8\nP(Z = 2) : 2 / 8\nP(Z = 3) : 1 / 8\n\n\n\nz = np.array([0, 1, 2, 3])\npz = np.array([4/8, 1/8, 2/8, 1/8])\nsum(z * pz)\n\n1.0\n\n\n\n\n\n28.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa:\n\\[\n\\mathbb{E}(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname{d}\\!y.\n\\tag{28.5}\\]\nAnche in questo caso il valore atteso √® una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) √® ponderato per il corrispondente valore della densit√† \\(p(y)\\). Possiamo leggere l‚Äôintegrale pensando che \\(y\\) rappresenti l‚Äôampiezza delle barre infinitamente strette di un istogramma, con la densit√† \\(p(y)\\) che corrisponde all‚Äôaltezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma.1\n\n28.1.3.1 Moda\nUn‚Äôaltra misura di tendenza centrale delle variabili casuali continue √® la moda. La moda di \\(Y\\) individua il valore \\(y\\) pi√π plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densit√† \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{28.6}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#varianza",
    "href": "chapters/probability/07_expval_var.html#varianza",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.2 Varianza",
    "text": "28.2 Varianza\nLa seconda pi√π importante propriet√† di una variabile casuale, dopo che conosciamo il suo valore atteso, √® la varianza.\n\nDefinizione 28.2 Se \\(Y\\) √® una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), √®\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big].\n\\tag{28.7}\\]\n\nA parole: la varianza √® la deviazione media quadratica della variabile dalla sua media.2 Se denotiamo \\(\\mathbb{E}(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\).\n\nEsempio 28.5 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilit√†:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\nSvolgiamo l‚Äôesercizio in Python.\n\nx = np.arange(2, 13)\npx = np.array(\n    [\n        1 / 36,\n        2 / 36,\n        3 / 36,\n        4 / 36,\n        5 / 36,\n        6 / 36,\n        5 / 36,\n        4 / 36,\n        3 / 36,\n        2 / 36,\n        1 / 36,\n    ]\n)\nX = stats.rv_discrete(values=(x, px))\nex = X.expect()\nex\n\n6.999999999999998\n\n\nApplichiamo l‚ÄôEquazione¬†28.7:\n\n((x - ex) ** 2 * px).sum()\n\n5.833333333333333\n\n\nUsiamo la funzione var() di rv_discrete:\n\nX.var()\n\n5.833333333333364\n\n\n\n\n28.2.1 Formula alternativa per la varianza\nC‚Äô√® un modo pi√π semplice per calcolare la varianza:\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big] &= \\mathbb{E}\\big(Y^2 - 2Y\\mathbb{E}(Y) + \\mathbb{E}(Y)^2\\big)\\notag\\\\\n&= \\mathbb{E}(Y^2) - 2\\mathbb{E}(Y)\\mathbb{E}(Y) + \\mathbb{E}(Y)^2,\n\\end{align}\n\\]\ndato che \\(\\mathbb{E}(Y)\\) √® una costante. Pertanto\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2.\n\\tag{28.8}\\]\nA parole: la varianza √® la media dei quadrati meno il quadrato della media della variabile.\n\nEsempio 28.6 Consideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilit√† di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) √®\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\nSvolgiamo l‚Äôesercizio in Python:\n\ny = np.array([0, 1])\npy = np.array([0.2, 0.8])\n\nsum(y**2 * py) - (sum(y * py)) ** 2\n\n0.15999999999999992\n\n\n\n\n\n28.2.2 Propriet√†\nSegno della varianza. La varianza di una variabile aleatoria non √® mai negativa, ed √® zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza √® invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\nx = np.array([2, 1, 4, 7])\ny = 100 + 2 * x\n\nnp.var(y) == 2**2 * np.var(x)\n\nTrue\n\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio √® fornita sotto.\n\nx = np.array([2, 1, 4, 7])\ny = np.array([1, 3, 5, 11])\n\nnp.var(x + y, ddof=0)\n\n35.25\n\n\n\nnp.var(x, ddof=0) + np.var(y, ddof=0) + 2 * np.cov(x, y, ddof=0)[0, 1]\n\n35.25\n\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente √® illustrato dalla seguente simulazione.\n\n# Set up the population distribution\npopulation = np.random.normal(loc=50, scale=10, size=10000)\n\n# Set up the sample size and number of samples\nsample_size = 30\nnum_samples = 100000\n\n# Create an array to hold the sample means\nsample_means = np.zeros(num_samples)\n\n# Generate the samples and compute their means\nfor i in range(num_samples):\n    sample = np.random.choice(population, size=sample_size)\n    sample_means[i] = np.mean(sample)\n\n# Calculate the variance of the sample means\nsampling_dist_mean_var = np.var(sample_means)\nsampling_dist_mean_var\n\n3.4103710835201433\n\n\nIl valore teorico della varianza della distribuzione campionaria della media √®\n\n10**2 / 30\n\n3.3333333333333335\n\n\n\n\n28.2.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\), la varianza diventa:\n\\[\n\\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\mathbb{E}(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y.\n\\tag{28.9}\\]\nCome nel caso discreto, la varianza di una v.c. continua \\(Y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(y\\) dalla loro media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#deviazione-standard",
    "href": "chapters/probability/07_expval_var.html#deviazione-standard",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.3 Deviazione standard",
    "text": "28.3 Deviazione standard\nQuando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell‚Äôunit√† di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente √® denotato dalla lettera greca \\(\\sigma\\).\n\nDefinizione 28.3 Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:\n\\[\n\\sigma_Y = \\sqrt{\\mathbb{V}(Y)}.\n\\tag{28.10}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media.\nPer i dadi equilibrati dell‚Äôesemio precedebte, la deviazione standard della variabile casuale \\(S\\) √® uguale a \\(\\sqrt{5.833} = 2.415\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#standardizzazione",
    "href": "chapters/probability/07_expval_var.html#standardizzazione",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.4 Standardizzazione",
    "text": "28.4 Standardizzazione\n\nDefinizione 28.4 Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l‚Äôespressione\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}.\n\\tag{28.11}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/07_expval_var.html#momenti-di-variabili-casuali",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.5 Momenti di variabili casuali",
    "text": "28.5 Momenti di variabili casuali\n\nDefinizione 28.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densit√† \\(p(x)\\), la quantit√†\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{28.12}\\]\nSe \\(X\\) √® una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i).\n\\tag{28.13}\\]\n\nI momenti sono importanti parametri indicatori di certe propriet√† di \\(X\\). I pi√π noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x ‚àí \\mathbb{E}(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#alcuni-esempi-in-python",
    "href": "chapters/probability/07_expval_var.html#alcuni-esempi-in-python",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.6 Alcuni esempi in Python",
    "text": "28.6 Alcuni esempi in Python\nUtilizzando il modulo stats di scipy, √® possibile semplificare i calcoli del valore atteso e della varianza di variabili casuali discrete.\nConsideriamo ad esempio una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilit√†: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx = np.arange(7)\nprint(x)\n\n[0 1 2 3 4 5 6]\n\n\nIl vettore px conterr√† le probabilit√† associate ai valori x:\n\npx = [0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\nprint(px)\n\n[0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\n\n\nControlliamo che la somma sia 1:\n\nnp.sum(px)\n\n1.0\n\n\nUsiamo ora la funzione rv_discrete() che √® una funzione della libreria stats di Python. Tale funzione viene utilizzata per creare una distribuzione discreta personalizzata. La funzione richiede che vengano forniti dei valori discreti (ossia interi) e le rispettive probabilit√† di occorrenza.\nUna volta definita la distribuzione discreta, rv_discrete() permette di eseguire operazioni come la generazione di numeri casuali dalla distribuzione, il calcolo della funzione di probabilit√† cumulativa (CDF) e della funzione di densit√† di probabilit√† (PDF), e la valutazione della media, della varianza e di altre statistiche della distribuzione.\nLa sintassi di base della funzione rv_discrete() √® la seguente:\nrv = stats.rv_discrete(name='rv', values=(xk, pk))\ndove name √® il nome della distribuzione discreta, xk sono i valori discreti e pk sono le rispettive probabilit√† di occorrenza. Ad esempio, creiamo la variabile casuale X:\n\nX = stats.rv_discrete(name='rv', values=(x, px))\n\n\n# Distribuzione di massa di probabilit√† di X.\nprint(X.pmf(x))\n\n[0.1 0.2 0.3 0.1 0.1 0.  0.2]\n\n\n\n# Distribuzione comulativa di probabilit√† di X.\nprint(X.cdf(x))\n\n[0.1 0.3 0.6 0.7 0.8 0.8 1. ]\n\n\nGeneriamo un grafico che rappresenta la distribuzione di massa con Matplotlib.\n\ncolor_fill = \"#B17F7D\"\ncolor_edge = \"#832F2B\"\nplt.plot(x, X.pmf(x), \"o\", ms=6, color=color_fill, markeredgecolor=color_edge)\nplt.vlines(x, 0, X.pmf(x), lw=2, colors=color_edge)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso, ovvero utilizzando i vettori x e px.\n\nx_ev = (x * px).sum()\nx_ev\n\n2.7\n\n\nLo stesso risultato si ottience applicando il metodo .expect() all‚Äôoggetto X.\n\nx_ev = X.expect()\nx_ev\n\n2.7\n\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px.\n\nx_var = ((x - x_ev)**2 * X.pmf(x)).sum()\nx_var\n\n3.8100000000000005\n\n\nOtteniamo lo stesso risultato applicando il metodo .var() all‚Äôoggetto X.\n\nX.var()\n\n3.8099999999999987\n\n\nCalcoliamo la deviazione standard di \\(X\\) prendento la radice quadrata della varianza.\n\nnp.sqrt(x_var)\n\n1.9519221295943137\n\n\nOppure, in maniera equivalente, applicando il metodo .std() all‚Äôoggetto X.\n\nX.std()\n\n1.9519221295943132",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/07_expval_var.html#commenti-e-considerazioni-finali",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.7 Commenti e considerazioni finali",
    "text": "28.7 Commenti e considerazioni finali\nL‚Äôinferenza bayesiana mira a descrivere la distribuzione a posteriori di variabili casuali che rappresentano i parametri di un modello statistico. Nel capitolo precedente, abbiamo esaminato le caratteristiche principali delle variabili casuali, concentrandoci sul caso discreto. In questo capitolo, abbiamo approfondito le propriet√† di una singola variabile casuale. Nel prossimo capitolo, invece, esploreremo il problema di descrivere il verificarsi congiunto di due o pi√π variabili casuali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "28.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "28.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nscipy     : 1.14.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#footnotes",
    "href": "chapters/probability/07_expval_var.html#footnotes",
    "title": "28¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "Per il significato della notazione di integrale, si veda l‚ÄôAppendice K.‚Ü©Ô∏é\nData una variabile casuale \\(Y\\) con valore atteso \\(\\mathbb{E}(Y)\\), le ‚Äúdistanze‚Äù tra i valori di \\(Y\\) e il valore atteso \\(\\mathbb{E}(Y)\\) definiscono la variabile casuale \\(Y - \\mathbb{E}(Y)\\) chiamata scarto, oppure deviazione oppure variabile casuale centrata. La variabile \\(Y - \\mathbb{E}(Y)\\) equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell‚Äôorigine degli assi. Si pu√≤ dimostrare facilmente che il valore atteso della variabile scarto \\(Y - \\mathbb{E}(Y)\\) vale zero, dunque la media di tale variabile non pu√≤ essere usata per quantificare la ‚Äúdispersione‚Äù dei valori di \\(Y\\) relativamente al suo valore medio. Occorre rendere sempre positivi i valori di \\(Y - \\mathbb{E}(Y)\\) e tale risultato viene ottenuto considerando la variabile casuale \\(\\left(Y - \\mathbb{E}(Y)\\right)^2\\).‚Ü©Ô∏é",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html",
    "href": "chapters/probability/08_sampling_distr.html",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† verranno utilizzate per costruire gli strumenti fondamentali dell‚Äôinferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.1 Popolazione e campioni",
    "text": "29.1 Popolazione e campioni\nNell‚Äôanalisi dei dati, l‚Äôobiettivo spesso √® comprendere una quantit√† specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantit√† sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta √® chiamata stima, e la formula che utilizziamo per ottenerla √® conosciuta come stimatore. In termini formali, uno stimatore √® una funzione dei dati osservati, utilizzata per fornire un‚Äôapprossimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo √® inferire determinate propriet√† della popolazione intera dalla quale il campione √® stato tratto. Il parametro √® l‚Äôindicatore numerico di queste propriet√†, ma poich√© spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore √® la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\n√à importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "href": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.2 La relazione tra stime e parametri",
    "text": "29.2 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo √® capire e caratterizzare l‚Äôincertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l‚Äôapproccio frequentista, facendo uso di un importante strumento statistico chiamato distribuzione campionaria.\n\n29.2.1 Distribuzione campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, √® fondamentale notare che le propriet√† e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci d√† una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all‚Äôintera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornir√† una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell‚Äôincertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL‚Äôistogramma seguente descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l‚Äôistogramma.\n\nprint(\"Intervalli utilizzati per l'istogramma:\", intervalli)\nprint(\"Frequenze relative utilizzate per l'istogramma:\", conteggi)\n\nIntervalli utilizzati per l'istogramma: [2.  2.7 3.4 4.1 4.8 5.5]\nFrequenze relative utilizzate per l'istogramma: [0.35714286 0.         0.         0.35714286 0.71428571]\n\n\nLe frequenze assolute si ottengono usando l‚Äôargomento density=False.\n\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=False,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\nprint(\"Frequenze assolute utilizzate per l'istogramma:\", conteggi)\n\n\n\n\n\n\n\n\nFrequenze assolute utilizzate per l'istogramma: [1. 0. 0. 1. 2.]\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nSupponiamo ora di voler considerare l‚Äôestrazione di tutti i possibili campioni di dimensione \\(n\\) = 2 da una popolazione rappresentata dall‚Äôarray x. Per fare ci√≤, possiamo fare uso di uno strumento di programmazione, come la funzione product del modulo itertools in Python.\nSpecificamente, possiamo utilizzare product con l‚Äôargomento repeat impostato a 2, che indica che vogliamo formare tutte le possibili coppie di valori. In altre parole, stiamo cercando tutte le combinazioni in cui ogni valore nell‚Äôarray x pu√≤ essere abbinato a se stesso o a un altro valore nell‚Äôarray.\nDopo aver utilizzato la funzione product, otteniamo una lista di tuple, che rappresenta tutte le possibili coppie di valori. Possiamo convertire questa lista in un array NumPy pi√π maneggevole utilizzando la funzione np.array. Stampando il risultato, otteniamo un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie che possono essere formate dall‚Äôarray x.\nQuesta rappresentazione di tutte le possibili coppie √® coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento pu√≤ essere scelto pi√π di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sar√† $4^2 = 16 $. Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di \\(4 \\times 4 = 16\\) possibili coppie.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nConvertiamo l‚Äôoutput di itertools.product in un array NumPy per sfruttare le funzionalit√† di questa libreria. L‚Äôarray risultante, samples, √® un array 2D, dove ogni riga rappresenta una coppia di valori.\n\nsamples.shape\n\n(16, 2)\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), possiamo utilizzare la funzione mean del modulo NumPy e applicarla lungo l‚Äôasse delle colonne dell‚Äôarray di coppie di valori. In questo modo otterremo un array unidimensionale contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nLa funzione np.mean(samples, axis=1) calcola la media lungo l‚Äôasse specificato, che in questo caso √® l‚Äôasse 1. In NumPy, l‚Äôasse 0 rappresenta le righe (verticale) e l‚Äôasse 1 rappresenta le colonne (orizzontale).\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\n_ = plt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x.\n\n\n29.2.2 Valore atteso della media campionaria\nSupponiamo che $ X_1, X_2, , X_n $ siano variabili aleatorie iid con valore atteso $ $ e varianza $ ^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nEcco la dimostrazione:\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n\\]\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid √® uguale al valore atteso di ciascuna variabile singola, che in questo caso √® $ $.\nVerifichiamo che ci√≤ sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\n\n\n29.2.3 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid √® uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso √® \\(\\sigma^2/n\\).\nPer l‚Äôesempio in discussione, il valore della varianza delle medie dei campioni √® dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione √® diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall‚Äôanalisi delle medie campionarie:\n\nMedia delle medie campionarie e media della popolazione: La media della distribuzione delle medie campionarie √® identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ $ √®:\n\n\\[\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\nVarianza delle medie campionarie e varianza della popolazione: La varianza della distribuzione delle medie campionarie √® inferiore alla varianza della popolazione e, precisamente, √® pari alla varianza della popolazione divisa per la dimensione del campione:\n\n\\[\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\nInoltre, √® importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\nSe la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sar√† anch‚Äôessa normale.\nSe la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale",
    "text": "29.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale\nNella statistica inferenziale, l‚Äôerrore standard √® una misura frequentemente utilizzata per rappresentare l‚Äôincertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L‚Äôerrore standard quantifica quanto possa variare la stima di una statistica da un campione all‚Äôaltro; un errore standard minore indica una stima pi√π precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di ‚Äúmedia pi√π o meno uno (o due) errori standard.‚Äù Questa espressione fornisce una gamma di valori entro cui √® plausibile che ricada il valore vero del parametro della popolazione.\nL‚Äôuso dell‚Äôerrore standard nei grafici non √® soltanto una convenzione; esso √® uno strumento per quantificare e visualizzare l‚Äôincertezza inferenziale. Contribuisce alla comprensione dell‚Äôaffidabilit√† delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, √® importante notare che questo utilizzo dell‚Äôerrore standard pu√≤ essere problematico (Ward e Mann 2022).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.4 Legge dei Grandi Numeri",
    "text": "29.4 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) √® un principio fondamentale della teoria delle probabilit√† che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione ‚Äúforte‚Äù e quella ‚Äúdebole‚Äù, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n29.4.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilit√† 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell‚Äôinsieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilit√† √® zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) ‚Äúquasi certamente‚Äù.\n\n\n29.4.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantit√† maggiore di \\(\\epsilon\\) tende a zero all‚Äôaumentare di \\(n\\). Questo fenomeno √® definito come convergenza in probabilit√† verso la media teorica \\(\\mu\\).\n\n\n29.4.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, pi√π in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l‚Äôutilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l‚Äôaffidabilit√† delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 29.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di ‚ÄúTesta‚Äù in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di ‚ÄúTesta‚Äù dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilit√† 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) converger√† a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di ‚ÄúTesta‚Äù (HHHHHH‚Ä¶) o sequenze irregolari come HHTHHTHHTHHT‚Ä¶, ma queste hanno una probabilit√† collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che \\(\\bar{X}_n\\) sia distante pi√π di \\(\\epsilon\\) da \\(1/2\\) pu√≤ essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realt√† non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All‚Äôinizio, notiamo una certa variazione nella proporzione cumulativa di ‚ÄúTesta‚Äù. Tuttavia, con l‚Äôaumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Number of sequences\nnum_sequences = 6\n# Number of tosses\nnum_tosses = 300\n# Initialize a figure\nplt.figure()\n\n# Loop through each sequence\nfor i in range(num_sequences):\n    \n    # Generate a sequence of fair coin tosses (Heads=1, Tails=0)\n    coin_tosses = np.random.choice([0, 1], num_tosses)\n    \n    # Calculate the running proportion of Heads\n    running_proportion = np.cumsum(coin_tosses) / np.arange(1, num_tosses + 1)\n    \n    # Plot the running proportion as a function of the number of tosses\n    plt.plot(np.arange(1, num_tosses + 1), running_proportion, label=f'Sequence {i+1}')\n\n# Plotting the true mean (1/2)\nplt.axhline(y=0.5, color='r', linestyle='--', label='True Mean (1/2)')\n\n# Adding labels and title\nplt.xlabel('Number of Tosses')\nplt.ylabel('Running Proportion of Heads')\nplt.title('Running Proportion of Heads in Six Sequences of Fair Coin Tosses')\nplt.legend()\nplt.legend(fontsize='small')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.5 Teorema del Limite Centrale",
    "text": "29.5 Teorema del Limite Centrale\nIl teorema del limite centrale √® un risultato fondamentale in statistica che √® stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare cos√¨ frequentemente nei fenomeni naturali. Ecco la formulazione essenziale:\n\n29.5.1 Enunciato\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all‚Äôinfinito, la distribuzione di \\(Z\\) converger√† a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n\n29.5.2 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma pu√≤ essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacit√† di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l‚Äôaltezza degli esseri umani adulti pu√≤ essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalit√† rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 29.2 Per visualizzare il TLC in azione, si pu√≤ condurre una simulazione. Immaginiamo una popolazione iniziale con una distribuzione asimmetrica, come una Beta(2, 1). Estraiamo 50.000 campioni di dimensione \\(n\\) da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornir√† un‚Äôillustrazione concreta dell‚Äôefficacia del TLC nell‚Äôapprossimare distribuzioni reali.\n\n# parameters of the beta distribution\na=2\nb=1\n\ndef plot_samples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n            v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together\n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(\n        sample_means,\n        color=color_fill,\n        edgecolor=color_edge,\n    )\n    ax2 = ax.twinx()\n    sns.lineplot(x=x, y=y, ax=ax2, color=color_edge)\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l‚Äôampiezza campionaria √® 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non √® certamente Normale, inizia ad avvicinarsi alla gaussianit√†.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c‚Äô√® ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l‚Äôapprossimazione migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, √® possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ci√≤ avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed √® espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.6 Distribuzioni campionarie di altre statistiche",
    "text": "29.6 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax, color=color_fill)\nax2 = ax.twinx()\nsns.lineplot(x=x, y=y, ax=ax2, color=color_edge);\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione √® uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto √® stato interessante: in media, l‚Äôutilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard\n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find\n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n177.69769879129643\n\n\n\n\n\n\n\n\n\nAbbiamo gi√† visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n226.51417694562372\n\n\n\n\n\n\n\n\n\nLa differenza tra la stima di un parametro e il valore vero del parametro √® chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici √® uguale al valore del parametro che si vuole stimare. In altre parole, l‚Äôerrore medio di stima √® zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) √® uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#considerazioni-conclusive",
    "href": "chapters/probability/08_sampling_distr.html#considerazioni-conclusive",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.7 Considerazioni conclusive",
    "text": "29.7 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#watermark",
    "href": "chapters/probability/08_sampling_distr.html#watermark",
    "title": "29¬† Stime, stimatori e parametri",
    "section": "29.8 Watermark",
    "text": "29.8 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nWard, Andrew, e Traci Mann. 2022. ¬´Control yourself: Broad implications of narrowed attention¬ª. Perspectives on Psychological Science 17 (6): 1692‚Äì1703.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html",
    "href": "chapters/probability/09_joint_prob.html",
    "title": "30¬† Probabilit√† congiunta",
    "section": "",
    "text": "Introduzione\nLa probabilit√† congiunta √® la probabilit√† che due o pi√π eventi si verifichino contemporaneamente. In questo capitolo verr√† esaminato il caso discreto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#sec-fun-join-prob",
    "href": "chapters/probability/09_joint_prob.html#sec-fun-join-prob",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.1 Funzione di Probabilit√† Congiunta",
    "text": "30.1 Funzione di Probabilit√† Congiunta\nDopo aver esplorato la distribuzione di probabilit√† di singole variabili casuali, che associa un unico numero reale ad ogni possibile risultato di un esperimento, si procede naturalmente all‚Äôestensione di questo concetto al caso di due o pi√π variabili casuali.\n\n30.1.1 Esempio: Lancio di Tre Monete Equilibrate\nConsideriamo l‚Äôesperimento del lancio di tre monete equilibrate. Lo spazio campione \\(\\Omega\\) √® dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove T rappresenta ‚Äútesta‚Äù e C rappresenta ‚Äúcroce‚Äù. Assumendo che i lanci siano indipendenti, ogni risultato nell‚Äôinsieme \\(\\Omega\\) ha la stessa probabilit√† di occorrenza, ovvero \\(1/8\\).\nDefiniamo le seguenti variabili casuali sullo spazio campione \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il ‚Äúnumero di teste ottenute nei tre lanci‚Äù.\n\\(Y \\in \\{0, 1\\}\\) indica se ‚Äúla testa √® stata ottenuta nel primo lancio‚Äù (1) o no (0).\n\nLa tabella seguente illustra lo spazio campione e le variabili casuali \\(X\\) e \\(Y\\), insieme alle rispettive probabilit√†:\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nPer ogni coppia \\((x, y)\\) definita su \\(\\Omega\\), associamo una probabilit√† come segue:\n\n\\(P(X=0, Y=0) = P(\\text{CCC}) = 1/8\\),\n\ne similmente per le altre coppie.\nLe probabilit√† calcolate per tutte le possibili coppie \\((X, Y)\\) sono:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= 1/8, \\\\\nP(X = 2, Y = 0) &= 1/8, \\\\\nP(X = 2, Y = 1) &= 1/4, \\\\\nP(X = 3, Y = 1) &= 1/8.\n\\end{aligned}\n\\]\nQueste probabilit√† compongono la distribuzione di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\).\n\n\n30.1.2 Definizione: Funzione di Probabilit√† Congiunta\nLa funzione di probabilit√† congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilit√† \\(P(X = x, Y = y)\\).\n\n\n30.1.3 Propriet√†\nUna distribuzione di probabilit√† congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilit√† su tutte le coppie deve essere 1.\n\n\n\n30.1.4 Calcolo della Probabilit√† di Eventi Specifici\nData la distribuzione di probabilit√† congiunta, possiamo determinare la probabilit√† di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilit√† che \\(X + Y \\leq 1\\), sommiamo le probabilit√† di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).\n\n\n30.1.5 Funzioni di Probabilit√† Marginali\nLa distribuzione marginale di un insieme di variabili casuali descrive la distribuzione di probabilit√† di queste variabili considerate singolarmente, indipendentemente dalle altre. La ‚Äúmarginalizzazione‚Äù √® un processo che permette di ottenere la distribuzione di probabilit√† di una o pi√π variabili casuali marginali sommando o integrando la distribuzione congiunta su tutte le possibili realizzazioni delle altre variabili casuali, ovvero quelle non considerate (e quindi ‚Äúmarginalizzate‚Äù).\nPer esempio, data la distribuzione congiunta di due variabili casuali discrete \\(X\\) e \\(Y\\), la distribuzione marginale di \\(X\\), indicata come \\(P(X=x)\\), si calcola come:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilit√† congiunta di \\(X\\) e \\(Y\\). Le distribuzioni marginali e congiunte di variabili casuali discrete sono frequentemente rappresentate in tabelle di contingenza. Si garantisce che le distribuzioni marginali siano normalizzate:\n\\[\n\\sum_x P(X=x) = 1, \\quad \\sum_y P(Y=y) = 1.\n\\]\nPer variabili casuali continue, la somma √® sostituita dall‚Äôintegrazione.\n\nEsempio 30.1 Prendiamo come riferimento l‚Äôesperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilit√† marginali di \\(X\\) e \\(Y\\), sommiamo le probabilit√† congiunte su una dimensione. La probabilit√† marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilit√† lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilit√† marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilit√† lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilit√† congiunta \\(P(X, Y)\\) e le probabilit√† marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n30.1.6 Marginalizzazione per Variabili Casuali Continue\nNell‚Äôambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo √®:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l‚Äôestensione dell‚Äôapproccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.2 Indipendenza tra Variabili Casuali",
    "text": "30.2 Indipendenza tra Variabili Casuali\nL‚Äôindipendenza tra variabili casuali √® un concetto fondamentale in statistica e probabilit√†, parallelo all‚Äôidea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l‚Äôinformazione su una non altera in alcun modo la distribuzione di probabilit√† dell‚Äôaltra. Questa sezione offre una formalizzazione dell‚Äôindipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilit√† congiunta.\n\n30.2.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ci√≤ significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilit√† congiunta √® il prodotto delle rispettive distribuzioni di probabilit√† marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l‚Äôindipendenza si verifica quando la funzione di densit√† congiunta √® il prodotto delle funzioni di densit√† marginali.\n\n\n30.2.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, √® utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile √® associata alla variazione dell‚Äôaltra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l‚Äôindipendenza tra variabili casuali √® un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate √® fondamentale per l‚Äôanalisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#covarianza",
    "href": "chapters/probability/09_joint_prob.html#covarianza",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.3 Covarianza",
    "text": "30.3 Covarianza\nLa covarianza √® un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell‚Äôaltra. Per esempio, considerando l‚Äôaltezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando cos√¨ una covarianza positiva. La covarianza √® denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n30.3.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) √® definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini pi√π espliciti, la covarianza pu√≤ essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) √® la funzione di probabilit√† congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che √® la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza pu√≤ essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n30.3.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n30.3.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si pu√≤ ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) √®:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 30.2 Per fare un esempio con Python, consideriamo l‚Äôesempio precedente nel quale \\(X\\) √® il numero che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) √® il numero di teste al primo lancio. Troviamo \\(Cov(X, Y)\\).\nCreiamo il prodotto cartesiano che si ottiene per tutti i possibili valori \\(X\\) e i possibili valori \\(Y\\).\n\nc3 = np.arange(0, 4)\nc1 = np.arange(0, 2)\nsample = [(i, j) for i in c1 for j in c3]\nsample\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo numero √® il valore di \\(X\\). Come abbiamo visto in precedenza, per√≤, quete coppie di valori \\(X, Y\\) non hanno tutte la stessa probabilit√† di verificarsi. Infatti, la probabilit√† che ciascuna coppia \\(X, Y\\) si osservi √® data, in sequenza, dai valori 1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8. Questi valori rappresentano la distribuzione di massa di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\). Possiamo quindi applicare l‚Äôeq. {eq}eq-cov-def-rv:\n\nres = []\n\npmf = np.array([1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8])\n\nfor i in range(8):\n    res.append((sample[i][0] - 0.5) * (sample[i][1] - 1.5) * pmf[i])\n\nsum(res)\n\nLa covarianza tra \\(X\\) e \\(Y\\) √® dunque uguale a 0.25.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#correlazione",
    "href": "chapters/probability/09_joint_prob.html#correlazione",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.4 Correlazione",
    "text": "30.4 Correlazione\nMentre la covarianza fornisce un‚Äôindicazione della tendenza di due variabili casuali a variare insieme, essa √® influenzata dalle unit√† di misura delle variabili, rendendo difficile valutare l‚Äôintensit√† della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo cos√¨ una misura standardizzata dell‚Äôassociazione lineare tra di esse.\n\nDefinizione 30.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), √® definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) √® un valore adimensionale, ovvero non dipende dalle unit√† di misura delle variabili, e varia nell‚Äôintervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#propriet√†-1",
    "href": "chapters/probability/09_joint_prob.html#propriet√†-1",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.5 Propriet√†",
    "text": "30.5 Propriet√†\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) √® sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza √® simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unit√† di Misura: La correlazione √® indipendente dalle unit√† di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) √® una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, √® \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n30.5.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza √® nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza pi√π debole rispetto all‚Äôindipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 30.3 Consideriamo una distribuzione di probabilit√† congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilit√† uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilit√† congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilit√† congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) √® zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ci√≤ non implica la loro indipendenza. L‚Äôindipendenza richiede che la funzione di probabilit√† congiunta si possa esprimere come il prodotto delle funzioni di probabilit√† marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l‚Äôassenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l‚Äôincorrelazione non garantisce l‚Äôindipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#variabili-continue",
    "href": "chapters/probability/09_joint_prob.html#variabili-continue",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.6 Variabili continue",
    "text": "30.6 Variabili continue\nConsideriamo ora le distribuzioni di densit√†. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilit√† congiunta \\(p(A,B)\\), le probabilit√† marginali \\(p(A)\\) e \\(p(B)\\), e le probabilit√† condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densit√† (figura tratta da Martin (2024)).\n\n\n\nProbabilit√† congiunta \\(p(A,B)\\): rappresenta la probabilit√† che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa √® data dall‚Äôintegrazione della funzione di densit√† congiunta su un‚Äôarea o volume di interesse.\nProbabilit√† marginale \\(p(A)\\) e \\(p(B)\\): √® la probabilit√† di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densit√† congiunta sull‚Äôintero intervallo di valori dell‚Äôaltra variabile.\nProbabilit√† condizionale \\(p(A \\mid B)\\): esprime la probabilit√† di A dato B. Si calcola dividendo la probabilit√† congiunta per la probabilit√† marginale di B, applicando la definizione di probabilit√† condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilit√† congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/09_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.7 Commenti e considerazioni finali",
    "text": "30.7 Commenti e considerazioni finali\nIn alcune situazioni, ogni singolo elemento di una popolazione pu√≤ essere associato a diverse variabili casuali. Ad esempio, consideriamo l‚Äôelenco di tutti gli studenti iscritti a un‚Äôuniversit√† e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione √® associato a due variabili casuali, l‚Äôaltezza e il peso. Quando si hanno due o pi√π variabili casuali associate ad ogni elemento di una popolazione, √® possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilit√† congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "30¬† Probabilit√† congiunta",
    "section": "30.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "30.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMartin, Osvaldo. 2024. Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html",
    "href": "chapters/probability/10_density_func.html",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Introduction\nIn precedenza abbiamo trattato solo variabili casuali discrete, ossia variabili che assumono solo valori interi. Tuttavia, se vogliamo rappresentare grandezze come lunghezze, volumi, distanze o qualsiasi altra propriet√† continua del mondo fisico o psicologico, √® necessario generalizzare l‚Äôapproccio utilizzato finora.\nLe variabili casuali continue assumono valori reali, e l‚Äôinsieme dei numeri reali √® non numerabile in quanto √® pi√π grande dell‚Äôinsieme degli interi.1 Le leggi della probabilit√† valgono sia per le variabili casuali discrete che per quelle continue. Tuttavia, la nozione di funzione di massa di probabilit√† deve essere sostituita dal suo equivalente continuo, la funzione di densit√† di probabilit√†. In questo capitolo, il nostro obiettivo √® chiarire il significato di questa nozione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "31.1 Spinner e variabili casuali continue uniformi",
    "text": "31.1 Spinner e variabili casuali continue uniformi\nConsideriamo l‚Äôesperimento casuale in cui facciamo ruotare ad alta velocit√† uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma, identificata dall‚Äôangolo acuto con segno tra il suo asse e l‚Äôasse orizzontale del goniometro. Denotiamo con \\(\\Theta\\) la variabile casuale corrispondente alla ‚Äúpendenza dello spinner‚Äù. In questo contesto, l‚Äôassunzione che lo spinner sia simmetrico implica che, in ogni prova, la rotazione produce un angolo qualunque da 0 a 360 gradi con la stessa probabilit√†. In altre parole, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilit√† di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, dal momento che 36 gradi corrisponde a un decimo del percorso intorno al cerchio, la probabilit√† di ottenere un qualsiasi intervallo di 36 gradi sar√† sempre uguale al 10%. Pi√π precisamente, si ha \\(P(0 \\leq \\Theta \\leq 36) = \\frac{1}{10}\\) e \\(P(200 \\leq \\Theta \\leq 236) = \\frac{1}{10}\\).\n√à importante sottolineare che le probabilit√† sopra menzionate non si riferiscono al fatto che la variabile casuale \\(\\Theta\\) assuma un valore specifico, ma piuttosto all‚Äôevento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilit√† che la pendenza \\(\\Theta\\) cada in un intervallo specificato √® data dalla frazione del cerchio rappresentata dall‚Äôintervallo, cio√® \\(P(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}\\), per ogni intervallo \\([\\theta_1, \\theta_2]\\) tale che \\(0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360\\).\nNel caso di una variabile casuale continua, come l‚Äôangolo dello spinner, dunque, √® facile capire come assegnare una probabilit√† all‚Äôevento in cui la variabile casuale assuma un valore compreso in un intervallo.\n\n31.1.1 Distribuzione uniforme\nL‚Äôesempio dello spinner rappresenta il ‚Äúmeccanismo generatore dei dati‚Äù della variabile casuale continua pi√π semplice, ovvero la distribuzione continua uniforme. In teoria della probabilit√†, la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna la stessa probabilit√† a tutti i punti appartenenti ad un intervallo [a, b] contenuto in un certo insieme.\nLa distribuzione uniforme continua definita sull‚Äôintervallo \\({\\displaystyle S=[a,b]\\subset \\mathbb {R}}\\) viene denotata con \\({\\displaystyle {\\mathcal {U}}(a,b)={\\mathcal {U}}([a,b])}\\). La sua densit√† di probabilit√† √®\n\\[\nf(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n\\]\ne 0 altrimenti. La distribuzione uniforme continua √® caratterizzata dalla sua propriet√† di equidistribuzione: tutti gli intervalli di pari lunghezza all‚Äôinterno dell‚Äôintervallo [a, b] hanno la stessa probabilit√†. In altre parole, se \\({\\displaystyle [c,d]}\\) √® un sottointervallo di \\({\\displaystyle [a,b]}\\), allora la probabilit√† che una variabile casuale continua con distribuzione uniforme in \\({\\displaystyle [a,b]}\\) cada in \\({\\displaystyle [c,d]}\\) √® \\({\\displaystyle (d-c)/(b-a)}\\).\nSvolgiamo un esercizio con Python in cui, per continuare il nostro esempio dello spinner, consideriamo una \\(\\mathcal {U}(0, 360)\\).\n\na = 0\nb = 360\nsize = 101\nx = np.linspace(a, b, size)\ny = st.uniform.pdf(x, loc=a, scale=b)\n\nplt.figure()\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.ylabel(\"Densit√†\");\n\n\n\n\n\n\n\n\nGeneriamo 100,000 valori casuali di una v.c. \\(\\Theta \\sim \\mathcal {U}(0, 360)\\).\n\ndata = rng.uniform(0, 360, size=100000)\n\nL‚Äôistogramma delle 100,000 realizzazioni di \\(\\Theta\\) √® il seguente.\n\nplt.figure()\nplt.hist(data, density=True, alpha=0.5)\nplt.xlabel(\"Theta ~ U[0, 360]\")\nplt.ylabel(\"Densit√†\")\nplt.title(\"Distribuzione uniforme\")\nplt.show()\n\n\n\n\n\n\n\n\n√à chiaro che, all‚Äôaumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell‚Äôistogramma tender√† a diventare una linea retta. Ci√≤ significa che la funzione di densit√† di una variabile casuale uniforme continua √® una costante: \\(f(\\Theta) = c\\).\nDalla figura precedente vediamo che l‚Äôarea sottesa alla funzione di densit√† √® \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densit√† di una variabile casuale uniforme continua non dipende da \\(\\theta\\) ‚Äì √® costante e identica per ogni possibile valore \\(\\theta\\).\nIl valore atteso di \\(X \\sim \\mathcal {U}(a,b)\\) √® dato da\n\\[\n\\mathbb{E} = \\frac{b - a}{2}.\n\\]\nNel caso della presente simulazione otteniamo\n\ndata.mean()\n\n180.44171561785456\n\n\nSvolgiamo un altro semplice esercizio. Consideriamo una variabile casuale uniforme \\(X\\) definita sull‚Äôintervallo [0, 100]. Poniamoci il problema di trovare la probabilit√† \\(P(20 &lt; X &lt; 60)\\).\nPer trovare la soluzione √® sufficiente calcolare l‚Äôarea di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilit√† cercata √® dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "31.2 Il paradosso delle variabili casuali continue",
    "text": "31.2 Il paradosso delle variabili casuali continue\nConsideriamo ora la probabilit√† che la variabile casuale continua assuma un valore specifico, come ad esempio una pendenza dello spinner esattamente uguale a 36 gradi. Sorprendentemente, la risposta √® zero:\n\\[\nP(\\Theta = 36) = 0.\n\\]\nCi√≤ √® dovuto al fatto che se la probabilit√† di un valore specifico fosse maggiore di zero, allora ogni altro possibile valore dovrebbe avere la stessa probabilit√†, poich√© abbiamo assunto che tutti i valori \\(\\Theta\\) sono egualmente probabili. Ma se sommiamo tutte queste probabilit√†, il totale sarebbe maggiore di uno, il che √® impossibile.\nNel caso delle variabili casuali continue, dobbiamo quindi rinunciare all‚Äôidea che ogni singolo valore della variabile casuale possa avere una massa di probabilit√† maggiore di zero. Invece, una massa di probabilit√† viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. Questo √® ci√≤ che differenzia le variabili casuali continue dalle variabili casuali discrete, dove ogni singolo valore ha una probabilit√† di massa non nulla. In sintesi, le variabili casuali continue non hanno una massa di probabilit√†, ma una densit√† di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densit√†",
    "href": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densit√†",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "31.3 Dagli istogrammi alle densit√†",
    "text": "31.3 Dagli istogrammi alle densit√†\nLe considerazioni precedenti ci fanno comprendere che, a differenza delle variabili casuali discrete, non esiste l‚Äôequivalente di una funzione di massa di probabilit√† per le variabili casuali continue. Invece, esiste una funzione di densit√† di probabilit√† che pu√≤ essere definita in termini di una simulazione. Considerando un numero enorme di casi e facendo tendere l‚Äôampiezza \\(\\Delta\\) di ciascuna classe a 0, il profilo dell‚Äôistogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) √® detta funzione di densit√† di probabilit√†.\nIn un istogramma, l‚Äôarea di ogni barra √® proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo considerato. Dato che tutti gli intervalli hanno la stessa ampiezza, l‚Äôaltezza di ogni barra sar√† proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo. Nella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore nell‚Äôintervallo considerato. Con l‚Äôaumentare del numero di osservazioni \\(M\\), le probabilit√† stimate si avvicinano sempre di pi√π ai valori effettivi della probabilit√†. Inoltre, all‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo tende a 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® appunto la funzione di densit√† di probabilit√† della variabile casuale.\nIn precedenza, nella statistica descrittiva, abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico utilizzato per stimare la funzione di densit√† di probabilit√† di una variabile casuale.\nPer fare un esempio, generiamo 50 valori dalla distribuzione del quoziente di intelligenza. Stampiamo i primi 5 valori.\n\nmu, sigma = 100, 15\nsize = 50\nx = rng.normal(loc=mu, scale=sigma, size=size)\nx[:5]\n\narray([ 91.33354594, 104.82329102, 112.23027301, 123.44901535,\n        98.12903873])\n\n\nCreiamo ora un istogramma a cui sovrapponiamo la funzione di densit√† Normale con parametri corrispondenti alla media e deviazione standard del campione. Con poche osservazioni, non c‚Äô√® una buona corrispondenza tra l‚Äôistogramma e la curva continua che abbiamo chiamato ‚Äúfunzione di densit√†‚Äù.\n\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=25, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.58 e 13.34')\n\n\n\n\n\n\n\n\n\nOra aumentiamo il numero di osservazioni. In questo caso consideriamo 20,000 valori del QI. Generiamo dunque una figura simile alla precedente, solo considerando un campione di dati pi√π grande.\n\nsize = 10000\nx = rng.normal(loc=mu, scale=sigma, size=size)\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=50, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.39 e 15.05')\n\n\n\n\n\n\n\n\n\nOra vediamo che c‚Äô√® una corrispondenza molto buona tra il profilo dell‚Äôistogramma e la curva continua. Questo ci consente la seguente interpretazione: la funzione di densit√† √® una curva che approssima il profilo di un istogramma, quando consideriamo un grande numero di osservazioni. In altre parole, una funzione di densit√† non √® altro che un (profilo di un) istogramma nel caso di un numero infinito di osservazioni e intervalli di ampiezza \\(\\Delta\\) infinitamente piccoli.\nIn un istogramma, l‚Äôarea di ciascuna barra √® proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo. Perch√© tutti gli intervalli hanno la stessa ampiezza, anche l‚Äôaltezza di ciascuna barra sar√† proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo.\nNella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore compreso nell‚Äôintervallo considerato. All‚Äôaumentare del numero \\(M\\) di osservazioni, le probabilit√† stimate si avvicinano sempre di pi√π ai veri valori della probabilit√†. All‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo \\(\\rightarrow\\) 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® la funzione di densit√† di probabilit√† della variabile casuale.\nNella statistica descrittiva abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico per stimare la funzione di densit√† di probabilit√† di una variabile casuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "href": "chapters/probability/10_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "31.4 Funzione di densit√† di probabilit√†",
    "text": "31.4 Funzione di densit√† di probabilit√†\nDa un punto di vista matematico, l‚Äôintuizione precedente si pu√≤ esprimere nel modo seguente.\nPer descrivere le probabilit√† che possono essere associate ad una variabile casuale continua \\(X\\) √® necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due propriet√†:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l‚Äôordinata della funzione di densit√† √® 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l‚Äôarea sottesa dalla \\(p(x)\\) √® unitaria2;\n\\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l‚Äôarea sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilit√† che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. √à possibile che \\(p(x) &gt; 1\\), quindi una densit√† di probabilit√† non pu√≤ essere interpretata come una probabilit√†. Piuttosto, la densit√† \\(p(x)\\) pu√≤ essere utilizzata per confrontare la credibilit√† relativa che pu√≤ essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui √® disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che √® pi√π credibile, in termini relativi, osservare realizzazioni \\(X\\) nell‚Äôintorno di \\(x_k\\) piuttosto che nell‚Äôintorno di \\(x_l\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "31.5 La funzione di ripartizione per una variabile casuale continua",
    "text": "31.5 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) √® definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCio√®, √® la probabilit√† che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua pu√≤ essere utilizzata per calcolare la probabilit√† che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "31.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "31.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.3\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#footnotes",
    "href": "chapters/probability/10_density_func.html#footnotes",
    "title": "31¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Georg Cantor dimostr√≤ che era impossibile mappare uno a uno i reali negli interi, dimostrando cos√¨ che l‚Äôinsieme dei reali √® non numerabile.‚Ü©Ô∏é\nPer quel che riguarda la notazione dell‚Äôintegrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html‚Ü©Ô∏é",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html",
    "href": "chapters/probability/11_discr_rv_distr.html",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esploreremo le distribuzioni di probabilit√† discrete, che sono fondamentali per la comprensione dei fenomeni aleatori con un numero finito o numerabile di esiti.\nOgni distribuzione di probabilit√† pu√≤ essere parametrizzata specificando dei parametri che permettono di controllare certi aspetti della distribuzione per raggiungere un obiettivo specifico.\nInizieremo con la distribuzione Bernoulliana, che rappresenta esperimenti con due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù. Questi esperimenti costituiscono il nucleo di ci√≤ che √® definito un processo Bernoulliano. Il parametro della distribuzione Bernoulliana √® la probabilit√† di successo in ciascuna prova.\nQuando tali prove Bernoulliane vengono ripetute per un numero fisso di volte \\(n\\), il conteggio totale dei successi segue una distribuzione binomiale. Anche la distribuzione binomiale dipende da un parametro, la probabilit√† di successo in ciascuna singola prova. Questa distribuzione nasce dalla somma di prove Bernoulliane indipendenti, quando il numero totale di prove \\(n\\) √® stabilito in anticipo.\nSe, invece, il numero stesso di prove diventa una variabile casuale, la distribuzione dei successi all‚Äôinterno di questa serie di prove segue la distribuzione di Poisson. Questa distribuzione √® particolarmente adatta a modellare eventi che avvengono raramente o su intervalli variabili. La distribuzione di Poisson dipende da un unico parametro: il tasso medio di successo per unit√† di tempo o spazio.\nSe la probabilit√† di successo in una serie di prove Bernoulliane non √® costante, ma varia seguendo una distribuzione Beta, il numero di successi osservati in \\(N\\) prove non seguir√† pi√π la distribuzione binomiale, ma seguir√† invece la distribuzione Beta-Binomiale. Questa distribuzione offre una rappresentazione pi√π flessibile e aderente alla realt√† in alcuni contesti.\nInfine, esamineremo la distribuzione uniforme discreta, dove ogni evento all‚Äôinterno di un determinato intervallo finito ha la stessa probabilit√† di verificarsi. Questa distribuzione √® particolarmente utile quando non esistono motivi per privilegiare un risultato rispetto a un altro. La distribuzione uniforme √® molto specifica e non dipende da alcun parametro: una volta stabilito il supporto della distribuzione, c‚Äô√® un unico modo per assegnare le probabilit√† agli eventi.\nIn sintesi, attraverso queste distribuzioni, possiamo modellare e analizzare matematicamente una vasta gamma di situazioni reali, fornendo strumenti utili per comprendere e prevedere fenomeni aleatori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-bernoulliana",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-bernoulliana",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "32.1 Distribuzione Bernoulliana",
    "text": "32.1 Distribuzione Bernoulliana\nIn statistica, un esperimento che presenta soltanto due esiti possibili viene modellato attraverso ci√≤ che √® noto come ‚Äúprova Bernoulliana‚Äù. Un esempio classico √® il lancio di una moneta, che pu√≤ risultare in testa o croce.\n\nDefinizione 32.1 Una variabile casuale \\(Y\\) che assume valori in \\(\\{0, 1\\}\\) √® definita come variabile di Bernoulli. La sua distribuzione di probabilit√† √® descritta come segue:\n\\[\nP(Y \\mid \\theta) =\n  \\begin{cases}\n    \\theta     & \\text{se $Y = 1$ (successo)}, \\\\\n    1 - \\theta & \\text{se $Y = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq \\theta \\leq 1\\). Il parametro \\(\\theta\\) rappresenta la probabilit√† dell‚Äôevento ‚Äúsuccesso‚Äù (\\(Y = 1\\)), mentre \\(1 - \\theta\\) quella dell‚Äôevento ‚Äúinsuccesso‚Äù (\\(Y = 0\\)).\n\nNella distribuzione Bernoulliana, la probabilit√† di osservare l‚Äôesito 1 √® \\(\\theta\\), mentre quella di osservare 0 √® \\(1 - \\theta\\). Questa distribuzione viene utilizzata per modellare situazioni in cui esistono due sole possibili risposte, come un ‚Äús√¨‚Äù o un ‚Äúno‚Äù, un ‚Äúsuccesso‚Äù o un ‚Äúinsuccesso‚Äù.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\\n\\mathbb{V}(Y) &= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta).\n\\end{align}\n\\tag{32.1}\\]\nEsplicitando ulteriormente la formula della varianza con \\(P(Y=0) = 1 - \\theta\\) e \\(P(Y=1) = \\theta\\), abbiamo:\n\\[ \\mathbb{V}(Y) = (0 - \\theta)^2 \\cdot (1 - \\theta) + (1 - \\theta)^2 \\cdot \\theta \\]\nCalcoliamo ora le singole parti dell‚Äôespressione: 1. $ (0 - )^2 = ^2 $ 2. $ (1 - )^2 = 1 - 2+ ^2 $\nSostituendo queste espressioni nell‚Äôequazione della varianza, otteniamo:\n\\[ \\mathbb{V}(Y) = \\theta^2 \\cdot (1 - \\theta) + (1 - 2\\theta + \\theta^2) \\cdot \\theta \\]\n\\[ \\mathbb{V}(Y) = \\theta^2 - \\theta^3 + \\theta - 2\\theta^2 + \\theta^3 \\]\nSemplificando:\n\\[ \\mathbb{V}(Y) = \\theta - \\theta^2 \\]\n\\[ \\mathbb{V}(Y) = \\theta(1-\\theta) \\]\nQuindi, l‚Äôequazione iniziale mostra come la varianza di una variabile casuale binaria \\(Y\\), che segue una distribuzione di Bernoulli con parametro \\(\\theta\\), sia espressa come \\(\\theta(1-\\theta)\\). Questo rispecchia il fatto che la varianza di una distribuzione di Bernoulli raggiunge il suo massimo quando \\(\\theta = 0.5\\), indicando la massima incertezza (o variabilit√†) quando la probabilit√† di successo √® uguale a quella di fallimento.\n\n# Define theta values between 0 and 1\ntheta = np.linspace(0, 1, 100)\n\n# Variance of a Bernoulli distribution is theta(1-theta)\nvariance = theta * (1 - theta)\n\nplt.plot(theta, variance, label='Varianza', color='blue')\nplt.title('Varianza di una variabile Bernoulliana in funzione di $\\\\theta$')\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Varianza')\nplt.show()\n\n\n\n\n\n\n\n\nUtilizziamo la notazione \\(Y \\sim Bernoulli(\\theta)\\) per indicare che la variabile casuale \\(Y\\) segue una distribuzione Bernoulliana di parametro \\(\\theta\\).\nAd esempio, nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilit√† di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilit√† assegna una probabilit√† di \\(\\frac{1}{2}\\) sia per \\(Y = 0\\) che per \\(Y = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "32.2 Distribuzione Binomiale",
    "text": "32.2 Distribuzione Binomiale\nLa distribuzione binomiale √® una distribuzione di probabilit√† discreta fondamentale, che si concentra sul conteggio del numero di successi in una serie di prove Bernoulliane indipendenti. Queste prove sono caratterizzate dal fatto che ogni evento ha solo due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù, con una probabilit√† di successo costante denotata da \\(\\theta\\).\n\nDefinizione 32.2 La distribuzione binomiale quantifica la probabilit√† di osservare esattamente \\(y\\) successi in \\(n\\) tentativi indipendenti di Bernoulli:\n\\[\nP(Y=y) = \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} = \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y},\n\\] (eq-binomialdistribution)\nQui, \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di combinazioni possibili per ottenere \\(y\\) successi in \\(n\\) prove, mentre \\(\\theta\\) √® la probabilit√† costante di successo per ogni prova.\n\nLa distribuzione binomiale √® spesso illustrata con esempi come il lancio di una moneta o l‚Äôestrazione da un‚Äôurna. Ad esempio, nel caso del lancio ripetuto di una moneta, questa distribuzione descrive la probabilit√† di ottenere un numero specifico di teste in un certo numero di lanci, con ciascun lancio che segue una distribuzione di Bernoulli con probabilit√† di successo \\(\\theta\\).\nUn aspetto interessante della distribuzione binomiale √® la sua propriet√† di riproducibilit√†: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\), ma con diversi numeri di prove (\\(N_1\\) e \\(N_2\\)), allora la loro somma, \\(y = y_1 + y_2\\), sar√† anch‚Äôessa distribuita binomialmente, con parametri \\(N_1 + N_2\\) e \\(\\theta\\).\n\n32.2.1 Calcolo delle Probabilit√†\nPer approfondire il calcolo delle probabilit√† in questa distribuzione, esaminiamo una serie di prove Bernoulliane. Consideriamo una serie di \\(n\\) prove che risultano in \\(y\\) successi:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots I}^\\text{$n-y$ volte}\n\\]\nOgni sequenza con \\(y\\) successi specifici ha una probabilit√† di \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\). Tuttavia, siamo interessati alla probabilit√† complessiva di osservare qualsiasi sequenza con \\(y\\) successi, che si ottiene moltiplicando la probabilit√† di una sequenza singola per il numero totale di sequenze possibili, dato dal coefficiente binomiale \\(\\binom{n}{y}\\).\nIn questo modo, la distribuzione binomiale diventa uno strumento statistico per analizzare fenomeni che presentano esiti binari, con prove che sono indipendenti e identicamente distribuite. Questa distribuzione trova applicazione in una moltitudine di scenari, dalla valutazione del numero di successi in una serie di tentativi, come i lanci di moneta, fino a sondaggi di opinione e altro ancora.\n\n\n32.2.2 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l‚Äôapplicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilit√† di successo in ogni prova √® \\(\\theta = 0.2\\). La probabilit√† di ottenere questo risultato specifico √® calcolata utilizzando l‚Äôeq. {eq}eq-binomialdistribution:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo pu√≤ essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\nn = 4\ntheta = 0.2\ny = 2\n\nprob = math.comb(n, y) * theta**y * (1 - theta) ** (n - y)\nprint(prob)\n\n0.15360000000000007\n\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\nstats.binom.pmf(y, n, theta)\n\n0.15359999999999993\n\n\nUtilizzando scipy.stats.binom.pmf(y, n, p), possiamo trovare le probabilit√† per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\ny = np.arange(0, n + 1)\nprint(y)\n\n[0 1 2 3 4]\n\n\n\nprobabilities = stats.binom.pmf(y, n, theta)\nprint(*probabilities)\n\n0.40959999999999985 0.4096 0.15359999999999993 0.02559999999999999 0.0016000000000000003\n\n\nVisualizziamo la distribuzione di massa di probabilit√†:\n\nplt.figure()\nplt.plot(y, probabilities, \"o\", ms=8)\nplt.vlines(y, 0, probabilities, linestyles=\"-\", lw=1)\nplt.title(f\"Distribuzione binomiale: $n$={n}, $\\\\theta$={theta}\")\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.xlim(-0.5, n + 0.5)\nplt.ylim(0, max(probabilities) + 0.05)\nplt.show()\n\n\n\n\n\n\n\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilit√† di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\nplt.figure()\n\nfor theta in np.arange(0.3, 1.0, 0.3):\n    y = np.arange(0, 25)\n    binom_dist = stats.binom.pmf(y, 20, theta)\n    plt.plot(y, binom_dist, \"-o\", label=f\"theta = {theta:.1f}\")\n\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.title(\"Distribuzione binomiale al variare di $\\\\theta$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nUn‚Äôaltra propriet√† interessante della distribuzione binomiale √® la sua riproducibilit√†. Se abbiamo due variabili casuali indipendenti che seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\) ma con diversi numeri di prove, la loro somma seguir√† anch‚Äôessa una distribuzione binomiale. Questo pu√≤ essere dimostrato analiticamente o sperimentato empiricamente.\n\n# Parameters\nn1, n2 = 10, 15  # Number of trials\ntheta = 0.5  # Success probability\n\n# Analytical binomial distributions\nx1 = np.arange(0, n1+1)\ny1 = stats.binom.pmf(x1, n1, theta)\nx2 = np.arange(0, n2+1)\ny2 = stats.binom.pmf(x2, n2, theta)\n\n# Combined analytical distribution\nx_combined = np.arange(0, n1+n2+1)\ny_combined = stats.binom.pmf(x_combined, n1+n2, theta)\n\n# Simulated distributions\nsimulated1 = rng.binomial(n1, theta, 10000)\nsimulated2 = rng.binomial(n2, theta, 10000)\nsimulated_combined = simulated1 + simulated2\n\n# Plotting\nplt.figure(figsize=(18, 6))\n\n# Plot 1: Binomial 1\nplt.subplot(1, 3, 1)\nplt.bar(x1, y1, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated1, bins=range(n1+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n1}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.ylabel('Probability')\nplt.legend()\n\n# Plot 2: Binomial 2\nplt.subplot(1, 3, 2)\nplt.bar(x2, y2, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated2, bins=range(n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\n# Plot 3: Combined Binomial\nplt.subplot(1, 3, 3)\nplt.bar(x_combined, y_combined, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated_combined, bins=range(n1+n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Combined Binomial Distribution n={n1+n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual √® la probabilit√† che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\nstats.binom.pmf(2, n=5, p=0.5) + stats.binom.pmf(3, n=5, p=0.5) + stats.binom.pmf(4, n=5, p=0.5) +  stats.binom.pmf(5, n=5, p=0.5)\n\n0.8125\n\n\n\nnp.sum([stats.binom.pmf(k, n=5, p=0.5) for k in range(2, 6)])\n\n0.8125\n\n\nPi√π facilmente, si trova la risposta usando la funzione di ripartizione stats.binom.cdf.\n\n1 - stats.binom.cdf(1, n=5, p=0.5) \n\n0.8125\n\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\nn = 5\ntheta = 0.5\ny = np.arange(0, n+1)\n\nplt.figure()\nplt.plot(y, stats.binom.cdf(y, n=n, p=theta))\nplt.scatter(y, stats.binom.cdf(y, n=n, p=theta))\nplt.axhline(1, color=\"k\", alpha=0.7, linestyle=\"--\", lw=1)\nplt.title(f\"Funzione di ripartizione binomiale: $n$={n}, $\\\\theta$={theta}\", loc=\"left\")\nplt.xlabel(\"y\")\n_ = plt.ylabel(\"Probabilit√†\")\n\n\n\n\n\n\n\n\nUn‚Äôaltra funzione utile √® quella che trova il numero di successi in una distribuzione binomiale che corrisponde ad una data probabilit√† (nella coda sinistra della funzione ripartizione). Per l‚Äôesempio presente:\n\ntarget_probability = 1 - 0.8125\nstats.binom.ppf(target_probability, n, theta)\n\n1.0\n\n\nUtilizzando la funzione punto percentuale (PPF), che √® l‚Äôinverso della funzione di distribuzione cumulativa (CDF), possiamo trovare il numero di successi corrispondente alla probabilit√† target di \\(1 - 0.8125 = 0.1875\\) in una distribuzione binomiale con parametri \\(n = 5\\) e \\(\\theta = 0.5\\). Il risultato mostra che il numero di successi cercato per questa probabilit√† target √® 1.\nFacciamo un altro esempio. Consideriamo la probabilit√† cumulativa \\(P(Y \\leq 4)\\) per una variabile casuale \\(Y\\) che segue una distribuzione binomiale con numero di prove \\(n = 10\\) e probabilit√† di successo \\(\\theta = 0.2\\). La funzione stats.binom.cdf(4, n=10, p=0.2) calcola la probabilit√† che ci siano al massimo 4 successi in 10 tentativi, dove la probabilit√† di successo in ogni tentativo √® del 20%.\n\ntarget_probability = stats.binom.cdf(4, n=10, p=0.2)\ntarget_probability\n\n0.9672065024\n\n\nDi conseguenza, la funzione inversa √®:\n\nstats.binom.ppf(target_probability, n=10, p=0.2)\n\n4.0\n\n\nPer generare una sequenza di valori casuali seguendo una distribuzione binomiale possiamo utilizzare la funzione random() di NumPy. Dopo aver inizializzato rng = np.random.default_rng(RANDOM_SEED), per esempio,\n\nrng = np.random.default_rng(42)\n\npossiamo impiegare rng per generare valori casuali da una distribuzione binomiale:\n\nx = rng.binomial(p=.5, n=5, size=30)\nprint(*x)\n\n3 5 1 2 3 2 3 3 3 1 2 4 2 3 0 2 2 2 3 3 4 4 2 0 4 2 2 1 3 2\n\n\nPer una discussione sulla generazione di numeri pseudo-casuali in Python, si veda il capitolo {ref}appendix-rng.\n\n\n32.2.3 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si trovano nel modo seguente:\n\\[\n\\begin{align}\n\\mu    &= n\\theta,  \\notag \\\\\n\\sigma &= \\sqrt{n\\theta(1-\\theta)}.\n\\end{align}\n\\tag{32.2}\\]\nDimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), √® facile vedere che\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = n\\theta, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = n \\theta (1-\\theta).\n\\end{align}\n\\]\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilit√† di ottenere testa (successo) pari a \\(\\theta = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo √® dato da \\(\\mu = n \\theta\\), dove \\(n\\) √® il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(\\theta = 0.2\\), abbiamo:\n\\[\n\\mu = n \\theta = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale √® calcolata come \\(n \\theta (1-\\theta)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n \\theta (1-\\theta) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nx = rng.binomial(p=.2, n=4, size=1000000)\n\n\nnp.mean(x)\n\n0.79956\n\n\n\nnp.var(x, ddof=0)\n\n0.6397598064000003\n\n\n\n\n32.2.4 Funzioni Python associate alle distribuzioni di probabilit√†\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (y | n, Œ∏)\nEsempio: Normale (y | Œº, œÉ)\n\n\n\n\nFunzione di verosimiglianza\nbinom.pmf(y, n, Œ∏)\nnorm.pdf(y, Œº, œÉ)\n\n\nProb Y=y\nbinom.pmf(y, n, Œ∏)\nsempre 0\n\n\nProb Y ‚â• y, Y ‚â§ y, y1 &lt; Y &lt; y2\nbinom.cdf(y, n, Œ∏) o binom.sf(y, n, Œ∏)\nnorm.cdf(y, Œº, œÉ) o norm.sf(y, Œº, œÉ)\n\n\nInversa della CDF\nbinom.ppf(q, n, Œ∏)\nnorm.ppf(q, Œº, œÉ)\n\n\nGenerazione di dati simulati\nrng.binomial(p, n, size)\nrng.normal(Œº, œÉ, size\n\n\n\nIn seguito, utilizzeremo altre distribuzioni, come Uniforme, Beta, ecc., e ognuna di queste ha il proprio insieme di funzioni in Python trovate in scipy.stats. √à possibile consultare queste diverse distribuzioni in opere di riferimento o documentazione online.\nSi noti che pmf (funzione di massa di probabilit√†) √® usato per le distribuzioni discrete come la binomiale, mentre pdf (funzione di densit√† di probabilit√†) √® usata per le distribuzioni continue come la normale. cdf (funzione di distribuzione cumulativa) e sf (funzione di sopravvivenza, che √® 1 - cdf) sono utilizzate per calcolare le probabilit√† cumulative. ppf (percent point function) √® l‚Äôinverso della cdf e viene utilizzata per determinare il valore di variabile al di sotto del quale cade una certa percentuale delle osservazioni. rvs (random variates) √® usata per generare dati simulati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "32.3 Distribuzione Discreta Uniforme",
    "text": "32.3 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme √® un tipo particolare di distribuzione di probabilit√†, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilit√† \\(p\\) di verificarsi. Questa distribuzione √® caratterizzata dalla sua semplicit√† e dalla sua propriet√† fondamentale di equiprobabilit√†.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che pu√≤ assumere valori nell‚Äôinsieme \\(\\{1, 2, \\dots, N\\}\\). Un‚Äôistanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilit√† di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilit√† che \\(X\\) assuma un valore specifico \\(x\\) √® uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilit√† di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci d√† un‚Äôidea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che √® la somma dei primi \\(N\\) numeri naturali. Questa somma √® data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) √® \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo √® calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilit√† (che √® \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l‚Äôidentit√† per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo gi√† stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l‚Äôespressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) √® \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-poisson",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-poisson",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "32.4 Distribuzione di Poisson",
    "text": "32.4 Distribuzione di Poisson\nLa distribuzione di Poisson √® utilizzata per modellare il numero di eventi indipendenti che si verificano in un intervallo di tempo o spazio prefissato. La variabile casuale discreta \\(Y\\) denota il numero di tali eventi, mentre il parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza di questi eventi in un intervallo specifico.\nLa funzione di massa di probabilit√† associata alla distribuzione di Poisson, che indica la probabilit√† che si verifichino esattamente \\(y\\) eventi, √® definita come segue:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\tag{32.3}\\]\nQuesta equazione illustra:\n\n\\(P(Y = y \\mid \\lambda)\\), la probabilit√† che esattamente \\(y\\) eventi si verifichino.\n\\(\\lambda\\), il tasso medio di occorrenza degli eventi per l‚Äôintervallo considerato.\n\\(y\\), il numero di eventi, che √® limitato ai valori interi non negativi.\n\nUna peculiarit√† della distribuzione di Poisson √® che sia il valore atteso (\\(E[Y]\\)) sia la varianza (\\(Var[Y]\\)) sono equivalenti a \\(\\lambda\\). Questo significa che con l‚Äôaumentare del valore di \\(\\lambda\\), aumenta anche la dispersione dei dati attorno al valore medio, evidenziando un incremento della variabilit√† degli eventi.\nQuale esempio, presentiamo qui sotto un grafico con la distribuzione di Poisson di parametro \\(\\lambda\\) = 2.\n\n# Tasso medio di occorrenza di eventi\nlambda_value = 2\n\n# Creazione della distribuzione di Poisson con il tasso medio specificato\npoisson_dist = stats.poisson(mu=lambda_value)\n\n# Calcolo della probabilit√† di avere un certo numero di eventi\nk_values = range(0, 11)  # Consideriamo valori da 0 a 10\n\n# Calcolo delle probabilit√† corrispondenti\nprobabilities = poisson_dist.pmf(k_values)\n\nplt.figure()\n\n# Plot della distribuzione di massa di probabilit√†\nplt.bar(k_values, probabilities, alpha=0.5)\nplt.xlabel('Numero di Eventi (k)')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione di Massa di Probabilit√† di Poisson')\nplt.show()\n\n\n\n\n\n\n\n\nLa probabilit√† di ottenere un singolo valore \\(y\\) si calcola utilizzando la funzione di massa di probabilit√† (pmf), dove l‚Äôargomento k rappresenta il numero di eventi (\\(y\\)) e mu √® uguale a \\(\\lambda\\). Ad esempio, per determinare la probabilit√† di osservare esattamente tre eventi (\\(y = 3\\)) con un tasso di occorrenza \\(\\lambda\\) = 2, indicata come \\(P(Y = 3)\\), si utilizza la seguente istruzione:\n\nstats.poisson.pmf(k=3, mu=2)\n\n0.18044704431548356\n\n\nLa probabilit√† di non pi√π di 3 eventi, indicata come \\(P(Y \\leq 3)\\), si ottiene nel modo seguente:\n\np = stats.poisson.pmf(k=0, mu=2) + stats.poisson.pmf(k=1, mu=2) + stats.poisson.pmf(k=2, mu=2) + stats.poisson.pmf(k=3, mu=2)\np\n\n0.857123460498547\n\n\nLa funzione ppf, con la probabilit√† e \\(\\lambda\\) come argomenti, restituisce il quantile della distribuzione di Poisson. Ad esempio, nel caso precedente, abbiamo:\n\nstats.poisson.ppf(p, mu=2)\n\n3.0\n\n\nLa funzione di distribuzione cumulativa si calcola utilizzando cdf. Ad esempio, per calcolare \\(P(Y \\leq 3)\\) si utilizza:\n\nstats.poisson.cdf(3, mu=2)\n\n0.857123460498547\n\n\nLa generazione di numeri casuali dalla distribuzione di Poisson pu√≤ essere ottenuta utilizzando rng. Ad esempio:\n\nmu = 2\nx = rng.poisson(mu, 1000000)\n\nVerifichiamo:\n\nnp.mean(x)\n\n1.998219\n\n\n\nnp.var(x, ddof=0)\n\n1.996941828039\n\n\nEsempio. I dati provenienti dal reparto di maternit√† di un certo ospedale mostrano che c‚Äô√® una media storica di 4.5 bambini nati in questo ospedale ogni giorno. Qual √® la probabilit√† che domani nascano 6 bambini in questo ospedale?\nPer prima cosa, calcoliamo la probabilit√† teorica di questo evento utilizzando dpois(). Il numero di successi che stiamo considerando √® 6, quindi imposteremo x = 6. Inoltre, questa media storica di 4,5 nascite al giorno √® il nostro valore per lambda, quindi imposteremo lambda = 6.\n\np = stats.poisson.pmf(k=6, mu=4.5)\nprint(f\"La probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: {p:.4f}\")\n\nLa probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: 0.1281\n\n\nSimuliamo le nascite in questo ospedale per un anno (n = 365) utilizzando la funzione np.random.poisson e confrontiamo la proporzione di giorni in cui ci sono stati 6 nascite con la probabilit√† teorica che abbiamo calcolato in precedenza.\n\n# Simuliamo le nascite in un anno (365 giorni) con una media storica di 4.5 nascite al giorno\nn_days = 365\nmean_births_per_day = 4.5\nsimulated_births = rng.poisson(mean_births_per_day, n_days)\n\n# Calcoliamo la proporzione di giorni in cui sono nati esattamente 6 bambini nella simulazione\nproportion_six_births = np.mean(simulated_births == 6)\n\n# Stampiamo la proporzione calcolata\nprint(f\"La proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: {proportion_six_births:.4f}\")\n\nLa proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: 0.0959\n\n\nVisualizziamo i risultati della simulazione.\n\n# Visualizziamo l'istogramma delle nascite simulate\nplt.hist(simulated_births, bins=np.arange(12) - 0.5, density=True, alpha=0.5)\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\nplt.xticks(np.arange(11));\n\n\n\n\n\n\n\n\nCalcoliamo la probabilit√† teorica della nascita di pi√π di 6 bambini in un giorno.\n\nprob_more_than_six = 1 - stats.poisson.cdf(6, mean_births_per_day)\nprint(f\"La probabilit√† teorica di pi√π di 6 bambini nati √®: {prob_more_than_six:.4f}\")\n\nLa probabilit√† teorica di pi√π di 6 bambini nati √®: 0.1689\n\n\nCalcoliamo la proporzione corrispondente nella simulazione\n\nproportion_more_than_six = np.mean(simulated_births &gt; 6)\nprint(f\"La proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: {proportion_more_than_six:.4f}\")\n\nLa proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: 0.1836\n\n\n\nbins = np.arange(12) - 0.5\nhist, edges = np.histogram(simulated_births, bins=bins, density=True)\n\n# Disegna l'istogramma\nfor i in range(len(hist)):\n    if edges[i] &gt;= 6:\n        color = 'red'  # Colore per x &gt; 6\n    else:\n        color = 'blue'  # Colore per x &lt;= 6\n    plt.bar(edges[i], hist[i], width=1, align='edge', color=color, alpha=0.5)\n\n# Imposta etichette e titolo\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\n_ = plt.xticks(np.arange(11))",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "32.5 Distribuzione Beta-Binomiale",
    "text": "32.5 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilit√† nella probabilit√† di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilit√† per la distribuzione beta-binomiale √® data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{32.4}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilit√† nella probabilit√† di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, √® definita tramite l‚Äôuso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL‚Äôimportanza della distribuzione beta-binomiale deriva dalla sua capacit√† di modellare situazioni in cui la probabilit√† di successo non √® fissa, ma segue una distribuzione di probabilit√†, specificatamente una distribuzione beta. Ci√≤ la rende particolarmente adatta per applicazioni in cui le probabilit√† di successo cambiano in maniera incerta da un tentativo all‚Äôaltro, come pu√≤ avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilit√† di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione pi√π realistica e flessibile per dati empirici che presentano variabilit√† nelle probabilit√† di successo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#considerazioni-conclusive",
    "href": "chapters/probability/11_discr_rv_distr.html#considerazioni-conclusive",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "32.6 Considerazioni Conclusive",
    "text": "32.6 Considerazioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarit√†. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilit√† nella probabilit√† di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilit√† a ogni evento in un insieme finito e discreto. Questa distribuzione √® particolarmente utile quando non abbiamo ragioni per assegnare probabilit√† diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell‚Äôanalisi statistica discreta e trovano applicazione in un‚Äôampia gamma di settori. In particolare, nel contesto dell‚Äôanalisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale √® cruciale, poich√© queste distribuzioni forniscono le basi per l‚Äôaggiornamento bayesiano, un concetto chiave che sar√† esplorato nei capitoli successivi.\nPer coloro interessati a tecniche pi√π avanzate, la generazione di valori casuali a partire da queste distribuzioni √® trattata nell‚Äôappendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l‚Äôapplicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni √® cruciale per chiunque desideri esplorare il vasto campo della probabilit√† e della statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "32¬† Distribuzioni di v.c. discrete",
    "section": "32.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "32.7 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html",
    "href": "chapters/probability/12_cont_rv_distr.html",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "Introduzione\nDopo avere introdotto con una simulazione il concetto di funzione di densit√† nel Capitolo 31, prendiamo ora in esame alcune delle densit√† di probabilit√† pi√π note. Iniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-uniforme",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-uniforme",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.1 Distribuzione uniforme",
    "text": "33.1 Distribuzione uniforme\nLa distribuzione uniforme √® la pi√π sempilce funzione di densit√† di probabilit√†. Consideriamo nuovamente l‚Äôesperimento con lo spinner che abbiamo introdotto nel capitolo {ref}density-function-notebook. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\ny = rng.uniform(low=0, high=360, size=20)\nprint(y)\n\n[272.91158643 127.62934853 349.45128878 321.52360368 280.21805895\n  70.06993483 168.01956134  15.76935568  55.54421714 245.89762317\n 268.11437613 348.30350368 117.29712893 133.36549417 169.04009206\n  68.20968927  46.77174192 171.25377344  81.68736566 241.13303809]\n\n\n\nplt.figure()\ncount, bins, ignored = plt.hist(y, bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\nplt.ylabel(\"Frequenza relativa\");\n\n\n\n\n\n\n\n\nSebbene possiamo pensare che sia ugualmente probabile che si verifichi qualsiasi risultato tra 0 e 360, l‚Äôistogramma non sembra suggerire questo. Ma lo spinner √® stato fatto ruotare solo 20 volte. Proviamo con 100,000 ripetizioni.\n\nplt.figure()\ncount, bins, ignored = plt.hist(rng.uniform(0, 360, 100000), bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\n_ = plt.ylabel(\"Frequenza relativa\")\n\n\n\n\n\n\n\n\nIn questo caso, anche se c‚Äô√® una variazione nelle altezze delle barre (con \\(\\Delta\\) = 10), la forma generale dell‚Äôistogramma sembra essere piuttosto piatta, ovvero uniforme, nell‚Äôintero intervallo dei valori possibili di \\(X\\), ovvero \\(0 &lt;= X &lt;= 360\\). Se potessimo ottenere un numero enorme di risultati dello spinner, il profilo dell‚Äôistogramma assumerebbe la forma della funzione di densit√† uniforme mostratra nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 100)\nplt.plot(x, stats.uniform.pdf(x, 0, 360), lw=2, label=\"uniform pdf\")\nplt.xlabel(\"x\")\nplt.ylabel(\"p(x)\");\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) √® continua, come nel caso del risultato della rotazione dello spinner, allora per rappresentare le probabilit√† usiamo una curva chiamata funzione di densit√† di probabilit√†. Poich√© la scala dello spinner va da 0 a 360, sappiamo che tutti i risultati possibili devono cadere in questo intervallo, quindi la probabilit√† che \\(X\\) assuma un valore nell‚Äôintervallo [0, 360] √® 1.0. Questa probabilit√† √® rappresentata dall‚Äôarea totale sotto la funzione di densit√† della figura precedente tra 0 e 360. Poich√© l‚Äôarea di questo rettangolo √® data dall‚Äôaltezza per la base e la base √® uguale a 360, l‚Äôaltezza di questa curva di densit√† deve essere 1/360 = 0.00278. L‚Äôordinata della funzione di densit√† (qui 0.00278 nell‚Äôintervallo [0, 360] e 0 altrove) √® chiamata densit√†.\nLe probabilit√† corrispondono alle aree sottese alla curva di densit√† nell‚Äôintervallo di valori \\(X\\) specificato. Per esempio, nell‚Äôesperimento dello spinner possiamo chiederci quale sia la probabilit√† di ottenere un numero compreso tra 150 e 250, ovvero \\(P(150 &lt; X &lt; 250)\\). Per trovare la risposta dobbiamo calcolare l‚Äôarea di un rettangolo. La base √® 250 - 150 = 100. L‚Äôaltezza √® 0.00278. Dunque, la probabilit√† √®\n\n100*1/360\n\n0.2777777777777778\n\n\nPer svolgere questo calcolo i software utilizzano la funzione di ripartizione, \\(P(X &lt; x)\\). Per trovare l‚Äôarea in un intervallo √® necessario sottrarre due aree. Nel caso presente abbiamo \\(P(x &lt; 250) - P(x &lt; 150)\\), ovvero:\n\nstats.uniform.cdf(250, 0, 360) - stats.uniform.cdf(150, 0, 360)\n\n0.27777777777777773\n\n\nLa probabilit√† cercata √® rappresentata dal rettangolo indicato nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 1000)\nfx = stats.uniform.pdf(x, 0, 360)\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 150) & (x &lt;= 250), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera pi√π formale possiamo dire che la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l‚Äôintervallo unitario \\(I=[0,1]\\).\nLa densit√† di probabilit√† di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) √®\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto √®\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza √®\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn Python √® possibile manipolare la distribuzione uniforme mediante la funzione uniform del modulo scipy.stats. Di default, la funzione scipy.stats.uniform() √® un‚Äôistanziazione di \\({\\mathcal{U}}(0,1)\\). Se utilizziamo la funzione pdf() (probability density function) otteniamo l‚Äôordinata della funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei valori \\(x\\) passati in input. Per esempio, esaminiamo la funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza di 0.5, 0.8 e 1.2. Per i primi due valori ci aspettiamo di ottenere 1; in corrispondenza di 1.2 ci aspettiamo di ottenere 0, poich√© questo valore √® al di fuori dell‚Äôintervallo \\([ 0, 1]\\).\n\nstats.uniform.pdf([0.5, 0.8, 1.2])\n\narray([1., 1., 0.])\n\n\nCon la funzione cdf() (cumulative density function) otteniamo la funzione di ripartizione. Per esempio, per \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei punti 0.5 e 0.8 otteniamo\n\nstats.uniform.cdf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nUsando la funzione di ripartizione √® possibile calcolare la probabilit√† che la variabile casuale continua assuma un valore nell‚Äôintervallo specificato. Per esempio, per \\({\\mathcal{U}}(0,1)\\) troviamo \\(P(0.5 &lt; x &lt; 0.8)\\)\n\nstats.uniform.cdf(0.8) - stats.uniform.cdf(0.5)\n\n0.30000000000000004\n\n\nI quantili di una funzione di densit√† (ovvero, il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input) si ottengono con la funzione ppf() (probability point function). Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di una \\({\\mathcal  {U}}(0,1)\\).\n\nstats.uniform.ppf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nInfine, √® possibile simulare dei valori casuali della distribuzione \\({\\mathcal{U}}(0,1)\\) usando la funzione stats.uniform(). Se vogliamo 5 valori da una \\({\\mathcal{U}}(0,1)\\), scriviamo:\n\nrng.uniform(0, 1, 5)\n\narray([0.51383373, 0.32883263, 0.16402071, 0.13786892, 0.15572435])\n\n\nVerifico il valore atteso di 100,000 realizzazioni di \\({\\mathcal {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).mean()\n\n0.4993283752250098\n\n\nVerifico la varianza di 100,000 realizzazioni di \\({\\mathcal  {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).var()\n\n0.0832097723457758\n\n\n\n1 / 12\n\n0.08333333333333333",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.2 Distribuzione esponenziale",
    "text": "33.2 Distribuzione esponenziale\nUn‚Äôaltra distribuzione di densit√† molto semplice √® la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale √® l‚Äôunica distribuzione di probabilit√† continua che possiede la propriet√† di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinch√© un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si √® rotto dopo 3 anni dal primo utilizzo. L‚Äôassenza di memoria significa che la probabilit√† che questo bicchiere da vino non si rompa nel prossimo anno √® la stessa della probabilit√† che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densit√† esponenziale √®\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{33.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale √®\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale √®\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard √® dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\nPer disegnare un grafico della funzione esponenziale possiamo usare la funzione stats.expon(). La densit√† √® data da pdf(x, loc, scale), laddove il parametro loc √® 0 e scale √® la deviazione standard. Nel caso presente abbiamo:\n\nx = np.arange(0, 20, 0.01)\nmu = 4\nlam = 1 / mu\nstdev = 1 / lam\npdf = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\");\n\n\n\n\n\n\n\n\nChiediamoci, ad esempio, quale sia la probabilit√† di dovere aspettare non pi√π di un giorno e mezzo per conoscere il voto dell‚Äôesame. La risposta a questa domanda √® data dalla funzione di ripartizione in corrispondenza di 1.5, ovvero \\(F(1.5) = P(X \\leq 1.5)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 0) & (x &lt;= 1.5), color=\"0.75\");\n\n\n\n\n\n\n\n\nPossiamo trovare la risposta usando la funzione cdf():\n\nstats.expon.cdf(1.5, loc=0, scale=stdev) \n\n0.3127107212090278\n\n\nChiediamoci, ad esempio quale sia la probabilit√† di conoscere il voto in un tempo compreso tra 1 e 6 giorni. Dobbiamo trovare l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo [1, 6]. Usando la fuzione di ripartizione, calcoliamo \\(F(6) - F(1) = P(X &lt;= 6) - P(X &lt;= 1)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1) & (x &lt;= 6), color=\"0.75\");\n\n\n\n\n\n\n\n\n\nstats.expon.cdf(6, loc=0, scale=stdev) - stats.expon.cdf(1, loc=0, scale=stdev)\n\n0.5556706229229751\n\n\nTroviamo la probabilit√† di dovere aspettare almeno 5 giorni e mezzo.\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 5.5) & (x &lt;= 21), color=\"0.75\");\n\n\n\n\n\n\n\n\nLa probabilit√† cercata √® data dalla probabilit√† dell‚Äôevento complementare di quello fornito dalla funzione di ripartizione.\n\n1 - stats.expon.cdf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\n\nstats.expon.sf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\nSe la media del tempo di attesa nel Corso di Laurea fosse di 4 giorni, allora circa una volta su 4 lo studente dovr√† aspettare almeno 5.5 giorni per conoscere il voto dello scritto.\nLa figura seguente mostra un istogramma di 1000000 valori casuali estratti dalla distribuzione esponenziale di parametro \\(\\lambda = 1/4\\). All‚Äôistogramma √® sovrapposta la funzione di densit√†.\n\nsamps = rng.exponential(stdev, 100000)\n\nplt.figure()\ncount, bins, ignored = plt.hist(samps, bins=100, density=True, alpha=0.5)\nplt.plot(x, fx)\nplt.xlim([0, 20])\nplt.ylabel(\"Frequenza relativa\")\nplt.xlabel(\"Tempo di attesa\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.3 Distribuzione Gaussiana",
    "text": "33.3 Distribuzione Gaussiana\nLa pi√π importante distribuzione di densit√† √® la Gaussiana. Non c‚Äô√® un‚Äôunica distribuzione gaussiana (o Normale): la distribuzione gaussiana √® una famiglia di distribuzioni. Tali distribuzioni sono dette ‚Äúgaussiane‚Äù in onore di Carl Friedrich Gauss (uno dei pi√π grandi matematici della storia il quale, tra le altre cose, scopr√¨ l‚Äôutilit√† di tale funzione di densit√† per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densit√† alle misurazioni dell‚Äôuomo. Karl Pearson us√≤ per primo il termine ‚Äúdistribuzione normale‚Äù anche se ammise che questa espressione ‚Äúha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell‚Äôaltro, non siano normali.‚Äù\n\n33.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre not√≤ che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilit√† di successo di 0.9, la distribuzione √® chiaramente asimmetrica.\n\nn = 10\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist);\n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilit√† di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densit√† di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilit√† binomiale.\n\nn = 1000\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist)\nplt.xlim(850, 950);\n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.4 La Normale prodotta con una simulazione",
    "text": "33.4 La Normale prodotta con una simulazione\nIl libro ‚ÄúRethinking Statistics‚Äù di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo pu√≤ variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall‚Äôorigine, che √® il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non √® possibile determinare la posizione esatta di ogni individuo, ma √® possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall‚Äôorigine.\nAd esempio, √® possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall‚Äôorigine. Queste previsioni sono fattibili perch√© la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sar√† usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando cos√¨ il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps √® un elenco di numeri di passi in cui il codice traccer√† linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array √® riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verr√† utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri della simulazione\nnumero_passi = 16  # Numero di passi per passeggiata\nripetizioni = 1000  # Numero di passeggiate da generare\npunti_da_evidenziare = [4, 8, 16]  # Punti da evidenziare sul grafico\n\n# Inizializza l'array per registrare le passeggiate casuali\nx = np.zeros((numero_passi + 1, ripetizioni))\n\n# Genera le passeggiate casuali\nfor i in range(ripetizioni):\n    passi = rng.uniform(-1, 1, numero_passi)  # Genera passi casuali\n    x[1:, i] = np.cumsum(passi)  # Calcola la posizione cumulativa\n\n# Prepara il grafico\nfig, ax = plt.subplots()\nplt.plot(x, color=\"blue\", alpha=0.05)  # Disegna tutte le passeggiate\nplt.plot(x[:, 0], color=\"black\")  # Evidenzia la prima passeggiata\n\n# Evidenzia i punti specifici\nfor punto in punti_da_evidenziare:\n    plt.axvline(punto, linestyle=\"--\", color=\"black\", alpha=0.5)\n\n# Imposta etichette e aspetti del grafico\nplt.xlabel(\"Numero di passi\")\nplt.ylabel(\"Distanza dall'origine\")\nax.set_xticks(punti_da_evidenziare)\nplt.xlim(0, numero_passi + 0.1)\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota √® che, man mano che procediamo nel numero di passi, le densit√† iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\n# Crea una figura con 3 subplots in orizzontale, condividendo l'asse X\nfig, axs = plt.subplots(1, 3, figsize=(9, 3), sharex=True)\n\n# Itera sui punti da evidenziare e sugli assi corrispondenti\nfor step, ax in zip(punti_da_evidenziare, axs):\n    # Estrae le posizioni al passo specificato per tutte le ripetizioni\n    posizioni_al_passo = x[step, :]\n    \n    az.plot_kde(posizioni_al_passo, bw=0.01, ax=ax)\n    \n    ax.set_title(f\"{step} passi\")\n    ax.set_ylabel(\"Densit√†\")\n    ax.set_xlabel(\"Posizioni\")\n    ax.set_xlim(-6, 6)\n    ax.set_xticks([-6, -3, 0, 3, 6])\n\nplt.tight_layout() \nplt.show()\n\n\n\n\n\n\n\n\nLa chiarezza dell‚Äôinformazione presentata nei grafici precedenti pu√≤ essere migliorata utilizzando un KDE plot.\n\n# Genera la distribuzione uniforme e calcola la somma come prima\npos = rng.uniform(-1, 1, size=(16, 1000)).sum(0)\n\n# Calcola media e deviazione standard dei dati generati\nmedia, dev_std = np.mean(pos), np.std(pos)\n\n# Spazio dei valori per la distribuzione normale\nvalori = np.linspace(np.min(pos), np.max(pos), 1000)\n\n# Calcola la distribuzione normale con la stessa media e deviazione standard\ndistribuzione_normale = stats.norm.pdf(valori, media, dev_std)\n\n# Disegna la stima della densit√† kernel dei dati\naz.plot_kde(pos, label='Distribuzione KDE')\n\n# Sovrappone la distribuzione normale\nplt.plot(valori, distribuzione_normale, label='Distribuzione Normale', color = \"C1\", linestyle='--')\n\nplt.xlabel(\"Posizione\")\nplt.ylabel(\"Densit√†\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilit√†: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che pu√≤ essere uniforme, come nell‚Äôesempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocit√† con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocit√† di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno √® rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana √® quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa pu√≤ essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ci√≤, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni pi√π lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densit√† di probabilit√† √® distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{33.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densit√† normale √® unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densit√† in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell‚Äôeq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densit√† Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 √® fornita nella figura seguente.\n\nx = np.arange(-5, 6, 0.001)\n\nmus = [-1.0, -0.5, 0.0, 1.0]\nsigmas = [0.25, 0.5, 1, 2]\n\nplt.figure()\n\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.norm.pdf(x, mu, sigma)\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n33.4.1 Concentrazione\n√à istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media √® superiore a 3 volte la deviazione standard presenti un carattere di eccezionalit√† perch√© meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n33.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) √® l‚Äôarea sottesa alla curva di densit√† \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilit√† \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEsaminiamo le funzioni per la densit√† Normale. Il metodo rng.normal(loc, scale, size) produce size valori casuali estratti dalla distribuzione Normale specificata. Per esempio, un singolo valore casuale dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\) √®:\n\nrng.normal(loc=100, scale=15, size=1)\n\narray([77.8271813])\n\n\nEstraiamo ora 10 valori a caso dalla \\(\\mathcal{N}(100, 15)\\):\n\nqi = rng.normal(loc=100, scale=15, size=10)\nprint(qi)\n\n[107.37134121  74.33288092  70.05953321 100.16099998  67.01041676\n 102.19573565 114.68076458  58.88627549  69.38274746 112.14401099]\n\n\nPer trovare la probabilit√† che un‚Äôosservazione estratta a caso dalla \\(\\mathcal{N}(100, 15)\\) abbia un valore minore o uguale a, diciamo, 115, troviamo il valore della funzione di ripartizione (o funzione cumulativa di densit√†) nel punto 115.\n\nstats.norm.cdf(115, 100, 15)\n\n0.8413447460685429\n\n\nQuesta √® l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo \\([-\\infty, 115]\\), come indicato nella figura seguente.\n\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\n\nplt.figure()\nplt.plot(x, fx)\n_ = plt.fill_between(x, fx, where=x &lt;= 115, color=\"0.75\")\n\n\n\n\n\n\n\n\nSolo per fare un esempio, qui di seguito fornisco il codice Python per calcolare l‚Äôintegrale che stiamo discutendo per mezzo della funzione quad della libreria SciPy:\n\ndef gaussian(x, mu, sig):\n    return (\n        1.0 / (np.sqrt(2.0 * np.pi) * sig) * np.exp(-np.power((x - mu) / sig, 2.0) / 2)\n    )\n\nmu = 100\nsigma = 15\nresult, error = quad(gaussian, -1000, 115, args=(mu, sigma))\nprint(\"Il risultato √®\", result, \"con errore\", error)\n\nIl risultato √® 0.8413447460685429 con errore 4.0191197364560644e-10\n\n\nIl risultato replica quello prodotto da .norm.cdf().\nPer trovare la proporzione di persone nella popolazione che hanno un QI maggiore di 2 deviazioni standard dalla media consideriamo l‚Äôevento complementare:\n\n1 - stats.norm.cdf(130, 100, 15)\n\n0.02275013194817921\n\n\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=x &gt;= 130, color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo usare la Survival Function:\n\nstats.norm.sf(130, 100, 15)\n\n0.022750131948179198\n\n\nLa funzione ppf restituisce il quantile della Normale. Ad esempio:\n\nstats.norm.ppf(1 - 0.022750131948179195, 100, 15)\n\n130.0\n\n\n\n\n33.4.3 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale √® l‚Äôinsieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL‚Äôarea sottesa alla curva di densit√† di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) √® uguale all‚Äôarea sottesa alla densit√† Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) √® il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l‚Äôarea sottesa nella semiretta \\([1, \\infty)\\) √® uguale all‚Äôarea sottesa nella semiretta \\((-\\infty, 1]\\) e quest‚Äôultima coincide con \\(F(-1)\\). Analogamente, l‚Äôarea sottesa nell‚Äôintervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), √® pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema √® quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato √® detto quantile di ordine \\(p\\) della Normale standard e pu√≤ essere trovato mediante un software.\nSupponiamo che l‚Äôaltezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un‚Äôaltezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l‚Äôarea sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell‚Äôintervallo \\([1.7, 1.8]\\):\n\nstats.norm.cdf(1.8, 1.7, 0.1) - stats.norm.cdf(1.7, 1.7, 0.1)\n\n0.34134474606854315\n\n\n\nmu = 1.7\nsigma = 0.1\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1.7) & (x &lt;= 1.8), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l‚Äôintervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell‚Äôintervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\nstats.norm.cdf(1.0, 0, 1) - stats.norm.cdf(0, 0, 1)\n\n0.3413447460685429\n\n\nIl modo pi√π semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilit√† richiesta non √® altro che la met√† dell‚Äôarea sottesa dalle distribuzioni Normali nell‚Äôintervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l‚Äôinverso della CDF della distribuzione normale.\n\n# Definisco i parametri della distribuzione\nmu = 100\nsigma = 15\n\n# Creo un range di valori su cui calcolare le funzioni\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\n\n# Calcolo la PDF, CDF, e l'inverso della CDF\npdf = stats.norm.pdf(x, mu, sigma)\ncdf = stats.norm.cdf(x, mu, sigma)\nppf = stats.norm.ppf(np.linspace(0.01, 0.99, 100), mu, sigma)  # Evitiamo 0 e 1 per l'inverso\n\n# Creo i grafici in una sola riga\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n# Grafico della PDF\naxs[0].plot(x, pdf, label='PDF')\naxs[0].set_title('PDF')\naxs[0].set_xlabel('Valori')\naxs[0].set_ylabel('Probabilit√†')\naxs[0].legend()\n\n# Grafico della CDF\naxs[1].plot(x, cdf, label='CDF', color='orange')\naxs[1].set_title('CDF')\naxs[1].set_xlabel('Valori')\naxs[1].set_ylabel('Cumulativa')\naxs[1].legend()\n\n# Grafico dell'inverso della CDF\naxs[2].plot(np.linspace(0.01, 0.99, 100), ppf, label='Inverse CDF', color='green')\naxs[2].set_title('Inverse CDF')\naxs[2].set_xlabel('Probabilit√†')\naxs[2].set_ylabel('Valori')\naxs[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalit√† di osservare la stessa informazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.5 Distribuzione Chi-quadrato",
    "text": "33.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libert√† descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libert√†. La densit√† di probabilit√† di \\(\\chi^2_{~\\nu}\\) √®\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) √® una costante positiva.\nLa figura seguente mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\n\nx = np.arange(0, 40, 0.1)\n\nnus = [2, 4, 8, 16]\nplt.figure()\nfor nu in nus:\n    pdf = stats.chi2.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n33.5.1 Propriet√†\n\nLa distribuzione di densit√† \\(\\chi^2_{~\\nu}\\) √® asimmetrica.\nIl valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(\\nu\\).\nLa varianza di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(2\\nu\\).\nPer \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).\nSe \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libert√†, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti.\n\nPer fare un esempio, consideriamo la v.c. \\(\\chi^2_5\\).\n\n# Set the degrees of freedom\ndf = 5\n\n# Create a chi-square distribution object\nchi2_dist = stats.chi2(df)\n\n# Generate x values for the plot\nx = np.linspace(0, 20, 200)\n\n# Calculate the probability density function (PDF) of the chi-square distribution for x values\npdf = chi2_dist.pdf(x)\n\n# Plot the PDF\nplt.figure()\nplt.plot(x, pdf)\nplt.title('Chi-Square Distribution (df=5)')\nplt.xlabel('x')\nplt.ylabel('PDF');\n\n\n\n\n\n\n\n\nGeneriamo 1000000 valori da questa distribuzione.\n\nx = rng.chisquare(5, 1000000)\nx[0:20]\n\narray([3.66284512, 2.96353593, 4.93609572, 4.67151242, 4.10927523,\n       4.16530706, 3.36823832, 9.92342755, 7.02541475, 3.23262943,\n       2.73771833, 3.01973299, 4.83304038, 3.16952063, 5.98040985,\n       6.26951139, 8.73351727, 7.28411818, 7.75225854, 5.77346535])\n\n\nCalcoliamo la media di questi valori.\n\nnp.mean(x)\n\n5.0050584059950385\n\n\nCalcolo la varianza.\n\nnp.var(x, ddof=0)\n\n10.013703149640937",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.6 Distribuzione \\(t\\) di Student",
    "text": "33.6 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un‚Äôaltra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\tag{33.3}\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libert√†. Si usa scrivere \\(T \\sim t_{\\nu}\\). L‚Äôandamento della distribuzione \\(t\\) di Student √® simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code pi√π pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa seguente mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\nx = np.arange(-5, 5, 0.1)\n\nnus = [1, 2, 5, 30]\n\nplt.figure()\nfor nu in nus:\n    pdf = stats.t.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.plot(x, stats.norm.pdf(x, 0, 1), label=\"N(Œº = 0, œÉ = 1)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n33.6.1 Propriet√†\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti propriet√†:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densit√† della \\(t_{\\nu}\\) √® una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto √® sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\).\n\nPer esempio, calcoliamo il valore della funzione di ripartizione di ordine 0.025 nel caso di una \\(t_{30}\\).\n\nstats.t.ppf(0.025, 30)\n\n-2.042272456301238\n\n\nAumentiamo i gradi di libert√†: \\(\\nu\\) = 1000.\n\nstats.t.ppf(0.025, 1000)\n\n-1.9623390808264078\n\n\nQuesto valore √® quasi identico a quello della Normale stanardizzata.\n\nstats.norm.ppf(0.025, 0, 1)\n\n-1.9599639845400545\n\n\nLa ragione per cui il quantile della distribuzione \\(t\\) con \\(\\nu=30\\) √® maggiore (in valore assoluto) del quantile omotetico della distribuzione Normale Standard √® che la distribuzione \\(t\\) ha una varianza maggiore rispetto alla distribuzione Normale Standard.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.7 Funzione Beta di Eulero",
    "text": "33.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero √® una funzione matematica, non una densit√† di probabilit√†. La menzioniamo qui perch√© viene utilizzata nella densit√† di probabilit√† Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si pu√≤ scrivere in molti modi diversi; per i nostri scopi la presentiamo cos√¨:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{33.4}\\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, ovvero il fattoriale discendente, cio√®\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore\n\nalpha = 3\nbeta = 9\nsc.beta(alpha, beta)\n\n0.00202020202020202\n\n\nSi noti che abbiamo usato la funzione beta della libreria scipy.special. Lo stesso risultato si ottiene svolgendo i calcoli in maniera esplicita:\n\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n\n0.00202020202020202\n\n\n\n(math.factorial(alpha-1)*math.factorial(beta-1)) / math.factorial(alpha+beta-1)\n\n0.00202020202020202\n\n\noppure usando la funzione gamma di scipy.special:\n\nsc.gamma(alpha) * sc.gamma(beta) / sc.gamma(alpha + beta)\n\n0.00202020202020202",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.8 Distribuzione Beta",
    "text": "33.8 Distribuzione Beta\nLa distribuzione di probabilit√† Beta, denotata comunemente come \\(Beta(\\alpha, \\beta)\\), √® utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione √® la sua definizione esclusiva nell‚Äôintervallo \\((0, 1)\\). In pratica, ci√≤ significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l‚Äô1 come estremi.\n\n33.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale pu√≤ assumere qualunque valore nell‚Äôintervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densit√† √® descritta dalla seguente formula:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) √® la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n33.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. √à essenziale che entrambi questi parametri siano positivi.\n\n\n33.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta pu√≤ essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilit√† di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilit√† di successo √® un parametro fisso; nella distribuzione Beta, questa probabilit√† diventa una variabile aleatoria.\n\n\n33.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione √® analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall‚Äôaspettativa iniziale della probabilit√† di successo: - Se si presume un‚Äôalta probabilit√† di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa pi√π stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali √® dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un‚Äôillustrazione √® fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\nx = np.linspace(0, 1, 200)\nalphas = [0.5, 5.0, 1.0, 2.0, 2.0]\nbetas = [0.5, 1.0, 3.0, 2.0, 5.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.beta.pdf(x, a, b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.ylim(0, 4.5)\nplt.legend(loc=9);\n\n\n\n\n\n\n\n\n\n\n33.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densit√† di probabilit√† che si estende sull‚Äôintervallo \\([0,1]\\), con l‚Äôarea sottesa dalla curva (l‚Äôintegrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo\n\ndef integrand(p, a, b):\n    return p ** (a - 1) * (1 - p) ** (b - 1)\n\na = 3\nb = 9\nresult, error = quad(integrand, 0, 1, args=(a, b))\nprint(result)\n\n0.00202020202020202\n\n\novvero\n\nresult = (math.gamma(a) * math.gamma(b)) / math.gamma(a + b)\nprint(result)\n\n0.00202020202020202\n\n\novvero, usando la funzione beta di Eulero di scipy.special\n\nsc.beta(a, b)\n\n0.00202020202020202\n\n\n\n\n33.8.6 Propriet√†\nIl valore atteso, la moda e la varianza di una densit√† di probabilit√† Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire la funzione beta_mean_mode_variance() in Python per calcolare la media, la moda e la varianza di una distribuzione di probabilit√† Beta:\n\ndef beta_mean_mode_variance(alpha, beta):\n    mean = alpha / (alpha + beta)\n    mode = (alpha - 1) / (alpha + beta - 2)\n    variance = alpha * beta / ((alpha + beta) ** 2 * (alpha + beta + 1))\n    return mean, mode, variance\n\nPer esempio\n\nalpha = 7\nbeta = 3\nmean, mode, variance = beta_mean_mode_variance(alpha, beta)\nprint(f\"Mean: {mean}, Mode: {mode}, Variance: {variance}\")\n\nMean: 0.7, Mode: 0.75, Variance: 0.019090909090909092\n\n\n\n\n33.8.7 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell‚Äôambito dell‚Äôinferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poich√© permette di bypassare onerose computazioni numeriche tipicamente associate all‚Äôinferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(Œ±, Œ≤), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterr√† la forma funzionale della distribuzione Beta. Ci√≤ significa che, una volta raccolti i dati, l‚Äôaggiornamento a posteriori pu√≤ essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri Œ± e Œ≤ del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (Œ±+x, Œ≤+n-x), senza la necessit√† di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\n√à importante prestare attenzione all‚Äôuso del termine ‚ÄúBeta‚Äù in questo contesto, poich√© assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilit√† continua. - La funzione Beta, una funzione matematica speciale. - Il parametro Œ≤, che insieme ad Œ±, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.9 Distribuzione di Cauchy",
    "text": "33.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy √® un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libert√†. √à definita da una densit√† di probabilit√† che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{33.5}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\nx = np.linspace(-5, 5, 500)\nalphas = [0.0, 0.0, 0.0, -2.0]\nbetas = [0.5, 1.0, 2.0, 1.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.cauchy.pdf(x, loc=a, scale=b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.10 Distribuzione Gamma",
    "text": "33.10 Distribuzione Gamma\nLa densit√† di probabilit√† Gamma √® una distribuzione di probabilit√† continua che gioca un ruolo chiave nella modellazione del tempo di attesa per l‚Äôoccorrenza di un certo numero di eventi indipendenti e rari. Essa √® caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti come parametro di forma e parametro di scala, rispettivamente.\n\n33.10.1 Parametro \\(\\alpha\\) ‚Äì parametro di forma\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione gamma si riduce a una distribuzione esponenziale.\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco attorno a \\((\\alpha - 1) \\cdot \\beta\\).\nSe \\(\\alpha &lt; 1\\), la distribuzione √® inclinata verso destra, mostrando una coda lunga che si estende verso valori pi√π bassi.\n\nIn termini interpretativi, \\(\\alpha\\) rappresenta il numero di eventi che si stanno aspettando. Ad esempio, potrebbe rappresentare il numero di ricordi vividi che ci si aspetta di esperire in un certo periodo di tempo.\n\n\n33.10.2 Parametro \\(\\beta\\) ‚Äì parametro di scala\nIl parametro di scala, \\(\\beta\\), controlla la ‚Äúlarghezza‚Äù della distribuzione:\n\nUn valore pi√π grande di \\(\\beta\\) produce una curva pi√π piatta, indicando una maggiore variabilit√† nel tempo di attesa.\nUn valore pi√π piccolo di \\(\\beta\\) rende la curva pi√π appuntita, indicando una minore variabilit√†.\n\nNel contesto del tempo di attesa, \\(\\beta\\) agisce come una scala temporale, con un valore pi√π grande che indica un periodo di tempo pi√π lungo tra gli eventi, e un valore pi√π piccolo che indica un periodo di tempo pi√π breve.\n\n\n33.10.3 Formula della funzione di densit√† di probabilit√†\nLa formula matematica per la funzione di densit√† di probabilit√† (PDF) della distribuzione gamma √®:\n\\[\nf(x|\\alpha, \\theta) = \\frac{x^{\\alpha-1}e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove,\n\n\\(x\\) √® la variabile casuale continua, con \\(x &gt; 0\\).\n\\(\\theta = \\frac{1}{\\beta}\\).\n\\(\\Gamma(\\alpha)\\) √® la funzione Gamma di Eulero, che estende la nozione di fattoriale ai numeri reali e complessi. Per numeri interi \\(n\\), si ha che \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma √® definita come \\(\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1}e^{-x}dx\\).\n\nLe espressioni per media e varianza della distribuzione Gamma sono le seguenti:\n\nLa media (\\(\\mu\\)) della distribuzione Gamma √® \\(\\mu = \\alpha / \\beta\\), o equivalentemente \\(\\mu = \\alpha \\theta\\), usando il parametro di scala.\nLa varianza (\\(\\sigma^2\\)) della distribuzione Gamma √® \\(\\sigma^2 = \\alpha / \\beta^2\\), o equivalentemente \\(\\sigma^2 = \\alpha \\theta^2\\), adottando il parametro di scala.\n\nQuesto chiarisce la relazione tra i parametri \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso) o \\(\\theta\\) (scala), e come influenzano la distribuzione Gamma.\nPer esempio, qui √® riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\nalpha = 3\nbeta = 5/3\n\nmean = alpha / beta\nprint(mean)\n\n1.7999999999999998\n\n\n\n# Standard deviation = sqrt(alpha / beta^2)\n\nsigma = np.sqrt(alpha / beta**2)\nprint(sigma)\n\n1.0392304845413263\n\n\n\n# Generazione di dati dalla distribuzione Gamma\ndata = rng.gamma(shape=alpha, scale=1/beta, size=100000)\n\n# Plot dell'istogramma dei dati generati\nplt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n\n# Plot della PDF (Probability Density Function) della distribuzione Gamma\nx = np.linspace(0, 10, 1000)\nplt.plot(x, stats.gamma.pdf(x, a=alpha, scale=1/beta), 'r-', lw=2, label='PDF')\n\nplt.xlabel('Valore')\nplt.ylabel('Densit√† di probabilit√†')\nplt.title('Distribuzione Gamma con alpha=3 e beta=5/3')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-log-normale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-log-normale",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.11 Distribuzione log-normale",
    "text": "33.11 Distribuzione log-normale\nSia \\(y\\) una variabile casuale avente distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo poi una nuova variabile casuale \\(x\\) attraverso la relazione\n\\[\nx = e^y \\quad \\Longleftrightarrow \\quad y = \\log x.\n\\]\nIl dominio di definizione della \\(x\\) √® il semiasse \\(x &gt; 0\\) e la densit√† di probabilit√† \\(f(x)\\) √® data da\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\frac{1}{x} \\exp \\left\\{-\\frac{(\\log x -  \\mu)^2}{2 \\sigma^2} \\right\\}.\n\\tag{33.6}\\]\nQuesta funzione di densit√† √® chiamata log-normale.\nIl valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(x) = \\exp \\left\\{\\mu + \\frac{\\sigma^2}{2} \\right\\}.\n\\]\n\\[\n\\mathbb{V}(x) = \\exp \\left\\{2 \\mu + \\sigma^2 \\right\\} \\left(\\exp \\left\\{\\sigma^2 \\right\\}  -1\\right).\n\\]\nSi puoÃÄ dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale.\nLa figura mostra tre distribuzioni log-normali con \\(\\mu\\) = 0.0 e \\(\\sigma\\) = .25, .5, 1.0.\n\nx = np.linspace(0, 3, 100)\nmus = [0.0, 0.0, 0.0]\nsigmas = [0.25, 0.5, 1.0]\nplt.figure()\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.lognorm.pdf(x, sigma, scale=np.exp(mu))\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/12_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.12 Commenti e considerazioni finali",
    "text": "33.12 Commenti e considerazioni finali\nLa statistica bayesiana impiega le distribuzioni di probabilit√† come motore inferenziale per la stima dei parametri e dell‚Äôincertezza. Immaginiamo che le distribuzioni di probabilit√† siano piccoli pezzi di ‚ÄúLego‚Äù con cui possiamo costruire qualsiasi cosa desideriamo. Questo principio si applica analogamente ai modelli statistici bayesiani. Possiamo costruire modelli che vanno dai pi√π semplici ai pi√π complessi, utilizzando le distribuzioni di probabilit√† e le loro interrelazioni.\nPython, oltre al modulo stats, offre la capacit√† di generare campioni casuali da varie distribuzioni di probabilit√† attraverso il generatore di numeri casuali disponibile in NumPy. Dopo aver importato NumPy con il comando:\nimport numpy as np\n√® possibile inizializzare il generatore di numeri casuali (rng) con un valore di seme (seed) specifico, garantendo cos√¨ la riproducibilit√† degli esperimenti:\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nA questo punto, si possono generare campioni da diverse distribuzioni di probabilit√†. Ad esempio, per generare un campione dalla distribuzione normale (gaussiana), si pu√≤ procedere nel seguente modo:\nmedia, deviazione_standard = 0, 1  # Valori per media e deviazione standard\ncampione_normale = rng.normal(media, deviazione_standard, size=100)\nIn questo esempio, size=100 indica che vogliamo generare un campione di 100 valori dalla distribuzione. Analogamente, si possono generare campioni da altre distribuzioni di probabilit√† specificando i relativi parametri:\nDistribuzione Uniforme: Per generare valori da una distribuzione uniforme, definita in un intervallo da a a b, si pu√≤ usare:\na, b = 0, 10  # Estremi dell'intervallo\ncampione_uniforme = rng.uniform(a, b, size=100)  # Aggiunta del parametro 'size'\nDistribuzione t di Student: Per ottenere valori dalla distribuzione t di Student, con un dato numero di gradi di libert√†:\ngradi_libert√† = 10  # Gradi di libert√†\ncampione_t = rng.standard_t(gradi_libert√†, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Beta: Per la distribuzione Beta, specificando i parametri alpha e beta:\nalpha, beta = 2, 5  # Parametri alpha e beta\ncampione_beta = rng.beta(alpha, beta, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Gamma: Infine, per generare un campione dalla distribuzione Gamma, con i parametri di forma e scala:\nforma, scala = 2, 1  # Parametri di forma e scala\ncampione_gamma = rng.gamma(forma, scala, size=100)  # Aggiunta del parametro 'size'\nIn tutti i casi, l‚Äôaggiunta del parametro size consente di specificare la dimensione del campione desiderato.\nPer analizzare le propriet√† statistiche di diverse distribuzioni di probabilit√†, oltre alla generazione di campioni casuali, si utilizzano le funzioni di densit√† di probabilit√† (PDF), le funzioni di ripartizione cumulativa (CDF) e le funzioni quantili. Queste operazioni possono essere effettuate efficacemente utilizzando la libreria SciPy in Python.\nPer determinare la funzione densit√† di probabilit√† (PDF), la quale rappresenta la probabilit√† relativa di osservare un valore all‚Äôinterno di un intervallo continuo, il procedimento √® il seguente. Per la distribuzione normale, ad esempio:\nimport numpy as np\nfrom scipy.stats import norm, uniform, t, beta, gamma\n\nmedia, deviazione_standard = 0, 1\nx = np.linspace(media - 4*deviazione_standard, media + 4*deviazione_standard, 100)\npdf_normale = norm.pdf(x, loc=media, scale=deviazione_standard)\nSimili operazioni possono essere effettuate per altre distribuzioni, come mostrato di seguito:\nDistribuzione Uniforme:\na, b = 0, 10\nx = np.linspace(a, b, 100)\npdf_uniforme = uniform.pdf(x, loc=a, scale=b-a)\nDistribuzione t di Student:\ngradi_libert√† = 10\nx = np.linspace(-5, 5, 100)\npdf_t = t.pdf(x, df=gradi_libert√†)\nDistribuzione Beta:\nalpha, beta_param = 2, 5\nx = np.linspace(0, 1, 100)\npdf_beta = beta.pdf(x, alpha, beta_param)\nDistribuzione Gamma:\nforma, scala = 2, 1\nx = np.linspace(0, 10, 100)\npdf_gamma = gamma.pdf(x, a=forma, scale=scala)\nPer determinare i quantili, ovvero i valori corrispondenti a specifiche probabilit√† cumulate nella funzione di distribuzione, si utilizza la funzione ppf (Percent Point Function). Ad esempio, per la distribuzione normale:\nprobabilit√† = 0.5\nquantile_normale = norm.ppf(probabilit√†, loc=media, scale=deviazione_standard)\nE per le altre distribuzioni:\nDistribuzione Uniforme:\nquantile_uniforme = uniform.ppf(probabilit√†, loc=a, scale=b-a)\nDistribuzione t di Student:\nquantile_t = t.ppf(probabilit√†, df=gradi_libert√†)\nDistribuzione Beta:\nquantile_beta = beta.ppf(probabilit√†, alpha, beta_param)\nDistribuzione Gamma:\nquantile_gamma = gamma.ppf(probabilit√†, a=forma, scale=scala)\nInfine, per calcolare la probabilit√† cumulativa associata a un dato quantile (ovvero la probabilit√† che una variabile casuale sia minore o uguale a quel quantile), si utilizza la funzione cdf (Cumulative Distribution Function). Questo permette di determinare la probabilit√† che si verifichi un evento entro un certo intervallo di valori per la distribuzione considerata. Ad esempio, per la distribuzione normale:\nquantile = 0\nprobabilit√†_normale = norm.cdf(quantile, loc=media, scale=deviazione_standard)\nE analogamente per le altre distribuzioni:\nDistribuzione Uniforme:\nprobabilit√†_uniforme = uniform.cdf(quantile, loc=a, scale=b-a)\nDistribuzione t di Student:\nprobabilit√†_t = t.cdf(quantile, df=gradi_libert√†)\nDistribuzione Beta:\nprobabilit√†_beta = beta.cdf(quantile, alpha, beta_param)\nDistribuzione Gamma:\nprobabilit√†_gamma = gamma.cdf(quantile, a=forma, scale=scala)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "33¬† Distribuzioni di v.c. continue",
    "section": "33.13 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "33.13 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\npandas    : 2.2.1\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html",
    "href": "chapters/probability/13_likelihood.html",
    "title": "34¬† La verosimiglianza",
    "section": "",
    "text": "Introduzione\nOltre agli approcci frequentisti e bayesiani, esiste un terzo metodo fondamentale nell‚Äôambito dell‚Äôinferenza statistica: la metodologia basata sulla verosimiglianza. Questo approccio consente ai ricercatori di valutare l‚Äôevidenza relativa quando si confrontano due modelli o ipotesi, in maniera simile alla metodologia bayesiana. Ci√≤ che lo distingue √® il suo esplicito rifiuto di incorporare informazioni pregresse (priori) nelle analisi statistiche.\nQuesto capitolo si concentra sulla funzione di verosimiglianza, concetto centrale che si estende attraverso tutti e tre gli approcci statistici, fungendo da collegamento tra i dati osservati e i parametri di un modello statistico specifico. La rilevanza della funzione di verosimiglianza risiede nella sua capacit√† di fornire un fondamento robusto per l‚Äôinterpretazione e la quantificazione dell‚Äôadeguatezza dei dati ai modelli teorici. Questo la rende uno strumento cruciale per l‚Äôinferenza statistica, indispensabile per comprendere e valutare la conformit√† dei dati rispetto alle teorie proposte.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/13_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "34¬† La verosimiglianza",
    "section": "34.1 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "34.1 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza e la funzione di densit√† (o massa) di probabilit√† sono due concetti fondamentali in statistica che, nonostante condividano la stessa espressione matematica, rivestono ruoli e interpretazioni distinti a seconda del contesto in cui vengono applicati. La chiave per distinguere tra i due concetti risiede nel modo in cui trattiamo i dati e i parametri del modello.\nNel caso della funzione di densit√† (o massa) di probabilit√†, i parametri del modello sono fissati e l‚Äôobiettivo √® valutare la probabilit√† di osservare un certo insieme di dati. Qui, i dati sono variabili, mentre i parametri sono considerati costanti. Per esempio, in un esperimento in cui lanciamo una moneta diverse volte, potremmo usare una distribuzione binomiale per calcolare la probabilit√† di ottenere un certo numero di teste, assumendo un valore noto e fisso per la probabilit√† di ottenere testa in un singolo lancio.\nAl contrario, nella funzione di verosimiglianza, manteniamo i dati osservati come fissi e variamo i parametri del modello per valutare quanto bene questi ultimi si adattino ai dati osservati. Questo processo ci permette di esplorare la plausibilit√† di diversi valori dei parametri dati gli stessi dati. L‚Äôobiettivo √® identificare il set di parametri che meglio spiega i dati osservati.\nFormalmente, la relazione tra la funzione di verosimiglianza e la funzione di densit√† di probabilit√† √® espressa come segue:\n\\[\nL(\\theta | y) \\propto p(y | \\theta),\n\\]\ndove \\(L(\\theta | y)\\) rappresenta la funzione di verosimiglianza per i parametri \\(\\theta\\) dati gli osservazioni \\(y\\), e \\(p(y | \\theta)\\) indica la probabilit√† (o densit√†) di osservare i dati \\(y\\) dato un certo set di parametri \\(\\theta\\).\nPrendiamo l‚Äôesempio del lancio di una moneta. Se osserviamo 7 teste su 10 lanci, la funzione di massa di probabilit√† della distribuzione binomiale ci permette di calcolare la probabilit√† di questo esito per un dato valore di \\(p\\) (la probabilit√† di testa). In questo contesto, \\(p\\) √® fisso e i dati (\\(y = 7\\) teste in \\(n = 10\\) lanci) sono variabili.\nDall‚Äôaltro lato, se consideriamo \\(p\\) variabile, la funzione di verosimiglianza ci permette di valutare come diversi valori di \\(p\\) si adattano all‚Äôesito osservato di 7 teste su 10 lanci, mantenendo i dati osservati fissi.\n√à importante sottolineare che, bench√© le due funzioni condividano la stessa forma matematica, il loro utilizzo e interpretazione sono profondamente diversi. La funzione di densit√† di probabilit√† si concentra sulla probabilit√† degli esiti dati i parametri, mentre la funzione di verosimiglianza valuta la plausibilit√† dei parametri dati gli esiti. Questa distinzione √® cruciale per l‚Äôinferenza statistica, permettendoci di stimare i parametri del modello che meglio si adattano ai dati osservati e di comprendere in modo pi√π approfondito la struttura e le caratteristiche del fenomeno studiato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/13_likelihood.html#verosimiglianza-binomiale",
    "title": "34¬† La verosimiglianza",
    "section": "34.2 Verosimiglianza Binomiale",
    "text": "34.2 Verosimiglianza Binomiale\nProseguendo con l‚Äôesempio della distribuzione binomiale, approfondiamo la rilevanza della funzione di verosimiglianza nell‚Äôanalisi statistica attraverso uno scenario pratico. Supponiamo di condurre un esperimento con un numero definito di prove \\(n\\), ognuna delle quali pu√≤ terminare con un successo o un fallimento, come nel caso dei lanci di una moneta. Se registriamo \\(y\\) successi e \\(n - y\\) fallimenti, la probabilit√† di osservare esattamente \\(y\\) successi segue la funzione di massa di probabilit√† (FMP) binomiale, che √® definita come:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\theta\\) √® la probabilit√† di successo in una singola prova di Bernoulli.\nNell‚Äôutilizzo della funzione di verosimiglianza, ci concentriamo su come i diversi valori di \\(\\theta\\) possono spiegare i dati osservati \\(y\\). La verosimiglianza √® espressa come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y},\n\\]\ndato che il coefficiente binomiale \\(\\binom{n}{y}\\), non dipendendo da \\(\\theta\\), pu√≤ essere omesso per la semplicit√† della formulazione.\n\nEsempio 34.1 Per esemplificare, immaginiamo uno studio su un gruppo di 30 individui, di cui 23 presentano un atteggiamento negativo verso il futuro, un indicatore comune in pazienti con depressione (Zetsche, Buerkner, e Renneberg 2019). Qui, i nostri dati \\(y\\) e \\(n\\) sono fissi, e la funzione di verosimiglianza per \\(\\theta\\) sconosciuto diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} (1 - \\theta)^7.\n\\]\nValutando questa funzione per una serie di valori di \\(\\theta\\) possiamo determinare quale valore di \\(\\theta\\) rende i dati osservati pi√π verosimili. Procediamo simulando 100 valori equidistanti di \\(\\theta\\) nell‚Äôintervallo [0, 1] e calcoliamo la verosimiglianza per ciascuno di questi valori.\n\nn = 30\ny = 23\n\nCreiamo i possibili valori del parametro \\(\\theta\\) per i quali calcoleremo la verosimiglianza.\n\ntheta = np.linspace(0.0, 1.0, num=100)\nprint(theta)\n\n[0.         0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n 0.06060606 0.07070707 0.08080808 0.09090909 0.1010101  0.11111111\n 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n 0.18181818 0.19191919 0.2020202  0.21212121 0.22222222 0.23232323\n 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n 0.3030303  0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n 0.36363636 0.37373737 0.38383838 0.39393939 0.4040404  0.41414141\n 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.5959596\n 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n 0.66666667 0.67676768 0.68686869 0.6969697  0.70707071 0.71717172\n 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n 0.78787879 0.7979798  0.80808081 0.81818182 0.82828283 0.83838384\n 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.8989899\n 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n 0.96969697 0.97979798 0.98989899 1.        ]\n\n\nPer esempio, ponendo \\(\\theta = 0.1\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.1)\n\n9.7371682902e-18\n\n\nPonendo \\(\\theta = 0.2\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.2)\n\n3.58141723492221e-11\n\n\nSe ripetiamo questo processo 100 volte, una volta per ciascuno dei valori \\(\\theta\\) che abbiamo elencato sopra, otteniamo 100 coppie di punti \\(\\theta\\) e \\(f(\\theta)\\). A tale fine, definiamo la seguente funzione.\n\ndef like(r, n, theta):\n    return math.comb(n, r) * theta**r * (1 - theta) ** (n - r)\n\nLa curva che interpola i punti ottenuti √® la funzione di verosimiglianza, come indicato dalla figura seguente.\n\nplt.figure()\nplt.plot(theta, like(r=y, n=n, theta=theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");\n\n\n\n\n\n\n\n\n\n\n34.2.1 Interpretazione della Funzione di Verosimiglianza\nL‚Äôinterpretazione della funzione di verosimiglianza ci permette di misurare l‚Äôadattamento dei vari valori di \\(\\theta\\) ai dati. Il valore che massimizza la funzione indica la stima pi√π plausibile di \\(\\theta\\) dati i dati osservati. In termini pratici, se per esempio il valore che massimizza la verosimiglianza √® \\(\\theta = 0.767\\), ci√≤ suggerisce che la probabilit√† pi√π plausibile di successo (o atteggiamento negativo) nella nostra popolazione di studio √® del 76.7%.\nLa determinazione numerica di questo valore ottimale pu√≤ avvenire attraverso tecniche computazionali, come l‚Äôidentificazione del punto di massimo della funzione di verosimiglianza tramite metodi di ottimizzazione. L‚Äôuso di librerie statistiche e matematiche in linguaggi di programmazione come Python consente di effettuare queste analisi con precisione e efficienza, offrendo una stima accurata del parametro \\(\\theta\\) che meglio si adatta ai dati osservati.\nQuesta metodologia, basata sull‚Äôuso della funzione di verosimiglianza, √® cruciale per l‚Äôinferenza statistica, permettendo agli scienziati di stimare i parametri dei modelli statistici in modo informato e di valutare l‚Äôadeguatezza di tali modelli in rappresentanza dei dati reali.\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si pu√≤ localizzare l‚Äôindice nel vettore dei valori di verosimiglianza dove questa raggiunge il suo picco. Metodi computazionali, come l‚Äôuso della funzione argmax in NumPy, possono automatizzare questo processo. Una volta individuato l‚Äôindice che massimizza la verosimiglianza, si pu√≤ risalire al valore corrispondente di \\(\\theta\\) nel vettore dei parametri, ottenendo cos√¨ la stima di \\(\\theta\\) che rende i dati osservati pi√π plausibili.\n\nl = like(r=y, n=n, theta=theta)\nl.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\n√à importante notare che, invece di utilizzare la funzione like() che abbiamo definito precedentemente per motivi didattici, √® possibile ottenere lo stesso risultato utilizzando in modo equivalente la funzione binom.pmf().\n\nplt.figure()\nplt.plot(theta, stats.binom.pmf(y, n, theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#massima-verosimiglianza",
    "href": "chapters/probability/13_likelihood.html#massima-verosimiglianza",
    "title": "34¬† La verosimiglianza",
    "section": "34.3 Massima verosimiglianza",
    "text": "34.3 Massima verosimiglianza\nTra tutti i possibili valori \\(\\theta\\) cerchiao il valore che massimizzi la probabilit√† dei dati osservati, ovvero, cerchiamo il valore \\(\\theta\\) che corrisponde al massimo della funzione di verosimiglianza.\nParliamo di ‚Äúminimizzazione‚Äù quando l ‚Äôobiettivo √® trovare il punto pi√π basso in una valle (minimizzare) o di ‚Äúmassimizzazione‚Äù, quando l‚Äôobiettivo √® quello di trovare il punto pi√π alto su una collina, a seconda della funzione. Nel caso della funzione di verosimiglianza, cerchiamo il punto in cui questa funzione raggiunge il suo valore massimo, ma poich√© molti algoritmi sono progettati per trovare minimi, possiamo cercare il minimo del negativo della funzione di verosimiglianza, che corrisponde al massimo della funzione stessa.\nLa Strategia di Base\n\nPunto di Partenza: L‚Äôalgoritmo inizia da un punto di partenza, che pu√≤ essere scelto casualmente o basato su una qualche ipotesi ragionevole.\nEsplorazione: L‚Äôalgoritmo esplora la ‚Äúsuperficie‚Äù della funzione, muovendosi in direzioni che sembrano portare verso il punto pi√π basso (o pi√π alto, se stiamo massimizzando). Questo √® simile a sentire la pendenza del terreno intorno a noi per decidere in quale direzione camminare.\nAggiustamento: Man mano che procede, l‚Äôalgoritmo aggiusta la sua traiettoria basandosi su ci√≤ che ha ‚Äúsentito‚Äù durante l‚Äôesplorazione. Se trova una discesa, continua in quella direzione; se incontra una salita, prova una direzione differente.\nConvergenza: Il processo continua finch√© l‚Äôalgoritmo non trova un punto in cui non ci sono pi√π discese significative in nessuna direzione, suggerendo che ha trovato il punto pi√π basso (o il punto pi√π alto, se stiamo massimizzando) raggiungibile da quel percorso.\n\nEsistono diversi metodi che l‚Äôalgoritmo pu√≤ utilizzare per decidere come muoversi. Alcuni esempi includono:\n\nDiscesa pi√π ripida (Gradient Descent): Utilizza il gradiente (la direzione e la pendenza della collina) per decidere in quale direzione muoversi.\nNewton-Raphson: Utilizza sia il gradiente sia la ‚Äúcurvatura‚Äù della funzione per fare passi pi√π informati verso il minimo.\nAlgoritmi Genetici: Ispirati dall‚Äôevoluzione biologica, questi algoritmi ‚Äúevolvono‚Äù una soluzione attraverso iterazioni che simulano la selezione naturale.\n\nIn termini intuitivi, dunque, l‚Äôottimizzazione √® un processo metodico di esplorazione e aggiustamento basato su feedback immediato dalla funzione che stiamo cercando di ottimizzare, con l‚Äôobiettivo di trovare il punto di massimo o minimo valore.\nDefiniamo dunque il negativo della funzione di verosimiglianza per l‚Äôottimizzazione (trovare il massimo della funzione):\n\ndef negative_likelihood(theta, n, y):\n    # Calcolo del negativo della funzione di verosimiglianza\n    return - (math.comb(n, y) * theta**y * (1 - theta) ** (n - y))\n\nUtilizziamo ora scipy.optimize.minimize per trovare il valore di theta che massimizza la verosimiglianza. Bisogna specificare un valore iniziale per theta, qui assumiamo 0.5 come punto di partenza. I vincoli su theta sono che deve essere compreso tra 0 e 1.\n\nresult = minimize(negative_likelihood, x0=0.5, args=(n, y), bounds=[(0, 1)])\nresult.x\n\narray([0.76666666])\n\n\n\n34.3.1 La Funzione di Log-Verosimiglianza\nProseguendo con il nostro approfondimento sull‚Äôanalisi statistica mediante la funzione di verosimiglianza, ci spostiamo verso una sua trasformazione matematica spesso preferita dagli statistici: la funzione di log-verosimiglianza. Il passaggio alla log-verosimiglianza, definita come il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y),\n\\tag{34.1}\\]\nnon altera la posizione del massimo della funzione originale grazie alla propriet√† di monotonicit√† del logaritmo. In termini pratici, ci√≤ significa che il valore di \\(\\theta\\) che massimizza la log-verosimiglianza, \\(\\hat{\\theta}\\), √® lo stesso che massimizza la verosimiglianza originale:\n\\[\n\\hat{\\theta} = \\arg \\max_{\\theta \\in \\Theta} \\ell(\\theta) = \\arg \\max_{\\theta \\in \\Theta} \\mathcal{L}(\\theta).\n\\]\nNell‚Äôanalisi di un campione di osservazioni, l‚Äôuso della log-verosimiglianza semplifica il processo di massimizzazione, che pu√≤ risultare complicato con la verosimiglianza tradizionale, soprattutto quando si gestiscono numeri molto piccoli. Questa semplificazione avviene perch√© la log-verosimiglianza trasforma il prodotto delle probabilit√† in una somma di logaritmi, rendendo il problema pi√π semplice e numericamente stabile. L‚Äôespressione della log-verosimiglianza per un modello binomiale, ad esempio, si presenta come segue:\n\\[\n\\ell(\\theta \\mid y) = \\log(\\theta^y (1 - \\theta)^{n - y}) = y \\log(\\theta) + (n - y) \\log(1 - \\theta).\n\\]\nQuesta formulazione trasforma il prodotto delle probabilit√† di osservazioni indipendenti in una somma, facilitando notevolmente i calcoli, specialmente per dataset di grandi dimensioni o in presenza di calcoli complessi. La forma logaritmica √® pi√π gestibile e si presta meglio all‚Äôapplicazione di tecniche di ottimizzazione numerica, grazie alla sua maggiore stabilit√† e alla riduzione di problemi come l‚Äôunderflow, comuni quando si lavora con probabilit√† molto piccole.\nRitornando all‚Äôesempio della distribuzione binomiale, l‚Äôapplicazione della log-verosimiglianza per il calcolo del parametro \\(\\theta\\) che meglio si adatta ai dati osservati pu√≤ essere eseguita con efficienza attraverso metodi computazionali. Per esempio, l‚Äôutilizzo di funzioni specifiche disponibili in pacchetti statistici, come binom.logpmf() in Python, permette di calcolare direttamente la log-verosimiglianza di un dato set di osservazioni per diversi valori di \\(\\theta\\). Questo approccio facilita la ricerca del valore di \\(\\theta\\) che massimizza la log-verosimiglianza, fornendo una stima accurata e computazionalmente efficiente del parametro.\nL‚Äôadozione della funzione di log-verosimiglianza, quindi, non solo consente di affrontare i limiti pratici legati alla manipolazione di piccole probabilit√†, ma offre anche un quadro concettuale chiaro per l‚Äôinterpretazione della plausibilit√† dei parametri del modello alla luce dei dati osservati. Questa trasformazione logaritmica rappresenta un passaggio cruciale nell‚Äôanalisi inferenziale, consentendo di stimare i parametri dei modelli statistici con maggiore precisione e affidabilit√†.\nPer illustrare questo concetto, riprendiamo l‚Äôesempio precedente e applichiamo la funzione di log-verosimiglianza per identificare il valore di $ $ che massimizza questa funzione. La rappresentazione grafica della funzione di log-verosimiglianza fornisce ulteriori intuizioni sul comportamento di questa funzione.\n\nn = 30\nr = 23\nplt.figure()\nplt.plot(theta, stats.binom.logpmf(y, n, theta), \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Log-verosimiglianza\");\n\n\n\n\n\n\n\n\nIl risultato replica quello trovato in precedenza con la funzione di verosimiglianza.\n\nll = stats.binom.logpmf(y, n, theta)\nll.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\nDefinizione della funzione del negativo della log-verosimiglianza con correzioni per evitare errori di dominio:\n\ndef corrected_negative_log_likelihood(theta, n, y):\n    # Assicurarsi che theta sia all'interno di un intervallo valido per evitare errori di logaritmo\n    theta = np.clip(theta, 1e-10, 1-1e-10)\n    return - (y * np.log(theta) + (n - y) * np.log(1 - theta))\n\nUtilizzo di scipy.optimize.minimize per trovare il valore di theta che massimizza la log-verosimiglianza:\n\nresult_log_likelihood_corrected = minimize(\n    corrected_negative_log_likelihood, x0=[0.5], args=(n, y), bounds=[(0, 1)]\n)\n\n\n# Il risultato ottimizzato per theta utilizzando la log-verosimiglianza corretta\noptimized_theta = result_log_likelihood_corrected.x\noptimized_theta\n\narray([0.76666666])\n\n\n\n\n34.3.2 Verosimiglianza Congiunta\nProseguendo nella nostra esplorazione dell‚Äôinferenza statistica attraverso la funzione di verosimiglianza, ci concentriamo ora sul caso in cui abbiamo pi√π osservazioni, tutte provenienti dalla stessa distribuzione binomiale e considerate indipendenti ed identicamente distribuite (IID). Tale scenario si presenta frequentemente nelle applicazioni pratiche, dove un insieme di \\(n\\) osservazioni \\(Y = [y_1, y_2, \\ldots, y_n]\\) viene raccolto sotto le stesse condizioni sperimentali.\nLa chiave per analizzare queste osservazioni congiuntamente risiede nel calcolo della probabilit√† congiunta di \\(y_1, y_2, \\ldots, y_n\\) data un‚Äôunica probabilit√† di successo \\(\\theta\\) comune a tutte le prove. L‚Äôindipendenza delle osservazioni ci consente di esprimere questa probabilit√† congiunta come il prodotto delle probabilit√† individuali di ciascuna osservazione:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa bellezza di questo approccio sta nel fatto che la verosimiglianza congiunta, che rappresenta la plausibilit√† complessiva di \\(\\theta\\) data l‚Äôintera sequenza di osservazioni \\(Y\\), √® semplicemente il prodotto delle verosimiglianze individuali di ogni osservazione \\(y_i\\) rispetto a \\(\\theta\\):\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta formulazione della verosimiglianza congiunta non solo evidenzia quanto bene il parametro \\(\\theta\\) si adatta all‚Äôintero set di dati \\(Y\\), ma offre anche una base metodologica solida per stimare \\(\\theta\\). Il parametro che massimizza la verosimiglianza congiunta, noto come stimatore di massima verosimiglianza (MLE) di \\(\\theta\\), √® quello che si ritiene essere il pi√π plausibile data l‚Äôosservazione dei dati.\nQuando abbiamo pi√π gruppi di osservazioni bernoulliane indipendenti ed identicamente distribuite (iid), la funzione di log-verosimiglianza congiunta per tutti i gruppi pu√≤ essere espressa come la somma delle log-verosimiglianze di ciascun gruppo. Ci√≤ √® dovuto alla propriet√† che il logaritmo del prodotto √® la somma dei logaritmi.\nSupponiamo di avere i seguenti dati per 4 gruppi di osservazioni:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 21 successi\nGruppo 3: 40 prove con 31 successi\nGruppo 4: 36 prove con 29 successi\n\nLa funzione di log-verosimiglianza congiunta per questi dati, assumendo una singola probabilit√† di successo \\(\\theta\\) per tutti i gruppi, √® data da:\n\\[\n\\log L(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove \\(n_i\\) e \\(y_i\\) sono rispettivamente il numero di prove e il numero di successi nel \\(i\\)-esimo gruppo.\nPer trovare il valore di \\(\\theta\\) che massimizza questa funzione di log-verosimiglianza, possiamo usare il metodo di ottimizzazione scipy.optimize.minimize, come abbiamo fatto in precedenza. Definiamo prima la funzione di log-verosimiglianza congiunta (usiamo np.clip per evitare errori):\n\ndef log_verosimiglianza_congiunta(theta, dati):\n    theta = np.clip(theta, 1e-10, 1-1e-10)  # Evita valori esattamente 0 o 1\n    log_likelihood = 0\n    for n, y in dati:\n        log_likelihood += y * np.log(theta) + (n - y) * np.log(1 - theta)\n    return -log_likelihood  # Restituisce il negativo per l'ottimizzazione\n\n\n# Dati dei gruppi: (prove, successi)\ndati_gruppi = [(30, 23), (28, 20), (40, 29), (36, 29)]\nprint(dati_gruppi)\n\n[(30, 23), (28, 20), (40, 29), (36, 29)]\n\n\nOttimizzazione con la funzione log_verosimiglianza_congiunta\n\nresult = minimize(\n    log_verosimiglianza_congiunta, x0=[0.5], args=(dati_gruppi,), bounds=[(0, 1)]\n)\n\n# Il risultato ottimizzato per theta con la funzione corretta\nresult.x\n\narray([0.75373134])\n\n\n\n# Intervallo di valori di theta da esplorare\ntheta_values = np.linspace(0.01, 0.99, 100)\n\n# Calcolo dei valori di log-verosimiglianza per ogni theta\nlog_likelihood_values = [log_verosimiglianza_congiunta(theta, dati_gruppi) for theta in theta_values]\n\n# Creazione del grafico\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, log_likelihood_values, label='Log-verosimiglianza')\nplt.xlabel('Theta')\nplt.ylabel('Log-verosimiglianza negativa')\nplt.title('Funzione di Log-verosimiglianza')\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/13_likelihood.html#la-verosimiglianza-marginale",
    "title": "34¬† La verosimiglianza",
    "section": "34.4 La Verosimiglianza Marginale",
    "text": "34.4 La Verosimiglianza Marginale\nAvanzando nella nostra discussione sulla verosimiglianza, approfondiamo ora un passaggio cruciale nell‚Äôapplicazione della teoria bayesiana: il concetto di verosimiglianza marginale. Questo approccio si rivela essenziale quando affrontiamo situazioni in cui il parametro di interesse, \\(\\theta\\), non √® definito da un valore singolo e fisso, ma √® invece descritto da una distribuzione di probabilit√† che riflette la nostra incertezza o variabilit√† su di esso.\nIn contesti pratici, non √® raro incontrare scenari in cui \\(\\theta\\) pu√≤ assumere una gamma di valori, ciascuno con una probabilit√† associata, piuttosto che un valore deterministico. L‚Äôintegrazione del parametro \\(\\theta\\) permette di calcolare la probabilit√† complessiva (o verosimiglianza) di osservare un determinato risultato dati tutti i possibili valori di \\(\\theta\\), piuttosto che appoggiarsi a un‚Äôanalisi basata su un singolo valore di \\(\\theta\\).\nConsideriamo, per esempio, una situazione in cui stiamo osservando una sequenza di prove binomiali, con un risultato specifico di interesse (ad esempio, \\(k=7\\) successi su \\(n=10\\) prove). Se \\(\\theta\\) rappresenta la probabilit√† di successo in ciascuna prova e pu√≤ assumere un insieme discreto di valori (per esempio, 0.1, 0.5, e 0.9) con probabilit√† uniforme, la verosimiglianza di osservare il nostro risultato specifico pu√≤ essere espressa come:\n\\[p(k=7, n=10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta),\\]\ndove \\(p(\\theta)\\) rappresenta la probabilit√† associata a ciascun possibile valore di \\(\\theta\\).\nTuttavia, in molte applicazioni reali, \\(\\theta\\) pu√≤ variare continuamente all‚Äôinterno di un intervallo, come tra 0 e 1 per una distribuzione binomiale. In questi casi, il calcolo della verosimiglianza marginale richiede l‚Äôutilizzo dell‚Äôintegrazione su tutto lo spazio dei valori possibili di \\(\\theta\\), riflettendo la gamma continua di possibili probabilit√† di successo. La formula si estende quindi a:\n\\[p(k=7, n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta) d\\theta,\\]\ndove \\(p(\\theta) d\\theta\\) rappresenta la densit√† di probabilit√† di \\(\\theta\\) su un intervallo infinitesimale, e l‚Äôintegrale copre tutti i possibili valori di \\(\\theta\\) da 0 a 1. Implementare questo calcolo nell‚Äôambito di uno spazio continuo richiede l‚Äôutilizzo di tecniche di integrazione.\nVediamo come sia possibile eseguire questo calcolo in Python, utilizzando la libreria scipy per l‚Äôintegrazione su uno spazio continuo:\n\n# Definire la funzione di verosimiglianza\ndef likelihood(theta):\n    return stats.binom.pmf(k=7, n=10, p=theta)\n\n# Calcolare la verosimiglianza marginale integrando su Œ∏\nmarginal_likelihood, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(\"La verosimiglianza marginale √®:\", marginal_likelihood)\n\nLa verosimiglianza marginale √®: 0.09090909090909094\n\n\nQuesto codice esegue l‚Äôintegrazione della funzione di verosimiglianza binomiale su tutti i possibili valori di Œ∏ (da 0 a 1), fornendo cos√¨ la verosimiglianza marginale per il nostro esempio. Questo processo ci permette di considerare l‚Äôincertezza su Œ∏, offrendo una visione completa della verosimiglianza dell‚Äôevento osservato senza fissare Œ∏ a un singolo valore.\nNumericamente, nell‚Äôesempio della verosimiglianza basata su una distribuzione binomiale precedente, la verosimiglianza marginale √® effettivamente interpretata come l‚Äôarea sottesa dalla funzione di verosimiglianza, calcolata integrandola su tutto l‚Äôintervallo dei possibili valori di \\(\\theta\\) (da 0 a 1, nel contesto di probabilit√†). Questa operazione di integrazione fornisce un valore che quantifica l‚Äôarea sotto la curva della funzione di verosimiglianza. Importante sottolineare, questo valore non corrisponde alla probabilit√† dei dati dati i parametri, dato che la verosimiglianza non √® una densit√† di probabilit√† sui parametri. Piuttosto, esso misura in che misura l‚Äôintero modello, considerando tutti i possibili valori del parametro, √® in grado di spiegare i dati osservati.\nLa vera importanza della verosimiglianza marginale emerge nel contesto dell‚Äôinferenza bayesiana: essa agisce come fattore di normalizzazione nella formula di Bayes. Nello specifico, la verosimiglianza marginale normalizza la funzione risultante dal prodotto tra la verosimiglianza e la distribuzione a priori dei parametri (il numeratore nella formula di Bayes), garantendo che il risultato sia una distribuzione di probabilit√† valida sullo spazio dei parametri. In altre parole, la verosimiglianza marginale assicura che l‚Äôarea sotto la curva della distribuzione posteriore sia esattamente 1, rendendola cos√¨ una vera distribuzione di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/13_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "34¬† La verosimiglianza",
    "section": "34.5 Modello Gaussiano e Verosimiglianza",
    "text": "34.5 Modello Gaussiano e Verosimiglianza\nAmpliamo ora la nostra analisi al caso della distribuzione gaussiana. Inizieremo con la verosimiglianza associata a una singola osservazione $ Y $, per poi estendere la discussione a un insieme di osservazioni gaussiane indipendenti e identicamente distribuite (IID).\n\n34.5.1 Caso di una Singola Osservazione\nIniziamo esaminiamo il caso di una singola osservazione. Quale esempio, prendiamo in considerazione la situazione in cui una variabile casuale rappresenta il Quoziente d‚ÄôIntelligenza (QI) di un individuo. Se consideriamo la distribuzione del QI come gaussiana, possiamo esprimere la funzione di verosimiglianza per un singolo valore osservato di QI tramite la formula della distribuzione gaussiana, che misura la probabilit√† di osservare quel particolare valore di QI dato un insieme di parametri specifici, \\(\\mu\\) (la media) e \\(\\sigma\\) (la deviazione standard). La verosimiglianza offre quindi un modo per quantificare quanto bene i parametri \\(\\mu\\) e \\(\\sigma\\) si accordano con il valore osservato di QI.\nSupponiamo che il QI osservato sia 114 e, per semplicit√†, assumiamo che la deviazione standard \\(\\sigma\\) sia conosciuta e pari a 15. Vogliamo esaminare un‚Äôampia gamma di possibili valori per la media \\(\\mu\\), diciamo tra 70 e 160, e valutare quale di questi valori rende pi√π plausibile l‚Äôosservazione fatta Definiamo quindi un insieme di 1000 valori per \\(\\mu\\) da esplorare:\n\nmu = np.linspace(70.0, 160.0, num=1000)\ny = 114\n\nLa nostra analisi consiste nell‚Äôapplicare la funzione di densit√† di probabilit√† gaussiana a ciascuno di questi 1000 valori di \\(\\mu\\), mantenendo fisso il valore osservato di QI, \\(y=114\\), e la deviazione standard, \\(\\sigma=15\\). In questo modo, possiamo costruire la funzione di verosimiglianza che esprime la plausibilit√† di ciascun valore di \\(\\mu\\) alla luce del QI osservato.\nIl calcolo specifico della densit√† di probabilit√† per ogni valore di \\(\\mu\\) pu√≤ essere eseguito con la funzione norm.pdf di scipy.stats, che accetta il valore osservato \\(y\\), un array di medie (i nostri valori di \\(\\mu\\)) e la deviazione standard \\(\\sigma\\). Per un singolo valore mu = 70, otteniamo\n\nstats.norm.pdf(y, loc=70, scale=15)\n\n0.00036007041207962535\n\n\nPer il valore mu = 70.05 otteniamo\n\nstats.norm.pdf(y, loc=70.05, scale=15)\n\n0.00036360634900376967\n\n\ne cos√¨ via. Se usiamo utti i 1000 valori possibili di mu, otteniamo un vettore di 1000 risultati:\n\nf_mu = stats.norm.pdf(y, loc=mu, scale=15)\n\nQuesto passaggio ci fornisce un array di valori che rappresentano la verosimiglianza di ciascun valore di \\(\\mu\\) data l‚Äôosservazione \\(y\\). Tracciando questi valori f_mu in funzione di \\(\\mu\\), otteniamo una curva di verosimiglianza che illustra visivamente quanto bene ciascun valore di \\(\\mu\\) si adatta al dato osservato y = 114:\n\nplt.figure()\nplt.plot(mu, f_mu, \"-\")\nplt.title(\"Funzione di verosimiglianza per QI = 114\")\nplt.xlabel(\"Valore di mu [70, 160]\")\nplt.ylabel(\"Verosimiglianza\")\nplt.xlim([70, 160])\nplt.show()\n\n\n\n\n\n\n\n\nAbbiamo dunque proceduto come nel caso della distribuzione binomiale esaminata in precedenza. Abbiamo utilizzato la formula\n\\[\nf(x | \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ntenendo costante il valore \\(x\\) = 114 e considerando noto \\(\\sigma\\) = 15, e abbiamo applicato la formula 1000 volte facendo variare mu ogni volta utilizziando ciascuno dei valori definiti con np.linspace(70.0, 160.0, num=1000).\nLa moda della distribuzione, si trova con\n\noptimal_mu = mu[f_mu.argmax()]\nprint(optimal_mu)\n\n113.96396396396396\n\n\nIn questo esempio, otteniamo il valore \\(\\mu\\) = 113.96 che massimizza la verosimiglianza.\nPer calcolare il massimo della log-verosimiglianza per una distribuzione Gaussiana usando la funzione optimize() di SciPy, possiamo seguire questi passi. Partiamo dalla formula della densit√† di probabilit√† della distribuzione gaussiana per una singola osservazione \\(y\\), con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La formula √®:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\n\\]\nPoich√© abbiamo una singola osservazione \\(y\\), la funzione di verosimiglianza coincide con la funzione di densit√† di probabilit√†. Quindi, prendiamo il logaritmo naturale di entrambi i lati della equazione della densit√† di probabilit√† gaussiana per ottenere la log-verosimiglianza:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log \\left( \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right) \\right)\n\\]\nApplichiamo le propriet√† dei logaritmi. Ricordiamo che:\n\n\\(\\log(ab) = \\log(a) + \\log(b)\\)\n\\(\\log\\left(\\frac{1}{a}\\right) = -\\log(a)\\)\n\\(\\log(e^x) = x\\)\n\nQuindi, possiamo scrivere:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log\\left(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\right) + \\log\\left(\\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\\right)\n\\]\n\\[\n= -\\log(\\sigma \\sqrt{2\\pi}) -\\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nRicordando che \\(\\log(ab) = \\log(a) + \\log(b)\\), possiamo scrivere \\(\\log(\\sigma \\sqrt{2\\pi})\\) come la somma di due logaritmi:\n\\[\n-\\log(\\sigma \\sqrt{2\\pi}) = -\\log(\\sigma) - \\log(\\sqrt{2\\pi}).\n\\]\nE dato che \\(\\log(\\sqrt{2\\pi}) = \\frac{1}{2}\\log(2\\pi)\\), possiamo sostituire per ottenere:\n\\[\n-\\log(\\sigma) - \\frac{1}{2}\\log(2\\pi).\n\\]\nCombinando tutto, otteniamo:\n\\[\n\\log L(\\mu; y, \\sigma) = -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2 \\sigma^2}.\n\\]\nQuesta √® la trasformata logaritmica della funzione di densit√† di probabilit√† gaussiana per una singola osservazione, che rappresenta la log-verosimiglianza di osservare \\(y\\) dato \\(\\mu\\) e \\(\\sigma\\).\nVogliamo trovare il valore di \\(\\mu\\) che massimizza questa funzione di log-verosimiglianza. Siccome optimize() di SciPy minimizza una funzione, possiamo passare il negativo della log-verosimiglianza per trovare il massimo.\n\n# Dati osservati\ny_obs = 114\nsigma = 15\n\n# Definizione della funzione negativa della log-verosimiglianza\ndef negative_log_likelihood(mu, y, sigma):\n    return 0.5 * np.log(2 * np.pi) + np.log(sigma) + ((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza\nresult = minimize(negative_log_likelihood, x0=0, args=(y_obs, sigma))\n\n# Il risultato ottimizzato per mu\nresult.x\n\narray([113.99997648])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per una distribuzione Gaussiana con \\(y = 114\\) e \\(\\sigma = 15\\) √® circa \\(114\\). Questo risultato dimostra che, nel caso di una distribuzione Gaussiana con una singola osservazione e deviazione standard nota, il massimo della log-verosimiglianza si ottiene quando la media stimata \\(\\mu\\) √® molto vicina al valore osservato \\(y\\).\n\n\n34.5.2 Campione indipendente di osservazioni da una distribuzione gaussiana\nPassiamo ora all‚Äôesame di un contesto pi√π complesso: quello di un campione composto da \\(n\\) osservazioni indipendenti, tutte provenienti da una distribuzione gaussiana. Consideriamo questo insieme di osservazioni come realizzazioni indipendenti ed identicamente distribuite (i.i.d.) di una variabile casuale \\(X\\), che segue una distribuzione normale con media $ $ e deviazione standard \\(\\sigma\\), entrambi parametri sconosciuti. Denotiamo questa situazione con la notazione \\(X \\sim N(\\mu, \\sigma^2)\\).\nIn presenza di osservazioni i.i.d., la densit√† di probabilit√† congiunta del campione √® il prodotto delle funzioni di densit√† per ogni singola osservazione. Matematicamente, ci√≤ si esprime attraverso l‚Äôequazione:\n\\[ p(y_1, y_2, \\ldots, y_n | \\mu, \\sigma) = \\prod_{i=1}^{n} p(y_i | \\mu, \\sigma), \\]\ndove \\(p(y_i | \\mu, \\sigma)\\) indica la funzione di densit√† gaussiana per l‚Äôosservazione \\(y_i\\), parametrizzata da \\(\\mu\\) e \\(\\sigma\\).\nSe manteniamo i dati osservati come costanti, ci√≤ che cambia in questa equazione quando variamo $ $ e \\(\\sigma\\) sono le probabilit√† associate ad ogni configurazione dei parametri, portandoci cos√¨ alla funzione di verosimiglianza congiunta per il campione.\n\nEsempio 34.2 Consideriamo, per illustrare questa dinamica, il caso di uno studio clinico che misura i punteggi del Beck Depression Inventory II (BDI-II) su trenta partecipanti. Supponiamo che questi punteggi seguano una distribuzione normale. Dati i punteggi BDI-II per i trenta partecipanti, il nostro obiettivo √® costruire una funzione di verosimiglianza per questi dati, assumendo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria di 6.50.\nPer la totalit√† del campione, la densit√† di probabilit√† congiunta diventa quindi il prodotto delle densit√† per ogni osservazione. Di conseguenza, la funzione di verosimiglianza per il campione intero √® rappresentata dal prodotto delle densit√† di probabilit√† di tutte le osservazioni.\nIn questo contesto, ogni possibile valore di \\(\\mu\\) viene valutato in termini di verosimiglianza. Per esemplificare, consideriamo un range di 1000 valori per \\(\\mu\\) e calcoliamo la funzione di verosimiglianza per ognuno di questi. Per rendere pi√π gestibili i calcoli, utilizziamo il logaritmo della funzione di verosimiglianza.\nDefinendo una funzione log_likelihood in Python che accetta i punteggi BDI-II \\(y\\), un valore medio \\(\\mu\\), e imposta \\(\\sigma\\) al valore noto, possiamo calcolare la log-verosimiglianza per un‚Äôampia gamma di valori di \\(\\mu\\) entro un intervallo specifico. Ci√≤ ci permette di visualizzare la credibilit√† relativa di ciascun valore di \\(\\mu\\) alla luce dei dati osservati.\nInfine, il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza corrisponde alla stima di massima verosimiglianza di \\(\\mu\\) data la distribuzione dei punteggi BDI-II nel campione. Questo valore, nel nostro esempio, coincide con la media campionaria dei punteggi BDI-II, offrendo una stima concorde con l‚Äôintuizione che la media del campione sia un buon rappresentante del parametro \\(\\mu\\) in una distribuzione normale.\nI dati sono:\n\ny = [\n    26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25,\n    28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n]\n\nIl nostro scopo √® sviluppare una funzione di verosimiglianza utilizzando le 30 osservazioni indicate sopra. Basandoci su studi precedenti, ipotizziamo che questi punteggi seguano una distribuzione normale. Assumiamo inoltre che la deviazione standard \\(\\sigma\\) sia nota e corrisponda a quella osservata nel campione, ossia 6.50.\nPer la prima osservazione del campione, dove \\(y_1 = 26\\), la funzione di densit√† di probabilit√† si esprime come:\n\\[\nf(26 \\,|\\, \\mu, \\sigma = 6.50) = \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(26 - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\]\nEstendendo questo calcolo all‚Äôintero campione, la funzione di densit√† di probabilit√† congiunta si ottiene come il prodotto delle densit√† di tutte le osservazioni individuali:\n\\[\nf(y \\,|\\, \\mu, \\sigma = 6.50) = \\prod_{i=1}^{n} f(y_i \\,|\\, \\mu, \\sigma = 6.50).\n\\]\nDi conseguenza, la funzione di verosimiglianza, indicata con \\(\\mathcal{L}(\\mu, \\sigma = 6.50 \\,|\\, y)\\), si determina moltiplicando insieme le densit√† di probabilit√† di tutte le osservazioni nel campione:\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu, \\sigma=6.50 \\,|\\, y) &= \\prod_{i=1}^{30} \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right) \\\\\n&= \\left( \\frac{1}{6.50\\sqrt{2\\pi}} \\right)^{30} \\exp\\left( -\\sum_{i=1}^{30} \\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\end{aligned}\n\\]\nIn questa formula, \\(\\mu\\) rappresenta il parametro di interesse, la media della distribuzione, la cui stima massimizza la funzione di verosimiglianza. Se si considerano 1000 valori differenti per \\(\\mu\\), dovremmo calcolare la funzione di verosimiglianza per ciascuno di questi valori.\nPer rendere i calcoli pi√π gestibili, √® consigliabile utilizzare il logaritmo della funzione di verosimiglianza. In Python, possiamo definire una funzione log_likelihood() che accetta come argomenti y, mu e sigma = true_sigma. Per semplificare, impostiamo true_sigma uguale alla deviazione standard osservata nel campione.\n\ntrue_sigma = np.std(y)\nprint(true_sigma)\n\n6.495810615739622\n\n\n\ndef log_likelihood(y, mu, sigma=true_sigma):\n    return np.sum(stats.norm.logpdf(y, loc=mu, scale=true_sigma))\n\nConsideriamo, ad esempio, il valore \\(\\mu_0 = \\bar{y}\\), ovvero\n\nbar_y = np.mean(y)\nprint(bar_y)\n\n30.933333333333334\n\n\nL‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di \\(\\mu = 30.93\\) √®\n\nlog_likelihood(y, 30.93, sigma=true_sigma)\n\n-98.70288339960591\n\n\nTroviamo ora i valori della log-verosimiglianza per ciascuno dei 1000 valori \\(\\mu\\) nell‚Äôintervallo \\([\\bar{y} - 2 \\sigma, \\bar{y} + 2 \\sigma]\\). Iniziamo a definire il vettore mu.\n\nmu = np.linspace(np.mean(y) - 2 * np.std(y), np.mean(y) + 2 * np.std(y), num=1000)\n\nTroviamo il valore dell‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di ciascuno dei 1000 valori mu che abbiamo definito.\n\nll = [log_likelihood(y, mu_val, true_sigma) for mu_val in mu]\n\nNel caso di un solo parametro sconosciuto (nel caso presente, \\(\\mu\\)) √® possibile rappresentare la log-verosimiglianza con una curva che interpola i punti (mu, ll). Tale funzione descrive la credibilit√† relativa che pu√≤ essere attribuita ai valori del parametro \\(\\mu\\) alla luce dei dati osservati.\n\nplt.figure()\nplt.plot(mu, ll, \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale mu\")\nplt.ylabel(\"Log-verosimiglianza\")\nplt.axvline(x=np.mean(y), alpha=0.4, ls=\"--\");\n\n\n\n\n\n\n\n\nIl valore \\(\\mu\\) pi√π credibile corrisponde al massimo della funzione di log-verosimiglinza e viene detto stima di massima verosimiglianza.\nIl massimo della funzione di log-verosimiglianza, ovvero 30.93 per l‚Äôesempio in discussione, √® identico alla media dei dati campionari.\nPer applicare lo stesso approccio usato precedentemente con optimize ad un campione di dati, anzich√© a una singola osservazione, possiamo modificare la funzione di log-verosimiglianza per prendere in considerazione tutte le osservazioni nel campione. La log-verosimiglianza per un campione da una distribuzione Gaussiana, dove ogni osservazione \\(y_i\\) ha la stessa media \\(\\mu\\) e deviazione standard \\(\\sigma\\), √® la somma delle log-verosimiglianze di ogni osservazione individuale.\nLa formula modificata per il campione sar√†:\n\\[\n\\log L(\\mu; y, \\sigma) = \\sum_{i=1}^{n} \\left[ -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y_i - \\mu)^2}{2 \\sigma^2} \\right],\n\\]\ndove \\(y\\) √® l‚Äôarray delle osservazioni e \\(n\\) √® il numero di osservazioni nel campione.\nPoich√©, per semplicit√†, assumiamo \\(\\sigma\\) come la deviazione standard del campione, prima calcoleremo \\(\\sigma\\) dal campione fornito e poi useremo quel valore per l‚Äôottimizzazione della log-verosimiglianza, cercando il valore di \\(\\mu\\) che la massimizza.\n\n# Calcolo della deviazione standard del campione\nsigma_sample = np.std(y, ddof=1)\n\n# Definizione della funzione negativa della log-verosimiglianza per il campione\ndef negative_log_likelihood_sample(mu, y, sigma):\n    n = len(y)\n    return n * 0.5 * np.log(2 * np.pi) + n * np.log(sigma) + np.sum((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza per il campione\nresult_sample = minimize(negative_log_likelihood_sample, x0=np.mean(y), args=(y, sigma_sample))\n\n# Il risultato ottimizzato per mu\nresult_sample.x\n\narray([30.93333333])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per il campione di dati fornito, assumendo noto il valore di \\(\\sigma\\) (la deviazione standard del campione), √® circa \\(30.93\\). Questo rappresenta la stima ottimale per la media della distribuzione Gaussiana che meglio si adatta al campione di dati dato.\n\n\n\n34.5.3 La Stima di Massima Verosimiglianza per \\(\\mu\\)\nPer determinare il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza, procediamo calcolando la sua derivata parziale rispetto a \\(\\mu\\) e impostando il risultato uguale a zero:\n\nPartiamo dalla funzione di log-verosimiglianza, che √® data da:\n\\[\n\\ell = -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\nCalcoliamo la derivata parziale di $ $ rispetto a $ $:\n\\[\n\\frac{\\partial \\ell}{\\partial \\mu} = \\sum_{i=1}^n \\frac{(y_i - \\mu)}{\\sigma^2}.\n\\]\nImpostiamo la derivata uguale a zero per trovare il punto di massimo:\n\\[\n\\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu) = 0.\n\\]\n\nRisolvendo questa equazione per $ $, otteniamo la stima di massima verosimiglianza:\n\\[\n\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar{y}.\n\\]\nQuesta formula ci mostra che la stima di massima verosimiglianza per \\(\\mu\\) corrisponde semplicemente alla media aritmetica delle osservazioni.\nQuesto processo pu√≤ essere analogamente applicato per stimare \\(\\sigma^2\\), la varianza, e si trova che la stima di massima verosimiglianza per \\(\\sigma^2\\) √® pari alla varianza campionaria.\nIn conclusione, all‚Äôinterno di una distribuzione gaussiana, le stime di massima verosimiglianza per \\(\\mu\\) (la media) e \\(\\sigma^2\\) (la varianza) coincidono con la media campionaria e la varianza campionaria, rispettivamente.\n\nEsempio 34.3 Consideriamo un esempio relativo all‚Äôapprendimento per rinforzo. Lo scopo degli studi sull‚Äôapprendimento per rinforzo √® quello di comprendere come le persone imparano a massimizzare le loro ricompense in situazioni in cui la scelta migliore √® inizialmente sconosciuta. In modo pi√π specifico, consideriamo il seguente problema di apprendimento. Un partecipante deve effettuare ripetutamente delle scelte tra diverse opzioni o azioni, e dopo ogni scelta riceve una ricompensa numerica estratta da una distribuzione di probabilit√† che dipende dall‚Äôazione selezionata. L‚Äôobiettivo del partecipante √® massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte. Per descrivere questa situazione, viene spesso utilizzata la metafora di un giocatore che deve fare una serie di \\(T\\) scelte tra \\(K\\) slot machine (conosciute anche come ‚Äúmulti-armed bandits‚Äù) al fine di massimizzare le sue vincite. Se nella scelta \\(t\\) viene selezionata la slot machine \\(k\\), viene ottenuta una ricompensa \\(r_t\\) che ha valore 1 con una probabilit√† di successo \\(\\mu^k_t\\), altrimenti ha valore 0. Le probabilit√† di successo sono diverse per ogni slot machine e inizialmente sono sconosciute al partecipante. Nella versione pi√π semplice di questo compito, le probabilit√† di successo rimangono costanti nel tempo.\nIl modello di Rescorla-Wagner √® un modello di apprendimento associativo che descrive come gli animali o gli umani aggiornano le loro aspettative di rinforzo in risposta a stimoli. Il modello pu√≤ essere descritto con la seguente formula di aggiornamento:\n\\[ V_{t+1} = V_t + \\alpha (\\lambda - V_t), \\]\ndove:\n\n\\(V_t\\) √® il valore predetto del rinforzo al tempo \\(t\\),\n\\(\\alpha\\) √® il tasso di apprendimento, un parametro che vogliamo stimare,\n\\(\\lambda\\) √® l‚Äôintensit√† del rinforzo,\n\\(V_{t+1}\\) √® il valore aggiornato dopo aver sperimentato il rinforzo.\n\nPer semplificare, consideriamo un caso in cui gli stimoli si presentano in maniera binaria (rinforzo presente o assente), e \\(\\lambda\\) √® noto. L‚Äôobiettivo √® stimare il valore di \\(\\alpha\\) che massimizza la verosimiglianza dei dati osservati sotto il modello.\nLa funzione di verosimiglianza per questo modello dipende dalla differenza tra i valori predetti e gli effettivi rinforzi ricevuti. Tuttavia, la formulazione esatta della funzione di verosimiglianza pu√≤ variare a seconda della specifica formulazione del problema e dei dati disponibili. Per mantenere le cose semplici, consideriamo una versione semplificata in cui la ‚Äúverosimiglianza‚Äù √® basata sulla somma dei quadrati degli errori (SSE) tra i rinforzi previsti e quelli osservati (anche se tecnicamente questo non √® un approccio basato sulla verosimiglianza nel senso statistico classico).\nPer questo esempio, assumiamo di avere un semplice set di dati di rinforzi osservati e vogliamo trovare il valore di \\(\\alpha\\) che minimizza l‚ÄôSSE:\n\\[ SSE = \\sum_{t=1}^{n} (\\lambda - V_t)^2. \\]\nEcco un esempio di implementazione in Python che utilizza scipy.optimize.minimize per stimare \\(\\alpha\\):\n\n# Dati di esempio: rinforzi osservati (lambda)\n# In questo esempio, assumiamo lambda = 1 per rinforzo presente e lambda = 0 per rinforzo assente\n# per semplicit√†. In pratica, lambda potrebbe essere diverso a seconda degli esperimenti.\nrinforzi_osservati = [1, 0, 1, 1, 0, 1]  # Esempio di sequenza di rinforzi\n\n\n# Funzione che calcola l'SSE per un dato valore di alpha\ndef sse(alpha, rinforzi, V0=0):\n    V = V0\n    sse = 0\n    for lambda_ in rinforzi:\n        sse += (lambda_ - V)**2\n        V += alpha * (lambda_ - V)  # Aggiornamento del valore secondo il modello Rescorla-Wagner\n    return sse\n\n# Ottimizzazione per trovare il valore di alpha che minimizza l'SSE\nresult_alpha = minimize(sse, x0=0.5, args=(rinforzi_osservati,))\n\n# Il risultato ottimizzato per alpha\nresult_alpha.x\n\narray([0.29739989])\n\n\nIl valore di \\(\\alpha\\) (tasso di apprendimento) che minimizza la somma dei quadrati degli errori (SSE) per il modello di Rescorla-Wagner, dato il campione di rinforzi osservati, √® circa \\(0.297\\). Questo suggerisce che il tasso di apprendimento ottimale per adattare il modello ai dati osservati in questo esempio semplificato √® di circa 0.297, secondo l‚Äôapproccio di minimizzazione dell‚Äôerrore utilizzato qui.\n\n\nEsempio 34.4 Consideriamo ora un esempio relativo alla distribuzione esponenziale. Supponiamo che i seguenti siano i tempi di attesa per un certo evento:\n\ndata = np.array([27, 64, 3, 18, 8])\n\nDefiniamo la funzione di log-verosimiglianza negativa. Per iniziare, ricordiamo che la funzione di densit√† di probabilit√† (PDF) per una distribuzione esponenziale, dato un tasso \\(\\lambda\\), √® definita come:\n\\[\nf(x; \\lambda) = \\lambda e^{-\\lambda x} \\quad \\text{per } x \\geq 0.\n\\]\nLa verosimiglianza (\\(L\\)) di osservare un insieme di dati \\(\\{x_1, x_2, ..., x_n\\}\\) dato un parametro \\(\\lambda\\) √® il prodotto delle funzioni di densit√† di probabilit√† per ogni punto dati, assumendo che ciascun dato sia indipendente dagli altri. Quindi, per \\(n\\) dati osservati, la funzione di verosimiglianza √®:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} f(x_i; \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\n\\]\nLa log-verosimiglianza (\\(\\log(L(\\lambda))\\)) √® il logaritmo naturale di \\(L(\\lambda)\\). Utilizziamo il logaritmo per semplificare la moltiplicazione in una somma, il che rende pi√π semplici sia il calcolo che la differenziazione. Pertanto, la log-verosimiglianza diventa:\n\\[\n\\log(L(\\lambda)) = \\log\\left(\\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\\right) = \\sum_{i=1}^{n} \\log(\\lambda e^{-\\lambda x_i}) = \\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nIl motivo per utilizzare il negativo della log-verosimiglianza, cio√® \\(-\\log(L(\\lambda))\\), nelle tecniche di ottimizzazione, √® perch√© molte librerie e funzioni di ottimizzazione sono progettate per minimizzare una funzione obiettivo piuttosto che massimizzarla. Dato che vogliamo trovare il valore di \\(\\lambda\\) che massimizza la log-verosimiglianza (e quindi la verosimiglianza), possiamo invece minimizzare il suo negativo. Di conseguenza, la funzione obiettivo che passiamo all‚Äôalgoritmo di minimizzazione √®:\n\\[\n-\\log(L(\\lambda)) = -\\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nScriviamo la funzione in Python:\n\ndef neg_log_likelihood(lambda_, data, eps=1e-8):\n    lambda_ = np.clip(lambda_, eps, None)  # Assicura che lambda_ sia almeno eps\n    return -np.sum(np.log(lambda_) - lambda_ * data)\n\nMinimizzaziamo la funzione di log-verosimiglianza negativa:\n\nresult = minimize(neg_log_likelihood, x0=0.1, args=(data,), bounds=[(0, None)])\nprint(f\"Il valore di lambda che massimizza la log-verosimiglianza √®: {result.x[0]}\")\n\nIl valore di lambda che massimizza la log-verosimiglianza √®: 0.04166666292998713\n\n\nAvendo trovato il tasso \\(\\lambda\\), la stima di massima verosimiglianza del tempo di attesa medio diventa:\n\n1 / result.x\n\narray([24.00000215])\n\n\nVisualizzazione.\n\nlambda_opt = result.x[0]\nlambda_array = np.geomspace(0.01, 0.1, 100)\nLL = [-neg_log_likelihood(L, data) for L in lambda_array]\n\nplt.plot(lambda_array, LL, label='Log-likelihood')\nplt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\nplt.xlabel('$\\lambda$')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood over a range of $\\lambda$ values')\nplt.legend()\nplt.show()\n\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:6: SyntaxWarning: invalid escape sequence '\\l'\n  plt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:7: SyntaxWarning: invalid escape sequence '\\l'\n  plt.xlabel('$\\lambda$')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:9: SyntaxWarning: invalid escape sequence '\\l'\n  plt.title('Log-likelihood over a range of $\\lambda$ values')",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#conclusione-e-riflessioni-finali",
    "href": "chapters/probability/13_likelihood.html#conclusione-e-riflessioni-finali",
    "title": "34¬† La verosimiglianza",
    "section": "34.6 Conclusione e Riflessioni Finali",
    "text": "34.6 Conclusione e Riflessioni Finali\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilit√† dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l‚Äôinsieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza √® centrale nella pratica dell‚Äôinferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo √® fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto √® indispensabile per un‚Äôanalisi dati rigorosa e per un‚Äôinterpretazione accurata dei risultati.\nUn‚Äôapplicazione pratica e illustrativa dei principi esposti in questo capitolo √® fornita nella sezione sul modello Rescorla-Wagner, che √® un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l‚Äôapplicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi √® impegnato nella ricerca empirica e nell‚Äôinterpretazione di dati complessi.\n\n\n\n\n\n\nAll‚Äôesame ti verr√† chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "34¬† La verosimiglianza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nSyntaxError: invalid syntax (2307612016.py, line 1)\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_grid_gauss.html",
    "href": "chapters/probability/14_grid_gauss.html",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo √® estendere la discussione precedente sul calcolo della distribuzione a posteriori utilizzando la verosimiglianza gaussiana, introducendo il metodo basato sulla griglia.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_grid_gauss.html#un-prior-uniforme",
    "href": "chapters/probability/14_grid_gauss.html#un-prior-uniforme",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.1 Un prior uniforme",
    "text": "35.1 Un prior uniforme\nConsideriamo il caso in cui abbiamo un campione di 10 osservazioni. Questo campione √® generato mediante il campionamento casuale da una Normale di media 50 e deviazione standard pari a 5. Nella simulazione successiva considereremo \\(\\sigma\\) nota.\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilit√†\nvera_media = 50  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione)\nprint(campione)\n\n[48.54283933 43.64834594 54.59899393 61.47236626 48.30510499 43.11175964\n 60.88971922 39.33729382 52.25731836 50.64725801]\n\n\nCreiamo ora una griglia di 100 elementi con valori compresi tra 40 e 60.\n\nmedia_griglia = np.linspace(start=40, stop=60, num=100)  # 100 punti tra 40 e 60\nprint(media_griglia)\n\n[40.         40.2020202  40.4040404  40.60606061 40.80808081 41.01010101\n 41.21212121 41.41414141 41.61616162 41.81818182 42.02020202 42.22222222\n 42.42424242 42.62626263 42.82828283 43.03030303 43.23232323 43.43434343\n 43.63636364 43.83838384 44.04040404 44.24242424 44.44444444 44.64646465\n 44.84848485 45.05050505 45.25252525 45.45454545 45.65656566 45.85858586\n 46.06060606 46.26262626 46.46464646 46.66666667 46.86868687 47.07070707\n 47.27272727 47.47474747 47.67676768 47.87878788 48.08080808 48.28282828\n 48.48484848 48.68686869 48.88888889 49.09090909 49.29292929 49.49494949\n 49.6969697  49.8989899  50.1010101  50.3030303  50.50505051 50.70707071\n 50.90909091 51.11111111 51.31313131 51.51515152 51.71717172 51.91919192\n 52.12121212 52.32323232 52.52525253 52.72727273 52.92929293 53.13131313\n 53.33333333 53.53535354 53.73737374 53.93939394 54.14141414 54.34343434\n 54.54545455 54.74747475 54.94949495 55.15151515 55.35353535 55.55555556\n 55.75757576 55.95959596 56.16161616 56.36363636 56.56565657 56.76767677\n 56.96969697 57.17171717 57.37373737 57.57575758 57.77777778 57.97979798\n 58.18181818 58.38383838 58.58585859 58.78787879 58.98989899 59.19191919\n 59.39393939 59.5959596  59.7979798  60.        ]\n\n\nCalcoliamo la likelihood.\n\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\nlikelihood\n\narray([4.43497974e-25, 1.00961743e-24, 2.26116493e-24, 4.98216199e-24,\n       1.07997486e-23, 2.30313636e-23, 4.83209939e-23, 9.97383700e-23,\n       2.02534436e-22, 4.04618453e-22, 7.95248204e-22, 1.53769396e-21,\n       2.92514449e-21, 5.47437998e-21, 1.00793553e-20, 1.82574775e-20,\n       3.25356129e-20, 5.70410371e-20, 9.83843533e-20, 1.66945554e-19,\n       2.78698020e-19, 4.57723393e-19, 7.39575534e-19, 1.17563407e-18,\n       1.83853539e-18, 2.82866831e-18, 4.28156219e-18, 6.37577071e-18,\n       9.34056882e-18, 1.34624518e-17, 1.90890888e-17, 2.66290968e-17,\n       3.65458340e-17, 4.93434508e-17, 6.55437614e-17, 8.56531629e-17,\n       1.10119860e-16, 1.39282995e-16, 1.73316833e-16, 2.12174698e-16,\n       2.55538678e-16, 3.02781890e-16, 3.52950131e-16, 4.04768775e-16,\n       4.56678807e-16, 5.06903062e-16, 5.53540208e-16, 5.94680409e-16,\n       6.28533301e-16, 6.53556524e-16, 6.68572052e-16, 6.72858096e-16,\n       6.66206627e-16, 6.48940106e-16, 6.21885576e-16, 5.86308990e-16,\n       5.43817056e-16, 4.96237176e-16, 4.45487960e-16, 3.93452986e-16,\n       3.41869158e-16, 2.92238345e-16, 2.45767628e-16, 2.03339784e-16,\n       1.65512287e-16, 1.32540414e-16, 1.04418297e-16, 8.09310345e-17,\n       6.17111697e-17, 4.62937824e-17, 3.41658127e-17, 2.48068172e-17,\n       1.77198703e-17, 1.24526055e-17, 8.60934527e-18, 5.85585374e-18,\n       3.91850601e-18, 2.57965137e-18, 1.67075095e-18, 1.06456606e-18,\n       6.67334716e-19, 4.11552289e-19, 2.49698841e-19, 1.49045282e-19,\n       8.75246011e-20, 5.05652605e-20, 2.87398541e-20, 1.60704142e-20,\n       8.84056013e-21, 4.78456761e-21, 2.54750949e-21, 1.33444023e-21,\n       6.87689899e-22, 3.48655374e-22, 1.73904286e-22, 8.53364173e-23,\n       4.11972976e-23, 1.95665048e-23, 9.14256335e-24, 4.20274369e-24])\n\n\nLa likelihood rappresenta quanto sono verosimili i dati osservati dato un certo parametro (o set di parametri) del modello. Nel contesto della distribuzione gaussiana, la likelihood di un insieme di osservazioni dato un valore specifico della media (\\(\\mu\\)) e conoscendo la deviazione standard (\\(\\sigma\\)) si calcola come il prodotto delle densit√† di probabilit√† di ogni osservazione data quella media e deviazione standard. Questo approccio si basa sull‚Äôassunzione di indipendenza tra le osservazioni.\nIl codice precedente calcola la likelihood per una serie di valori possibili della media (\\(\\mu\\)), mantenendo la deviazione standard (\\(\\sigma\\)) come un valore noto e fisso. Ecco come funziona passo dopo passo:\nlikelihood = np.array([np.prod(norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\nnorm.pdf(campione, loc=media, scale=sigma_conosciuta): Per ogni valore di media nella griglia specificata (media_griglia), questa espressione calcola la densit√† di probabilit√† (PDF) della distribuzione normale per ciascun punto nel campione (campione). loc=media specifica il valore medio della distribuzione normale considerata in quel momento, mentre scale=sigma_conosciuta indica la deviazione standard della distribuzione, che √® considerata nota e costante per tutti i calcoli. Il risultato di norm.pdf per ogni valore di media √® un array che contiene le probabilit√† di ogni osservazione del campione date quella media e la deviazione standard conosciuta.\nnp.prod(...): Calcola il prodotto degli elementi nell‚Äôarray restituito da norm.pdf, ovvero moltiplica tra loro le probabilit√† di tutte le osservazioni del campione per il valore corrente di media. Questo prodotto rappresenta la likelihood complessiva del campione dato quel valore specifico della media, assumendo che le osservazioni siano indipendenti. Il concetto di indipendenza √® cruciale qui perch√© ci permette di moltiplicare le probabilit√† delle singole osservazioni per ottenere la probabilit√† complessiva (likelihood) del set di dati.\nComprehension list [...] for media in media_griglia: Questa parte del codice esegue il calcolo della likelihood per ogni valore di media nella griglia e salva i risultati in un array NumPy. Quindi, per ciascun valore possibile della media considerata, calcoliamo quanto il campione osservato sia verosimile, data quella media e la deviazione standard nota.\n\nIl risultato finale, likelihood, √® un array dove ogni elemento corrisponde alla likelihood del campione di dati osservati per un specifico valore della media sulla griglia.\nPer fare un esempio, consideriamo il primo punto della griglia, corrispondente ad una una media di \\(40\\) (dato che media_griglia √® definita da 40 a 60). Calcoliamo la densit√† di probabilit√† (PDF) per ogni osservazione nel campione dato questo valore della media (\\(40\\)) e una deviazione standard conosciuta di \\(5\\). Ecco le PDF per ciascuna osservazione nel campione:\n[2.28493333e-02, 4.62542534e-02, 3.31420922e-02, 3.00464741e-02,\n 1.11418804e-05, 1.96649746e-02, 2.18282203e-02, 2.11292630e-02,\n 4.05476440e-03, 1.40537162e-07]\nQuesti valori rappresentano la densit√† di probabilit√† di osservare ciascuna misurazione data una distribuzione normale con media \\(40\\) e deviazione standard \\(5\\). La likelihood del campione dato questo valore della media √® calcolata come il prodotto di queste densit√† di probabilit√†, risultando in \\(6.060521630996206 \\times 10^{-26}\\).\nQuesto numero molto piccolo riflette il fatto che, dato un valore medio di \\(40\\), la probabilit√† complessiva di osservare questo specifico campione √® estremamente bassa.\nPer costruire la likelihood completa, ripetiamo questa procedura per ogni punto della nostra griglia di valori.\nDopo aver calcolato la likelihood per ogni punto, procediamo moltiplicandola per il valore del prior corrispondente. Questo passaggio ci consente di ottenere una distribuzione a posteriori non ancora normalizzata.\nNel contesto di una griglia discreta, la normalizzazione della distribuzione a posteriori pu√≤ essere facilmente conseguita dividendo ogni valore per la somma totale dei valori della distribuzione a posteriori.\n\nprior = np.ones(len(media_griglia))  # Una prior uniforme\nposterior_non_norm = likelihood * prior  # Calcoliamo la posterior non normalizzata moltiplicando per la prior\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizziamo la posterior\n\nLa figura successiva presenta una rappresentazione grafica della distribuzione a posteriori normalizzata.\n\nplt.plot(media_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media')\nplt.xlabel('Media')\nplt.ylabel('Probabilit√†')\nplt.show()\n\n\n\n\n\n\n\n\nPer fare un altro esempio, consideriamo un prior non uniforme corrispondente ad una distribuzione gaussiana con media 40 e \\(\\sigma\\) = 3.\n\n# Calcolo della prior gaussiana per ogni valore della griglia della media\nprior = stats.norm.pdf(media_griglia, loc=40, scale=3)\n\n# Calcolo della likelihood (rimane invariato)\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\n# Calcolo della distribuzione a posteriori (aggiornamento con la nuova prior)\nposterior_non_norm = likelihood * prior  # Moltiplicazione element-wise\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizzazione\n\nRiesaminiamo la distribuzione a posteriori calcolata in questo caso, confrontandola con la distribuzione a priori. √à importante notare che, in questo secondo esempio, la distribuzione a posteriori mostra una ‚Äútraslazione‚Äù in direzione del prior.\n\nplt.plot(media_griglia, posterior, label='Posterior')\nplt.plot(media_griglia, prior / np.sum(prior), label='Prior', linestyle='--')\nplt.title('Distribuzione a Posteriori e Prior della Media')\nplt.xlabel('Media')\nplt.ylabel('Densit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nDopo aver calcolato la distribuzione a posteriori come mostrato sopra, per ottenere un campione casuale da questa distribuzione possiamo seguire un approccio di campionamento discreto. Poich√© la distribuzione a posteriori √® definita su una griglia di valori della media, possiamo utilizzare il campionamento ponderato per selezionare casualmente un valore dalla griglia secondo le probabilit√† a posteriori.\nQuesto metodo ci permette di ‚Äúcampionare‚Äù dalla distribuzione a posteriori nonostante essa sia rappresentata in forma discreta anzich√© continua. Ecco come si pu√≤ fare in Python:\n\n# Selezione casuale di un indice dalla griglia secondo le probabilit√† a posteriori\nindice_campionato = np.random.choice(a=len(media_griglia), size=1000, p=posterior)\n\n# Estrazione del valore della media corrispondente all'indice campionato\nmedia_campionata = media_griglia[indice_campionato]\nmedia_campionata.shape\n\n(1000,)\n\n\nIl metodo np.random.choice permette di selezionare un indice dalla griglia con probabilit√† proporzionale ai valori della distribuzione a posteriori. In questo modo, i valori della media con probabilit√† a posteriori pi√π alta saranno selezionati pi√π frequentemente, riflettendo la loro maggiore plausibilit√† data la combinazione dei dati osservati e della prior.\nQuesto campione dalla distribuzione a posteriori rappresenta quindi una possibile stima della media della popolazione, tenendo conto sia dei dati osservati (attraverso la likelihood) sia delle nostre conoscenze o supposizioni precedenti (attraverso la prior).\nL‚Äôistogramma seguente mostra la distribuzione di un campione casuale ottenuto dalla distribuzione a posteriori.\n\n_ = sns.histplot(media_campionata)\n\n\n\n\n\n\n\n\nCalcoliamo ora la media a posteriori:\n\nnp.mean(media_campionata)\n\n48.07676767676767\n\n\nL‚Äôintervallo di credibilit√† al 94% √® dato da:\n\n# Calcolo del 3¬∞ e 97¬∞ percentile dei campioni per ottenere l'intervallo di credibilit√† al 95%\nlimite_inferiore = np.percentile(media_campionata, 3)\nlimite_superiore = np.percentile(media_campionata, 97)\n\nprint(f\"Intervallo di credibilit√† al 94% per la media: [{limite_inferiore}, {limite_superiore}]\")\n\nIntervallo di credibilit√† al 94% per la media: [45.45454545454545, 50.511111111111106]\n\n\nL‚Äôintervallo di credibilit√† al 94%, calcolato come descritto sopra, rappresenta un intervallo all‚Äôinterno del quale ci aspettiamo che si trovi il vero valore della media della popolazione con una probabilit√† del 94%. In altre parole, basandoci sulle informazioni ottenute dai campioni e su precedenti conoscenze rappresentate dalla distribuzione a priori, possiamo essere il 94% confidenti che l‚Äôintervallo definito dal 3¬∞ al 97¬∞ percentile includa la vera media della popolazione.\nL‚Äôintervallo di credibilit√† che √® stato calcolato offre una stima probabilitica di dove si trova il vero valore della media della popolazione, basandosi sui dati del campione e sull‚Äôapproccio inferenziale bayesiano. Questo intervallo fornisce quindi una misura diretta dell‚Äôincertezza della nostra stima, riflettendo la forza e la precisione delle evidenze a nostra disposizione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_grid_gauss.html#la-log-verosimiglianza",
    "href": "chapters/probability/14_grid_gauss.html#la-log-verosimiglianza",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.2 La Log-Verosimiglianza",
    "text": "35.2 La Log-Verosimiglianza\nNell‚Äôesempio presente abbiamo calcolato la verosimiglianza con una somma. Tuttavia questo produce dei problemi e, in generale, √® preferibile lavorare con i logaritmi.\nStabilit√† Numerica I prodotti di molte probabilit√† piccole possono portare a un ‚Äúunderflow‚Äù numerico, dove il valore risultante √® cos√¨ piccolo che viene arrotondato a zero dalla rappresentazione in virgola mobile del computer. I logaritmi trasformano questi prodotti in somme, riducendo significativamente il rischio di underflow.\nSemplificazione dei Calcoli Il logaritmo di un prodotto √® uguale alla somma dei logaritmi (log(ab) = log(a) + log(b)). Questo trasforma il prodotto di molte verosimiglianze in una somma di logaritmi, semplificando i calcoli e migliorando l‚Äôefficienza computazionale.\nMiglioramento della Precisione I calcolatori sono generalmente pi√π precisi nel sommare che nel moltiplicare numeri, specialmente quando si tratta di numeri molto grandi o molto piccoli. L‚Äôuso dei logaritmi pu√≤ quindi aiutare a mantenere una maggiore precisione nei calcoli.\nFacilit√† di Ottimizzazione Molti algoritmi di ottimizzazione lavorano meglio con somme piuttosto che con prodotti, soprattutto perch√© le derivate delle funzioni somma sono pi√π semplici da calcolare rispetto a quelle dei prodotti. Questo √® particolarmente utile nella stima di massima verosimiglianza e in altri contesti di ottimizzazione bayesiana.\nGestione di Valori Estremi I logaritmi possono aiutare a gestire meglio un ampio range di valori, riducendo gli effetti di valori estremamente grandi o piccoli che potrebbero altrimenti dominare il prodotto di verosimiglianze e portare a risultati distorti.\nIn conclusione, l‚Äôuso dei logaritmi nella stima delle distribuzioni posteriori e in altri calcoli probabilistici offre numerosi vantaggi in termini di stabilit√† numerica, precisione e efficienza computazionale, rendendolo un approccio preferibile in molte situazioni.\nPer riprodurre l‚Äôesempio precedente utilizzando la log-verosimiglianza, anzich√© lavorare direttamente con i valori delle verosimiglianze, convertiremo i calcoli in termini di logaritmi. Questo approccio migliora la stabilit√† numerica e l‚Äôefficienza dei calcoli, come discusso precedentemente. Seguiamo il processo passo dopo passo:\n\nGenerazione del Campione: Iniziamo generando un campione dalla distribuzione normale con una media vera e una deviazione standard conosciuta.\nDefinizione della Griglia per la Media: Stabiliremo una griglia di valori possibili per la media sulla quale calcoleremo la log-verosimiglianza.\nCalcolo della Log-Likelihood: Calcoleremo la log-verosimiglianza per ciascun valore della griglia, utilizzando la densit√† di probabilit√† normale.\nApplicazione della Prior e Calcolo della Posterior: Moltiplicheremo la log-verosimiglianza per la log-prior (se applicabile) e normalizzeremo per ottenere la distribuzione a posteriori.\nVisualizzazione: Infine, visualizzeremo la distribuzione a posteriori della media.\n\nProcediamo con l‚Äôimplementazione in Python:\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilit√†\nvera_media = 50  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione)\n\n# Definizione della griglia per la media\nmedia_griglia = np.linspace(start=40, stop=60, num=100)  \n\n# Calcolo della log-likelihood\nlog_likelihood = np.array([np.sum(stats.norm.logpdf(campione, loc=media, scale=sigma_conosciuta)) for media in media_griglia])\n\n# Calcoliamo la log-prior gaussiana\nlog_prior = stats.norm.logpdf(media_griglia, loc=40, scale=3)\n\n# Calcoliamo la log-posterior non normalizzata sommando log-likelihood e log-prior\nlog_posterior_non_norm = log_likelihood + log_prior  \n\n# Normalizziamo la log-posterior\nlog_posterior = log_posterior_non_norm - np.log(np.sum(np.exp(log_posterior_non_norm - np.max(log_posterior_non_norm))))\nposterior = np.exp(log_posterior)\n\n# Visualizzazione della distribuzione a posteriori\nplt.plot(media_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media (Log-verosimiglianza)')\nplt.xlabel('Media')\nplt.ylabel('Probabilit√†')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_grid_gauss.html#deviazione-standard-ignota",
    "href": "chapters/probability/14_grid_gauss.html#deviazione-standard-ignota",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.3 Deviazione Standard Ignota",
    "text": "35.3 Deviazione Standard Ignota\nEstendere l‚Äôapproccio usato sopra al caso in cui la deviazione standard (\\(\\sigma\\)) della popolazione non √® conosciuta introduce una complessit√† maggiore nell‚Äôinferenza bayesiana, poich√© ora dobbiamo stimare due parametri (la media e la deviazione standard) invece di uno solo. In questo contesto, la distribuzione a posteriori diventa una funzione delle due dimensioni (media e \\(\\sigma\\)), e la sua esplorazione richiede metodi pi√π sofisticati per navigare efficacemente lo spazio dei parametri. Vediamo come affrontare questo problema:\n\n35.3.1 1. Definizione dello Spazio dei Parametri\nDobbiamo definire una griglia bidimensionale che copra le possibili combinazioni di valori per la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)). Questo approccio, sebbene computazionalmente intensivo, √® fattibile per problemi di dimensioni moderate.\n\nmu_griglia = np.linspace(start=40, stop=60, num=100)\nsigma_griglia = np.linspace(start=1, stop=10, num=50)\n\n\n\n35.3.2 2. Calcolo della Log-Likelihood Bidimensionale\nPer ogni coppia di valori (\\(\\mu\\), \\(\\sigma\\)) nella griglia, calcoliamo la log-likelihood del campione. Questo richiede un‚Äôiterazione su entrambe le dimensioni della griglia.\n\nlog_likelihood_2d = np.array([[np.sum(stats.norm.logpdf(campione, loc=mu, scale=sigma))\n                                for sigma in sigma_griglia] for mu in mu_griglia])\n\n\n\n35.3.3 3. Applicazione delle Priors\nLe priors per \\(\\mu\\) e \\(\\sigma\\) possono essere definite in modo indipendente e poi combinate, o si pu√≤ definire una prior congiunta che rifletta la conoscenza o le assunzioni sui parametri. Le log-priors per \\(\\mu\\) e \\(\\sigma\\) sono calcolate su ogni griglia rispettivamente e poi sommate per ottenere una log-prior congiunta.\n\nlog_prior_mu = stats.norm.logpdf(mu_griglia, loc=40, scale=5)\nlog_prior_sigma = stats.norm.logpdf(sigma_griglia, loc=5, scale=2)\nlog_prior_2d = log_prior_mu[:, np.newaxis] + log_prior_sigma\n\n\n\n35.3.4 4. Calcolo della Distribuzione a Posteriori Bidimensionale\nSommando la log-likelihood con la log-prior congiunta e normalizzando, otteniamo la distribuzione a posteriori bidimensionale.\n\nlog_posterior_2d = log_likelihood_2d + log_prior_2d\nlog_posterior_2d -= np.max(log_posterior_2d)  # Stabilizzazione\nposterior_2d = np.exp(log_posterior_2d)\nposterior_2d /= np.sum(posterior_2d)\n\n\n\n35.3.5 5. Visualizzazione\nLa visualizzazione di distribuzioni bidimensionali pu√≤ essere effettuata tramite contour plot o heatmaps.\n\nplt.contourf(mu_griglia, sigma_griglia, posterior_2d.T)\nplt.xlabel('Media ($\\mu$)')\nplt.ylabel('Deviazione Standard ($\\sigma$)')\nplt.colorbar(label='Densit√† Posterior')\nplt.title('Distribuzione a Posteriori Bidimensionale')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_grid_gauss.html#conclusione-e-riflessioni-finali",
    "href": "chapters/probability/14_grid_gauss.html#conclusione-e-riflessioni-finali",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.4 Conclusione e Riflessioni Finali",
    "text": "35.4 Conclusione e Riflessioni Finali\nQuesto approccio richiede di navigare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, rendendo l‚Äôanalisi pi√π computazionalmente intensiva. Inoltre, la scelta delle priors per pi√π parametri richiede attenzione, poich√© influenzer√† direttamente le stime a posteriori.\nPer problemi con pi√π dimensioni o quando l‚Äôesplorazione della griglia diventa impraticabile, metodi come il campionamento di Markov Chain Monte Carlo (MCMC) diventano essenziali. Questi metodi permettono di campionare efficacemente dalla distribuzione a posteriori senza dover esplorare esplicitamente tutto lo spazio dei parametri.\nIn sintesi, l‚Äôestensione dell‚Äôapproccio bayesiano a casi in cui pi√π parametri sono sconosciuti richiede una maggiore attenzione nella definizione dello spazio dei parametri, nella scelta delle priors, e nel calcolo delle distribuzioni a posteriori",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Mar 20 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.1\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "36¬† Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa introduce l‚Äôinferenza bayesiana, una metodologia statistica per stimare un parametro di interesse \\(\\theta\\) (come la media di una popolazione o il coefficiente di regressione) utilizzando il Teorema di Bayes. L‚Äôapproccio bayesiano considera sia i dati osservati che le conoscenze iniziali per ottenere una stima del parametro \\(\\theta\\) sotto forma di una distribuzione di probabilit√†, nota come distribuzione a posteriori.\nIn questa parte del materiale, esploreremo il processo di aggiornamento bayesiano e le tecniche per sintetizzare la distribuzione a posteriori. Discuteremo delle famiglie di distribuzioni coniugate, concentrandoci principalmente sul caso beta-binomiale, poich√© consentono una derivazione analitica della distribuzione a posteriori.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "37¬† Modellazione bayesiana",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® introdurre il quadro concettuale della modellizzazione bayesiana. L‚Äôapproccio bayesiano alla statistica si distingue non solo per l‚Äôuso del Teorema di Bayes, ma anche per il modo in cui gestisce l‚Äôincertezza e valuta l‚Äôintero spettro di possibili esiti attraverso le distribuzioni di probabilit√†. La modellazione bayesiana segue un approccio metodologico strutturato in diverse fasi: progettazione del modello, applicazione del teorema di Bayes e valutazione critica del modello. Questo flusso di lavoro bayesiano (Baribault e Collins 2023) costituisce un ciclo di apprendimento e miglioramento continuo, in cui l‚Äôobiettivo non √® trovare una ‚Äúverit√† ultima‚Äù fissa e immutabile, ma aggiornare continuamente in modo razionale il grado di certezza attribuito alle ipotesi, sulla base delle nuove evidenze disponibili.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-statistica",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-statistica",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.1 Inferenza Statistica",
    "text": "37.1 Inferenza Statistica\nL‚Äôinferenza statistica si configura come un processo che integra deduzione e induzione, finalizzato all‚Äôesame di dati campionari per dedurre le propriet√† di una popolazione pi√π ampia. Immaginiamo di analizzare l‚Äôaltezza di cinque soggetti selezionati casualmente. Un meccanismo sottostante, che chiameremo ‚Äúprocesso T‚Äù, governa la determinazione delle loro altezze. Comprendere o stimare questo processo √® l‚Äôobiettivo dell‚Äôinferenza statistica. La natura di T √® spesso avvolta nel mistero, oscurata dalla variabilit√† dei dati che osserviamo. Questa variabilit√† pu√≤ essere scissa in due grandi cause: la variabilit√† intrinseca del fenomeno sotto osservazione (come differenze genetiche o ambientali) e le limitazioni delle nostre capacit√† di osservazione e analisi.\nMcElreath (2020) nel suo lavoro ‚ÄúStatistical Rethinking‚Äù introduce il concetto di ‚ÄúGrande Mondo‚Äù, che rappresenta l‚Äôinfinit√† di processi possibili che potrebbero spiegare le nostre osservazioni. Di fronte a questa infinit√†, effettuare inferenze dirette su tutte le possibili propriet√† del Grande Mondo si rivela impraticabile. Ci orientiamo quindi verso il ‚ÄúPiccolo Mondo‚Äù, una rappresentazione semplificata che considera un insieme finito di modelli e parametri ritenuti rilevanti per il nostro studio. Per esempio, nell‚Äôanalisi dell‚Äôaltezza, potremmo proporre un modello probabilistico in cui l‚Äôaltezza segue una distribuzione normale, caratterizzata da una media (¬µ) e una deviazione standard (œÉ), con l‚Äôintento di stimare questi parametri ignoti.\nLa collezione di distribuzioni di probabilit√† derivante dalla variazione dei parametri del modello nel Piccolo Mondo costituisce la funzione di verosimiglianza. Questo insieme, tuttavia, √® spesso troppo ampio per essere gestito con facilit√†. La nostra conoscenza pregressa o le nostre convinzioni riguardo al fenomeno in esame ci assistono nel restringere le possibilit√†.\nNell‚Äôinferenza bayesiana, queste convinzioni iniziali vengono espresse tramite una densit√† di probabilit√† a priori, che attribuisce un peso ai possibili parametri del modello in base alle nostre convinzioni iniziali. La regola di Bayes sta al cuore dell‚Äôinferenza bayesiana, permettendoci di aggiornare queste convinzioni alla luce dei nuovi dati osservati. Attraverso questo processo, otteniamo la probabilit√† a posteriori dei parametri, che fornisce una stima pi√π accurata del processo generativo dei dati, T.\nL‚Äôinferenza statistica, dunque, ci avvicina alla comprensione di fenomeni complessi attraverso la modellazione delle osservazioni via processi semplificati nel ‚ÄúPiccolo Mondo‚Äù. Grazie all‚Äôinferenza bayesiana, che integra le conoscenze pregresse ai nuovi dati, perfezioniamo le nostre stime per una comprensione pi√π profonda del vero processo sottostante.\nLa nota affermazione di Box, Luceno, e del Carmen Paniagua-Quinones (2011)\n\nTutti i modelli sono sbagliati, ma alcuni sono utili\n\ncattura l‚Äôessenza dell‚Äôinferenza statistica. Non miriamo a un ‚Äúmodello perfetto‚Äù che rifletta ogni dettaglio del ‚ÄúGrande Mondo‚Äù, bens√¨ a individuare modelli del ‚ÄúPiccolo Mondo‚Äù che siano efficaci nel fare previsioni sul fenomeno studiato.\nAttraverso la statistica, disponiamo degli strumenti per costruire, valutare e selezionare modelli basati sull‚Äôinferenza bayesiana, che ci consentono di aggiornare e rifinire i nostri modelli in risposta a nuove informazioni. Questo processo ci guida verso modelli ‚Äúutili‚Äù, che, seppur non perfetti, ci permettono di fare previsioni accurate e di approfondire la nostra comprensione del fenomeno di interesse.\n\n37.1.1 I Metodi Bayesiani in Psicologia\nNell‚Äôambito dell‚Äôinferenza statistica, i metodi bayesiani hanno guadagnato sempre popolarit√† anche in psicologia, dove l‚Äôadozione di approcci bayesiani ha visto una crescita esponenziale, grazie anche alla disponibilit√† di risorse educative e pubblicazioni specializzate. In particolare, diversi testi di rilievo hanno contribuito in modo significativo a fornire agli studiosi gli strumenti necessari per applicare con successo l‚Äôinferenza bayesiana all‚Äôanalisi dei dati psicologici. Tra questi testi spiccano opere come quelle di Albert e Hu (2019), Johnson, Ott, e Dogucu (2022), McElreath (2020) e Kruschke (2014), che hanno svolto un ruolo fondamentale nel facilitare l‚Äôintegrazione dei metodi bayesiani nella pratica analitica della psicologia.\n\n\n37.1.2 Approccio Bayesiano alla Statistica\nL‚Äôapproccio bayesiano alla statistica si distingue non solo per l‚Äôuso del Teorema di Bayes, ma anche per il suo modo di gestire l‚Äôincertezza e di valutare l‚Äôintero spettro di possibili esiti attraverso le distribuzioni di probabilit√†. Questo approccio rifiuta l‚Äôadozione acritica di stime puntuali, favorendo invece una visione probabilistica che accoglie una vasta gamma di esiti, rimanendo fedele alla concezione bayesiana della probabilit√†.\n\n\n37.1.3 Elementi Fondamentali della Modellazione Statistica Bayesiana\nI fondamenti della modellazione statistica bayesiana includono variabili casuali, distribuzioni di probabilit√† priori e posteriori, e il processo di aggiornamento bayesiano.\n\nVariabili casuali rappresentano elementi chiave nella modellazione bayesiana, consentendoci di esprimere e quantificare relazioni probabilistiche.\nDistribuzioni di probabilit√† sono strumenti cruciali per rappresentare quantitativamente l‚Äôincertezza e le conoscenze pregresse. Le distribuzioni priori esprimono le nostre convinzioni iniziali, mentre le distribuzioni posteriori risultano dall‚Äôintegrazione delle nuove evidenze.\nL‚Äôaggiornamento bayesiano √® il meccanismo che affina le distribuzioni priori alla luce di nuovi dati, riducendo l‚Äôincertezza e migliorando le stime dei parametri.\n\nLa modellazione bayesiana segue un approccio metodologico strutturato in progettazione del modello, applicazione del teorema di Bayes, e valutazione critica del modello. Questo flusso di lavoro bayesiano (Baribault e Collins 2023) costituisce un ciclo di apprendimento e affinamento continuo, che esploreremo nei capitoli successivi per una comprensione approfondita del processo.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#riesame-del-teorema-di-bayes",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#riesame-del-teorema-di-bayes",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.1 Riesame del Teorema di Bayes",
    "text": "37.1 Riesame del Teorema di Bayes\nPrima di esplorare il flusso di lavoro bayesiano, √® utile rivisitare il teorema di Bayes nelle sue diverse forme.\n\n37.1.1 Caso di Probabilit√† Discrete\nPer eventi discreti osservabili, il teorema di Bayes si esprime come:\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i) \\cdot P(H_i)}{P(O)}\n\\]\ndove:\n\n\\(P(H_i \\mid O)\\) √® la probabilit√† dell‚Äôipotesi \\(H_i\\) data l‚Äôosservazione \\(O\\),\n\\(P(O \\mid H_i)\\) √® la probabilit√† dell‚Äôosservazione \\(O\\) data l‚Äôipotesi \\(H_i\\),\n\\(P(H_i)\\) √® la probabilit√† a priori dell‚Äôipotesi \\(H_i\\),\n\\(P(O)\\) √® la probabilit√† marginale dell‚Äôosservazione \\(O\\), calcolata come somma delle probabilit√† congiunte di tutte le ipotesi.\n\n\n\n37.1.2 Caso di Densit√† di Probabilit√†\nIn molte applicazioni statistiche, siamo interessati a stimare parametri continui basandoci su dati osservati. In questo contesto, passiamo dalla notazione per probabilit√† discrete a quella per distribuzioni di probabilit√†. Consideriamo un dato osservato \\(y\\) e un parametro \\(\\theta\\). Il teorema di Bayes pu√≤ essere riformulato come:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) \\cdot p(\\theta)}{p(y)}\n\\tag{37.1}\\]\ndove:\n\n\\(p(\\cdot)\\) rappresenta una funzione di densit√† di probabilit√†,\n\\(p(\\theta \\mid y)\\) √® la distribuzione posteriore del parametro \\(\\theta\\) alla luce dei dati \\(y\\),\n\\(p(y \\mid \\theta)\\) √® la funzione di verosimiglianza,\n\\(p(\\theta)\\) √® la distribuzione a priori del parametro \\(\\theta\\),\n\\(p(y)\\) √® la verosimiglianza marginale, calcolata come:\n\\[ p(y) = \\int p(y \\mid \\theta) p(\\theta) \\, d\\theta .\\]\n\nL‚ÄôEquazione¬†37.1 pu√≤ essere interpretata verbalmente come:\n\\[\n\\text{Posteriore} = \\frac{\\text{Verosimiglianza} \\times \\text{A Priori}}{\\text{Verosimiglianza Marginale}}.\n\\]\nPossiamo attribuire ai termini dell‚ÄôEquazione¬†37.1 il seguente significato.\n\nPosteriore \\(p(\\theta \\mid y)\\): √à la distribuzione di probabilit√† del parametro \\(\\theta\\) condizionata ai dati osservati \\(y\\). Rappresenta la nostra conoscenza aggiornata sul parametro dopo aver considerato i dati.\nVerosimiglianza \\(p(y \\mid \\theta)\\): Questa √® la probabilit√† (o densit√†) dei dati osservati \\(y\\), espressa come funzione del parametro \\(\\theta\\).\nA Priori \\(p(\\theta)\\): √à la distribuzione di probabilit√† iniziale del parametro \\(\\theta\\), prima di osservare i dati. Pu√≤ basarsi su conoscenze pregresse o assumere forme non informative per minimizzare l‚Äôinfluenza sulle inferenze.\nVerosimiglianza Marginale \\(p(y)\\): Questo termine normalizza la distribuzione posteriore, assicurando che integri a 1 e sia quindi una distribuzione di probabilit√† valida.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#costruzione-del-modello-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#costruzione-del-modello-dellaggiornamento-bayesiano",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.2 Costruzione del Modello dell‚ÄôAggiornamento Bayesiano",
    "text": "37.2 Costruzione del Modello dell‚ÄôAggiornamento Bayesiano\nPer spiegare il concetto di aggiornamento bayesiano in maniera intuitiva, McElreath (2020) propone il seguente esempio. Supponiamo di avere un mappamondo e di volere stimare qual √® la proporzione coperta d‚Äôacqua del globo. Per stimare questa proporzione eseguiamo il seguente esperimento casuale: lanciamo in aria il mappamondo e poi lo afferriamo quando cade. Registriamo se la superficie sotto il nostro indice destro √® terra o acqua. Ripetiamo questa procedura un certo numero di volte e calcoliamo la proporzione di volte in cui abbiamo osservato ‚Äúacqua‚Äù. In ogni lancio, ogni valore della proporzione sconosciuta \\(p\\) pu√≤ essere pi√π o meno plausibile, date le evidenze fornite dai lanci precedenti.\nUn modello bayesiano inizia assegnando un insieme di plausibilit√† iniziali a ciascuno dei possibili valori \\(p\\), dette plausibilit√† priori. Poi, queste plausibilit√† vengono aggiornate alla luce dei dati raccolti, producendo le plausibilit√† posteriori. Questo processo di aggiornamento √® una forma di apprendimento, conosciuto come aggiornamento bayesiano.\nNell‚Äôesempio di McElreath (2020), supponiamo che il nostro modello bayesiano assegni inizialmente la stessa plausibilit√† a ogni possibile valore di \\(p\\) (proporzione di acqua). Ora, osserviamo il primo grafico in alto a sinistra nella figura generata dallo script. La linea tratteggiata orizzontale rappresenta la plausibilit√† iniziale di ciascun possibile valore di \\(p\\). Dopo aver visto il primo lancio, che risulta in ‚ÄúW‚Äù (acqua), il modello aggiorna le plausibilit√† alla linea continua. La plausibilit√† che \\(p\\) = 0 scende a zero, indicando che √® ‚Äúimpossibile‚Äù non avere acqua, dato che abbiamo osservato almeno una traccia di acqua sul globo. Allo stesso modo, la plausibilit√† che \\(p\\) &gt; 0.5 aumenta, poich√© non c‚Äô√® ancora evidenza di terra sul globo, quindi le plausibilit√† iniziali vengono modificate per essere coerenti con questa osservazione. Tuttavia, le differenze nelle plausibilit√† non sono ancora molto grandi, poich√© le evidenze raccolte finora sono limitate. In questo modo, la quantit√† di evidenza vista finora si riflette nelle plausibilit√† di ciascun valore di \\(p\\): la plausibilit√† che \\(p\\) sia 0 √® zero e la plausibilit√† che \\(p\\) sia 1 √® massima. Quindi, la distribuzione a posteriori di \\(p\\) √® rappresentata dalla linea continua che collega questi due estremi.\nNei grafici successivi, vengono introdotti ulteriori campioni dal globo, uno alla volta. Ogni curva tratteggiata rappresenta la curva continua dal grafico precedente, spostandosi da sinistra a destra e dall‚Äôalto in basso. La seconda osservazione √® ‚Äúterra‚Äù (L). La distribuzione a priori √® la linea tratteggiata del secondo pannello e la distribuzione a postriori √® la linea curva. Otteniamo questa curva perch√© assegniamo una verosimiglianza 0 agli eventi \\(p\\) = 0 (abbiamo osservato ‚Äúacqua‚Äù) e \\(p\\) = 1 (abbiamo osservato ‚Äúterra‚Äù). In due lanci abbiamo osservato una volta ‚Äúterra‚Äù e una volta ‚Äúacqua‚Äù. Dunque la plausibilit√† che \\(p\\) = 0.5 √® massima. Da cui la curva che abbiamo disegnato.\nIl terzo lancio del mappamondo produce nuovamente ‚Äúacqua‚Äù. Quindi a questo punto il valore pi√π plausibile di \\(p\\) √® 0.75. modifichiamo dunque la distribuzione a priori (linea tratteggiata nel terzo pannello) in modo da rappresentare le nostre nuove conoscenze, come indicato dalla linea continua.\nOgni volta che viene osservato un ‚ÄúW‚Äù, il picco della curva di plausibilit√† si sposta a destra, verso valori maggiori di \\(p\\). Ogni volta che viene osservato un ‚ÄúL‚Äù (terra), si sposta nella direzione opposta. L‚Äôaltezza massima della curva aumenta con ogni campione, significando che la plausibilit√† complessiva (1) viene ridistribuita ad un numero minore di valori di \\(p\\) i quali accumulano una maggiore plausibilit√† man mano che aumenta la quantit√† di evidenza. Con l‚Äôaggiunta di ogni nuova osservazione, la curva viene aggiornata in modo coerente con tutte le osservazioni precedenti.\n√à importante notare che ogni set aggiornato di plausibilit√† diventa la plausibilit√† iniziale per l‚Äôosservazione successiva. Ogni conclusione √® il punto di partenza per l‚Äôinferenza futura. Questo processo di aggiornamento funziona anche al contrario: conoscendo l‚Äôultimo set di plausibilit√† e l‚Äôultima osservazione, √® possibile matematicamente dedurre la curva di plausibilit√† precedente. I dati potrebbero essere presentati al modello in qualsiasi ordine, o anche tutti insieme. Nella maggior parte dei casi, i dati verranno considerati tutti insieme per comodit√†, ma √® importante capire che ci√≤ rappresenta solo l‚Äôabbreviazione di un processo di apprendimento iterato.\n\ndef beta(W, L, p):\n    return factorial(W + L + 1) / (factorial(W) * factorial(L)) * p ** W * (1-p) ** L\n\n\ndef plot_beta_from_observations(observations: str, resolution: int = 50, **plot_kwargs):\n    \"\"\"Calcualte the posterior for a string of observations\"\"\"\n    n_W = len(observations.replace(\"L\", \"\"))\n    n_L = len(observations) - n_W\n    proportions = np.linspace(0, 1, resolution)\n        \n    probs = beta(n_W, n_L, proportions)\n    plt.plot(proportions, probs, **plot_kwargs)\n    plt.yticks([])\n    plt.title(observations)\n    \n\n# Tossing the globe\nobservations = \"WLWWWLWLW\"\nfig, axs = plt.subplots(3, 3, figsize=(8, 8))\nfor ii in range(9):\n    ax = axs[ii // 3][ii % 3]\n    plt.sca(ax)\n    # Plot previous\n    if ii &gt; 0:\n        plot_beta_from_observations(observations[:ii], color='k', linestyle='--')\n    else:\n        # First observation, no previous data\n        plot_beta_from_observations('', color='k', linestyle='--')\n        \n    color = 'C1' if observations[ii] == 'W' else 'C0'\n    plot_beta_from_observations(observations[:ii+1], color=color, linewidth=4, alpha=.5)\n    \n    if not ii % 3:\n        plt.ylabel(\"posterior probability\")\n\n\n\n\n\n\n\n\nIl lettore attento si sar√† chiesto se la curva continua dell‚Äôultimo pannello non sia in realt√† identica alla funzione di verosimiglianza binomiale con 6 successi in 9 prove ‚Äì si veda il Capitolo 34. In effetti √® proprio cos√¨. Lo stesso vale, ovviamente, per ciascuno dei pannelli della figura.\n\ny = 6\nn = 9\ntheta = np.linspace(0.0, 1.0, num=100)\n\nlike = stats.binom.pmf(y, n, theta)\n\nplt.plot(theta, like, \"-\", linewidth=4, alpha=.5)\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\n_ = plt.ylabel(\"Verosimiglianza\")\n\n\n\n\n\n\n\n\nQuesto esempio illustra come la funzione di probabilit√† a posteriori si modifichi progressivamente con l‚Äôacquisizione di nuove evidenze. Tale processo avviene in maniera automatica, riflettendo il meccanismo di aggiornamento delle credenze che caratterizza l‚Äôinferenza bayesiana. In ogni pannello, la transizione dalla linea tratteggiata alla linea piena simboleggia questo aggiornamento: la linea tratteggiata rappresenta la distribuzione di probabilit√† a priori, ovvero le nostre credenze iniziali prima dell‚Äôosservazione dei nuovi dati; la linea piena, invece, rappresenta la distribuzione di probabilit√† a posteriori, che integra le nuove evidenze ai preconcetti iniziali. Quest‚Äôultima rispecchia dunque una sintesi ottimizzata delle informazioni pregresse e attuali, offrendo una rappresentazione aggiornata e pi√π accurata della realt√† in esame.\n\n37.2.1 Il flusso di lavoro bayesiano\nMetaforicamente descritto come ‚Äúgirare la manovella bayesiana‚Äù, il flusso di lavoro bayesiano √® composto da diverse fasi.\n\nStudio di Simulazione: Questa fase prevede la generazione di dati sintetici che riproducono il contesto di ricerca. Questo aiuta a valutare la robustezza del disegno sperimentale e ad assicurare che il modello sia adeguato.\nRaccolta e Identificazione dei Dati: Qui si acquisiscono e analizzano i dati reali, assicurandosi che siano appropriati per le analisi successive.\nSelezione del Modello Statistico: In questa fase si formula un modello statistico che rappresenta le teorie e le ipotesi alla base della ricerca, basandosi su una solida comprensione del fenomeno e su principi statistici.\nDefinizione delle Distribuzioni a Priori: Si stabiliscono le distribuzioni a priori dei parametri del modello, basandosi su conoscenze pregresse e un ragionamento teorico robusto.\nCalcolo delle Distribuzioni a Posteriori: Utilizzando metodi analitici o tecniche di campionamento come le Catene di Markov Monte Carlo (MCMC), si derivano le distribuzioni a posteriori dei parametri.\nRisoluzione dei Problemi e Diagnostica: In questa fase si eseguono controlli per assicurare la convergenza del modello e la validit√† delle inferenze, utilizzando metriche e diagnosi specializzate.\nControlli di Coerenza: Oltre alla diagnostica tecnica, si valuta la coerenza e la plausibilit√† del modello rispetto ai dati e al contesto teorico, incluso un esame predittivo a posteriori.\nInterpretazione e Comunicazione dei Risultati: Infine, i risultati vengono interpretati nel contesto della teoria sottostante e comunicati in modo chiaro, integrandoli nell‚Äôambito pi√π ampio della comprensione del fenomeno in studio.\n\nQuesto processo iterativo mira a ottenere inferenze valide, fornendo una base solida per la ricerca scientifica. Una rappresentazione visiva di questo flusso di lavoro bayesiano √® illustrata nella figura tratta dall‚Äôarticolo di Baribault e Collins (2023).\n\n\n\n\n\n\nFigura¬†37.1: Una rappresentazione abbreviata del flusso di lavoro bayesiano. L‚Äôoutput del modello che non supera il filtro (che rappresenta i necessari controlli computazionali e di coerenza) deve essere respinto. √à necessario migliorare la specifica del modello in modo che l‚Äôoutput possa superare tutti i controlli. Solo allora il modello bayesiano pu√≤ essere utilizzato come base per l‚Äôinferenza. (Figura tratta da Baribault e Collins (2023)).",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#notazione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#notazione",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.4 Notazione",
    "text": "37.4 Notazione\nLa costruzione di modelli statistici bayesiani, che utilizzano un approccio probabilistico per caratterizzare l‚Äôincertezza, richiede una conoscenza preliminare del linguaggio e delle notazioni matematiche impiegate in questi modelli. Questa comprensione facilita la comunicazione delle caratteristiche del modello e permette di estendere il linguaggio di modellazione a diversi domini.\nIn seguito, utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo \\(x\\) per denotare le quantit√† note, come i predittori di un modello lineare.\nPer rappresentare i modelli probabilistici (ovvero, i modelli generatori dei dati) in modo pi√π conciso, adotteremo una notazione specifica. Ad esempio, invece di scrivere la distribuzione di probabilit√† di \\(\\theta\\) come \\(p(\\theta) = Beta(1, 1)\\), scriveremo semplicemente \\(\\theta \\sim Beta(1, 1)\\). Il simbolo ‚Äú\\(\\sim\\)‚Äù si legge come ‚Äúsegue la distribuzione di‚Äù. Possiamo anche interpretarlo nel senso che \\(\\theta\\) √® un campione casuale estratto dalla distribuzione Beta(1, 1). Analogamente, la verosimiglianza di un modello binomiale sar√† espressa come \\(y \\sim \\text{Bin}(n, \\theta)\\), dove ‚Äú\\(\\sim\\)‚Äù indica che \\(y\\) segue una distribuzione binomiale con parametri \\(n\\) e \\(\\theta\\). Questa notazione semplifica la rappresentazione dei modelli probabilistici, rendendo pi√π chiara la relazione tra i dati, i parametri e le distribuzioni di probabilit√† coinvolte nelle analisi statistiche.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#metodi-di-stima-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#metodi-di-stima-della-distribuzione-a-posteriori",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.5 Metodi di Stima della Distribuzione a Posteriori",
    "text": "37.5 Metodi di Stima della Distribuzione a Posteriori\nNella modellizzazione bayesiana, \\(\\theta\\) √® solitamente una variabile casuale continua. In tali circostanze, la distribuzione posteriore si formula come segue:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) \\cdot p(\\theta)}{\\int_{\\Theta} p(y \\mid \\theta) \\cdot p(\\theta) \\, d\\theta}, \\quad \\text{dove} \\quad \\theta \\in \\Theta,\n\\]\ndove \\(\\Theta\\) denota l‚Äôinsieme di tutti i possibili valori del parametro \\(\\theta\\).\nIl calcolo di \\(p(\\theta \\mid y)\\) richiede la normalizzazione del prodotto tra la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) e la distribuzione a priori \\(p(\\theta)\\) attraverso una costante di normalizzazione. Questa costante, nota come verosimiglianza marginale, assicura che l‚Äôintegrale di \\(p(\\theta \\mid y)\\) su tutto lo spazio dei parametri \\(\\Theta\\) sia pari a uno.\n\n37.5.1 Esempio di Calcolo della Verosimiglianza Marginale\nConsideriamo una variabile casuale binomiale \\(Y\\) con funzione di massa di probabilit√† (PMF) \\(p(Y)\\) in relazione a un parametro \\(\\theta\\). Supponiamo che \\(\\theta\\) possa assumere uno di tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con probabilit√† \\(\\frac{1}{3}\\).\nFissiamo i dati a \\(n = 10\\) prove e \\(k = 7\\) successi, ottenendo la seguente funzione di likelihood:\n\\[\np(k = 7, n = 10 | \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la verosimiglianza marginale \\(p(k = 7, n = 10)\\), marginalizziamo il parametro \\(\\theta\\) valutando la likelihood per ciascun valore possibile di \\(\\theta\\), moltiplicandola per la probabilit√† di quel valore di \\(\\theta\\) e sommando i risultati ottenuti:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 | \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e la loro probabilit√†:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesto processo mostra come la marginalizzazione incorpori tutte le possibili variazioni di \\(\\theta\\), ottenendo una misura complessiva che considera l‚Äôincertezza su \\(\\theta\\).\n\n\n37.5.2 Implementazione in Python\nPer implementare questo calcolo in Python, possiamo definire una funzione che calcoli la likelihood per i valori discreti di \\(\\theta\\) e poi sommare i risultati. Per l‚Äôintegrazione su un intervallo continuo, possiamo utilizzare la libreria scipy.\n\n# Funzione di likelihood\ndef likelihood(theta, k=7, n=10):\n    return comb(n, k) * (theta**k) * ((1 - theta)**(n - k))\n\n# Likelihood marginale per valori discreti di theta\ntheta_vals = np.array([0.1, 0.5, 0.9])\nprob_theta = 1/3\nmarginal_likelihood_discrete = sum([likelihood(theta) * prob_theta for theta in theta_vals])\n\nprint(f\"Likelihood Marginale (discreta): {marginal_likelihood_discrete}\")\n\n# Likelihood marginale su un intervallo continuo [0, 1]\nmarginal_likelihood_continuous, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(f\"Likelihood Marginale (continua): {marginal_likelihood_continuous}\")\n\nLikelihood Marginale (discreta): 0.05819729199999999\nLikelihood Marginale (continua): 0.09090909090909091\n\n\n\n\n37.5.3 Metodi per Determinare la Distribuzione a Posteriori\nEsistono due approcci principali per determinare la distribuzione posteriore:\n\nApproccio Analitico: Questo metodo si applica quando la distribuzione a priori e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, dette coniugate. In questi casi, √® possibile calcolare analiticamente la distribuzione posteriore. Questo approccio √® efficiente ma limitato alle situazioni con coniugazione tra distribuzioni a priori e funzioni di verosimiglianza.\nApproccio Numerico: Quando l‚Äôapproccio analitico non √® applicabile, si usano tecniche di approssimazione numerica. Le catene di Markov Monte Carlo (MCMC) sono spesso impiegate per stimare numericamente la distribuzione posteriore. Questo metodo √® versatile ma richiede un maggiore impegno computazionale.\n\n\n\n37.5.4 Linguaggi di Programmazione Probabilistici\nL‚Äôuso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori √® facilitato dai linguaggi di programmazione probabilistica (PPL). Questi strumenti rendono la modellazione bayesiana pi√π accessibile, riducendo le barriere di competenza matematica e computazionale. I PPL permettono agli analisti di formulare modelli probabilistici con maggiore chiarezza e flessibilit√†, aprendo nuovi orizzonti nell‚Äôanalisi bayesiana e permettendo di affrontare problemi complessi con tecniche bayesiane avanzate.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.6 Commenti e considerazioni finali",
    "text": "37.6 Commenti e considerazioni finali\nNell‚Äôambito dell‚Äôinferenza statistica, i metodi bayesiani stanno guadagnando una crescente popolarit√† anche in psicologia. Questa tendenza √® sostenuta dalla disponibilit√† di risorse educative e pubblicazioni specializzate che facilitano l‚Äôintegrazione dei metodi bayesiani nella pratica analitica. Opere come quelle di Albert e Hu (2019), Johnson, Ott, e Dogucu (2022), McElreath (2020) e Kruschke (2014) hanno svolto un ruolo cruciale in questo contesto, rendendo accessibili e comprensibili i concetti fondamentali della modellizzazione bayesiana.\nL‚Äôapproccio bayesiano offre una prospettiva unica sull‚Äôincertezza associata ai parametri di interesse, differenziandosi dalla metodologia frequentista basata sul test dell‚Äôipotesi nulla. Mentre il paradigma frequentista considera i parametri come valori fissi e sconosciuti, l‚Äôapproccio bayesiano li tratta come quantit√† probabilistiche, assegnando loro una distribuzione a priori che riflette le credenze iniziali. Attraverso il teorema di Bayes, queste credenze vengono aggiornate sulla base dei dati osservati, portando alla definizione della distribuzione a posteriori. Questa distribuzione fornisce una visione aggiornata dell‚Äôincertezza, integrando sia l‚Äôevidenza empirica che le informazioni pregresse.\nLa forza dell‚Äôapproccio bayesiano risiede nella sua capacit√† di combinare conoscenze pregresse con nuove osservazioni, producendo stime dei parametri di interesse che sono non solo pi√π accurate ma anche pi√π significative dal punto di vista interpretativo. Pi√π di un semplice strumento statistico, il bayesianesimo si rivela un potente mezzo decisionale, promuovendo un‚Äôinterazione dinamica tra teoria ed esperienza.\nTuttavia, uno svantaggio dell‚Äôapproccio bayesiano √® la sua potenziale inefficienza nel trattare dataset molto estesi. Questo pu√≤ comportare problemi di scalabilit√† e di efficienza computazionale, soprattutto con insiemi di dati di grandi dimensioni. Per affrontare questa sfida, sono in sviluppo metodi di variational inference, che offrono un‚Äôalternativa al campionamento MCMC. Questi metodi approssimativi permettono di calcolare la distribuzione a posteriori in tempi significativamente ridotti, migliorando l‚Äôefficienza computazionale senza sacrificare troppo la precisione delle stime.\nIn conclusione, l‚Äôapproccio bayesiano rappresenta un paradigma potente e flessibile per l‚Äôinferenza statistica, in grado di incorporare le conoscenze pregresse e aggiornarsi alla luce di nuove evidenze. Nonostante le sfide computazionali, i progressi nei metodi approssimativi come la variational inference promettono di rendere l‚Äôanalisi bayesiana sempre pi√π praticabile ed efficace, estendendo ulteriormente il suo utilizzo in campi come la psicologia e oltre.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html",
    "href": "chapters/bayesian_inference/02_subj_prop.html",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Introduzione\nQuesto capitolo mira a esplorare in profondit√† il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L‚Äôobiettivo √® dimostrare come le nostre credenze preesistenti sulla probabilit√† \\(\\theta\\) di un evento specifico possano essere affinate mediante l‚Äôosservazione di nuovi dati.\nInizieremo descrivendo come rappresentare le nostre convinzioni iniziali, ovvero quelle formulate prima di raccogliere qualsiasi dato, tramite una distribuzione a priori. Successivamente, delineeremo i passaggi calcolativi necessari per derivare la distribuzione a posteriori di \\(\\theta\\). Questa distribuzione rappresenta le nostre credenze aggiornate su \\(\\theta\\) una volta considerati i dati osservati. L‚Äôottenimento della distribuzione a posteriori avviene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, seguita da una normalizzazione per garantire che il risultato sia una distribuzione di probabilit√† valida.\nIl capitolo si focalizza principalmente sul modello binomiale, un contesto elementare ma cruciale per l‚Äôinferenza bayesiana. Questo modello √® utilizzato per stimare una proporzione di popolazione sconosciuta a partire da una serie di ‚Äúprove di Bernoulli‚Äù, ovvero dati \\(y_1, \\ldots, y_n\\), ciascuno dei quali assume valore 0 o 1. Questo problema rappresenta un punto di partenza relativamente semplice ma fondamentale per la discussione dell‚Äôinferenza bayesiana. Inizieremo esplorando il caso in cui la distribuzione a priori √® discreta, per poi passare all‚Äôanalisi di scenari in cui essa √® continua.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/02_subj_prop.html#verosimiglianza-binomiale",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.1 Verosimiglianza Binomiale",
    "text": "38.1 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova d√† origine a uno dei due possibili esiti, convenzionalmente etichettati come ‚Äòsuccesso‚Äô e ‚Äòfallimento‚Äô. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilit√† di successo in ciascuna prova. Il modello di campionamento binomiale √®:\n\\[ p(y|\\theta) = \\text{Bin}(y|n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}, \\]\ndove nella parte sinistra dell‚Äôequazione non si indica la dipendenza da \\(n\\) perch√© viene considerato parte del disegno sperimentale e fissato; tutte le probabilit√† discusse per questo problema sono considerate condizionate su \\(n\\), cio√® assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.2 Applicazione Specifica del Modello Binomiale",
    "text": "38.2 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, consideriamo un‚Äôapplicazione specifica del modello binomiale per stimare la proporzione di presenza di ideazione suicidaria all‚Äôinterno di una popolazione specifica. Prenderemo in esame lo studio di Comtois et al. (2023), in cui viene valutata l‚Äôefficacia di un intervento volto a prevenire l‚Äôideazione suicidaria nella comunit√† universitaria. I partecipanti allo studio erano pazienti reclutati secondo i seguenti criteri: 1. Ricovero ospedaliero o accesso al pronto soccorso per rischio suicidario. 2. Tentativo di suicidio nel mese precedente (compresi tentativi interrotti o auto-interrotti).\nNel gruppo di controllo dello studio, composto da 75 pazienti, √® stato somministrato il trattamento standard (TAU), che seguiva le politiche e procedure standard per i servizi brevi e orientati alla crisi. Questo trattamento comprendeva una valutazione iniziale seguita da 1-11 visite con un clinico (con una media di 4,5 visite) e gestione dei farmaci, se necessario, terminando con un rinvio a un altro servizio per il follow-up delle cure primarie o per un ulteriore trattamento per la salute mentale o l‚Äôabuso di sostanze.\nDopo 12 mesi, l‚Äôideazione suicidaria √® stata misurata utilizzando la Beck Scale for Suicide Ideation (BSS; Beck & Steer, 1993), la versione self-report della Scale for Suicide Ideation (Beck, Brown, & Steer, 1997), una misura valida e affidabile dell‚Äôideazione suicidaria. I dati mostrano che, dopo 12 mesi, 35 pazienti del gruppo TAU hanno riportato almeno un episodio di ideazione suicidaria. L‚Äôobiettivo dell‚Äôanalisi √® quantificare l‚Äôincertezza di questa stima di \\(\\theta\\), la proporzione di presenza di ideazione suicidaria in questa popolazione dopo un anno.\nConsideriamo ogni paziente come una prova bernoulliana in cui emerge (1) o non emerge (0) almeno un episodio di ideazione suicidaria nel corso dell‚Äôanno considerato. Utilizzando il modello binomiale, stimiamo quindi la probabilit√† \\(\\theta\\) di ideazione suicidaria nella popolazione e quantifichiamo l‚Äôincertezza associata a questa stima.\n\n38.2.1 Processo di Lavoro\nMcElreath (2020) descrive il flusso lavoro bayesiano nel modo seguente.\n\nDefinire un Modello Generativo per i Dati: Un modello generativo spiega come i dati sono stati prodotti. Nel nostro caso, consideriamo ogni paziente come un esperimento di Bernoulli con due possibili esiti: presenza (1) o assenza (0) di ideazione suicidaria. Definiamo \\(\\theta\\) come la probabilit√† di osservare ideazione suicidaria in un singolo paziente. Il modello generativo dei dati si esprime quindi come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, ..., 75\\) e \\(X_i\\) assume valore 1 in caso di presenza e 0 in caso di assenza di ideazione suicidaria.\nDefinire uno Stimatore per il Parametro di Interesse: Uno stimatore √® una regola o una formula che utilizza i dati del campione per calcolare una stima del parametro di interesse. Nel nostro caso, lo stimatore che cerchiamo √® la probabilit√† \\(\\theta\\) di osservare un episodio di ideazione suicidaria dopo 12 mesi dall‚Äôepisodio di crisi. L‚Äôobiettivo √® stimare l‚Äôincertezza di questa probabilit√† basandoci sui dati raccolti.\nSviluppare un Metodo Statistico per la Stima del Parametro di Interesse: Per stimare \\(\\theta\\), applichiamo l‚Äôapproccio bayesiano. Nella statistica bayesiana, partiamo da una distribuzione a priori che esprime le nostre convinzioni iniziali su \\(\\theta\\), per poi aggiornarla con i dati osservati e ottenere una distribuzione a posteriori. Una scelta comune per la priori in un contesto Bernoulli/Binomiale √® la distribuzione Beta. Partiamo da una priori non informativa, \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme.\nLa verosimiglianza dei nostri dati (35 ‚Äúsuccessi‚Äù, 40 ‚Äúinsuccessi‚Äù) √® data dalla distribuzione binomiale:\n\\[\nL(p) = {75 \\choose 35} \\theta^{35} (1-\\theta)^{40}.\n\\]\nUtilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}\n\\]\nValidazione del Modello attraverso Simulazioni: Prima di esaminare i dati concreti, effettuiamo una simulazione predittiva a priori per verificare se il modello pu√≤ generare dati plausibili. Dopo l‚Äôadattamento del modello ai dati veri, conduciamo una simulazione predittiva a posteriori per testare la capacit√† del modello di produrre dati comparabili a quelli osservati.\nAnalisi e Sintesi dei Risultati: Infine, procediamo con l‚Äôanalisi dei dati veri, calcolando la distribuzione a posteriori, solitamente attraverso metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per inferire su \\(\\theta\\), utilizzando statistiche descrittive quali media, mediana e intervalli di credibilit√†.\n\nNel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano",
    "text": "38.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano\nDopo aver discusso l‚Äôaggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia √® un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l‚Äôuso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilit√† sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l‚Äôarea totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "38.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente considerare un valore di 0.5, suggerendo una probabilit√† ugualmente bilanciata tra la presenza e l‚Äôassenza di ideazione suicidaria. Tuttavia, questo valore non rappresenta adeguatamente l‚Äôintero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilit√† distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilit√† a priori uguale, creando cos√¨ una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) pi√π probabili.\nDopo aver osservato i dati ‚Äî ad esempio, 35 casi di ideazione suicidaria su 75 ‚Äî applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilit√† a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilit√† a posteriori aggiornata per \\(\\theta\\).\nLa distribuzione a posteriori integra quindi le nostre conoscenze pregresse con le nuove informazioni ottenute dalle osservazioni, offrendoci una visione aggiornata e quantitativamente informata del parametro \\(\\theta\\). Attraverso questo esempio, possiamo osservare un approccio sistematico ed efficace per affinare le nostre credenze alla luce di nuove prove.\n\ntheta = np.linspace(0, 1, 11)\nprint(theta)\n\n[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n\n\nNel caso in cui non vi siano motivi fondati per assegnare probabilit√† diverse ai vari valori di \\(\\theta\\), √® possibile attribuire la stessa probabilit√† a ciascun valore, creando cos√¨ una distribuzione uniforme. √à importante prestare attenzione alla seconda riga di codice, che esegue una standardizzazione. Poich√© unif_discr_pdf √® un vettore composto da un numero finito di elementi, questi elementi devono essere considerati come probabilit√†, e tali probabilit√† devono obbligatoriamente sommarsi a uno.\n\nunif_distr_pdf = stats.uniform.pdf(theta) \nunif_distr_pdf = unif_distr_pdf / np.sum(unif_distr_pdf)\nunif_distr_pdf\n\narray([0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909])\n\n\nUna rappresentazione visiva di questa distribuzione di massa di probabilit√† si ottiene nel modo seguente.\n\nplt.stem(theta, unif_distr_pdf, markerfmt=\" \", linefmt=color_edge)\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nSe, al contrario, riteniamo che i valori centrali nella distribuzione di \\(\\theta\\) siano pi√π credibili rispetto a quelli situati agli estremi, potremmo esprimere questa opinione soggettiva mediante la seguente distribuzione di massa di probabilit√†.\n\nnot_unif_distr_pdf = [0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05]\nplt.stem(theta, not_unif_distr_pdf, markerfmt=\" \", linefmt=color_edge)\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nLa prima distribuzione di probabilit√† √® una distribuzione discreta uniforme, in quanto assegna la stessa probabilit√† a ciascun elemento dell‚Äôinsieme discreto su cui √® definita, ossia i valori \\(\\{0, 0.1, 0.2, \\dots, 1.0\\}\\). La seconda distribuzione di probabilit√†, pur essendo discreta, segue un andamento non uniforme: si presume che \\(\\theta\\) abbia una probabilit√† maggiore di assumere un valore nell‚Äôinsieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) rispetto all‚Äôinsieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).\nLe credenze iniziali riguardo ai possibili valori di \\(\\theta\\) costituiscono la ‚Äúdistribuzione a priori‚Äù. L‚Äôinferenza bayesiana aggiorna queste credenze iniziali utilizzando le informazioni ottenute dai dati. Queste informazioni vengono combinate con le credenze iniziali su \\(\\theta\\) attraverso l‚Äôapplicazione del teorema di Bayes, allo scopo di ottenere la ‚Äúdistribuzione a posteriori‚Äù. Quest‚Äôultima rappresenta le nostre credenze aggiornate sui possibili valori di \\(\\theta\\) dopo l‚Äôosservazione dei dati.\nSupponiamo di aver osservato 35 ‚Äúsuccessi‚Äù in 75 prove. Per calcolare la distribuzione a posteriori, utilizzeremo la seconda delle due distribuzioni a priori precedentemente descritte. In base al teorema di Bayes, la distribuzione a posteriori si ottiene moltiplicando la verosimiglianza per la distribuzione a priori e quindi dividendo per una costante di normalizzazione (la verosimiglianza marginale):\n\\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}. \\]\nPer calcolare la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), dobbiamo comprendere il processo mediante il quale i dati sono stati generati. Nel nostro contesto, i dati rappresentano i risultati di 75 ripetizioni di un esperimento casuale che pu√≤ produrre solo due risultati possibili: ‚Äúpresenza‚Äù e ‚Äúassenza‚Äù di ideazione suicidaria. Inoltre, i 75 casi esaminati sono tra loro indipendenti (i pazienti non si influenzano reciprocamente). In tali circostanze, possiamo assumere che il modello generativo dei dati sia il modello binomiale con probabilit√† sconosciuta \\(\\theta\\).\nUtilizzando Python, √® possibile calcolare la funzione di verosimiglianza tramite la funzione binom.pmf().\n\nlk = stats.binom.pmf(35, 70, theta)\nlk = lk / np.sum(lk)\nlk\n\narray([0.00000000e+00, 1.99180385e-16, 1.10906788e-07, 1.50811359e-03,\n       1.61492440e-01, 6.73998671e-01, 1.61492440e-01, 1.50811359e-03,\n       1.10906788e-07, 1.99180385e-16, 0.00000000e+00])\n\n\nPer i 10 valori \\(\\theta\\) considerati, la funzione di verosimiglianza assume la forma indicata dalla figura seguente.\n\nplt.stem(theta, lk, markerfmt=\" \", linefmt=color_edge)\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"$L(\\\\theta)$\");\n\n\n\n\n\n\n\n\nPer calcolare la distribuzione a posteriori, eseguiamo una moltiplicazione elemento per elemento tra il vettore contenente i valori della distribuzione a priori e il vettore contenente i valori della funzione di verosimiglianza. Usando Python, il risultato si trova nel modo seguente.\n\nnot_unif_distr_pdf * lk\n\narray([0.00000000e+00, 9.95901924e-18, 5.54533942e-09, 7.54056793e-05,\n       2.82611770e-02, 1.17949767e-01, 2.82611770e-02, 2.63919878e-04,\n       5.54533942e-09, 9.95901924e-18, 0.00000000e+00])\n\n\nPer illustrare con un esempio, il valore dell‚Äôottavo elemento della distribuzione a posteriori si calcola come segue (tenendo presente che in Python gli indici partono da 0):\n\nnot_unif_distr_pdf[7] * lk[7]\n\n0.0002639198775144677\n\n\nDopo questa moltiplicazione, otteniamo una distribuzione che rappresenta le probabilit√† condizionate dei possibili valori di \\(\\theta\\) alla luce dei dati osservati. Tuttavia, questa distribuzione potrebbe non √® normalizzata, il che significa che la somma di tutte le probabilit√† condizionate non √® uguale a 1.\nPer ottenere una distribuzione di probabilit√† correttamente normalizzata, dobbiamo dividere ciascun valore ottenuto precedentemente per la probabilit√† marginale dei dati \\(y\\). La probabilit√† marginale dei dati \\(y\\) √® una costante di normalizzazione e pu√≤ essere calcolata utilizzando la legge della probabilit√† totale (si veda l‚Äôeq. {eq}eq-prob-tot).\nPer chiarire, ricordiamo che, nel capitolo {ref}cond-prob-notebook abbiamo considerato il caso di una partizione dello spazio campione in due eventi mutualmente esclusivi ed esaustivi, \\(H_1\\) e \\(H_2\\). All‚Äôinterno dello spazio campione abbiamo definito un evento \\(E\\) non nullo e abbiamo visto che \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\), ovvero \\(P(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2)\\). Usando la terminologia che stiamo usando qui, \\(P(E \\mid H_i)\\) corrisponde alla funzione di verosimiglianza e \\(P(H_i)\\) corrisponde alla funzione a priori. Nel caso discreto, come quello che stiamo considerando ora, il teorema della probabilit√† totale ci dice dunque che dobbiamo fare la somma dei prodotti tra i valori della funzione di verosimiglianza e i corrispondenti valori della distribuzione a priori.\n\nnp.sum(not_unif_distr_pdf * lk)\n\n0.17481145807507814\n\n\nOtteniamo dunque il seguente risultato.\n\npost = (not_unif_distr_pdf * lk) / np.sum(not_unif_distr_pdf * lk)\nprint(post)\n\n[0.00000000e+00 5.69700599e-17 3.17218304e-08 4.31354330e-04\n 1.61666617e-01 6.74725608e-01 1.61666617e-01 1.50974015e-03\n 3.17218304e-08 5.69700599e-17 0.00000000e+00]\n\n\nVerifichiamo di avere ottenuto una distribuzione di massa di probabilit√†:\n\nnp.sum(post)\n\n1.0000000000000002\n\n\nEsaminiamo la distribuzione a posteriori di \\(\\theta\\) con un grafico.\n\nplt.stem(theta, post, markerfmt=\" \", linefmt=color_edge)\nplt.title(\"Distribuzione a posteriori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\");\n\n\n\n\n\n\n\n\nUna volta trovata la distribuzione a posteriori di \\(\\theta\\), possiamo calcolare altre quantit√† di interesse. Ad esempio, la moda a posteriori di \\(\\theta\\) pu√≤ essere individuata direttamente dal grafico precedente e risulta pari a 0.5. Per calcolare invece la media a posteriori, ci avvaliamo della formula del valore atteso delle variabili casuali.\n\nnp.sum(theta * post)\n\n0.5002156771647586\n\n\nLa varianza della distribuzione a posteriori √®\n\nnp.sum(theta**2 * post) - (np.sum(theta * post)) ** 2\n\n0.0033109353091205773\n\n\nCon questo metodo, possiamo calcolare la distribuzione a posteriori di \\(\\theta\\) per qualsiasi distribuzione a priori discreta.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "38.5 Aggiornamento bayesiano con una distribuzione a priori continua\nA fini didattici, abbiamo esaminato il caso di una distribuzione a priori discreta. Tuttavia, √® importante notare che l‚Äôimpiego di una distribuzione a priori continua, come la distribuzione Beta, risulta pi√π appropriato in quanto permette di rappresentare un‚Äôampia gamma di possibili valori per il parametro non noto \\(\\theta\\), senza essere vincolati a un insieme discreto di valori. Inoltre, la distribuzione Beta presenta l‚Äôulteriore vantaggio di avere un dominio definito nell‚Äôintervallo [0, 1], che corrisponde alla gamma dei possibili valori per la proporzione \\(\\theta\\).\nPer esempio, consideriamo la distribuzione Beta(2, 2), caratterizzata da una simmetria nella sua forma. Per valutare la distribuzione Beta in corrispondenza di punti specifici, come ad esempio 0.5, 0.8 e 1.2, possiamo fare affidamento sulla funzione beta.pdf. A titolo illustrativo, la densit√† di probabilit√† della distribuzione Beta(2, 2) nel caso del valore 0.5 risulta essere 1.5, suggerendo che i valori di \\(\\theta\\) vicini a 0.5 appaiono pi√π plausibili rispetto a quelli intorno a 0.8, dove la funzione assume un valore di 0.96. √à importante sottolineare che la densit√† di probabilit√† della distribuzione Beta(2, 2) relativa al valore 1.2 √® pari a 0, poich√© tale valore esula dall‚Äôintervallo di definizione della distribuzione (0 e 1). La distribuzione Beta(2, 2) √® illustrata nella figura qui di seguito.\n\nalpha = 2\nbeta = 2\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf, color=color_edge)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nSupponiamo ‚Äì solo allo scopo di illustrare la procedura ‚Äì che le nostre credenze a priori siano rappresentate da una Beta(2, 5).\n\nalpha = 2\nbeta = 5\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf, color=color_edge)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nNel seguente esempio, useremo la funzione beta.pdf() per generare una distribuzione a priori discretizzata.\n\nprint(stats.beta.pdf(theta, 2, 5))\n\n[0.     1.9683 2.4576 2.1609 1.5552 0.9375 0.4608 0.1701 0.0384 0.0027\n 0.    ]\n\n\n\n_ = plt.plot(theta, stats.beta.pdf(theta, 2, 5), color=color_edge)\n\n\n\n\n\n\n\n\nOra per√≤ usiamo un numero maggiore di valori \\(\\theta\\).\n\ntheta = np.linspace(0, 1, 1001)\nprint(theta)\n\n[0.    0.001 0.002 ... 0.998 0.999 1.   ]\n\n\nCalcoliamo la distribuzione a priori normalizzata.\n\nprior = stats.beta.pdf(theta, 2, 5) \nprior = prior / np.sum(prior)\nprint(prior)\n\n[0.00000000e+00 2.98802546e-05 5.95215869e-05 ... 4.79041198e-13\n 2.99700749e-14 0.00000000e+00]\n\n\n\nsum(prior)\n\n1.0000000000000002\n\n\nPer calcolare la verosimiglianza, seguiamo la medesima procedura illustrata nel capitolo {ref}cap-likelihood. In aggiunta, effettuiamo la normalizzazione dei valori discretizzati della verosimiglianza, come precedentemente descritto.\n\nlk = stats.binom.pmf(6, 9, theta)\nlk = lk / np.sum(lk)\nprint(lk)\n\n[0.00000000e+00 8.37482519e-19 5.34380847e-17 ... 6.63976213e-09\n 8.34972583e-10 0.00000000e+00]\n\n\nInfine, otteniamo la distribuzione a posteriori moltiplicando la distribuzione a priori per la verosimiglianza e dividendo per la costante di normalizzazione.\n\npost = (prior * lk) / np.sum(prior * lk)\n\n\nnp.sum(post)\n\n1.0\n\n\n\nplt.plot(theta, prior, linestyle=\"solid\", color=\"#D7BEBD\", label=\"Prior\")\nplt.plot(theta, lk, linestyle=\"solid\", color=\"#B17F7D\", label=\"Likelihood\")\nplt.plot(theta, post, linestyle=\"solid\", color=\"#832F2B\", label=\"Posterior\")\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nPossiamo calcolare la media e la deviazione standard della distribuzione a posteriori come abbiamo fatto in precedenza.\n\n# media\nnp.sum(theta * post)\n\n0.5000000000000001\n\n\n\n# deviazione standard\nnp.sqrt(np.sum(theta**2 * post) - (np.sum(theta * post)) ** 2)\n\n0.12126781251816628",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori",
    "text": "38.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori\nUna volta ottenuta la distribuzione a posteriori, √® possibile generare un campione casuale da questa distribuzione. A titolo di esempio, possiamo estrarre un campione di 10000 punti dalla distribuzione a posteriori di \\(\\theta\\) che abbiamo calcolato.\n\nsamples = np.random.choice(theta, p=post, size=int(1e4), replace=True)\n\nL‚Äôistruzione precedente genera un array denominato samples contenente 10000 punti campionati dalla distribuzione a posteriori calcolata. La funzione np.random.choice viene impiegata per selezionare casualmente i valori theta basandosi sulle probabilit√† definite da post.\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n# Primo subplot: Scatter plot\naxs[0].plot(samples, \"o\", alpha=0.2, color=\"#B17F7D\")\naxs[0].set_xlabel(\"Numero di campione\")\naxs[0].set_ylabel(r\"$\\theta$\")\naxs[0].set_title(\"Scatter Plot dei Campioni\")\n\n# Secondo subplot: KDE plot\naz.plot_kde(samples, ax=axs[1], plot_kwargs={\"color\": \"#832F2B\"})\naxs[1].set_xlabel(r\"$\\theta$\")\naxs[1].set_ylabel(\"Densit√†\")\naxs[1].set_title(\"KDE Plot dei Campioni\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_92945/3196915724.py:15: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nSfruttando il campione estratto dalla distribuzione a posteriori, √® possibile calcolare diverse quantit√† di interesse. Ad esempio, la stima della media a posteriori di \\(\\theta\\) si ottiene semplicemente calcolando la media dei valori cos√¨ ottenuti.\n\nnp.mean(samples)\n\n0.499356\n\n\nIn maniera analoga possiamo calcolare la deviazione standard della distribuzione a posteriori di \\(\\theta\\).\n\nnp.std(samples)\n\n0.1199298022344738\n\n\nLa moda a posteriori si pu√≤ calcolare nel modo seguente.\n\nprint(theta[post == max(post)])\n\n[0.5]\n\n\nOppure, usando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo\n\nstats.mode(samples)[0]\n\n0.507\n\n\nUsando il campione estratto dalla distribuzione a posteriori, √® immediato trovare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(samples)\n\n0.5\n\n\nPossiamo calcolare la probabilit√† di varie ipotesi relative a \\(\\theta\\) nella distribuzione a posteriori. Per esempio, calcoliamo la probabilit√† \\(P(\\theta &lt; 0.5)\\).\n\nsum(post[theta &lt; 0.5])\n\n0.49842895507812507\n\n\nAlternativamente, utilizzando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo un risultato analogo, sebbene soggetto a variazioni dovute all‚Äôapprossimazione numerica.\n\nsum(samples &lt; 0.5) / 1e4\n\n0.4996\n\n\nPossiamo trovare la probabilit√† a posteriori che \\(\\theta\\) sia compresa in un dato intervallo. Per esempio, troviamo \\(P(0.5 &lt; \\theta &lt; 0.75)\\).\n\nsum((samples &gt; 0.6) & (samples &lt; 0.8)) / 1e4\n\n0.2073\n\n\nUtilizzando il campionamento effettuato dalla distribuzione a posteriori di \\(\\theta\\), √® possibile risolvere il problema inverso, ovvero determinare l‚Äôintervallo che contiene \\(\\theta\\) con una specifica probabilit√†. Ad esempio, si pu√≤ calcolare l‚Äôintervallo che ha una probabilit√† pari a 0.94 di contenere \\(\\theta\\), basandosi sulla distribuzione a posteriori campionata.\n\nnp.percentile(samples, [2, 98])\n\narray([0.261, 0.741])\n\n\nL‚Äôintervallo specificato √® noto come intervallo di credibilit√† e rappresenta una quantificazione statistica dell‚Äôincertezza associata alla stima del parametro \\(\\theta\\). In termini probabilistici, si pu√≤ affermare con il 94% di credibilit√† che il valore ‚Äúvero‚Äù di \\(\\theta\\) √® contenuto nell‚Äôintervallo [0.26, 0.74].\nSe vogliamo trovare l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPD), usiamo la funzione ArviZ hdi() (si veda il capitolo {ref}sintesi-distr-post-notebook).\n\naz.hdi(samples, hdi_prob=0.94)\n\narray([0.278, 0.721])\n\n\nNel contesto attuale, la distribuzione a posteriori √® simmetrica. Di conseguenza, l‚Äôintervallo di credibilit√† calcolato attraverso i quantili e l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPDI) sono molto simili.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "href": "chapters/bayesian_inference/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?",
    "text": "38.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?\nNonostante abbiamo discusso in precedenza dei diversi metodi di stima puntuale e intervallare per riassumere la distribuzione a posteriori di \\(\\theta\\), la migliore stima del parametro che stiamo cercando di inferire √® rappresentata dall‚Äôintera distribuzione a posteriori. Per citare le parole di McElreath (2020):\n\nThat an arbitrary interval contains an arbitrary value is not meaningful. Use the whole distribution.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.8 Metodo basato su griglia",
    "text": "38.8 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori √® noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l‚Äôapprossimazione della distribuzione a posteriori pu√≤ essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l‚Äôapprossimazione della densit√† a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densit√† a posteriori normalizzata.\n\nQuesto metodo pu√≤ essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all‚Äôaumentare della dimensionalit√† dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l‚Äôapproccio basato sulla griglia √® intuitivo e non richiede competenze di programmazione avanzate per l‚Äôimplementazione. Inoltre, fornisce un risultato che pu√≤ essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilit√† a posteriori condizionata ai dati. Tuttavia, questo metodo √® limitato a causa della maledizione della dimensionalit√†1, il che significa che pu√≤ essere applicato soltanto a modelli statistici semplici con non pi√π di due parametri. Di conseguenza, in pratica, √® spesso sostituito da altre tecniche pi√π efficienti, poich√© i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/02_subj_prop.html#commenti-e-considerazioni-finali",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "38.9 Commenti e Considerazioni Finali",
    "text": "38.9 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato l‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l‚Äôelaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell‚Äôinferenza relativa alle proporzioni, dove la distribuzione a priori √® modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, √® possibile derivare analiticamente la distribuzione a posteriori. L‚Äôanalisi dettagliata di questo caso sar√† trattata nel capitolo successivo.\nL‚Äôaspetto fondamentale della discussione presente risiede nell‚Äôapproccio adottato per affrontare una specifica questione di ricerca, ossia la quantificazione dell‚Äôincertezza relativa alla proporzione di presenza di ideazione suicidaria nella popolazione considerata. Abbiamo illustrato come sia possibile mettere in pratica alcuni dei passaggi del flusso di lavoro bayesiano proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nComtois, Katherine Anne, Karin E Hendricks, Christopher R DeCou, Samantha A Chalker, Amanda H Kerbrat, Jennifer Crumlish, Tierney K Huppert, e David Jobes. 2023. ¬´Reducing short term suicide risk after hospitalization: A randomized controlled trial of the Collaborative Assessment and Management of Suicidality¬ª. Journal of affective disorders 320: 656‚Äì66.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/02_subj_prop.html#footnotes",
    "title": "38¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalit√†, possiamo considerare l‚Äôesempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). √à evidente che la quantit√† di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, √® necessario utilizzare un approccio diverso.‚Ü©Ô∏é",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html",
    "title": "39¬† Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduction\nIn questo capitolo, ci focalizziamo sulla derivazione della distribuzione a posteriori attraverso l‚Äôuso di una distribuzione a priori coniugata. Sar√† esaminato in dettaglio il modello beta-binomiale, un esempio paradigmatico che evidenzia il vantaggio dell‚Äôuso delle distribuzioni a priori coniugate in inferenza bayesiana. L‚Äôimpiego di tali distribuzioni facilita notevolmente il processo di inferenza, permettendo di ottenere una distribuzione a posteriori attraverso calcoli analitici diretti e semplificati. Questa metodologia non solo rende il processo di inferenza pi√π gestibile ma anche pi√π intuitivo, offrendo una chiara dimostrazione di come le scelte a priori influenzino l‚Äôanalisi bayesiana.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#derivazione-analitica-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#derivazione-analitica-della-distribuzione-a-posteriori",
    "title": "39¬† Distribuzioni coniugate (1)",
    "section": "39.1 Derivazione analitica della distribuzione a posteriori",
    "text": "39.1 Derivazione analitica della distribuzione a posteriori\nLe distribuzioni a priori coniugate costituiscono una classe speciale di distribuzioni di probabilit√† aventi una particolare caratteristica: se la distribuzione a priori appartiene a questa classe, anche la distribuzione a posteriori appartiene alla stessa classe, ovvero mantiene la stessa forma funzionale. Questo aspetto semplifica notevolmente l‚Äôaggiornamento delle nostre credenze riguardo al parametro di interesse, in quanto coinvolge semplicemente la modifica dei parametri della distribuzione a priori. Ad esempio, quando selezioniamo una distribuzione a priori Beta e la verosimiglianza corrisponde a una distribuzione binomiale, la distribuzione a posteriori sar√† anch‚Äôessa una distribuzione Beta.\nNonostante le distribuzioni a priori coniugate siano la scelta preferibile dal punto di vista matematico, in quanto permettono di calcolare analiticamente la distribuzione a posteriori evitando calcoli complessi, le moderne tecniche di inferenza bayesiana offrono flessibilit√† nell‚Äôutilizzo di una vasta gamma di distribuzioni a priori. Questa flessibilit√† elimina la necessit√† di vincolarsi esclusivamente alle distribuzioni coniugate. Tuttavia, le distribuzioni a priori coniugate continuano a giocare un ruolo didattico rilevante, poich√© presentano una soluzione analitica per il processo di aggiornamento bayesiano. Nel presene capitolo, esploreremo dettagliatamente il modello beta-binomiale, in cui la verosimiglianza binomiale si combina con la scelta di una distribuzione a priori Beta. Questo modello rappresenta la base dell‚Äôinferenza bayesiana su una proporzione.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#lo-schema-beta-binomiale",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#lo-schema-beta-binomiale",
    "title": "39¬† Distribuzioni coniugate (1)",
    "section": "39.2 Lo schema beta-binomiale",
    "text": "39.2 Lo schema beta-binomiale\nLa distribuzione Beta √® utilizzata per descrivere la variabilit√† di una variabile casuale che √® limitata all‚Äôintervallo [0,1]. Questa distribuzione √® definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\]\ndove \\(B(\\alpha, \\beta)\\) rappresenta la funzione Beta di Eulero, espressa attraverso la funzione Gamma (\\(\\Gamma\\)) come segue:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}.\n\\]\nLa funzione Gamma, a sua volta, √® definita per i valori positivi di \\(x\\) e generalizza il concetto di fattoriale. I parametri \\(\\alpha\\) e \\(\\beta\\) modulano la forma della distribuzione Beta, influenzando la sua varianza e la sua moda.\nNel contesto bayesiano, la distribuzione Beta √® spesso usata come distribuzione a priori per modellare la nostra conoscenza preliminare sulla probabilit√† di successo \\(\\theta\\) in una serie di eventi di Bernoulli. Dopo aver raccolto i dati, possiamo aggiornare questa conoscenza a priori in base alle osservazioni effettive mediante l‚Äôapproccio di aggiornamento bayesiano.\nLa densit√† a priori, data da \\(\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}\\), viene combinata con la funzione di verosimiglianza che, in caso di dati binomiali, assume la forma \\(\\theta^{y} (1 - \\theta)^{n - y}\\). Moltiplicando la densit√† a priori per la verosimiglianza e tralasciando il fattore di normalizzazione (che sar√† calcolato in seguito), otteniamo una forma che ricorda quella di una distribuzione Beta:\n\\[\n\\theta^{\\alpha + y - 1} (1 - \\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta √® la distribuzione a posteriori non normalizzata per \\(\\theta\\). Per convertirla in una distribuzione di probabilit√† valida, dobbiamo normalizzarla in modo che l‚Äôintegrale su tutto il suo dominio sia pari a 1. Questo si ottiene dividendo per la funzione Beta \\(B(\\alpha', \\beta')\\), dove \\(\\alpha' = \\alpha + y\\) e \\(\\beta' = \\beta + n - y\\).\nIn conclusione, la distribuzione a posteriori per \\(\\theta\\), dopo aver osservato \\(y\\) successi in \\(n\\) prove, diventa una distribuzione Beta con i parametri aggiornati \\(\\alpha'\\) e \\(\\beta'\\):\n\\[\n\\text{Beta}(\\theta \\mid \\alpha + y, \\beta + n - y).\n\\]\nLa normalizzazione richiede il calcolo di \\(B(\\alpha + y, \\beta + n - y)\\), che utilizza la funzione Gamma per garantire che l‚Äôarea sotto la curva della funzione di densit√† di probabilit√† sia esattamente 1 sull‚Äôintervallo [0,1].\nQuesto esempio illustra un‚Äôapplicazione dell‚Äôanalisi coniugata, dove la scelta di una distribuzione a priori Beta, combinata con una funzione di verosimiglianza binomiale, produce una distribuzione a posteriori che √® ancora una distribuzione Beta. Questo risultato √® noto come ‚Äúcaso coniugato beta-binomiale‚Äù, riassunto nel seguente teorema:\n\nTeorema: Se la funzione di verosimiglianza √® binomiale, data da \\(Bin(n, y \\mid \\theta)\\), e la distribuzione a priori √® una Beta con parametri \\((\\alpha, \\beta)\\), allora la distribuzione a posteriori di \\(\\theta\\) sar√† una distribuzione Beta con parametri aggiornati \\((\\alpha + y, \\beta + n - y)\\).\n\nQuesta relazione facilita l‚Äôaggiornamento bayesiano delle nostre credenze sulla proporzione di successi in una serie di prove, utilizzando un approccio analitico e computazionalmente efficiente.\n\nEsempio 39.1 In un esempio ispirato da McElreath (2020) nel suo libro ‚ÄúStatistical Rethinking‚Äù, consideriamo un esperimento dove otteniamo 6 successi (indicati come ‚Äúacqua‚Äù) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento √® data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) √® il numero di successi e \\(n = 9\\) √® il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l‚Äôaggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l‚Äôesito delle nostre prove. L‚Äôapplicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definiamo i parametri\nalpha_prior, beta_prior = 2, 2\ny, n = 6, 9\nalpha_post, beta_post = alpha_prior + y, beta_prior + n - y\n\n# Creiamo un array di valori theta\ntheta = np.linspace(0, 1, 1000)  # Aumentiamo la risoluzione per un calcolo pi√π preciso\n\n# Calcoliamo le PDF\nprior_pdf = stats.beta.pdf(theta, alpha_prior, beta_prior)\nlikelihood = theta**y * (1-theta)**(n-y)\n\n# Normalizziamo la verosimiglianza\nlikelihood_integral = trapezoid(likelihood, theta)\nnormalized_likelihood = likelihood / likelihood_integral\n\nposterior_pdf = stats.beta.pdf(theta, alpha_post, beta_post)\n\n# Disegnamo le distribuzioni\nplt.plot(theta, prior_pdf, label=f'Prior Beta({alpha_prior}, {beta_prior})', color='blue')\nplt.plot(theta, normalized_likelihood, label='Likelihood (normalizzata)', linestyle='--', color='green')\nplt.plot(theta, posterior_pdf, label=f'Posterior Beta({alpha_post}, {beta_post})', color='red')\n\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Density')\nplt.title('Distribuzioni Prior, Likelihood e Posterior')\n_ = plt.legend()\n\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l‚Äôintegrale della funzione di verosimiglianza non normalizzata su Œ∏, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] √® uguale a 1. La normalizzazione della verosimiglianza √® eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 39.2 Esaminiamo ora un esempio discuso da Johnson, Ott, e Dogucu (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorit√†, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell‚Äôarticolo, Milgram descrive lo studio come segue:\n\nconsistente nell‚Äôordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che √® un complice addestrato dell‚Äôesperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‚Äòesperimento di apprendimento‚Äô apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l‚Äôesperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre pi√π intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realt√† era un attore addestrato) sulla loro capacit√† di memorizzare una serie di item. Se l‚Äôattore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all‚Äôattore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l‚Äôattore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello ‚ÄúPericolo: Scossa Grave‚Äù. Il problema richiede di costruire la distribuzione a posteriori della probabilit√† \\(\\theta\\) di infliggere una scossa a l livello ‚ÄúPericolo: Scossa Grave‚Äù, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha = 1\nbeta_val = 10\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha, beta_val)\n\n# Plot della densit√† di probabilit√†\ncolor_fill = \"#b97c7c\"\nplt.plot(x_values, beta_pdf, label='Beta(1, 10)', color=color_fill)\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('x')\nplt.ylabel('Densit√† di probabilit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori √® una Beta di parametri aggiornati\n\ny = 26\nn = 40\n\nalpha_prior = 1\nbeta_prior = 10\n\nalpha_post = alpha_prior + y\nbeta_post = beta_prior + n - y\n\nalpha_post, beta_post\n\n(27, 24)\n\n\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha_post, beta_post)\n\n# Plot della densit√† di probabilit√†\nplt.plot(x_values, beta_pdf, label='Beta(27, 24)', color=color_fill)\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('theta')\nplt.ylabel('Densit√† di probabilit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n\n0.5294117647058824\n\n\nCalcoliamo la moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n\n0.5306122448979592\n\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\)\n\nstats.beta.sf(0.6, alpha_post, beta_post)\n\n0.15616833089995472\n\n\novvero\n\n1 - stats.beta.cdf(0.6, alpha_post, beta_post)\n\n0.15616833089995474\n\n\nSvolgiamo ora il problema usando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta = np.linspace(0, 1, 100)\n\n\nalpha_prior = 1  \nbeta_prior = 10   \n\n# Calcolo della PDF della distribuzione Beta per i valori x\nprior = stats.beta.pdf(theta, alpha_prior, beta_prior)\n\nplt.vlines(theta, 0, prior / np.sum(prior), color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione a priori')\n\nplt.show()\n\n\n\n\n\n\n\n\nCreiamo la verosimiglianza.\n\nlk = stats.binom.pmf(y, n, theta)\n\nplt.vlines(theta, 0, lk / np.sum(lk), color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Verosimiglianza')\n\nplt.show()\n\n\n\n\n\n\n\n\n\npost = (prior * lk) / np.sum(prior * lk)\n\nplt.vlines(theta, 0, post, color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione a posteriori')\n\nplt.show()\n\n\n\n\n\n\n\n\nEstraiamo un campione dalla distribuzione a posteriori.\n\nsamples = np.random.choice(theta, p=post, size=int(1e6), replace=True)\n\nTroviamo la media a posteriori.\n\nnp.mean(samples)\n\n0.5294427575757579\n\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\).\n\nnp.mean(samples &gt; 0.6)\n\n0.15274",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "39¬† Distribuzioni coniugate (1)",
    "section": "39.3 Principali distribuzioni coniugate",
    "text": "39.3 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle pi√π note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori √® \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori √® \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori √® \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori √® \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#conclusioni",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#conclusioni",
    "title": "39¬† Distribuzioni coniugate (1)",
    "section": "39.4 Conclusioni",
    "text": "39.4 Conclusioni\nIn conclusione, l‚Äôutilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell‚Äôadozione di distribuzioni a priori coniugate risiede nella loro capacit√† di rendere l‚Äôanalisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, √® cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e pi√π realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilit√†. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale √® sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la pi√π adeguata (Johnson, Ott, e Dogucu 2022).",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "39¬† Distribuzioni coniugate (1)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html",
    "title": "40¬† Distribuzioni coniugate (2)",
    "section": "",
    "text": "Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale √® che, attraverso l‚Äôaggiornamento bayesiano, l‚Äôincertezza sulla stima del parametro si riduce. Questo √® dovuto al fatto che l‚Äôinformazione aggiuntiva fornita dai dati osservati consente di ‚Äúrestringere‚Äù la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo cos√¨ la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle {ref}distr-coniugate-1-notebook, focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello √® la sua capacit√† di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini pi√π semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l‚Äôadozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "title": "40¬† Distribuzioni coniugate (2)",
    "section": "40.1 Perch√© Usare la Distribuzione Normale?",
    "text": "40.1 Perch√© Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori √® nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma √® solo approssimativamente normale. Nei casi in cui il ricercatore abbia un‚Äôidea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza pu√≤ offrire buone approssimazioni alla densit√† a posteriori desiderata, con la consapevolezza che, con l‚Äôaumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede propriet√† frequentiste desiderabili. Sebbene l‚Äôenfasi nell‚Äôanalisi bayesiana non sia sulle stime puntuali, si pu√≤ dimostrare che, con campioni sempre pi√π grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa propriet√† esiste perch√© la distribuzione a posteriori √® un compromesso ponderato tra la distribuzione a priori specificata dall‚Äôutente, che in questo capitolo √® normale, e la funzione di verosimiglianza derivata dai dati, anch‚Äôessa normale in questo capitolo. Con l‚Äôaumentare delle dimensioni del campione, la verosimiglianza diventa sempre pi√π dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l‚Äôaumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "40¬† Distribuzioni coniugate (2)",
    "section": "40.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "40.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo √® stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n40.2.1 Distribuzione a Priori\nNell‚Äôapproccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n\n40.2.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilit√† di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza √® data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n\n40.2.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l‚Äôevidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoich√© la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulter√† anch‚Äôessa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n\n40.2.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula √®:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) √® una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con pi√π dati, la nostra fiducia nella media campionaria cresce, mentre l‚Äôincertezza a priori diminuisce.\n\n\n40.2.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l‚Äôincertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula √®:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) √® sempre inferiore o uguale. In altre parole, l‚Äôincertezza sulla stima di \\(\\mu\\) si riduce con l‚Äôaumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l‚Äôincertezza a priori (\\(\\sigma_0^2\\)) e l‚Äôinformazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un‚Äôintegrazione bilanciata tra l‚Äôinformazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l‚Äôaumento del numero di osservazioni.\n\nEsempio 40.1 I test standard di QI sono progettati per misurare l‚Äôintelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un‚Äôulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poich√© le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L‚Äôidea chiave nella descrizione della distribuzione a posteriori √® se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq = np.array(\n    [\n        96,\n        100,\n        100,\n        85,\n        83,\n        97,\n        92,\n        99,\n        87,\n        72,\n        86,\n        85,\n        67,\n        99,\n        94,\n        103,\n        97,\n        101,\n        87,\n        98,\n        87,\n        73,\n        97,\n        59,\n        98,\n        79,\n        81,\n        93,\n        105,\n        92,\n        78,\n        98,\n        95,\n        96,\n        72,\n        104,\n        90,\n        96,\n        98,\n        102,\n        78,\n        90,\n        63,\n        84,\n        84,\n        107,\n        86,\n        102,\n        106,\n        94,\n        102,\n        72,\n        101,\n        89,\n        72,\n        101,\n        91,\n        100,\n        100,\n        66,\n        107,\n        86,\n        78,\n        84,\n        78,\n        64,\n        72,\n        101,\n        91,\n        100,\n        67,\n        86,\n    ]\n)\n\n\n# Numero di osservazioni\nn = len(iq)\n\n# Media campionaria\ny_bar = np.mean(iq)\n\n# Deviazione standard nota\nsigma = 15\n\n# Parametri a priori\nmu_0 = 100\nsigma_0 = 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\\(\\mu_0\\) √® la media a priori\n\\(\\sigma_0\\) √® la deviazione standard a priori\n\\(n\\) √® il numero di osservazioni\n\\(\\sigma\\) √® la deviazione standard delle osservazioni (nota)\n\\(\\bar{y}\\) √® la media campionaria\n\n\nmu_p = ((1 / sigma_0**2) * mu_0 + (n / sigma**2) * y_bar) / (\n    (1 / sigma_0**2) + (n / sigma**2)\n)\nprint(f\"Media a posteriori (mu_p): {mu_p}\")\n\nMedia a posteriori (mu_p): 89.35616438356165\n\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq = 1 / ((1 / sigma_0**2) + (n / sigma**2))\nprint(f\"Varianza a posteriori (sigma_p_sq): {sigma_p_sq}\")\n\nVarianza a posteriori (sigma_p_sq): 3.082191780821918\n\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\nsigma_p = np.sqrt(sigma_p_sq)\n\n# Definizione dei valori sull'asse x\nx = np.linspace(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, 1000)\n\n# Calcolo della densit√† di probabilit√†\npdf = stats.norm.pdf(x, mu_p, sigma_p)\n\n# Creazione del grafico\nplt.plot(x, pdf, label=f\"N({mu_p:.2f}, {sigma_p:.2f})\", color=\"blue\")\nplt.fill_between(x, pdf, color=\"blue\", alpha=0.2)\nplt.title(\"Distribuzione a Posteriori\")\nplt.xlabel(\"Media del Quoziente di Intelligenza\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nL‚Äôanalisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un‚Äôinterpretazione completa di questo dato, √® fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori √® ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo pu√≤ innescare un effetto di aggregazione, dove la media ‚Äúsmussata‚Äù risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilit√† potrebbero essere mascherate da questa media aggregata.\n√à importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ci√≤ significa che nazioni con popolazioni pi√π piccole, anche se con punteggi QI mediamente pi√π alti o pi√π bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni pi√π grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell‚Äôintelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l‚Äôaccesso all‚Äôistruzione, la qualit√† della nutrizione e l‚Äôesposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilit√† osservata tra le nazioni.\nInoltre, √® fondamentale considerare la possibilit√† di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l‚Äôimportanza di un‚Äôattenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L‚Äôeffetto di aggregazione, l‚Äôutilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un‚Äôanalisi pi√π approfondita che consideri questi fattori e utilizzi metodi statistici pi√π sofisticati per ottenere una comprensione pi√π completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#commenti-e-considerazioni-finali",
    "title": "40¬† Distribuzioni coniugate (2)",
    "section": "40.3 Commenti e considerazioni finali",
    "text": "40.3 Commenti e considerazioni finali\nIn questa sezione, abbiamo approfondito il meccanismo dell‚Äôaggiornamento bayesiano attraverso l‚Äôimplementazione del modello normale-normale.\nIl processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l‚Äôacquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori $ _0 $ e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media √® determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) √® determinata utilizzando un‚Äôespressione che incorpora entrambe le varianze.\nIn sintesi, l‚Äôadozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la propriet√† di coniugatezza, semplificando cos√¨ l‚Äôintero processo analitico.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "40¬† Distribuzioni coniugate (2)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.8.4\nscipy     : 1.13.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGill, Jeff. 2015. Bayesian methods: A social and behavioral sciences approach. 3rd Edition. Chapman; Hall/CRC.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html",
    "href": "chapters/bayesian_inference/05_summary_posterior.html",
    "title": "41¬† Sintesi a posteriori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell‚Äôinformazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell‚Äôinferenza.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#riepilogo-numerico",
    "title": "41¬† Sintesi a posteriori",
    "section": "41.1 Riepilogo numerico",
    "text": "41.1 Riepilogo numerico\nLa distribuzione a posteriori contiene in s√© tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con pi√π di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilit√†.\n\n\n41.1.1 Stima puntuale\nNel contesto dell‚Äôinferenza bayesiana, il processo di stima del valore pi√π credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori √® un compito cruciale. Comunemente, tale processo si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta √® guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il ‚Äúvalore pi√π credibile‚Äù del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\nMedia a posteriori: La media a posteriori √® il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, √® espressa dalla formula:\n\\[ E(\\theta | y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta | y) \\, d\\theta. \\]\nModa (Massimo a posteriori, MAP): La moda identifica il valore pi√π probabile del parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore √® noto come ‚Äúmassimo a posteriori‚Äù (MAP). La stima MAP inizia con il concetto di stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta | y)\\), come segue:\n\\[ \\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta | y). \\]\nNell‚Äôinferenza bayesiana, \\(\\theta\\) √® considerato come una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere la nostra incertezza su \\(\\theta\\). Integrando la distribuzione a priori, otteniamo la formula per la stima MAP:\n\\[ \\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta | y)p(\\theta). \\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densit√† a posteriori di \\(\\theta\\) dati \\(y\\), che coincide con la moda della densit√† a posteriori.\nMediana: La mediana √® il valore del parametro per cui il 50% della massa di probabilit√† a posteriori si distribuisce equamente a sinistra e a destra. √à una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore pi√π probabile del parametro.\n\nPer valutare l‚Äôincertezza associata al parametro \\(\\theta\\), √® utile calcolare la varianza a posteriori. Questa varianza √® basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l‚Äôincertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unit√† di misura dei dati. La formula per la varianza a posteriori √® data da:\n\\[ V(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2. \\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l‚Äôincertezza associata a \\(\\theta\\) in modo informativo.\n\n\n41.1.2 Intervallo di credibilit√†\nNel contesto dell‚Äôinferenza bayesiana, l‚Äôintervallo di credibilit√† √® uno strumento fondamentale per valutare l‚Äôampiezza dell‚Äôintervallo che racchiude una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo fornisce informazioni sulla nostra incertezza relativa al valore del parametro: un intervallo pi√π ampio indica una maggiore incertezza associata. L‚Äôobiettivo primario dell‚Äôintervallo di credibilit√† √® di fornire una misura quantitativa dell‚Äôincertezza legata alla stima del parametro \\(\\theta\\).\nLa definizione di intervallo di credibilit√† non determina un unico intervallo di ordine \\((1 - \\alpha) \\cdot 100\\%\\), ma rende possibile una gamma infinita di tali intervalli. Di conseguenza, √® essenziale introdurre condizioni aggiuntive per la selezione dell‚Äôintervallo di credibilit√†. Due delle condizioni aggiuntive pi√π comuni sono l‚Äôintervallo di credibilit√† simmetrico e l‚Äôintervallo di credibilit√† pi√π stretto.\n\nIntervallo di Credibilit√† Simmetrico: Questa condizione richiede che l‚Äôintervallo di credibilit√† sia simmetrico rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) √® il valore stimato del parametro, l‚Äôintervallo di credibilit√† avr√† la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) √® un valore positivo adeguato. Un intervallo di credibilit√† simmetrico al livello \\(\\alpha\\) pu√≤ essere rappresentato come:\n\\[ I_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}], \\]\ndove \\(q_z\\) √® un quantile della distribuzione a posteriori. Ad esempio, un intervallo di credibilit√† simmetrico al 94% sar√†:\n\\[ I_{0.06} = [q_{0.03}, q_{0.97}] \\]\nassicurando che il 3% della densit√† di probabilit√† a posteriori sia compreso in ciascuna coda dell‚Äôintervallo.\nIntervallo di Credibilit√† Pi√π Stretto (Intervallo di Massima Densit√† Posteriore, HPD): Questo intervallo √® scelto in modo da avere la larghezza minima tra tutti gli intervalli di ordine \\((1 - \\alpha) \\cdot 100\\%\\), rappresentando la stima pi√π precisa possibile del parametro \\(\\theta\\). A differenza dell‚Äôintervallo di credibilit√† simmetrico, l‚Äôintervallo di credibilit√† pi√π stretto, o Intervallo di Massima Densit√† Posteriore (HPD), √® costruito per includere tutti i valori di \\(\\theta\\) che godono di maggiore credibilit√† a posteriori. Questo intervallo pu√≤ essere ottenuto tracciando una linea orizzontale sulla rappresentazione grafica della distribuzione a posteriori e regolando l‚Äôaltezza della linea in modo che l‚Äôarea sottesa alla curva sia pari a \\(1 - \\alpha\\). L‚Äôintervallo HPD √® il pi√π stretto possibile tra tutti gli intervalli possibili con lo stesso livello di fiducia. Quando la distribuzione a posteriori √® unimodale e simmetrica, l‚Äôintervallo di credibilit√† pi√π stretto coincide con l‚Äôintervallo di credibilit√† simmetrico.\n\nIl calcolo degli intervalli di credibilit√† pu√≤ richiedere l‚Äôuso di software statistici dedicati, data la complessit√† nel determinarli manualmente, specialmente in situazioni con modelli bayesiani pi√π complessi o quando il calcolo coinvolge simulazioni numeriche.\nUn aspetto importante del trattare i parametri in modo probabilistico riguarda l‚Äôinterpretazione degli intervalli di confidenza. Nell‚Äôambito frequentista, √® necessario immaginare un parametro fisso, ad esempio la media della popolazione \\(\\mu\\), e immaginare un numero infinito di campioni ripetuti dalla popolazione caratterizzata da \\(\\mu\\). Per ogni campione, possiamo ottenere la media del campione \\(\\bar{x}\\) e quindi formare un intervallo di confidenza al \\(100(1 ‚àí \\alpha)\\%\\). L‚Äôinterpretazione corretta in termini frequentisti √® che il \\(100(1 ‚àí \\alpha)\\%\\) degli intervalli di confidenza formati in questo modo cattura il vero parametro \\(\\mu\\) sotto l‚Äôipotesi nulla. In questo contesto, la probabilit√† che il parametro sia nell‚Äôintervallo √® o 0 o 1.\nIn contrasto, il framework bayesiano assume che un parametro abbia una distribuzione di probabilit√†. Campionando dalla distribuzione a posteriori dei parametri del modello, possiamo ottenere i suoi quantili e, dai quantili, possiamo ottenere direttamente la probabilit√† che un parametro rientri in un determinato intervallo. Quindi, in questo caso, un intervallo di probabilit√† a posteriori del 95% significherebbe che la probabilit√† che il parametro rientri nell‚Äôintervallo √® 0.95. Questo √® completamente diverso dall‚Äôinterpretazione frequentista, e si allinea pi√π sensatamente con il senso comune.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "41¬† Sintesi a posteriori",
    "section": "41.2 Verifica di ipotesi bayesiana",
    "text": "41.2 Verifica di ipotesi bayesiana\nL‚Äôinferenza bayesiana pu√≤ anche procedere attraverso un altro approccio, conosciuto come verifica di ipotesi bayesiana. Questo secondo tipo di inferenza bayesiana si concentra su problemi in cui intendiamo valutare la plausibilit√† dell‚Äôaffermazione che il parametro \\(\\theta\\) assuma valori all‚Äôinterno di un intervallo specifico (ad esempio, \\(\\theta &gt; 0.5\\)). In questa situazione, √® possibile calcolare la probabilit√† a posteriori che \\(\\theta\\) cada all‚Äôinterno dell‚Äôintervallo di interesse (come ad esempio, [0.5, 1.0]), integrando la distribuzione a posteriori su tale intervallo.\n\nEsempio 41.1 Per comprendere meglio attraverso un esempio pratico, esaminiamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche, Buerkner, e Renneberg (2019). Il BDI-II √® un questionario utilizzato per valutare la gravit√† dei sintomi depressivi.\n\nbdi = np.array([\n    26,\n    35,\n    30,\n    25,\n    44,\n    30,\n    33,\n    43,\n    22,\n    43,\n    24,\n    19,\n    39,\n    31,\n    25,\n    28,\n    35,\n    30,\n    26,\n    31,\n    41,\n    36,\n    26,\n    35,\n    33,\n    28,\n    27,\n    34,\n    27,\n    22,\n])\nprint(*bdi)\n\n26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33 28 27 34 27 22\n\n\nUn valore BDI-II \\(\\geq 30\\) indica la presenza di un livello grave di depressione. Nel campione clinico di {cite:t}zetsche_2019future, 17 pazienti su 30 manifestano un livello grave di depressione.\n\nnp.sum(bdi &gt;= 30)\n\n17\n\n\nSupponiamo di volere stimare la distribuzione a posteriori della probabilit√† \\(\\theta\\) di depressione grave nei pazienti clinici, cos√¨ come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione a priori \\(Beta(8, 2)\\).\nPoich√© i dati possono essere concepiti come una sequenza di prove Bernoulliane indipendenti, laddove la presenza di depressione grave viene concepita come un ‚Äúsuccesso‚Äù, la verosimiglianza sar√† Binomiale con paramentri \\(n\\) = 30 e \\(y\\) = 17.\nAvendo scelto, quale distribuzione a priori, una \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sar√† una \\(Beta(8 + 17, 2 + 30 - 17)\\):\n\\[\nf(\\theta \\mid y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ for } \\theta \\in [0,1] \\; .\n\\] (eq-post-beta-25-15)\n\ntheta = np.linspace(0, 1, 200)\nalpha = 25\nbeta = 15\npdf = stats.beta.pdf(theta, alpha, beta)\nplt.plot(theta, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(alpha, beta))\nplt.xlabel(r\"$\\theta$\", fontsize=14)\nplt.ylabel(\"Densit√† di probabilit√†\", fontsize=14)\nplt.legend(loc=1)\nplt.show()\n\n\n\n\n\n\n\n\nVediamo ora come ottenere delle stime puntuali da tale distribuzione a posteriori.\nper il presente esempio, la media della distribuzione a posteriori di \\(\\theta\\) √®\n\\[\n\\mathbb{E}(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625.\n\\]\nUna stima del massimo della probabilit√† a posteriori, o brevemente massimo a posteriori, MAP (da maximum a posteriori probability), √® la moda della distribuzione a posteriori. Nel caso presente, abbiamo\n\\[\nMo(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316.\n\\]\nLa mediana si ottiene con la funzione beta.ppf():\n\nstats.beta.ppf(0.5, alpha, beta)\n\n0.6271031100419254\n\n\nL‚Äôintervallo di credibilit√† simmetrico al 94% √® dato dalla chiamata a beta.ppf().\n\n[stats.beta.ppf(0.03, alpha, beta), stats.beta.ppf(0.97, alpha, beta)]\n\n[0.4781025861696672, 0.7612890799836668]\n\n\nIl calcolo precedente evidenzia l‚Äôinterpretazione intuitiva dell‚Äôintervallo di credibilit√†. Tale intervallo, infatti, pu√≤ essere interpretato nel modo seguente: possiamo attribuire una certezza soggettiva del 94% all‚Äôevento che \\(\\theta\\) assuma un valore compreso tra 0.478 e 0.761. Il valore di 0.94 corrisponde infatti all‚Äôarea sottesa dalla distribuzione a posteriori nell‚Äôintervallo \\[0.478, 0.761\\].\n\\[\nP(\\theta \\in (0.478, 0.761) \\mid Y = 17) = \\int_{0.478}^{0.761} f(\\theta \\mid y=17) d\\theta = 0.94.\n\\]\n\nbetacdf = stats.beta(alpha, beta).cdf\nbetacdf(0.7612890799836668) - betacdf(0.4781025861696672)\n\n0.9400000000000001\n\n\nPossiamo costruire vari intervalli di credibilit√† simmetrici. Ad esempio, l‚Äôintervallo di credibilit√† compreso tra il 25-esimo e il 75-esimo percentile:\n\n[stats.beta.ppf(0.25, alpha, beta), stats.beta.ppf(0.75, alpha, beta)]\n\n[0.5743877928498646, 0.6778673380880944]\n\n\nIn questo secondo caso, possiamo affermare con una certezza soggettiva del 50% che la probabilit√† di depressione grave tra i pazienti clinici si situa tra 0.57 e 0.68.\nNon esiste un livello ‚Äúgiusto‚Äù di credibilit√† soggettiva. I ricercatori adottano livelli differenti, come il 50%, l‚Äô80% o il 94%, a seconda del contesto dell‚Äôanalisi statistica. Ogni intervallo offre una prospettiva unica sulla nostra comprensione della distribuzione a posteriori del parametro d‚Äôinteresse.\nNon sempre √® appropriato presentare un intervallo di credibilit√† con le stesse code. Quando la distribuzione a posteriori √® marcatamente asimmetrica, risulta pi√π adeguato fornire l‚Äôintervallo di credibilit√† pi√π stretto (o Intervallo di Massima Densit√† Posteriore, HPD). L‚Äôintervallo HPD √® pi√π facilmente calcolabile quando si approssima la distribuzione a posteriori con il metodo MCMC.\nPassiamo ora alla verifica di ipotesi bayesiana. Supponiamo che la nostra ipotesi sia: \\(\\theta &gt;\\) 0.5. La credibilit√† soggettiva dell‚Äôevento \\(\\theta &gt; 0.5\\) pu√≤ essere ottenuta calcolando il seguente integrale:\n\\[\nf(\\theta &gt; 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;,\n\\]\ndove \\(f(\\cdot)\\) √® la distribuzione Beta(25, 15).\n√à facile trovare questo valore con Python.\n\n# Parametri della distribuzione Beta\nalpha = 25\nbeta = 15\n\n# Calcoliamo la probabilit√† P(theta &lt; 0.5) utilizzando la funzione cdf \nprobability = stats.beta.cdf(0.5, alpha, beta)\n\n# La probabilit√† P(theta &lt; 0.5) √® data da 1 - P(theta &gt; 0.5)\nprobability_less_than_0_5 = 1 - probability\n\nprint(f\"La probabilit√† P(theta &lt; 0.5) per una Beta(25, 15) √®: {probability_less_than_0_5:.4f}\")\n\nLa probabilit√† P(theta &lt; 0.5) per una Beta(25, 15) √®: 0.9459",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#commenti-e-considerazioni-finali",
    "title": "41¬† Sintesi a posteriori",
    "section": "41.3 Commenti e considerazioni finali",
    "text": "41.3 Commenti e considerazioni finali\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L‚Äôimpiego delle statistiche descrittive e l‚Äôanalisi degli intervalli di credibilit√† contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilit√† forniscono un intervallo di valori all‚Äôinterno del quale si ritiene, con un certo grado di probabilit√† soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l‚Äôincertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l‚Äôanalisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale pu√≤ essere condotto agevolmente calcolando l‚Äôarea appropriata sotto la distribuzione a posteriori, in accordo con l‚Äôipotesi in questione.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "41¬† Sintesi a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 28 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\nsys       : 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:51:20) [Clang 16.0.6 ]\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html",
    "title": "42¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo si focalizza sull‚Äôimportanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi tratti dal libro ‚ÄúBayes Rules!‚Äù di Johnson e collaboratori {cite:p}Johnson2022bayesrules.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "42¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "42.1 La Distribuzione a Priori",
    "text": "42.1 La Distribuzione a Priori\nLa distribuzione a priori assume un ruolo centrale nell‚Äôapproccio bayesiano, poich√© riflette le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto √® di fondamentale importanza perch√© consente di integrare le informazioni pregresse con i dati osservati al fine di ottenere una stima pi√π precisa dei parametri. Le distribuzioni a priori possono variare in base al grado di certezza attribuito ai valori dei parametri.\n\n42.1.1 Distribuzioni a Priori Non Informative\nLe distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilit√† a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa √® la distribuzione uniforme, basata sul ‚ÄúPrincipio della Ragione Insufficiente‚Äù formulato da Laplace (1774/1951). Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\n\n\n42.1.2 Distribuzioni a Priori Debolmente Informative\nLe distribuzioni a priori debolmente informative consentendo di integrare una quantit√† limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori ‚Äúragionevoli‚Äù dei parametri del modello, tenendo conto delle incertezze presenti nell‚Äôanalisi. L‚Äôuso di informazioni a priori debolmente informative pu√≤ contribuire a migliorare la stabilit√† dell‚Äôanalisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non ‚Äúspostare‚Äù in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori ‚Äúneutri‚Äù dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ci√≤ che rende queste distribuzioni debolmente informative √® la specifica definizione di un intervallo ‚Äúplausibile‚Äù di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo pi√π stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l‚Äôanalisi verso soluzioni pi√π verosimili senza imporre vincoli eccessivi sui risultati.\n\n\n42.1.3 Distribuzioni a Priori Informativa\nLe conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l‚Äôincorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull‚Äôanalisi statistica, fornendo una solida base di conoscenza su cui fondare l‚Äôinferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L‚Äôincorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l‚Äôaccuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull‚Äôanalisi bayesiana.\nNell‚Äôambito della ricerca psicologica, l‚Äôutilizzo di distribuzioni a priori informative √® attualmente poco diffuso, tuttavia emergono segnali che all‚Äôinterno della comunit√† statistica sta crescendo l‚Äôinteresse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#il-caso-beta-binomiale",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#il-caso-beta-binomiale",
    "title": "42¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "42.2 Il caso beta-binomiale",
    "text": "42.2 Il caso beta-binomiale\nLa formula \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\) √® fondamentale per la comprensione dell‚Äôinferenza bayesiana. Essa illustra chiaramente che la distribuzione a posteriori emerge dalla congiunzione tra la distribuzione a priori e la funzione di verosimiglianza associata ai dati osservati. Questa sinergia permette di integrare informazioni a priori con evidenze empiriche recenti, risultando in una stima a posteriori del parametro \\(\\theta\\) che √® caratterizzata da un elevato grado di precisione e informativit√†.\nNel corso di questo capitolo, faremo uso di due funzioni specifiche per esplorare il modello beta-binomiale: plot_beta_binomial e summarize_beta_binomial. La prima funzione permette di visualizzare graficamente le distribuzioni a priori, di verosimiglianza e a posteriori, offrendo quindi un quadro intuitivo dell‚Äôaggiornamento bayesiano. La seconda funzione, invece, si concentra sull‚Äôestrazione di statistiche descrittive come la media, la moda e la varianza dalla distribuzione a posteriori. Entrambe queste risorse provengono dal testo di Johnson, Ott, e Dogucu (2022) e saranno strumentali per una comprensione approfondita del modello in esame.\n\ndef plot_beta_binomial(alpha, beta, y=None, n=None, prior=True, likelihood=True, posterior=True) -&gt; None:\n    \"\"\"Plot a Beta-Binomial Bayesian Model\n    \n    Parameters:\n    - alpha, beta: positive shape parameters of the prior Beta distribution\n    - y: observed number of successes\n    - n: observed number of trials\n    - prior: indicates whether the prior distribution should be plotted\n    - likelihood: indicates whether the scaled likelihood should be plotted\n    - posterior: indicates whether the posterior distribution should be plotted\n    \"\"\"\n    \n    Œ∏ = np.linspace(0, 1, 100)  # Range of possible values for Œ∏\n    \n    if prior:\n        p_theta = stats.beta.pdf(Œ∏, alpha, beta)\n        plt.fill_between(Œ∏, p_theta, step='mid', alpha=0.2, color='blue', label='Prior')\n    \n    if y is not None and n is not None:\n        if likelihood:\n            likelihood_values = stats.binom.pmf(y, n, Œ∏)\n            scale_factor = integrate.simpson(y=likelihood_values, x=Œ∏)  # Corrected to use keyword arguments\n            plt.plot(Œ∏, likelihood_values / scale_factor, color='orange', label='Likelihood (scaled)', lw=2)\n        \n        if posterior:\n            alpha_post = alpha + y\n            beta_post = beta + n - y\n            p_theta_post = stats.beta.pdf(Œ∏, alpha_post, beta_post)\n            plt.fill_between(Œ∏, p_theta_post, step='mid', alpha=0.4, color='green', label='Posterior')\n    \n    plt.xlabel(r'$\\theta$')\n    plt.ylabel('Density')\n    plt.legend(loc='upper left')\n    plt.title('Beta-Binomial Model')\n    plt.show()\n\n\ndef summarize_beta_binomial(alpha, beta, y=None, n=None):\n    \"\"\"Summarize a Beta-Binomial Bayesian model\n\n    @param alpha,beta positive shape parameters of the prior Beta model\n    @param y number of successes\n    @param n number of trials\n\n    Return: Pandas dataframe summarizing beta binomial\n    \"\"\"\n\n    def beta_mean(a, b):\n        return a / (a + b)\n\n    def beta_mode(a, b):\n        if a &lt; 1 and b &lt; 1:\n            return \"0 and 1\"\n        elif a &lt;= 1 and b &gt; 1:\n            return 0\n        elif a &gt; 1 and b &lt; 1:\n            return 1\n        else:\n            return (a - 1) / (a + b - 2)\n\n    def beta_var(a, b):\n        return a * b / ((a + b) ** 2 * (a + b + 1))\n\n    prior_mean = beta_mean(alpha, beta)\n    prior_mode = beta_mode(alpha, beta)\n    prior_var = beta_var(alpha, beta)\n    prior_sd = np.sqrt(prior_var)\n    if y is None and n is None:\n        summary = pd.DataFrame(\n            {\n                \"alpha\": alpha,\n                \"beta\": beta,\n                \"mean\": prior_mean,\n                \"mode\": prior_mode,\n                \"var\": prior_var,\n                \"sd\": prior_sd,\n            },\n            index=[\"prior\"],\n        )\n    else:\n        post_alpha = y + alpha\n        post_beta = n - y + beta\n        post_mean = beta_mean(post_alpha, post_beta)\n        post_mode = beta_mode(post_alpha, post_beta)\n        post_var = beta_var(post_alpha, post_beta)\n        post_sd = np.sqrt(post_var)\n        summary = pd.DataFrame(\n            {\n                \"alpha\": [alpha, post_alpha],\n                \"beta\": [beta, post_beta],\n                \"mean\": [prior_mean, post_mean],\n                \"mode\": [prior_mode, post_mode],\n                \"var\": [prior_var, post_var],\n                \"sd\": [prior_sd, post_sd],\n            },\n            index=[\"prior\", \"posterior\"],\n        )\n    return summary\n\nNel caso in cui disponiamo di un campione di dati di dimensioni molto ridotte, come ad esempio 15 successi su 20 tentativi in una distribuzione beta-binomiale, la distribuzione a priori pu√≤ esercitare un notevole impatto sulla distribuzione a posteriori. In contrasto, se consideriamo una distribuzione a priori uniforme, la distribuzione a posteriori assomiglier√† alla funzione di verosimiglianza, con l‚Äôeccezione dell‚Äôarea sotto le due curve. In parole pi√π semplici, quando la distribuzione a priori √® uniforme, la distribuzione a posteriori presenter√† un picco nella stima di massima verosimiglianza. Tuttavia, quando adottiamo diverse distribuzioni a priori, la distribuzione a posteriori potrebbe notevolmente discostarsi.\nCominciamo esaminando il caso in cui viene adottata una distribuzione a priori uniforme.\n\nplot_beta_binomial(alpha=1, beta=1, y=15, n=20)\n\n\n\n\n\n\n\n\nEsaminiamo ora l‚Äôeffetto di una distribuzione a priori poco informativa, come ad esempio una Beta(2, 2). In questa situazione, l‚Äôimpatto di tale scelta sulla distribuzione a posteriori √® di modesta entit√†, ma comunque presente. Questo fenomeno pu√≤ essere interpretato come un effetto di ‚Äúregolarizzazione‚Äù, il quale influisce sulla nostra stima in modo pi√π cauto rispetto a quanto ottenuto tramite il principio di massima verosimiglianza. In altre parole, la stima risultante risulta essere pi√π ‚Äúbilanciata‚Äù verso il valore intermedio di 0.5.\n\nplot_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n17\n7\n0.708333\n0.727273\n0.008264\n0.090906\n\n\n\n\n\n\n\n\nSe il campione √® di dimensioni maggiori, l‚Äôadozione di una distribuzione a priori Beta(2, 2) ha un effetto trascurabile: infatti, il valore massimo della distribuzione a posteriori risulta essere quasi identico alla stima di massima verosimiglianza.\n\nplot_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n152\n52\n0.745098\n0.747525\n0.000926\n0.030438\n\n\n\n\n\n\n\n\nSe optiamo per una distribuzione a priori informativa, questa avr√† un notevole impatto sulla distribuzione a posteriori quando ci si trova di fronte a un campione di dimensioni ridotte.\n\nplot_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.20\n0.025510\n0.159719\n\n\nposterior\n17\n10\n0.629630\n0.64\n0.008328\n0.091260\n\n\n\n\n\n\n\n\nAl contrario, la medesima distribuzione a priori ha un effetto insignificante sulla distribuzione a posteriori quando il campione √® di dimensioni considerevoli.\n\nplot_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n152\n55\n0.734300\n0.736585\n0.000938\n0.030627\n\n\n\n\n\n\n\n\n\nplot_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n1502\n505\n0.748381\n0.748628\n0.000094\n0.009684",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "42¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "42.3 Connessione tra intuizioni e teoria",
    "text": "42.3 Connessione tra intuizioni e teoria\nL‚Äôequilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessit√† matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che pu√≤ essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL‚Äôequazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) √® significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sar√† principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) √® piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente √® \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilit√† a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletter√† l‚Äôimportanza attribuita all‚Äôinformazione a priori: maggiore √® il valore di \\(\\alpha + \\beta\\), maggiore sar√† il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) √® considerevolmente grande, la distribuzione a posteriori avr√† un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#un-esempio-controintuitivo",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#un-esempio-controintuitivo",
    "title": "42¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "42.4 Un Esempio Controintuitivo",
    "text": "42.4 Un Esempio Controintuitivo\nEsaminiamo ora un altro esempio proposto in un tweet di McElreath:\n\nLesson: Don‚Äôt trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi scenari in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libert√†) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code pi√π spesse.\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento pi√π ‚Äúprevedibile‚Äù e concentrato attorno al valore medio.\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code pi√π spesse. La presenza di ‚Äúextra massa‚Äù nelle code significa che ciascuna distribuzione trova il modo dell‚Äôaltra pi√π plausibile, portando a una media che non rappresenta il miglior ‚Äúcompromesso‚Äù. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa √® molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non √® sorpreso dalla likelihood. Questo porta a un posterior che √® pi√π influenzato dalla likelihood normale.\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, √® il prior normale a dominare. Il ragionamento √® simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code pi√π spesse della likelihood di Student-t.\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code pi√π spesse e quindi eserciti una maggiore influenza sul posterior.\nDi seguito √® riportato il codice per riprodurre i risultati delle figure precedenti.\n\n# Observed data\nyobs = 0\n\n# Number of samples\nn_samples = 2000\n\n# Model with normal prior and normal likelihood\nwith pm.Model() as mnn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and t likelihood\nwith pm.Model() as mtt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and normal likelihood\nwith pm.Model() as mnt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with normal prior and t likelihood\nwith pm.Model() as mtn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n\n# Function to plot the results\ndef plot_posterior(trace, model_name):\n    mu_samples = trace.posterior['mu'].values.flatten()  # Extracting 'mu' samples\n    plt.hist(mu_samples, density=True, bins=30, alpha=0.7, label=f'{model_name} Posterior')\n    plt.xlabel('mu')\n    plt.ylabel('Density')\n    plt.legend()\n\n# Plotting the results\nplt.figure(figsize=(9, 7))\n\nplt.subplot(2, 2, 1)\nplot_posterior(trace_mnn, 'Normal Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 2)\nplot_posterior(trace_mtt, 't Prior, t Likelihood')\n\nplt.subplot(2, 2, 3)\nplot_posterior(trace_mnt, 't Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 4)\nplot_posterior(trace_mtn, 'Normal Prior, t Likelihood')\nplt.tight_layout()\nplt.show()\n\n/var/folders/hl/dt523djx7_q7xjrthzjpdvc40000gn/T/ipykernel_61930/765634110.py:23: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nIn conclusione, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non √® una scelta consigliabile. √à invece fondamentale procedere con l‚Äôesecuzione dei calcoli.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#commenti-e-considerazioni-finali",
    "title": "42¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "42.5 Commenti e considerazioni finali",
    "text": "42.5 Commenti e considerazioni finali\nLa conclusione dell‚Äôesempio presentato da Johnson (2022) ci offre una panoramica intuitiva ma fondamentale: l‚Äôaggiornamento bayesiano rispecchia i processi di ragionamento che intuitivamente utilizziamo nel quotidiano. Quando ci troviamo di fronte a nuove evidenze deboli, le nostre credenze preesistenti rimangono invariate. Al contrario, evidenze robuste ci costringono a rivedere e aggiornare le nostre credenze in linea con i nuovi dati. Questa √® la quintessenza dell‚Äôapproccio bayesiano: un meccanismo quantitativo e preciso che formalizza le nostre intuizioni.\nQuesto √® in netto contrasto con l‚Äôapproccio frequentista, che ignora le credenze o le conoscenze preesistenti. In questo schema, i risultati di un test statistico basato su un campione limitato di dati possono portare a una modifica delle credenze senza alcuna considerazione per le evidenze o le intuizioni pregresse. Questo divario metodologico tra i due approcci √® sintetizzata con efficacia nella celebre striscia comica di xkcd.\nEntrando nel dettaglio del contesto bayesiano, la scelta delle distribuzioni a priori √® un elemento cruciale, con due obiettivi principali. In primo luogo, l‚Äôutilizzo di distribuzioni a priori debolmente informative agisce come un meccanismo di regolarizzazione, contribuendo a ottenere inferenze pi√π prudenti mitigando l‚Äôeffetto di osservazioni estreme. Questo aspetto √® generalmente accettato e ritenuto non controverso nel campo statistico.\nIn secondo luogo, un settore in rapida crescita e di grande interesse √® l‚Äôintegrazione esplicita di conoscenza esperta preesistente. Tale processo, noto come ‚Äòelicitazione della conoscenza esperta‚Äô (expert knowledge elicitation) Brownstein et al. (2019), va ben oltre la semplice intervista con gli esperti. Esso richiede un elevato grado di rigore metodologico per prevenire l‚Äôinsorgenza di bias cognitivi. Questo aspetto √® particolarmente rilevante in ambiti come la psicologia, dove gli sviluppi teorici possono essere meno frequenti. Tale necessit√† √® supportata da un‚Äôampia letteratura accademica e da protocolli ben definiti, quali Cooke, SHELF e Delphi probabilistico O‚ÄôHagan (2019).\nIn conclusione, pur aspirando all‚Äôobiettivit√† come ideale della ricerca scientifica, √® indispensabile riconoscere e affrontare la soggettivit√† intrinseca nel processo di scelta dei priori. Attraverso l‚Äôuso di protocolli rigorosi di elicitazione della conoscenza esperta, √® possibile realizzare analisi bayesiane robuste e ben informate, che riflettano in modo accurato sia le incertezze intrinseche che la competenza specifica nel campo di studio.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "42¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p jax\n\nLast updated: Tue Apr 09 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\njax: 0.4.25\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.0\nrequests  : 2.31.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\npymc      : 5.10.4\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBrownstein, Naomi C, Thomas A Louis, Anthony O‚ÄôHagan, e Jane Pendergast. 2019. ¬´The role of expert judgment in statistical inference and evidence-based decision-making¬ª. The American Statistician 73 (sup1): 56‚Äì68.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO‚ÄôHagan, Anthony. 2019. ¬´Expert knowledge elicitation: subjective but scientific¬ª. The American Statistician 73 (sup1): 69‚Äì81.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "43¬† Introduzione",
    "section": "",
    "text": "In questa parte della dispensa, esamineremo le procedure Monte Carlo a catena di Markov, con un focus particolare sull‚Äôalgoritmo di Metropolis, che permette di approssimare la distribuzione a posteriori quando non √® possibile ottenere una soluzione analitica.\nIntrodurremo il concetto di predizione bayesiana, essenziale per costruire la distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l‚Äôinferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esploreremo inoltre il modello bayesiano di Poisson per le frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento efficace per affrontare situazioni in cui le osservazioni sono organizzate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "",
    "text": "Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana relativi alla distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche discusso l‚Äôutilizzo di approcci come l‚Äôapprossimazione tramite griglia e i metodi dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione e spiegheremo perch√© sono necessari approcci speciali noti come metodi di Monte Carlo a Catena di Markov (MCMC).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.1 Il denominatore bayesiano",
    "text": "44.1 Il denominatore bayesiano\nNell‚Äôapproccio bayesiano, il nostro obiettivo principale √® determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando sia i dati osservati $ y $ che la distribuzione a priori \\(p(\\theta)\\). Questo processo si basa sul teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIn questa formula, il denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta l‚Äôintegrazione (o la somma, nel caso di variabili discrete) su tutti i possibili valori di \\(\\theta\\), fornendo cos√¨ la probabilit√† marginale di \\(y\\). Questo assicura che $ p(y) $ sia una distribuzione di probabilit√† valida che si integra (o si somma) a 1.\nTuttavia, spesso incontriamo una sfida significativa: il calcolo dell‚Äôevidenza \\(p(y) = \\int p(y \\mid \\theta) p(\\theta) d\\theta\\) pu√≤ essere estremamente complesso, specialmente per modelli pi√π articolati, rendendo difficile ottenere con precisione la distribuzione a posteriori.\nUna soluzione possibile √® rappresentata dalle distribuzioni a priori coniugate, che offrono un metodo analitico per determinare la distribuzione a posteriori. Tuttavia, questo limita la selezione delle distribuzioni a priori e di verosimiglianza.\nUn metodo per superare questa limitazione √® ricorrere a soluzioni numeriche, ma i metodi di campionamento a griglia sono applicabili solo nel caso di modelli con un numero di parametri molto piccolo.\nLa soluzione generale √® utilizzare i Metodi di Monte Carlo a Catena di Markov (MCMC). Questi metodi consentono di derivare la distribuzione a posteriori basandosi su presupposti teorici e senza restrizioni nella scelta delle distribuzioni. L‚Äôapproccio Monte Carlo si basa sulla generazione di sequenze di numeri casuali per creare un ampio campione di osservazioni dalla distribuzione a posteriori. Da questi campioni, possiamo poi stimare empiricamente le propriet√† di interesse. Questo approccio richiede l‚Äôuso di metodi computazionalmente intensivi e, con la crescente potenza di calcolo dei computer moderni, tali metodi stanno diventando sempre pi√π accessibili e popolari nell‚Äôanalisi dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-di-monte-carlo",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-di-monte-carlo",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.2 Il Metodo di Monte Carlo",
    "text": "44.2 Il Metodo di Monte Carlo\nNei capitoli precedenti abbiamo gi√† esplorato l‚Äôefficacia della simulazione nel campo della teoria delle probabilit√†. Un esempio classico √® il problema di Monty Hall, che mostra come la simulazione ripetuta possa fornire stime affidabili per la media e la varianza di variabili casuali. Inoltre, applicando la legge dei grandi numeri, queste stime diventano pi√π accurate all‚Äôaumentare del numero di simulazioni. Ci√≤ evidenzia la potenza dei metodi Monte Carlo, che evitano la necessit√† di calcolare integrali complessi.\nIl Metodo di Monte Carlo, sviluppato durante il Progetto Manhattan negli anni ‚Äô40, utilizza numeri casuali per risolvere problemi matematici complessi. Originariamente ideato da Stanislaw Ulam e successivamente implementato da John von Neumann, il metodo prende il nome dallo zio giocatore d‚Äôazzardo di Ulam, come suggerito da Nicholas Metropolis. Da allora, questo metodo √® diventato una tecnica fondamentale in diverse discipline, contribuendo significativamente alla risoluzione di problemi complessi.\nLa metodologia di Monte Carlo genera un‚Äôampia serie di punti casuali per stimare quantit√† di interesse, come l‚Äôintegrazione numerica. Un esempio classico √® l‚Äôapprossimazione dell‚Äôintegrale di un cerchio in 2D, dove il rapporto tra il numero di punti che cadono all‚Äôinterno del cerchio e tutti i campioni fornisce un‚Äôapprossimazione dell‚Äôarea (per un esempio numerico, si veda Appendice O).\nPer illustrare ulteriormente questo concetto, consideriamo ora una distribuzione continua \\(p(\\theta \\mid y)\\) con una media \\(\\mu\\). Se siamo in grado di generare una sequenza di campioni casuali \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) indipendenti e identicamente distribuiti secondo \\(p(\\theta \\mid y)\\), possiamo stimare il valore atteso teorico di \\(\\theta\\) utilizzando la media campionaria \\(\\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}\\). Questa approssimazione diventa sempre pi√π accurata man mano che aumenta il numero di campioni \\(T\\), grazie alla Legge Forte dei Grandi Numeri.\nUn altro vantaggio del Metodo di Monte Carlo √® la sua capacit√† di approssimare la probabilit√† che una variabile casuale \\(\\theta\\) cada all‚Äôinterno di un intervallo specifico \\((l, u)\\). Questo pu√≤ essere ottenuto calcolando la media campionaria della funzione indicatrice \\(I(l &lt; \\theta &lt; u)\\) per ogni realizzazione \\(\\theta^{(t)}\\), cio√® \\(Pr(l &lt; \\theta &lt; u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\in (l, u)}{T}\\).\nNonostante la loro efficacia, un limite dei metodi Monte Carlo tradizionali risiede nella generazione efficiente di un elevato numero di campioni \\(X_1, X_2, \\ldots, X_n\\). In risposta a questa sfida, i metodi di Monte Carlo basati su catene di Markov (MCMC) offrono una soluzione potente per simulare da distribuzioni complesse attraverso catene di Markov. L‚Äôevoluzione di questi algoritmi ha trasformato radicalmente la statistica e il calcolo scientifico, permettendo la simulazione da una vasta gamma di distribuzioni, anche in spazi di alta dimensionalit√†.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.3 Le Catene di Markov",
    "text": "44.3 Le Catene di Markov\nLe catene di Markov, ideate da Andrey Markov nel 1906, rappresentano un tentativo di estendere la legge dei grandi numeri a contesti in cui le variabili casuali non sono indipendenti. Tradizionalmente, la statistica si concentra su sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), simboleggiate come \\(X_0, X_1, \\ldots, X_n, \\ldots\\). In tali sequenze, ogni variabile √® indipendente dalle altre e segue la stessa distribuzione, con \\(n\\) che rappresenta un indice temporale discreto. Tuttavia, questa assunzione di indipendenza non √® sempre realistica nei modelli di fenomeni complessi, portando alla necessit√† di esplorare forme alternative di dipendenza tra variabili.\nPer superare le limitazioni dell‚Äôindipendenza, le catene di Markov introducono una cosiddetta ‚Äúdipendenza a un passo‚Äù, incarnata nella ‚Äúpropriet√† di Markov‚Äù. Questa propriet√† stabilisce che la previsione di un evento futuro \\(X_{n+1}\\) dipende unicamente dall‚Äôevento immediatamente precedente \\(X_n\\), indipendentemente dagli eventi passati \\(X_0, X_1, X_2, \\ldots, X_{n-1}\\). La propriet√† di Markov √® espressa matematicamente come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta propriet√† afferma che la previsione di un evento futuro dipende solo dall‚Äôevento immediatamente precedente, semplificando i calcoli relativi alle probabilit√† condizionali.\nLe catene di Markov rappresentano un framework fondamentale per la modellazione delle dipendenze tra variabili casuali, una nozione cruciale in numerosi campi della statistica e della scienza dei dati, inclusa la metodologia MCMC (Markov Chain Monte Carlo). In particolare, nell‚Äôambito dell‚Äôanalisi bayesiana, l‚Äôuso di MCMC si rivela di estrema importanza, soprattutto quando non √® possibile calcolare in modo analitico la distribuzione a posteriori.\nL‚Äôalgoritmo di Metropolis rappresenta una delle implementazioni pi√π semplici del metodo MCMC. Questo algoritmo sfrutta la natura dipendente delle catene di Markov per navigare in modo efficace attraverso lo spazio della distribuzione a posteriori. Questo aspetto rende il MCMC uno strumento di grande potenza per affrontare problemi complessi in cui i metodi analitici tradizionali non possono essere applicati (per ulteriori dettagli, si veda Appendice O). In breve, il MCMC consente di generare un vasto insieme di valori per il parametro \\(\\theta\\). Idealmente, questi valori riflettono la distribuzione a posteriori \\(p(\\theta \\mid y)\\) quando questa non pu√≤ essere ottenuta direttamente. Questa caratteristica rende il MCMC uno strumento essenziale per risolvere problemi complessi in cui i metodi analitici convenzionali non sono applicabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.4 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "44.4 Estrazione di campioni dalla distribuzione a posteriori\nNella discussione seguente ci porremo l‚Äôobiettivo di comprendere come utilizzare l‚Äôalgoritmo di Metropolis per approssimare la distribuzione a posteriori \\(p(\\theta \\mid y)\\). A questo fine, il capitolo √® strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o ‚Äúa posteriori,‚Äù sia gi√† conosciuta o disponibile per l‚Äôanalisi.\nIn seguito, passeremo a illustrare come l‚Äôalgoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non √® direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un‚Äôapprossimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse √® focalizzato sulla determinazione della probabilit√† che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilit√† sar√† indicata come \\(\\pi\\). Iniziamo importando i dati.\n\nmoma_sample = pd.read_csv(\"../../data/moma_sample.csv\")\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample.head()\n\n\n\n\n\n\n\n\n\nartist\ncountry\nbirth\ndeath\nalive\ngenx\ngender\ncount\nyear_acquired_min\nyear_acquired_max\n\n\n\n\n0\nAd Gerritsen\ndutch\n1940\n2015.0\nFalse\nFalse\nmale\n1\n1981\n1981\n\n\n1\nKirstine Roepstorff\ndanish\n1972\nNaN\nTrue\nTrue\nfemale\n3\n2005\n2005\n\n\n2\nLisa Baumgardner\namerican\n1958\n2015.0\nFalse\nFalse\nfemale\n2\n2016\n2016\n\n\n3\nDavid Bates\namerican\n1952\nNaN\nTrue\nFalse\nmale\n1\n2001\n2001\n\n\n4\nSimon Levy\namerican\n1946\nNaN\nTrue\nFalse\nmale\n1\n2012\n2012\n\n\n\n\n\n\n\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\nresult = moma_sample[\"genx\"].value_counts()\nprint(result)\n\ngenx\nFalse    86\nTrue     14\nName: count, dtype: int64\n\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che √® stato osservato. Tuttavia, poich√© il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilit√† di appartenere alla generazione X o a una generazione successiva) all‚Äôinterno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l‚Äôesito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le propriet√† delle distribuzioni coniugate, possiamo calcolare la distribuzione a posteriori esatta:\nY ~ Binomiale(100, œÄ)\nŒ∏ = Beta(4, 6)\nŒ∏ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) ‚Üí Beta(18, 92)\nNella figura successiva √® rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori scelta.\n\nx = np.linspace(0, 1, 1000)\n\nprior_density = stats.beta.pdf(x, 4, 6)\nposterior_density = stats.beta.pdf(x, 18, 92)\n\nplt.fill_between(x, prior_density, alpha=0.5, label=\"Prior: Beta(4, 6)\")\nplt.fill_between(x, posterior_density, alpha=0.5, label=\"Posterior: Beta(18, 92)\")\nplt.xlabel(\"Parameter Value\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.title(\"Prior and Posterior Densities\")\nplt.show()\n\n\n\n\n\n\n\n\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto √®\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n44.4.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un‚Äôapprossimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con poche osservazioni (ad esempio, 10), possiamo procedere con la seguente simulazione:\n\ny = stats.beta(18, 92).rvs(10)\nprint(y)\n\n[0.18694021 0.12067309 0.17576971 0.1608302  0.12912987 0.20527983\n 0.14209658 0.15057358 0.12001648 0.13024873]\n\n\n\nnp.mean(y)\n\n0.1521558285153169\n\n\nTuttavia, con solo 10 campioni l‚Äôapprossimazione potrebbe non essere molto accurata. Pi√π aumentiamo il numero di campioni (cio√® il numero di osservazioni casuali generate), pi√π precisa sar√† l‚Äôapprossimazione. Aumentando il numero di campioni, ad esempio a 10000, otteniamo un risultato pi√π preciso:\n\nstats.beta(18, 92).rvs(10000).mean()\n\n0.16380917953899665\n\n\nQuando il numero di campioni a posteriori diventa molto grande, la distribuzione campionaria converge alla densit√† della popolazione. Questo concetto si applica non solo alla media, ma anche ad altre statistiche descrittive, come la moda e la varianza.\n√à importante sottolineare che l‚Äôapplicazione della simulazione di Monte Carlo √® efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ci√≤ √® stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poich√© le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l‚Äôespressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l‚Äôutilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, per√≤, √® possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l‚Äôuso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l‚Äôalgoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#algoritmo-di-metropolis",
    "href": "chapters/mcmc/01_metropolis.html#algoritmo-di-metropolis",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.5 Algoritmo di Metropolis",
    "text": "44.5 Algoritmo di Metropolis\nL‚Äôalgoritmo di Metropolis √® un metodo avanzato per il campionamento da distribuzioni probabilistiche complesse. Appartiene alla famiglia dei metodi Monte Carlo Markov Chain (MCMC) e combina strategie di campionamento Monte Carlo con catene di Markov per navigare nello spazio dei parametri in modo intelligente. Questo consente di ottenere campioni rappresentativi della distribuzione di interesse indipendentemente dal punto di partenza, riducendo il rischio di bias nei risultati.\n\n44.5.1 Passaggi Fondamentali dell‚ÄôAlgoritmo di Metropolis\n\nScegli un valore iniziale \\(\\theta_1\\). Imposta \\(t = 1\\).\nCampiona un possibile nuovo valore \\(\\theta_p\\) basato su una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\). Di solito, si usa una distribuzione normale \\(N(\\theta_t, \\tau)\\) come distribuzione di proposta, dove \\(\\tau\\) funge da parametro di regolazione che controlla la dimensione del passo.\nCalcola il rapporto \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\).\nSe \\(\\alpha \\geq 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\).\nSe \\(\\alpha &lt; 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\) con probabilit√† \\(\\alpha\\). Altrimenti, imposta \\(\\theta_{t+1} = \\theta_t\\).\nRipeti dal passo 2 per campionare un nuovo valore \\(\\theta_p\\).\n\n\n\n44.5.2 Dettagli dell‚ÄôAlgoritmo\n\nDistribuzione di Proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) √® usata per generare nuovi campioni di \\(\\theta_p\\) basati sul valore corrente \\(\\theta_t\\). Una scelta comune √® la distribuzione normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) √® un parametro di tuning che controlla la dimensione dei passi del campionamento. Un valore di \\(\\tau\\) troppo grande o troppo piccolo pu√≤ influenzare negativamente l‚Äôefficienza del campionamento.\nCalcolo del Rapporto \\(\\alpha\\): Il rapporto \\(\\alpha\\) √® dato dalla probabilit√† a posteriori del nuovo valore \\(\\theta_p\\) rispetto alla probabilit√† a posteriori del valore corrente \\(\\theta_t\\). Questo rapporto determina l‚Äôaccettazione o il rifiuto del nuovo campione.\nDecisione di Accettazione:\n\nSe \\(\\alpha \\geq 1\\), il nuovo valore \\(\\theta_p\\) √® sempre accettato.\nSe \\(\\alpha &lt; 1\\), il nuovo valore \\(\\theta_p\\) √® accettato con probabilit√† \\(\\alpha\\). Se non viene accettato, il valore corrente \\(\\theta_t\\) √® mantenuto per il prossimo passo.\n\n\nQuesto processo permette di esplorare lo spazio dei parametri \\(\\theta\\) generando una catena di Markov che, nel tempo, converge verso la distribuzione a posteriori \\(p(\\theta \\mid y)\\). Utilizzando questa catena, possiamo stimare empiricamente le propriet√† della distribuzione a posteriori.\nLa procedura continua con l‚Äôiterazione dei passi dal 2 al 5, permettendo alla catena di campioni di convergere alla distribuzione target. Inizialmente, i campioni potrebbero non essere rappresentativi, ma dopo un sufficiente numero di iterazioni (il cosiddetto ‚Äúburn-in‚Äù), la distribuzione dei punti accettati dovrebbe avvicinarsi a quella che si intende esplorare.\nL‚Äôefficienza di questo algoritmo deriva dalla sua abilit√† nel mantenere un equilibrio tra l‚Äôesplorazione di nuove possibilit√† e l‚Äôutilizzo di quelle gi√† note. Questo viene realizzato attraverso l‚Äôadozione di un meccanismo che accetta i punti suggeriti in modo probabilistico, facilitando cos√¨ la raccolta di un campione che riflette accuratamente la distribuzione di probabilit√† complessa sotto indagine.\nPer una visualizzazione del comportamento dell‚Äôalgoritmo di Metropolis nell‚Äôesplorare lo spazio dei parametri, si pu√≤ consultare questo post. La distinzione tra i diversi metodi MCMC si basa principalmente sul tipo di distribuzione proposta e sul criterio di accettazione dei punti nel campionamento.\n\n\n44.5.3 Implementazione dell‚ÄôAlgoritmo di Metropolis\nIniziamo col definire la distribuzione a priori. In questo esempio, la distribuzione a priori √® una distribuzione Beta(4, 6).\n\ndef prior(p):\n    alpha = 4\n    beta = 6\n    return stats.beta.pdf(p, alpha, beta)\n\nDefiniamo la verosimiglianza. Il problema presente richiede una verosimiglianza binomiale.\n\ndef likelihood(p):\n    y = 14\n    n = 100\n    return stats.binom.pmf(y, n, p)\n\nLa distribuzione a posteriori non normalizzata √® il prodotto della distribuzione a priori e della verosimiglianza. Si noti che, per il motivo spiegato prima, non √® necessario normalizzare la distribuzione a posteriori.\n\ndef posterior(p):\n    return likelihood(p) * prior(p)\n\nNell‚Äôimplementazione di un algoritmo di Metropolis in ambito bayesiano, vi sono diversi aspetti da considerare attentamente. Ecco alcuni punti cruciali:\n\nSimmetria della Distribuzione Proposta: √à fondamentale che la distribuzione proposta sia simmetrica. Questa √® una condizione necessaria per il funzionamento dell‚Äôalgoritmo di Metropolis, ma non per quello di Metropolis-Hastings.\nValore Iniziale: Il valore iniziale scelto dovrebbe essere plausibile in base alla distribuzione a priori, in modo da facilitare la convergenza dell‚Äôalgoritmo.\nProbabilit√† Zero: Nel caso in cui la verosimiglianza o il prior assumano un valore di zero, il rapporto tra le densit√† di probabilit√† (pdfratio) all‚Äôinterno dell‚Äôalgoritmo di Metropolis risulter√† indefinito. Pertanto, √® importante garantire che il valore x_star, generato dalla distribuzione proposta, cada sempre entro i limiti del supporto sia del prior che della verosimiglianza.\n\nDi seguito √® presentato il codice dell‚Äôalgoritmo di Metropolis.\n\n# Definizione della funzione dell'algoritmo di Metropolis.\n# nsamp: Numero di campioni da generare.\n# xinit: Valore iniziale da cui iniziare il sampling.\ndef metropolis(nsamp, xinit):\n    # Inizializza un array vuoto per conservare i campioni generati.\n    samples = np.empty(nsamp)\n\n    # Imposta il primo valore (valore iniziale) da cui partire per la generazione dei campioni.\n    x_prev = xinit\n\n    # Inizia un ciclo che si ripeter√† per il numero di volte specificato da nsamp (numero di campioni da generare).\n    for i in range(nsamp):\n        # Genera un nuovo punto (x_star) usando una distribuzione normale (gaussiana).\n        # Questo nuovo punto √® generato in modo da essere \"vicino\" al punto precedente (x_prev),\n        # con una deviazione standard di 0.1. Questo significa che la maggior parte dei punti\n        # sar√† entro 0.1 unit√† da x_prev, ma alcuni potrebbero essere pi√π lontani.\n        x_star = np.random.normal(x_prev, 0.1)\n\n        # Verifica che il nuovo punto (x_star) sia un valore plausibile nel contesto del problema.\n        # Qui, l'assunzione √® che x_star debba essere tra 0 e 1. Se non lo √®, il punto √® rifiutato.\n        if 0 &lt;= x_star &lt;= 1:\n            # Calcola il valore della funzione di densit√† di probabilit√† posterior per il nuovo punto e il punto precedente.\n            # La funzione posterior √® definita altrove e rappresenta il prodotto del prior e della likelihood.\n            p_star = posterior(x_star)\n            p_prev = posterior(x_prev)\n\n            # Calcola il rapporto tra le densit√† posterior del nuovo punto e del punto precedente.\n            # Questo rapporto determina la probabilit√† di accettare il nuovo punto.\n            # Se p_prev √® 0, per evitare la divisione per zero, il rapporto √® impostato a 1.\n            pdfratio = p_star / p_prev if p_prev &gt; 0 else 1\n\n            # Genera un numero casuale tra 0 e 1.\n            random_chance = np.random.uniform()\n\n            # Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n            # Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n            # Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\n            acceptance_probability = min(1, pdfratio)\n\n            # Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n            # Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n            # mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\n            if random_chance &lt; acceptance_probability:\n                samples[i] = x_star  # Accetta il nuovo punto.\n                x_prev = (\n                    x_star  # Aggiorna il punto precedente con il nuovo punto accettato.\n                )\n            else:\n                samples[i] = (\n                    x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\n                )\n        else:\n            samples[i] = (\n                x_prev  # Se x_star non √® nel supporto, conserva il punto precedente.\n            )\n\n    # Dopo aver generato il numero desiderato di campioni, ritorna l'array dei campioni.\n    return samples\n\nL‚Äôidea fondamentale dietro la fase dell‚Äôalgoritmo di Metropolis successiva al calcolo di p_star e p_prev √® decidere se ‚Äúmuoversi‚Äù verso un nuovo punto basandosi su quanto √® probabile (o ‚Äúbuono‚Äù) quel punto rispetto al punto attuale, in termini della densit√† posteriore. Qui, la ‚Äúprobabilit√†‚Äù di un punto √® data dalla sua densit√† posteriore, che √® un modo per misurare quanto bene un certo valore del parametro si adatta ai dati osservati, dato un modello.\nEcco come funziona:\n\nGenerazione di un numero casuale.\nConfronto tra i punti: Si confronta il ‚Äúvalore‚Äù del nuovo punto (x_star) con quello del punto precedente (x_prev). Questo ‚Äúvalore‚Äù √® dato dalla densit√† posteriore: pi√π alto √®, meglio √®.\nDecisione:\n\nSe il nuovo punto √® migliore del precedente (ovvero, ha una densit√† posteriore maggiore o uguale), lo accettiamo sempre.\nSe il nuovo punto √® peggiore del precedente (ha una densit√† posteriore minore), non lo rifiutiamo subito. Invece, gli diamo una chance di essere scelto, ma questa chance √® pi√π piccola quanto pi√π il nuovo punto √® ‚Äúpeggiore‚Äù.\n\n\nIn termini di codice, questa logica si traduce cos√¨:\n# Genera un numero casuale tra 0 e 1.\nrandom_chance = np.random.uniform()\n\n# Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n# Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n# Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\nacceptance_probability = min(1, pdfratio)\n\n# Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n# Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n# mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\nif random_chance &lt; acceptance_probability:\n    samples[i] = x_star  # Accetta il nuovo punto.\n    x_prev = x_star      # Aggiorna il punto precedente con il nuovo punto accettato.\nelse:\n    samples[i] = x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\nIn sintesi, questo meccanismo consente all‚Äôalgoritmo di esplorare lo spazio dei parametri in modo efficiente, accettando sempre miglioramenti e, occasionalmente, facendo passi in direzioni non ottimali per evitare di rimanere intrappolati in ‚Äúminimi locali‚Äù, ovvero in soluzioni che sembrano buone rispetto a quelle vicine ma non sono le migliori globalmente.\nSi osservi un punto importante: nel calcolo di pdfratio, il rapporto tra la densit√† a posteriori del parametro proposto x_star e quella del parametro corrente x_prev, la costante di normalizzazione si annulla grazie alla regola di Bayes. Questo lascia nel rapporto solamente le componenti relative alla verosimiglianza e alla distribuzione a priori, che sono entrambe facilmente calcolabili. Matematicamente, questo si esprime come:\n\\[\n\\begin{equation}\n\\text{pdfratio} = \\frac{p(\\theta^* \\mid y)}{p(\\theta^{\\text{prev}} \\mid y)} = \\frac{\\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y)}}{\\frac{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}{p(y)}}\n= \\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}\n\\end{equation}\n\\] (eq-ratio-metropolis)\nEseguiamo dunque il campionamento usando l‚Äôalgoritmo che abbiamo definito.\n\nn_samples = 100_000\nsamps = metropolis(n_samples, 0.5)\n\nIn somma, l‚Äôalgoritmo Metropolis accetta come input il numero nsamp di passi da simulare e il punto di partenza. Come output, l‚Äôalgoritmo restituisce una catena di valori del parametro, specificamente la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{\\text{nsamp}}\\). Uno degli aspetti cruciali per la riuscita dell‚Äôalgoritmo √® il raggiungimento della stazionariet√† da parte della catena. In genere, i primi 1000-5000 valori vengono scartati in quanto rappresentano il periodo di ‚Äúburn-in‚Äù della catena. Dopo un determinato numero di passi \\(k\\), la catena converge e i valori diventano campioni effettivi dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nIl modello descritto √® stato inizialmente proposto da Metropolis et al.¬†nel 1953 (Metropolis et al. 1953). Hastings nel 1970 introdusse un‚Äôestensione nota come algoritmo Metropolis-Hastings (Hastings 1970). Altre varianti includono il campionatore di Gibbs, introdotto da Geman e Geman nel 1984 (Geman e Geman 1984), l‚ÄôHamiltonian Monte Carlo (Duane et al. 1987), e il No-U-Turn Sampler (NUTS) utilizzato in pacchetti come PyMC e Stan (Hoffman, Gelman, et al. 2014). Per un‚Äôanalisi pi√π dettagliata e intuitiva dell‚Äôalgoritmo Metropolis, si rimanda a Kruschke (2014).\nUn elemento chiave da considerare nell‚Äôuso dell‚Äôalgoritmo Metropolis √® il tasso di accettazione, che √® il rapporto tra il numero di valori del parametro proposti e il numero di quei valori che vengono effettivamente accettati. Un limite di questo algoritmo √® la sua inefficienza relativa: rispetto alle sue varianti pi√π moderne, l‚Äôalgoritmo Metropolis tende ad essere meno efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#aspetti-computazionali",
    "href": "chapters/mcmc/01_metropolis.html#aspetti-computazionali",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.6 Aspetti computazionali",
    "text": "44.6 Aspetti computazionali\n\n44.6.1 Warm-up/Burn-in\nUna catena di Markov ha bisogno di alcune iterazioni per raggiungere la distribuzione stazionaria. Queste iterazioni sono comunemente chiamate iterazioni di warm-up o burn-in (a seconda dell‚Äôalgoritmo e del software utilizzato) e vengono di solito scartate. In molti programmi software, la prima met√† delle iterazioni viene considerata come iterazioni di warm-up, quindi, nel caso presente, anche se abbiamo ottenuto 100000 iterazioni, ne utilizzeremo solo 50000.\n\n\n44.6.2 Sintesi della distribuzione a posteriori\nL‚Äôarray samps contiene 100000 valori di una catena di Markov. Escludiamo i primi 50000 valori considerati come burn-in e consideriamo i restanti 50000 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nMediante i valori della catena cos√¨ ottenuta √® facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, possiamo trovare la stima della media a posteriori.\n\nburnin = int(n_samples * 0.5)\nburnin\n\n50000\n\n\n\nnp.mean(samps[burnin:])\n\n0.16408968344081415\n\n\nOppure possiamo stimare la deviazione standard della distribuzione a posteriori.\n\nnp.std(samps[burnin:])\n\n0.03513787973422409\n\n\nVisualizziamo un trace plot dei valori della catena di Markov dopo il periodo di burn-in.\n\nplt.plot(samps[burnin:])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nIl trace plot indica che la catena inizia con un valore casuale per poi spostarsi rapidamente nell‚Äôarea intorno a 0.16, che √® l‚Äôarea con alta densit√† a posteriori. Successivamente, oscilla intorno a quel valore per le iterazioni successive.\n\nplt.plot(samps[:500])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nL‚Äôistogramma mostrato di seguito, sul quale √® stata sovrapposta la distribuzione a posteriori derivata analiticamente ‚Äì specificamente una \\(\\text{Beta}(25, 17)\\) ‚Äì dimostra che la catena converge effettivamente alla distribuzione a posteriori desiderata.\n\nplt.hist(samps[burnin:], bins=30, alpha=0.4, label=\"MCMC distribution\", density=True)\n# plot the true function\nx = np.linspace(0, 1, 1000)\nplt.plot(x, stats.beta.pdf(x, 18, 92), \"C0\", label=\"True distribution\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n√à possibile usare la funzione summary del pacchetto AriviZ per calolare l‚Äôintervallo di credibilit√†, ovvero l‚Äôintervallo che contiene la proporzione indicata dei valori estratti a caso dalla distribuzione a posteriori.\n\naz.summary(samps[burnin:], kind=\"stats\", hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nx\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\n\nUn KDE plot corrispondente all‚Äôistogramma precedente si pu√≤ generare usando az.plot_posterior(). La curva rappresenta l‚Äôintera distribuzione a posteriori e viene calcolata utilizzando la stima della densit√† del kernel (KDE) che serve a ‚Äúlisciare‚Äù l‚Äôistogramma.\n\naz.plot_posterior(samps[burnin:])\nplt.show()\n\n\n\n\n\n\n\n\nL‚ÄôHDI √® una scelta comune nelle statistiche bayesiane e valori arrotondati come 50% o 95% sono molto popolari. Ma ArviZ utilizza il 94% come valore predefinito. La ragione di questa scelta √® che il 94% √® vicino al valore ampiamente utilizzato del 95%, ma √® anche diverso da questo, cos√¨ da servire da ‚Äúamichevole promemoria‚Äù che non c‚Äô√® niente di speciale nella soglia del 5%. Idealmente sarebbe opportuno scegliere un valore che si adatti alle specifiche esigenze dell‚Äôanalisi statistica che si sta svolgendo, o almeno riconoscere che si sta usando un valore arbitrario.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.7 Diagnostiche della soluzione MCMC",
    "text": "44.7 Diagnostiche della soluzione MCMC\n\n44.7.1 Catene multiple\nPoich√© ciascuno stato in una catena di Markov dipende dagli stati precedenti, il valore o i valori iniziali possono influenzare i valori campionati. Una soluzione per verificare la sensibilit√† rispetto ai valori iniziali √® utilizzare pi√π catene, ognuna con diversi valori iniziali. Se pi√π catene campionano la stessa distribuzione target, queste dovrebbero mescolarsi bene, ovvero intersecarsi l‚Äôuna con l‚Äôaltra in un trace plot.\n\n\n44.7.2 Stazionariet√†\nUn punto importante da verificare √® se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta ‚Äúmixing‚Äù.\n\n\n44.7.3 Autocorrelazione\nOgni passo nell‚Äôalgoritmo MCMC √® chiamato iterazione. I valori campionati sono dipendenti, il che significa che il valore all‚Äôiterazione \\(m\\) dipende dal valore all‚Äôiterazione \\(m-1\\). Questa √® una differenza importante rispetto alle funzioni che generano campioni casuali indipendenti, come beta(25, 17).rvs(). I valori campionati formano una catena di Markov, il che significa che ciascun valore campionato √® correlato con il valore precedente (ad esempio, se \\(\\theta(m)\\) √® grande, \\(\\theta(m+1)\\) sar√† anch‚Äôesso grande).\nInformazioni sul ‚Äúmixing‚Äù della catena di Markov sono fornite dall‚Äôautocorrelazione. L‚Äôautocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantit√† \\(k\\) (dove \\(k\\) √® l‚Äôentit√† del ritardo) per verificare quanto si correli al variare di \\(k\\). L‚Äôautocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l‚Äôautocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due ‚Äúpassi‚Äù (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e cos√¨ via.\nL‚Äôautocorrelazione di ordine \\(k\\) √® data da \\(\\rho_k\\) e pu√≤ essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\] (eq-autocor)\nPer fare un esempio pratico, simuliamo dei dati autocorrelati.\n\nx = pd.array([22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51])\nprint(x)\n\n&lt;IntegerArray&gt;\n[22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51]\nLength: 15, dtype: Int64\n\n\nL‚Äôautocorrelazione di ordine 1 √® semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza.\n\nsm.tsa.acf(x)\n\narray([ 1.        ,  0.83174224,  0.65632458,  0.49105012,  0.27863962,\n        0.03102625, -0.16527446, -0.30369928, -0.40095465, -0.45823389,\n       -0.45047733, -0.36933174])\n\n\nNell‚Äôesempio, il vettore x √® una sequenza temporale di 15 elementi. Il vettore \\(x'\\) include gli elementi con gli indici da 0 a 13 nella sequenza originaria, mentre il vettore \\(x''\\) include gli elementi 1:14. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((0, 1)\\), \\((1, 2), (2, 3), \\dots (13, 14)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori \\(x'\\) e \\(x''\\) corrisponde all‚Äôautocorrelazione di ordine 1 della serie temporale.\nNell‚Äôoutput precedente\n\n0.83174224 √® l‚Äôautocorrelazione di ordine 1 (lag = 1),\n0.65632458 √® l‚Äôautocorrelazione di ordine 2 (lag = 2),\n0.49105012 √® l‚Äôautocorrelazione di ordine 3 (lag = 3),\necc.\n\n√à possibile specificare il numero di ritardi (lag) da utilizzare con l‚Äôargomento nlags:\n\nsm.tsa.acf(x, nlags=4)\n\narray([1.        , 0.83174224, 0.65632458, 0.49105012, 0.27863962])\n\n\nIn Python possiamo creare un grafico della funzione di autocorrelazione (correlogramma) per una serie temporale usando la funzione tsaplots.plot_acf() dalla libreria statsmodels.\n\ntsaplots.plot_acf(x, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nPer i dati dell‚Äôesempio in discussione otteniamo la situazione seguente.\n\ntsaplots.plot_acf(samps[burnin:], lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nIl correlogramma √® uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall‚Äôautocorrelazione \\(\\rho_k\\) di una catena di Markov in funzione del ritardo \\(k\\) con cui l‚Äôautocorrelazione √® calcolata: nel grafico ogni barretta verticale riporta il valore dell‚Äôautocorrelazione (sull‚Äôasse delle ordinate) in funzione del ritardo (sull‚Äôasse delle ascisse).\nIn situazioni ottimali l‚Äôautocorrelazione diminuisce rapidamente ed √® effettivamente pari a 0 per piccoli lag. Ci√≤ indica che i valori della catena di Markov che si trovano a pi√π di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del ‚Äúmixing‚Äù della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l‚Äôautocorrelazione √® quella di assottigliare l‚Äôoutput immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning.\nNel seguente correlogramma, analizziamo la medesima catena di Markov. Tuttavia, in questa occasione applichiamo un ‚Äúthinning‚Äù (sottocampionamento) con un fattore di 5.\n\nthin = 5\nsampsthin = samps[burnin::thin]\ntsaplots.plot_acf(sampsthin, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nSi pu√≤ notare come l‚Äôautocorrelazione diminuisce molto pi√π rapidamente.\n\n44.7.3.1 Tasso di accettazione\nQuando si utilizza l‚Äôalgoritmo Metropolis, √® importante monitorare il tasso di accettazione e assicurarsi che sia nell‚Äôintervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegher√† molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D‚Äôaltra parte, se il tasso di accettazione √® molto basso, la catena rimarr√† bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l‚Äôalgoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale √® compreso tra il 40% e il 50%.\n\n\n44.7.3.2 Test di convergenza\nPer valutare la convergenza di una catena di Markov Monte Carlo (MCMC), esistono diversi metodi, tra cui approcci grafici e test statistici. Ecco una spiegazione pi√π chiara e dettagliata:\n\n\n\n44.7.4 Approcci Grafici: Tracce delle Serie Temporali (Trace Plots)\nLe tracce delle serie temporali, o trace plots, sono grafici che mostrano l‚Äôevoluzione dei valori campionati rispetto al numero di iterazioni. Questi grafici sono utili per valutare visivamente se la catena ha raggiunto la convergenza. Segni che indicano una potenziale convergenza includono:\n\nAssenza di Tendenze: Non ci sono trend ascendenti o discendenti nel corso delle iterazioni.\nCostanza dell‚ÄôAmpiezza: La variabilit√† dei valori campionati rimane costante nel tempo, senza significative fluttuazioni.\nMancanza di Periodicit√†: Non si osservano cicli o ripetizioni regolari che potrebbero indicare la presenza di correlazioni residue.\n\n\n\n44.7.5 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n44.7.5.1 Test di Geweke\nIl test di Geweke √® una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l‚Äôultimo 50% dei campioni, dopo aver escluso un iniziale periodo di ‚Äúburn-in‚Äù (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base √® che, se la catena √® in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n\n44.7.5.2 Geweke Z-score\nUna variante del test di Geweke √® lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in pi√π esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. √à importante notare che nessun test pu√≤ garantire con certezza la convergenza, ma l‚Äôutilizzo congiunto di approcci grafici e test statistici pu√≤ offrire una buona indicazione dello stato della catena.\n\n\n\n44.7.6 Effective sample size (ESS)\nQuando le iterazioni sono dipendenti, ogni iterazione contiene informazioni sovrapposte con le iterazioni precedenti. In altre parole, quando si ottengono 500 campioni dipendenti dalla distribuzione a posteriori, questi contengono solo informazioni equivalenti a &lt; 500 campioni indipendenti. L‚ÄôESS (Effective Sample Size) quantifica la quantit√† effettiva di informazioni, quindi una catena con ESS = n conterr√† approssimativamente la stessa quantit√† di informazioni di n campioni indipendenti. In generale, vogliamo che l‚ÄôESS sia almeno 400 per un‚Äôutilizzazione generale nel riassumere la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.8 Caso Normale-Normale",
    "text": "44.8 Caso Normale-Normale\nConsideriamo ora il caso Normale-Normale di cui √® possibile trovare una soluzione analitica. Supponiamo, come prior, una \\(\\mathcal{N}(30, 5\\).\n\ndef prior(mu):\n    return stats.norm.pdf(mu, 30, 5)\n\nPer la verosimiglianza del parametro \\(\\mu\\), supponiamo \\(\\sigma\\) nota e uguale alla deviazione standard del campione.\n\ndef likelihood(mu, data):\n    std_data = np.std(data)  # Calcola la deviazione standard dei dati\n    return np.prod(stats.norm.pdf(data, mu, std_data))\n\nDefiniamo il posterior non normalizzato:\n\ndef posterior(mu, data):\n    return likelihood(mu, data) * prior(mu)\n\nModifichiamo ora l‚Äôalgoritmo di Metropolis descritto sopra per adattarlo al caso presente.\n\n# Algoritmo di Metropolis per il caso normale-normale\ndef metropolis_for_normal(nsamp, xinit, data):\n    samples = np.empty(nsamp)\n    x_prev = xinit\n\n    for i in range(nsamp):\n        x_star = np.random.normal(x_prev, 0.5)  # Genera un nuovo punto dalla proposta\n\n        # Calcola il rapporto di accettazione e accetta il nuovo punto con una certa probabilit√†\n        if posterior(x_star, data) / posterior(x_prev, data) &gt; np.random.uniform():\n            x_prev = x_star\n\n        samples[i] = x_prev\n\n    return samples\n\nVediamo cosa fa la presente versione dell‚Äôalgoritmo di Metropolis passo dopo passo:\n\nCiclo sui Campioni: for i in range(nsamp): inizia un ciclo che si ripeter√† nsamp volte, dove nsamp √® il numero totale di campioni che vogliamo generare. Ogni iterazione di questo ciclo produrr√† un campione dalla distribuzione di interesse.\nGenerazione di un Nuovo Punto: x_star = np.random.normal(x_prev, 0.5) genera un nuovo punto (x_star) come proposta per il prossimo passo del campionamento. Questo √® fatto campionando da una distribuzione normale con media uguale all‚Äôultimo punto accettato (x_prev) e una deviazione standard di 0.5. Questa distribuzione √® detta distribuzione di proposta e serve a esplorare lo spazio dei parametri.\nCalcolo del Rapporto di Accettazione:\n\nIl rapporto di accettazione √® calcolato come posterior(x_star, data) / posterior(x_prev, data), che √® il rapporto tra la probabilit√† del posterior del nuovo punto proposto (x_star) e la probabilit√† del posterior dell‚Äôultimo punto accettato (x_prev).\nQuesto rapporto indica quanto sia preferibile il nuovo punto rispetto al precedente, basandosi sulla funzione posterior, che calcola la probabilit√† a posteriori del modello dato il parametro e i dati osservati.\n\nDecisione di Accettazione del Nuovo Punto:\n\nLa decisione se accettare o meno il nuovo punto (x_star) si basa su un confronto del rapporto di accettazione con un numero casuale uniformemente distribuito tra 0 e 1 (np.random.uniform()).\nSe il rapporto di accettazione √® maggiore di questo numero casuale, il nuovo punto √® accettato come il prossimo punto nella catena (x_prev = x_star). Ci√≤ significa che il nuovo punto ha una probabilit√† a posteriori pi√π alta rispetto al punto precedente, o √® stato ‚Äúfortunato‚Äù nel processo di selezione casuale, consentendo all‚Äôalgoritmo di esplorare lo spazio dei parametri anche in zone di minore probabilit√†.\nSe il nuovo punto non viene accettato, la catena rimane nel punto precedente (x_prev), e questo punto viene nuovamente aggiunto all‚Äôarray dei campioni.\n\nSalvataggio del Campione: samples[i] = x_prev salva il punto corrente (che pu√≤ essere il nuovo punto accettato o il punto precedente se il nuovo punto √® stato rifiutato) nell‚Äôarray samples. Questo processo si ripete fino a quando non si raggiunge il numero desiderato di campioni.\n\nCome dati, usiamo il campione di 30 valori BDI-II ottenuti dai soggetti clinici esaminati da {cite}zetsche_2019future.\n\ny = np.array([\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n    41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n])\n\nProcediamo con l‚Äôesecuzione dell‚Äôalgoritmo di Metropolis.\n\nsamples = metropolis_for_normal(100_000, np.mean(y), y)\nsamples.shape\n\n(100000,)\n\n\n\n44.8.1 Calcolo dei Parametri del Posterior Analitico\nNel caso normale-normale, possiamo derivare analiticamente la distribuzione posteriore quando sia il prior che la likelihood sono distribuzioni normali. La bellezza di questo approccio sta nella forma chiusa del posterior, che √® anch‚Äôesso una distribuzione normale con parametri specifici facilmente calcolabili. Ecco come si fa:\n\nMedia Posteriore (\\(\\mu_{post}\\)): La media del posterior √® un peso tra la media del campione e la media del prior, dove i pesi sono determinati dalle varianze del prior e dei dati.\n\\[\n\\mu_{post} = \\frac{\\frac{\\mu_{prior}}{\\sigma_{prior}^2} + \\frac{\\sum y_i}{\\sigma_{data}^2}}{\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}}\n\\]\nVarianza Posteriore (\\(\\sigma_{post}^2\\)): La varianza del posterior √® determinata dalle varianze del prior e dei dati.\n\\[\n\\sigma_{post}^2 = \\left(\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}\\right)^{-1}\n\\]\n\nDove: - \\(\\mu_{prior}\\) √® la media del prior (in questo caso, 30), - \\(\\sigma_{prior}^2\\) √® la varianza del prior (\\(5^2\\) in questo caso), - \\(\\sigma_{data}^2\\) √® la varianza dei dati (calcolata dai dati), - \\(n\\) √® il numero di osservazioni, - \\(\\sum y_i\\) √® la somma delle osservazioni.\n\n\n44.8.2 Codice per il Grafico\nPer produrre il grafico con l‚Äôistogramma dei campioni dal posterior (usando l‚Äôalgoritmo di Metropolis) e la curva della distribuzione posteriore analitica, usiamo i parametri calcolati:\n\n# Parametri del prior\nmu_prior = 30\nstd_prior = 5\nvar_prior = std_prior ** 2\n\n# Dati osservati\nn = len(y)\nsum_y = np.sum(y)\nvar_data = np.var(y, ddof=1)  # ddof=1 for sample variance\n\n# Calcolo dei parametri posterior\nmu_post = (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post = 1 / (1 / var_prior + n / var_data)\nstd_post = np.sqrt(var_post)\n\n# Generazione dei punti x per il grafico\nx = np.linspace(mu_post - 4 * std_post, mu_post + 4 * std_post, 1000)\n\n# Istogramma dei campioni dal posterior\nplt.hist(samples[burnin:], bins=30, alpha=0.4, density=True, label=\"MCMC Samples Distribution\")\n\n# Curva della distribuzione posteriore analitica\nplt.plot(x, stats.norm.pdf(x, mu_post, std_post), \"C1\", label=\"Analytical Posterior Distribution\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice mostra come integrare l‚Äôanalisi MCMC con l‚Äôapproccio analitico per il caso normale-normale, offrendo sia una visualizzazione dei risultati del sampling che la conferma attraverso la soluzione analitica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/01_metropolis.html#commenti-e-considerazioni-finali",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "44.9 Commenti e considerazioni finali",
    "text": "44.9 Commenti e considerazioni finali\nIn generale, la distribuzione a posteriori dei parametri di un modello statistico non pu√≤ essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilit√† che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre pi√π semplice l‚Äôuso dei metodi MCMC, insieme all‚Äôincremento della potenza di calcolo dei computer, ha contribuito a rendere sempre pi√π popolare il metodo dell‚Äôinferenza bayesiana che, in questo modo, pu√≤ essere estesa a problemi di qualunque grado di complessit√†.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "44¬† Monte Carlo a Catena di Markov",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 15 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nsys        : 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:35:20) [Clang 16.0.6 ]\nmatplotlib : 3.8.4\narviz      : 0.18.0\nstatsmodels: 0.14.2\nscipy      : 1.13.1\nnumpy      : 1.26.4\nseaborn    : 0.13.2\npymc       : 5.15.1\npandas     : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, e Duncan Roweth. 1987. ¬´Hybrid monte carlo¬ª. Physics letters B 195 (2): 216‚Äì22.\n\n\nGeman, Stuart, e Donald Geman. 1984. ¬´Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images¬ª. IEEE Transactions on pattern analysis and machine intelligence 6: 721‚Äì41.\n\n\nHastings, W. Keith. 1970. ¬´Monte Carlo sampling methods using Markov chains and their applications¬ª. Biometrika 57 (1): 97‚Äì109.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ¬´The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.¬ª Journal of Machine Learning Research 15 (1): 1593‚Äì623.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, e Edward Teller. 1953. ¬´Equation of state calculations by fast computing machines¬ª. The Journal of Chemical Physics 21 (6): 1087‚Äì92.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html",
    "href": "chapters/mcmc/02_stan_beta_binomial.html",
    "title": "45¬† Linguaggio Stan",
    "section": "",
    "text": "45.1 Introduzione\nNel presente capitolo, presenteremo un linguaggio di programmazione probabilistica denominato Stan. Stan consente di estrarre campioni da distribuzioni di probabilit√† mediante la costruzione di una catena di Markov, la cui distribuzione di equilibrio (o stazionaria) coincide con la distribuzione desiderata. Il nome del linguaggio deriva da uno dei pionieri del metodo Monte Carlo, Stanislaw Ulam. Un‚Äôintroduzione dettagliata al linguaggio Stan √® fornita nell‚ÄôAppendice Q. In questo capitolo, utilizzeremo Stan per fare inferenza su una proporzione.\nIl linguaggio di programmazione probabilistica Stan √® compatibile con diverse piattaforme e offre varie interfacce (R, Python, Julia). In questo corso, useremo CmdStanPy, un‚Äôinterfaccia per Stan pensata per gli utenti di Python. CmdStanPy √® un pacchetto puramente in Python3 che √® un wrapper di CmdStan, l‚Äôinterfaccia a riga di comando per Stan scritta in C++. Pertanto, oltre a Python3, CmdStanPy richiede un toolchain C++ per compilare ed eseguire i modelli Stan.\nLa procedura per installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge √® descritta nel capitolo Appendice E.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#inferenza-bayesiana-e-metodi-mcmc",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#inferenza-bayesiana-e-metodi-mcmc",
    "title": "45¬† Linguaggio Stan",
    "section": "45.2 Inferenza Bayesiana e Metodi MCMC",
    "text": "45.2 Inferenza Bayesiana e Metodi MCMC\nL‚Äôinferenza bayesiana, impiegata per la stima dei parametri, la previsione e la valutazione della probabilit√† di eventi, si basa sulle aspettative a posteriori. Queste aspettative si configurano come integrali multidimensionali nello spazio dei parametri. Stan, un software all‚Äôavanguardia per l‚Äôanalisi statistica, si avvale del metodo Monte Carlo per risolvere questi integrali complessi. I metodi Monte Carlo sfruttano il campionamento casuale per affrontare integrali ad alta dimensionalit√†.\nTuttavia, per la maggior parte dei problemi bayesiani, non √® possibile utilizzare i metodi Monte Carlo standard, poich√© non √® fattibile generare campioni indipendenti dalla densit√† a posteriori di interesse, fatta eccezione per modelli estremamente semplici con prior coniugati. Di conseguenza, √® necessario ricorrere ai metodi Monte Carlo a Catena di Markov (MCMC), che producono campioni correlati tra loro. Stan implementa il Monte Carlo Hamiltoniano (HMC), il metodo MCMC pi√π efficiente e scalabile per le densit√† target. Altri metodi, come il Metropolis-Hastings e il campionamento di Gibbs, risultano pi√π semplici ma meno efficienti dell‚ÄôHMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "title": "45¬† Linguaggio Stan",
    "section": "45.3 Stan e la Programmazione Probabilistica",
    "text": "45.3 Stan e la Programmazione Probabilistica\nStan si configura come un linguaggio di programmazione probabilistica (PPL) concepito per definire modelli statistici complessi e effettuare inferenze su di essi. Un PPL consente di esprimere modelli probabilistici in modo conciso e di utilizzare algoritmi avanzati per l‚Äôinferenza. Ci√≤ risulta particolarmente utile nell‚Äôinferenza bayesiana, dove si aggiornano le distribuzioni a priori con dati osservati per ottenere distribuzioni a posteriori.\n\n45.3.1 Struttura di un Programma Stan\nUn programma Stan richiede la specificazione di variabili e parametri, definendo le distribuzioni a priori dei parametri del modello statistico e la funzione di verosimiglianza. In sostanza, un programma Stan descrive l‚Äôinterazione tra dati e parametri e le distribuzioni probabilistiche che li governano. Questo consente di effettuare inferenze sulle distribuzioni a posteriori dei parametri del modello, dedotte dai dati osservati e dalle distribuzioni a priori.\n\n\n45.3.2 Esecuzione di un Programma Stan\nUn programma Stan utilizza metodi di inferenza avanzati:\n\nCampionamento MCMC: Stan impiega metodi come il Monte Carlo a Catena di Markov per generare campioni dalle distribuzioni a posteriori.\nInferenza Variazionale: Un metodo approssimativo che fornisce stime delle distribuzioni a posteriori.\nApprossimazione di Laplace: Un ulteriore metodo approssimativo per l‚Äôinferenza.\n\nStan √® accessibile attraverso vari linguaggi di programmazione e strumenti di analisi open-source, tra cui Python, R e Julia, ed √® compatibile con gli strumenti di analisi bayesiana integrati in questi linguaggi. √à inoltre disponibile in ambienti come Mathematica, Stata e MATLAB, sebbene queste interfacce siano meno complete.\nStan genera dati attraverso procedure pseudo-casuali, applicabili sia per simulazioni in avanti che per risolvere il problema inverso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#simulazione-in-avanti",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#simulazione-in-avanti",
    "title": "45¬† Linguaggio Stan",
    "section": "45.4 Simulazione in Avanti",
    "text": "45.4 Simulazione in Avanti\nLa simulazione in avanti consiste nella generazione di dati simulati a partire da un insieme di parametri noti di un modello probabilistico. In altri termini, date determinate assunzioni sui parametri di un modello, si utilizza la simulazione in avanti per prevedere i possibili risultati.\nAd esempio, consideriamo uno studio clinico con \\(N\\) soggetti e una probabilit√† \\(\\theta\\) di esito positivo per ciascun soggetto. Conoscendo il valore di \\(\\theta\\) e il numero di soggetti \\(N\\), possiamo impiegare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci consente di generare dati che riflettono le nostre assunzioni sui parametri del modello.\nIn notazione statistica, questo si esprime come:\n\\[\nY \\sim \\text{Binomiale}(N, \\theta)\n\\]\ndove \\(Y\\) rappresenta il numero di esiti positivi su \\(N\\) pazienti, con probabilit√† \\(\\theta\\) di esito positivo per ciascun paziente.\n\n45.4.0.1 Esempio di Simulazione in Avanti\nSupponiamo di avere \\(N = 100\\) soggetti in uno studio clinico e un tasso di successo \\(\\theta = 0.3\\). Possiamo simulare un risultato \\(Y\\) generando casualmente il numero di soggetti con esito positivo. Utilizzando una distribuzione binomiale, possiamo calcolare la probabilit√† di ottenere esattamente \\(y\\) esiti positivi su \\(N\\) tentativi:\n\\[\np(Y = y \\mid N, \\theta) = \\binom{N}{y} \\cdot \\theta^y \\cdot (1 - \\theta)^{N - y}\n\\]\nQuesta espressione ci permette di calcolare la probabilit√† di ottenere un certo numero di successi, dato il numero di soggetti e la probabilit√† di successo.\n\n\n45.4.1 Un Primo Programma in Stan: Generazione di Dati Casuali\nSupponiamo di voler generare dei valori casuali \\(Y\\) da una distribuzione binomiale con parametri \\(N\\) e \\(\\theta\\). Ad esempio, possiamo impostare \\(\\theta = 0.3\\), per rappresentare una probabilit√† del 30% di un esito positivo (in statistica, il termine ‚Äòsuccesso‚Äô indica un esito positivo), e possiamo impostare \\(N = 100\\). Il seguente programma Stan pu√≤ essere utilizzato per generare valori di \\(Y\\) compresi tra 0 e 100.\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\n\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;\n  y = binomial_rng(N, theta);\n}\n\n\n45.4.2 Organizzazione di un Programma Stan\nLa prima cosa da notare √® che un programma Stan √® organizzato in blocchi. Qui abbiamo due blocchi: un blocco dei dati (data)contenente le dichiarazioni delle variabili che devono essere fornite come dati e un blocco delle quantit√† generate (generated quantities), che non solo dichiara variabili ma assegna loro un valore. In questo programma Stan, la variabile y viene assegnata come risultato di una singola estrazione da una distribuzione \\(\\textrm{binomiale}(N, \\theta)\\), che Stan fornisce attraverso la funzione binomial_rng.\n\n\n45.4.3 Tipi di Variabili in Stan\nLa seconda cosa da notare √® che tutte le variabili in un programma Stan sono dichiarate con tipi specifici. Stan utilizza la tipizzazione statica, il che significa che, a differenza di Python o R, il tipo di una variabile √® dichiarato nel programma prima del suo utilizzo, piuttosto che essere determinato al momento dell‚Äôesecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile non cambia mai.\nIl programma in esame dichiara tre variabili: N e y di tipo int (interi) e theta di tipo real (numeri reali). Nei computer, gli interi hanno limiti precisi e i numeri reali possono avere errori di calcolo. Stan utilizza numeri reali con precisione doppia (64 bit) secondo lo standard IEEE 754, tranne in alcune operazioni ottimizzate che possono perdere un po‚Äô di precisione.\n\n\n45.4.4 Vincoli sui Tipi\nUn tipo di variabile pu√≤ avere dei vincoli. Poich√© N √® un conteggio, deve essere maggiore o uguale a zero, cosa che indichiamo con il vincolo lower=0. Allo stesso modo, la variabile y, che rappresenta il numero di esiti positivi su N, deve essere compresa tra 0 e N (inclusi); questo √® indicato con il vincolo lower=0, upper=N. Infine, la variabile theta √® un numero reale e deve essere compresa tra 0 e 1, cosa che indichiamo con il vincolo lower=0, upper=1. Anche se tecnicamente i limiti per i numeri reali sono aperti, in pratica possiamo ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.\n\n\n45.4.5 Esecuzione del Programma Stan\nLa funzione cmdstan_model() crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan. In background, CmdStan traduce un programma Stan in C++ e creare un eseguibile compilato.\n\nmodel = CmdStanModel(stan_file='../../stan/binomial-rng.stan')\n\nDurante l‚Äôesecuzione, il programma Stan compilato richiede i valori di N e theta. Ad ogni iterazione, il programma campiona un valore di y utilizzando il suo generatore di numeri pseudocasuali integrato. I valori di N e theta devono essere forniti in un dizionario Python.\n\nN = 100\ntheta = 0.3\ndata = {\n    'N': N, \n    'theta': theta\n}\n\nInfine campioniamo dal modello utilizzando il metodo sample di CmdStanModel.\n\ntrace = model.sample(\n    data=data, \n    seed=123, \n    chains=1,\n    iter_sampling=30, \n    iter_warmup=1,\n    show_progress=False, \n    show_console=False\n)\n\n\n\n45.4.6 Costruzione del Modello\nIl costruttore di CmdStanModel viene utilizzato per creare un modello a partire da un programma Stan presente nel file specificato. Si consiglia vivamente di utilizzare un file separato per i programmi Stan. In pratica, il processo inizia con la traduzione del programma Stan in una classe C++ utilizzando un traduttore specifico. Successivamente, il programma C++ viene compilato.\n\n\n45.4.7 Interfaccia Python\nNell‚Äôinterfaccia Python, il metodo sample() accetta i seguenti argomenti:\n\ndata: i dati letti nel blocco dati del programma Stan,\nseed: generatore di numeri pseudocasuali per la riproducibilit√†,\nchains: il numero di simulazioni da eseguire (parallel_chains indica quante eseguire in parallelo),\niter_sampling: numero di estrazioni (cio√®, dimensione del campione) da restituire,\niter_warmup: numero di iterazioni di riscaldamento per tarare i parametri dell‚Äôalgoritmo di campionamento (non necessari qui, quindi impostato a 0),\nshow_progress: se True, stampa aggiornamenti di progresso,\nshow_console: apre un monitor di progresso GUI.\n\nIl risultato della chiamata a sample() sull‚Äôistanza del modello viene assegnato alla variabile trace e contiene le 10 estrazioni richieste con l‚Äôargomento iter_sampling = 30.\nQuando si chiama model.sample(...), CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell‚Äôargomento data di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poich√© il nostro programma Stan ha solo un blocco di quantit√† generate, l‚Äôunico compito rimanente della classe C++ √® generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da iter_sampling, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.\nLa generazione di numeri casuali √® determinata dal valore seed specificato nella chiamata.\n\n\n45.4.8 Estrazione dei Risultati\nUna volta completato il campionamento, possiamo estrarre il campione di 30 valori per la variabile scalare y sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.\n\ny = trace.stan_variable('y')\nprint(\"N =\", N, \";  theta =\", theta, \";  y(0:30) =\", *y.astype(int))\n\nN = 100 ;  theta = 0.3 ;  y(0:30) = 28 34 31 29 26 25 31 28 30 36 29 36 37 27 29 23 29 34 30 42 37 29 34 28 35 31 30 31 23 28",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#integrazione-monte-carlo",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#integrazione-monte-carlo",
    "title": "45¬† Linguaggio Stan",
    "section": "45.5 Integrazione Monte Carlo",
    "text": "45.5 Integrazione Monte Carlo\nIl calcolo bayesiano si basa sulla media delle incertezze nella stima dei parametri. In generale, ci√≤ implica il calcolo di aspettative, che sono medie ponderate con pesi dati dalle densit√† di probabilit√†. In questa sezione, introdurremo i metodi Monte Carlo per calcolare un semplice integrale che corrisponde all‚Äôaspettativa di una variabile indicatrice discreta. Utilizzeremo l‚Äôesempio classico del lancio di freccette su un bersaglio per stimare la costante matematica \\(\\pi\\) ‚Äì si veda l‚ÄôAppendice O.\n\n45.5.1 Metodi Monte Carlo a Catena di Markov\nNelle sezioni precedenti, abbiamo visto come generare un campione eseguendo una serie di estrazioni indipendenti e calcolare la media dei risultati per ottenere stime delle aspettative.\nNei moderni modelli bayesiani, raramente √® possibile generare estrazioni indipendenti dalle distribuzioni di interesse. Questo rende i semplici metodi Monte Carlo non applicabili. Solo in rari casi, con modelli molto semplici, √® possibile ottenere estrazioni indipendenti, ma questi casi sono limitati (Diaconis e Ylvisaker 1979). Prima della rivoluzione dei metodi Monte Carlo a catena di Markov (MCMC) negli anni ‚Äô90, l‚Äôinferenza bayesiana era per lo pi√π limitata a questi modelli semplici.\nL‚Äôintroduzione dei metodi MCMC ha rivoluzionato l‚Äôinferenza bayesiana. Questi metodi permettono di generare campioni da distribuzioni complesse dove non √® possibile ottenere estrazioni indipendenti. Tra questi, il metodo Hamiltonian Monte Carlo (HMC) √® particolarmente efficiente e scalabile, grazie all‚Äôuso della differenziazione automatica. HMC √® implementato in Stan e ha ampliato notevolmente la gamma di modelli che possono essere analizzati in tempi ragionevoli.\n\n\n45.5.2 Catene di Markov\nNei metodi Monte Carlo a catena di Markov, ogni estrazione dipende dall‚Äôestrazione precedente. Una sequenza di variabili casuali in cui ciascuna dipende solo dalla variabile precedente √® chiamata catena di Markov. In altre parole, una catena di Markov √® una sequenza di variabili casuali dove ogni variabile √® condizionatamente indipendente dalle precedenti, dato il valore della variabile immediatamente precedente.\nIn conclusione, i metodi Monte Carlo a catena di Markov, come l‚ÄôHamiltonian Monte Carlo, hanno ampliato notevolmente le capacit√† dell‚Äôinferenza bayesiana, permettendo di affrontare modelli complessi che non possono essere analizzati con semplici estrazioni indipendenti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#il-problema-inverso",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#il-problema-inverso",
    "title": "45¬† Linguaggio Stan",
    "section": "45.6 Il Problema Inverso",
    "text": "45.6 Il Problema Inverso\nIl problema inverso consiste nella stima dei parametri del modello, come la probabilit√† di successo \\(\\theta\\), dato un insieme di dati osservati. Supponiamo di avere i seguenti dati: \\(N = 100\\) soggetti e \\(y = 32\\) esiti positivi. L‚Äôobiettivo √® stimare \\(\\theta\\), la probabilit√† di successo.\nNell‚Äôapproccio bayesiano, si inizia specificando una distribuzione a priori per \\(\\theta\\). Supponiamo di utilizzare una distribuzione Beta(\\(\\alpha\\), \\(\\beta\\)) come prior per \\(\\theta\\), dove \\(\\alpha\\) e \\(\\beta\\) sono parametri scelti in base alle conoscenze precedenti. La distribuzione a posteriori di \\(\\theta\\) data l‚Äôosservazione \\(y\\) √® ancora una distribuzione Beta, ma con parametri aggiornati:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + N - y)\n\\]\nAd esempio, scegliendo una distribuzione a priori non informativa con \\(\\alpha = 1\\) e \\(\\beta = 1\\), la distribuzione a posteriori diventa:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(1 + 32, 1 + 100 - 32) = \\text{Beta}(33, 69)\n\\]\nQuesta distribuzione a posteriori fornisce una stima aggiornata della probabilit√† di successo \\(\\theta\\) considerando i dati osservati. Utilizzando Stan, √® possibile ottenere campioni da questa distribuzione a posteriori per calcolare statistiche riassuntive e effettuare previsioni.\nIn sintesi, la simulazione in avanti e il problema inverso rappresentano due approcci complementari: la simulazione in avanti genera dati simulati da parametri noti, mentre il problema inverso stima i parametri del modello dai dati osservati.\nQuando si dispone di un modello che genera dati a partire dai parametri, il problema inverso consiste nell‚Äôinferire i valori dei parametri dai dati osservati. Questo tipo di problema richiede di ragionare a ritroso dalle osservazioni, attraverso il modello di misurazione e il modello diretto, per stimare parametri come, ad esempio, la probabilit√† di successo. La risoluzione dei problemi inversi √® uno degli ambiti in cui le statistiche bayesiane eccellono.\n\n45.6.1 Storia e Applicazione\nUn decennio dopo la pubblicazione della regola di Bayes, Laplace utilizz√≤ la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori. In questa sezione, analizzeremo il problema di Laplace utilizzando Stan.\nLaplace raccolse dati sul sesso dei bambini nati vivi a Parigi tra il 1745 e il 1770:\n\n\n\nSesso\nNascite vive\n\n\n\n\nFemmina\n105.287\n\n\nMaschio\n110.312\n\n\n\nLaplace si chiese se, sulla base di questi dati, la probabilit√† di nascita dei maschi fosse superiore a quella delle femmine.\n\n\n45.6.2 Modello di Laplace\nLaplace adott√≤ la seguente distribuzione campionaria per modellare il numero di maschi nati su un totale di \\(N\\) nascite:\n\\[\ny \\sim \\text{binomiale}(N, \\theta),\n\\]\ndove \\(N\\) √® il numero totale di nascite, \\(\\theta\\) √® la probabilit√† di nascita di un maschio e \\(y\\) √® il numero di nascite maschili.\n\n\n45.6.3 Distribuzione a Priori\nLaplace utilizz√≤ la seguente distribuzione a priori per \\(\\theta\\):\n\\[\n\\theta \\sim \\text{beta}(1, 1),\n\\]\ndove la distribuzione \\(\\text{beta}(1, 1)\\) √® uniforme sull‚Äôintervallo \\(\\theta \\in (0, 1)\\) poich√© la densit√† √® proporzionale a una costante:\n\\[\n\\text{beta}(\\theta \\mid 1, 1) \\propto \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} = 1.\n\\]\n\n\n45.6.4 Distribuzione a Posteriori\nIl modello di Laplace √® abbastanza semplice da permettere una soluzione analitica della distribuzione a posteriori:\n\\[\n\\begin{aligned}\n    p(\\theta \\mid y, N) &\\propto p(y \\mid N, \\theta) \\cdot p(\\theta) \\\\\n    &= \\text{binomiale}(y \\mid N, \\theta) \\cdot \\text{beta}(\\theta \\mid 1, 1) \\\\\n    &\\propto \\theta^y \\cdot (1 - \\theta)^{N - y} \\cdot \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} \\\\\n    &= \\theta^{y} \\cdot (1 - \\theta)^{N - y} \\\\\n    &\\propto \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\end{aligned}\n\\]\nQuindi, possiamo concludere che:\n\\[\np(\\theta \\mid y, N) = \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\]\n\n\n45.6.5 Implementazione in Stan\nA differenza del primo modello Stan che abbiamo visto, che generava solo dati, il seguente programma Stan richiede che vengano forniti dati, specificamente il numero di nascite maschili (\\(y\\)) e il numero totale di nascite (\\(N\\)). Il modello ci permetter√† di stimare la probabilit√† di nascita di un maschio (\\(\\theta\\)) e la probabilit√† che nascano pi√π maschi che femmine (\\(\\theta &gt; 0.5\\)).\nEcco come possiamo specificare il modello Stan:\n\nstan_file = os.path.join(project_directory, 'stan', 'sex-ratio.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che sia il numero totale di nascite (\\(N\\)) sia il numero di nascite maschili (\\(y\\)) sono forniti come dati. Poi ci sono due blocchi aggiuntivi: un blocco dei parametri, usato per dichiarare valori sconosciuti (qui, solo il tasso di nascite maschili \\(\\theta\\)), e un blocco del modello, dove specifichiamo la distribuzione a priori e la verosimiglianza. La distribuzione a posteriori viene calcolata da Stan combinando queste due componenti. Inoltre, c‚Äô√® un blocco delle quantit√† generate dove viene calcolata una variabile booleana che indica se la probabilit√† di nascita dei maschi \\(\\theta\\) √® maggiore di 0.5.\nIl modello di Laplace e la sua implementazione in Stan ci permettono di affrontare il problema inverso delle nascite, inferendo la probabilit√† di nascita di un maschio dai dati osservati. Utilizzando le tecniche bayesiane, possiamo stimare non solo la probabilit√† di nascita di un maschio, ma anche la probabilit√† che nascano pi√π maschi che femmine.\n\n\n45.6.6 Campionare dalla Distribuzione a Posteriori\nQuando eseguiamo un programma Stan, esso genera una serie di campioni casuali che approssimano la distribuzione a posteriori. Con il proseguire delle estrazioni, questi campioni tendono a diventare sempre pi√π simili a veri campioni della distribuzione a posteriori, fino a diventare numericamente indistinguibili da essa.\nStan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che pu√≤ introdurre autocorrelazione nei campioni della distribuzione a posteriori. In altre parole, i campioni non sono indipendenti tra loro, ma ogni campione √® correlato (o anti-correlato) con il campione precedente.\nL‚Äôautocorrelazione non introduce bias nelle stime Monte Carlo, ma i campioni positivamente autocorrelati, che si osservano nei modelli pi√π complessi, aumentano la varianza delle stime rispetto ai campioni indipendenti. Questo incremento della varianza aumenta l‚Äôerrore quadratico medio atteso, che √® una combinazione di errore dovuto al bias (qui nullo) e alla varianza. Al contrario, nei modelli molto semplici, l‚Äôautocorrelazione negativa riduce la varianza rispetto ai campioni indipendenti, riducendo quindi l‚Äôerrore quadratico medio atteso.\nPer affrontare problemi ad alta dimensionalit√†, Duane et al.¬†(1987) hanno introdotto l‚Äôalgoritmo Hamiltonian Monte Carlo (HMC) che migliora l‚Äôefficienza del campionamento. Per Stan, Hoffman e Gelman (2014) hanno sviluppato una versione adattiva dell‚ÄôHMC chiamata No-U-Turn Sampler (NUTS), successivamente migliorata da Betancourt (2017a). NUTS pu√≤ essere estremamente efficiente, generando campioni anti-correlati che possono portare a stime Monte Carlo pi√π precise rispetto ai campioni indipendenti.\n\n\n45.6.7 Compilazione del Codice Stan\nPer utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato model.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nInseriamo i dati in un dizionario.\n\nboys = 110312\ngirls = 105287\n\ndata = {\n    'N': boys + girls, \n    'y': boys,\n    \"alpha_prior\" : 1,\n    \"beta_prior\" : 1\n    }\n\nprint(data)\n\n{'N': 215599, 'y': 110312, 'alpha_prior': 1, 'beta_prior': 1}\n\n\nEseguiamo il campionamento MCMC con la seguente chiamata.\n\nsample = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 10_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\nIl metodo $sample() viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato model.\nAvendo assunto una distribuzione a priori per il parametro \\(\\theta\\), l‚Äôalgoritmo procede in maniera ciclica, aggiornando la distribuzione a priori di \\(\\theta\\) condizionandola ai valori gi√† generati. Dopo un certo numero di iterazioni, l‚Äôalgoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di \\(\\theta\\).\nAll‚Äôinizio del campionamento, la distribuzione dei campioni pu√≤ essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale √® chiamato ‚Äúburn-in‚Äù. Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e sono tipicamente scartati. Man mano che il numero di iterazioni aumenta, la distribuzione dei campioni si avvicina sempre pi√π alla distribuzione target.\nDopo aver eseguito il modello in Stan, otteniamo una serie di campioni \\(\\theta^{(m)}\\) dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\). Ogni campione rappresenta un possibile valore di \\(\\theta\\) compatibile con i dati osservati \\(y\\). Procediamo quindi a estrarre i campioni a posteriori per le variabili theta e boys_gt_girls.\n\ntheta_draws = sample.stan_variable('theta')\nboys_gt_girls_draws = sample.stan_variable('boys_gt_girls')\n\nTracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di \\(\\theta\\) sono pi√π probabili e comprendere meglio la forma della distribuzione a posteriori. L‚Äôistogramma ci fornisce diverse informazioni:\n\nValore pi√π probabile di \\(\\theta\\): Questo √® il valore intorno al quale i campioni sono pi√π concentrati, noto come la moda della distribuzione.\nDistribuzione dei possibili valori di \\(\\theta\\): Questo ci d√† un‚Äôidea dell‚Äôincertezza nella stima di \\(\\theta\\).\n\nSe l‚Äôistogramma √® stretto e concentrato attorno a un valore specifico, significa che c‚Äô√® poca incertezza nella stima di \\(\\theta\\). In altre parole, possiamo essere abbastanza sicuri che il valore vero di \\(\\theta\\) sia vicino a questo valore.\nSe l‚Äôistogramma √® largo e distribuito, significa che c‚Äô√® maggiore incertezza nella stima di \\(\\theta\\). Questo indica che i dati osservati non forniscono una stima precisa e che il valore di \\(\\theta\\) potrebbe variare notevolmente.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    theta_draws,\n    bins=30,\n    alpha=0.5,\n    color=color_fill,\n    edgecolor=color_edge,\n    density=True,\n)\nplt.title('Istogramma della distribizione a posteriori di theta')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\nplt.show()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "title": "45¬† Linguaggio Stan",
    "section": "45.7 Stime Puntuali Bayesiane",
    "text": "45.7 Stime Puntuali Bayesiane\nIn termini bayesiani, una stima puntuale per un parametro \\(\\Theta\\) condizionato sui dati osservati \\(Y = y\\) √® un singolo valore \\(\\hat{\\theta} \\in \\mathbb{R}^D\\) che riassume la distribuzione a posteriori \\(p(\\theta \\mid y)\\). La notazione \\(\\hat{\\theta}\\) √® convenzionale nella statistica per indicare una stima di un parametro \\(\\theta\\). In questa sezione definiamo tre stimatori e discutiamo come i due stimatori bayesiani minimizzino una funzione di perdita tra il valore vero e la stima. Torneremo alla funzione di perdita e alle propriet√† degli stimatori dopo averli definiti.\n\n45.7.1 Stimatore della Media Posteriori\nLa stima puntuale bayesiana pi√π comune per un parametro √® la media posteriori,\n\\[\n\\begin{align}\n\\widehat{\\theta}\n&= \\mathbb{E}[\\Theta \\mid Y = y] \\\\\n&= \\int_{\\Theta} \\theta \\cdot p(\\theta \\mid y) \\, \\textrm{d}\\theta \\\\\n&= \\lim_{M \\rightarrow \\infty} \\, \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)} \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)},\n\\end{align}\n\\]\ndove nelle ultime due righe, ogni estrazione √® distribuita approssimativamente secondo la distribuzione a posteriori,\n\\[\n\\theta^{(m)} \\sim p(\\theta \\mid y).\n\\]\nAbbiamo introdotto la notazione di aspettativa condizionale nella prima riga di questa definizione. Le aspettative sono semplicemente medie ponderate, con i pesi dati da una densit√† di probabilit√†. L‚Äôinferenza bayesiana coinvolge aspettative sulla distribuzione a posteriori, la cui notazione concisa √® quella dell‚Äôaspettativa condizionale,\n\\[\n\\mathbb{E}\\!\n\\left[ f(\\Theta) \\mid Y = y \\right]\n= \\int_{\\mathbb{R^N}} f(\\theta) \\cdot p_{\\Theta \\mid Y}(\\theta \\mid y) \\, \\textrm{d}\\theta,\n\\]\ndove \\(\\Theta\\) e \\(Y\\) sono variabili casuali, mentre \\(\\theta\\) e \\(y\\) sono variabili vincolate ordinarie.\nPer il modello di Laplace, la stima per il tasso di nascite maschili \\(\\theta\\) condizionata sui dati di nascita \\(y\\) √® calcolata come la media campionaria delle estrazioni per theta.\n\ntheta_hat = np.mean(theta_draws)\nprint(f\"estimated theta = {theta_hat:.3f}\")\n\nestimated theta = 0.512\n\n\n\n\n45.7.2 Stimatore della Mediana Posteriori, Quantili e Intervalli\nUn‚Äôalternativa popolare alla stima puntuale bayesiana √® la mediana posteriori, \\(\\theta^+\\). La mediana √® il valore tale che, per ogni dimensione \\(d \\in 1{:}D\\),\n\\[\n\\Pr[\\Theta_d \\leq \\theta^+_d] = \\frac{1}{2}.\n\\]\nIn altre parole, la mediana √® il valore che divide la distribuzione a posteriori in due parti uguali: il 50% dei campioni √® al di sotto della mediana e il 50% √® al di sopra. La mediana posteriori pu√≤ essere calcolata prendendo la mediana dei campioni dalla distribuzione a posteriori.\nEcco come calcolare la mediana posteriori utilizzando Python:\n\ntheta_plus = np.median(theta_draws)\nprint(f\"estimated (median) theta = {theta_plus:.3f}\")\n\nestimated (median) theta = 0.512\n\n\nPoich√© la distribuzione a posteriori per i dati di Laplace √® quasi simmetrica, la media posteriori e la mediana posteriori sono molto simili.\n\n\n45.7.3 Quantili e Intervalli di Credibilit√†\nOltre alla mediana, possiamo anche calcolare i quantili e gli intervalli di credibilit√† per fornire ulteriori informazioni sulla distribuzione a posteriori. I quantili sono valori che dividono la distribuzione in intervalli con una probabilit√† specificata. Gli intervalli di credibilit√† indicano l‚Äôintervallo entro il quale cade una certa percentuale della distribuzione a posteriori.\n\n45.7.3.1 Quantili\nAd esempio, se vogliamo calcolare il quantile al 95% della distribuzione a posteriori, possiamo semplicemente prendere il valore che si trova al 95¬∞ percentile nella sequenza ordinata dei campioni. Di seguito sono riportati i quantili al 5% e al 95% della distribuzione a posteriori di Laplace, calcolati utilizzando i quantili empirici.\n\nquantile_05 = np.quantile(theta_draws, 0.05)\nquantile_95 = np.quantile(theta_draws, 0.95)\nprint(f\"\"\"0.05 quantile = {quantile_05:.3f};\n0.95 quantile = {quantile_95:.3f}\"\"\")\n\n0.05 quantile = 0.510;\n0.95 quantile = 0.513\n\n\n\n\n45.7.3.2 Intervalli Posteriori\nInsieme, il quantile al 5% e al 95% ci forniscono i limiti del nostro intervallo di probabilit√† centrale al 90%. Questo intervallo √® definito come l‚Äôintervallo che contiene il 90% della massa di probabilit√† a posteriori, con il 5% della massa rimanente al di sotto dell‚Äôintervallo e il 5% al di sopra.\n\n\n\n45.7.4 Errore di Stima e Bias\nL‚Äôerrore di una stima √® la differenza tra la stima stessa e il valore vero del parametro,\n\\[\n\\textrm{err} = \\hat{\\theta} - \\theta.\n\\]\nLa nostra stima \\(\\hat{\\theta}\\) √® implicitamente una funzione dei dati \\(y\\), quindi anche l‚Äôerrore dipende dai dati. Possiamo rendere esplicita questa dipendenza scrivendo\n\\[\n\\text{err}(y) = \\hat{\\theta}(y) - \\theta.\n\\]\nIl bias di uno stimatore √® definito come l‚Äôerrore atteso, cio√® la media dell‚Äôerrore rispetto alla distribuzione dei dati per la variabile casuale \\(Y\\),\n\\[\n\\begin{align}\n\\text{bias}\n&= \\mathbb{E}[\\text{err}(Y)] \\\\\n&= \\mathbb{E}[\\hat{\\theta}(Y) - \\theta] \\\\\n&= \\int_Y (\\hat{\\theta}(y) - \\theta) \\, \\text{d}y.\n\\end{align}\n\\]\nIn altre parole, il bias misura quanto, in media, la stima \\(\\hat{\\theta}\\) si discosta dal valore vero \\(\\theta\\) considerando tutte le possibili realizzazioni dei dati \\(Y\\). Un bias nullo indica che lo stimatore √® corretto in media, cio√® non tende a sovrastimare o sottostimare il valore vero del parametro.\n\n\n45.7.5 Stimatore della Moda Posteriori\nUno stimatore popolare, sebbene non strettamente bayesiano, √® la moda a posteriori, che rappresenta il valore del parametro \\(\\theta\\) per cui la densit√† a posteriori √® massima. Formalmente, √® definita come:\n\\[\n\\theta^* = \\text{arg max}_\\theta \\ p(\\theta \\mid y).\n\\]\nLa stima \\(\\theta^*\\) √® spesso chiamata stima MAP (Maximum A Posteriori). La moda a posteriori non √® considerata un vero stimatore bayesiano perch√© non tiene conto dell‚Äôincertezza nella stessa misura in cui lo fanno altri metodi bayesiani. In altre parole, non minimizza una funzione di perdita basata sui valori veri dei parametri, ma cerca semplicemente il valore pi√π probabile dato i dati osservati.\n\n\n45.7.6 Caratteristiche della Moda Posteriori\n\nNon considera l‚Äôincertezza: La stima MAP si focalizza solo sul valore pi√π probabile della distribuzione a posteriori, senza tenere conto della variabilit√† dei dati.\nMassimo della densit√† a posteriori: La moda a posteriori rappresenta il punto in cui la densit√† a posteriori raggiunge il suo massimo.\nPossibili limitazioni: La stima MAP potrebbe non esistere in alcuni casi, come nei modelli in cui la densit√† cresce senza limiti. Questo pu√≤ accadere, ad esempio, nei modelli bayesiani gerarchici o in distribuzioni semplici come la distribuzione esponenziale con parametro 1 (\\(\\textrm{esponenziale}(1)\\)).\n\n\n\n45.7.7 Funzioni di Perdita e Propriet√† degli Stimatori\nLa media a posteriori √® uno stimatore bayesiano popolare per due ragioni principali. Primo, √® uno stimatore non distorto, il che significa che ha un bias nullo. Secondo, ha l‚Äôerrore quadratico medio atteso minimo tra tutti gli stimatori non distorti. L‚Äôerrore quadratico di una stima √® definito come:\n\\[\n\\text{err}^2(y) = \\left(\\hat{\\theta}(y) - \\theta\\right)^2.\n\\]\nQuesta √® una funzione di perdita, che misura la differenza tra una stima \\(\\hat{\\theta}\\) e il valore vero \\(\\theta\\). Tuttavia, la media a posteriori potrebbe non esistere se la distribuzione a posteriori ha code molto ampie, come accade nella distribuzione di Cauchy standard.\n\n\n45.7.8 Propriet√† della Mediana Posteriori\nLa mediana a posteriori \\(\\theta^+\\) ha tre propriet√† interessanti:\n\nSempre ben definita: La mediana a posteriori √® sempre ben definita, anche per densit√† con poli o code molto ampie.\nMinimizzazione dell‚Äôerrore assoluto atteso: La mediana minimizza l‚Äôerrore assoluto atteso, il che la rende robusta.\nRobustezza ai valori anomali: La mediana √® meno sensibile ai valori anomali rispetto alla media, perch√© minimizza l‚Äôerrore assoluto anzich√© l‚Äôerrore quadrato.\n\n\n\n45.7.9 Concentrazione sulle Medie a Posteriori\nIn questa introduzione a Stan, ci concentreremo principalmente sulle medie a posteriori. La media a posteriori non solo fornisce una stima non distorta, ma minimizza anche l‚Äôerrore quadratico medio atteso, rendendola uno strumento potente per l‚Äôinferenza bayesiana. Tuttavia, √® importante essere consapevoli delle sue limitazioni, specialmente in presenza di distribuzioni a posteriori con code molto ampie.\n\n\n45.7.10 Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo\nQuando utilizziamo un campionatore di catene di Markov per stimare parametri, otteniamo una sequenza di campioni casuali. Questa sequenza √® essa stessa una variabile casuale, perch√© √® composta da molte variabili casuali. A causa di questa natura casuale, ogni esecuzione del campionatore pu√≤ produrre risultati leggermente diversi, introducendo quello che √® noto come errore Monte Carlo.\nL‚Äôerrore Monte Carlo √® l‚Äôerrore introdotto dal fatto che utilizziamo solo un numero finito di campioni ($ M $) per stimare i parametri. Questo tipo di errore si verifica perch√©, con un numero limitato di campioni, non possiamo catturare perfettamente l‚Äôintera distribuzione a posteriori.\n\n45.7.10.1 Errore Standard di Monte Carlo (MCMC)\nStan riporta l‚Äôerrore standard di Monte Carlo (MCMC) insieme alle stime della media. L‚Äôerrore standard MCMC per un parametro scalare $ _d $ √® definito come:\n\\[\n\\text{mcmc-se} = \\frac{\\textrm{sd}[\\Theta_d \\mid Y = y]}{\\sqrt{N^{\\text{eff}}}},\n\\]\ndove: - \\(\\text{sd}[\\Theta_d \\mid Y = y]\\) √® la deviazione standard del parametro $ _d $ nella distribuzione a posteriori. - \\(N^{\\text{eff}}\\) √® la dimensione del campione effettivo, che riflette il numero di campioni indipendenti equivalenti ottenuti dal campionatore.\n\n\n45.7.10.2 Dimensione del Campione Effettivo\nNel classico teorema del limite centrale, la dimensione del campione (numero di estrazioni indipendenti) appare al posto di \\(N^{\\text{eff}}\\). Tuttavia, nel contesto delle catene di Markov, i campioni successivi sono correlati tra loro. La dimensione del campione effettivo (\\(N^{\\text{eff}}\\)) tiene conto di questa correlazione e rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle nostre estrazioni correlate.\nLa dimensione del campione effettivo per un campione di dimensione $ M $ √® definita come:\n\\[\nN^{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(\\text{IAT}\\) √® il tempo di autocorrelazione integrata. Sebbene non sia definito formalmente qui, pu√≤ essere considerato come l‚Äôintervallo tra estrazioni effettivamente indipendenti nella nostra catena di Markov. Se l‚Äôautocorrelazione √® bassa, \\(\\text{IAT}\\) sar√† vicino a 1; se l‚Äôautocorrelazione √® alta, \\(\\text{IAT}\\) sar√† molto pi√π alto.\nIn sintesi, \\(N^{\\text{eff}}\\) rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle estrazioni correlate della nostra catena di Markov.\nIn conclusione, l‚Äôerrore standard di Monte Carlo (MCMC) fornisce una misura di quanto varierebbero le nostre stime se ripetessimo il processo di campionamento pi√π volte. √à un indicatore dell‚Äôaffidabilit√† delle nostre stime, tenendo conto della casualit√† introdotta dall‚Äôutilizzo di un numero finito di campioni. Conoscere questo errore ci aiuta a valutare la precisione delle nostre stime e a comprendere meglio l‚Äôincertezza associata ai risultati ottenuti tramite il campionamento di catene di Markov.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "title": "45¬† Linguaggio Stan",
    "section": "45.8 Stima delle Probabilit√† di Evento",
    "text": "45.8 Stima delle Probabilit√† di Evento\nLaplace non cercava semplicemente un valore specifico per \\(\\theta\\). Voleva sapere qual era la probabilit√† che \\(\\theta\\) fosse maggiore di \\(\\frac{1}{2}\\) dopo aver osservato \\(y\\) nascite maschili su un totale di \\(N\\) nascite. In termini di teoria della probabilit√†, voleva stimare la probabilit√† di un evento.\nUn sottoinsieme di parametri √® noto come evento. Possiamo convertire le condizioni sui parametri in eventi. Ad esempio, la condizione \\(\\theta &gt; \\frac{1}{2}\\) pu√≤ essere espressa come l‚Äôevento:\n\\[ A = \\left\\{ \\theta \\in \\Theta : \\theta &gt; \\frac{1}{2} \\right\\}. \\]\nData una misura di probabilit√†, la probabilit√† dell‚Äôevento \\(A\\), ossia che il tasso di nascite maschili sia superiore a quello delle nascite femminili, sar√† ben definita. Poich√© possiamo convertire le condizioni in eventi, possiamo trattarle come tali. Questo ci permette di scrivere \\(\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\, \\big| \\, N, y\\right]\\) per indicare la probabilit√† dell‚Äôevento \\(\\Theta &gt; \\frac{1}{2}\\).\n\n45.8.1 Probabilit√† di Evento tramite Indicatori\nLa funzione indicatrice \\(\\textrm{I}\\) assegna il valore 1 alle proposizioni vere e 0 a quelle false. Ad esempio, \\(\\textrm{I}(\\theta &gt; \\frac{1}{2}) = 1\\) se la proposizione \\(\\theta &gt; \\frac{1}{2}\\) √® vera, cio√® quando \\(\\theta\\) √® maggiore di un mezzo.\nLe probabilit√† di evento sono definite come aspettative condizionali posteriori delle funzioni indicatrici per eventi:\n\\[\n\\begin{align}\n\\Pr[\\Theta &gt; 0.5 \\mid N, y]\n&= \\mathbb{E}\\!\\left[\\textrm{I}[\\Theta &gt; 0.5] \\mid N, y\\right] \\\\\n&= \\int_{\\Theta} \\textrm{I}(\\theta &gt; 0.5) \\cdot p(\\theta \\mid N, y) \\, \\textrm{d}\\theta \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\textrm{I}(\\theta^{(m)} &gt; 0.5),\n\\end{align}\n\\]\ndove \\(\\theta^{(m)}\\) rappresenta i campioni dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\) per \\(m = 1, 2, \\ldots, M\\).\n\n\n45.8.2 Eventi come Indicatori in Stan\nIn Stan, possiamo codificare direttamente il valore della funzione indicatrice e assegnarlo a una variabile nel blocco delle quantit√† generate.\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\nLe espressioni condizionali come theta &gt; 0.5 assumono il valore 1 se sono vere e 0 se sono false. In notazione matematica, scriveremmo \\(\\textrm{I}(\\theta &gt; 0.5)\\), che assume valore 1 se \\(\\theta &gt; 0.5\\) e 0 altrimenti. In Stan, come in C++, trattiamo &gt; come un operatore binario che restituisce 0 o 1, quindi scriviamo semplicemente theta &gt; 0.5.\n\n\n45.8.3 La Risposta alla Domanda di Laplace\nLa media a posteriori della variabile boys_gt_girls √® quindi la nostra stima per \\(\\Pr[\\theta &gt; 0.5 \\mid N, y]\\). √à essenzialmente 1. Stampando a 15 cifre decimali, vediamo\n\nPr_boy_gt_girl = np.mean(boys_gt_girls_draws)\nprint(f\"estimated Pr[boy more likely] = {Pr_boy_gt_girl:.15f}\")\n\nestimated Pr[boy more likely] = 1.000000000000000\n\n\nCome possiamo vedere di seguito, tutti i nostri campioni per \\(\\theta\\) sono maggiori di \\(\\frac{1}{2}\\), ovvero boys_gt_girls_draws √® sempre uguale a 1:\n\nnp.unique(boys_gt_girls_draws)\n\narray([1.])\n\n\nIl valore 1 restituito come stima solleva l‚Äôimportante problema della precisione numerica. Laplace calcol√≤ il risultato analiticamente, che √®\n\\[\n\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\ \\bigg| \\ N, y\\right] \\approx 1 - 10^{-27}.\n\\]\nQuindi avremmo bisogno di un numero astronomico di campioni a posteriori prima di generare un valore di \\(\\theta\\) inferiore a \\(\\frac{1}{2}\\). Come detto, la risposta di 1.0 √® molto vicina alla risposta vera e ben entro il nostro errore Monte Carlo atteso.\n\n\n45.8.4 Statistiche di riepilogo MCMC da Stan\nCon Stan, possiamo ottenere un riepilogo completo della variabile \\(\\theta\\) nella distribuzione a posteriori. Per fare ci√≤, basta chiamare la funzione .summary() sul campione. Questo riepilogo include tutte le statistiche rilevanti.\n\nsample.summary(sig_figs = 3)\n\n\n\n\n\n\n\n\n\nMean\nMCSE\nStdDev\n5%\n50%\n95%\nN_Eff\nN_Eff/s\nR_hat\n\n\n\n\nlp__\n-149000.000\n0.004770\n6.720000e-01\n-149000.00\n-149000.000\n-149000.000\n19800.0\n51300.0\n1.0\n\n\ntheta\n0.512\n0.000009\n1.090000e-03\n0.51\n0.512\n0.513\n13700.0\n35400.0\n1.0\n\n\nboys_gt_girls\n1.000\nNaN\n9.380000e-14\n1.00\n1.000\n1.000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nL‚Äôistruzione print(sample.diagnose()) in Stan viene utilizzata per eseguire una diagnosi completa del campionamento MCMC. Questa funzione fornisce una serie di statistiche diagnostiche che aiutano a valutare la qualit√† e la convergenza del campionamento.\nQuesti sono alcuni degli aspetti che possono essere diagnosticati:\n\nConvergenza: La diagnosi verifica se le catene di Markov sono convergenti, ad esempio controllando il valore di \\(\\hat{R}\\). Un valore di \\(\\hat{R}\\) vicino a 1 indica che le catene sono ben mescolate e convergenti.\nAutocorrelazione: Fornisce informazioni sull‚Äôautocorrelazione delle catene, che pu√≤ influire sull‚Äôefficienza del campionamento. Bassa autocorrelazione √® desiderabile per ottenere campioni indipendenti.\nEfficienza del campionamento: Viene calcolata la dimensione del campione effettivo (\\(N_{\\text{eff}}\\)), che indica quanti campioni indipendenti equivarrebbero ai campioni correlati ottenuti.\nVarianza e Deviazione Standard: Viene riportata la varianza e la deviazione standard dei campioni, aiutando a comprendere la distribuzione a posteriori del parametro.\n\n\nprint(sample.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp2f8ucg3j/sex-ratioils7kx9j/sex-ratio-20240725102513_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nUn grafico con le tracce si ottiene nel modo seguente:\n\n_ = az.plot_trace(sample, var_names=(\"theta\"), combined=False)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#riscaldamento",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#riscaldamento",
    "title": "45¬† Linguaggio Stan",
    "section": "46.1 Riscaldamento",
    "text": "46.1 Riscaldamento\nDurante le fasi iniziali di riscaldamento, Stan cerca di trovare la regione di alta probabilit√† da cui campionare, adattare una buona dimensione del passo e stimare la varianza a posteriori. La varianza stimata viene utilizzata per migliorare l‚Äôefficienza del campionatore, un processo chiamato ‚Äúprecondizionamento‚Äù. Precondizionare significa ridimensionare i parametri per rendere il campionamento pi√π efficiente.\nStan pu√≤ anche stimare una matrice di covarianza completa, che rappresenta le relazioni tra tutti i parametri. Utilizzando questa matrice, Stan pu√≤ effettuare rotazioni e ridimensionamenti dei parametri per campionare in modo pi√π efficace. In questo contesto, ‚Äúrotazione e scalatura‚Äù si riferiscono alla trasformazione dei parametri in una nuova base (rotazione) e alla regolazione delle loro scale (scalatura) per facilitare il campionamento, rendendolo pi√π rapido e affidabile. Per ulteriori dettagli su questi processi, si pu√≤ fare riferimento a Neal (2011).\nIl riscaldamento converge quando la dimensione del passo e le stime della covarianza a posteriori diventano stabili. Con pi√π catene, √® possibile verificare che tutte convergano verso una dimensione del passo e una stima della covarianza simili. A meno che non ci siano problemi, generalmente non misuriamo la convergenza dell‚Äôadattamento, ma piuttosto se otteniamo campioni a posteriori ragionevoli dopo il riscaldamento.\nDurante la fase di riscaldamento, Stan non produce una catena di Markov coerente perch√© utilizza la memoria per adattarsi alle condizioni del modello. Questo adattamento serve a trovare i migliori parametri di campionamento. Tuttavia, una volta terminato il riscaldamento e iniziata la fase di campionamento, Stan inizia a produrre una vera e propria catena di Markov.\nLe nostre analisi a posteriori si baseranno esclusivamente sui campioni generati durante questa fase di campionamento, non sui campioni raccolti durante il riscaldamento. √à comunque possibile salvare ed esaminare i campioni del riscaldamento per comprendere meglio come il processo di adattamento √® avvenuto e se ci sono stati problemi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#riduzione-potenziale-della-scala-e-widehatr",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#riduzione-potenziale-della-scala-e-widehatr",
    "title": "45¬† Linguaggio Stan",
    "section": "46.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)",
    "text": "46.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)\nStan utilizza la statistica di riduzione potenziale della scala \\(\\widehat{R}\\) (pronunciata ‚ÄúR hat‚Äù). Dato un insieme di catene di Markov, Stan divide ciascuna di esse a met√† per assicurarsi che la prima met√† e la seconda met√† della catena concordino, quindi calcola le varianze all‚Äôinterno di ciascuna catena e tra tutte le catene e le confronta. La statistica \\(\\widehat{R}\\) converge a 1 quando le catene di Markov convergono alla stessa distribuzione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#quante-catene-per-quanto-tempo",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#quante-catene-per-quanto-tempo",
    "title": "45¬† Linguaggio Stan",
    "section": "46.3 Quante catene per quanto tempo?",
    "text": "46.3 Quante catene per quanto tempo?\nUna semplice regola empirica consiste nell‚Äôeseguire quattro catene finch√© \\(\\widehat{R} \\leq 1.01\\) e la dimensione campionaria effettiva (ESS) √® superiore a 100. La raccomandazione di avere una dimensione campionaria effettiva di ‚Äúsoli‚Äù 100 √® dovuta al fatto che questo valore implica un errore standard pari a \\(\\frac{1}{10}\\) della deviazione standard. Poich√© la deviazione standard a posteriori rappresenta l‚Äôincertezza residua, calcolare le medie con una precisione maggiore √® raramente utile.\nIl modo pi√π semplice per ottenere \\(\\widehat{R} \\leq 1.01\\) e \\(N_{\\text{eff}} &gt; 100\\) √® iniziare con 100 iterazioni di riscaldamento e 100 iterazioni di campionamento. Se i valori di \\(\\widehat{R}\\) sono troppo alti o se la dimensione campionaria effettiva √® troppo bassa, raddoppiare il numero di iterazioni di riscaldamento e di campionamento e riprovare. Eseguire pi√π iterazioni di riscaldamento √® importante perch√© il campionamento non sar√† efficiente se il riscaldamento non √® convergente. Utilizzare lo stesso numero di iterazioni di riscaldamento e di campionamento pu√≤ comportare un costo massimo doppio rispetto alle impostazioni ottimali, che non sono note in anticipo.\nAnche se si utilizzano pi√π di quattro catene, √® necessario assicurarsi che la dimensione campionaria effettiva sia almeno 25 per catena. Non √® tanto per l‚Äôinferenza, quanto per garantire la fiducia nello stimatore della dimensione campionaria effettiva, che non √® affidabile se √® molto inferiore. Un modo per verificare l‚Äôadeguatezza dello stimatore ESS √® raddoppiare il numero di campioni e assicurarsi che anche l‚ÄôESS raddoppi. Se ci√≤ non accade, significa che la prima stima dell‚ÄôESS non √® affidabile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#esecuzione-delle-catene-contemporaneamente",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#esecuzione-delle-catene-contemporaneamente",
    "title": "45¬† Linguaggio Stan",
    "section": "46.4 Esecuzione delle catene contemporaneamente",
    "text": "46.4 Esecuzione delle catene contemporaneamente\n√à possibile impostare il numero di catene da eseguire utilizzando l‚Äôargomento chains del metodo sample(). Inoltre, √® possibile controllare quante catene possono essere eseguite contemporaneamente con l‚Äôargomento parallel_cores (che per default √® impostato su 1, ovvero esecuzione sequenziale).\nSe il numero massimo di catene parallele √® impostato troppo basso, le risorse della CPU potrebbero non essere sfruttate appieno. Al contrario, se √® impostato troppo alto, la CPU o la memoria potrebbero diventare il collo di bottiglia, rallentando le prestazioni complessive rispetto all‚Äôesecuzione con un numero inferiore di catene parallele.\nIn progetti personali sul nostro hardware, l‚Äôobiettivo √® solitamente ottenere la massima dimensione campionaria effettiva nel minor tempo possibile. Tuttavia, a volte √® necessario lasciare abbastanza potenza di elaborazione per continuare a lavorare su altre attivit√† come documenti, email, ecc.\n\n46.4.1 Matrici, Vettori o Array in Stan\nStan offre vari tipi di dati per gestire operazioni di algebra lineare e per definire strutture di dati pi√π generali come gli array. Capire le differenze tra questi tipi √® fondamentale per sapere cosa possiamo fare con essi e per ottimizzare la velocit√† di esecuzione del nostro modello.\n\nTipi di base per l‚Äôalgebra lineare:\n\nvector: un vettore colonna di dimensione N.\nrow_vector: un vettore riga di dimensione N.\nmatrix: una matrice di dimensioni N1 √ó N2.\n\nArray:\n\nGli array possono essere creati con qualsiasi tipo di elemento e possono avere pi√π dimensioni. Ad esempio:\n\narray[N] real a; definisce un array unidimensionale di numeri reali.\narray[N1, N2] real m; definisce un array bidimensionale di numeri reali.\n\n\nIntercambiabilit√† e limitazioni:\n\nAnche se possiamo usare sia vector che array per contenitori unidimensionali, l‚Äôalgebra matriciale (come la moltiplicazione) √® definita solo per vettori e matrici, non per array.\nAlcune funzioni, come normal_lpdf, accettano sia vettori che array.\n\nEsempi pratici:\n\nQuando definiamo una media (mu) come somma di un parametro (alpha) e il prodotto di un vettore di carichi (c_load) con un coefficiente (beta), dobbiamo usare i vettori:\nvector[N] mu = alpha + c_load * beta;\nPer utilizzare un generatore di numeri casuali (_rng) in modo vettoriale, dobbiamo usare un array:\narray[N] real p_size_pred = normal_rng(alpha + c_load * beta, sigma);\n\n\nIn sintesi, la scelta tra vector, row_vector, matrix e array dipende dalle operazioni che si desidera eseguire e dalle specifiche esigenze del modello. Scegliere il tipo di dato appropriato permette di sfruttare appieno le funzionalit√† di Stan e ottimizzare le prestazioni del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#modello-di-esecuzione-di-stan",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#modello-di-esecuzione-di-stan",
    "title": "45¬† Linguaggio Stan",
    "section": "46.5 Modello di esecuzione di Stan",
    "text": "46.5 Modello di esecuzione di Stan\nI programmi Stan sono composti da diversi blocchi. Ecco una panoramica di ciascun blocco, di quando viene eseguito e di cosa fa. Nessuno di questi blocchi √® obbligatorio, ma se presenti, devono seguire quest‚Äôordine.\n\n\n\n\n\n\n\n\nBlocco\nQuando viene eseguito\nCosa fa\n\n\n\n\nfunctions\nsecondo necessit√†\nDefinizione delle funzioni create dall‚Äôutente\n\n\ndata\nuna volta\nLettura dei dati per costruire il modello\n\n\ntransformed data\nuna volta\nDefinizione dei dati trasformati\n\n\nparameters\nuna volta / densit√† logaritmica\nDefinizione dei parametri con i relativi vincoli\n\n\ntransformed parameters\nuna volta / densit√† logaritmica\nDefinizione dei parametri trasformati\n\n\nmodel\nuna volta / densit√† logaritmica\nValutazione della densit√† logaritmica del modello\n\n\ngenerated quantities\nuna volta / per estrazione\nDefinizione delle quantit√† generate\n\n\n\n\n46.5.1 Dati e dati trasformati\nIl blocco data contiene solo le dichiarazioni delle variabili. Queste variabili vengono lette una volta durante il caricamento dei dati.\nIl blocco transformed data contiene sia dichiarazioni che definizioni delle variabili. Questo blocco serve per calcolare nuove variabili a partire dai dati originali, come predittori standardizzati o costanti per i priori. Pu√≤ anche includere la generazione pseudocasuale di numeri. Viene eseguito una volta, dopo la lettura dei dati, per definire le nuove variabili trasformate.\nIn ogni blocco, tutte le variabili devono avere il loro tipo e dimensione dichiarati (che possono dipendere dai dati). Le variabili locali all‚Äôinterno dei blocchi, invece, sono dichiarate senza specificare la dimensione.\nI vincoli sulle variabili nel blocco data vengono controllati mentre i dati vengono letti, mentre quelli nel blocco transformed data vengono verificati alla fine dell‚Äôesecuzione del blocco. Se ci sono violazioni dei vincoli nei dati o nei dati trasformati, si genera un‚Äôeccezione che interrompe l‚Äôesecuzione del programma.\nLe variabili definite nel blocco transformed data possono essere assegnate una volta, ma non possono essere riassegnate dopo l‚Äôesecuzione del blocco.\n\n\n46.5.2 Parametri e Parametri Trasformati\nIl blocco parameters serve a dichiarare le variabili su cui √® basato il modello. In pratica, si tratta di elencare i parametri che il modello utilizzer√†, specificandone le dimensioni. Quando il blocco viene eseguito, vengono forniti i valori concreti di questi parametri.\nI vincoli sui parametri sono utilizzati per trasformare le variabili vincolate in variabili non vincolate. Ad esempio, se una variabile ha un vincolo lower=0 (cio√® deve essere maggiore o uguale a zero), questa variabile viene trasformata usando il logaritmo per renderla non vincolata. √à essenziale dichiarare tutti i vincoli necessari sui parametri affinch√© il modello funzioni correttamente su tutto lo spazio dei parametri.\nIl blocco transformed parameters permette di definire nuove variabili che sono funzioni dei parametri originali e dei dati. Gli utenti possono creare le loro trasformazioni dei parametri in questo blocco. I vincoli su queste nuove variabili vengono verificati alla fine dell‚Äôesecuzione del blocco. Se questi vincoli non sono rispettati, viene generata un‚Äôeccezione che di solito porta al rifiuto della proposta corrente.\nLe variabili dichiarate nel blocco parameters sono simili agli argomenti di una funzione: la funzione di densit√† logaritmica del programma Stan prende questi parametri come input. Quindi, i valori dei parametri vengono sempre forniti dall‚Äôesterno del programma Stan.\nDopo l‚Äôesecuzione del blocco transformed parameters, le variabili dichiarate in esso non possono essere modificate ulteriormente.\nLa differenza principale tra le variabili dichiarate come locali nel blocco model e quelle nel blocco transformed parameters √® che le variabili trasformate vengono stampate e sono disponibili anche nel blocco generated quantities.\n\n\n46.5.3 Modello\nLo scopo del blocco model √® definire la funzione che calcola la densit√† logaritmica del modello. Una volta caricati i dati, il compito principale di un programma Stan √® fornire questa funzione di densit√† logaritmica non normalizzata sui parametri non vincolati. Algoritmi esterni, come ottimizzatori, campionatori o metodi di inferenza variazionale, forniranno i valori dei parametri non vincolati per la valutazione.\nIl valore della densit√† logaritmica non normalizzata calcolato dal modello viene conservato in una variabile chiamata target. Le densit√† posteriori (che ci interessano) sono calcolate moltiplicando i fattori delle funzioni di densit√† o massa di probabilit√†. In termini logaritmici, questo equivale ad aggiungere i termini delle funzioni di densit√† o massa non normalizzate alla target.\nL‚Äôaccumulatore target parte da zero e viene incrementato durante l‚Äôesecuzione del programma Stan. Come accennato prima, la prima cosa che questa funzione di densit√† logaritmica non normalizzata fa √® trasformare i parametri vincolati in non vincolati e aggiungere un aggiustamento logaritmico per il cambio di variabili alla target. Questo processo √® automatico e fornisce i valori dei parametri trasformati al codice che verr√† eseguito successivamente nel blocco model.\nLa densit√† logaritmica accumulata in target pu√≤ essere incrementata direttamente, come mostrato nell‚Äôesempio seguente:\ntarget += -0.5 * x^2;\nAnche se non √® possibile usare direttamente target come variabile, il suo valore attuale pu√≤ essere recuperato tramite la funzione target(), utile per il debugging.\nLe istruzioni di campionamento sono una scorciatoia per incrementare target. Ad esempio, l‚Äôistruzione\nx ~ normal(0, 1);\n√® equivalente a\ntarget += normal_lupdf(x | 0, 1);\nQui, _lupdf indica che si tratta di una funzione di densit√† di probabilit√† logaritmica non normalizzata.\nLa barra verticale | √® utilizzata per separare le variabili osservate dai parametri. La notazione lpdf denota una funzione di densit√† di probabilit√† logaritmica, mentre lpmf indica una funzione di massa di probabilit√† logaritmica. Le varianti lupdf e lupmf sono le loro controparti non normalizzate, che possono omettere le costanti di normalizzazione che non dipendono dai parametri. A meno che non siano necessarie, ad esempio in un componente di un modello di mescolanza, √® pi√π efficiente usare le forme lupdf e lupmf incrementando direttamente target o tramite istruzioni di campionamento.\n\n\n46.5.4 Quantit√† generate\nIl blocco generated quantities viene eseguito una volta per ogni campione generato, anzich√© ogni volta che viene calcolata la densit√† logaritmica. Con algoritmi come il campionamento Monte Carlo Hamiltoniano, ogni campione pu√≤ richiedere diverse valutazioni della densit√† logaritmica.\nUn vantaggio delle quantit√† generate √® che vengono calcolate utilizzando numeri in virgola mobile a doppia precisione, il che le rende molto efficienti. Questo blocco pu√≤ anche utilizzare numeri pseudocasuali. I vincoli sui dati generati vengono verificati alla fine del blocco, ma eventuali errori non causano il rigetto del campione, solo possibili avvertimenti o valori non definiti (NaN).\nLe quantit√† generate non influenzano il calcolo della densit√† logaritmica, ma sono comunque una parte importante del modello statistico. Sono utilizzate principalmente per fare previsioni su nuovi dati, basandosi sui parametri stimati dal modello. Questo processo √® noto come inferenza predittiva posteriore. In altre parole, ci permette di fare previsioni su nuovi dati utilizzando i valori dei parametri generati dal modello.\nEsempi di utilizzo delle quantit√† generate includono la previsione di nuovi valori o il calcolo di statistiche derivate dai parametri stimati. Le quantit√† generate offrono un modo per esplorare ulteriormente il comportamento del modello e fare inferenze utili dai dati simulati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "title": "45¬† Linguaggio Stan",
    "section": "46.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "46.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html",
    "href": "chapters/mcmc/03_stan_summary_posterior.html",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® quello di descrivere i metodi di sintesi della distribuzione a posteriori mediante l‚Äôutilizzo della tecnica MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.1 Sintesi della Distribuzione a Posteriori",
    "text": "46.1 Sintesi della Distribuzione a Posteriori\nIl risultato di un‚Äôanalisi bayesiana √® una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. √à prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un‚Äôidea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l‚Äôincertezza delle stime. La deviazione standard √® adeguata per distribuzioni simili alla normale, ma pu√≤ risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l‚ÄôIntervallo di Densit√† Pi√π Alta (HDI, Highest-Density Interval). L‚ÄôHDI √® l‚Äôintervallo pi√π breve che contiene una data porzione della densit√† di probabilit√†. Ad esempio, se diciamo che l‚ÄôHDI al 95% per un‚Äôanalisi √® [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilit√† di 0.95. Non vi √® nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l‚Äôintervallo HDI all‚Äô89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma √® accettabile stabilire un valore comune come il 95%. Per ricordarci della natura arbitraria di questa scelta, il valore predefinito in ArviZ √® del 94%.\nArviZ √® un pacchetto Python per l‚Äôanalisi esplorativa di modelli bayesiani e offre numerose funzioni utili per riassumere la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#campionamento-con-stan",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.2 Campionamento con Stan",
    "text": "46.2 Campionamento con Stan\nA scopo illustrativo, utilizziamo ancora una volta i dati relativi agli artisti della Generazione X presenti al MOMA. I dati consistono in 14 casi di successo, ovvero artisti della Generazione X, su un totale di 100 opere selezionate casualmente dal MOMA. Come fatto in precedenza, impostiamo il parametro \\(\\theta\\), che rappresenta la probabilit√† di appartenere alla Generazione X o alle successive, seguendo una distribuzione Beta(4, 6).\nPer iniziare, eseguiamo il processo di campionamento MCMC usando Stan.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'moma.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y_rep;\n  y_rep = binomial_rng(N, theta);\n}\n\n\n\nCompiliamo il modello:\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nDefiniamo il dizionario con i dati:\n\nN = 100\ny = 14\n\ndata = {\n    'N': N, \n    'y': y,\n    \"alpha_prior\" : 4,\n    \"beta_prior\" : 6\n    }\n\nprint(data)\n\n{'N': 100, 'y': 14, 'alpha_prior': 4, 'beta_prior': 6}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 4_000,\n    chains = 4,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.3 Analisi della distribuzione a posteriori",
    "text": "46.3 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.\nLa distribuzione a posteriori rappresenta un aggiornamento delle nostre credenze a priori in base ai dati osservati.\nIn genere, il primo passo da fare dopo il campionamento √® quello di verificare l‚Äôaspetto dei risultati.\n\ntrace.draws().shape\n\n(4000, 4, 9)\n\n\nLe dimensioni (4000, 4, 9) restituite dall‚Äôistruzione trace.draws().shape in CmdStanPy si riferiscono alla struttura dei dati campionati ottenuti dall‚Äôesecuzione del modello Stan. Vediamo cosa rappresenta ciascuna dimensione:\n\n4000: Questo rappresenta il numero di iterazioni di campionamento per catena. Qui, abbiamo specificato iter_sampling = 4000, quindi ci sono 4000 campioni per ciascuna catena.\n4: Questo √® il numero di catene. Abbiamo specificato chains = 4, quindi ci sono 4 catene di campionamento eseguite in parallelo.\n9: Questo rappresenta il numero di parametri o quantit√† di interesse (inclusi parametri trasformati e quantit√† generate) che sono stati campionati. Include tutte le variabili definite nei blocchi parameters, transformed parameters e generated quantities del modello Stan.\n\nPossiamo recuperare i nomi delle variabili dall‚Äôoggetto trace e il numero di campioni a posteriori per ciascuna variabile nel modo seguente:\n\nvars = trace.stan_variables()\nfor (k,v) in vars.items():\n    print(k, v.shape)\n\ntheta (16000,)\ny_rep (16000,)\n\n\nRecuperiamo i campioni posteriori per theta:\n\ntheta_samples = trace.stan_variable('theta')\ntheta_samples.shape\n\n(16000,)\n\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\nplt.hist(theta_samples, bins=30, density=True, alpha=0.5, color='blue')\nplt.xlabel('Valori di $\\\\theta$')\nplt.ylabel('Frequenza')\nplt.title('Istogramma della Distribuzione a Posteriori di $\\\\theta$')\nplt.show()\n\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l‚Äôoggetto trace alle funzioni di ArviZ. La funzione plot_trace di ArviZ √® particolarmente adatta a questo scopo:\n\n_ = az.plot_trace(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nLa figura illustra il risultato predefinito ottenuto chiamando az.plot_trace; vengono generati due subplot per ogni variabile non osservata. Nella configurazione del nostro modello, l‚Äôunica variabile non osservata √® Œ∏. A sinistra, viene visualizzato un grafico di stima della densit√† del kernel (KDE), che rappresenta una versione liscia dell‚Äôistogramma. √à auspicabile che tutte le catene abbiano un KDE molto simile ad una gaussiana, come mostrato nella figura. A destra, vengono mostrati i valori individuali ad ogni passo di campionamento, con tante linee quanti sono i percorsi delle catene. L‚Äôideale √® che questa rappresentazione appaia rumorosa, senza un pattern chiaro, rendendo difficile l‚Äôidentificazione di una catena rispetto alle altre. Il concetto chiave √® che, eseguendo molte catene, ci aspettiamo che risultino praticamente indistinguibili l‚Äôuna dall‚Äôaltra. Nel caso presente, il campionatore ha svolto un buon lavoro e possiamo fiduciosi nei risultati ottenuti.\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha, beta_param = 4, 6\n\n# Creazione di un range di valori\nx = np.linspace(0, 1, 1000)\n\n# Calcolo della PDF\npdf = stats.beta.pdf(x, alpha, beta_param)\n\n# Visualizzazione della PDF\n_ = plt.plot(x, pdf, lw=2)\n\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ci√≤ indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.\n\n46.3.1 Intervallo di credibilit√†\nLa funzione az.plot_posterior ci consente di generare un grafico della distribuzione a posteriori che include la media e l‚Äôintervallo di credibilit√† HDI al 94%. Questo tipo di grafico √® stato presentato da John K. Kruschke nel suo libro ‚ÄúDoing Bayesian Data Analysis‚Äù Kruschke (2014).\n\n_ = az.plot_posterior(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nL‚Äôintervallo di credibilit√† fornisce una stima dell‚Äôintervallo entro cui il parametro si trova con una certa probabilit√†. Nel caso presente, l‚Äôintervallo di credibilit√† del 94% ci dice che, data la nostra comprensione a posteriori del parametro, c‚Äô√® il 94% di probabilit√† che il vero valore del parametro si trovi all‚Äôinterno dell‚Äôintervallo [0.1, 0.23].\nA differenza dell‚Äôintervallo di confidenza frequentista, che √® interpretato in termini di lungo termine su ripetuti campionamenti, l‚Äôintervallo di credibilit√† bayesiano √® direttamente interpretato come la probabilit√† che il parametro si trovi all‚Äôinterno di un certo intervallo dato il set di dati specifico.\nUn sommario numerico della distribuzione a posteriori si ottiene con la funzione az.summary, la quale ritorna una Pandas Data Frame:\n\naz.summary(trace, var_names=['theta'], kind=\"stats\").round(2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\ntheta\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\n\nNella prima colonna abbiamo il nome della variabile, nella seconda colonna troviamo la media del posteriore, nella terza colonna la deviazione standard del posteriore, e nelle ultime due colonne troviamo i limiti inferiore e superiore dell‚Äôintervallo di densit√† pi√π alta al 94%. Di conseguenza, secondo il nostro modello e i dati a disposizione, riteniamo che il valore di Œ∏ sia probabilmente 0.16, con una probabilit√† del 94% che si trovi effettivamente tra 0.1 e 0.23. Possiamo riportare un riassunto simile utilizzando la deviazione standard. Il vantaggio della deviazione standard rispetto all‚ÄôHDI √® che √® una statistica pi√π conosciuta. Come svantaggio, dobbiamo essere pi√π attenti nell‚Äôinterpretarla; altrimenti, potrebbe portare a risultati privi di significato. Nel caso presente, se calcoliamo la media ¬± 2 deviazioni standard, otterremo gli intervalli (0.08, 0.24) che sono simili ai limiti dell‚Äôintervallo HDI riportato sopra.\n\n[0.16 + i*0.04 for i in (-2, 2)]\n\n[0.08, 0.24]\n\n\nTuttavia, in alcuni casi, questa procedura potrebbe generare un limite inferiore o superiore al di fuori dell‚Äôintervallo consentito per i valori di Œ∏, il quale √® compreso tra 0 e 1.\n\n\n46.3.2 Test di Ipotesi Bayesiane\nIn alcune situazioni, la mera descrizione della distribuzione a posteriori non basta. Spesso ci troviamo di fronte alla necessit√† di fare scelte basate sulle nostre inferenze, traducendo stime continue in decisioni binarie: ad esempio, affermare se un individuo √® sano o malato, se un intervento ha avuto successo o meno, e cos√¨ via.\nPrendiamo come esempio la questione se, nel Museum of Modern Art (MoMA), gli artisti appartenenti alla generazione X rappresentino il 50% dell‚Äôintero corpus. Avvalendoci di un campione casuale di 100 opere, unitamente alle nostre convinzioni pregresse (prior), abbiamo determinato un Intervallo di Massima Densit√† (HDI) che va da 0.1 a 0.23. La nostra ipotesi prevede che Œ∏ (la proporzione degli artisti della generazione X) sia 0.5. Confrontando questo valore con l‚ÄôHDI ottenuto, osserviamo che 0.5 non rientra nell‚Äôintervallo [0.1, 0.23]. Questo risultato pu√≤ essere interpretato come un‚Äôindicazione che il MoMA manifesti una preferenza per artisti nati prima del periodo 1965-1980. Tuttavia, non possiamo escludere del tutto la possibilit√† che la generazione X contribuisca per met√† alle opere presenti nel museo. Per arrivare a una conclusione pi√π definita, sarebbe necessario raccogliere ulteriori dati per ridurre la variabilit√† della distribuzione a posteriori, o considerare l‚Äôadozione di un prior pi√π informativo per affinare la nostra analisi.\nOppure possiamo chiederci quale sia la probabilit√† che il valore a posteriori \\(\\theta\\) assuma un valore minore di 0.5. La funzione az.plot_posterior(idata, ref_val=0.5) ci dice che questa probabilit√† √® uguale a 1. Ovvero, possiamo essere del tutto certi che la proporzione di opere d‚Äôarte della generazione X rappresentate al MoMA sia minore del 50% del totale.\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.5)\n\n\n\n\n\n\n\n\nPossiamo usare qualsiasi valore di riferimento. Per esempio\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.20)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.4 La Regione di Equivalenza Pratica (ROPE)",
    "text": "46.4 La Regione di Equivalenza Pratica (ROPE)\nLa Regione di Equivalenza Pratica (ROPE) costituisce un elemento chiave nei test di equivalenza, mirando a stabilire la rilevanza pratica di un parametro. Questa regione si allinea a un‚Äôipotesi nulla predefinita, permettendo di valutare se un parametro pu√≤ essere considerato equivalente rispetto a tale ipotesi.\n√à fondamentale comprendere che, data l‚Äôinfinita precisione teorica nella misurazione dei parametri, la probabilit√† di identificare un valore esatto di un parametro √® sempre uguale a zero. Pertanto, l‚Äôanalisi si concentra non sull‚Äôottenimento di valori precisi, ma piuttosto su valori che rientrano in un intervallo di accettabilit√† prefissato.\nIl metodo decisionale ‚ÄúHDI+ROPE‚Äù (Kruschke, 2014; Kruschke & Liddell, 2018) viene frequentemente utilizzato per determinare se i valori di un parametro debbano essere considerati accettabili o meno in relazione all‚Äôipotesi nulla delineata dalla ROPE. Questo metodo esamina la percentuale dell‚ÄôIntervallo Credibile (CI) che si trova all‚Äôinterno della ROPE, considerata come regione corrispondente all‚Äôipotesi nulla. Se questa percentuale √® notevolmente bassa, l‚Äôipotesi nulla viene scartata; viceversa, se √® elevata, l‚Äôipotesi viene accettata.\nPer illustrare, consideriamo l‚Äôesempio di una moneta teoricamente equilibrata, la cui probabilit√† di ottenere ‚Äútesta‚Äù si vuole sia vicina al valore teorico di 0.5. Al posto di focalizzarsi esclusivamente sul valore esatto di 0.5, possiamo definire una ROPE, ad esempio tra [0.45, 0.55]. Tale intervallo viene considerato praticamente equivalente a 0.5 ai fini della nostra analisi, consentendo di valutare l‚Äôequit√† della moneta tenendo conto delle naturali fluttuazioni nelle misurazioni.\nDopo aver definito la ROPE, confrontiamo il nostro risultato con l‚Äôintervallo di densit√† pi√π alta (HDI). Da questo confronto emergono tre possibili scenari:\n\nAssenza di sovrapposizione tra ROPE e HDI: Indica che i risultati ottenuti sono sufficientemente distanti dall‚Äôintervallo di equivalenza pratica, portando al rifiuto dell‚Äôipotesi di equivalenza. Questo scenario suggerisce che il parametro analizzato ha un impatto pratico che va oltre l‚Äôipotesi di nullit√† considerata dalla ROPE.\nLa ROPE include completamente l‚ÄôHDI: Questo scenario si verifica quando l‚Äôintero intervallo di densit√† pi√π alta cade all‚Äôinterno della ROPE, indicando che i risultati sono pienamente compatibili con l‚Äôipotesi di nullit√†. In questo caso, possiamo accettare l‚Äôipotesi che il parametro sia praticamente equivalente all‚Äôipotesi nulla, suggerendo una mancanza di significativit√† pratica del parametro in esame.\nSovrapposizione parziale tra ROPE e HDI: In questo caso, una porzione dell‚ÄôHDI si sovrappone con la ROPE, ma non completamente. Questo risultato implica che non possiamo trarre conclusioni definitive riguardo all‚Äôequivalenza pratica del parametro rispetto all‚Äôipotesi nulla. Si rende necessaria un‚Äôulteriore analisi o l‚Äôimpiego di altri criteri decisionali per determinare la rilevanza pratica del parametro.\n\nConsiderando un esempio relativo all‚Äôanalisi dei dati della Generazione X, con una ROPE definita come [0.25, 0.35].\n\n_ = az.plot_posterior(trace, var_names=['theta'], rope=[0.25, .35])\n\n\n\n\n\n\n\n\nLa ROPE cos√¨ definita corrisponde all‚Äôipotesi del parametro \\(\\theta\\) = 0.3 e considerando equivalenti i valori osservati nell‚Äôintervallo [0.25, 0.35].\nL‚Äôanalisi mostra che l‚ÄôHDI non si sovrappone alla ROPE. Inoltre, solo l‚Äô1.3% della distribuzione a posteriori √® contenuta nella ROPE. Possiamo dunque rifiutare l‚Äôipotesi specificata dalla ROPE.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.5 Estrazione degli attributi da InferenceData",
    "text": "46.5 Estrazione degli attributi da InferenceData\nVediamo ora nei dettagli come sia possibile effettuare le varie operazioni sulla distribuzione a posteriori, ovvero la stima puntuale, gli intervalli di credibilit√† e i test di ipotesi, mediante la manipolazione dell‚Äôoggetto theta_draws ottenuto dalla funzione sample.stan_variable().",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#stima-puntuale",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#stima-puntuale",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.6 Stima puntuale",
    "text": "46.6 Stima puntuale\nPossiamo recuperare la traccia di campionamento dalla variabile latente theta nel modo seguente:\n\ntheta_draws = trace.stan_variable('theta')\ntheta_draws.shape\n\n(16000,)\n\n\nIn cmdstanpy, quando si utilizza il metodo stan_variable per estrarre i campioni di un parametro specifico dai campioni posteriori, questo restituisce un array numpy contenente i campioni.\nIl metodo stan_variable('theta') estrae tutti i campioni per il parametro theta dalla distribuzione posteriore. Questo include i campioni da tutte le catene e tutte le iterazioni dopo il warmup. Il risultato, theta_draws, √® un array numpy in cui i campioni di tutte le catene sono concatenati insieme. La forma di theta_draws √® tipicamente (num_samples * num_chains, ) se theta √® un parametro scalare, o (num_samples * num_chains, dim1, dim2, ...) se theta √® un vettore o una matrice. I campioni delle 4 catene sono concatenati. Questo significa che i campioni di ciascuna catena sono aggiunti uno dopo l‚Äôaltro in un singolo array. Non sono mescolati insieme in modo casuale; piuttosto, sono semplicemente posizionati in sequenza.\nPer visualizzare il primi 30 valori di theta_draws, ad esempio, usiamo:\n\ntheta_draws[0:30]\n\narray([0.152399, 0.164544, 0.185841, 0.210788, 0.210788, 0.158488,\n       0.152418, 0.117835, 0.161514, 0.168753, 0.137032, 0.162867,\n       0.168521, 0.182565, 0.123249, 0.114717, 0.123867, 0.128263,\n       0.171871, 0.142336, 0.204677, 0.221803, 0.171478, 0.121296,\n       0.108108, 0.199047, 0.133709, 0.138647, 0.144356, 0.174385])\n\n\nDi conseguenza, possiamo calcolare su theta_draws tutte le misure statistiche descrittive che si possono ottenere da un vettore di dati. Per esempio, possiamo calcolare la media a posteriori.\n\nnp.mean(theta_draws)\n\n0.16424613186875\n\n\nPossiamo calcolare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(theta_draws)\n\n0.16208250000000002\n\n\nOppure la deviazione standard della stima a posteriori di \\(\\theta\\).\n\nnp.std(theta_draws)\n\n0.03521655992174475",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#intervallo-di-credibilit√†-1",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#intervallo-di-credibilit√†-1",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.7 Intervallo di credibilit√†",
    "text": "46.7 Intervallo di credibilit√†\nL‚Äôinferenza bayesiana tramite l‚Äôintervallo di credibilit√† riguarda invece la stima dell‚Äôintervallo che contiene il parametro \\(\\theta\\) ad un dato livello di probabilit√† soggettiva.\nUsando l‚Äôoggetto sample, possiamo ottenere un sommario della distribuzione a posteriori con il metodo az.summary().\n\naz.summary(trace, var_names=['theta'], hdi_prob=0.94, round_to=3)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta\n0.164\n0.035\n0.1\n0.231\n0.0\n0.0\n5412.045\n7678.797\n1.0\n\n\n\n\n\n\n\n\nSi ottiene cos√¨ l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPD) al 94%. Questo intervallo ci informa sul fatto che, a posteriori, possiamo essere certi al 94%, che il vero valore del parametro \\(\\theta\\) sia contenuto nell‚Äôintervallo [0.103, 0.23].\nDato che, nel caso presente, conosciamo la soluziona analitica, possiamo verificare il risultato precedente calcolando i quantili della distribuzione a posteriori Beta(18, 92) di ordine 0.03 e 0.97.\n\nll = stats.beta.ppf(0.03, 18, 92)\nul = stats.beta.ppf(0.97, 18, 92)\nlist([ll, ul])\n\n[0.10303527075398665, 0.23457657606771784]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.8 Verifica di ipotesi bayesiana",
    "text": "46.8 Verifica di ipotesi bayesiana\nUn secondo tipo di inferenza bayesiana riguarda problemi in cui siamo interessati a valutare la plausibilit√† che il parametro \\(\\theta\\) assuma valori contenuti in un dato intervallo di valori. Per esempio, ci potrebbe interessare l‚Äôipotesi \\(\\theta &gt; 0.5\\). In questo caso, possiamo calcolare la probabilit√† a posteriori che \\(\\theta\\) cada nell‚Äôintervallo di interesse, integrando la distribuzione a posteriori Beta su tale intervallo.\nNel caso dell‚Äôesempio degli artisti della Generazione X, supponiamo di essere interessati alle due seguenti ipotesi:\n\\[\n\\begin{split}\nH_0: & \\; \\; \\pi \\ge 0.2 \\\\\nH_a: & \\; \\; \\pi &lt; 0.2\n\\end{split}\n\\]\nLa nostra domanda √® la seguente: Date le nostre credenze iniziali e i dati disponibili, quale importanza relativa possiamo attribuire a queste due ipotesi?\nPer affrontare questa questione, iniziamo a calcolare la probabilit√† \\(P(\\theta &lt; 0.2)\\).\n\nprint(np.mean(theta_draws &lt; 0.2))\n\n0.846125\n\n\nPassiamo ora a calcolare gli odds a posteriori:\n\npost_odds = (np.mean(theta_draws &lt; 0.2)) / (1 - np.mean(theta_draws &lt; 0.2))\nprint(post_odds)\n\n5.498781478472787\n\n\nCi√≤ implica che la probabilit√† che \\(\\pi\\) sia inferiore al 20% √® circa 6 volte superiore rispetto alla probabilit√† che sia al di sopra del 20%.\nQuesto risultato si basa solo sulle informazioni relative alla distribuzione a posteriori. Prima di avere osservato i dati del campione, avevamo una distribuzione a priori \\(\\operatorname{Beta}(6, 4)\\), e in quel contesto avevamo una probabilit√† del 9% che \\(H_a\\) fosse vera e una probabilit√† del 91% che fosse falsa.\n\nthreshold = 0.2\nprior_prob = stats.beta.cdf(threshold, a=4, b=6)\n\n\nprior_odds = prior_prob / (1 - prior_prob)\nprint(prior_odds)\n\n0.09366320688790145\n\n\nOra possiamo combinare le informazioni degli odds a posteriori e degli odds a priori in una quantit√† chiamata Bayes Factor, che √® semplicemente il rapporto tra le due:\n\nBF = post_odds / prior_odds\nprint(BF)\n\n58.70802058970575\n\n\nIn conclusione, dopo aver appreso informazioni riguardo a 14 artisti appartenenti alla generazione X, le probabilit√† posteriori della nostra ipotesi \\(H_a: \\; \\pi &lt; 0.2\\) sono circa 60 volte superiori rispetto alle probabilit√† a priori.\nQuesto √® un esempio di test di ipotesi bayesiano.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "46.9 Commenti e considerazioni finali",
    "text": "46.9 Commenti e considerazioni finali\nLa crescente popolarit√† dei metodi bayesiani in psicologia e nelle scienze sociali √® stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un‚Äôintroduzione a cmdstanpy, un‚Äôimplementazione in Python di cmdstan, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, √® possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacit√† di effettuare inferenze bayesiane e rendendo l‚Äôanalisi di modelli complessi pi√π accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalit√† per ottenere intervalli di credibilit√†. Successivamente, √® stata discussa l‚Äôanalisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\). In alcune situazioni, questo confronto viene tradotto in una misura denominata Fattore di Bayes.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "46¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nmatplotlib: 3.8.4\ncmdstanpy : 1.2.3\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n# Stampa la versione di CmdStan\nprint(\"CmdStan version:\", cmdstanpy.utils.cmdstan_version())\n\nCmdStan version: (2, 35)\n\n\n\n\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html",
    "href": "chapters/mcmc/04_stan_diagnostics.html",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "",
    "text": "Introduzione\nLe catene di Markov sono utilizzate per approssimare la distribuzione a posteriori. Tuttavia, √® fondamentale riconoscere che tale approssimazione √® soggetta a errori e imperfezioni. Schoot et al. (2020) propongono una When-to-Worry- and-How-to-Avoid-the-Misuse-of-Bayesian-Statistics (WAMBS) checklist.\nLa diagnostica delle catene Markoviane, quindi, si configura come un insieme di pratiche e strumenti mirati a indagare vari aspetti della convergenza. Questi includono l‚Äôaccuratezza dell‚Äôapprossimazione della distribuzione a posteriori, l‚Äôefficienza del campionamento e l‚Äôesplorazione esaustiva dello spazio dei parametri. Tali strumenti diagnostici possono essere sia grafici che numerici e dovrebbero essere applicati in un contesto olistico per fornire una panoramica completa della qualit√† della catena di Markov.\nNon esiste un‚Äôunica metrica o diagnostico che possa fornire un quadro completo; piuttosto, √® l‚Äôanalisi combinata di pi√π metriche e diagnostici che permette di acquisire una comprensione pi√π profonda del comportamento della catena. Inoltre, l‚Äôesperienza del ricercatore gioca un ruolo significativo nel distinguere tra una ‚Äúbuona‚Äù e una ‚Äúcattiva‚Äù catena di Markov e nel suggerire strategie per migliorare la qualit√† del campionamento.\nIn sintesi, l‚Äôanalisi della convergenza e la diagnostica delle catene Markoviane sono fasi imprescindibili nel processo di inferenza bayesiana, soprattutto quando si utilizzano metodi MCMC. La loro applicazione consente di garantire che le stime a posteriori siano tanto accurate e affidabili quanto possibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#grafici-di-tracciamento",
    "href": "chapters/mcmc/04_stan_diagnostics.html#grafici-di-tracciamento",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.1 Grafici di Tracciamento",
    "text": "47.1 Grafici di Tracciamento\nUn metodo diagnostico comunemente utilizzato per valutare la convergenza nei metodi di Monte Carlo basati su catene di Markov (MCMC) √® l‚Äôanalisi dei grafici di tracciamento, o ‚Äútrace plots‚Äù. Questi grafici rappresentano sequenzialmente le stime dei parametri posteriori ottenute ad ogni iterazione della catena. In generale, si tende a interpretare che un parametro sta convergendo quando le stime campionarie si aggregano in una banda orizzontale ristretta lungo l‚Äôasse delle iterazioni che compongono la catena. Tuttavia, considerare questa disposizione come prova conclusiva di convergenza √® piuttosto grossolano, in quanto una traccia compatta non garantisce che la convergenza sia stata effettivamente raggiunta. Di fatto, questa metodologia risulta essere pi√π un indicatore di non-convergenza. Ad esempio, se due catene per lo stesso parametro sono campionate da regioni diverse della distribuzione target e le stime rimangono separate lungo la storia della catena, ci√≤ costituisce un‚Äôevidenza di non-convergenza. Allo stesso modo, se il grafico mostra fluttuazioni significative o salti nella catena, √® probabile che la catena associata a quel parametro non abbia raggiunto la convergenza.\nUn trace plot ideale presenta una dispersione casuale dei valori attorno a un livello medio stabile, indicando una buona miscelazione delle catene e un‚Äôadeguata configurazione del processo MCMC. Questo pattern suggerisce che l‚Äôalgoritmo √® assestato su una distribuzione stabile e le inferenze tratte dai dati campionati sono affidabili.\nApprofondendo con l‚Äôesempio di Martin, Kumar, e Lao (2022), √® possibile osservare diversi esempi di trace plots per catene MCMC. Questi esempi illustrano sia scenari in cui il comportamento √® ottimale, segnalando una convergenza adeguata, sia casi in cui le catene mostrano segni di problemi di convergenza o di miscelazione. Tali situazioni indicano la necessit√† di un‚Äôulteriore affinazione dei parametri dell‚Äôalgoritmo MCMC per garantire l‚Äôaffidabilit√† delle stime statistiche ottenute.\n\ngood_chains = stats.beta.rvs(2, 5, size=(2, 2000))\nbad_chains0 = np.random.normal(\n    np.sort(good_chains, axis=None), 0.05, size=4000\n).reshape(2, -1)\n\nbad_chains1 = good_chains.copy()\nfor i in np.random.randint(1900, size=4):\n    bad_chains1[i % 2 :, i : i + 100] = np.random.beta(i, 950, size=100)\n\nchains = {\n    \"good_chains\": good_chains,\n    \"bad_chains0\": bad_chains0,\n    \"bad_chains1\": bad_chains1,\n}\n\n\naz.plot_trace(chains)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2425599176.py:2: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe cattive catene non convergono n√© si mescolano tra loro. Uno dei motivi per l‚Äôesecuzione di pi√π catene √® che ogni singola catena potrebbe convergere verso un target, mentre un‚Äôaltra catena potrebbe convergere su un target diverso, e questo sarebbe un problema. Inoltre, catene altrimenti sane possono bloccarsi occasionalmente nel corso della serie, il che suggerirebbe la necessit√† di modifiche al modello o alle impostazioni del campionatore. Un altro modo per valutare la convergenza dell‚Äôalgoritmo √® plottando la densit√† della distribuzione a posteriori degli effetti stimati, per assicurarsi che si avvicini ad una classica curva a campana.\nIn pratica, non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perch√© la diagnostica delle catene di Markov √® cos√¨ importante: se vediamo trace-plots come le precedenti ‚Äúbad chains‚Äù, sappiamo che non abbiamo ottenuto una approssimazione adeguata della distribuzione a posteriori. In tali circostanze possiamo ricorrere ad alcuni rimedi.\n\nControllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?\nUtilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-della-densit√†-posteriore-sono-adeguati",
    "href": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-della-densit√†-posteriore-sono-adeguati",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.2 I Grafici della Densit√† Posteriore Sono Adeguati?",
    "text": "47.2 I Grafici della Densit√† Posteriore Sono Adeguati?\nI grafici della densit√† posteriore rappresentano uno degli strumenti diagnostici pi√π efficaci per identificare eventuali anomalie nella convergenza delle catene di Markov nell‚Äôanalisi bayesiana. Questi grafici mostrano la distribuzione dei valori campionati per ogni parametro del modello statistico e per ogni catena di Markov. L‚Äôimportanza di questi grafici √® primaria: essi sono la base da cui deriviamo le statistiche riassuntive dei parametri del modello, quali la media, la mediana, o l‚Äôintervallo di credibilit√†.\nPrendiamo come esempio un parametro di interesse in un modello di regressione che assume una distribuzione a priori gaussiana (normale). In un contesto ideale, senza problemi di convergenza, ci aspetteremmo che la densit√† posteriore del parametro sia anch‚Äôessa normalmente distribuita, centrata intorno a una media con una certa varianza. Questo andamento simmetrico e unimodale della densit√† posteriore √® un segnale che la catena di Markov ha esplorato adeguatamente lo spazio dei parametri e che i campioni estratti possono essere considerati rappresentativi della distribuzione posteriore effettiva del parametro.\nTuttavia, se il grafico della densit√† posteriore mostra deviazioni significative dalla forma attesa, come ad esempio asimmetrie marcate o bimodalit√†, questo suggerisce che potrebbero esserci problemi nella convergenza della catena al vero valore del parametro. Una distribuzione bimodale, in particolare, pu√≤ indicare che la catena √® rimasta ‚Äúintrappolata‚Äù in aree locali dello spazio dei parametri, senza riuscire a esplorare adeguatamente l‚Äôintero spazio e raggiungere l‚Äôequilibrio.\nPer risolvere tali problemi e ottenere una stima pi√π accurata della distribuzione posteriore, potremmo considerare diverse strategie:\n\nAumentare il Numero di Iterazioni: Incrementare il numero delle iterazioni delle catene di Markov pu√≤ permettere una migliore esplorazione dello spazio dei parametri e aiutare a superare le barriere tra i picchi di una distribuzione bimodale.\nOttimizzazione delle Distribuzioni a Priori: La scelta delle distribuzioni a priori pu√≤ influenzare fortemente la convergenza della catena. Selezionare priori pi√π informativi o pi√π flessibili pu√≤ aiutare la catena a guidare l‚Äôesplorazione dello spazio dei parametri in modo pi√π efficace.\nAffinamento dei Parametri dell‚ÄôAlgoritmo MCMC: Modificare i parametri di configurazione dell‚Äôalgoritmo MCMC, come il passo del campionamento o i criteri di accettazione, pu√≤ migliorare la qualit√† del campionamento e favorire una convergenza pi√π rapida e stabile.\n\nIn definitiva, l‚Äôanalisi dei grafici della densit√† posteriore non solo fornisce una stima visiva dell‚Äôandamento dei parametri, ma serve anche come fondamento per decisioni metodologiche che possono migliorare la robustezza e l‚Äôaffidabilit√† delle inferenze bayesiane.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-√®-troppo-alta",
    "href": "chapters/mcmc/04_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-√®-troppo-alta",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.3 L‚ÄôAutocorrelazione nelle Catene di Markov Monte Carlo √à Troppo Alta?",
    "text": "47.3 L‚ÄôAutocorrelazione nelle Catene di Markov Monte Carlo √à Troppo Alta?\nNell‚Äôambito dell‚Äôanalisi bayesiana tramite le catene di Markov Monte Carlo (MCMC), √® di fondamentale importanza valutare la rapidit√† con cui i campioni estratti dalla distribuzione a posteriori raggiungono l‚Äôindipendenza. Inizialmente, come √® noto, i campioni della distribuzione a posteriori non sono indipendenti l‚Äôuno dall‚Äôaltro, ma ci si aspetta che, nel tempo, la catena ‚Äúdimentichi‚Äù il suo stato iniziale e converga verso un insieme di estrazioni indipendenti e stazionarie dalla distribuzione a posteriori.\nUna metodologia per determinare la velocit√† con cui la catena si allontana dallo stato iniziale √® l‚Äôanalisi della funzione di autocorrelazione (ACF), che si basa sull‚Äôosservazione che un campione \\(\\theta^{(s)}\\) tende a essere pi√π simile al campione immediatamente precedente \\(\\theta^{(s-1)}\\) rispetto a quelli pi√π distanti come \\(\\theta^{(s-2)}\\), \\(\\theta^{(s-3)}\\), e cos√¨ via. La correlazione di lag-l per una catena stazionaria di Markov, dove \\(s = 1, \\ldots, S\\), pu√≤ essere espressa come:\n\\[\n\\rho_l = \\text{cor}(\\theta^{(s)}, \\theta^{(s+l)}).\n\\]\nIn generale, ci aspettiamo che l‚Äôautocorrelazione a lag-1 sia vicina a 1, ma che diminuisca man mano che il lag aumenta, indicando che i componenti della catena stanno diventando indipendenti. Una riduzione rapida dell‚Äôautocorrelazione con il numero di iterazioni √® preferibile, poich√© una lenta diminuzione pu√≤ suggerire che la catena sia ‚Äúintrappolata‚Äù e non esplori completamente il supporto della distribuzione target.\nIl correlogramma, che mostra l‚Äôautocorrelazione in funzione dei ritardi fino a un certo valore (ad esempio 20), √® utile per valutare questa caratteristica. Se l‚Äôautocorrelazione a lag 1 non √® eccessivamente alta e diminuisce rapidamente con l‚Äôincremento dei lag, ci√≤ indica che la catena sta fornendo una buona approssimazione di un campionamento casuale dalla distribuzione \\(p(\\theta \\mid y)\\).\nCatene che mostrano un rapido ‚Äúmixing‚Äù si comportano in modo simile a un campione indipendente: i valori si concentrano nei range pi√π plausibili della distribuzione a posteriori e l‚Äôautocorrelazione tra i campioni diminuisce rapidamente, risultando in un rapporto campionario effettivo alto. Al contrario, catene che non sono rapidamente ‚Äúmixing‚Äù tendono a non concentrarsi nei valori pi√π plausibili, presentano un‚Äôautocorrelazione che diminuisce lentamente e un rapporto campionario effettivo basso.\nIn caso di catene non rapidamente ‚Äúmixing‚Äù, si possono adottare due strategie:\n\nAumento del Numero di Iterazioni: Anche una catena lenta nel ‚Äúmixing‚Äù pu√≤ alla fine fornire una buona approssimazione della distribuzione a posteriori se si permette un numero sufficientemente grande di iterazioni.\nThinning (Diradamento): Questo processo consiste nel selezionare solo alcuni campioni a intervalli regolari, come ogni secondo o ogni decimo valore della catena, con l‚Äôobiettivo di ridurre le autocorrelazioni presenti nei lag pi√π brevi.\n\nUn esempio pratico √® fornito da Martin, Kumar, e Lao (2022).\n\nfig, ax = plt.subplots(3, 1)  \naz.plot_autocorr(chains, combined=True, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/4208770402.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-dimensione-effettiva-del-campione-√®-sufficiente",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-dimensione-effettiva-del-campione-√®-sufficiente",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.4 La Dimensione Effettiva del Campione √à Sufficiente?",
    "text": "47.4 La Dimensione Effettiva del Campione √à Sufficiente?\nNell‚Äôambito delle analisi con catene di Markov Monte Carlo (MCMC), un aspetto strettamente correlato alla diagnosi di autocorrelazione √® la dimensione effettiva del campione, indicata con \\(N_{\\text{eff}}\\) nell‚Äôoutput del software Stan. Questa grandezza rappresenta una stima del numero di estrazioni indipendenti dalla distribuzione a posteriori. In altre parole, corrisponde al numero di campioni indipendenti che possiede lo stesso potere di stima di \\(T\\) campioni autocorrelati. Seguendo la notazione di Stan, la \\(N_{\\text{eff}}\\) √® calcolata come segue:\n\\[\nN_{\\text{eff}} = \\frac{T}{1 + 2 \\sum_{s=1}^{S} \\rho_{s}},\n\\]\ndove \\(T\\) √® il numero totale di campioni e \\(\\rho_{s}\\) rappresenta l‚Äôautocorrelazione a lag \\(s\\).\nPoich√© i campioni della distribuzione a posteriori non sono indipendenti, ci aspettiamo che la \\(N_{\\text{eff}}\\) sia minore del numero totale di estrazioni. Se il rapporto tra la dimensione effettiva del campione e il numero totale di estrazioni √® vicino a 1, ci√≤ indica che l‚Äôalgoritmo ha raggiunto un campionamento sostanzialmente indipendente. Valori molto inferiori potrebbero essere motivo di preoccupazione poich√© indicano una forte dipendenza tra i campioni, ma √® importante notare che questo rapporto dipende fortemente dalla scelta dell‚Äôalgoritmo MCMC, dal numero di iterazioni di ‚Äúwarmup‚Äù (o ‚Äúburn-in‚Äù), e dal numero di iterazioni successive al ‚Äúwarmup‚Äù.\nUn metodo per affrontare il problema dell‚Äôautocorrelazione e del conseguente abbassamento della dimensione effettiva del campione coinvolge l‚Äôuso del diradamento (thinning). Supponiamo che l‚Äôalgoritmo venga impostato per effettuare 3.000 estrazioni dalla distribuzione a posteriori. Questo pu√≤ essere paragonato a effettuare 30.000 estrazioni ma conservando solo ogni decima. Sebbene questo metodo sia un modo per ridurre il carico sulla memoria, il vantaggio √® che tipicamente l‚Äôautocorrelazione viene ridotta, risultando in una dimensione effettiva del campione maggiore.\nPer distinguere tra buone e cattive catene MCMC, possiamo utilizzare la statistica \\(N_{\\text{eff}}\\). Un basso valore di \\(N_{\\text{eff}}\\) pu√≤ indicare una catena con una mescolanza insufficiente, suggerendo la necessit√† di aumentare il numero di iterazioni o di implementare il diradamento. In contrasto, un valore alto di \\(N_{\\text{eff}}\\) √® indice di una catena con una buona mescolanza, che assicura un campionamento efficace dalla distribuzione a posteriori. Esempi pratici di queste considerazioni sono illustrati in Martin, Kumar, e Lao (2022), dove la statistica \\(N_{\\text{eff}}\\) √® utilizzata per valutare la qualit√† delle catene MCMC.\n\n_, axes = plt.subplots(2, 3, sharey=True, sharex=True)\naz.plot_ess(chains, kind=\"local\", ax=axes[0])\naz.plot_ess(chains, kind=\"quantile\", ax=axes[1])\n\nfor ax_ in axes[0]:\n    ax_.set_xlabel(\"\")\nfor ax_ in axes[1]:\n    ax_.set_title(\"\")\n\nfor ax_ in axes[:, 1:].ravel():\n    ax_.set_ylabel(\"\")\nplt.ylim(-100, 5000);",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-statistica-hatr-√®-prossima-a-uno",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-statistica-hatr-√®-prossima-a-uno",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.5 La Statistica \\(\\hat{R}\\) √à Prossima a Uno?",
    "text": "47.5 La Statistica \\(\\hat{R}\\) √à Prossima a Uno?\nNell‚Äôambito dell‚Äôanalisi bayesiana, √® cruciale assicurarsi che ogni catena di Markov sia stazionaria e che le diverse catene mostrino coerenza tra loro. La statistica \\(\\hat{R}\\), introdotta da Gelman e Rubin nel 1992, serve proprio a valutare il grado di convergenza tra pi√π catene per ciascun parametro in esame. Questo indicatore si basa sul confronto tra due tipi di varianza: la varianza media all‚Äôinterno di ogni singola catena (W) e la varianza tra le diverse catene (B). Questo metodo ricorda l‚Äôapproccio dell‚Äôanalisi della varianza unidirezionale, in cui si confrontano stime di varianza per determinare se esistono differenze significative, in questo caso tra le catene.\nLa formula per calcolare \\(\\hat{R}\\) √® \\(\\hat{R} = \\frac{W + \\frac{1}{n} (B - W)}{W}\\), e tale metrica viene calcolata automaticamente dalla maggior parte dei software Bayesiani, come indicato da Gelman e collaboratori nel 2014. Nel contesto pratico, un valore di \\(\\hat{R}\\) superiore a 1.1 √® generalmente considerato un segnale di convergenza inadeguata delle catene. Inoltre, √® fondamentale esaminare visivamente la convergenza delle catene attraverso il confronto delle distribuzioni posteriori di ciascun parametro per ogni catena. In condizioni ideali, \\(\\hat{R}\\) dovrebbe essere pari a 1. Se \\(\\hat{R}\\) si discosta notevolmente da questo valore, ci√≤ indica che la convergenza non √® stata ancora raggiunta.\nPi√π specificamente, un valore di \\(\\hat{R}\\) maggiore di 1.01, secondo Vehtari et al. (2021), segnala una mancanza di coerenza nelle approssimazioni della distribuzione a posteriori ottenute dalle diverse catene parallele. Un valore cos√¨ elevato di \\(\\hat{R}\\) suggerisce una simulazione non stabile, indicando la necessit√† di ulteriori iterazioni o di un raffinamento del modello per garantire una convergenza affidabile. Questo aspetto √® fondamentale per assicurare che le simulazioni Monte Carlo basate su catene di Markov (MCMC) forniscano risultati consistenti e attendibili per l‚Äôanalisi statistica in corso.\n\naz.rhat(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 2.43\n    bad_chains1  float64 8B 1.018\n    good_chains  float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float642.43array(2.42962207)bad_chains1()float641.018array(1.01782964)good_chains()float641.001array(1.00080843)Indexes: (0)Attributes: (0)\n\n\nNell‚Äôesempio di Martin, Kumar, e Lao (2022) vediamo come \\(\\hat{R}\\) √® in grado di distinguere tra le buone e le cattive catene MCMC. Mentre bad_chains0 ha valori \\(\\hat{R}\\) totalmente inadeguati, bad_chains1 tende ad avere valori accettabili e good_chains ha un valore \\(\\hat{R}\\) praticamente uguale a 1.0.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-diagnostica-di-geweke-√®-prossima-a-zero",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-diagnostica-di-geweke-√®-prossima-a-zero",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.6 La Diagnostica di Geweke √à Prossima a Zero?",
    "text": "47.6 La Diagnostica di Geweke √à Prossima a Zero?\nLa statistica diagnostica di convergenza di Geweke √® basata su un test per l‚Äôuguaglianza delle medie della prima e dell‚Äôultima parte di una catena di Markov (di default il primo 10% e l‚Äôultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.\nInterpretazione: la statistica di Geweke √® uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali; valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#lerrore-standard-di-monte-carlo-√®-piccolo",
    "href": "chapters/mcmc/04_stan_diagnostics.html#lerrore-standard-di-monte-carlo-√®-piccolo",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.7 L‚ÄôErrore Standard di Monte Carlo √à Piccolo?",
    "text": "47.7 L‚ÄôErrore Standard di Monte Carlo √à Piccolo?\nQuando utilizziamo i metodi MCMC introduciamo un ulteriore livello di incertezza poich√© stiamo approssimando il posteriore con un numero finito di campioni. Possiamo stimare la quantit√† di questo tipo di errore mediante la statistica errore standard di Monte Carlo (MCSE). Il MCSE √® definitp come la deviazione standard delle catene MCMC divisa per la loro numerosit√† campionaria effettiva (ESS). Il MCSE ci fornisce dunque un‚Äôindicazione quantitativa di quanto √® grande sia il ‚Äúrumore‚Äù della stima.\nPer l‚Äôesempio di Martin, Kumar, e Lao (2022) otteniamo i valori seguenti.\n\naz.mcse(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 0.1087\n    bad_chains1  float64 8B 0.01616\n    good_chains  float64 8B 0.002583xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float640.1087array(0.10870935)bad_chains1()float640.01616array(0.01615769)good_chains()float640.002583array(0.00258312)Indexes: (0)Attributes: (0)\n\n\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 9))  \naz.plot_mcse(chains, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/1242931680.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "href": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.8 I Grafici di Rango Sono Piatti?",
    "text": "47.8 I Grafici di Rango Sono Piatti?\nIn alcune situazioni, l‚Äôinterpretazione dei grafici di traccia pu√≤ risultare estremamente complessa. Ad esempio, quando si raccolgono un numero molto elevato di campioni, comprimere lunghe tracce in un grafico di dimensioni standard pu√≤ occultare alcuni comportamenti problematici delle catene, facendo apparire erroneamente buone le tracce. Giudicare i grafici di traccia pu√≤ essere difficile anche quando le distribuzioni sono fortemente asimmetriche e/o a code pesanti. Per queste ragioni, ora si raccomanda di utilizzare i grafici di rango oltre, se non al posto, dei grafici di traccia, in modo che qualsiasi differenza nei valori campionati da ogni catena possa essere riconosciuta in un modo pi√π affidabile (Vehtari et al., 2021).\nIn statistica, il ‚Äúrango‚Äù di un‚Äôosservazione √® la sua posizione in un insieme di dati ordinati. Ad esempio, consideriamo il seguente insieme di dati: [5, 3, 8, 10]. Se ordiniamo questi dati in ordine crescente otterremo [3, 5, 8, 10]. In questo caso, il rango del numero 5 √® 2 perch√© √® il secondo numero nell‚Äôinsieme ordinato. Allo stesso modo, il rango del numero 10 √® 4 perch√© √® il quarto numero nell‚Äôinsieme ordinato.\nI grafici di rango rappresentano un nuovo strumento diagnostico che si ottiene ordinando i campioni aggregati da tutte le catene, e poi presentando un istogramma dei ranghi derivanti da ogni catena separatamente. Se tutte le catene hanno come target la stessa distribuzione, allora la distribuzione dei ranghi per ogni catena dovrebbe approssimare una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ci√≤ indica una buon mixing delle catene. Le deviazioni dall‚Äôuniformit√† possono indicare una vasta gamma di problemi di convergenza. Qui sotto √® riportato l‚Äôesempio fornito da Martin, Kumar, e Lao (2022):\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"bars\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2441558539.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa (con dei segmenti verticali al posto delle barre) √® la seguente:\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"vlines\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_24737/353816278.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "href": "chapters/mcmc/04_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.9 Ci Sono Transizioni Divergenti?",
    "text": "47.9 Ci Sono Transizioni Divergenti?\nQuando usiamo l‚Äôalgoritmo di campionamento Hamiltonian Monte Carlo (HMC), √® molto importante assicurarci che non ci siano ‚Äútransizioni divergenti‚Äù riportate nei risultati. Idealmente, il numero di queste transizioni dovrebbe essere zero. Una transizione divergente √® come un segnale di allarme che ci avverte di possibili problemi nella fase in cui l‚Äôalgoritmo esplora i vari parametri. In pratica, indica che l‚Äôalgoritmo non √® riuscito a esaminare correttamente alcune aree dello spazio dei parametri.\nOgni volta che notiamo una transizione divergente, dobbiamo indagare attentamente il motivo. La presenza di queste transizioni ci dice che l‚Äôalgoritmo potrebbe non avere esplorato adeguatamente certe zone, mettendo a rischio l‚Äôaffidabilit√† delle conclusioni del nostro studio. In presenza di divergenze, i campioni risultanti non possono essere considerati affidabili e, pertanto, non dovrebbero essere impiegati per la stima dei parametri, il confronto tra modelli, o qualsiasi altra forma di inferenza statistica Gelman et al. (2020).\nPer capire e risolvere il problema delle transizioni divergenti, possiamo considerare diverse soluzioni:\n\nControllo dei dati: √à utile controllare se ci sono dati anormali o estremi che potrebbero complicare il lavoro dell‚Äôalgoritmo.\nValutazione delle distribuzioni a priori: Dobbiamo assicurarci che le distribuzioni a priori usate si adattino bene al modello e ai dati che stiamo analizzando. Se non sono appropriate, possono creare problemi durante l‚Äôesplorazione dello spazio dei parametri.\nRegolazione della dimensione del passo: √à importante controllare e, se necessario, modificare la dimensione del passo (o step size) dell‚Äôalgoritmo HMC. Un passo troppo lungo o troppo breve pu√≤ causare instabilit√† e favorire l‚Äôoccorrenza di transizioni divergenti.\n\nAffrontando questi problemi con attenzione, possiamo migliorare la performance dell‚Äôalgoritmo HMC e ridurre il rischio di incontrare transizioni divergenti. Risolvere questi problemi √® fondamentale per assicurare che l‚Äôalgoritmo fornisca una rappresentazione precisa della distribuzione a posteriori e per garantire inferenze statistiche corrette.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-bmfi-√®-sufficientemente-grande",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-bmfi-√®-sufficientemente-grande",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.10 LA BMFI √à Sufficientemente Grande?",
    "text": "47.10 LA BMFI √à Sufficientemente Grande?\nUn altro strumento diagnostico che √® stato recentemente sviluppato per il campionamento HMC/NUTS si chiama Bayesian Fraction of Missing Information (BFMI), calcolato in modo bayesiano. Questo indicatore si basa sull‚Äôanalisi delle variazioni di energia durante ciascuna iterazione del campionamento nelle catene. Esso ci permette di capire con maggiore precisione quanto bene l‚Äôalgoritmo HMC/NUTS sta funzionando a un livello pi√π dettagliato rispetto ad altre tecniche di diagnostica.\nUn valore basso di BFMI in una catena specifica indica che l‚Äôalgoritmo non sta esplorando efficacemente la distribuzione dei dati che stiamo analizzando, il che pu√≤ portare a risultati distorti o fuorvianti. √à generalmente accettato che il valore di BFMI debba essere almeno 0.2 per ogni catena. Se in una o pi√π catene il valore scende al di sotto di 0.2, si considera che i risultati ottenuti non siano affidabili per fare inferenze corrette, poich√© le stime prodotte potrebbero essere distorte (Betancourt 2016).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?",
    "text": "47.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?\nLa Leave-One-Out Cross-Validation (LOO) rappresenta un metodo ampiamente impiegato nell‚Äôambito dell‚Äôanalisi bayesiana per valutare quanto adeguatamente un modello statistico si adatta ai dati osservati. Immaginiamo di avere una serie di foto e di voler valutare quanto bene un software riesce a riconoscere le persone in queste foto. La LOO ci aiuta a testare il software in un modo accurato.\nIl processo √® semplice: prendiamo tutte le foto tranne una, e usiamo queste per insegnare al software come riconoscere le persone. Poi, usiamo la foto che abbiamo messo da parte per vedere se il software riesce a riconoscere la persona in quella foto. Ripetiamo questo processo per ogni singola foto, una alla volta. Ogni volta, il software apprende da tutte le foto tranne una, e quella esclusa serve per testarlo.\nQuesto metodo √® molto efficace perch√© assicura che il software non impari solo a riconoscere le persone nelle foto specifiche che ha gi√† visto (questo si chiama ‚Äúoverfitting‚Äù, ovvero sovraadattamento), ma che sia davvero capace di riconoscere persone anche in foto nuove che non ha mai analizzato. Inoltre, evita il problema opposto, chiamato ‚Äúunderfitting‚Äù, dove il software non impara abbastanza dai dati e quindi non riesce a fare buone previsioni.\nNel contesto dell‚Äôanalisi bayesiana, dove si utilizzano modelli statistici complessi, la LOO √® spesso accompagnata da calcoli come il logaritmo della verosimiglianza, che aiutano a quantificare quanto bene il modello riesce a prevedere i dati esclusi. I risultati di questi calcoli possono essere usati per calcolare un indice chiamato LOOIC (Leave-One-Out Information Criterion), che permette di confrontare diversi modelli per scegliere quello che si adatta meglio ai dati.\nIn conclusione, la LOO √® uno strumento molto utile per valutare in modo imparziale e preciso quanto bene un modello statistico possa prevedere nuovi dati, garantendo che le nostre previsioni siano il pi√π accurate possibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#il-parametro-k",
    "href": "chapters/mcmc/04_stan_diagnostics.html#il-parametro-k",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "47.12 Il Parametro \\(k\\)",
    "text": "47.12 Il Parametro \\(k\\)\nIl parametro \\(k\\), noto anche come parametro di coda di Pareto, riveste un ruolo importante nell‚Äôambito del campionamento MCMC. √à utilizzato per valutare l‚Äôefficienza e la convergenza delle catene di campionamento, nonch√© per misurare la qualit√† del processo di campionamento di importanza, come nel caso del Pareto Smoothed Importance Sampling (PSIS).\nImmaginiamo di essere a una festa dove stai cercando di scoprire quale gusto di gelato √® il preferito tra gli invitati. Invece di chiedere a tutti, decidiamo di assaggiare solo alcuni gelati per avere un‚Äôidea generale. Questo processo di selezionare solo alcuni gelati per fare un‚Äôassunzione sul gusto preferito √® simile a quello che avviene nel campionamento per l‚ÄôImportance Sampling: scegliamo solo alcuni punti (o ‚Äúcampioni‚Äù) da un insieme molto grande per fare delle stime su tutta la popolazione.\nNel Pareto Smoothed Importance Sampling (PSIS), dopo aver scelto i campioni, cerchiamo di ‚Äúlisciare‚Äù le nostre stime per renderle pi√π precise e meno variabili. Pensalo come se stessi cercando di bilanciare le risposte per non dare troppo peso a poche opinioni estreme.\nIl parametro \\(k\\) ci dice quanto siamo vicini a raggiungere questo obiettivo di bilanciamento. Se \\(k\\) √® vicino a 0, significa che abbiamo fatto un buon lavoro: le nostre stime sono affidabili e non troppo dipendenti da pochi campioni estremi. Se, invece, \\(k\\) √® pi√π alto, specialmente sopra 0.7, ci indica che ci sono problemi: forse abbiamo dato troppo peso a poche opinioni estreme, o non abbiamo un buon mix di opinioni per fare una stima affidabile. In pratica, un \\(k\\) alto √® come un campanello d‚Äôallarme che ci dice che dobbiamo essere cauti con le nostre conclusioni e, possibilmente, raccogliere pi√π dati o ripensare come li stiamo campionando.\nIn sostanza, il parametro \\(k\\) √® uno strumento per aiutarci a capire quanto possiamo fidarci delle nostre stime basate su un campione limitato di dati. Un valore basso √® buono, indicando che le stime sono solide e ben equilibrate, mentre un valore alto suggerisce che potremmo avere dei problemi e che dovremmo esaminare pi√π attentamente i dati che abbiamo raccolto.\nPer calcolare il parametro \\(\\hat{\\kappa}\\), √® possibile fare uso di ArviZ, uno strumento appositamente progettato per le analisi bayesiane avanzate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/04_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "title": "47¬† Diagnostica delle catene markoviane",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nlogging   : 0.5.1.2\ncmdstanpy : 1.2.3\nscipy     : 1.13.1\narviz     : 0.18.0\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBetancourt, Michael. 2016. ¬´Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo¬ª. arXiv preprint arXiv:1604.00695.\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian B√ºrkner, e Martin Modr√°k. 2020. ¬´Bayesian workflow¬ª. arXiv preprint arXiv:2011.01808.\n\n\nMartin, Osvaldo A, Ravin Kumar, e Junpeng Lao. 2022. Bayesian Modeling and Computation in Python. CRC Press.\n\n\nSchoot, Van Rens de, Duco Veen, Laurent Smeets, e Sonja Winter. 2020. ¬´A tutorial on using the WAMBS checklist to avoid the misuse of Bayesian statistics¬ª. Routledge.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, e Paul-Christian B√ºrkner. 2021. ¬´Rank-normalization, folding, and localization: An improved R ÃÇ for assessing convergence of MCMC (with discussion)¬ª. Bayesian analysis 16 (2): 667‚Äì718.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html",
    "href": "chapters/mcmc/05_stan_prediction.html",
    "title": "48¬† La predizione bayesiana",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo il concetto e l‚Äôimportanza delle distribuzioni predittive a priori e a posteriori nel contesto dell‚Äôanalisi di dataset. La distribuzione predittiva a posteriori √® cruciale per verificare l‚Äôaderenza delle previsioni del modello ai dati osservati. Un allineamento tra queste previsioni e i dati effettivamente raccolti ci consente di convalidare l‚Äôaccuratezza del modello nel rappresentare il processo generativo sottostante.\nParallelamente, la distribuzione predittiva a priori modella le aspettative dei dati prima di qualsiasi osservazione effettiva. Essa integra le nostre conoscenze preesistenti e le ipotesi sui parametri del modello, fornendo un quadro essenziale per la proiezione e l‚Äôinterpretazione di fenomeni complessi in un contesto statistico avanzato. Questa distribuzione non solo predispone una struttura per l‚Äôanalisi inferenziale, ma √® anche fondamentale per la formulazione di nuove ipotesi e per la progettazione di esperimenti futuri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "href": "chapters/mcmc/05_stan_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "title": "48¬† La predizione bayesiana",
    "section": "48.1 La distribuzione predittiva a posteriori",
    "text": "48.1 La distribuzione predittiva a posteriori\nLa distribuzione predittiva a posteriori √® un concetto essenziale nell‚Äôinferenza bayesiana e permette di valutare quanto bene un modello si adatti ai dati osservati. Secondo Gelman e Shalizi (2013), questa metodologia fornisce una valutazione critica della coerenza tra i dati reali e quelli simulati dal modello. La verifica predittiva a posteriori utilizza la distribuzione predittiva a posteriori per confrontare direttamente i dati osservati con quelli generati dal modello, rivelando eventuali discrepanze che possono indicare problemi nella specificazione del modello. In pratica, la PPC funge da test diagnostico, consentendo di individuare e correggere eventuali lacune nel modello al fine di migliorarne le capacit√† predittive.\nPer comprendere meglio il concetto, √® utile considerare la distribuzione predittiva a posteriori in termini di un modello coniugato normale-normale. Supponiamo di voler predire la media di una distribuzione normale futura, basandoci sui dati osservati e sulle nostre conoscenze a priori. La PPD ci offre uno strumento per calcolare queste probabilit√†, combinando le informazioni provenienti dai dati osservati con quelle fornite dalla distribuzione a priori.\nAd esempio, immaginiamo di aver raccolto dati sulle altezze di 100 persone, ottenendo una media campionaria di 170 cm e una deviazione standard campionaria di 10 cm. Il nostro obiettivo √® stimare la media delle altezze in un futuro campione di \\(n=100\\) persone. La nostra conoscenza a priori sulla media delle altezze √® rappresentata da una distribuzione normale con media 175 cm e deviazione standard di 5 cm.\nIn termini di notazione, possiamo esprimere questa distribuzione come \\(P(\\tilde{y}|\\theta=\\theta_1)\\), dove \\(\\tilde{y}\\) rappresenta un nuovo dato che √® diverso dai dati attuali \\(y\\), e \\(\\theta_1\\) √® la media a posteriori. Tuttavia, in statistica bayesiana, √® fondamentale incorporare tutta l‚Äôincertezza nei risultati. Poich√© \\(\\theta_1\\) √® solo uno dei possibili valori per \\(\\theta\\), dovremmo includere ogni valore di \\(\\theta\\) per la nostra previsione. Per ottenere la migliore previsione, possiamo ‚Äúmediare‚Äù le previsioni attraverso i diversi valori di \\(\\theta\\), ponderando ciascun valore secondo la sua probabilit√† a posteriori.\nLa distribuzione risultante √® la distribuzione predittiva a posteriori, che in notazione matematica √® data da:\n\\[ P(\\tilde{y}|y) = \\int_\\theta p(\\tilde{y}|\\theta, y) p(\\theta|y) d\\theta \\]\nIn questo modo, la distribuzione predittiva a posteriori combina le informazioni dai dati osservati con la conoscenza a priori, fornendo una previsione che riflette l‚Äôincertezza associata a tutti i possibili valori dei parametri del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "href": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "title": "48¬† La predizione bayesiana",
    "section": "48.2 Distribuzione predittiva a posteriori nel modello normale-normale",
    "text": "48.2 Distribuzione predittiva a posteriori nel modello normale-normale\nNel modello coniugato normale-normale, se i dati osservati \\(Y = \\{y_1, y_2, ..., y_n\\}\\) sono modellati come provenienti da una distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e assumendo una distribuzione a priori normale per \\(\\mu\\), la distribuzione a posteriori di \\(\\mu\\) sar√† anch‚Äôessa normale.\n\n48.2.1 Formule della distribuzione predittiva a posteriori\nDato che:\n\nI dati osservati \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nLa prior per \\(\\mu\\) √® \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)\\)\n\nLa distribuzione a posteriori per \\(\\mu\\) sar√†:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)\n\\]\ndove:\n\\[\n\\mu_n = \\frac{\\tau_0^2 \\bar{y} + \\sigma^2 \\mu_0}{\\tau_0^2 + \\sigma^2}\n\\]\ne\n\\[\n\\tau_n^2 = \\frac{\\tau_0^2 \\sigma^2}{\\tau_0^2 + \\sigma^2}\n\\]\nQui, \\(\\bar{y}\\) √® la media campionaria dei dati osservati.\n\nEsempio 48.1 Consideriamo che:\n\n\\(\\mu_0 = 175\\) cm (media a priori)\n\\(\\tau_0 = 5\\) cm (deviazione standard a priori)\n\\(\\bar{y} = 170\\) cm (media campionaria)\n\\(\\sigma = 10\\) cm (deviazione standard campionaria)\n\\(n = 100\\) (numero di osservazioni)\n\nI parametri della distribuzione a posteriori sono:\n\\[\n\\mu_n = \\frac{(5^2 \\cdot 170) + (10^2 \\cdot 175)}{5^2 + 10^2} = \\frac{42500 + 175000}{25 + 100} = \\frac{217500}{125} = 174 \\quad \\text{cm}\n\\]\n\\[\n\\tau_n^2 = \\frac{5^2 \\cdot 10^2}{5^2 + 10^2} = \\frac{2500}{125} = 20 \\quad \\text{cm}^2 \\Rightarrow \\tau_n = \\sqrt{20} \\approx 4.47 \\quad \\text{cm}\n\\]\nPertanto, la distribuzione a posteriori per \\(\\mu\\) √®:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(174, 4.47^2)\n\\]\nPer la distribuzione predittiva a posteriori, dobbiamo considerare anche la varianza della distribuzione futura. Se stiamo predicendo per \\(n_{\\text{fut}}=100\\) nuove osservazioni, la varianza della media predittiva sar√†:\n\\[\n\\sigma_{\\text{pred}}^2 = \\tau_n^2 + \\frac{\\sigma^2}{n_{\\text{fut}}}\n\\]\n\\[\n\\sigma_{\\text{pred}}^2 = 20 + \\frac{10^2}{100} = 20 + 1 = 21 \\quad \\text{cm}^2 \\Rightarrow \\sigma_{\\text{pred}} = \\sqrt{21} \\approx 4.58 \\quad \\text{cm}\n\\]\nQuindi, la distribuzione predittiva a posteriori √®:\n\\[\n\\tilde{Y} \\sim \\mathcal{N}(174, 4.58^2)\n\\]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#implementazione-con-cmdstanpy",
    "href": "chapters/mcmc/05_stan_prediction.html#implementazione-con-cmdstanpy",
    "title": "48¬† La predizione bayesiana",
    "section": "48.3 Implementazione con cmdstanpy",
    "text": "48.3 Implementazione con cmdstanpy\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanpy per eseguire l‚Äôanalisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\ny_observed = np.random.normal(170, 10, 100)\nmean_y = np.mean(y_observed)\nstd_y = np.std(y_observed)\n\n# Parametri a priori\nmu_0 = 175\ntau_0 = 5\n\n# Parametri posteriori\ntau_n_sq = (tau_0**2 * std_y**2) / (tau_0**2 + std_y**2)\ntau_n = np.sqrt(tau_n_sq)\nmu_n = (tau_0**2 * mean_y + std_y**2 * mu_0) / (tau_0**2 + std_y**2)\n\n# Parametri predittivi\nn_fut = 100\nsigma_pred_sq = tau_n_sq + (std_y**2 / n_fut)\nsigma_pred = np.sqrt(sigma_pred_sq)\nmu_pred = mu_n\n\n# Simulazioni\ny_pred_samples = np.random.normal(mu_pred, sigma_pred, 1000)\n\ncolor_fill = \"#B17F7D\"\ncolor_edge = \"#832F2B\"\n\n# Grafico\nplt.hist(y_pred_samples, bins=30, density=True, color=color_fill, alpha=0.5, label='Posterior Predictive')\nx = np.linspace(160, 190, 200)\nplt.plot(x, stats.norm.pdf(x, mu_pred, sigma_pred), 'r-', lw=2, label='Predictive Distribution')\nplt.axvline(x=mu_pred, color=color_edge, linestyle='--', label='Mean Prediction')\nplt.xlabel('Heights (cm)')\nplt.ylabel('Density')\nplt.title('Posterior Predictive Distribution for Heights')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori √® stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#metodo-mcmc",
    "href": "chapters/mcmc/05_stan_prediction.html#metodo-mcmc",
    "title": "48¬† La predizione bayesiana",
    "section": "48.4 Metodo MCMC",
    "text": "48.4 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che √® particolarmente utile in scenari complessi dove l‚Äôanalisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un‚Äôosservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l‚Äôistogramma risultante approssimer√† la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell‚Äôesempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\n\nstan_ncp_file = os.path.join(\n    project_directory, 'stan', 'gaussian_model.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\nprint(model_ncp.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of observations\n  vector[N] y; // observed data\n  real mu_prior; // prior mean for mu\n  real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n  real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n  real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n}\nparameters {\n  real mu; // parameter of interest\n  real&lt;lower=0&gt; sigma; // parameter for the standard deviation\n}\nmodel {\n  mu ~ normal(mu_prior, sigma_prior); // prior for mu\n  sigma ~ normal(sigma_prior_mean, sigma_prior_sd); // prior for sigma\n  y ~ normal(mu, sigma); // likelihood\n}\ngenerated quantities {\n  array[N] real y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\n\n\nDefiniamo un dizionario che contiene i dati.\n\nstan_data = {\n    'N': len(y_observed), \n    'y': y_observed,\n    'mu_prior': 180,\n    'sigma_prior': 20,\n    'sigma_prior_mean': 10,\n    'sigma_prior_sd': 3\n}\n\nprint(stan_data)\n\n{'N': 100, 'y': array([162.84787146, 161.04839081, 179.47577095, 181.12527437,\n       171.49098193, 159.22874224, 176.45915011, 185.03984279,\n       155.86708548, 166.74740115, 178.42289272, 172.60852497,\n       172.44806286, 167.26396127, 166.30450208, 170.05155153,\n       180.8355277 , 172.55633398, 170.17618804, 173.07907092,\n       163.54108406, 165.73937461, 181.31548994, 149.61562483,\n       167.40960479, 170.69764087, 155.04683583, 174.53102596,\n       174.13818648, 156.86288728, 151.03523009, 157.39548176,\n       163.70335409, 166.11651898, 155.22542166, 165.02308717,\n       169.6978678 , 184.06879508, 179.77051126, 160.28623502,\n       168.35101542, 170.29659473, 154.82238549, 178.62021142,\n       176.1802103 , 157.61538566, 163.02477907, 182.03113017,\n       192.00390212, 167.57285945, 179.18080576, 172.08287015,\n       154.41187389, 159.49697373, 170.1896094 , 174.42961851,\n       170.80827696, 168.62216784, 163.97488914, 164.5576843 ,\n       161.13774343, 160.59831839, 174.79536747, 181.71164366,\n       185.60098039, 160.46056883, 158.34680483, 155.84009689,\n       182.21908406, 163.21383868, 181.04765122, 177.73559479,\n       176.09674444, 145.33347281, 167.16959796, 171.78867767,\n       194.14953508, 177.29486361, 171.08615454, 155.68094096,\n       175.51890099, 183.82918407, 178.04883624, 158.13937901,\n       169.96512415, 162.17717457, 190.64787268, 169.68701713,\n       176.276485  , 157.29360776, 175.59538391, 189.98182609,\n       166.98236999, 163.19208668, 160.11878234, 164.24464514,\n       172.26831966, 165.03295583, 177.08597046, 177.22899718]), 'mu_prior': 180, 'sigma_prior': 20, 'sigma_prior_mean': 10, 'sigma_prior_sd': 3}\n\n\n\ny_mean = np.mean(y_observed)\ny_std = np.std(y_observed)\n\nprint(f\"Mean of y: {y_mean}\")\nprint(f\"Standard Deviation of y: {y_std}\")\n\nMean of y: 169.57193226941754\nStandard Deviation of y: 9.930634097490112\n\n\nEseguiamo il campionamento MCMC:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n16:57:29 - cmdstanpy - INFO - CmdStan start processing\n16:57:29 - cmdstanpy - INFO - Chain [1] start processing\n16:57:29 - cmdstanpy - INFO - Chain [2] start processing\n16:57:29 - cmdstanpy - INFO - Chain [3] start processing\n16:57:29 - cmdstanpy - INFO - Chain [4] start processing\n16:57:29 - cmdstanpy - INFO - Chain [1] done processing\n16:57:29 - cmdstanpy - INFO - Chain [2] done processing\n16:57:29 - cmdstanpy - INFO - Chain [3] done processing\n16:57:29 - cmdstanpy - INFO - Chain [4] done processing\n\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n169.62\n1.00\n167.73\n171.43\n0.01\n0.01\n6155.68\n5203.68\n1.0\n\n\nsigma\n10.09\n0.71\n8.69\n11.35\n0.01\n0.01\n7169.12\n5070.39\n1.0\n\n\n\n\n\n\n\n\nConvertiamo l‚Äôoggetto sample_ncp in un oggetto di classe InferenceData:\n\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp, \n    posterior_predictive='y_rep', \n    observed_data={\"y\": y_observed}\n)\n\nLa distribuzione predittiva a posteriori √® utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato √® adeguato per descrivere le propriet√† dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), √® possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma √® possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un‚Äôanalisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi pi√π adatti ai dati in esame.\nPossiamo ora usare ArviZ per generare il posterior-predictive plot:\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-priori",
    "href": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-priori",
    "title": "48¬† La predizione bayesiana",
    "section": "48.5 Distribuzione Predittiva a Priori",
    "text": "48.5 Distribuzione Predittiva a Priori\nLe verifiche predittive a priori generano dati utilizzando unicamente le distribuzioni a priori, ignorando i dati osservati, al fine di valutare se tali distribuzioni a priori sono appropriate (Gabry et al.¬†2019). La distribuzione predittiva a priori √® quindi simile alla distribuzione predittiva a posteriori, ma senza dati osservati, rappresentando il caso limite di una verifica predittiva a posteriori senza dati.\nQuesto processo pu√≤ essere realizzato facilmente simulando i parametri secondo le distribuzioni a priori e poi simulando i dati in base al modello dati i parametri simulati. Il risultato √® una simulazione dalla distribuzione predittiva a priori.\nQuesta procedura √® fondamentale per verificare se le ipotesi a priori sono realistiche e adeguate prima di raccogliere o utilizzare i dati osservati. Se i dati simulati dalla distribuzione predittiva a priori non risultano plausibili, potrebbe essere necessario rivedere le scelte delle distribuzioni a priori.\nUn prior predictive check √® codificato come un posterior predictive check. Se disponiamo gi√† del codice per un posterior predictive check ed √® possibile impostare i dati come vuoti, allora non √® necessario alcun codice ulteriore. I prior predictive checks possono essere codificati interamente all‚Äôinterno del blocco generated quantities utilizzando la generazione di numeri casuali. I draw risultanti saranno indipendenti.\nConsideriamo, quale esempio, il caso discusso in precedenza di un campione di dati gaussiani e di un modello gaussiano in cui le distribuzioni a priori per Œº e œÉ sono gaussiane.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian_model_prior.stan')\nmodel_gauss = CmdStanModel(stan_file=stan_file)\nprint(model_gauss.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of observations\n  real mu_prior; // prior mean for mu\n  real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n  real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n  real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n}\ngenerated quantities {\n  real mu = normal_rng(mu_prior, sigma_prior); // prior draw for mu\n  real&lt;lower=0&gt; sigma = normal_rng(sigma_prior_mean, sigma_prior_sd); // prior draw for sigma\n  array[N] real y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\n\n\nIl codice precedente\nfor (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\nillustra come generare campioni predittivi a priori nel blocco generated quantities. In questo esempio, mu e sigma sono generati dalle loro rispettive distribuzioni a priori e usati per generare campioni di dati simulati y_rep.\nEseguiamo il campionamento MCMC.\n\nprior_predictive_samples = model_gauss.sample(\n    data=stan_data, \n    fixed_param=True, \n    iter_sampling=1000, \n    iter_warmup=1, \n    chains=1,\n    show_progress=False, \n    show_console=False\n)\n\n16:57:47 - cmdstanpy - INFO - CmdStan start processing\n16:57:47 - cmdstanpy - INFO - Chain [1] start processing\n16:57:47 - cmdstanpy - INFO - Chain [1] done processing\n\n\nEstraiamo le variabili necessarie.\n\ny_rep_samples = prior_predictive_samples.stan_variable(\"y_rep\")\ny_rep_flattened = y_rep_samples.flatten()\n\nCalcoliamo le statistiche descrittive dei valori y_rep.\n\ny_rep_mean = np.mean(y_rep_flattened)\ny_rep_std = np.std(y_rep_flattened)\n\nprint(f'Mean of y_rep: {y_rep_mean}')\nprint(f'Standard Deviation of y_rep: {y_rep_std}')\n\nMean of y_rep: 179.22629213099998\nStandard Deviation of y_rep: 22.230201028377742\n\n\nCreiamo un KDE plot con la distribuzione predittiva a priori.\n\nsns.kdeplot(y_rep_flattened, fill=True, color=color_fill)\nplt.title('Prior Predictive Check')\nplt.xlabel('Height (cm)')\nplt.ylabel('Density')\nplt.axvline(x=y_rep_mean, color=color_edge, linestyle='--', label=f'Mean: {y_rep_mean:.2f}')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse y che √® approssimativamente normale con media di 180.25 e deviazione standard di 22.23. Questo prior predictive check garantisce che le distribuzioni a priori dei parametri mu e sigma siano realistiche e adeguate per l‚Äôanalisi dei dati considerati. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l‚Äôanalisi dei dati osservati, migliorando cos√¨ la validit√† dei risultati ottenuti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#considerazioni-conclusive",
    "href": "chapters/mcmc/05_stan_prediction.html#considerazioni-conclusive",
    "title": "48¬† La predizione bayesiana",
    "section": "48.6 Considerazioni conclusive",
    "text": "48.6 Considerazioni conclusive\nLe distribuzioni predittive a priori e a posteriori sono generate in maniera simile, con la seguente differenza.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre previsioni sui dati prima di osservare qualsiasi dato effettivo. In questo caso, prendiamo valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati predittivi. La distribuzione di questi dati generati √® la nostra distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze prima dell‚Äôosservazione dei dati.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sulla distribuzione dei parametri usando il teorema di Bayes, ottenendo cos√¨ la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene generata prendendo valori dei parametri dalla distribuzione a posteriori (che incorpora le informazioni dai dati osservati) e inserendoli nella funzione di verosimiglianza per generare nuovi dati predittivi. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver considerato i dati attuali.\n\nLa differenza chiave tra le due distribuzioni predittive √® quindi la distribuzione dei parametri utilizzata per generare i dati: il prior nel caso della distribuzione predittiva a priori, e il posterior nel caso della distribuzione predittiva a posteriori. La distribuzione predittiva a posteriori √® generalmente pi√π informativa perch√© tiene conto dei dati osservati.\n√à fondamentale, per l‚Äôintegrit√† del modello, che la distribuzione predittiva a posteriori rifletta la distribuzione dei dati osservati. Per validare questa corrispondenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite stime di densit√† Kernel (KDE). Questo confronto consente di valutare l‚Äôefficacia del modello nell‚Äôapprossimare la struttura sottostante dei dati e la sua capacit√† di guidare previsioni affidabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/05_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "title": "48¬† La predizione bayesiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Sun Aug 04 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, Andrew, e Cosma Rohilla Shalizi. 2013. ¬´Philosophy and the practice of Bayesian statistics¬ª. British Journal of Mathematical and Statistical Psychology 66 (1): 8‚Äì38.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html",
    "href": "chapters/mcmc/06_stan_odds_ratio.html",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo l‚Äôapplicazione degli strumenti statistici descritti nei capitoli precedenti all‚Äôanalisi bayesiana di due proporzioni. Inizieremo definendo i concetti di odds, odds ratio e logit. Successivamente, mostreremo come effettuare l‚Äôanalisi bayesiana per il confronto tra due proporzioni.\nUn rapporto di odds (OR) √® una misura di associazione tra un‚Äôesposizione (o un certo gruppo o una certa conditione) e un risultato. L‚ÄôOR rappresenta gli odds che si verifichi un risultato dato un‚Äôesposizione particolare, confrontate con gli odds del risultato che si verifica in assenza di tale esposizione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#odds",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#odds",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "49.1 Odds",
    "text": "49.1 Odds\nIl termine ‚Äúodds‚Äù rappresenta il rapporto tra la probabilit√† che un evento si verifichi e la probabilit√† che l‚Äôevento opposto si verifichi. Matematicamente, l‚Äôodds pu√≤ essere calcolato come:\n\\[ \\text{odds} = \\frac{\\pi}{1-\\pi}, \\]\ndove \\(\\pi\\) rappresenta la probabilit√† dell‚Äôevento di interesse.\nMentre una probabilit√† \\(\\pi\\) √® sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilit√† di un evento.\nSe la probabilit√† di un evento √® \\(\\pi = \\frac{2}{3}\\), allora la probabilit√† che l‚Äôevento non si verifichi √® \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell‚Äôevento sono:\n\\[ \\text{odds} = \\frac{2/3}{1-2/3} = 2. \\]\nQuesto significa che la probabilit√† che l‚Äôevento si verifichi √® il doppio della probabilit√† che non si verifichi.\nSe, invece, la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{3}\\), allora gli odds che l‚Äôevento si verifichi sono la met√† rispetto agli odds che non si verifichi:\n\\[ \\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}. \\]\nInfine, se la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{2}\\), allora gli odds dell‚Äôevento sono pari a 1:\n\\[ \\text{odds} = \\frac{1/2}{1-1/2} = 1. \\]\n\n49.1.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilit√† \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull‚Äôincertezza dell‚Äôevento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilit√† dell‚Äôevento sono inferiori al 50-50, cio√® \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilit√† dell‚Äôevento sono del 50-50, cio√® \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilit√† dell‚Äôevento sono superiori al 50-50, cio√® \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l‚Äôuso dell‚Äôodds rispetto alla probabilit√†, nonostante quest‚Äôultima sia un concetto pi√π intuitivo, risiede nel fatto che quando le probabilit√† si avvicinano ai valori estremi (cio√® 0 o 1), √® pi√π facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilit√†.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#odds-ratio",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#odds-ratio",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "49.2 Odds Ratio",
    "text": "49.2 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l‚Äôodds ratio. L‚Äôodds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[ OR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}. \\]\nInterpretazione:\n\nOR = 1: l‚Äôappartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR aumenta la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR riduce la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore.\n\nL‚Äôodds ratio √® particolarmente utile quando vogliamo confrontare due gruppi e vedere come l‚Äôappartenenza a uno di essi influenza la probabilit√† di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l‚Äôefficacia di una terapia comportamentale per ridurre l‚Äôansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l‚Äôodds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilit√† di riduzione dell‚Äôansia. Se l‚Äôodds ratio √® maggiore di 1, significa che la terapia ha aumentato le probabilit√† di riduzione dell‚Äôansia; se √® inferiore a 1, significa che il trattamento ha ridotto le probabilit√† di riduzione dell‚Äôansia. L‚Äôodds ratio ci fornisce quindi una misura dell‚Äôeffetto della terapia rispetto al controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "49.3 Logaritmo dell‚ÄôOdds Ratio",
    "text": "49.3 Logaritmo dell‚ÄôOdds Ratio\nIl logaritmo dell‚Äôodds ratio √® una trasformazione matematica molto utilizzata nell‚Äôanalisi statistica, specialmente nella regressione logistica. Essa permette di rendere l‚Äôodds ratio interpretabile su una scala lineare, semplificando l‚Äôanalisi e l‚Äôinterpretazione dei risultati.\nLa formula per calcolare il logaritmo dell‚Äôodds ratio √® la seguente:\n\\[ \\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right). \\]\nIn altre parole, il logaritmo dell‚Äôodds ratio √® il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n49.3.1 Interpretazione\nL‚Äôinterpretazione del logaritmo dell‚Äôodds ratio √® pi√π intuitiva rispetto all‚Äôodds ratio stesso. Una variazione di una unit√† nel logaritmo dell‚Äôodds ratio corrisponde a un cambiamento costante nell‚Äôodds ratio stesso.\nSe il logaritmo dell‚Äôodds ratio √® positivo, significa che l‚Äôodds dell‚Äôevento nel primo gruppo √® maggiore rispetto al secondo gruppo. Pi√π il valore del logaritmo dell‚Äôodds ratio si avvicina a zero, pi√π l‚Äôodds dell‚Äôevento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell‚Äôodds ratio √® negativo, l‚Äôodds dell‚Äôevento nel primo gruppo √® inferiore rispetto al secondo gruppo. Un valore di logaritmo dell‚Äôodds ratio vicino a zero indica che l‚Äôodds dell‚Äôevento √® simile nei due gruppi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "49.4 Analisi bayesiana delle proporzioni",
    "text": "49.4 Analisi bayesiana delle proporzioni\nUna volta compresi i concetti di odds, odds ratio e logit, possiamo procedere all‚Äôanalisi bayesiana delle proporzioni. Questo approccio consente di confrontare le proporzioni di due gruppi, ottenendo stime delle probabilit√† a posteriori e degli intervalli di credibilit√†.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nIn questo capitolo, analizzeremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Hoffmann, Hofman, e Wagenmakers (2022). Von Frisch (1914) ha voluto verificare se le api possiedono la visione dei colori confrontando il comportamento di due gruppi di api. L‚Äôesperimento si compone di una fase di addestramento e di una fase di test.\nNella fase di addestramento, le api del gruppo sperimentale vengono esposte a un disco blu e a un disco verde. Solo il disco blu √® ricoperto di una soluzione zuccherina, molto appetita dalle api. Il gruppo di controllo, invece, non riceve alcun addestramento.\nNella fase di test, la soluzione zuccherina viene rimossa dal disco blu e si osserva il comportamento di entrambi i gruppi. Se le api del gruppo sperimentale hanno appreso che solo il disco blu contiene la soluzione zuccherina e sono in grado di distinguere tra il blu e il verde, dovrebbero preferire esplorare il disco blu piuttosto che quello verde durante la fase di test.\nIl ricercatore osserva che in 130 casi su 200, le api del gruppo sperimentale continuano ad avvicinarsi al disco blu dopo la rimozione della soluzione zuccherina. Le api del gruppo di controllo, che non sono state addestrate, si avvicinano al disco blu 100 volte su 200.\nPer confrontare il comportamento delle api nelle due condizioni, useremo l‚Äôodds ratio, cos√¨ da confrontare le probabilit√† dell‚Äôevento critico (scelta del disco blu) tra i due gruppi.\nCalcoliamo la proporzione delle api che scelgono il disco blu nella condizione sperimentale:\n\\[ p_e = \\frac{130}{200} = 0.65 \\]\nCalcoliamo gli odds nella condizione sperimentale:\n\\[ \\text{odds}_e = \\frac{p_e}{1 - p_e} \\approx 1.86 \\]\nQuesto ci indica che, nel gruppo sperimentale, ci sono circa 1.86 ‚Äúsuccessi‚Äù (ossia la scelta del disco blu) per ogni ‚Äúinsuccesso‚Äù (scelta del disco verde).\nProcediamo calcolando gli odds nella condizione di controllo:\n\\[ p_c = \\frac{100}{200} = 0.5 \\]\n\\[ \\text{odds}_c = \\frac{p_c}{1 - p_c} = 1.0 \\]\nQuesto ci indica che, nel gruppo di controllo, il numero di ‚Äúsuccessi‚Äù e ‚Äúinsuccessi‚Äù √® uguale.\nInfine, confrontiamo gli odds tra la condizione sperimentale e la condizione di controllo per calcolare l‚Äôodds ratio (OR):\n\\[ \\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = 1.86 \\]\nGli odds di scelta del disco blu aumentano di circa 1.86 volte nel gruppo sperimentale rispetto al gruppo di controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "49.5 Analisi Bayesiana dell‚ÄôOdds Ratio",
    "text": "49.5 Analisi Bayesiana dell‚ÄôOdds Ratio\nNella nostra analisi, ci focalizziamo sull‚ÄôOdds Ratio (OR) per valutare la differenza nel comportamento di scelta delle api nelle due condizioni dell‚Äôesperimento discusso. L‚ÄôOR fornisce una stima puntuale della differenza basata sul nostro campione specifico. Tuttavia, per realizzare un‚Äôinferenza statistica robusta, √® essenziale considerare l‚Äôincertezza nelle nostre stime, caratterizzata attraverso la distribuzione a posteriori.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le nostre conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo ci permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nPer affrontare questa questione, adottiamo un approccio bayesiano, costruendo la distribuzione a posteriori dell‚ÄôOR. A partire da questa distribuzione, determiniamo un intervallo di credibilit√† del 90%, che rappresenta l‚Äôintervallo entro il quale, con il 90% di confidenza, possiamo aspettarci che ricada il vero valore dell‚ÄôOR della popolazione.\nSe questo intervallo non include il valore 1, disponiamo di una solida evidenza (con un livello di credibilit√† del 90%) che la differenza tra le due condizioni esaminate corrisponde a una differenza reale nella popolazione, il che suggerisce che non si tratta di un artefatto generato dalla nostra incertezza. In altre parole, possiamo affermare con ragionevole certezza che le api dispongono di una visione cromatica.\nD‚Äôaltro canto, se l‚Äôintervallo di credibilit√† includesse il valore 1, ci√≤ indicherebbe che la differenza osservata nel nostro campione potrebbe non riflettere una differenza significativa nella popolazione generale, suggerendo che potrebbe essere una peculiarit√† del nostro campione specifico.\nL‚Äôanalisi bayesiana e il calcolo dell‚Äôintervallo di credibilit√† verranno condotti utilizzando cmdstanpy, che ci permette di implementare modelli bayesiani in modo efficiente e rigoroso. Utilizzeremo una distribuzione a priori debolmente informativa per l‚ÄôOR, in modo da non influenzare eccessivamente i risultati con assunzioni preliminari.\nUna volta ottenuta la distribuzione a posteriori dell‚ÄôOR, possiamo calcolare il nostro intervallo di credibilit√† del 90%. Questo intervallo fornir√† una rappresentazione della nostra incertezza riguardo il vero valore dell‚ÄôOR nella popolazione. Se il nostro intervallo di credibilit√† esclude il valore 1, possiamo concludere che esiste una differenza significativa tra i due gruppi, confermando che le api possono distinguere i colori e preferire il disco blu.\nIn sintesi, l‚Äôapproccio bayesiano non solo ci permette di stimare l‚ÄôOR, ma anche di quantificare la nostra incertezza e fare inferenze pi√π solide e informative sulla capacit√† delle api di distinguere tra colori.\n\n49.5.1 Likelihood\nLa likelihood del modello descrive la probabilit√† di osservare i dati dati i parametri del modello. Nel nostro caso, abbiamo due gruppi con eventi binomiali.\nPer il gruppo 1:\n\\[ y_1 \\sim \\text{Binomiale}(N_1, \\theta_1) .\\]\nPer il gruppo 2:\n\\[ y_2 \\sim \\text{Binomiale}(N_2, \\theta_2) .\\]\n\n\n49.5.2 Priors\nI priors del modello descrivono le nostre convinzioni iniziali sui parametri prima di osservare i dati. Nel nostro caso, i parametri \\(\\theta_1\\) e \\(\\theta_2\\) seguono una distribuzione Beta(2, 2).\nPer \\(\\theta_1\\):\n\\[ \\theta_1 \\sim \\text{Beta}(2, 2) .\\]\nPer \\(\\theta_2\\):\n\\[ \\theta_2 \\sim \\text{Beta}(2, 2) .\\]\nCompiliamo e stampiamo il modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'odds-ratio.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n08:02:19 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio\n08:02:28 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio\n\n\n//  Comparison of two groups with Binomial\ndata {\n  int&lt;lower=0&gt; N1; // number of experiments in group 1\n  int&lt;lower=0&gt; y1; // number of events in group 1\n  int&lt;lower=0&gt; N2; // number of experiments in group 2\n  int&lt;lower=0&gt; y2; // number of events in group 2\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta1; // probability of event in group 1\n  real&lt;lower=0, upper=1&gt; theta2; // probability of event in group 2\n}\nmodel {\n  // model block creates the log density to be sampled\n  theta1 ~ beta(2, 2); // prior\n  theta2 ~ beta(2, 2); // prior\n  y1 ~ binomial(N1, theta1); // observation model / likelihood\n  y2 ~ binomial(N2, theta2); // observation model / likelihood\n}\ngenerated quantities {\n  real oddsratio = (theta1 / (1 - theta1)) / (theta2 / (1 - theta2));\n}\n\n\n\nNel blocco generated quantities, calcoliamo l‚Äôodds ratio:\n\\[ \\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}. \\]\nQuesto rapporto delle odds ci d√† una misura della forza dell‚Äôassociazione tra l‚Äôevento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.\nCreiamo un dizionario che contiene i dati.\n\nn1 = 200\ny1 = 130\nn2 = 200\ny2 = 100\n\nstan_data = {\n    'N1': n1,\n    'y1': y1,\n    'N2': n2,\n    'y2': y2\n}\n\nprint(stan_data)\n\n{'N1': 200, 'y1': 130, 'N2': 200, 'y2': 100}\n\n\nEseguiamo il campionamento.\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n08:02:35 - cmdstanpy - INFO - CmdStan start processing\n08:02:35 - cmdstanpy - INFO - Chain [1] start processing\n08:02:35 - cmdstanpy - INFO - Chain [2] start processing\n08:02:35 - cmdstanpy - INFO - Chain [3] start processing\n08:02:35 - cmdstanpy - INFO - Chain [4] start processing\n08:02:35 - cmdstanpy - INFO - Chain [1] done processing\n08:02:35 - cmdstanpy - INFO - Chain [2] done processing\n08:02:35 - cmdstanpy - INFO - Chain [3] done processing\n08:02:35 - cmdstanpy - INFO - Chain [4] done processing\n\n\nEstraiamo la distribuzione a posteriori dell‚Äôodds ratio e generiamo un istogramma.\n\nor_draws = trace.stan_variable('oddsratio')\n\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    or_draws, bins=30, alpha=0.5, color=color_fill, edgecolor=color_edge, density=True\n)\nplt.title('Istogramma della distribizione a posteriori di OR')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds √® il modo pi√π semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi √® un‚Äôelevata probabilit√† che la differenza tra i due gruppi sia affidabile e relativamente grande.\nUn sommario della distribuzione a posteriori dell‚Äôodds ratio si ottine nel modo seguente.\n\naz.summary(trace, var_names=['oddsratio'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.88\n0.39\n1.2\n2.6\n0.0\n0.0\n6936.86\n5183.54\n1.0\n\n\n\n\n\n\n\n\nPossiamo determinare la probabilit√† che il rapporto di probabilit√† (odds ratio) superi 1. Per farlo, √® sufficiente analizzare gli 8000 campioni della distribuzione posteriore dell‚Äôodds ratio\n\nlen(or_draws)\n\n8000\n\n\ne calcolare la proporzione di questi che presenta un valore maggiore di 1:\n\nnp.mean(or_draws &gt; 1.0)\n\n0.9985",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "49.6 Diagnostica delle catene markoviane",
    "text": "49.6 Diagnostica delle catene markoviane\nPrima di esaminare i risultati, eseguiamo la diagnostica delle catene markoviane.\n\n49.6.1 Mixing\nIl trace plot precedente dimostra un buon mixing. Questo √® evidenza che il campionamento MCMC ha raggiunto uno stato stazionario.\n\n_ = az.plot_trace(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n49.6.2 NumerositaÃÄ campionaria effettiva\nQuando si utilizzano metodi di campionamento MCMC, √® ragionevole chiedersi se un particolare campione estratto dalla distribuzione a posteriori sia sufficientemente grande per calcolare con sicurezza le quantit√† di interesse, come una media o un HDI. Questo non √® qualcosa che possiamo rispondere direttamente guardando solo il numero di punti della catena MCMC, e il motivo √® che i campioni ottenuti dai metodi MCMC hanno un certo grado di autocorrelazione, quindi la quantit√† effettiva di informazioni contenute in quel campione sar√† inferiore a quella che otterremmo da un campione iid della stessa dimensione. Possiamo pensare alla dimensione del campione effettivo (ESS) come a un stimatore che tiene conto dell‚Äôautocorrelazione e fornisce il numero di estrazioni che avremmo se il nostro campione fosse effettivamente iid.\nPer le catene buone, solitamente, il valore della dimensione del campione effettivo sar√† inferiore al numero di campioni. Ma l‚ÄôESS pu√≤ essere in realt√† pi√π grande del numero di campioni estratti. Quando si utilizza il campionatore NUTS, valori di ESS maggiori del numero totale di campioni possono verificarsi per parametri le cui distribuzioni posteriori sono vicine alla Gaussiana e che sono quasi indipendenti da altri parametri nel modello.\nNell‚Äôoutput di PyCM si considera ESS_BULK. Un euristica √® che deve essere almeno uguale a 400. Nel caso presente questo si verifica, quindi il valore ESS_BULK non fornisce alcuna evidenza di cattivo mixing.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.881\n0.386\n1.198\n2.597\n0.005\n0.003\n6937.0\n5184.0\n1.0\n\n\ntheta1\n0.647\n0.033\n0.585\n0.710\n0.000\n0.000\n6865.0\n5296.0\n1.0\n\n\ntheta2\n0.499\n0.035\n0.434\n0.564\n0.000\n0.000\n7465.0\n5391.0\n1.0\n\n\n\n\n\n\n\n\n\n\n49.6.3 R hat\nIn condizioni molto generali, i metodi di Markov chain Monte Carlo hanno garanzie teoriche che otterranno la risposta corretta indipendentemente dal punto di partenza. Sfortunatamente, tali garanzie sono valide solo per campioni infiniti. Quindi, nella pratica, abbiamo bisogno di modi per stimare la convergenza per campioni finiti. Un‚Äôidea diffusa √® quella di generare pi√π di una catena, partendo da punti molto diversi e quindi controllare le catene risultanti per vedere se sembrano simili tra loro. Questa nozione intuitiva pu√≤ essere formalizzata in un indicatore numerico noto come R-hat. Esistono molte versioni di questo stimatore, poich√© √® stato perfezionato nel corso degli anni. In origine il R-hat veniva interpretato come la sovrastima della varianza dovuta al campionamento MCMC finito. Ci√≤ significa che se si continua a campionare all‚Äôinfinito si dovrebbe ottenere una riduzione della varianza della stima di un fattore R-hat. E quindi il nome ‚Äúfattore di riduzione potenziale della scala‚Äù (potential scale reduction factor), con il valore target di 1 che significa che aumentare il numero di campioni non ridurr√† ulteriormente la varianza della stima. Tuttavia, nella pratica √® meglio pensarlo solo come uno strumento diagnostico senza cercare di sovra-interpretarlo.\nL‚ÄôR-hat per il parametro theta viene calcolato come la deviazione standard di tutti i campioni di theta, ovvero includendo tutte le catene insieme, diviso per la radice quadratica media delle deviazioni standard separate all‚Äôinterno della catena. Il calcolo effettivo √® un po‚Äô pi√π complesso ma l‚Äôidea generale √® questa. Idealmente dovremmo ottenere un valore di 1, poich√© la varianza tra le catene dovrebbe essere la stessa della varianza all‚Äôinterno della catena. Da un punto di vista pratico, valori di R-hat inferiori a 1.1 sono considerati sicuri.\nNel caso presente questo si verifica. Possiamo ottenere R hat con Arviz:\n\naz.rhat(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 1.0\n    theta1     float64 8B 1.001\n    theta2     float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float641.0array(1.00038283)theta1()float641.001array(1.00052497)theta2()float641.001array(1.00059406)Indexes: (0)Attributes: (0)\n\n\nIl valore di \\(\\hat{R}\\), al massimo, raggiunge il valore di 1.001. Essendo il valore molto simile a 1 nel caso presente, possiamo dire che non ci sono evidenza di assenza di convergenza.\n\n\n49.6.4 Errore standard di Monte Carlo\nQuando si utilizzano metodi MCMC introduciamo un ulteriore livello di incertezza poich√© stiamo approssimando la posteriore con un numero finito di campioni. Possiamo stimare la quantit√† di errore introdotta utilizzando l‚Äôerrore standard di Monte Carlo (MCSE). L‚ÄôMCSE tiene conto del fatto che i campioni non sono veramente indipendenti l‚Äôuno dall‚Äôaltro e sono in realt√† calcolati dall‚ÄôESS. Mentre i valori di ESS e R-hat sono indipendenti dalla scala dei parametri, la statistica MCSE non lo √®. Se vogliamo riportare il valore di un parametro stimato al secondo decimale, dobbiamo essere sicuri che MCSE sia al di sotto del secondo decimale altrimenti, finiremo, erroneamente, per riportare una precisione superiore a quella che abbiamo realmente. Dovremmo controllare MCSE solo una volta che siamo sicuri che ESS sia abbastanza alto e R-hat sia abbastanza basso; altrimenti, MCSE non √® utile.\nNel nostro caso il MCSE √® sufficientemente piccolo.\n\naz.mcse(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 0.004636\n    theta1     float64 8B 0.0004029\n    theta2     float64 8B 0.0004034xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float640.004636array(0.00463567)theta1()float640.0004029array(0.00040294)theta2()float640.0004034array(0.00040337)Indexes: (0)Attributes: (0)\n\n\nCome per l‚ÄôESS, l‚ÄôMCSE varia nello spazio dei parametri e quindi potremmo anche volerlo valutare per diverse regioni dello spazio dei parametri.\n\n_ = az.plot_mcse(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nL‚Äôerrore standard di Monte Carlo ci informa della precisione della stima ottenuta usando il metodo MCMC. Non possiamo riportare una precisione dei risultati maggiore di quella indicata dalla MCSE. Pertanto, per il caso presente relativo all‚ÄôOdds Ratio (OR), possiamo affermare che la precisione massima raggiungibile √® limitata a due decimali.\n\n\n49.6.5 Autocorrelazione\nL‚Äôautocorrelazione riduce la quantit√† effettiva di informazioni contenute in un campione e quindi √® qualcosa che vogliamo mantenere al minimo. Possiamo ispezionare direttamente l‚Äôautocorrelazione con az.plot_autocorr.\n\n_ = az.plot_autocorr(trace, combined=True, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n49.6.6 Rank Plots\nI grafici dei ranghi sono un altro strumento diagnostico visivo che possiamo utilizzare per confrontare il comportamento del campionamento sia all‚Äôinterno che tra le catene. I grafici dei ranghi, in parole semplici, sono istogrammi dei campioni della distribuzione a posteriori espressi in termini di ranghi. Nei grafici dei ranghi, i ranghi sono calcolati combinando prima tutte le catene ma poi rappresentando i risultati separatamente per ogni catena. Se tutte le catene stimano la stessa distribuzione, ci aspettiamo che i ranghi abbiano una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ci√≤ indica un buon mix delle catene.\nPossiamo ottenere i grafici dei ranghi con az.plot_rank.\n\n_ = az.plot_rank(trace, kind=\"bars\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa √® la seguente.\n\n_ = az.plot_rank(trace, kind=\"vlines\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nPossiamo vedere nella figura che i ranghi sono molto simili ad una distribuzione uniforme e che tutte le catene sono simili tra loro senza alcuno scostamento distintivo.\n\n\n49.6.7 Divergenza\nFinora abbiamo diagnosticato il funzionamento di un campionatore esaminando i campioni generati. Un altro modo per eseguire una diagnosi √® monitorare il comportamento dei meccanismi interni del metodo di campionamento. Un esempio importante di tali diagnosi √® il concetto di divergenza presente in alcuni metodi Hamiltonian Monte Carlo (HMC). Le divergenze (o transizioni divergenti) sono un modo potente e sensibile per diagnosticare i campioni e funzionano come complemento alle diagnosi che abbiamo visto nelle sezioni precedenti.\nPyMC riporta il numero di transizioni divergenti. Se non viene riportato alcun messaggio che informa della presenza di transizioni divergenti, questo vuol dire che la distribuzione a posteriori √® stata stimata correttamente.\n\n\n49.6.8 BFMI\nIl BFMI (Fraction of Missing Information) serve a valutare quanto bene il processo di campionamento si allinea con la distribuzione della ‚Äúenergia‚Äù associata a ciascun campione. Nel contesto del campionamento Hamiltoniano, il termine ‚Äúenergia‚Äù si riferisce a una quantit√† calcolata durante il processo di campionamento che aiuta a valutare quanto √® probabile un certo set di parametri alla luce dei dati osservati e del modello statistico in esame.\nIl BFMI √® uno strumento che ci aiuta a valutare se il processo di campionamento sta ‚Äúesplorando‚Äù adeguatamente lo spazio dei parametri possibili. In altre parole, ci dice se il nostro processo di campionamento sta dando un‚Äôimmagine accurata delle regioni dello spazio dei parametri che sono realmente plausibili dati i nostri dati e il nostro modello. Un valore BFMI basso indica che il campionamento non √® riuscito a esplorare adeguatamente alcune regioni dello spazio dei parametri che dovrebbero essere state esplorate, e quindi i risultati del campionamento potrebbero non essere affidabili.\nGeneralmente, un valore inferiore a 0.3 indica un campionamento insufficiente.\nNel caso presente, dal momento che i valori BFMI sono superiori a 0.3 per tutte le catene, sembra che il processo di campionamento sia riuscito a esplorare adeguatamente lo spazio dei parametri.\n\naz.bfmi(trace)\n\narray([1.14346921, 1.11602384, 1.1467078 , 1.03197001])\n\n\nLa validazione del processo di campionamento pu√≤ essere efficacemente eseguita analizzando graficamente le quantit√† note come ‚Äúenergy transition‚Äù e ‚Äúmarginal energy‚Äù. Queste metriche sono strettamente legate alla funzione obiettivo che l‚Äôalgoritmo di campionamento intende ottimizzare e giocano un ruolo cruciale nel rilevare potenziali problematiche che possono emergere durante il campionamento.\n\nEnergy transition: questa metrica illustra l‚Äô‚Äúenergia‚Äù calcolata in ogni singolo passo dell‚Äôalgoritmo di campionamento, offrendo una visione dettagliata delle fluttuazioni che intervengono ad ogni iterazione. Facilita l‚Äôidentificazione delle aree dello spazio dei parametri dove l‚Äôalgoritmo potrebbe incontrare difficolt√† nel campionare in modo corretto.\nMarginal energy: fornisce un profilo dell‚Äô‚Äúenergia‚Äù marginale per l‚Äôintero set di campioni, riflettendo l‚Äô‚Äúenergia‚Äù media in ogni punto del campione. √à una rappresentazione grafica dell‚Äô‚Äúenergia‚Äù associata alla distribuzione a posteriori che si intende campionare.\n\nPer un‚Äôanalisi diagnostica efficace, √® auspicabile che il tracciato dell‚Äô‚Äúenergy transition‚Äù coincida sostanzialmente con quello della ‚Äúmarginal energy‚Äù. Tale congruenza √® indicativa di una esplorazione ben riuscita dello spazio dei parametri, assicurando che le regioni ad alta probabilit√† nella distribuzione a posteriori siano state correttamente campionate. Pertanto, una buona sovrapposizione tra i grafici delle due metriche attesterebbe un funzionamento ottimale del modello, conferendo un grado di affidabilit√† elevato alle stime dei parametri derivanti dal processo di campionamento.\n\n_ = az.plot_energy(trace)\n\n\n\n\n\n\n\n\n\n\n49.6.9 Conclusione\nIn questo capitolo abbiamo approfondito l‚Äôanalisi bayesiana focalizzandoci sulla stima dell‚Äôodds ratio (OR). I risultati della diagnosi delle catene Markoviane non evidenziano problematiche relative alla convergenza dell‚Äôalgoritmo n√© discrepanze nel modello statistico adottato, permettendoci di procedere con l‚Äôanalisi dei risultati ottenuti.\nL‚Äôanalisi ha determinato un valore a posteriori per l‚ÄôOR di 1.88, accompagnato da un intervallo di credibilit√† del 94% compreso tra 1.20 e 2.60. Poich√© questo intervallo non include il valore 1, possiamo affermare, con un grado di certezza del 94%, che il comportamento delle api differisce nelle due condizioni sperimentali. Questo fornisce evidenza a supporto dell‚Äôipotesi che le api dispongano di una visione cromatica.\nL‚Äôapproccio bayesiano adottato ci ha permesso di integrare le conoscenze a priori con i dati ottenuti dall‚Äôanalisi, risultando in una stima dell‚Äôodds ratio pi√π affidabile e accurata.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "49¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nscipy     : 1.14.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHoffmann, Tabea, Abe Hofman, e Eric-Jan Wagenmakers. 2022. ¬´Bayesian tests of two proportions: A tutorial with R and JASP¬ª. Methodology 18 (4): 239‚Äì77.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html",
    "href": "chapters/mcmc/07_stan_normal_normal.html",
    "title": "50¬† Inferenza bayesiana su una media",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo principale di questo capitolo √® esaminare un contesto che abbiamo gi√† preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione √® stato estratto. Tuttavia, anzich√© procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo i metodi MCMC con Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#il-modello-normale",
    "href": "chapters/mcmc/07_stan_normal_normal.html#il-modello-normale",
    "title": "50¬† Inferenza bayesiana su una media",
    "section": "50.1 Il modello Normale",
    "text": "50.1 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l‚Äôapprossimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l‚Äôesercizio descritto nel capitolo {ref}distr-coniugate-2-notebook usando Stan.\n\n50.1.1 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell‚Äôarea di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ‚Äô60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un‚Äôeconomia basata su caccia e raccolta. Riprodurremo l‚Äôanalisi descritta da {cite:t}McElreath_rethinking, esaminando unicamente i valori di altezza per individui di et√† superiore ai 18 anni.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\ndf.head()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\n\nlen(df[\"height\"])\n\n352\n\n\n\nsns.kdeplot(df[\"height\"], bw_adjust=0.5, fill=True)  # Adjust bw_adjust for smoothing\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\nLa media dei valori dell‚Äôaltezza nel campione √®:\n\nnp.mean(df[\"height\"])\n\n154.5970926136364\n\n\ncon una deviazione standard pari a:\n\nnp.std(df[\"height\"], ddof=1)\n\n7.742332137351995\n\n\n\n\n50.1.2 Modello di Base\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo {cite:t}McElreath_rethinking, ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell‚Äôaltezza.\nPertanto, il modello Normale si definisce nel seguente modo:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilit√†, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l‚Äôoggetto dell‚Äôinferenza.\n\nstan_file = os.path.join(project_directory, 'stan', 'gaussian_height.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\nparameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  sigma ~ normal(0, 20);\n  mu ~ normal(181, 30);\n}\n\n\n\nCreaiamo un dizionario con i dati in formato appropriato per Stan:\n\nstan_data = {'N': len(df[\"height\"]), 'y': df[\"height\"]}\nprint(stan_data)\n\n{'N': 352, 'y': 0      151.765\n1      139.700\n2      136.525\n3      156.845\n4      145.415\n        ...   \n347    162.560\n348    142.875\n349    162.560\n350    156.210\n351    158.750\nName: height, Length: 352, dtype: float64}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\mu\\) e \\(\\sigma\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\nUna sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente.\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.60\n0.42\n153.84\n155.39\n0.0\n0.0\n7864.52\n5825.33\n1.0\n\n\nsigma\n7.77\n0.30\n7.21\n8.34\n0.0\n0.0\n6655.48\n5167.04\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#parametrizzazione-non-centrata",
    "href": "chapters/mcmc/07_stan_normal_normal.html#parametrizzazione-non-centrata",
    "title": "50¬† Inferenza bayesiana su una media",
    "section": "50.2 Parametrizzazione Non Centrata",
    "text": "50.2 Parametrizzazione Non Centrata\nNella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell‚Äôinferenza (\\(\\mu\\) e \\(\\sigma\\)) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro \\(\\mu\\) abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro \\(\\sigma\\) abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare.\n√à possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura √® chiamata ‚Äúparametrizzazione non centrata‚Äù (non-centered parametrization). In questo modello, utilizziamo variabili latenti \\(\\mu_{\\text{raw}}\\) e \\(\\sigma_{\\text{raw}}\\), che seguono una distribuzione normale standard:\n\\[\n\\begin{align}\n\\mu_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\\\\\n\\sigma_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\n\\end{align}\n\\]\nQueste variabili vengono poi trasformate per ottenere i parametri \\(\\mu\\) e \\(\\sigma\\) sulla scala originale:\n\\[\n\\begin{align}\n\\mu &= y_{\\text{mean}} + y_{\\text{sd}} \\cdot \\mu_{\\text{raw}} \\notag\\\\\n\\sigma &= y_{\\text{sd}} \\cdot \\sigma_{\\text{raw}} \\notag\n\\end{align}\n\\]\nDove: - \\(y_{\\text{mean}}\\) √® la media dei dati osservati \\(y\\). - \\(y_{\\text{sd}}\\) √® la deviazione standard dei dati osservati \\(y\\).\n\nstan_ncp_file = os.path.join(project_directory, 'stan', 'gaussian_ncp.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\n\nDi seguito √® riportato il codice Stan per questo modello con la parametrizzazione non centrata:\n\nprint(model_ncp.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\ntransformed data {\n    real y_mean = mean(y);\n    real y_sd = sd(y);\n}\nparameters {\n    real mu_raw;\n    real&lt;lower=0&gt; sigma_raw;\n}\ntransformed parameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Priors:\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    // Likelihood:\n    y ~ normal(mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\n\n\nEcco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.\n\nBlocco Dati:\n\nint&lt;lower=1&gt; N;: Il numero totale di prove o osservazioni.\nvector[N] y;: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.\n\nBlocco Dati Trasformati:\n\nreal y_mean = mean(y);: La media dei dati osservati y.\nreal y_sd = sd(y);: La deviazione standard dei dati osservati y.\n\nBlocco Parametri:\n\nreal mu_raw;: Un parametro latente che segue una distribuzione normale standard.\nreal&lt;lower=0&gt; sigma_raw;: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.\n\nBlocco Parametri Trasformati:\n\nreal mu;: La media della distribuzione normale per y sulla sua scala originale.\nreal&lt;lower=0&gt; sigma;: La deviazione standard della distribuzione normale per y sulla sua scala originale.\nQuesti parametri trasformati sono definiti come:\nmu = y_mean + y_sd * mu_raw;\nsigma = y_sd * sigma_raw;\n\n\nLa parametrizzazione non centrata comporta la riparametrizzazione del modello in termini di variabili standardizzate (mu_raw e sigma_raw) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e propriet√† di convergenza, specialmente nei modelli gerarchici.\n\nParametri Latenti (mu_raw e sigma_raw):\n\nmu_raw ~ normal(0, 1);: mu_raw √® una variabile normale standardizzata.\nsigma_raw ~ normal(0, 1);: sigma_raw √® una variabile normale standardizzata vincolata a essere positiva.\n\nTrasformazione alla Scala Originale:\n\nmu = y_mean + y_sd * mu_raw;: Questo scala e trasla mu_raw alla posizione e scala dei dati osservati y.\nsigma = y_sd * sigma_raw;: Questo scala sigma_raw alla scala dei dati osservati y.\n\n\nLa dichiarazione della verosimiglianza y ~ normal(mu, sigma); indica che i dati osservati y seguono una distribuzione normale con media mu e deviazione standard sigma. Ecco perch√© ha senso anche se y √® sulla sua scala originale:\n\nDati Osservati sulla Scala Originale: I dati osservati y sono sulla loro scala originale.\nParametri sulla Scala Originale: I parametri mu e sigma, dopo la trasformazione nel blocco transformed parameters, sono anch‚Äôessi sulla scala originale di y.\n\nQuindi, la dichiarazione y ~ normal(mu, sigma); specifica correttamente che i dati osservati y (sulla loro scala originale) sono modellati da una distribuzione normale con media mu e deviazione standard sigma, entrambe sulla scala originale di y.\nInfine, il blocco generated quantities viene utilizzato per i controlli predittivi posteriori generando nuovi dati (y_rep) dalla distribuzione posteriore dei parametri (mu e sigma):\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\ny_rep: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore mu e la deviazione standard posteriore sigma. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.\n\nEseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\n_ = az.plot_trace(trace_ncp, var_names=['mu', 'sigma'])\n\n\n\n\n\n\n\n\nOtteniamo una sintesi delle distribuzioni a posteriori dei parametri:\n\nsummary = az.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\nprint(summary)\n\n         mean    sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nmu     154.61  0.42  153.83   155.39       0.01      0.0   6329.64   5029.29   \nsigma    7.76  0.29    7.20     8.30       0.00      0.0   7836.78   5829.76   \n\n       r_hat  \nmu       1.0  \nsigma    1.0  \n\n\nI risultati sono molto simili a quelli ottenuti in precedenza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#posterior-predictive-check",
    "href": "chapters/mcmc/07_stan_normal_normal.html#posterior-predictive-check",
    "title": "50¬† Inferenza bayesiana su una media",
    "section": "50.3 Posterior predictive check",
    "text": "50.3 Posterior predictive check\nUno dei vantaggi del toolkit bayesiano √® che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(Œ∏|Y) √® possibile utilizzarla per generare le previsioni p(·ª∏). Matematicamente, questo pu√≤ essere fatto calcolando:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta distribuzione √® nota come distribuzione predittiva posteriore. √à predittiva perch√© viene utilizzata per fare previsioni e posteriore perch√© √® calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.\nUtilizzando Stan √® facile per ottenere campioni predittivi posteriori: non √® necessario calcolare alcun integrale. Dobbiamo convertire l‚Äôoggetto creato dalla funzione sample() nel formato ArviZ InferenceData:\n\n# Convert to ArviZ InferenceData object\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nUn uso comune della distribuzione predittiva posteriore √® quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello √® una buona rappresentazione dei dati. Possiamo utilizzare la funzione plot_ppc di ArviZ per visualizzare la distribuzione predittiva posteriore e i dati osservati. Il codice √®:\n\n# Plot the posterior predictive check\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nNella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee blu sono KDE calcolate da ciascuno dei 500 campioni predittivi posteriori. Le linee blu riflettono l‚Äôincertezza associata alla distribuzione dei dati previsti.\nDi default, in ArviZ le KDE vengono stimati all‚Äôinterno dell‚Äôintervallo effettivo dei dati e si assume che siano zero al di fuori di questo intervallo.\nDato che il tracciato del KDE plot √® contenuto nell‚Äôinsieme di profili dei KDE plot dei campioni predittivi a posteriori, si pu√≤ concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed √® utile per la maggior parte delle analisi. Tuttavia, √® importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all‚Äôintero dataset. Esploreremo ora come poter sviluppare un modello alternativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#modello-robusto",
    "href": "chapters/mcmc/07_stan_normal_normal.html#modello-robusto",
    "title": "50¬† Inferenza bayesiana su una media",
    "section": "50.4 Modello ‚Äúrobusto‚Äù",
    "text": "50.4 Modello ‚Äúrobusto‚Äù\nNon √® necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianit√† possono essere considerate attraverso l‚Äôutilizzo della distribuzione t di Student, che √® particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello ‚Äòrobusto‚Äô, maggiormente adatto a gestire osservazioni che si discostano dalla normalit√† nelle code della distribuzione.\nLa distribuzione t di Student √® caratterizzata dal parametro \\(\\nu\\), noto come ‚Äògradi di libert√†‚Äô. Quando \\(\\nu\\) √® pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale.\n\nnu_values = [1, 2, 10]\n\nfig, ax = plt.subplots()\n\nfor nu in nu_values:\n    x = np.linspace(-5, 5, 1000)\n    y = stats.t.pdf(x, df=nu, loc=0, scale=1)\n    ax.plot(x, y, label=f\"ŒΩ={nu}\")\n\nx = np.linspace(-5, 5, 1000)\ny = stats.t.pdf(x, df=np.inf, loc=0, scale=1)\nax.plot(x, y, linestyle=\"--\", color=\"k\", label=\"ŒΩ=‚àû\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTuttavia, le code della distribuzione t di Student risultano pi√π pesanti rispetto a quelle della normale quando \\(\\nu\\) √® basso. Pertanto, proponiamo di assegnare a \\(\\nu\\) una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.\n\n# Define the rate parameter for the exponential distribution\nrate = 1 / 30\n\n# Generate samples from the exponential distribution\nsamples = np.random.exponential(scale=1 / rate, size=10000)\n\n# Create the histogram plot of the samples\nplt.hist(samples, bins=50, density=True, alpha=0.75, label=\"Sampled Distribution\")\nplt.title(\"Exponential Distribution (Œª = 1/30)\")\nplt.xlabel(\"Values\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nstan_student_file = os.path.join(project_directory, 'stan', 'student-model.stan')\nmodel_student = CmdStanModel(stan_file=stan_student_file)\nprint(model_student.code())\n\ndata {\n    int&lt;lower=1&gt; N;  // Numero totale di prove\n    vector[N] y;  // Punteggio in ciascuna prova\n}\ntransformed data {\n    real y_mean = mean(y);  // Media dei dati osservati\n    real y_sd = sd(y);  // Deviazione standard dei dati osservati\n}\nparameters {\n    real mu_raw;  // Parametro latente standardizzato per mu\n    real&lt;lower=0&gt; sigma_raw;  // Parametro latente standardizzato per sigma\n    real&lt;lower=1&gt; nu;  // Gradi di libert√† per la distribuzione t di Student\n}\ntransformed parameters {\n    real mu;  // Media sulla scala originale\n    real&lt;lower=0&gt; sigma;  // Deviazione standard sulla scala originale\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Distribuzioni a priori non centrate\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    nu ~ exponential(1.0 / 30.0);  // Prior esponenziale per i gradi di libert√†\n    // Verosimiglianza\n    y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = student_t_rng(nu, mu, sigma);\n    }\n}\n\n\n\n\ntrace_student = model_student.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori e le tracce dei parametri del nuovo modello.\n\n_ = az.plot_trace(trace_student, var_names=['mu', 'sigma', 'nu'])\n\n\n\n\n\n\n\n\nConvertiamo i risultati in un oggetto InferenceData di ArviZ.\n\nidata = az.from_cmdstanpy(\n    posterior=trace_student,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nGeneriamo la distribuzione predittiva a posteriori.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nLa figura illustra che la situazione √® analoga a quella del caso gaussiano. Questo non √® sorprendente, dato che i dati relativi all‚Äôaltezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l‚Äôimpiego della distribuzione t di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto.\n\naz.summary(trace_student, var_names=['mu', 'sigma', 'nu'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.57\n0.42\n153.85\n155.40\n0.00\n0.00\n8798.72\n6040.50\n1.0\n\n\nsigma\n7.63\n0.30\n7.08\n8.21\n0.00\n0.00\n7145.94\n6226.65\n1.0\n\n\nnu\n62.39\n36.10\n11.40\n129.62\n0.41\n0.31\n7870.31\n5565.90\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/07_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "title": "50¬† Inferenza bayesiana su una media",
    "section": "50.5 Commenti e considerazioni finali",
    "text": "50.5 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato il metodo per calcolare l‚Äôintervallo di credibilit√† per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l‚Äôinferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/07_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "title": "50¬† Inferenza bayesiana su una media",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\narviz     : 0.18.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html",
    "href": "chapters/mcmc/08_stan_two_groups.html",
    "title": "51¬† Confronto tra due gruppi",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® di ampliare la discussione del Capitolo 50, affrontando il confronto tra le medie di due gruppi indipendenti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "href": "chapters/mcmc/08_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.1 Stima bayesiana e test dell‚Äôipotesi nulla",
    "text": "51.1 Stima bayesiana e test dell‚Äôipotesi nulla\nSpesso, ci troviamo ad affrontare la necessit√† di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo √® maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, √® fondamentale utilizzare un modello statistico, poich√© le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o pi√π gruppi √® quello di utilizzare un test statistico. Questo approccio prevede l‚Äôindividuazione di un‚Äôipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l‚Äôutilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L‚Äôipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significativit√† adottare) √® spesso arbitraria e basata su convenzioni piuttosto che sulla specificit√† del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l‚Äôipotesi nulla (Goodman, 1999).\nUn approccio pi√π informativo ed efficace per il confronto tra gruppi √® quello basato sulla stima invece che sul test dell‚Äôipotesi nulla, ed √® guidato dalla probabilit√† bayesiana anzich√© dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio √® intrinsecamente pi√π informativo. Inoltre, viene inclusa una stima dell‚Äôincertezza associata a tale differenza, che tiene conto sia dell‚Äôincertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell‚Äôincertezza causata dalla variabilit√† intrinseca del sistema (incertezza aleatoria).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#un-esempio-illustrativo",
    "href": "chapters/mcmc/08_stan_two_groups.html#un-esempio-illustrativo",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.2 Un esempio illustrativo",
    "text": "51.2 Un esempio illustrativo\nIn questo esempio, l‚Äôobiettivo √® stimare la differenza tra le medie del quoziente di intelligenza dei bambini di due gruppi distinti in base al livello di scolarit√† della madre. Il primo gruppo include i bambini la cui madre non ha completato le scuole superiori, mentre il secondo gruppo comprende quelli la cui madre ha ottenuto il diploma superiore. Per questo, useremo i dati kidiq e un modello bayesiano al fine di ottenere una stima affidabile della differenza tra le medie dei due gruppi nella popolazione.\nI dati utilizzati sono forniti da Gelman e Hill (2007) e costituiscono un sottocampione estratto dal National Longitudinal Survey of Youth.\nLeggiamo i dati.\n\ndf = pd.read_stata(\"../../data/kidiq.dta\")\ndf.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nIl dataset contiene le seguenti colonne:\n\n‚Äúkid_score‚Äù: il quoziente intellettivo (QI) dei bambini. √à una misura dell‚Äôintelligenza del bambino.\n‚Äúmom_hs‚Äù: una variabile binaria che indica se la madre del bambino ha completato o meno la scuola superiore. Pu√≤ assumere i valori 0 o 1, dove 0 rappresenta ‚Äúno‚Äù (la madre non ha completato la scuola superiore) e 1 rappresenta ‚Äús√¨‚Äù (la madre ha completato la scuola superiore).\n\nCi sono 93 bambini la cui madre non ha completato la scuola superiore e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\ndf.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nLe statistiche descrittive si ottengono nel modo seguente.\n\ndf[\"kid_score\"].mean()\n\n86.79723502304148\n\n\n\nsummary_stats = [np.mean, stat.stdev]\ndf.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1859022749.py:2: FutureWarning: The provided callable &lt;function mean at 0x11c1f6660&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  df.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\nI bambini la cui madre ha completato le superiori tendono ad avere un QI maggiore di 11.8 punti rispetto ai bambini la cui madre non ha concluso le superiori.\n\n89.319648 - 77.548387\n\n11.771260999999996\n\n\nCreiamo due vettori che contengono il QI dei bambini dei due gruppi.\n\n# Vector of kid_score when mom_hs is 1\nkid_score_mom_hs_1 = df[df[\"mom_hs\"] == 1][\"kid_score\"]\n\n# Vector of kid_score when mom_hs is 0\nkid_score_mom_hs_0 = df[df[\"mom_hs\"] == 0][\"kid_score\"]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#dimensione-delleffetto",
    "href": "chapters/mcmc/08_stan_two_groups.html#dimensione-delleffetto",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.3 Dimensione dell‚Äôeffetto",
    "text": "51.3 Dimensione dell‚Äôeffetto\nNel caso presente, la differenza tra le medie dei due gruppi √® di 11.8 punti sulla scala del QI, e potrebbe sembrare un risultato rilevante, considerando che la metrica del QI √® facilmente interpretabile. Tuttavia, √® importante notare che il test utilizzato in questo studio non √® il WISC, che ha una distribuzione normale con media 100 e deviazione standard 15, ma il test PIAT.\nIn generale, √® difficile comprendere il significato di una differenza tra le medie di due gruppi quando viene presentata solo come valore assoluto, soprattutto quando le varianze dei gruppi sono diverse. Per ottenere una misura pi√π informativa, √® necessario considerare sia la differenza tra le medie dei gruppi che l‚Äôincertezza associata a queste stime delle medie della popolazione. L‚Äôindice statistico che soddisfa questo scopo √® noto come ‚Äúdimensione dell‚Äôeffetto‚Äù (effect size).\nLa dimensione dell‚Äôeffetto √® una misura della forza dell‚Äôassociazione osservata, che tiene conto sia della grandezza della differenza tra i gruppi attesi che dell‚Äôincertezza sui dati. Tra gli indici pi√π comunemente utilizzati per quantificare la dimensione dell‚Äôeffetto, vi √® l‚Äôindice \\(d\\) di Cohen.\nNel caso di due medie, questo indice √® dato da:\n\\[\nd={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{s}},\n\\]\nladdove\n\\[\ns={\\sqrt {\\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}\n\\]\ne la varianza di ciascun gruppo √® calcolata come\n\\[\ns_{1}^{2}={\\frac {1}{n_{1}-1}}\\sum _{i=1}^{n_{1}}(x_{1,i}-{\\bar {x}}_{1})^{2}.\n\\]\nSolitamente, l‚Äôindice \\(d\\) di Cohen si interpreta usando la metrica seguente:\n\n\n\nDimensione dell‚Äôeffetto\n\\(d\\)\n\n\n\n\nVery small\n0.01\n\n\nSmall\n0.20\n\n\nMedim\n0.50\n\n\nLarge\n0.80\n\n\nVery large\n1.20\n\n\nHuge\n2.0\n\n\n\nPer una trattazione bayesiana della stima della dimensione dell‚Äôeffetto, si veda Kruschke (2014).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-bayesiano",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-bayesiano",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.4 Modello bayesiano",
    "text": "51.4 Modello bayesiano\nIl modello bayesiano per il confronto tra le medie di due gruppi indipendenti comprende la definizione della verosimiglianza per i dati di ciascun gruppo e la descrizione delle distribuzioni a priori dei parametri rilevanti. Inoltre, in questo caso, abbiamo incluso anche la stima della dimensione dell‚Äôeffetto, che ci permette di valutare la forza dell‚Äôassociazione osservata tra i gruppi, tenendo conto dell‚Äôincertezza sui dati.\nCreiamo un dizonario con i dati rilevanti.\n\nstan_data = {\n    'N1': len(kid_score_mom_hs_1), \n    'N2': len(kid_score_mom_hs_0), \n    'y1': kid_score_mom_hs_1,\n    'y2': kid_score_mom_hs_0\n}\nstan_data\n\n{'N1': 341,\n 'N2': 93,\n 'y1': 0       65\n 1       98\n 2       85\n 3       83\n 4      115\n       ... \n 425    102\n 426    104\n 430     76\n 432     88\n 433     70\n Name: kid_score, Length: 341, dtype: int32,\n 'y2': 5       98\n 14     102\n 19     101\n 24      99\n 33     106\n       ... \n 422    100\n 427     59\n 428     93\n 429     94\n 431     50\n Name: kid_score, Length: 93, dtype: int32}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-stan",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-stan",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.5 Modello Stan",
    "text": "51.5 Modello Stan\nPer analizzare questi dati ci serviremo del seguente modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'kid-score.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response times (group 1)\n  vector[N2] y2;  // response times (group 2)\n}\n\nparameters {\n  real mu_1;  // mean of group 1\n  real mu_2;  // mean of group 2\n  real&lt;lower=0&gt; sigma_1;  // standard deviation of group 1\n  real&lt;lower=0&gt; sigma_2;  // standard deviation of group 2\n}\n\ntransformed parameters {\n  real delta;  // difference in means\n  real cohen_d;  // Cohen's d effect size\n  delta = mu_1 - mu_2;\n  cohen_d = delta / sqrt((sigma_1^2 + sigma_2^2) / 2);\n}\n\nmodel {\n  // Priors\n  mu_1 ~ normal(80, 20);  // Prior for mean of group 1\n  mu_2 ~ normal(80, 20);  // Prior for mean of group 2\n  sigma_1 ~ normal(0, 10);  // Prior for standard deviation of group 1\n  sigma_2 ~ normal(0, 10);  // Prior for standard deviation of group 2\n\n  // Likelihood\n  y1 ~ normal(mu_1, sigma_1);\n  y2 ~ normal(mu_2, sigma_2);\n}\n\ngenerated quantities {\n  vector[N1] y1_rep;  // replicated data for group 1\n  vector[N2] y2_rep;  // replicated data for group 2\n  for (i in 1:N1) {\n    y1_rep[i] = normal_rng(mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2_rep[i] = normal_rng(mu_2, sigma_2);\n  }\n}\n\n\n\nNel nostro modello: - N1 √® il numero di osservazioni nel primo gruppo (bambini le cui madri hanno completato le superiori) - N2 √® il numero di osservazioni nel secondo gruppo (bambini le cui madri non hanno completato le superiori) - y1 √® un vettore contenente i valori di QI per il primo gruppo - y2 √® un vettore contenente i valori di QI per il secondo gruppo\n\n51.5.1 Spiegazione del modello\n\n51.5.1.1 Parametri\n\nmu_1 e mu_2: Rappresentano le medie dei valori di QI per i due gruppi.\nsigma_1 e sigma_2: Rappresentano le deviazioni standard dei valori dei QI per i due gruppi.\n\n\n\n51.5.1.2 Parametri trasformati\n\ndelta: √à la differenza tra le medie dei due gruppi (mu_1 - mu_2).\ncohen_d: √à la dimensione dell‚Äôeffetto di Cohen, che quantifica la differenza tra i gruppi in unit√† di deviazione standard.\n\n\n\n51.5.1.3 Prior\nImpostiamo delle prior per i parametri:\nmu_1 ~ normal(80, 20);\nmu_2 ~ normal(80, 20);\nsigma_1 ~ normal(0, 10);\nsigma_2 ~ normal(0, 10);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri. Per esempio, ci aspettiamo che i QI medi siano intorno a 80, ma con una certa variabilit√†.\n\n\n51.5.1.4 Likelihood\ny1 ~ normal(mu_1, sigma_1);\ny2 ~ normal(mu_2, sigma_2);\nQuesta parte del modello descrive come i dati osservati (y1 e y2) sono generati, date le medie e le deviazioni standard per ciascun gruppo. Assumiamo che i valori del QI seguano una distribuzione normale in ciascun gruppo.\n\n\n\n51.5.2 Quantit√† generate\ny1_rep[i] = normal_rng(mu_1, sigma_1);\ny2_rep[i] = normal_rng(mu_2, sigma_2);\nQueste righe generano dati ‚Äúreplicati‚Äù basati sul modello stimato. Questi possono essere utilizzati per il controllo del modello (posterior predictive checks).\n\n\n51.5.3 Interpretazione dei risultati\n\nmu_1 e mu_2: Ci dicono i valori QI medi stimati per ciascun gruppo.\nsigma_1 e sigma_2: Ci dicono quanto variano i valori del QI all‚Äôinterno di ciascun gruppo.\ndelta: Ci dice quanto √® grande la differenza nei valori dei QI medi tra i due gruppi.\ncohen_d: Ci fornisce una misura standardizzata della dimensione dell‚Äôeffetto.\n\n\n\n51.5.4 Conclusione\nQuesto modello ci permette di:\n\nStimare i valori dei QI medi e la loro variabilit√† per ciascun gruppo.\nQuantificare la differenza tra i gruppi e la sua incertezza.\nCalcolare una misura standardizzata della dimensione dell‚Äôeffetto (Cohen‚Äôs d).\nGenerare previsioni basate sul modello per future osservazioni.\n\nIl vantaggio principale di questo approccio bayesiano √® che otteniamo distribuzioni di probabilit√† complete per tutti i parametri di interesse, permettendoci di fare affermazioni probabilistiche sulla differenza tra i gruppi e sulla dimensione dell‚Äôeffetto.\nEseguiamo il campionamento MCMC:\n\nsample = model.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:30:52 - cmdstanpy - INFO - CmdStan start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] start processing\n10:30:52 - cmdstanpy - INFO - Chain [2] start processing\n10:30:52 - cmdstanpy - INFO - Chain [3] start processing\n10:30:52 - cmdstanpy - INFO - Chain [4] start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] done processing\n10:30:52 - cmdstanpy - INFO - Chain [3] done processing\n10:30:52 - cmdstanpy - INFO - Chain [2] done processing\n10:30:52 - cmdstanpy - INFO - Chain [4] done processing\n10:30:52 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\n    Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(\n    sample, \n    figsize=(9, 12), \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    divergences=\"bottom\"\n)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1925110735.py:7: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe distribuzioni predittive a posteriori sono adeguate, senza essere perfette.\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y1_rep'], \n    observed_data={\"y1\": stan_data[\"y1\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y1\": \"y1_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y2_rep'], \n    observed_data={\"y2\": stan_data[\"y2\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y2\": \"y2_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(\n    sample, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.28\n1.04\n87.33\n91.18\n0.02\n0.01\n3990.38\n2947.67\n1.0\n\n\nmu_2\n77.61\n2.27\n73.61\n82.01\n0.03\n0.02\n4317.58\n2940.56\n1.0\n\n\nsigma_1\n19.03\n0.73\n17.70\n20.42\n0.01\n0.01\n4729.21\n3162.76\n1.0\n\n\nsigma_2\n22.27\n1.63\n19.35\n25.38\n0.02\n0.02\n4419.97\n2908.53\n1.0\n\n\ndelta\n11.67\n2.47\n6.89\n16.32\n0.04\n0.03\n4346.03\n2887.27\n1.0\n\n\ncohen_d\n0.56\n0.12\n0.33\n0.78\n0.00\n0.00\n4334.34\n2953.62\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-robusto",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-robusto",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.6 Modello Robusto",
    "text": "51.6 Modello Robusto\nUn modello bayesiano robusto per il confronto tra due medie indipendenti pu√≤ gestire deviazioni standard disuguali e outlier sostituendo la verosimiglianza normale con quella della distribuzione t di Student. Utilizzare una distribuzione t di Student al posto di una normale rende il modello pi√π resistente agli outlier. La distribuzione t di Student ha code pi√π pesanti rispetto alla normale, il che significa che √® meno influenzata da valori estremi nei dati. Questo √® particolarmente utile quando si sospetta la presenza di outlier nei dati o quando le deviazioni standard tra i gruppi sono disuguali. In questo modo, il modello bayesiano robusto offre stime pi√π affidabili delle medie e delle deviazioni standard dei gruppi, nonch√© della differenza tra le medie e della dimensione dell‚Äôeffetto.\n\nstan_file_t = os.path.join(project_directory, 'stan', 'kid-score-t.stan')\nmodel_t = CmdStanModel(stan_file=stan_file_t)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_t = model_t.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:31:20 - cmdstanpy - INFO - CmdStan start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] start processing\n10:31:20 - cmdstanpy - INFO - Chain [2] start processing\n10:31:20 - cmdstanpy - INFO - Chain [3] start processing\n10:31:20 - cmdstanpy - INFO - Chain [4] start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] done processing\n10:31:20 - cmdstanpy - INFO - Chain [3] done processing\n10:31:20 - cmdstanpy - INFO - Chain [2] done processing\n10:31:20 - cmdstanpy - INFO - Chain [4] done processing\n10:31:20 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nNel caso presente, usare un modello robusto non produce nessuna differenza rispetto al modello precedente in quanto non ci sono deviazoni importanti rispetto alla gaussianit√† e le due deviazioni standard sono simili.\n\naz.summary(\n    sample_t, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.49\n1.07\n87.43\n91.37\n0.02\n0.01\n3892.59\n3003.83\n1.0\n\n\nmu_2\n78.39\n2.29\n74.04\n82.63\n0.05\n0.03\n2486.44\n2273.07\n1.0\n\n\nsigma_1\n18.43\n0.77\n17.04\n19.94\n0.01\n0.01\n3278.45\n2545.50\n1.0\n\n\nsigma_2\n21.71\n1.62\n18.77\n24.82\n0.03\n0.02\n3175.33\n2299.83\n1.0\n\n\ndelta\n11.11\n2.50\n6.40\n15.82\n0.05\n0.04\n2487.74\n2084.50\n1.0\n\n\ncohen_d\n0.55\n0.13\n0.33\n0.81\n0.00\n0.00\n2496.90\n2123.93\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-con-iper-priors",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-con-iper-priors",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.7 Modello con Iper-priors",
    "text": "51.7 Modello con Iper-priors\nIl seguente modello bayesiano per il confronto tra due medie indipendenti utilizza una distribuzione di Student‚Äôs t per gestire deviazioni standard disuguali e outlier. Inoltre, include iper-priors per una maggiore flessibilit√† nella definizione dei parametri delle distribuzioni a priori, che vengono stimate dai dati. Questo approccio permette di incorporare in modo pi√π efficace le incertezze sui parametri dei priors stessi, migliorando la robustezza del modello.\n\nstan_file_h = os.path.join(project_directory, 'stan', 'kid-score-h.stan')\nmodel_h = CmdStanModel(stan_file=stan_file_h)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_h = model_h.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=2_000, iter_warmup=1_000,\n    show_progress=False, show_console=False\n)\n\n10:31:27 - cmdstanpy - INFO - CmdStan start processing\n10:31:27 - cmdstanpy - INFO - Chain [1] start processing\n10:31:27 - cmdstanpy - INFO - Chain [2] start processing\n10:31:27 - cmdstanpy - INFO - Chain [3] start processing\n10:31:27 - cmdstanpy - INFO - Chain [4] start processing\n10:31:28 - cmdstanpy - INFO - Chain [1] done processing\n10:31:28 - cmdstanpy - INFO - Chain [4] done processing\n10:31:28 - cmdstanpy - INFO - Chain [2] done processing\n10:31:28 - cmdstanpy - INFO - Chain [3] done processing\n10:31:28 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n10:31:28 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 1 had 25 divergent transitions (1.2%)\n    Chain 2 had 8 divergent transitions (0.4%)\n    Chain 3 had 24 divergent transitions (1.2%)\n    Chain 4 had 12 divergent transitions (0.6%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\nAnche in questo caso, la risposta non cambia:\n\naz.summary(\n    sample_h, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.52\n1.03\n87.65\n91.54\n0.01\n0.01\n8653.78\n6400.92\n1.0\n\n\nmu_2\n78.30\n2.29\n73.95\n82.52\n0.03\n0.02\n5688.16\n5777.55\n1.0\n\n\nsigma_1\n18.43\n0.79\n16.97\n19.94\n0.01\n0.01\n7954.84\n5392.71\n1.0\n\n\nsigma_2\n21.88\n1.65\n18.88\n25.08\n0.02\n0.01\n9745.94\n5250.42\n1.0\n\n\ndelta\n11.22\n2.50\n6.51\n15.83\n0.03\n0.02\n5590.51\n6029.02\n1.0\n\n\ncohen_d\n0.56\n0.13\n0.32\n0.79\n0.00\n0.00\n5626.06\n5815.05\n1.0\n\n\n\n\n\n\n\n\nIl nostro obiettivo √® comprendere se le medie dei due gruppi sono diverse, e l‚Äôincertezza associata alla stima a posteriori del parametro delta √® fondamentale per rispondere a questa domanda. Se l‚Äôintervallo di credibilit√† associato a delta non include lo 0, allora possiamo concludere con un certo grado di sicurezza che le medie dei due gruppi sono diverse. In altre parole, se l‚Äôintervallo di credibilit√† non contiene lo 0, allora ci sono prove convincenti che le medie dei due gruppi sono diverse.\nNel caso presente, l‚Äôintervallo di credibilit√† al 94% non include lo 0. Pertanto, possiamo concludere, con un livello di sicurezza soggettivo del 94%, che il QI dei bambini le cui madri hanno completato le scuole superiori tende ad essere pi√π elevato rispetto a quello dei bambini le cui madri non hanno completato le scuole superiori.\n\n_ = az.plot_posterior(sample_h, var_names=\"delta\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nLa figura seguente mostra la distribuzione a posteriori della grandezza dell‚Äôeffetto.\n\n_ = az.plot_posterior(sample_h, var_names=\"cohen_d\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nPossiamo dunque concludere che, per ci√≤ che concerne l‚Äôeffetto della scolarit√† della madre sul quoziente di intelligenza del bambino, la dimensione dell‚Äôeffetto √® ‚Äúmedia‚Äù.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/mcmc/08_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.8 Verifica di ipotesi bayesiana",
    "text": "51.8 Verifica di ipotesi bayesiana\nCome ulteriore approfondimento di questa analisi statistica, possiamo esaminare l‚Äôapproccio bayesiano equivalente al test di ipotesi tradizionale.\nDopo aver ottenuto un campione dalla distribuzione a posteriori del parametro di interesse \\(\\mu\\) per ciascun gruppo, possiamo porci la domanda: qual √® la probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo? Per rispondere a questa domanda, utilizzeremo campioni casuali dalle distribuzioni a posteriori dei parametri. Confronteremo le coppie di valori campionati dalle due distribuzioni a posteriori del parametro di interesse e calcoleremo la media di tali confronti. Questo ci fornir√† un‚Äôindicazione sulla probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo, basandoci sulla distribuzione a posteriori dei parametri stimati dal modello.\nPer eseguire un test d‚Äôipotesi per calcolare la probabilit√† che $ _1 &gt; _2 $ utilizzando il modello Stan fornito e cmdstanpy, √® necessario estrarre i campioni posteriori per i parametri \\(\\mu_1\\) e \\(\\mu_2\\) dopo aver adattato il modello. Successivamente, √® possibile calcolare la probabilit√† basandosi sui campioni posteriori. Ad esempio, ci possiamo chiedere quale sia la probabilit√† che un bambino la cui madre ha completato la scuola superiore abbia un QI maggiore di un bambino la cui madre non ha completato la scuola superiore.\n\n# Extract the posterior samples for mu_1 and mu_2\nposterior = sample_h.draws_pd()\nposterior['mu_1'] = posterior['mu_2'] + posterior['delta']\n\n# Compute the probability that mu_1 &gt; mu_2\nprob_mu1_greater_mu2 = np.mean(posterior['mu_1'] &gt; posterior['mu_2'])\n\nprint(f\"Probability that mu_1 &gt; mu_2: {prob_mu1_greater_mu2:.4f}\")\n\nProbability that mu_1 &gt; mu_2: 1.0000\n\n\nUna tale probabilit√† √® effettivamente uguale a 1 il che conferma il risultato precedente, ovvero l‚Äôiportanza del livello di istruzione della madre per il QI del figlio.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/08_stan_two_groups.html#commenti-e-considerazioni-finali",
    "title": "51¬† Confronto tra due gruppi",
    "section": "51.9 Commenti e considerazioni finali",
    "text": "51.9 Commenti e considerazioni finali\nIn questo capitolo abbiamo esaminato la procedura bayesiana per calcolare la distribuzione a posteriori della differenza tra le medie di due gruppi indipendenti. Inoltre, abbiamo esplorato il calcolo della dimensione dell‚Äôeffetto in termini bayesiani. Nell‚Äôesempio trattato, abbiamo considerato il caso in cui la verosimiglianza √® descritta da una distribuzione Gaussiana. Tuttavia, va sottolineato che la scelta di una distribuzione specifica per la verosimiglianza non √® vincolante nella statistica bayesiana. √à possibile utilizzare qualsiasi distribuzione di probabilit√†, purch√© sia adeguata ai dati del campione.\nNel caso del confronto tra le medie di due gruppi indipendenti, una distribuzione molto utilizzata √® la distribuzione \\(t\\) di Student. Questa distribuzione √® particolarmente vantaggiosa quando si desidera condurre un‚Äôanalisi statistica ‚Äúrobusta‚Äù, ovvero un‚Äôanalisi che non sia influenzata da osservazioni anomale o outlier presenti nei dati. Per questo motivo, la distribuzione \\(t\\) di Student √® spesso preferita quando si lavora con dati che potrebbero contenere valori anomali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/08_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "title": "51¬† Confronto tra due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBland, J Martin, e Douglas G Altman. 2011. ¬´Comparisons within randomised groups can be very misleading¬ª. Bmj 342.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_hier_beta_binom.html",
    "href": "chapters/mcmc/09_stan_hier_beta_binom.html",
    "title": "52¬† Modello gerarchico beta-binomiale con Stan",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo il concetto di modellazione gerarchica nel contesto Bayesiano. Partiamo da un esempio semplice per introdurre la stima statistica: consideriamo un‚Äôurna con palline di colore blu e rosso. Estraendo un campione di 10 palline, possiamo stimare la proporzione di palline blu presenti nell‚Äôurna. Questo scenario classico ci introduce ai fondamenti della stima statistica.\nImmaginiamo ora una situazione pi√π complessa: abbiamo a disposizione una grande urna che contiene al suo interno 10 urne pi√π piccole, ciascuna delle quali √® riempita con proprie palline blu e rosse. Supponiamo di scegliere 7 di queste urne minori ed estrarre 10 palline da ciascuna. La questione √®: come analizziamo questi dati?\nUna possibile soluzione √® trattare ogni urna piccola come un‚Äôentit√† completamente indipendente, ripetendo il problema statistico base per sette volte. Questo metodo, tuttavia, non √® ideale perch√© assume che non ci sia nessuna correlazione tra le urne piccole, ignorando il fatto che tutte provengono da una urna comune pi√π grande che potrebbe influenzarne il contenuto.\nUn altro metodo potrebbe essere quello di ignorare completamente la presenza delle urne minori e focalizzarsi unicamente sulla stima della proporzione totale di palline blu nell‚Äôurna grande. Questo approccio, per√≤, trascura completamente la struttura gerarchica dei dati, ossia il fatto che le palline sono organizzate in urne separate.\nIl metodo pi√π appropriato per analizzare questa situazione √® attraverso la modellazione gerarchica. Con questo approccio, ci proponiamo di stimare non solo la proporzione di palline blu in ogni urna minore, ma anche di comprendere quanto le urne sono correlate tra loro. L‚Äôurna grande funge da modello generativo per le urne pi√π piccole, e comprendere questa relazione sottostante ci consente di fare previsioni pi√π accurate sulla proporzione di palline blu in ogni urna minore, riconoscendo e sfruttando la struttura gerarchica dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "href": "chapters/mcmc/09_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "title": "52¬† Modello gerarchico beta-binomiale con Stan",
    "section": "52.1 Analisi bayesiana della ‚Äúterapia tattile‚Äù",
    "text": "52.1 Analisi bayesiana della ‚Äúterapia tattile‚Äù\nEsaminiamo un problema presentato nel lavoro di {cite:t}doing_bayesian_data_an riguardante la ‚Äúterapia tattile‚Äù (Therapeutic Touch), una pratica infermieristica incentrata sulla manipolazione del presunto ‚Äúcampo energetico‚Äù di un paziente. Nonostante la sua prevalenza nelle scuole di infermieristica e negli ospedali negli Stati Uniti, come riportato da {cite:t}rosa1998close, evidenze empiriche a supporto della sua efficacia sono scarse o assenti.\nIl focus dell‚Äôindagine di {cite:t}rosa1998close √® una delle asserzioni cardine degli operatori di terapia tattile: la presunta capacit√† di percepire i campi energetici senza contatto visivo. Per testare questa affermazione, √® stato progettato un esperimento in cui gli operatori ponevano le loro mani attraverso un pannello che bloccava la visione. In ciascuna prova, un esaminatore, seguendo l‚Äôesito di un lancio di moneta, posizionava la sua mano sopra una delle mani dell‚Äôoperatore. L‚Äôoperatore doveva quindi identificare quale delle sue mani era stata ‚Äúselezionata‚Äù dall‚Äôesaminatore. Ogni tentativo √® stato classificato come ‚Äúcorretto‚Äù o ‚Äúerrato‚Äù.\nL‚Äôunit√† di osservazione in questo esperimento √® costituita da un set di 10 prove per operatore. In totale, lo studio ha coinvolto 21 operatori, con sette di loro sottoposti a retest dopo circa un anno. I dati di retest sono stati trattati come entit√† indipendenti, portando a un campione effettivo di 28 osservazioni. La metrica di interesse √® la proporzione di risposte corrette per ciascun operatore, con una proporzione attesa di 0.50 sotto l‚Äôipotesi nulla di performance casuale.\nLa domanda della ricerca centrale √® se il campione nel suo complesso √® in grado di ottenere una prestazione superiore a quella attesa in base al caso soltanto e, inoltre, se vi sono variazioni nelle prestazioni individuali.\nInizieremo importando i dati forniti da {cite:t}doing_bayesian_data_an.\n\n# Define the URL of the CSV file on GitHub\nurl = \"https://raw.githubusercontent.com/boboppie/kruschke-doing_bayesian_data_analysis/master/2e/TherapeuticTouchData.csv\"\n# Download the content of the CSV file\nresponse = requests.get(url)\ntt_dat = pd.read_csv(StringIO(response.text))\nprint(tt_dat.head())\n\n   y    s\n0  1  S01\n1  0  S01\n2  0  S01\n3  0  S01\n4  0  S01\n\n\n\ntt_dat.shape\n\n(280, 2)\n\n\nNella colonna y, il valore 1 indica una risposta corretta, mentre 0 indica una risposta errata. La seconda colonna contiene il codice identificativo di ciascun operatore.\nCalcoliamo la proporzione di risposte corrette per ciascun operatore.\n\ntt_agg = tt_dat.groupby(\"s\").agg(proportion_correct=(\"y\", \"mean\")).reset_index()\ntt_agg\n\n\n\n\n\n\n\n\n\ns\nproportion_correct\n\n\n\n\n0\nS01\n0.1\n\n\n1\nS02\n0.2\n\n\n2\nS03\n0.3\n\n\n3\nS04\n0.3\n\n\n4\nS05\n0.3\n\n\n5\nS06\n0.3\n\n\n6\nS07\n0.3\n\n\n7\nS08\n0.3\n\n\n8\nS09\n0.3\n\n\n9\nS10\n0.3\n\n\n10\nS11\n0.4\n\n\n11\nS12\n0.4\n\n\n12\nS13\n0.4\n\n\n13\nS14\n0.4\n\n\n14\nS15\n0.4\n\n\n15\nS16\n0.5\n\n\n16\nS17\n0.5\n\n\n17\nS18\n0.5\n\n\n18\nS19\n0.5\n\n\n19\nS20\n0.5\n\n\n20\nS21\n0.5\n\n\n21\nS22\n0.5\n\n\n22\nS23\n0.6\n\n\n23\nS24\n0.6\n\n\n24\nS25\n0.7\n\n\n25\nS26\n0.7\n\n\n26\nS27\n0.7\n\n\n27\nS28\n0.8\n\n\n\n\n\n\n\n\nCostruiamo un modello gerarchico partendo dall‚Äôipotesi che il numero di risposte corrette di ciascun operatore sia modellato da una variabile casuale binomiale. Per ciascuno dei ventotto operatori, possiamo esprimere questo come segue:\n\\[\ny_i \\sim \\text{Binomial}(n_i, p_i),\n\\]\ndove \\(i = 0, \\dots, 27\\).\nPer modellare la distribuzione a priori del parametro sconosciuto \\(p_i\\), possiamo utilizzare una distribuzione Beta con parametri \\(a\\) e \\(b\\) ‚Äì si veda {cite:t}doingbayesian:\n\\[\np_i \\sim \\text{Beta}(a, b).\n\\]\n√à importante notare che gli iperparametri \\(a\\) e \\(b\\) sono condivisi tra tutti gli operatori, caratteristica che definisce un modello gerarchico.\nSe \\(a\\) e \\(b\\) sono noti, la distribuzione a posteriori del parametro \\(p\\) per ciascun operatore, dati i risultati osservati \\(y_i\\), √® anch‚Äôessa una distribuzione Beta:\n\\[\np_i \\mid y_i \\sim \\text{Beta}(a + y_i, b + n_i - y_i).\n\\]\nNel caso pi√π generale, dove gli iperparametri \\(a\\) e \\(b\\) sono incogniti, √® necessario stabilire una distribuzione a priori anche per questi. Nell‚Äôesempio seguente, useremo i seguenti prior:\n\\[\na \\sim \\text{Gamma}(8, 12)\\\\\nb \\sim \\text{Gamma}(27, 5)\n\\]\nPer applicare il modello gerarchico descritto sopra ai dati del therapeutic touch, iniziamo a calcolare il numero di risposte corrette di ciascun operatore.\n\nresult = tt_dat.groupby(\"s\")[\"y\"].sum().reset_index()\ny = result[\"y\"]\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreiamo il vettore N che fornisce il numero di prove per ciascun operatore.\n\nN = tt_dat.groupby(\"s\")[\"y\"].count()\n\nEsaminiamo dunque i dati a disposizione.\n\nprint(*N)\n\n10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n\n\n\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreaiamo un dizionario con i dati necessari per Stan.\n\ndata = {\n    \"N\": 28,\n    \"y\": y.tolist(),\n    \"n_trials\": N.tolist()\n}\n\nprint(data)\n\n{'N': 28, 'y': [1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 7, 8], 'n_trials': [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_hier_beta_binom.html#modello-stan",
    "href": "chapters/mcmc/09_stan_hier_beta_binom.html#modello-stan",
    "title": "52¬† Modello gerarchico beta-binomiale con Stan",
    "section": "52.2 Modello Stan",
    "text": "52.2 Modello Stan\nLeggiamo il codice Stan che implementa il modello descritto nel capitolo {ref}hier_beta_binom_model.\n\nstan_file = os.path.join(project_directory, \"stan\", \"h_beta_binom_model.stan\")\n\nwith open(stan_file, \"r\") as f:\n    print(f.read())\n\ndata {\n  int&lt;lower=0&gt; N;  // Number of participants\n  array[N] int&lt;lower=0&gt; y;  // Number of successes for each participant\n  array[N] int&lt;lower=0&gt; n_trials;  // Number of trials for each participant\n}\n\nparameters {\n  real&lt;lower=0&gt; alpha;  // Alpha parameter for the Beta distribution\n  real&lt;lower=0&gt; beta;   // Beta parameter for the Beta distribution\n  array[N] real&lt;lower=0, upper=1&gt; p;  // Success probability for each participant\n}\n\nmodel {\n  // Priors\n  alpha ~ gamma(8, 2);\n  beta ~ gamma(27, 5);\n  \n  // Each participant's success probability follows a Beta distribution\n  p ~ beta(alpha, beta);\n  \n  // Likelihood of the observed data\n  for (i in 1:N) {\n    y[i] ~ binomial(n_trials[i], p[i]);\n  }\n}\n\ngenerated quantities {\n  real overall_p = alpha / (alpha + beta);  // Calculate the mean success probability\n}\n\n\n\nNel nostro modello: - N √® il numero totale di partecipanti - y √® un array che contiene il numero di successi per ogni partecipante - n_trials √® un array che contiene il numero di prove per ogni partecipante\n\n52.2.1 Il concetto di gerarchia\nIl modello √® chiamato ‚Äúgerarchico‚Äù perch√© considera due livelli: 1. Il livello individuale: ogni partecipante ha la propria probabilit√† di successo 2. Il livello di gruppo: c‚Äô√® una distribuzione generale che descrive come variano le probabilit√† di successo tra i partecipanti\n\n\n52.2.2 Spiegazione del modello\n\n52.2.2.1 Parametri\n\np: √à un array che contiene la vera probabilit√† di successo per ogni partecipante.\nalpha e beta: Sono i parametri che definiscono la distribuzione Beta, che descrive come variano le probabilit√† di successo tra i partecipanti.\n\n\n\n52.2.2.2 Prior\nImpostiamo delle prior per alpha e beta:\nalpha ~ gamma(8, 2);\nbeta ~ gamma(27, 5);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri.\n\n\n52.2.2.3 Il cuore del modello\np ~ beta(alpha, beta);\nQuesta riga √® il cuore del modello gerarchico. Dice che la probabilit√† di successo di ogni partecipante (p) segue una distribuzione Beta, i cui parametri sono alpha e beta. Questo crea un legame tra tutti i partecipanti: le loro prestazioni individuali sono considerate come variazioni attorno a una tendenza generale del gruppo.\n\n\n52.2.2.4 Likelihood\nfor (i in 1:N) {\n  y[i] ~ binomial(n_trials[i], p[i]);\n}\nQuesta parte del modello descrive come i dati osservati (y) sono generati, dato il numero di prove (n_trials) e la vera probabilit√† di successo (p) per ogni partecipante.\n\n\n\n52.2.3 Quantit√† generate\nreal overall_p = alpha / (alpha + beta);\nQuesta riga calcola la probabilit√† di successo media per l‚Äôintero gruppo.\n\n\n52.2.4 Conclusione\nQuesto modello ci permette di: 1. Stimare la probabilit√† di successo individuale per ogni partecipante 2. Comprendere come queste probabilit√† variano nel gruppo 3. Ottenere una stima della probabilit√† di successo media per l‚Äôintero gruppo\nIl vantaggio principale di questo approccio gerarchico √® che combina informazioni a livello individuale e di gruppo, permettendo stime pi√π precise, specialmente per i partecipanti con pochi dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_hier_beta_binom.html#compilazione-e-sampling",
    "href": "chapters/mcmc/09_stan_hier_beta_binom.html#compilazione-e-sampling",
    "title": "52¬† Modello gerarchico beta-binomiale con Stan",
    "section": "52.3 Compilazione e sampling",
    "text": "52.3 Compilazione e sampling\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(\n    data=data,\n    iter_warmup=2000, \n    iter_sampling=4000,\n    seed=84735, \n    chains=4,\n    show_progress=False, \n    show_console=False\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "href": "chapters/mcmc/09_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "title": "52¬† Modello gerarchico beta-binomiale con Stan",
    "section": "52.4 Esame delle distribuzioni a posteriori",
    "text": "52.4 Esame delle distribuzioni a posteriori\nEsaminiamo le stime a posteriori dei parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"p\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n4.591\n0.866\n2.991\n6.359\n0.008\n0.006\n10600.0\n10141.0\n1.0\n\n\nbeta\n5.756\n0.932\n4.009\n7.623\n0.008\n0.006\n12032.0\n11787.0\n1.0\n\n\np[0]\n0.273\n0.100\n0.091\n0.469\n0.001\n0.000\n20279.0\n11628.0\n1.0\n\n\np[1]\n0.324\n0.103\n0.129\n0.524\n0.001\n0.001\n20614.0\n11911.0\n1.0\n\n\np[2]\n0.373\n0.107\n0.174\n0.588\n0.001\n0.001\n20791.0\n11355.0\n1.0\n\n\np[3]\n0.372\n0.106\n0.179\n0.590\n0.001\n0.001\n22416.0\n11620.0\n1.0\n\n\np[4]\n0.373\n0.107\n0.173\n0.582\n0.001\n0.001\n22260.0\n11753.0\n1.0\n\n\np[5]\n0.374\n0.106\n0.173\n0.583\n0.001\n0.001\n21443.0\n12716.0\n1.0\n\n\np[6]\n0.372\n0.106\n0.172\n0.580\n0.001\n0.001\n21992.0\n12317.0\n1.0\n\n\np[7]\n0.372\n0.106\n0.173\n0.582\n0.001\n0.001\n21133.0\n11017.0\n1.0\n\n\np[8]\n0.372\n0.105\n0.176\n0.583\n0.001\n0.001\n21459.0\n11369.0\n1.0\n\n\np[9]\n0.372\n0.108\n0.167\n0.580\n0.001\n0.001\n22007.0\n11102.0\n1.0\n\n\np[10]\n0.422\n0.108\n0.209\n0.627\n0.001\n0.001\n21331.0\n12556.0\n1.0\n\n\np[11]\n0.421\n0.109\n0.217\n0.634\n0.001\n0.001\n22045.0\n11591.0\n1.0\n\n\np[12]\n0.422\n0.108\n0.213\n0.632\n0.001\n0.001\n22874.0\n12190.0\n1.0\n\n\np[13]\n0.421\n0.110\n0.214\n0.637\n0.001\n0.001\n22807.0\n12055.0\n1.0\n\n\np[14]\n0.421\n0.109\n0.213\n0.634\n0.001\n0.001\n21851.0\n12199.0\n1.0\n\n\np[15]\n0.471\n0.112\n0.257\n0.689\n0.001\n0.001\n22072.0\n10892.0\n1.0\n\n\np[16]\n0.471\n0.111\n0.249\n0.680\n0.001\n0.001\n22559.0\n11739.0\n1.0\n\n\np[17]\n0.470\n0.111\n0.258\n0.683\n0.001\n0.001\n23384.0\n11679.0\n1.0\n\n\np[18]\n0.471\n0.111\n0.259\n0.688\n0.001\n0.001\n22495.0\n11479.0\n1.0\n\n\np[19]\n0.471\n0.111\n0.264\n0.691\n0.001\n0.001\n22949.0\n11720.0\n1.0\n\n\np[20]\n0.472\n0.110\n0.251\n0.680\n0.001\n0.001\n22288.0\n11847.0\n1.0\n\n\np[21]\n0.472\n0.109\n0.264\n0.685\n0.001\n0.001\n24414.0\n12216.0\n1.0\n\n\np[22]\n0.519\n0.109\n0.306\n0.728\n0.001\n0.001\n22363.0\n11502.0\n1.0\n\n\np[23]\n0.521\n0.111\n0.305\n0.732\n0.001\n0.001\n20720.0\n11618.0\n1.0\n\n\np[24]\n0.570\n0.109\n0.357\n0.780\n0.001\n0.001\n22438.0\n11048.0\n1.0\n\n\np[25]\n0.570\n0.109\n0.349\n0.772\n0.001\n0.001\n20850.0\n12520.0\n1.0\n\n\np[26]\n0.569\n0.110\n0.358\n0.786\n0.001\n0.001\n21973.0\n11715.0\n1.0\n\n\np[27]\n0.620\n0.107\n0.409\n0.821\n0.001\n0.001\n22119.0\n11629.0\n1.0\n\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilit√† di una risposta corretta per tutto il gruppo.\nConvertiamo l‚Äôoggetto fit creato da cmdstanpy in un oggetto InferenceData usando ArviZ:\n\nidata = az.from_cmdstanpy(posterior=fit)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "href": "chapters/mcmc/09_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "title": "52¬† Modello gerarchico beta-binomiale con Stan",
    "section": "52.5 Schrinkage bayesiano",
    "text": "52.5 Schrinkage bayesiano\nNel contesto dei modelli gerarchici bayesiani, il fenomeno dello ‚Äúshrinkage‚Äù (o riduzione) √® un aspetto fondamentale e desiderabile, specialmente quando si modellano dati provenienti da gruppi o sotto-popolazioni con campionature di dimensioni diverse o variazioni intrinseche. Questo fenomeno pu√≤ essere particolarmente rilevante e utile nel tuo modello gerarchico per il numero di risposte corrette di ciascun operatore, modello che utilizza una distribuzione binomiale per le osservazioni e una Beta per i priori dei parametri di successo $ p_i $.\n\n52.5.1 Cosa Significa Shrinkage in un Modello Gerarchico?\nLo ‚Äúshrinkage‚Äù in un modello bayesiano gerarchico si riferisce al processo per cui le stime dei parametri individuali (ad esempio, le probabilit√† di successo per ciascun operatore nel presente modello) sono ‚Äúspostate‚Äù verso una media di gruppo. Questo accade perch√© il modello considera sia i dati osservati per ciascun gruppo (o individuo) sia le informazioni aggiuntive fornite dalla struttura gerarchica e dai dati degli altri gruppi.\n\n\n52.5.2 Meccanismo dello Shrinkage\nNel presente modello: - Ogni operatore ha una probabilit√† di successo $ p_i $ che segue una distribuzione Beta $ (a, b) $, dove $ a $ e $ b $ sono iperparametri condivisi tra tutti gli operatori. - Gli iperparametri $ a $ e $ b $ sono stimati dai dati di tutti gli operatori, e quindi forniscono una base comune che riflette le caratteristiche medie di tutti gli operatori.\nSe un operatore ha pochi dati (ad esempio, pochi tentativi o risposte), la stima di $ p_i $ per quell‚Äôoperatore sar√† fortemente influenzata dai valori di $ a $ e $ b $, ‚Äúspostando‚Äù la stima di $ p_i $ verso la media di gruppo. Questo riduce l‚Äôimpatto delle fluttuazioni casuali nei dati di quell‚Äôoperatore, che potrebbero altrimenti portare a stime eccessivamente ottimistiche o pessimistiche.\n\n\n52.5.3 Benefici dello Shrinkage\n\nMigliore Stima per Gruppi con Pochi Dati: Operatori con meno dati beneficiano maggiormente dello shrinkage, in quanto le loro stime sono stabilizzate attraverso l‚Äôinformazione ‚Äúprestata‚Äù dagli altri operatori.\nRiduzione dell‚ÄôOverfitting: Il modello evita di adattarsi troppo ai dati di un singolo operatore, specialmente quando questi sono limitati o rumorosi, risultando in generalizzazioni pi√π robuste.\nIncorporazione della Struttura dei Dati: Lo shrinkage riflette l‚Äôassunzione che gli operatori siano simili ma non identici, permettendo una certa individualit√† ma entro un quadro comune che li lega.\n\nSupponiamo che alcuni operatori abbiano mostrato risultati estremamente buoni o cattivi, che potrebbero essere dovuti a varianze casuali. Lo shrinkage modera queste stime estreme, specialmente se non sono supportate da una grande quantit√† di dati, rendendo le previsioni finali pi√π credibili e meno soggette a errori casuali.\nIn conclusione, lo shrinkage in un modello gerarchico aiuta a ottenere stime pi√π accurate e credibili per tutti i membri del gruppo, sfruttando le informazioni collettive e limitando l‚Äôimpatto delle anomalie nei dati individuali.\nPer rappresentare visivamente questo fenomeno, iniziamo con il recuperare le stime a posteriori di alpha e beta.\n\nalphas = idata.posterior[\"alpha\"]\nbetas = idata.posterior[\"beta\"]\n\nCreiamo un array che contiene le stime bayesiane della probabilit√† di successo di ciascun operatore fornite sopra dalla funzione summary di ArviZ. Per fare questo usiamo le funzionalit√† di xarray.\n\n# Calcola la media lungo le dimensioni 'chain' e 'draw'\nbayesian_estimates = idata.posterior[\"p\"].mean(dim=(\"chain\", \"draw\"))\nprint(bayesian_estimates.values)\n\n[0.27273311 0.32377131 0.37344338 0.37214022 0.37257493 0.37351838\n 0.37219305 0.37214675 0.37185773 0.37173435 0.42165569 0.42127528\n 0.42172633 0.42118034 0.42149943 0.47116033 0.47087155 0.46970487\n 0.47107502 0.47138671 0.47205312 0.47221249 0.51906367 0.52052519\n 0.57032404 0.57017976 0.56928041 0.62016621]\n\n\nGeneriamo un array con le probabilit√† empiriche.\n\n# Empirical probabilities\nempirical_probs = y.values / N.values\nprint(empirical_probs)\n\n[0.1 0.2 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.5 0.5 0.5\n 0.5 0.5 0.5 0.5 0.6 0.6 0.7 0.7 0.7 0.8]\n\n\nIl grafico seguente confronta le probabilit√† empiriche con le stime Bayesiane per la probabilit√† di successo associata a ciascun operatore. Questa rappresentazione evidenzia il fenomeno di ‚Äúshrinkage‚Äù intrinseco ai modelli Bayesiani gerarchici. In particolare, il grafico illustra come le stime Bayesiane delle probabilit√† di successo per gli operatori tendono a convergere verso la media generale, in confronto alle probabilit√† empiriche.\n\n# Calcola la media generale delle probabilit√† empiriche\nmean_empirical_prob = np.mean(empirical_probs)\nmean_empirical_prob\n\n0.43928571428571417\n\n\n\n# Calcola la media generale delle stime Bayesiane\nmean_bayesian_estimate = np.mean(bayesian_estimates)\nmean_bayesian_estimate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'p' ()&gt; Size: 8B\narray(0.44112334)xarray.DataArray'p'0.4411array(0.44112334)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\n\n# Crea il grafico\nplt.figure()\n\n# Traccia le probabilit√† empiriche\nplt.scatter(range(1, 29), empirical_probs, label=\"Probabilit√† Empiriche\")\n\n# Traccia le stime Bayesiane\nplt.scatter(range(1, 29), bayesian_estimates, color=\"C1\", label=\"Stime Bayesiane\")\n\n# Aggiungi linee orizzontali per indicare le medie generali\nplt.axhline(\n    y=mean_empirical_prob,\n    linestyle=\"--\",\n    label=f\"Media Generale Empirica: {mean_empirical_prob:.2f}\",\n)\nplt.axhline(\n    y=mean_bayesian_estimate,\n    linestyle=\"--\",\n    label=f\"Media Generale Bayesiana: {mean_bayesian_estimate:.2f}\",\n)\n\n# Etichette e titolo\nplt.xlabel(\"Indice dell'Operatore\")\nplt.ylabel(\"Probabilit√† di Successo\")\nplt.title(\"Fenomeno dello Shrinkage in un Modello Bayesiano Gerarchico\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nEsaminiamo la distribuzione a posteriori dei parametri alpha e beta.\n\naz.plot_posterior(idata, var_names=[\"alpha\", \"beta\"], figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\n_ = az.plot_trace(idata, combined=True, figsize=(9, 6), kind=\"rank_bars\")\n\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilit√† di una risposta corretta per tutto il gruppo.\n\n# Function to calculate the mean of a Beta distribution\ndef beta_mean(alpha, beta):\n    return alpha / (alpha + beta)\n\n# Calculate the means for each pair of alpha and beta\nsample_posterior_x_means = np.array([beta_mean(a, b) for a, b in zip(alphas, betas)])\n\n\nsample_posterior_x_means.shape\n\n(4, 4000)\n\n\n\nsample_posterior_x_means\n\narray([[0.37604496, 0.41922669, 0.47345362, ..., 0.49569844, 0.47777766,\n        0.4247707 ],\n       [0.45096577, 0.41051049, 0.49462864, ..., 0.50996786, 0.53271226,\n        0.4371311 ],\n       [0.47134244, 0.47201767, 0.44473739, ..., 0.35595368, 0.41136842,\n        0.46184053],\n       [0.36027889, 0.42282699, 0.43706697, ..., 0.41162794, 0.43983373,\n        0.46031791]])\n\n\n\nprint(sample_posterior_x_means.mean())\n\n0.4428264916259948\n\n\n\n_ = az.plot_posterior(sample_posterior_x_means)\n\n\n\n\n\n\n\n\nL‚Äôintervallo [0.37, 0.51] rappresenta l‚Äôintervallo di credibilit√† al 94% per la probabilit√† di risposta corretta p, considerando l‚Äôinsieme del gruppo degli operatori. Questo intervallo ci fornisce un‚Äôindicazione sulla variabilit√† delle probabilit√† di successo tra gli operatori, considerando sia le differenze tra di loro che le somiglianze all‚Äôinterno del gruppo.\nPoich√© l‚Äôintervallo di credibilit√† include il valore 0.5, possiamo concludere che non ci sono evidenze credibili che gli operatori, considerati nel loro insieme, siano in grado di ‚Äúpercepire il campo energetico di una persona senza vedere le mani‚Äù ad un livello diverso rispetto a quello che ci si potrebbe aspettare dal caso soltanto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/09_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "title": "52¬† Modello gerarchico beta-binomiale con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nrequests  : 2.32.3\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html",
    "href": "chapters/mcmc/10_stan_poisson_model.html",
    "title": "53¬† Modello di Poisson",
    "section": "",
    "text": "Introduction\nNel capitolo precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo capitolo, useremo tale metodo per affrontare una questione relativa all‚Äôanalisi di un set di dati reali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#domanda-della-ricerca",
    "href": "chapters/mcmc/10_stan_poisson_model.html#domanda-della-ricerca",
    "title": "53¬† Modello di Poisson",
    "section": "53.1 Domanda della ricerca",
    "text": "53.1 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1¬∞ gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nLo scopo della presente analisi dei dati √® determinare il tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, e fornire una stima dell‚Äôincertezza associata a questo valore.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "href": "chapters/mcmc/10_stan_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "title": "53¬† Modello di Poisson",
    "section": "53.2 Importazione e pre-processing dei dati",
    "text": "53.2 Importazione e pre-processing dei dati\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1161\n2022    1095\n2021    1050\n2020    1020\n2019     996\n2015     995\n2018     992\n2017     984\n2016     959\nName: count, dtype: int64\n\n\nCreiamo un DataFrame con i dati necessari per PyMC.\n\nyear_counts.values\n\narray([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959])\n\n\n\n# Convert year_counts Series to a DataFrame\ndf = year_counts.reset_index()  # This converts the index (year) to a column and resets the index of the DataFrame\ndf.columns = ['year', 'events']  # Renaming the columns to 'year' and 'events'\n\n# Now, df is the DataFrame you wanted, with 'year' and 'events' columns\nprint(df)\n\n   year  events\n0  2023    1161\n1  2022    1095\n2  2021    1050\n3  2020    1020\n4  2019     996\n5  2015     995\n6  2018     992\n7  2017     984\n8  2016     959",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#modello-di-poisson",
    "href": "chapters/mcmc/10_stan_poisson_model.html#modello-di-poisson",
    "title": "53¬† Modello di Poisson",
    "section": "53.3 Modello di Poisson",
    "text": "53.3 Modello di Poisson\nIl nostro interesse riguarda il tasso di occorrenza di sparatorie fatali da parte della polizia per anno. Indicheremo questo tasso come \\(\\theta\\), e il suo intervallo di valori possibili √® \\([0, \\infty)\\). Un modello di Poisson rappresenta tipicamente il punto di partenza per l‚Äôanalisi di dati relativi alle frequenze assolute di un evento in un intervallo di tempo fissato. Il modello presuppone che i dati seguano una distribuzione di Poisson con un parametro di tasso \\(\\lambda\\):\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#distribuzione-a-priori",
    "href": "chapters/mcmc/10_stan_poisson_model.html#distribuzione-a-priori",
    "title": "53¬† Modello di Poisson",
    "section": "53.4 Distribuzione a priori",
    "text": "53.4 Distribuzione a priori\nCome distribuzione a priori per il parametro \\(\\lambda\\) nel modello di Poisson possiamo usare la distribuzione Gamma, poich√© √® una scelta coniugata. Ci√≤ significa che, quando viene combinata con la distribuzione di Poisson come verosimiglianza dei dati, la distribuzione Gamma produce una distribuzione a posteriori con una forma analitica semplice. Questa caratteristica semplifica il processo di inferenza bayesiana.\nNel nostro caso, il parametro \\(\\lambda\\) rappresenta il tasso di occorrenza di sparatorie fatali per anno negli Stati Uniti. Prima di osservare i dati effettivi riportati dal Washington Post, abbiamo una conoscenza limitata su tale fenomeno. Pertanto, dobbiamo specificare una distribuzione a priori per \\(\\lambda\\) che rifletta la nostra incertezza iniziale. As esempio, possiamo ipotizzare che ci sia, in media, una sparatoria mortale per stato al mese, quindi 12 sparatorie mortali all‚Äôanno per stato. Questo ci porta a una stima iniziale di 600 sparatorie fatali negli Stati Uniti ogni anno. Dato che non siamo molto sicuri di questa ipotesi, vogliamo specificare una distribuzione a priori con un certo grado di incertezza. Imponiamo dunque una deviazione standard pari a 200.\nPer visualizzare la distribuzione a priori per il parametro \\(\\lambda\\), creiamo un istogramma della distribuzione Gamma con i parametri specificati usando PyMC.\n\n# Parameters for the Gamma distribution\nmu = 600\nsigma = 200\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 600 e sigma = 200\")\nplt.show()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#modello-di-poisson-con-pymc",
    "href": "chapters/mcmc/10_stan_poisson_model.html#modello-di-poisson-con-pymc",
    "title": "53¬† Modello di Poisson",
    "section": "53.5 Modello di Poisson con PyMC",
    "text": "53.5 Modello di Poisson con PyMC\nFormuliamo il modello di Poisson usando questi iper-parametri per la distribuzione a priori del parametro \\(\\lambda\\) (rate) della distribuzione di Poisson.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\n\n# Caricare i dati\nstan_data = {\n    \"y\": [1161, 1095, 1050, 1020, 996, 995, 992, 984, 959],\n    \"N\": 9,\n    \"mu\": 600,\n    \"sigma\": 200\n}\nprint(stan_data)\n\n{'y': [1161, 1095, 1050, 1020, 996, 995, 992, 984, 959], 'N': 9, 'mu': 600, 'sigma': 200}\n\n\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro rate.\n\naz.plot_trace(trace, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\nIl modello converge rapidamente e i grafici delle tracce sembrano ben mescolati.\nGeneriamo un sommario numerico della distribuzione a posteriori.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n1027.83\n10.819\n1007.71\n1048.01\n0.21\n0.149\n2650.0\n3735.0\n1.0\n\n\n\n\n\n\n\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\nUsiamo ArviZ per generare l‚Äôintervallo di credibilit√† al 94% per la distribuzione a posteriori del parametro rate.\n\naz.plot_posterior(trace, var_names=\"rate\")\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, analizzando i dati compresi tra il 2015 e il 2023 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 94% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all‚Äôanno, con un intervallo di credibilit√† compreso tra 1008 e 1048.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#derivazione-analitica",
    "href": "chapters/mcmc/10_stan_poisson_model.html#derivazione-analitica",
    "title": "53¬† Modello di Poisson",
    "section": "53.6 Derivazione analitica",
    "text": "53.6 Derivazione analitica\nPer derivare i parametri della distribuzione Gamma (\\(\\alpha\\) e \\(\\beta\\)) conoscendo la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), possiamo utilizzare le seguenti relazioni:\n\n\\(\\alpha = (\\frac{\\mu}{\\sigma})^2\\)\n\\(\\beta = \\frac{\\mu}{\\sigma^2}\\)\n\nQueste formule si basano sul fatto che la media della distribuzione Gamma √® data da \\(\\frac{\\alpha}{\\beta}\\), mentre la varianza √® \\(\\frac{\\alpha}{\\beta^2}\\). Inoltre, la deviazione standard √® la radice quadrata della varianza.\nLa distribuzione a posteriori per \\(\\lambda\\), data una verosimiglianza di Poisson e una distribuzione a priori gamma, √® ancora una distribuzione gamma con parametri aggiornati. Possiamo calcolare i parametri della distribuzione a posteriori nel modo seguente:\n\nParametro di forma a posteriori (Œ±_post) = Œ±_prior + Œ£(y_i), dove Œ£(y_i) rappresenta la somma dei dati osservati.\nParametro di tasso a posteriori (Œ≤_post) = Œ≤_prior + n, dove n √® il numero di punti dati.\n\nCon questi parametri aggiornati, possiamo poi calcolare la media a posteriori della distribuzione gamma e l‚Äôintervallo di credibilit√†.\n\ndata = df[\"events\"]\n\n# Prior hyperparameters\nalpha_prior = (mu / sigma)**2\nbeta_prior = mu / sigma**2\n\n# Data summary\nn = len(df[\"events\"])\nsum_y = np.sum(df[\"events\"])\n\n# Posterior hyperparameters\nalpha_post = alpha_prior + sum_y\nbeta_post = beta_prior + n\n\n# Posterior distribution (Gamma)\nposterior_gamma = stats.gamma(alpha_post, scale=1 / beta_post)\n\n# Calculate the mean and credibility interval (94%)\nposterior_mean = posterior_gamma.mean()\ncredible_interval = posterior_gamma.interval(0.94)\n\nprint(\"Estimated Rate (Posterior Mean):\", posterior_mean)\nprint(\"Credibility Interval (94%):\", credible_interval)\n\nEstimated Rate (Posterior Mean): 1027.287853577371\nCredibility Interval (94%): (1007.3046264976574, 1047.4587209661117)\n\n\nL‚Äôoutput delle istruzioni precedenti fornisce il tasso stimato a posteriori e l‚Äôintervallo di credibilit√† al 94%. A causa di approssimazioni numeriche, i valori non coincidono esattamente con i risultati ottenuti con PyMC, ma sono molto simili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#vittime-non-armate",
    "href": "chapters/mcmc/10_stan_poisson_model.html#vittime-non-armate",
    "title": "53¬† Modello di Poisson",
    "section": "53.7 Vittime non armate",
    "text": "53.7 Vittime non armate\nConsideriamo ora uno studio di Ross, Winterhalder, e McElreath (2021). Nell‚Äôintroduzione allo studio, gli autori affermano che studi precedenti hanno dimostrato che la polizia negli Stati Uniti uccide cittadini neri rispetto a cittadini bianchi a tassi pi√π elevati di quanto ci si potrebbe aspettare secondo un modello generativo in cui la polizia incontra e uccide cittadini neri e bianchi in proporzione alle loro dimensioni relative della popolazione (ad esempio, Gabrielson et al., 2014; The Guardian, 2016; Takagi, 1981). Tuttavia, l‚Äôutilit√† di questi studi nel rilevare disparit√† razziali ingiustificabili nel comportamento della polizia √® stata messa in discussione (Cesario et al., 2019; Fryer, 2017; Selby et al., 2016; Tregle et al., 2019) perch√© la polizia uccide principalmente individui - neri o bianchi - che erano armati e impegnati in attivit√† criminali al momento dell‚Äôinterazione (Ross, 2015; Selby et al., 2016). Le differenze sottostanti nei tassi di attivit√† criminale armata specifici per la razza, piuttosto che - o oltre a - pregiudizi e/o bias stereotipati non intenzionali (Payne, 2006) da parte della polizia, sono state quindi citate come possibili cause dell‚Äôaumento dei tassi di sparatorie della polizia contro gli afroamericani. Tuttavia, Ross, Winterhalder, e McElreath (2021) fanno notare che le disparit√† a discapito degli individui afro-americani nell‚Äôuso della forza da parte della polizia statunitense persistono nel caso di individui disarmati sia a livello non letale (Fryer, 2016) che letale (Ross, 2015).\nPer verificare questa affermazione di Ross, Winterhalder, e McElreath (2021), usiamo i dati forniti dal Washington Post. Iniziamo a considerare il numero di sparatorie fatali da parte delle polizia statunitense nei confronti di un individuo disarmato caucasico.\n\n# Filter the dataframe to include only rows where the individual was unarmed\nunarmed_events = fps[fps[\"armed_with\"] == \"unarmed\"]\n\n# Filter the dataframe to create two separate dataframes for white and non-white races\nwhite_df = unarmed_events[unarmed_events[\"race\"] == \"W\"]\nnon_white_df = unarmed_events[unarmed_events[\"race\"] != \"W\"]\n\nprint(\"\\nWhite Race DataFrame:\")\nprint(white_df.head())\n\n\nWhite Race DataFrame:\n      id       date threat_type flee_status armed_with         city  \\\n8     16 2015-01-06    accident         not    unarmed   Burlington   \n72   342 2015-01-29        move        foot    unarmed   Stillwater   \n76   114 2015-02-02        flee        foot    unarmed  Hummelstown   \n119  159 2015-02-17        flee        foot    unarmed  Springfield   \n136  371 2015-02-23        move         not    unarmed        Omaha   \n\n         county state   latitude  longitude location_precision  \\\n8    Des Moines    IA  40.809250 -91.118875      not_available   \n72        Payne    OK  36.121177 -97.050127      not_available   \n76      Dauphin    PA  40.273404 -76.712841      not_available   \n119      Greene    MO  37.225250 -93.319432      not_available   \n136     Douglas    NE  41.244051 -95.933308      not_available   \n\n                name   age  gender race    race_source  \\\n8      Autumn Steele  34.0  female    W  not_available   \n72      Ralph Willis  42.0    male    W  not_available   \n76     David Kassick  59.0    male    W  not_available   \n119  Michael Ireland  31.0    male    W  not_available   \n136     Daniel Elrod  39.0    male    W  not_available   \n\n     was_mental_illness_related  body_camera agency_ids  year  \n8                         False         True        287  2015  \n72                        False        False        164  2015  \n76                        False        False        303  2015  \n119                       False        False        350  2015  \n136                       False        False        158  2015  \n\n\n\nprint(\"\\nNon-White Race DataFrame:\")\nprint(non_white_df.head())\n\n\nNon-White Race DataFrame:\n     id       date threat_type flee_status armed_with         city    county  \\\n2     5 2015-01-03        move         not    unarmed      Wichita  Sedgwick   \n17   36 2015-01-08      attack         not    unarmed       Strong     Union   \n62  352 2015-01-26        flee         car    unarmed       Tahoka      Lynn   \n83  116 2015-02-04      attack         not    unarmed  Tallahassee      Leon   \n86  125 2015-02-04    accident         not    unarmed        Tempe  Maricopa   \n\n   state   latitude   longitude location_precision                 name   age  \\\n2     KS  37.694766  -97.280554      not_available   John Paul Quintero  23.0   \n17    AR  33.111333  -92.358981      not_available  Artago Damon Howard  36.0   \n62    TX  33.166180 -101.666311      not_available   Joshua Omar Garcia  24.0   \n83    FL  30.465764  -84.330427      not_available          Jeremy Lett  28.0   \n86    AZ  33.378178 -111.978345      not_available    Joaquin Hernandez  28.0   \n\n   gender race    race_source  was_mental_illness_related  body_camera  \\\n2    male    H  not_available                       False        False   \n17   male    B  not_available                       False        False   \n62   male    H  not_available                       False        False   \n83   male    B  not_available                       False        False   \n86   male    H  not_available                       False        False   \n\n          agency_ids  year  \n2                238  2015  \n17               249  2015  \n62               179  2015  \n83               311  2015  \n86  247;195;2267;319  2015  \n\n\nDi seguito sono riportate le frequenze assolute di vittime disarmate di razza caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as white\nunarmed_white_events = white_df[white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_white_race = unarmed_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_white_race)\n\n   year  event_count\n0  2015           31\n1  2016           29\n2  2017           29\n3  2018           26\n4  2019           26\n5  2020           27\n6  2021            7\n7  2022           23\n8  2023           17\n\n\nPer gli stessi anni, qui sotto sono riportate le frequenze assolute delle vittime di razza non caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as non-white\nunarmed_non_white_events = non_white_df[non_white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_non_white_race = unarmed_non_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_non_white_race)\n\n   year  event_count\n0  2015           63\n1  2016           35\n2  2017           40\n3  2018           33\n4  2019           28\n5  2020           34\n6  2021           26\n7  2022           29\n8  2023           34\n\n\nCome distribuzione a priori per il tasso di morti, usiamo la media dei due campioni.\n\n0.5 * (np.mean(events_by_year_non_white_race.event_count) + \nnp.mean(events_by_year_white_race.event_count))\n\n29.833333333333336\n\n\nUtilizziamo una deviazione standard piuttosto grande per esprimere la nostra incertezza.\n\n# Parameters for the Gamma distribution\nmu = 30\nsigma = 10\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 30 e sigma = 10\")\nplt.show()\n\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo caucasico\nstan_data_white = {\n    \"y\": events_by_year_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_white = model.sample(\n    data=stan_data_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza caucasica.\n\naz.plot_trace(trace_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_white)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n24.141\n1.583\n21.246\n27.201\n0.03\n0.021\n2864.0\n3732.0\n1.0\n\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo non caucasico\nstan_data_non_white = {\n    \"y\": events_by_year_non_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_non_white = model.sample(\n    data=stan_data_non_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza noln caucasica.\n\naz.plot_trace(trace_non_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_non_white)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n35.615\n1.954\n32.06\n39.396\n0.036\n0.026\n2920.0\n4095.0\n1.0\n\n\n\n\n\n\n\n\nIl confronto tra i due intervalli di credibilit√† suggerisce che le frequenze attese del modello di Poisson risultano maggiori nel gruppo non caucasico rispetto al gruppo caucasico. √à importante considerare anche che la popolazione caucasica negli Stati Uniti √® numericamente superiore rispetto agli individui non caucasici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#modello-combinato-per-i-due-gruppi",
    "href": "chapters/mcmc/10_stan_poisson_model.html#modello-combinato-per-i-due-gruppi",
    "title": "53¬† Modello di Poisson",
    "section": "53.8 Modello combinato per i due gruppi",
    "text": "53.8 Modello combinato per i due gruppi\nIn alternativa, possiamo creare un modello Stan unico che valuti direttamente la differenza a posteriori delle frequenze attese dal modello di Poisson per i due gruppi. Per fare questo, possiamo estendere il modello per includere due rate, uno per ogni gruppo, e calcolare la differenza a posteriori delle frequenze attese.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_diff_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni per ogni gruppo\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y_white; // dati osservati per il gruppo caucasico\n  array[N] int&lt;lower=0&gt; y_non_white; // dati osservati per il gruppo non caucasico\n}\nparameters {\n  real&lt;lower=0&gt; rate_white; // parametro rate per la distribuzione Poisson per il gruppo caucasico\n  real&lt;lower=0&gt; rate_non_white; // parametro rate per la distribuzione Poisson per il gruppo non caucasico\n}\nmodel {\n  // Priori\n  rate_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  rate_non_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y_white ~ poisson(rate_white);\n  y_non_white ~ poisson(rate_non_white);\n}\ngenerated quantities {\n  real diff_rate = rate_non_white - rate_white; // differenza tra le frequenze attese\n}\n\n\n\nNel blocco generated quantities calcoliamo la distribuzione a posteriori della differenza tra i tassi di occorrenza stimati per i gruppi non caucasici e caucasici. Questa differenza permette di quantificare direttamente il confronto tra i tassi di incidenza dei due gruppi.\nGeneriamo il dizionario appropriato per il modello.\n\nstan_groups_data = {\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n    \"y_white\": events_by_year_white_race[\"event_count\"],\n    \"y_non_white\": events_by_year_non_white_race[\"event_count\"],\n}\nprint(stan_groups_data)\n\n{'N': 9, 'mu': 30, 'sigma': 10, 'y_white': 0    31\n1    29\n2    29\n3    26\n4    26\n5    27\n6     7\n7    23\n8    17\nName: event_count, dtype: int64, 'y_non_white': 0    63\n1    35\n2    40\n3    33\n4    28\n5    34\n6    26\n7    29\n8    34\nName: event_count, dtype: int64}\n\n\nEseguiamo il campionamento.\n\ntrace_groups = model.sample(\n    data=stan_groups_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro di interesse.\n\n_ = az.plot_trace(trace_groups, combined=True, var_names=[\"diff_rate\"], figsize= (9, 3))\n\n\n\n\n\n\n\n\n\naz.summary(trace_groups)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ndiff_rate\n11.508\n2.586\n6.792\n16.443\n0.033\n0.023\n6263.0\n5254.0\n1.0\n\n\nrate_non_white\n35.577\n1.946\n31.978\n39.260\n0.023\n0.016\n7282.0\n5576.0\n1.0\n\n\nrate_white\n24.069\n1.627\n21.098\n27.285\n0.021\n0.015\n5931.0\n4896.0\n1.0\n\n\n\n\n\n\n\n\nSulla base dei risultati ottenuti dal modello di Poisson, possiamo trarre le seguenti conclusioni:\nIl tasso stimato di incidenza delle vittime disarmate uccise dalla polizia negli Stati Uniti √® pi√π alto per il gruppo non caucasico rispetto al gruppo caucasico. La differenza media stimata tra i due tassi di incidenza √® di 11.508, con una deviazione standard di 2.586. Questo significa che, in media, il tasso per il gruppo non caucasico √® di circa 11.5 punti superiore rispetto al tasso per il gruppo caucasico.\nL‚Äôintervallo di credibilit√† al 94% per questa differenza va da 6.792 a 16.443, indicando che √® molto probabile che la vera differenza tra i tassi di incidenza dei due gruppi si trovi all‚Äôinterno di questo intervallo. Questo intervallo di credibilit√† non include lo zero, il che fornisce ulteriore evidenza che il tasso di incidenza per il gruppo non caucasico √® effettivamente pi√π alto rispetto al gruppo caucasico.\nInoltre, i tassi di incidenza stimati per ciascun gruppo sono i seguenti:\n\nGruppo non caucasico: tasso medio di 35.577 con un intervallo di credibilit√† al 94% tra 31.978 e 39.260.\nGruppo caucasico: tasso medio di 24.069 con un intervallo di credibilit√† al 94% tra 21.098 e 27.285.\n\nQuesti risultati indicano chiaramente che il gruppo non caucasico ha un tasso di incidenza pi√π alto di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico. L‚Äôintervallo di credibilit√† per ciascun tasso fornisce una stima robusta e credibile della variabilit√† di questi tassi.\nIn sintesi, il modello di Poisson fornisce una forte evidenza che esiste una differenza robusta tra i tassi di incidenza dei due gruppi, con il gruppo non caucasico che presenta un tasso pi√π elevato di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/10_stan_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "53¬† Modello di Poisson",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\nlogging   : 0.5.1.2\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\n\n\n\n\n\n\n\nRoss, Cody T, Bruce Winterhalder, e Richard McElreath. 2021. ¬´Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates¬ª. Social Psychological and Personality Science 12 (3): 323‚Äì32.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "54¬† Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo un approccio all‚Äôanalisi dei dati che si basa sull‚Äôutilizzo della regressione lineare, esaminandola dalla prospettiva dell‚Äôinferenza bayesiana. La regressione lineare, eseguita mediante l‚Äôuso del modello bayesiano, non solo ci consentir√† di analizzare le relazioni tra le variabili in modo pi√π profondo e flessibile, ma terr√† conto anche dell‚Äôincertezza e della variabilit√† presenti nelle stime.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html",
    "href": "chapters/linear_models/01_reglin_bayesian.html",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "",
    "text": "Introduzione\nI modelli lineari sono stati utilizzati in varie forme per molto tempo. Stigler (1986) descrive come il metodo dei minimi quadrati, una tecnica per adattare una semplice regressione lineare, fosse associato a problemi fondamentali in astronomia nel 1700, come la determinazione del moto della luna e la riconciliazione del moto non periodico di Giove e Saturno. All‚Äôepoca, gli astronomi erano tra i primi a sentirsi a proprio agio nell‚Äôutilizzare questi metodi, poich√© raccoglievano personalmente le loro osservazioni e sapevano che le condizioni di raccolta dei dati erano simili, anche se i valori delle osservazioni differivano. Questo contrastava con l‚Äôapproccio pi√π cauto delle scienze sociali, dove la riluttanza a combinare dati eterogenei ritardava l‚Äôadozione dei modelli lineari (Stigler 1986).\nCome nota Alexander (2023), quando costruiamo modelli, non stiamo scoprendo ‚Äúla verit√†‚Äù. Un modello non pu√≤ essere una rappresentazione fedele della realt√†. Utilizziamo i modelli per esplorare e comprendere i nostri dati. Non esiste un modello migliore in assoluto, ma solo modelli utili che ci aiutano a imparare qualcosa sui dati che abbiamo e, si spera, qualcosa sul mondo da cui sono stati generati. Quando utilizziamo i modelli, cerchiamo di comprendere il mondo, ma ci sono limiti alla prospettiva che portiamo in questo. Non dovremmo semplicemente inserire dati in un modello sperando che risolva tutto. Non lo far√†.\nI modelli scientifici sono strumenti essenziali per comprendere la realt√† che ci circonda. Il processo di creazione, esplorazione e analisi di questi modelli √® fondamentale per approfondire la nostra conoscenza del mondo. Questo processo si pu√≤ suddividere in diverse fasi:\n√à importante sottolineare che il valore principale di questo processo non risiede nel risultato finale, cio√® nel modello stesso, ma nell‚Äôapprendimento e nella comprensione che otteniamo durante il percorso. Anche se a volte il modello finale pu√≤ effettivamente rappresentare accuratamente la realt√†, √® il processo di sviluppo e analisi che ci fornisce intuizioni preziose.\nQuando lavoriamo con i modelli, dobbiamo considerare due aspetti cruciali:\n√à fondamentale riconoscere che i dati su cui basiamo i nostri modelli spesso non sono perfettamente rappresentativi della realt√†. Questo pu√≤ essere dovuto a limitazioni nella raccolta dei dati, bias nei campioni o semplicemente alla complessit√† del mondo reale. Di conseguenza, i modelli addestrati su questi dati, sebbene utili, non sono infallibili.\nCome gi√† rilevato nel Capitolo 14, per utilizzare efficacemente i modelli, dobbiamo porci costantemente due domande chiave:\nMantenere queste domande in primo piano ci aiuta a utilizzare i modelli in modo critico e consapevole, riconoscendone sia il potenziale che i limiti. Questo approccio ci permette di sfruttare al meglio i modelli come strumenti per comprendere il mondo, pur rimanendo consapevoli delle loro imperfezioni e delle sfide nella rappresentazione della realt√† complessa.\nL‚Äôevoluzione e l‚Äôapplicazione dei metodi statistici moderni presentano un interessante caso di studio nell‚Äôadattamento degli strumenti scientifici a contesti in rapida evoluzione. Molti dei metodi statistici attualmente in uso trovano le loro radici in campi come l‚Äôastronomia e l‚Äôagricoltura. Un esempio emblematico √® rappresentato da Ronald Fisher, figura di spicco nello sviluppo della statistica moderna, le cui opere seminali furono concepite durante il suo periodo presso un istituto di ricerca agricola.\nTuttavia, il panorama scientifico e tecnologico ha subito profondi cambiamenti dall‚Äôepoca di Fisher. L‚Äôapplicazione di questi metodi statistici si √® estesa a contesti che i loro ideatori difficilmente avrebbero potuto prevedere. Questa espansione solleva interrogativi cruciali sulla validit√† delle assunzioni fondamentali di questi metodi quando applicati in ambiti cos√¨ diversi da quelli originari.\nIn conclusione, mentre la statistica rimane uno strumento di inestimabile valore, il suo utilizzo efficace richiede un equilibrio tra una solida conoscenza dei principi fondamentali e la flessibilit√† necessaria per adattarsi a scenari di ricerca in continua evoluzione. L‚Äôintegrazione di metodologie diverse √® essenziale per garantire l‚Äôaffidabilit√† e la robustezza dei modelli statistici. Solo attraverso questo approccio olistico e adattativo possiamo sperare di comprendere e interpretare adeguatamente la complessit√† del mondo contemporaneo.\nIn questo capitolo, esploreremo due modelli statistici fondamentali: la regressione lineare bivariata e la regressione lineare multipla. La prima considera una sola variabile esplicativa, mentre la seconda ne include diverse. Per ciascun modello, esamineremo due approcci distinti:\n√à importante sottolineare che i modelli statistici vengono utilizzati principalmente per due scopi: inferenza e previsione. Mentre la previsione si limita a descrivere l‚Äôassociazione tra le variabili, l‚Äôinferenza mira a stabilire relazioni di causa-effetto attraverso l‚Äôuso del modello lineare. L‚Äôinferenza causale richiede una profonda conoscenza del fenomeno in esame e una progettazione sperimentale o quasi-sperimentale adeguata per giustificare le assunzioni necessarie.\nIndipendentemente dall‚Äôapproccio scelto, √® fondamentale tenere presente che l‚Äôanalisi di regressione √® essenzialmente una forma di media ponderata. Di conseguenza, i risultati ottenuti riflettono inevitabilmente i bias e le peculiarit√† del dataset utilizzato.\nInfine, una nota sulla terminologia e sulla notazione. Per ragioni storiche e specifiche del contesto, esistono vari termini usati per descrivere la stessa idea nella letteratura. Seguiamo Gelman, Hill, e Vehtari (2020) e utilizziamo i termini ‚Äúoutcome‚Äù e ‚Äúpredictor‚Äù, e la specificazione del modello bayesiano di McElreath (2020).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#introduzione",
    "href": "chapters/linear_models/01_reglin_bayesian.html#introduzione",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "",
    "text": "La regressione √® in effetti un oracolo, ma un oracolo crudele. Parla per enigmi e si diletta nel punirci per aver posto domande sbagliate.\nMcElreath (2020)\n\n\n\nCostruzione: Creiamo modelli basati sulle nostre attuali conoscenze e ipotesi.\nEsplorazione: Studiamo le caratteristiche e le implicazioni dei modelli creati.\nVerifica: Testiamo i modelli confrontandoli con dati reali e osservazioni.\nValutazione: Apprezziamo l‚Äôeleganza e l‚Äôefficacia dei modelli quando funzionano bene.\nAnalisi critica: Cerchiamo di comprendere i limiti e le debolezze dei nostri modelli.\nRevisione o sostituzione: Quando necessario, modifichiamo o abbandoniamo i modelli inadeguati.\n\n\n\n\nIl ‚Äúmondo del modello‚Äù: le assunzioni, le semplificazioni e le regole interne del modello stesso.\nIl ‚Äúmondo reale‚Äù: la realt√† pi√π ampia e complessa che stiamo cercando di comprendere e descrivere.\n\n\n\n\nIn che misura il modello ci insegna qualcosa sui dati che abbiamo a disposizione?\nQuanto accuratamente i dati che abbiamo riflettono il mondo reale su cui vogliamo trarre conclusioni?\n\n\n\n\n\n\n\nL‚Äôutilizzo delle funzioni di pingouin, particolarmente utili per l‚Äôanalisi esplorativa dei dati (EDA) quando si necessita di risultati rapidi.\nL‚Äôapproccio bayesiano, ideale quando l‚Äôobiettivo principale √® l‚Äôinferenza statistica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "href": "chapters/linear_models/01_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "55.1 Modellare l‚Äôassociazione statistica tra variabili",
    "text": "55.1 Modellare l‚Äôassociazione statistica tra variabili\nPer introdurre l‚Äôapproccio bayesiano al modello di regressione, esamineremo un set di dati che riguarda la relazione tra i punteggi di affect e arousal. I dati provengono da due studi condotti nel Personality, Motivation and Cognition Laboratory della Northwestern University, in cui sono stati utilizzati film per indurre stati affettivi (Rafaeli e Revelle 2006).\nQui ci concentreremo sull‚Äôassociazione tra l‚Äôansia di stato, considerata come variabile indipendente, e la scala di Tense Arousal del Motivational State Questionnaire (MSQ), considerata come variabile dipendente.\nIn precedenza, abbiamo applicato il modello normale a una singola variabile. Tuttavia, di solito siamo interessati a modellare come una variabile di esito sia associata a una variabile predittiva. Se esiste un‚Äôassociazione statistica tra la variabile predittiva e la variabile di esito, possiamo utilizzarla per predire il risultato. Quando la variabile predittiva √® incorporata nel modello in un modo specifico, otteniamo una regressione lineare.\nI dati dell‚Äôesempio sono forniti di seguito.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"affect.csv\")\n\n# Leggere il file CSV in un DataFrame pandas\ndata = pd.read_csv(file_path)\n\n# Selezionare le colonne state1 e TA1\ndf = data[[\"state1\", \"TA1\"]]\ndf.head()\n\n\n\n\n\n\n\n\n\nstate1\nTA1\n\n\n\n\n0\n41\n11.0\n\n\n1\n26\n5.0\n\n\n2\n31\n8.0\n\n\n3\n28\n8.0\n\n\n4\n47\n12.0\n\n\n\n\n\n\n\n\nL‚Äôassociazione tra le due variabili, ansia di stato e Tense Arousal, √® rappresentata nel grafico sottostante. Il grafico suggerisce che l‚Äôassociazione pu√≤ essere approssimata da una semplice funzione matematica, come una retta. Tuttavia, √® evidente che una funzione lineare sia troppo semplicistica per rappresentare accuratamente questi dati, poich√© non √® possibile trovare una singola retta che passi per tutti i punti del diagramma di dispersione.\n\ncolor_fill = \"#b97c7c\"\nplt.scatter(df[\"state1\"], df[\"TA1\"], color=color_fill)\nplt.xlabel(\"State Anxiety\")\nplt.ylabel(\"Tense Arousal\")\nplt.show()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#modello-generativo-dei-dati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#modello-generativo-dei-dati",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "55.2 Modello Generativo dei Dati",
    "text": "55.2 Modello Generativo dei Dati\nPer descrivere la relazione tra ansia di stato e Tense Arousal, utilizzeremo un modello statistico lineare. Assumeremo che la relazione media tra \\(x\\) (ansia di stato) e \\(y\\) (Tense Arousal) possa essere rappresentata da una retta, ma influenzata da un certo grado di errore. Supponiamo che questo errore sia costante ai vari livelli di \\(x\\) e segua una distribuzione Normale. Inoltre, presupponiamo che gli errori attorno alla retta di regressione siano indipendenti tra loro.\nIn questo contesto, le nostre assunzioni delineano un modello statistico lineare, formalizzato come segue:\n\\[ y_i = \\alpha + \\beta x_i + \\epsilon_i \\]\ndove:\n\n\\(\\alpha\\) √® l‚Äôintercetta,\n\\(\\beta\\) √® il coefficiente angolare,\n\\(\\epsilon_i \\sim \\text{Normale}(0, \\sigma^2)\\) rappresenta l‚Äôerrore, con media zero e varianza costante \\(\\sigma^2\\).\n\nQueste assunzioni ci permettono di applicare metodi di regressione lineare per stimare i parametri del modello (\\(\\alpha\\) e \\(\\beta\\)) e quantificare l‚Äôincertezza delle predizioni, considerando la variabilit√† nei dati.\nIl modello lineare descritto sopra costituisce il modello generativo dei dati (verosimiglianza):\n\\[ y_i = \\alpha + \\beta x_i + \\epsilon_i,  \\quad i \\in 1, \\dots N \\]\no equivalentemente\n\\[ \\epsilon_n \\sim \\text{Normale}(0, \\sigma) \\]\nQuesto modello descrive come i dati \\(y\\) sono generati. Ogni osservazione \\(y_i\\) √® una combinazione lineare di una costante \\(\\alpha\\) (intercetta), un coefficiente \\(\\beta\\) che moltiplica il valore della variabile \\(x\\) (ansia di stato), e un termine di errore \\(\\epsilon_n\\) che cattura la variabilit√† non spiegata dal modello lineare.\nIl termine di errore \\(\\epsilon_i\\) √® distribuito secondo una distribuzione normale con media 0 e deviazione standard \\(\\sigma\\). Questo implica che l‚Äôerrore √® simmetricamente distribuito attorno a zero e ha una variabilit√† definita da \\(\\sigma\\).\nL‚Äôequazione\n\\[ y_i \\sim \\text{Normale}(\\alpha + \\beta x_i, \\sigma), \\quad i \\in 1, \\dots N \\]\nmostra come il valore osservato \\(y_i\\) segue una distribuzione normale con media \\(\\alpha + \\beta x_i\\) e deviazione standard \\(\\sigma\\). Questo significa che, dato \\(x_i\\), i valori di \\(y_i\\) sono distribuiti normalmente attorno alla retta di regressione definita da \\(\\alpha + \\beta x_i\\).\nConsideriamo il caso in cui \\(y_i\\) rappresenta Tense Arousal e \\(x_i\\) rappresenta l‚Äôansia di stato. Secondo il nostro modello:\n\n\\(\\alpha\\) √® l‚Äôintercetta, ovvero il valore atteso di Tense Arousal quando l‚Äôansia di stato √® zero.\n\\(\\beta\\) √® il coefficiente che indica quanto aumenta (o diminuisce) Tense Arousal per ogni aumento di un punto dell‚Äôansia di stato.\n\\(\\sigma\\) √® la deviazione standard che misura la variabilit√† di Tense Arousal attorno alla media prevista dal modello.\n\nQuesto modello ci consente di stimare l‚Äôeffetto dell‚Äôansia di stato su Tense Arousal e di quantificare l‚Äôincertezza associata a queste stime.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#modello-bayesiano-della-regressione-bivariata",
    "href": "chapters/linear_models/01_reglin_bayesian.html#modello-bayesiano-della-regressione-bivariata",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "55.3 Modello Bayesiano della Regressione Bivariata",
    "text": "55.3 Modello Bayesiano della Regressione Bivariata\n\n55.3.1 Verosimiglianza\nAssumiamo la verosimiglianza che abbiamo descritto in precedenza:\n\\[ y \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma) \\]\nQuesto significa che i dati \\(y\\) seguono una distribuzione normale con media \\(\\alpha + \\beta x\\) e deviazione standard \\(\\sigma\\). In altre parole, il valore osservato \\(y\\) √® generato come una combinazione lineare di \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente della variabile \\(x\\)), pi√π un errore che segue una distribuzione normale con deviazione standard \\(\\sigma\\).\n\n\n55.3.2 Distribuzioni a Priori\nIn una prima versione del modello, useremo delle distribuzioni a priori uniformi per i tre parametri.\n\n\n55.3.3 Distribuzioni a Posteriori\nLe distribuzioni a priori vengono combinate con i dati osservati attraverso il teorema di Bayes per aggiornare le nostre credenze sui parametri del modello. Il risultato √® una distribuzione a posteriori per ciascun parametro che riflette sia l‚Äôinformazione contenuta nei dati che le credenze iniziali incorporate nelle distribuzioni a priori. Questo processo permette di fare inferenze pi√π robuste, specialmente quando i dati sono limitati o rumorosi.\n\n\n55.3.4 Codice Stan\nIl codice Stan che implementa il modello precedente √® contenuto nel file arousal_model_1.stan. Compiliamo e stampiamo il modello.\n\nstan_file = os.path.join(project_directory, 'stan', 'arousal_model_1.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSi osservi che, in questa prima istanziazione del modello bayesiano, non avendo specificato le distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), Stan assume distribuzioni a priori uniformi per questi parametri.\n\n\n55.3.5 Dizionario con i dati\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\n    \"N\": len(df[\"TA1\"]),\n    \"x\": df[\"state1\"],\n    \"y\": df[\"TA1\"]\n}\nprint(stan_data)\n\n{'N': 78, 'x': 0     41\n1     26\n2     31\n3     28\n4     47\n      ..\n73    40\n74    60\n75    24\n76    33\n77    33\nName: state1, Length: 78, dtype: int64, 'y': 0     11.0\n1      5.0\n2      8.0\n3      8.0\n4     12.0\n      ... \n73    13.0\n74    20.0\n75    10.0\n76    10.0\n77     6.0\nName: TA1, Length: 78, dtype: float64}\n\n\n\n\n55.3.6 Campionamento MCMC\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n\n\n55.3.7 Distribuzioni a posteriori\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]))\n\n\n\n\n\n\n\n\nL‚Äôoggetto fit generato da cmdstanpy appartiene alla classe cmdstanpy.stanfit.mcmc.CmdStanMCMC. Questo oggetto √® funzionalmente equivalente a un oggetto della classe InferenceData, permettendo quindi la sua manipolazione tramite le funzioni fornite da ArviZ. Esaminiamo dunque un sommario delle distribuzioni a posteriori dei parametri del modello lineare.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.552\n1.256\n-0.859\n3.816\n0.026\n0.019\n2395.0\n2748.0\n1.0\n\n\nbeta\n0.267\n0.029\n0.213\n0.323\n0.001\n0.000\n2436.0\n2858.0\n1.0\n\n\nsigma\n2.716\n0.227\n2.314\n3.149\n0.004\n0.003\n3410.0\n3273.0\n1.0\n\n\n\n\n\n\n\n\nConfrontiamo i valori ottenuti con l‚Äôapproccio bayesiano con quelli trovati usando la procedura di massima verosimiglianza.\n\nlm = pg.linear_regression(df[\"state1\"], df[\"TA1\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n1.56\n1.25\n1.25\n0.22\n0.52\n0.52\n-0.93\n4.04\n\n\n1\nstate1\n0.27\n0.03\n9.14\n0.00\n0.52\n0.52\n0.21\n0.33\n\n\n\n\n\n\n\n\nLa somiglianza tra le due soluzioni conferma che, quando usiamo dei prior uniformi per i parametri, i due approcci producono risultati equivalenti.\n\n\n55.3.8 Interpretazione\nPossiamo interpretare i parametri come segue:\n\nl‚Äôintercetta \\(\\alpha\\) corrisponde al valore atteso di Tense Arousal quando l‚Äôansia di stato vale 0;\nla pendenza \\(\\beta\\) ci informa sull‚Äôincremento atteso di Tense Arousal quando l‚Äôansia di stato aumenta di un‚Äôunit√†;\nil parametro \\(\\sigma\\) descrive la deviazione standard della dispersione di Tense Arousal attorno alla retta di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#predizione",
    "href": "chapters/linear_models/01_reglin_bayesian.html#predizione",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "55.4 Predizione",
    "text": "55.4 Predizione\nLa distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere trasformati in vari modi. Ad esempio, possiamo calcolare la predizione a posteriori del modello lineare per il valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 30 usando il seguente comando nel blocco generated quantities:\npred = alpha + beta * 30;\nModifichiamo il modello Stan per aggiungere questo comando nel blocco generated quantities e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model_2.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  real pred; // predizione\n  \n  pred = alpha + beta * 30;\n}\n\n\n\nIn questo modello Stan aggiornato, il blocco generated quantities calcola la predizione a posteriori pred per una variabile predittore con valore 30. Questa modifica permette di ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore.\nEseguiamo il campionamento.\n\nfit2 = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la stima a posteriori del valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 30. Questa analisi fornir√† sia una stima puntuale di Tense Arousal che una misura dell‚Äôincertezza associata, rappresentata dall‚Äôintervallo di credibilit√† al livello di confidenza scelto.\n\naz.summary(fit2, var_names=([\"pred\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npred\n9.566\n0.456\n8.722\n10.392\n0.008\n0.006\n3111.0\n4351.0\n1.0\n\n\n\n\n\n\n\n\n\n55.4.1 Quantificazione dell‚Äôincertezza\nPer quantificare l‚Äôincertezza complessiva nelle predizioni del modello, possiamo calcolare la distribuzione a posteriori delle predizioni per tutti i valori di \\(x\\) del campione. Questo ci permette di ottenere sia le stime puntuali delle predizioni sia una misura dell‚Äôincertezza associata.\nPer fare ci√≤, modifichiamo il blocco generated quantities nel seguente modo:\ngenerated quantities {\n  vector[N] y_rep; // Predizioni a posteriori per ciascun valore di x\n  \n  for (n in 1:N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\nEsaminiamo le modifiche:\n\nDichiarazione del vettore y_rep:\n\nvector[N] y_rep;: Dichiara un vettore y_rep di lunghezza N per contenere le predizioni a posteriori per ciascun valore di x.\n\nCiclo for per generare le predizioni:\n\nfor (n in 1:N): Itera su tutte le osservazioni.\ny_rep[n] = normal_rng(alpha + beta * x[n], sigma);: Per ogni valore di x[n], genera una predizione dalla distribuzione normale con media alpha + beta * x[n] e deviazione standard sigma. La funzione normal_rng genera numeri casuali dalla distribuzione normale specificata, rappresentando l‚Äôincertezza nelle predizioni.\n\n\nQuesto approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell‚Äôincertezza associata. Dalla distribuzione a posteriori di y_rep, possiamo calcolare sia la stima puntuale (come la media o la mediana delle predizioni) sia gli intervalli di credibilit√† (come l‚Äôintervallo al 95%) per ogni valore di x. Questo offre una misura dell‚Äôincertezza delle predizioni, riflettendo la variabilit√† e l‚Äôaffidabilit√† del modello.\nModifichiamo il modello imponendo distribuzioni a priori debolmente informative sui parametri:\n\nPer \\(\\alpha\\) e \\(\\beta\\), utilizziamo una distribuzione Normale centrata su 0 con una deviazione standard di 2.\nPer \\(\\sigma\\), utilizziamo una distribuzione di Cauchy centrata su 0 con una scala di 2.\n\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model_3.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 2);\n  beta ~ normal(0, 2);\n  sigma ~ cauchy(0, 2);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // variabili predette\n  \n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\n\nfit3 = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\n\naz.summary(fit3, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.126\n1.071\n-0.895\n3.084\n0.020\n0.014\n2803.0\n3269.0\n1.0\n\n\nbeta\n0.277\n0.025\n0.230\n0.325\n0.000\n0.000\n2792.0\n3204.0\n1.0\n\n\nsigma\n2.688\n0.223\n2.308\n3.129\n0.004\n0.003\n3466.0\n3325.0\n1.0\n\n\n\n\n\n\n\n\nSi noti che, utilizzando distribuzioni a priori debolmente informative, le stime a posteriori dei parametri sono rimaste praticamente invariate, indicando che la verosimiglianza ha prevalso sulle distribuzioni a priori.\nCostruiamo ora un grafico che rappresenta i valori osservati insieme alla linea di regressione stimata tramite il modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ciascuna orientata in base ai valori campionati casualmente dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\nPoniamoci dunque il problema di recuperare le stime a posteriori dei parametri dall‚Äôoggetto fit3, creato dal metodo sample(). La User‚Äôs Guide specifica quanto segue:\n\nThe sampler outputs are the set of per-chain Stan CSV files, a non-standard CSV file format. Each data row of the Stan CSV file contains the per-iteration estimate of the Stan model parameters, transformed parameters, and generated quantities variables.\n\nUtilizzando il metodo stan_variable(), possiamo ottenere un numpy.ndarray la cui struttura corrisponde a quella delle variabili del programma Stan, ossia i valori della distribuzione a posteriori di ciascun parametro. In questo caso, otteniamo i valori della distribuzione a posteriori di \\(\\alpha\\) e \\(\\beta\\):\n\n# Extract posterior samples\nalpha_samples = fit3.stan_variable(\"alpha\")\nbeta_samples = fit3.stan_variable(\"beta\")\n\nPer esempio, stampiamo i primi 20 valori di alpha_samples:\n\nprint(alpha_samples[0:20])\n\n[1.84977   1.95471   3.53495   0.0202381 2.37552   1.73716   2.02379\n 0.498677  1.16321   0.997901  1.1977    0.90099   1.62343   0.994237\n 0.102088  0.648134  2.29379   0.833032  0.98      1.27316  ]\n\n\n\nlen(alpha_samples)\n\n8000\n\n\nAvendo ottenuto 8.000 stime della distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) (2,000 valori per ciascuna delle 4 catene), possiamo calcolare la stima puntuale a posteriori dei parametri nel seguente modo:\n\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\n\nprint(mean_alpha, mean_beta)\n\n1.125774793247875 0.276703434375\n\n\nPossiamo sovrapporre la retta di regressione al grafico a dispersione utilizzando le stime a posteriori dei parametri.\n\n# Plot y vs x\nx = df[\"state1\"] \nplt.scatter(\n    x, df[\"TA1\"], color=color_fill, label=\"Data\", s=10\n)  # s is the size of the point\n\n# Draw lines from posterior samples\nfor i in range(300):  # assuming you have at least 300 samples\n    plt.plot(\n        x,\n        alpha_samples[i] + beta_samples[i] * x,\n        color=\"gray\",\n        linestyle=\"-\",\n        linewidth=0.5,\n        alpha=0.05,\n    )\n\n# Line using the mean of posterior estimates\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\ncolor_edge = \"#8f2727\"\nplt.plot(\n    x,\n    mean_alpha + mean_beta * x,\n    color=color_edge,\n    linewidth=2,\n    label=\"Mean Posterior Prediction\",\n)\n\n# Additional plot formatting\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Regression with Posterior Samples\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLe numerose linee di regressione presenti nel grafico visualizzano la nostra incertezza riguardo l‚Äôinclinazione esatta della linea di regressione principale. Tuttavia, il grafico mostra chiaramente che questa incertezza √® minima.\nPossiamo procedere in un altro modo per descrivere l‚Äôincertezza della stima. Anzich√© utilizzare le distribuzioni a posteriori di alpha e beta, possiamo utilizzare la distribuzione a posteriori di y_rep. Procedendo in questo modo otteniamo il grafico mostrato qui sotto.\nIn questo plot, la linea rossa rappresenta la media delle predizioni a posteriori, mentre l‚Äôarea grigia rappresenta l‚Äôintervallo di credibilit√† al 95%, mostrando l‚Äôincertezza delle predizioni del modello. Questo approccio fornisce una visione pi√π completa e realistica dell‚Äôincertezza nelle predizioni rispetto all‚Äôapproccio che utilizza solo alpha e beta.\n\n# Estrai i campioni posteriori di y_rep\ny_rep_samples = fit3.stan_variable(\"y_rep\")\n\n# Calcola la media e l'intervallo di credibilit√† (ad esempio, 95%) per y_rep\ny_rep_mean = np.mean(y_rep_samples, axis=0)\ny_rep_lower = np.percentile(y_rep_samples, 2.5, axis=0)\ny_rep_upper = np.percentile(y_rep_samples, 97.5, axis=0)\n\n# Plot y vs x\nx = df[\"state1\"]\ny = df[\"TA1\"]\nplt.scatter(x, y, color=color_fill, label=\"Dati\", s=10)\n\n# Plot della media delle predizioni a posteriori\nplt.plot(x, y_rep_mean, color=color_edge, linewidth=2, label=\"Media delle predizioni\")\n\n# Plot dell'intervallo di credibilit√†\nplt.fill_between(\n    x,\n    y_rep_lower,\n    y_rep_upper,\n    color=\"gray\",\n    alpha=0.3,\n    label=\"Intervallo di credibilit√† 95%\",\n)\n\n# Formattazione del plot\nplt.xlabel(\"State Anxiety\")\nplt.ylabel(\"Tense Arousal\")\nplt.title(\"Incertezza delle predizioni del modello\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNel primo approccio, calcoliamo l‚Äôincertezza delle predizioni utilizzando le distribuzioni a posteriori di alpha e beta. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di alpha e beta, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri alpha e beta. Questo metodo visualizza come l‚Äôincertezza nei parametri del modello si traduce in incertezza nelle predizioni.\nNel secondo approccio, descriviamo l‚Äôincertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di y_rep. In questo caso, generiamo predizioni per ciascun valore osservato di x nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l‚Äôincertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.\nLe due descrizioni dell‚Äôincertezza delle predizioni del modello sono diverse perch√© riflettono aspetti differenti della distribuzione a posteriori:\n\nDistribuzione a posteriori di alpha e beta: Questo approccio considera solo l‚Äôincertezza nei parametri del modello (alpha e beta). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell‚Äôincertezza residua (sigma).\nDistribuzione a posteriori di y_rep: Questo approccio include non solo l‚Äôincertezza nei parametri alpha e beta, ma anche l‚Äôincertezza residua (sigma). La distribuzione di y_rep riflette la variabilit√† totale nel modello, inclusa la variabilit√† nei dati osservati. Pertanto, l‚Äôincertezza nelle predizioni √® maggiore perch√© tiene conto di tutte le fonti di variabilit√†.\n\nCertamente, ecco una versione migliorata del testo:",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#ricodifica-dei-dati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#ricodifica-dei-dati",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "55.5 Ricodifica dei dati",
    "text": "55.5 Ricodifica dei dati\nL‚Äôintercetta (\\(\\alpha\\)) rappresenta il valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 0. Tuttavia, poich√© l‚Äôansia di stato √® misurata su una scala ad intervalli, l‚Äôorigine √® arbitraria e non rappresenta l‚Äôassenza della propriet√†. Lo stesso vale per la variabile Tense Arousal. Per entrambe le variabili, inoltre, anche l‚Äôunit√† di misura √® arbitraria.\nIn queste circostanze, una trasformazione utile √® la standardizzazione. La standardizzazione fa s√¨ che il valore 0 corrisponda alla media campionaria e che l‚Äôunit√† di misura sia una deviazione standard.\nQuando standardizziamo l‚Äôansia di stato, il valore 0 della variabile standardizzata corrisponde alla media della variabile originale. Dato che la retta di regressione passa per il punto \\((\\bar{x}, \\bar{y})\\), utilizzando i valori standardizzati di \\(x\\) e \\(y\\), la nuova intercetta (\\(\\alpha\\)) sar√† 0. La pendenza (\\(\\beta\\)) avr√† un‚Äôinterpretazione utile: nel caso di dati standardizzati, la pendenza stima l‚Äôincremento (o decremento) atteso di \\(y\\) quando \\(x\\) aumenta di una deviazione standard.\n\n# Calcolo della media e della deviazione standard di state1\nmean_state1 = np.mean(df[\"state1\"])\nstd_state1 = np.std(df[\"state1\"])\n# Standardizzazione \ndf[\"state1_z\"] = (df[\"state1\"] - mean_state1) / std_state1\n\n# Calcolo della media e della deviazione standard di TA1\nmean_ta1 = np.mean(df[\"TA1\"])\nstd_ta1 = np.std(df[\"TA1\"])\n# Standardizzazione \ndf[\"ta1_z\"] = (df[\"TA1\"] - mean_ta1) / std_ta1\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_11934/3940630615.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"state1_z\"] = (df[\"state1\"] - mean_state1) / std_state1\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_11934/3940630615.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"ta1_z\"] = (df[\"TA1\"] - mean_ta1) / std_ta1\n\n\n\nstan_data2 = {\"N\": len(df[\"state1_z\"]), \"x\": df[\"state1_z\"], \"y\": df[\"ta1_z\"]}\nprint(stan_data2)\n\n{'N': 78, 'x': 0    -0.042127\n1    -1.491782\n2    -1.008563\n3    -1.298494\n4     0.537735\n        ...   \n73   -0.138770\n74    1.794103\n75   -1.685069\n76   -0.815276\n77   -0.815276\nName: state1_z, Length: 78, dtype: float64, 'y': 0    -0.424575\n1    -1.995334\n2    -1.209955\n3    -1.209955\n4    -0.162782\n        ...   \n73    0.099012\n74    1.931564\n75   -0.686368\n76   -0.686368\n77   -1.733541\nName: ta1_z, Length: 78, dtype: float64}\n\n\n\nfit4 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\n\naz.summary(fit4, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.001\n0.079\n-0.149\n0.152\n0.001\n0.001\n8039.0\n5594.0\n1.0\n\n\nbeta\n0.722\n0.081\n0.564\n0.868\n0.001\n0.001\n7720.0\n5935.0\n1.0\n\n\nsigma\n0.710\n0.058\n0.604\n0.821\n0.001\n0.000\n7766.0\n5919.0\n1.0\n\n\n\n\n\n\n\n\nQuando l‚Äôansia di stato aumenta di una deviazione standard Tense Arousal aumenta, in media, di 0.725 deviazioni standard.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#distribizioni-a-priori-sui-parametri",
    "href": "chapters/linear_models/01_reglin_bayesian.html#distribizioni-a-priori-sui-parametri",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "55.6 Distribizioni a priori sui parametri",
    "text": "55.6 Distribizioni a priori sui parametri\nSpefichiamo ora le seguenti distribuzioni a priori debolmente informative sui parametri del modello.\n\nIntercetta (\\(\\alpha\\)):\n\n\\(\\alpha \\sim \\text{Normale}(0, 1)\\)\nLa scelta di una deviazione standard ampia (2) riflette l‚Äôincertezza riguardo al valore iniziale dell‚Äôintercetta. Si crede che l‚Äôintercetta possa essere qualsiasi valore vicino a 0, ma con una variazione significativa.\n\nCoefficiente Angolare (\\(\\beta\\)):\n\n\\(\\beta \\sim \\text{Normale}(0, 2)\\)\nUn‚Äôampia deviazione standard (2) per \\(\\beta\\) permette di incorporare l‚Äôincertezza riguardo all‚Äôinfluenza della temperatura sui ricavi del gelato. Questo prior permette che \\(\\beta\\) possa essere sia positivo che negativo con una vasta gamma di valori.\n\nDeviazione Standard Residua (\\(\\sigma\\)):\n\n\\(\\sigma \\sim \\text{Cauchy}^+(0, 2)\\)\nLa distribuzione Half-Cauchy √® scelta perch√© √® debolmente informativa e adatta per i parametri di scala come la deviazione standard residua. La scala di 2 consente a \\(\\sigma\\) di assumere una vasta gamma di valori positivi, riflettendo l‚Äôincertezza riguardo alla variabilit√† residua.\n\n\n\n55.6.1 Interpretazione delle Distribuzioni a Priori\nQueste distribuzioni a priori rappresentano le credenze iniziali riguardanti i parametri del modello prima di osservare i dati. Le distribuzioni normali per \\(\\alpha\\) e \\(\\beta\\) con deviazioni standard ampie permettono una grande flessibilit√†, mentre la distribuzione Half-Cauchy per \\(\\sigma\\) √® scelta per la sua capacit√† di gestire bene i parametri di scala. Queste scelte garantiscono che il modello sia debolmente informativo, permettendo ai dati osservati di avere un‚Äôinfluenza significativa sulle stime posteriori dei parametri.\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model_prior.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 2);\n  beta ~ normal(0, 2);\n  sigma ~ cauchy(0, 2);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nAdattiamo il nuovo modello ai dati.\n\nfit5 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit5, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.000\n0.081\n-0.152\n0.151\n0.001\n0.001\n8115.0\n5652.0\n1.0\n\n\nbeta\n0.723\n0.079\n0.576\n0.876\n0.001\n0.001\n7440.0\n6078.0\n1.0\n\n\nsigma\n0.709\n0.059\n0.603\n0.822\n0.001\n0.000\n8278.0\n5413.0\n1.0\n\n\n\n\n\n\n\n\nSi noti che, utilizzando distribuzioni a priori debolmente informative, le distribuzioni a posteriori dei parametri risultano molto simili a quelle ottenute usando distribuzioni uniformi. Tuttavia, le distribuzioni a priori debolmente informative sono preferibili poich√© forniscono una maggiore stabilit√† numerica e sono generalmente pi√π affidabili e robuste, specialmente quando si lavora con dati reali. L‚Äôuso di distribuzioni uniformi √® sconsigliato per via delle possibili instabilit√† numeriche che possono introdurre nei modelli.\n\n\n55.6.2 Posterior-predictive check\nGeneriamo ora un PPC plot per confrontare le predizioni del modello con i dati osservati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model_3.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nfit6 = model.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nPer creare un PPC plot dobbiamo creare un oggetto InferenceData nel quale i dati sono strutturati come si aspetta ArviZ:\n\nidata = az.from_cmdstanpy(\n    posterior=fit6,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": df[\"ta1_z\"]},\n)\n\nAvendo generato l‚Äôoggetto idata, possiamo ora creare il pp-check plot.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=100)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "href": "chapters/linear_models/01_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "55.7 Commenti e considerazioni finali",
    "text": "55.7 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato la stima dei parametri di un modello di regressione bivariato utilizzando l‚Äôapproccio bayesiano.\nPer fornire un confronto con un metodo alternativo, in appendice √® presentata un‚Äôintroduzione all‚Äôapproccio frequentista per il modello di regressione lineare bivariato. Questa sezione aggiuntiva offre una panoramica degli aspetti chiave dell‚Äôapproccio frequentista, consentendo di confrontare e comprendere le differenze tra i due approcci nella stima dei parametri e nell‚Äôinterpretazione dei risultati.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "title": "55¬† Modello di regressione lineare bayesiano",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\nlogging   : 0.5.1.2\npingouin  : 0.5.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nFox, John. 2015. Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nRafaeli, Eshkol, e William Revelle. 2006. ¬´A premature consensus: are happiness and sadness truly opposite affects?¬ª Motivation and Emotion 30: 1‚Äì12.\n\n\nStigler, Stephen. 1986. The History of Statistics. Massachusetts: Belknap Harvard.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello di regressione lineare bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_synt_sugar.html",
    "href": "chapters/linear_models/02_synt_sugar.html",
    "title": "56¬† Zucchero sintattico",
    "section": "",
    "text": "56.1 Introduzione\nI modelli lineari sono cos√¨ ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie √® bambi (BAyesian Model-Building Interface). bambi √® un pacchetto Python progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato √® un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm o brms. bambi si basa su PyMC, ma offre un‚ÄôAPI di livello superiore.\nIn questo capitolo esploreremo come condurre un‚Äôanalisi di regressione utilizzando bambi invece di cmdstan.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_synt_sugar.html#bayesian-model-building-interface",
    "href": "chapters/linear_models/02_synt_sugar.html#bayesian-model-building-interface",
    "title": "56¬† Zucchero sintattico",
    "section": "56.2 BAyesian Model-Building Interface",
    "text": "56.2 BAyesian Model-Building Interface\nLeggiamo i dati utilizzati nel capitolo precedente.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\n\nGeneriamo un diagramma a dispersione:\n\nplt.plot(df[\"weight\"], df[\"height\"], \"x\")\nplt.xlabel(\"Weight\")\nplt.ylabel(\"Height\")\n\nText(0, 0.5, 'Height')\n\n\n\n\n\n\n\n\n\nBambi si concentra sui modelli di regressione e questa restrizione porta a una sintassi pi√π semplice, ovvero la sintassi di Wilkinson {cite:p}wilkinson1973symbolic. Inoltre, bambi implementa delle distribuzioni a priori ottimizzate, eliminando cos√¨ la necessit√† di definirle esplicitamente. Tuttavia, se si preferisce un maggiore controllo sulle distribuzioni a priori, √® possibile specificarle manualmente.\nPer replicare il modello descritto nel capitolo precedente possiamo utilizzare la seguente istruzione.\n\ndf[\"weight_c\"] = df[\"weight\"] - np.mean(df[\"weight\"])\n\nmodel = bmb.Model(\"height ~ weight_c\", df)\n\nSul lato sinistro della tilde (‚àº), abbiamo la variabile dipendente, e sul lato destro, le variabili indipendenti. Con questa sintassi, stiamo semplicemente specificando la media (Œº nel modello lm di PyMC). Per impostazione predefinita, Bambi assume che la verosimiglianza sia gaussiana; √® possibile modificarla con l‚Äôargomento family. La sintassi della formula non specifica la distribuzione delle priors, ma solo come sono associate le variabili dipendenti e indipendenti. Bambi definir√† automaticamente delle priors (molto) debolmente informative per noi. Possiamo ottenere ulteriori informazioni stampando il modello Bambi.\n\nprint(model)\n\n       Formula: height ~ weight_c\n        Family: gaussian\n          Link: mu = identity\n  Observations: 352\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 154.5971, sigma: 19.3283)\n            weight_c ~ Normal(mu: 0.0, sigma: 2.9978)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 7.7313)\n\n\nLa descrizione inizia mostrando la formula utilizzata per definire il modello, y ~ x, che indica come la variabile dipendente y √® predetta dalla variabile indipendente x in una relazione lineare. La seconda riga specifica che si sta utilizzando una distribuzione gaussiana (normale) come funzione di verosimiglianza per il modello, il che implica l‚Äôassunzione che i residui del modello (le differenze tra i valori osservati e i valori predetti) seguano una distribuzione normale.\nLa terza riga menziona la funzione di collegamento, in questo caso l‚Äôidentit√†, che non applica alcuna trasformazione al valore atteso della variabile dipendente. Questo √® caratteristico dei modelli lineari, dove il valore atteso di y √® direttamente modellato come una combinazione lineare delle variabili indipendenti (E(Y) = \\alpha + \\beta x). √à importante notare che, nei modelli lineari generalizzati, la funzione di collegamento gioca un ruolo cruciale nel collegare il valore atteso della variabile risposta alla combinazione lineare delle variabili predittive.\nSegue il numero di osservazioni utilizzate per adattare il modello, indicando la dimensione del dataset su cui il modello √® stato allenato.\nLa parte successiva dell‚Äôoutput dettaglia i priors utilizzati per i parametri del modello. In Bambi, i priors sono assunzioni a priori sui valori dei parametri prima di osservare i dati. Questi priors aiutano a guidare l‚Äôinferenza, soprattutto in presenza di dati limitati o per regolarizzare il modello. L‚Äôintercetta (Intercept) ha un prior normale con media (mu) 2.0759 e deviazione standard (sigma) 3.9401, indicando la posizione iniziale attesa della linea di regressione e quanto ci si aspetta che vari. Il coefficiente della variabile x ha anch‚Äôesso un prior normale, centrato in zero con una deviazione standard ampia (6.8159), riflettendo incertezza su quale possa essere il vero effetto di x su y senza presupporre una direzione specifica dell‚Äôeffetto.\nLa sezione finale riguarda i parametri ausiliari del modello, in questo caso il parametro sigma della distribuzione gaussiana, che rappresenta la deviazione standard dei residui del modello. Questo ha un prior HalfStudentT, che √® una distribuzione che ammette solo valori positivi (essendo la deviazione standard sempre positiva), con un grado di libert√† (nu) 4.0 e una scala (sigma) 0.791. Questo prior √® scelto per la sua flessibilit√† e la capacit√† di gestire dati con potenziali outlier.\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nEseguiamo il campionamento MCMC.\n\nidata = model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\nLe distribuzioni a posteriori dei parametri e i trace plot si ottengono con la seguente istruzione.\n\n_ = az.plot_trace(idata)\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(idata, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n154.61\n0.27\n154.09\n155.09\n0.0\n0.0\n4300.59\n2955.37\n1.0\n\n\nsigma\n5.09\n0.19\n4.76\n5.45\n0.0\n0.0\n3966.32\n2953.56\n1.0\n\n\nweight_c\n0.90\n0.04\n0.82\n0.98\n0.0\n0.0\n4327.37\n3193.28\n1.0\n\n\n\n\n\n\n\n\nI dati replicano quelli ottenuti in precedenza.\nPossiamo anche generare un grafico che descrive l‚Äôincertezza a posteriori delle predizioni del modello.\nLa funzione plot_predictions del pacchetto Bambi serve per facilitare l‚Äôinterpretazione dei modelli di regressione attraverso la visualizzazione grafica. Il metodo appartiene al sottomodulo interpret di Bambi e si concentra sulla rappresentazione delle previsioni generate dal modello.\nQuando si esegue la funzione plot_predictions con i parametri specificati (model, idata, [\"weight_c\"]), essa produce un grafico che sintetizza le previsioni del modello in relazione a una o pi√π variabili indipendenti. In questo caso, il parametro model indica il modello di regressione Bayesiana costruito con Bambi, idata rappresenta i dati inferenziali (ottenuti tramite il fit del modello), e [\"weight_c\"] specifica la variabile indipendente da considerare per il grafico.\n\nbmb.interpret.plot_predictions(model, idata, [\"weight_c\"]);\n\nDefault computed for conditional variable: weight_c\n\n\n\n\n\n\n\n\n\nIl grafico generato da questa funzione illustra due aspetti principali:\n\nMedia Posteriore di y: Il grafico include una linea che rappresenta la media posteriore della variabile dipendente (height) rispetto alla variabile indipendente specificata (weight_c). La media posteriore √® una stima centrale delle previsioni del modello, che riflette la posizione pi√π probabile dei valori di height data l‚Äôevidenza fornita dai dati.\nIntervallo di Densit√† pi√π Alta del 94%: Attorno alla retta della media posteriore, il grafico mostra anche un‚Äôarea evidenziata che rappresenta l‚Äôintervallo di densit√† pi√π alta (HDI) del 94%. Questo intervallo √® un modo per quantificare l‚Äôincertezza delle previsioni del modello. L‚ÄôHDI del 94% significa che, data la distribuzione posteriore delle previsioni di height, c‚Äô√® il 94% di probabilit√† che il valore vero di height cada all‚Äôinterno di questo intervallo per un dato valore di weight_c. Questo fornisce una misura visiva dell‚Äôincertezza associata alle stime del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "56¬† Zucchero sintattico",
    "section": "56.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "56.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nbambi     : 0.14.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\narviz     : 0.18.0\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_two_means.html",
    "href": "chapters/linear_models/03_two_means.html",
    "title": "57¬† Confronto tra le medie di due gruppi",
    "section": "",
    "text": "Introduzione\nNel Capitolo 51, abbiamo discusso l‚Äôinferenza sulla differenza tra le medie di due campioni indipendenti utilizzando un approccio bayesiano. In quell‚Äôanalisi, i due gruppi sono stati considerati entit√† distinte e abbiamo calcolato la differenza tra le loro medie.\nUn‚Äôalternativa consiste nell‚Äôuso di un modello di regressione. In questo caso, invece di calcolare direttamente la differenza tra le medie, si introduce una variabile ‚Äúdummy‚Äù nel modello di regressione. La variabile ‚Äúdummy‚Äù codifica l‚Äôappartenenza ai gruppi con valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto. Il modello di regressione stima un coefficiente per la variabile ‚Äúdummy‚Äù, che rappresenta la differenza tra le medie dei due gruppi. In questo modo, la variabile ‚Äúdummy‚Äù funge da indicatore del gruppo, permettendo di stimare in modo efficiente la differenza tra le medie.\nEntrambi i metodi sono validi per analizzare la differenza tra le medie di due gruppi indipendenti; tuttavia, il modello di regressione offre maggiore flessibilit√† e potenzialit√† di espansione. Questo modello permette di includere ulteriori variabili esplicative, ampliando la nostra capacit√† di comprendere i fattori che influenzano il risultato d‚Äôinteresse. Tale versatilit√† √® particolarmente vantaggiosa per esaminare come altre variabili possano influire sulla differenza tra le medie o per analizzare pi√π variabili contemporaneamente.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/03_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "57¬† Confronto tra le medie di due gruppi",
    "section": "57.1 Regressione bayesiana per due gruppi indipendenti",
    "text": "57.1 Regressione bayesiana per due gruppi indipendenti\nNel contesto bayesiano, il modello di regressione pu√≤ essere formulato nel modo seguente:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta x_i.\n\\end{align*}\n\\]\nIn questa rappresentazione:\n\n$ $ agisce come intercetta,\n$ $ √® il coefficiente angolare o la pendenza,\n$ $ √® l‚Äôerrore standard associato alle osservazioni.\n\nNel caso specifico, la variabile $ x $ √® una variabile indicatrice che assume i valori 0 o 1. Per il gruppo identificato da $ x = 0 $, il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nQuesto implica che $ $ rappresenta la media del gruppo codificato come $ x = 0 $.\nPer il gruppo contrassegnato da $ x = 1 $, il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta.\n\\end{align*}\n\\]\nIn termini dei parametri del modello, la media per il gruppo codificato con $ x = 1 $ √® rappresentata da $ + $. In questa configurazione, $ $ indica la differenza tra la media del gruppo con $ x = 1 $ e quella del gruppo con $ x = 0 $. Di conseguenza, l‚Äôanalisi della differenza tra le medie dei due gruppi pu√≤ essere effettuata attraverso l‚Äôinferenza sul parametro $ $. In sintesi, per confrontare le medie dei due gruppi indipendenti, si pu√≤ esaminare la distribuzione a posteriori di $ $.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/03_two_means.html#un-esempio-illustrativo",
    "title": "57¬† Confronto tra le medie di due gruppi",
    "section": "57.2 Un esempio illustrativo",
    "text": "57.2 Un esempio illustrativo\nEsaminiamo nuovamente i dati relativi al quoziente di intelligenza dei bambini le cui madri hanno completato oppure no la scuola superiore. Ci poniamo il problema di replicare i risultati ottenuti in precedenza usando l‚Äôanalisi di regressione.\nLeggiamo i dati:\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\n\nkidiq.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nCi sono 93 bambini la cui madre non ha completato le superiori e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\nsummary_stats = [st.mean, st.stdev]\nkidiq.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\n\naz.plot_violin(\n    {\n        \"mom_hs=0\": kidiq.loc[kidiq.mom_hs == 0, \"kid_score\"],\n        \"mom_hs=1\": kidiq.loc[kidiq.mom_hs == 1, \"kid_score\"],\n    }\n);\n\n\n\n\n\n\n\n\nIniziamo l‚Äôinferenza statistica sulla differenza tra le medie dei due gruppi utilizzando bambi. Questo pacchetto offre una sintassi semplice per formulare il modello bayesiano di interesse. Un altro vantaggio √® che bambi selezioner√† automaticamente le distribuzioni a priori appropriate per i parametri del modello, rendendo il processo pi√π intuitivo.\nIl modello di regressione sopra descritto si scrive nel modo seguente.\n\nmod = bmb.Model(\"kid_score ~ mom_hs\", kidiq)\n\nEffettuiamo il campionamento.\n\nresults = mod.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nPossiamo ispezionare le propriet√† del modello nel modo seguente.\n\nmod\n\n       Formula: kid_score ~ mom_hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 86.7972, sigma: 110.1032)\n            mom_hs ~ Normal(mu: 0.0, sigma: 124.2132)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nLe distribuzioni a priori utilizzate di default dal modello possono essere visualizzate nel modo seguente.\n\n_ = mod.plot_priors()\n\nSampling: [Intercept, mom_hs, sigma]\n\n\n\n\n\n\n\n\n\nPer ispezionare il nostro posteriore e il processo di campionamento possiamo utilizzare az.plot_trace(). L‚Äôopzione kind='rank_vlines' ci fornisce una variante del grafico di rango che utilizza linee e punti e ci aiuta a ispezionare la stazionariet√† delle catene. Poich√© non c‚Äô√® un modello chiaro o deviazioni serie dalle linee orizzontali, possiamo concludere che le catene sono stazionarie.\n\n_ = az.plot_trace(results)\n\n\n\n\n\n\n\n\n\naz.summary(results, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n77.55\n2.01\n73.68\n81.27\n0.03\n0.02\n4272.34\n2738.90\n1.0\n\n\nmom_hs\n11.76\n2.25\n7.74\n16.17\n0.03\n0.03\n4169.77\n2921.90\n1.0\n\n\nsigma\n19.88\n0.66\n18.69\n21.12\n0.01\n0.01\n4540.09\n3039.19\n1.0\n\n\n\n\n\n\n\n\nIl parametro ‚ÄúIntercept‚Äù rappresenta la stima a posteriori del punteggio del QI per il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. La media a posteriori di questo gruppo √® di 77.6, che √® praticamente identica al valore campionario corrispondente.\nIl parametro ‚Äúmom_hs‚Äù corrisponde alla stima a posteriori della differenza nei punteggi del QI tra il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 1 e il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. Anche in questo caso, la differenza a posteriori di 11.8 tra le medie dei due gruppi √® molto simile alla differenza campionaria tra le medie dei due gruppi. La parte importante della tabella riguarda l‚Äôintervallo di credibilit√† al 94%, che √® [7.5, 16.2], e che non include lo 0. Ci√≤ significa che, con un livello di certezza soggettiva del 94%, possiamo essere sicuri che il QI dei bambini le cui madri hanno il diploma superiore sar√† maggiore (in media) di almeno 7.5 punti, e tale differenza pu√≤ arrivare fino a 16.2 punti, rispetto al QI dei bambini le cui madri non hanno completato la scuola superiore.\nSe confrontiamo questi risultati con quelli ottenuti nel capitolo {ref}two_groups_comparison_notebook, notiamo che sono quasi identici. Le piccole differenze che si osservano possono essere attribuite sia all‚Äôapprossimazione numerica sia al fatto che nel modello precedente abbiamo consentito deviazioni standard diverse per i due gruppi, mentre nel caso attuale abbiamo assumo la stessa variabilit√† per entrambi i gruppi.\nUsiamo ora l‚Äôapproccio di massima verosimiglianza.\n\nlm = pg.linear_regression(kidiq[\"mom_hs\"], kidiq[\"kid_score\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n77.55\n2.06\n37.67\n0.0\n0.06\n0.05\n73.50\n81.59\n\n\n1\nmom_hs\n11.77\n2.32\n5.07\n0.0\n0.06\n0.05\n7.21\n16.34\n\n\n\n\n\n\n\n\nI risultati sono quasi identici a quelli trovati con l‚Äôapproccio bayesiano.\nIl test bayesiano di ipotesi pu√≤ essere svolto, per esempio, calcolando la probabilit√† che \\(\\beta_{mean\\_diff} &gt; 0\\). Questa probabilit√† √® 1, per cui concludiamo che la media del gruppo codificato con ‚Äúmom_hs = 1‚Äù √® maggiore della media del gruppo codificato con ‚Äúmom_hs = 0‚Äù.\n\naz.plot_posterior(results, var_names=\"mom_hs\", ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\nUn valore numerico si ottiene nel modo seguente.\n\nresults.posterior\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104kB\nDimensions:    (chain: 4, draw: 1000)\nCoordinates:\n  * chain      (chain) int64 32B 0 1 2 3\n  * draw       (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\nData variables:\n    Intercept  (chain, draw) float64 32kB 80.81 75.64 77.14 ... 77.32 77.43\n    mom_hs     (chain, draw) float64 32kB 7.963 13.55 10.86 ... 9.91 10.79 12.88\n    sigma      (chain, draw) float64 32kB 19.3 20.92 20.21 ... 19.26 19.12 20.3\nAttributes:\n    created_at:                  2024-07-30T09:47:03.975197+00:00\n    arviz_version:               0.18.0\n    inference_library:           numpyro\n    inference_library_version:   0.15.1\n    sampling_time:               1.772095\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (3)Intercept(chain, draw)float6480.81 75.64 77.14 ... 77.32 77.43array([[80.81483632, 75.63639888, 77.14478867, ..., 75.72595312,\n        77.5423379 , 77.5423379 ],\n       [79.368775  , 79.97070154, 75.33769344, ..., 74.13336094,\n        80.08358757, 81.84041564],\n       [78.28138375, 76.8210174 , 80.13760742, ..., 77.78397138,\n        76.51013651, 78.79410939],\n       [82.03066779, 73.96217327, 76.20589234, ..., 78.7092881 ,\n        77.31896306, 77.4298698 ]])mom_hs(chain, draw)float647.963 13.55 10.86 ... 10.79 12.88array([[ 7.96339175, 13.55420539, 10.86033092, ..., 13.62558002,\n        11.84062159, 11.84062159],\n       [ 9.35003845,  9.9135694 , 13.79285124, ..., 16.97280286,\n         8.09604384,  5.89320385],\n       [12.97640867, 10.9104082 ,  8.77804029, ..., 11.30792615,\n        12.21403645, 11.0726028 ],\n       [ 5.64421123, 16.74073888, 13.98410457, ...,  9.91029743,\n        10.78713598, 12.8766417 ]])sigma(chain, draw)float6419.3 20.92 20.21 ... 19.12 20.3array([[19.29803974, 20.92199049, 20.21123626, ..., 20.58998924,\n        20.11170957, 20.11170957],\n       [17.91763444, 20.64037291, 19.88999257, ..., 20.09847731,\n        19.51073177, 19.25492589],\n       [19.99147265, 19.78098389, 19.27150942, ..., 20.86967072,\n        19.83582888, 19.83827133],\n       [19.22442038, 20.07102966, 20.0293815 , ..., 19.26291194,\n        19.11822346, 20.29616769]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2024-07-30T09:47:03.975197+00:00arviz_version :0.18.0inference_library :numpyroinference_library_version :0.15.1sampling_time :1.772095tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.14.0\n\n\n\n# Probabiliy that posterior is &gt; 0\n(results.posterior[\"mom_hs\"] &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_two_means.html#parametrizzazione-alternativa",
    "href": "chapters/linear_models/03_two_means.html#parametrizzazione-alternativa",
    "title": "57¬† Confronto tra le medie di due gruppi",
    "section": "57.3 Parametrizzazione alternativa",
    "text": "57.3 Parametrizzazione alternativa\nConsideriamo adesso il caso in cui, per distinguere i gruppi, anzich√© una variabile dicotomica, con valori 0 e 1, usiamo una variabile qualitativa con i nomi dei due gruppi. Introduciamo questa nuova variabile nel data frame.\n\n# Add a new column 'hs' with the categories based on 'mom_hs'\nkidiq[\"hs\"] = kidiq[\"mom_hs\"].map({0: \"not_completed\", 1: \"completed\"})\nkidiq.tail()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\nhs\n\n\n\n\n429\n94\n0.0\n84.877412\n4\n21\nnot_completed\n\n\n430\n76\n1.0\n92.990392\n4\n23\ncompleted\n\n\n431\n50\n0.0\n94.859708\n2\n24\nnot_completed\n\n\n432\n88\n1.0\n96.856624\n2\n21\ncompleted\n\n\n433\n70\n1.0\n91.253336\n2\n25\ncompleted\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati, usando questa nuova variabile e forziamo a zero l‚Äôintercetta che Bambi aggiunge di default al modello.\n\nmod_2 = bmb.Model(\"kid_score ~ 0 + hs\", kidiq)\nresults_2 = mod_2.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nIspezionare il modello e le distribuzioni a priori.\n\nmod_2\n\n       Formula: kid_score ~ 0 + hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            hs ~ Normal(mu: [0. 0.], sigma: [124.2132 124.2132])\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\n_ = mod_2.plot_priors()\n\nSampling: [hs, sigma]\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri del modello.\n\n_ = az.plot_trace(results_2)\n\n\n\n\n\n\n\n\n\naz.summary(results_2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nhs[completed]\n89.297\n1.089\n87.209\n91.231\n0.016\n0.012\n4429.0\n3149.0\n1.0\n\n\nhs[not_completed]\n77.506\n1.988\n73.744\n81.191\n0.031\n0.022\n4102.0\n2940.0\n1.0\n\n\nsigma\n19.881\n0.660\n18.647\n21.112\n0.010\n0.007\n4216.0\n2870.0\n1.0\n\n\n\n\n\n\n\n\nIn questo caso, notiamo che abbiamo ottenuto le distribuzioni a posteriori per i parametri hs[completed] e hs[not_completed] che corrispondono alle medie dei due gruppi. Tali distribuzioni a posteriori illustrano direttamente l‚Äôincertezza sulla media dei due gruppi, alla luce della variabilit√† campionaria e delle nostre credenze a priori.\nPossiamo svolgere il test bayesiano di ipotesi sulla differenza tra le due medie a posteriori nel modo seguente.\n\npost_group = results_2.posterior[\"hs\"]\ndiff = post_group.sel(hs_dim=\"completed\") - post_group.sel(hs_dim=\"not_completed\")\naz.plot_posterior(diff, ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\n\n# Probabiliy that posterior is &gt; 0\n(post_group &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "57¬† Confronto tra le medie di due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nbambi     : 0.14.0\nnumpy     : 1.26.4\npandas    : 2.2.2\npingouin  : 0.5.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html",
    "href": "chapters/linear_models/04_stan_multreg.html",
    "title": "58¬† Regressione multipla con Stan",
    "section": "",
    "text": "Introduzione\nIn questo capitolo introdurremo il modello di regressione multipla mostrando come possa essere implementato in Stan. Ci concentreremo sull‚Äôinterpretazione dei coefficienti parziali di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#regressione-multipla",
    "href": "chapters/linear_models/04_stan_multreg.html#regressione-multipla",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.1 Regressione multipla",
    "text": "58.1 Regressione multipla\nLa regressione multipla rappresenta un‚Äôestensione del modello di regressione semplice, e permette di esplorare e quantificare le relazioni tra una variabile dipendente e pi√π variabili indipendenti. Passando dal modello semplice \\(y = a + bx + \\text{errore}\\) al modello pi√π generale \\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\text{errore}\\), emergono nuove complessit√†. Queste includono le decisioni su quali predittori \\(x\\) includere nel modello, l‚Äôinterpretazione dei coefficienti e delle loro interazioni, e la costruzione di nuovi predittori a partire dalle variabili esistenti per catturare elementi di discrezionalit√† e non linearit√†.\nI coefficienti di regressione, in un contesto di regressione multipla, sono tipicamente pi√π complicati da interpretare rispetto a quelli di un modello con un solo predittore. L‚Äôinterpretazione di un dato coefficiente, infatti, √® parzialmente condizionata dalle altre variabili presenti nel modello. Il coefficiente \\(\\beta_k\\) rappresenta la differenza media o attesa nella variabile risposta \\(y\\), confrontando due individui che differiscono di un‚Äôunit√† nel predittore \\(x_k\\) ma sono identici per quanto riguarda gli altri predittori. Questo concetto √® talvolta sintetizzato con l‚Äôespressione ‚Äúconfrontare due osservazionni (o persone) che differiscono per \\(x_k\\) a parit√† delle altre variabili‚Äù.\nDal punto di vista dell‚Äôimplementazione con Stan, l‚Äôestensione del modello per includere molteplici predittori dell‚Äôintelligenza del bambino √® relativamente semplice. √à necessario costruire una matrice \\(X\\) contenente le colonne che rappresentano i vari predittori che intendiamo analizzare. Per l‚Äôesempio specifico in questione, i predittori selezionati per l‚Äôintelligenza del bambino includono: la scolarit√† della madre (codificata come 0 o 1 a seconda che la madre abbia completato o meno le scuole superiori), l‚Äôintelligenza della madre e l‚Äôet√† della madre. Prima di procedere con l‚Äôanalisi, √® importante standardizzare tutte queste variabili per facilitare l‚Äôinterpretazione dei risultati e migliorare la stabilit√† numerica del modello.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#un-esempio-pratico",
    "href": "chapters/linear_models/04_stan_multreg.html#un-esempio-pratico",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.2 Un esempio pratico",
    "text": "58.2 Un esempio pratico\nPer fare un esempio pratico, analizzeremo nuovamente i dati sull‚Äôintelligenza di un gruppo di bambini. In questo caso, cercheremo di predire l‚Äôintelligenza media dei bambini considerando tre fattori: se le madri hanno completato la scuola superiore, l‚Äôintelligenza della madre e l‚Äôet√† della madre.\nImportiamo i dati:\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nCompiliamo e stampiamo il modello Stan di regressione multipla per questi dati. Il modello assume che i dati siano standardizzati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"mreg.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;   // Numero di osservazioni\n    int&lt;lower=1&gt; K;   // Numero di variabili indipendenti, intercetta inclusa\n    vector[N] x1;     // Prima variabile indipendente\n    vector[N] x2;     // Seconda variabile indipendente\n    vector[N] x3;     // Seconda variabile indipendente\n    // Aggiungi altri vettori se ci sono pi√π variabili indipendenti\n    vector[N] y;      // Vettore della variabile dipendente\n}\nparameters {\n    real alpha;           // Intercetta\n    real beta1;           // Coefficiente per la prima variabile indipendente\n    real beta2;           // Coefficiente per la seconda variabile indipendente\n    real beta3;           // Coefficiente per la terza variabile indipendente\n    // Definisci altri real per ulteriori coefficienti\n    real&lt;lower=0&gt; sigma;  // Errore del modello\n}\nmodel {\n    // Prior\n    alpha ~ student_t(3, 0, 2.5);\n    beta1 ~ student_t(3, 0, 2.5);\n    beta2 ~ student_t(3, 0, 2.5);\n    beta3 ~ student_t(3, 0, 2.5);\n    // Definisci prior per altri coefficienti\n    sigma ~ exponential(1);\n\n    // Likelihood\n    for (n in 1:N) {\n        y[n] ~ normal(alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\ngenerated quantities {\n    vector[N] log_lik; // Log-likelihood per ogni osservazione\n    vector[N] y_rep;  // Predizioni posteriori per ogni osservazione\n\n    for (n in 1:N) {\n        log_lik[n] = normal_lpdf(y[n] | alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n        y_rep[n] = normal_rng(alpha + beta1 * x1[n] + beta2 * x2[n] + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\n\n\n\nStandaridizziamo i predittori:\n\nx1 = stats.zscore(kidiq[\"mom_hs\"])\nx2 = stats.zscore(kidiq[\"mom_iq\"])\nx3 = stats.zscore(kidiq[\"mom_age\"])\n\n\ndf = pd.DataFrame({\n    \"one\": [1] * len(x1),  # Crea una lista di 1 della stessa lunghezza di x1\n    \"x1\": x1,\n    \"x2\": x2,\n    \"x3\": x3\n})\n\ndf.head()\n\n\n\n\n\n\n\n\n\none\nx1\nx2\nx3\n\n\n\n\n0\n1\n0.522233\n1.409460\n1.562029\n\n\n1\n1\n0.522233\n-0.710026\n0.820727\n\n\n2\n1\n0.522233\n1.030732\n1.562029\n\n\n3\n1\n0.522233\n-0.036733\n0.820727\n\n\n4\n1\n0.522233\n-0.484177\n1.562029\n\n\n\n\n\n\n\n\n\n# Convert scaled DataFrame to numpy matrix\nX = df.to_numpy()\n\n\n# Verificare le dimensioni di X\nprint(\"Dimensioni di X:\", X.shape)\n\nDimensioni di X: (434, 4)\n\n\nCreiamo un dizionario con i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\": X.shape[0],\n    \"K\": X.shape[1],  # Nota: questa include anche la colonna dell'intercetta\n    \"x1\": df[\"x1\"],\n    \"x2\": df[\"x2\"],\n    \"x3\": df[\"x3\"],\n    \"y\": stats.zscore(\n        kidiq[\"kid_score\"]\n    )\n}\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le tracce dei parametri:\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]))\n\n\n\n\n\n\n\n\nAnche nel caso della regressione multipla, i risultati ottenuti con l‚Äôapproccio bayesiano sono molto simili a quelli prodotti dall‚Äôapproccio basato sulla massima verosimiglianza.\nCalcoliamo una sintesi delle distribuzioni a posteriori dei parametri:\n\naz.summary(\n    fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]), hdi_prob=0.94\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.000\n0.043\n-0.082\n0.080\n0.0\n0.001\n9553.0\n5261.0\n1.0\n\n\nbeta1\n0.114\n0.045\n0.031\n0.201\n0.0\n0.000\n9409.0\n6308.0\n1.0\n\n\nbeta2\n0.414\n0.044\n0.330\n0.496\n0.0\n0.000\n9556.0\n6280.0\n1.0\n\n\nbeta3\n0.029\n0.043\n-0.050\n0.112\n0.0\n0.000\n9647.0\n6545.0\n1.0\n\n\nsigma\n0.891\n0.031\n0.835\n0.949\n0.0\n0.000\n9403.0\n5961.0\n1.0\n\n\n\n\n\n\n\n\nReplichiamo il risultato usando l‚Äôapproccio di massima verosimiglianza:\n\nlm = pg.linear_regression(X, stats.zscore(kidiq[\"kid_score\"]))\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-0.00\n0.04\n-0.00\n1.00\n0.21\n0.21\n-0.08\n0.08\n\n\n1\nx2\n0.11\n0.05\n2.50\n0.01\n0.21\n0.21\n0.02\n0.20\n\n\n2\nx3\n0.41\n0.04\n9.28\n0.00\n0.21\n0.21\n0.33\n0.50\n\n\n3\nx4\n0.03\n0.04\n0.68\n0.50\n0.21\n0.21\n-0.06\n0.12",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/04_stan_multreg.html#interpretazione-dei-coefficienti",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.3 Interpretazione dei coefficienti",
    "text": "58.3 Interpretazione dei coefficienti\nNel contesto della regressione multipla, l‚Äôinterpretazione dei coefficienti parziali differisce da quella della regressione bivariata. Una differenza chiave rispetto al modello di regressione bivariato √® nell‚Äôinterpretazione dei coefficienti. Nel caso bivariato, il coefficiente \\(\\beta_1\\) viene interpretato come il cambiamento atteso in \\(Y\\) al variare di una unit√† in \\(X_1\\). Tuttavia, nel modello di regressione multipla, l‚Äôinterpretazione di \\(\\beta_1\\) cambia. In questo caso, \\(\\beta_1\\) rappresenta il cambiamento atteso in \\(Y\\) al variare di una unit√† in \\(X_1\\), mantenendo costanti gli effetti di tutte le altre variabili \\(X_2, X_3, \\ldots, X_p\\). In altre parole, \\(\\beta_1\\) ci dice come varia in media \\(Y\\) quando \\(X_1\\) cambia, ma considera che altre variabili possono variare insieme a \\(X_1\\), e \\(\\beta_1\\) tiene conto di queste variazioni.\nNel nostro caso, il coefficiente associato all‚Äôintelligenza della madre, indicato come \\(\\beta\\) = 0.41, assume il seguente significato: prevediamo che l‚Äôintelligenza del bambino aumenti di 0.41 deviazioni standard in media per ogni deviazione standard aggiuntiva nell‚Äôintelligenza della madre, mantenendo costanti gli effetti del livello di istruzione e dell‚Äôet√† della madre. Questo implica che stiamo considerando l‚Äôimpatto dell‚Äôintelligenza della madre sull‚Äôintelligenza del bambino all‚Äôinterno di una popolazione di madri che sono omogenee per quanto riguarda il livello di istruzione e l‚Äôet√†.\nCosa significa mantenere costante l‚Äôeffetto di altre variabili? Consideriamo l‚Äôesempio della correlazione tra il numero di scarpe e le abilit√† matematiche. Esiste una marcata correlazione positiva tra queste due variabili. Tuttavia, √® evidente che i bambini, avendo in genere numeri di scarpe pi√π piccoli rispetto agli adulti, mostrano anche, presumibilmente, minori capacit√† matematiche. Questo esempio illustra che, se controlliamo per l‚Äôet√†, ossia se consideriamo solo soggetti della stessa et√†, la correlazione tra il numero di scarpe e le abilit√† matematiche scompare. Pertanto, nell‚Äôanalisi della relazione tra abilit√† matematiche (Y) e numero di scarpe (X), l‚Äôet√† (Z) agisce come variabile confondente. Controllare per Z significa esaminare la relazione tra Y e X limitandosi a individui della stessa et√†.\nMa ovviamente questo controllo empirico non √® sempre possibile. Nel modello di regressione, esso viene ‚Äúapprossimato‚Äù con una procedura statistica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "href": "chapters/linear_models/04_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.4 Distribuzione predittiva a posteriori",
    "text": "58.4 Distribuzione predittiva a posteriori\nCalcoliamo la distribuzione predittiva a posteriori e generiamo il PPC plot:\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_rep',\n    observed_data={'y': stats.zscore(kidiq[\"kid_score\"])},\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_rep'})\n\n/opt/anaconda3/envs/cmdstan_env/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  func(*args, **kwargs)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#il-controllo-statisico",
    "href": "chapters/linear_models/04_stan_multreg.html#il-controllo-statisico",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.5 Il Controllo Statisico",
    "text": "58.5 Il Controllo Statisico\nNella seguente simulazione illustreremo la procedura statistica utilizzata per isolare l‚Äôeffetto di una variabile controllando per un‚Äôaltra.\n\n# Creiamo dei dati di esempio\nnp.random.seed(0)\nN = 100\nX1 = np.random.normal(0, 1, N)\nX2 = X1 + np.random.normal(0, 0.5, N)\nY = 1 + 2 * X1 + 3 * X2 + np.random.normal(0, 1, N)\n\n# Modello completo Y ~ X1 + X2\nmodel_full = sm.OLS(Y, sm.add_constant(np.column_stack((X1, X2))))\nresults_full = model_full.fit()\n\n# Regressione di Y su X2\nmodel_Y_on_X2 = sm.OLS(Y, sm.add_constant(X2))\nresiduals_Y = model_Y_on_X2.fit().resid\n\n# Regressione di X1 su X2\nmodel_X1_on_X2 = sm.OLS(X1, sm.add_constant(X2))\nresiduals_X1 = model_X1_on_X2.fit().resid\n\n# Regressione dei residui di Y sui residui di X1\nmodel_residuals = sm.OLS(residuals_Y, sm.add_constant(residuals_X1))\nresults_residuals = model_residuals.fit()\n\n# Stampiamo i risultati\nprint(\"Coefficient from full model for X1: {:.4f}\".format(results_full.params[1]))\nprint(\n    \"Coefficient from regression of residuals: {:.4f}\".format(\n        results_residuals.params[1]\n    )\n)\n\nCoefficient from full model for X1: 1.9782\nCoefficient from regression of residuals: 1.9782\n\n\nQuesto esempio illustra il concetto di coefficiente parziale di regressione. Questo coefficiente quantifica l‚Äôeffetto della variabile esplicativa \\(X_j\\) sulla variabile dipendente \\(Y\\), depurando l‚Äôeffetto di \\(X_j\\) dall‚Äôinfluenza degli altri predittori nel modello. In sostanza, il coefficiente parziale di regressione valuta l‚Äôimpiego di \\(X_j\\) su \\(Y\\) quando \\(X_j\\) √® considerata linearmente indipendente rispetto agli altri predittori \\(X\\). L‚Äôeffetto misurato √® quindi quello della sola componente di \\(X_j\\) che non √® spiegata linearmente dai restanti predittori \\(X\\) sulla parte di \\(Y\\) che √® anch‚Äôessa indipendente dai medesimi predittori.\nPer chiarire ulteriormente, questo approccio statistico si focalizza sull‚Äôanalizzare l‚Äôeffetto di \\(X_j\\) eliminando l‚Äôinfluenza lineare degli altri predittori \\(X\\). √à simile a valutare la relazione tra \\(Y\\) e \\(X_j\\) in un contesto ideale dove tutti gli individui presentano livelli identici per le altre variabili \\(X\\). Tale metodo non eguaglia gli effetti non lineari che possono essere presenti tra le variabili, limitandosi a correggere solo per le associazioni lineari. In questo modo, il controllo statistico tenta di approssimare una condizione di omogeneit√† tra i soggetti rispetto alle altre variabili \\(X\\), consentendo di isolare e valutare pi√π precisamente l‚Äôeffetto puro di \\(X_j\\) su \\(Y\\).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#quali-predittori-includere-nel-modello",
    "href": "chapters/linear_models/04_stan_multreg.html#quali-predittori-includere-nel-modello",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.6 Quali predittori includere nel modello?",
    "text": "58.6 Quali predittori includere nel modello?\nL‚Äôutilizzo del modello di regressione multipla ha principalmente due scopi. In primo luogo, √® utilizzato per la predizione, cio√® per ottenere la migliore stima possibile di \\(Y\\) utilizzando una combinazione lineare delle variabili \\(X_1, X_2, \\ldots, X_p\\). In questo contesto, i coefficienti \\(\\beta_i\\) sono considerati come pesi che permettono di effettuare questa previsione.\nIn secondo luogo, il modello di regressione multipla viene spesso utilizzato per descrivere le relazioni causali tra le variabili. Tuttavia, √® importante sottolineare che questo modello non √® stato originariamente creato per stabilire relazioni causali, ed √® necessario essere cauti nell‚Äôattribuire interpretazioni causali dirette ai coefficienti \\(\\beta_i\\). Questo perch√© il modello stima correttamente i coefficienti parziali di regressione solo quando tutte le variabili che influenzano \\(Y\\) sono incluse nel modello. Nella pratica, spesso non conosciamo tutte le variabili causalmente rilevanti, il che pu√≤ portare a problemi di errore di specificazione.\nI modello di regressione multipla rappresenta uno strumento potente per predire e analizzare le relazioni tra variabili. Tuttavia, √® fondamentale riconoscerne le limitazioni, specialmente quando si tentano interpretazioni causali. In ambiti come la psicologia, dove √® cruciale comprendere le dinamiche causali, diventa essenziale una scelta accurata delle variabili da includere nel modello per prevenire distorsioni nelle stime dei coefficienti di regressione.\nTradizionalmente, si riteneva vantaggioso includere nel modello il maggior numero possibile di variabili per ottenere un livello di ‚Äúcontrollo‚Äù statistico pi√π elevato. Tuttavia, come sottolineato da McElreath (2020), questo metodo pu√≤ trasformarsi in una ‚Äúinsalata causale‚Äù. Questo termine descrive una situazione in cui la mancanza di attenzione alla struttura causale tra le variabili pu√≤ portare all‚Äôinclusione di variabili di controllo inappropriate, causando distorsioni nelle stime.\nIn alcuni casi, l‚Äôinserimento di determinate variabili di controllo nel modello √® indispensabile per evitare distorsioni, mentre in altri casi, l‚Äôinclusione di variabili non pertinenti pu√≤ portare a risultati fuorvianti. Questo enfatizza l‚Äôimportanza di formulare ipotesi chiare e ben ponderate sulla struttura causale che intercorre tra le variabili in esame.\nL‚Äôefficacia e la validit√† dei risultati ottenuti tramite regressione dipendono strettamente dalla correttezza delle ipotesi causali formulate, sia esplicitamente che implicitamente, dal ricercatore. Pertanto, per superare i limiti dell‚Äôapproccio dell‚Äô‚Äúinsalata causale‚Äù, √® cruciale che la formulazione del modello di regressione rifletta attentamente tali ipotesi causali.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#utilizzo-della-regressione-multipla",
    "href": "chapters/linear_models/04_stan_multreg.html#utilizzo-della-regressione-multipla",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.7 Utilizzo della Regressione Multipla",
    "text": "58.7 Utilizzo della Regressione Multipla\nLa regressione √® il metodo pi√π comune per adattare una linea (o un iper-piano) che spiega la variazione di una variabile dipendente rispetto a una o pi√π variabili indipendenti. Utilizzare una o pi√π variabili per spiegare la variazione in un‚Äôaltra √® un concetto chiave dei modelli lineari.\n\n58.7.1 Identificazione degli Effetti Causali\nQuando si tratta di identificare effetti causali, la regressione √® il metodo pi√π comune per stimare la relazione tra due variabili, controllando contemporaneamente per altre variabili. Questo processo permette di chiudere ‚Äúporte backdoor‚Äù con questi controlli. √à pi√π preciso parlare di ‚Äúaggiustare‚Äù per queste variabili piuttosto che ‚Äúcontrollarle‚Äù, poich√© non esercitiamo un vero controllo come faremmo in un esperimento controllato. Tuttavia, il termine ‚Äúcontrollo‚Äù rimane il pi√π comunemente usato.\nEcco alcuni punti chiave:\n\nPredire una Variabile con un‚ÄôAltra: Possiamo utilizzare i valori di una variabile \\(X\\) per predire i valori di un‚Äôaltra variabile \\(Y\\). Questo √® chiamato spiegare \\(Y\\) utilizzando \\(X\\). Si tratta di una spiegazione puramente statistica che non chiarisce il motivo per cui \\(Y\\) accade, a meno che non abbiamo identificato un effetto causale di \\(X\\) su \\(Y\\).\nAdattare una Linea o un Iperpiano: Esistono diversi modi per modellare la relazione tra variabili; uno comune √® adattare una linea o un iperpiano. Ad esempio, nella regressione lineare standard \\(Y = a + bX\\), i coefficienti vengono stimati minimizzando la somma dei residui quadrati, ovvero la somma degli errori di previsione elevati al quadrato. Oppure, i coefficienti possono essere stimati con un metodo bayesiano. La qualit√† dell‚Äôapprossimazione dipende dalla linearit√† del vero modello.\nPro e Contro:\n\nPro: Utilizza efficientemente la variazione nei dati.\nPro: Una retta o un iperpiano sono facili da interpretare.\nContro: Pu√≤ perdere variazioni interessanti nei dati.\nContro: Se la forma funzionale scelta √® errata, i risultati possono essere inaccurati.\n\nInterpretazione dei Coefficienti: Il coefficiente associato a una variabile \\(X\\) pu√≤ essere interpretato come la pendenza: un aumento di un‚Äôunit√† in \\(X\\) √® associato a un aumento di \\(b\\) unit√† in \\(Y\\).\nCon pi√π Predittori: Con un solo predittore, la stima della pendenza √® la covarianza di \\(X\\) e \\(Y\\) divisa per la varianza di \\(X\\). Con pi√π predittori, la stima tiene conto delle correlazioni tra i diversi predittori.\nPrevisioni e Residui: Inserendo i valori predittivi di un‚Äôosservazione in una regressione stimata, otteniamo una previsione \\(\\hat{Y}\\). La differenza tra \\(Y\\) e \\(\\hat{Y}\\) rappresenta la parte non spiegata, chiamata ‚Äúresiduo‚Äù.\nAggiunta di un‚ÄôAltra Variabile: Aggiungendo una variabile \\(Z\\) all‚Äôequazione di regressione, il coefficiente di ciascuna variabile viene stimato utilizzando la variazione residua dopo aver rimosso quella spiegata dall‚Äôaltra variabile. Questo processo ‚Äúaggiusta per \\(Z\\)‚Äù.\nModelli Non Lineari: Se la relazione tra \\(X\\) e \\(Y\\) non √® ben rappresentata da una linea retta, possiamo utilizzare modelli non lineari. I modelli lineari possono essere adattati per previsioni non lineari mediante combinazioni lineari di variabili (sono ‚Äúlineari nei parametri‚Äù). Alternativamente, possiamo utilizzare modelli di regressione non lineare come il probit, il logit, o altri modelli avanzati.\n\nQuesti sono i concetti fondamentali della regressione. √à importante ricordare che, se il modello di regressione scelto si avvicina al vero modello della popolazione, le sue stime saranno generalmente accurate. Tuttavia, dobbiamo sempre tenere presente che il modello di regressione √® stato ideato per descrivere le associazioni tra variabili e non necessariamente per identificare rapporti causali, anche se spesso viene usato in questo modo ‚Äì si vedano il Capitolo 61 e il Capitolo 62.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#considerazioni-conclusive",
    "href": "chapters/linear_models/04_stan_multreg.html#considerazioni-conclusive",
    "title": "58¬† Regressione multipla con Stan",
    "section": "58.8 Considerazioni conclusive",
    "text": "58.8 Considerazioni conclusive\nNel suo libro Statistical Rethinking, McElreath (2020) introduce l‚Äôidea di modelli statistici paragonandoli ai Golem, antiche creature della mitologia, prive di volont√† propria e animate solo dall‚Äôintento di chi le crea. Questi enti, pur essendo dotati di grande forza, possono diventare pericolosi se non guidati con saggezza.\nMcElreath (2020) sostiene che gli scienziati, nella creazione di modelli matematici e software, diano vita a moderni equivalenti di questi Golem. Questi modelli, sebbene influenzino il mondo reale tramite le loro previsioni e le intuizioni che generano, non dovrebbero essere considerati n√© completamente veritieri n√© falsi. Essi sono piuttosto strumenti sviluppati con uno scopo specifico, capaci di operare calcoli con estrema precisione, ma privi della capacit√† di comprendere o interpretare il contesto pi√π ampio in cui sono applicati.\nIn particolare, il modello di regressione viene esaminato come esempio di come tali strumenti possano produrre risultati concreti, ma manchino di adattabilit√† e giudizio autonomo, limitando la loro efficacia nel trattare questioni che richiedono un approccio pi√π creativo e comprensivo. McElreath (2020) enfatizza ulteriormente che nessun strumento statistico, da solo, √® sufficiente per affrontare adeguatamente il complesso problema dell‚Äôinferenza causale a partire da dati empirici. Questi modelli, privi di una reale comprensione delle dinamiche di causa ed effetto, si limitano a descrivere relazioni tra variabili. Senza un‚Äôinterpretazione critica e un orientamento consapevole da parte degli scienziati, questi strumenti, creati per fini ben definiti, possono rivelarsi non solo inefficaci, ma anche potenzialmente dannosi.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "title": "58¬† Regressione multipla con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas     : 2.2.2\narviz      : 0.18.0\nmatplotlib : 3.9.1\ncmdstanpy  : 1.2.4\npingouin   : 0.5.4\nscipy      : 1.14.0\nstatsmodels: 0.14.2\nnumpy      : 1.26.4\nlogging    : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html",
    "href": "chapters/linear_models/05_hier_regr.html",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "",
    "text": "Introduzione\nI modelli multilivello rappresentano una tecnica statistica di fondamentale importanza per la psicologia, in particolare per quella sperimentale. Questi modelli affrontano efficacemente una delle principali limitazioni del modello di regressione tradizionale: l‚Äôassunzione di indipendenza delle osservazioni.\nNel modello di regressione classico, si presuppone che per ogni valore di \\(x\\), le osservazioni \\(y\\) siano campionate in modo indipendente dalla distribuzione \\(p(y \\mid x)\\). Ci√≤ implica che gli errori \\(y_i - E(Œ± + Œ≤x_i)\\) siano tra loro indipendenti, una condizione garantita solo in specifici disegni di ricerca, come il campionamento casuale semplice. Tuttavia, numerosi disegni sperimentali in psicologia violano questa assunzione. √à frequente, ad esempio, che lo stesso individuo venga osservato in diverse condizioni, generando una struttura di dati con osservazioni correlate o raggruppate (clustered).\nI modelli ad effetti misti, o multilivello, sono stati sviluppati proprio per gestire queste situazioni complesse, rendendoli particolarmente adatti per i disegni a misure ripetute, cos√¨ comuni nella ricerca psicologica. Questi modelli, conosciuti anche come modelli gerarchici, modelli ad effetti casuali o modelli nidificati, rappresentano un approccio efficace per l‚Äôanalisi di dati organizzati in gruppi o livelli.\nLa versatilit√† dei modelli gerarchici si manifesta nella loro applicabilit√† a diverse tipologie di dati: geograficamente nidificati (ad esempio, dati di citt√† all‚Äôinterno di province, province all‚Äôinterno di stati), organizzati gerarchicamente (come studenti all‚Äôinterno di scuole o pazienti in ospedali), o implicanti misurazioni ripetute sugli stessi individui. Questa flessibilit√† consente di gestire le complessit√† intrinseche a tali dati, tenendo conto sia delle variazioni condivise che di quelle uniche tra i gruppi.\nUn aspetto fondamentale dei modelli gerarchici √® la loro capacit√† di facilitare la condivisione di informazioni tra i gruppi. Ci√≤ avviene mediante l‚Äôimpiego di distribuzioni priori per i parametri, influenzate a loro volta da distribuzioni priori di livello superiore, comunemente chiamate iperpriori. Il prefisso ‚Äúiper‚Äù deriva dal termine greco per ‚Äúsopra‚Äù, indicando che queste distribuzioni priori operano a un livello superiore rispetto alle distribuzioni priori standard. Le distribuzioni degli iperparametri consentono al modello di equilibrare la descrizione delle caratteristiche specifiche dei gruppi con una descrizione delle tendenze comuni tra i gruppi.\nLa figura successiva illustra graficamente le differenze tra gli approcci dei modelli aggregati (dove i dati sono trattati come se provenissero da un unico gruppo), dei modelli non aggregati (dove ogni gruppo √® trattato separatamente) e dei modelli gerarchici (o parzialmente aggregati), dove le informazioni sono condivise tra i gruppi.\nNel contesto della regressione lineare gerarchica Bayesiana, l‚Äôutilizzo di librerie specializzate come Bambi facilita l‚Äôimplementazione di questi modelli complessi. Questa metodologia si rivela particolarmente utile nell‚Äôanalisi di dataset che comprendono diverse unit√† di osservazione, rappresentate dai soggetti, ciascuna delle quali √® associata a multiple misurazioni.\nPer una comprensione visiva pi√π intuitiva dei modelli gerarchici, si consiglia di consultare il demo interattivo di Michael Freeman, accessibile su questo sito.\nL‚Äôimportanza dei modelli multilivello in psicologia trascende la mera flessibilit√† statistica. Come discusso da Gelman e Brown (2024), questi modelli sono strettamente correlati alla cosiddetta ‚ÄúCrisi della Riproducibilit√†‚Äù, offrendo potenzialmente strumenti pi√π robusti per affrontare le sfide metodologiche attuali nel campo della ricerca psicologica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#introduzione",
    "href": "chapters/linear_models/05_hier_regr.html#introduzione",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "",
    "text": "Le differenze tra un modello aggregato (pooled), un modello non aggregato (unpooled) e un modello gerarchico. (Figura tratta da Martin (2024)).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#complete-pooling-no-pooling-partial-pooling",
    "href": "chapters/linear_models/05_hier_regr.html#complete-pooling-no-pooling-partial-pooling",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.1 Complete Pooling, No Pooling, Partial Pooling",
    "text": "59.1 Complete Pooling, No Pooling, Partial Pooling\nNei capitoli precedenti, √® stato introdotto il concetto di modellazione gerarchica bayesiana, con particolare attenzione alla stima dei parametri di distribuzioni di probabilit√†. Per un approfondimento su questo tema, si veda il Capitolo 52. Il presente capitolo si propone di estendere tale concetto alla stima dei parametri in un modello di regressione lineare, focalizzandosi sull‚Äôanalisi di dati suddivisi in vari gruppi.\nNell‚Äôaffrontare l‚Äôanalisi di dati provenienti da gruppi eterogenei, si possono delineare tre principali approcci metodologici, ciascuno con peculiari vantaggi e limitazioni:\n\nComplete Pooling: Questo modello prescinde dalla struttura gerarchica dei dati, trattando tutte le unit√† osservative come appartenenti a un‚Äôunica popolazione. Sebbene questo approccio possa incrementare la precisione delle stime attraverso l‚Äôaggregazione di tutti i dati, rischia di obliterare informazioni cruciali specifiche di ciascun gruppo, risultando potenzialmente eccessivamente generalizzante.\nNo Pooling: In antitesi al precedente, questo modello considera ogni gruppo come entit√† indipendente, ignorando qualsiasi struttura gerarchica. Questa metodologia, pur consentendo di evidenziare le peculiarit√† di ogni gruppo, pu√≤ condurre a conclusioni meno robuste a causa della mancanza di un contesto pi√π ampio e della potenziale scarsit√† di dati per singoli gruppi.\nPartial Pooling (o Modello Multi-Livello): Rappresenta un approccio intermedio e pi√π equilibrato. Questo modello presuppone che pendenze e intercette di ciascun gruppo siano realizzazioni di variabili casuali, distribuite normalmente con parametri di media e varianza condivisi tra tutti i gruppi.\n\nIl modello di ‚Äúpartial pooling‚Äù si distingue per la sua capacit√† di conciliare l‚Äôindipendenza dei gruppi con l‚Äôesigenza di un‚Äôanalisi aggregata. Questa metodologia facilita un adeguato ‚Äúshrinkage‚Äù dei parametri, attenuando l‚Äôimpatto di valori anomali o di gruppi con campioni limitati. Consente inoltre alle stime parametriche di ogni gruppo di essere influenzate sia dai dati specifici che dalla tendenza generale osservata nei dati aggregati.\nL‚Äôanalisi gerarchica, incarnata nel modello di partial pooling, offre quindi un compromesso ottimale tra gli approcci di complete pooling e no pooling, sintetizzando i benefici di entrambe le metodologie. Questo approccio permette di preservare le informazioni specifiche di ciascun gruppo, mantenendo al contempo una visione d‚Äôinsieme che migliora la robustezza e l‚Äôaccuratezza delle stime.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#eda",
    "href": "chapters/linear_models/05_hier_regr.html#eda",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.2 EDA",
    "text": "59.2 EDA\nIniziamo importando i dati e ispezionando la struttura delle osservazioni suddivise nei diversi cluster.\n\ndata = bmb.load_data(\"sleepstudy\")\ndata.head()\n\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n0\n249.5600\n0\n308\n\n\n1\n258.7047\n1\n308\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n\n\n\n\n\n\nEliminiamo le righe in cui la colonna ‚ÄúDays‚Äù ha valore 0 o 1 dal dataset ‚Äúsleepstudy‚Äù utilizzando il seguente codice:\n\ndata = data[data['Days'].isin([0, 1]) == False]\ndata.head()\n\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n5\n414.6901\n5\n308\n\n\n6\n382.2038\n6\n308\n\n\n\n\n\n\n\n\nAnalizziamo il tempo di reazione medio in relazione ai giorni di deprivazione del sonno, osservando come questo varia per ciascun soggetto coinvolto nello studio.\n\ndef plot_data(data):\n    fig, axes = plt.subplots(3, 6, sharey=True, sharex=True, dpi=100, constrained_layout=True)\n    fig.subplots_adjust(left=0.075, right=0.975, bottom=0.075, top=0.925, wspace=0.03)\n\n    axes_flat = axes.ravel()\n\n    for i, subject in enumerate(data[\"Subject\"].unique()):\n        ax = axes_flat[i]\n        idx = data.index[data[\"Subject\"] == subject].tolist()\n        days = data.loc[idx, \"Days\"].values\n        reaction = data.loc[idx, \"Reaction\"].values\n\n        # Plot observed data points\n        ax.scatter(days, reaction, color=\"#B17F7D\", ec=\"#832F2B\", alpha=0.7)\n\n        # Add a title\n        ax.set_title(f\"Subject: {subject}\", fontsize=9)\n\n    # Remove axis labels for individual plots\n    for ax in axes_flat:\n        ax.set_xlabel(\"\")\n        ax.set_ylabel(\"\")\n\n    # Set x-axis ticks for the last row\n    for ax in axes[-1]:\n        ax.xaxis.set_ticks([0, 2, 4, 6, 8])\n\n    return axes\n\n\nplot_data(data)\nplt.tight_layout()",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#modello-complete-pooling",
    "href": "chapters/linear_models/05_hier_regr.html#modello-complete-pooling",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.3 Modello complete pooling",
    "text": "59.3 Modello complete pooling\nIl modello complete pooling tratta tutte le osservazioni come se fossero indipendenti, aggregandole in un unico gruppo. In questo modello, le rette di regressione lineare per tutti i soggetti hanno la stessa pendenza e la stessa intercetta. Il modello pu√≤ essere descritto esplicitamente come segue:\nSe disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello pu√≤ essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha + \\beta \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto $ i $ all‚Äôosservazione $ j $.\n\\(\\alpha\\) √® l‚Äôintercetta comune a tutti i soggetti.\n\\(\\beta\\) √® la pendenza comune a tutti i soggetti.\n\\(\\epsilon_{ij}\\) √® il termine di errore casuale per il soggetto $ i $ all‚Äôosservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non distingue tra i gruppi di osservazoni che appartengono a soggetti diversi e stima un‚Äôunica pendenza e un‚Äôunica intercetta dai dati di tutti i soggetti. In Bambi, questo modello pu√≤ essere specificato utilizzando solo la variabile Days come predittore, senza includere il Subject come fattore.\n\nmodel_pooling = bmb.Model(\"Reaction ~ 1 + Days\", data)\n\nProcediamo con l‚Äôesecuzione del campionamento MCMC, utilizzando il metodo NUTS specifico per il campionatore JAX. Questo pu√≤ essere fatto semplicemente passando l‚Äôopzione method=\"nuts_numpyro\" durante la chiamata al campionamento. In questo modo, stiamo invocando direttamente il campionatore JAX, sfruttando le sue caratteristiche avanzate.\n\nresults_pooling = model_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_pooling.build()\nmodel_pooling.graph()\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(results_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nDays\n11.40\n1.85\n7.81\n14.75\n0.03\n0.02\n3973.92\n3076.45\n1.0\n\n\nIntercept\n245.43\n10.98\n225.74\n267.66\n0.18\n0.12\n3896.29\n2946.29\n1.0\n\n\nsigma\n51.06\n3.02\n45.62\n56.99\n0.05\n0.03\n3938.54\n3105.94\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#modello-no-pooling",
    "href": "chapters/linear_models/05_hier_regr.html#modello-no-pooling",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.4 Modello no-pooling",
    "text": "59.4 Modello no-pooling\nIl modello no-pooling tratta ogni soggetto come indipendente e adatta una retta di regressione separata per ciascun soggetto. Se disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello pu√≤ essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2), \\quad j = 1, \\ldots, n_i,\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto $ i $ all‚Äôosservazione $ j $.\n\\(\\alpha_i\\) √® l‚Äôintercetta per il soggetto $ i $.\n\\(\\beta_i\\) √® la pendenza per il soggetto $ i $.\n\\(\\epsilon_{ij}\\) √® il termine di errore casuale per il soggetto $ i $ all‚Äôosservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non fa alcuna ipotesi sulle relazioni tra diversi soggetti e stima la pendenza e l‚Äôintercetta di ciascun soggetto indipendentemente dagli altri soggetti. In Bambi, questo modello viene specificato con l‚Äôinterazione tra Days e Subject, come descritto in seguito.\n\nmodel_no_pooling = bmb.Model(\"Reaction ~ Days * C(Subject)\", data=data)\nresults_no_pooling = model_no_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_no_pooling.build()\nmodel_no_pooling.graph()\n\n\n\n\n\n\n\n\n\naz.summary(results_no_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nC(Subject)[309]\n-54.41\n33.08\n-117.14\n8.18\n1.59\n1.12\n434.16\n1234.93\n1.00\n\n\nC(Subject)[310]\n-28.46\n34.41\n-92.08\n37.71\n1.63\n1.15\n446.93\n959.79\n1.00\n\n\nC(Subject)[330]\n10.45\n33.17\n-52.07\n71.27\n1.58\n1.12\n439.74\n1159.39\n1.00\n\n\nC(Subject)[331]\n41.82\n33.96\n-21.18\n108.56\n1.58\n1.12\n459.56\n1007.98\n1.00\n\n\nC(Subject)[332]\n64.33\n32.98\n-0.26\n123.40\n1.55\n1.09\n455.09\n1173.28\n1.00\n\n\nC(Subject)[333]\n17.00\n33.88\n-44.18\n84.00\n1.59\n1.12\n453.44\n1102.92\n1.00\n\n\nC(Subject)[334]\n-44.39\n34.38\n-110.22\n20.77\n1.62\n1.15\n451.31\n1084.12\n1.00\n\n\nC(Subject)[335]\n24.00\n33.40\n-40.37\n85.95\n1.55\n1.10\n464.51\n1290.34\n1.01\n\n\nC(Subject)[337]\n21.28\n33.23\n-42.14\n83.67\n1.50\n1.06\n487.70\n1162.81\n1.00\n\n\nC(Subject)[349]\n-50.34\n34.18\n-115.10\n12.81\n1.68\n1.19\n414.36\n1113.99\n1.00\n\n\nC(Subject)[350]\n-45.34\n33.41\n-106.32\n19.24\n1.56\n1.10\n459.86\n1157.10\n1.00\n\n\nC(Subject)[351]\n0.29\n33.69\n-62.90\n62.81\n1.58\n1.12\n451.49\n1163.97\n1.00\n\n\nC(Subject)[352]\n69.17\n34.13\n2.46\n130.82\n1.61\n1.14\n447.47\n1004.66\n1.00\n\n\nC(Subject)[369]\n-7.34\n33.26\n-70.44\n54.57\n1.52\n1.07\n478.62\n1222.38\n1.00\n\n\nC(Subject)[370]\n-53.12\n33.72\n-114.47\n12.43\n1.56\n1.10\n468.51\n974.86\n1.00\n\n\nC(Subject)[371]\n-14.29\n33.53\n-77.62\n49.35\n1.60\n1.13\n439.26\n1256.78\n1.00\n\n\nC(Subject)[372]\n21.32\n34.08\n-43.82\n83.96\n1.61\n1.14\n446.77\n1161.10\n1.00\n\n\nDays\n21.33\n4.02\n13.42\n28.63\n0.25\n0.18\n255.36\n594.72\n1.01\n\n\nDays:C(Subject)[309]\n-17.11\n5.61\n-28.14\n-6.80\n0.27\n0.19\n436.25\n1113.11\n1.00\n\n\nDays:C(Subject)[310]\n-17.45\n5.76\n-27.71\n-6.12\n0.28\n0.19\n440.23\n1039.77\n1.00\n\n\nDays:C(Subject)[330]\n-13.34\n5.59\n-24.08\n-2.95\n0.27\n0.19\n430.17\n1107.97\n1.00\n\n\nDays:C(Subject)[331]\n-16.47\n5.72\n-27.68\n-6.03\n0.27\n0.19\n460.81\n1097.02\n1.00\n\n\nDays:C(Subject)[332]\n-18.88\n5.59\n-29.76\n-9.05\n0.26\n0.19\n453.06\n1013.31\n1.00\n\n\nDays:C(Subject)[333]\n-10.47\n5.71\n-21.47\n0.10\n0.27\n0.19\n452.59\n1044.24\n1.00\n\n\nDays:C(Subject)[334]\n-3.30\n5.78\n-14.05\n7.56\n0.28\n0.20\n436.59\n1060.73\n1.00\n\n\nDays:C(Subject)[335]\n-25.45\n5.68\n-36.25\n-14.82\n0.27\n0.19\n458.37\n1283.24\n1.01\n\n\nDays:C(Subject)[337]\n1.07\n5.56\n-9.53\n11.57\n0.26\n0.18\n473.85\n1269.32\n1.00\n\n\nDays:C(Subject)[349]\n-4.95\n5.75\n-15.76\n5.71\n0.28\n0.20\n425.03\n1378.41\n1.00\n\n\nDays:C(Subject)[350]\n1.93\n5.61\n-8.57\n12.23\n0.27\n0.19\n443.50\n968.05\n1.00\n\n\nDays:C(Subject)[351]\n-12.84\n5.68\n-23.47\n-2.20\n0.27\n0.19\n429.68\n1127.77\n1.00\n\n\nDays:C(Subject)[352]\n-13.93\n5.76\n-24.20\n-2.72\n0.27\n0.19\n467.87\n923.11\n1.00\n\n\nDays:C(Subject)[369]\n-7.62\n5.63\n-18.39\n2.79\n0.25\n0.18\n493.37\n1318.71\n1.00\n\n\nDays:C(Subject)[370]\n-0.68\n5.66\n-11.25\n10.11\n0.26\n0.19\n464.88\n1064.05\n1.00\n\n\nDays:C(Subject)[371]\n-8.92\n5.70\n-19.62\n1.93\n0.27\n0.19\n448.30\n1113.21\n1.00\n\n\nDays:C(Subject)[372]\n-10.15\n5.70\n-20.99\n0.46\n0.27\n0.19\n444.97\n1095.08\n1.00\n\n\nIntercept\n246.77\n23.80\n202.81\n291.98\n1.49\n1.05\n255.66\n503.10\n1.01\n\n\nsigma\n25.77\n1.73\n22.74\n29.02\n0.03\n0.02\n3514.27\n2909.58\n1.00\n\n\n\n\n\n\n\n\nPer ricavare i coefficienti \\(\\alpha\\) delle regressioni individuali, dobbiamo sommare Intercept al valore del singolo soggetto. Per esempio, per il soggetto 309 abbiamo\n\n246.98 + -55.29\n\n191.69\n\n\nFacciamo lo stesso per la pendenza individuale delle rette di regressione. Per il soggetto 309 otteniamo\n\n21.30 + -16.97\n\n4.330000000000002\n\n\nQuesti valori sono identici a quelli che si otterrebbero se adattassimo il modello di regressione separatamente per ciascun soggetto. In effetti, abbiamo fatto proprio questo, utilizzando un modello unico. Per esempio, esaminiamo i singoli dati del soggetto 309.\n\ndata_subject_309 = data[data[\"Subject\"] == 309]\ndata_subject_309.shape\n\n(8, 3)\n\n\nStimiamo l‚Äôintercetta e la pendenza della retta di regressione usando l‚Äôapproccio frequentista mediante la funzione linear_regression del pacchetto pingouin.\n\nresult = pg.linear_regression(data_subject_309[\"Days\"], data_subject_309[\"Reaction\"])\nprint(result)\n\n       names        coef        se          T          pval        r2  \\\n0  Intercept  191.576970  3.723259  51.454104  3.615788e-09  0.890144   \n1       Days    4.357144  0.624898   6.972569  4.325982e-04  0.890144   \n\n     adj_r2    CI[2.5%]   CI[97.5%]  \n0  0.871834  182.466483  200.687458  \n1  0.871834    2.828074    5.886214  \n\n\nSi noti che i risultati ottenuti sono sostanzialmente gli stessi, con solo qualche minima differenza numerica. Questa discrepanza deriva dalla diversit√† degli approcci utilizzati: in un caso abbiamo applicato un metodo bayesiano, mentre nell‚Äôaltro abbiamo adottato una tecnica di stima frequentista.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#modello-partial-pooling",
    "href": "chapters/linear_models/05_hier_regr.html#modello-partial-pooling",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.5 Modello partial pooling",
    "text": "59.5 Modello partial pooling\nIl modello gerarchico, conosciuto anche come modello di ‚Äúpartial pooling‚Äù, consente di gestire la complessit√† presente nei dati raggruppati o clusterizzati, come nel caso presente. La regressione lineare classica presume che ogni osservazione sia indipendente dalle altre, ma questa ipotesi viene meno quando i dati sono organizzati in gruppi. Le osservazioni all‚Äôinterno dello stesso gruppo tendono ad essere pi√π correlate tra loro rispetto a quelle in gruppi diversi. Trascurare questa struttura gerarchica potrebbe portare a stime errate e conclusioni fuorvianti.\nIl modello gerarchico affronta questo problema introducendo la nozione di effetti casuali, in contrapposizione agli effetti fissi del modello classico. Gli effetti fissi rappresentano l‚Äôeffetto medio di una variabile predittiva su tutti gli individui o gruppi, mentre gli effetti casuali considerano come l‚Äôeffetto di una variabile possa variare da un gruppo all‚Äôaltro. Mentre gli effetti fissi sono comuni a tutto il dataset, gli effetti casuali tengono conto delle differenze tra i gruppi.\nQuesto modello gerarchico unisce effetti fissi e casuali per fornire una rappresentazione pi√π accurata dei dati, quando questi mostrano relazioni gerarchiche o raggruppate. Il modello gerarchico di ‚Äúpartial pooling‚Äù considera le somiglianze tra i soggetti stimando un‚Äôintercetta e una pendenza comuni, ma consente anche variazioni individuali attorno a questi valori medi.\nPossiamo rappresentare matematicamente il modello come segue:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione del soggetto \\(i\\) al giorno \\(j\\).\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto \\(i\\) all‚Äôosservazione \\(j\\).\n\\(\\alpha_i\\) √® l‚Äôintercetta per il soggetto \\(i\\), che segue la distribuzione \\(\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2)\\).\n\\(\\beta_i\\) √® la pendenza per il soggetto \\(i\\), che segue la distribuzione \\(\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2)\\).\n\\(\\epsilon_{ij}\\) √® l‚Äôerrore casuale per il soggetto \\(i\\) all‚Äôosservazione \\(j\\), distribuito normalmente con media 0 e varianza costante \\(\\sigma^2\\).\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) rappresentano l‚Äôintercetta e la pendenza medie per tutti i soggetti, e le varianze \\(\\tau_\\alpha^2\\) e \\(\\tau_\\beta^2\\) quantificano le differenze tra gli individui.\nIn questo modo, il modello gerarchico riesce a rappresentare sia le informazioni comuni a tutti i soggetti, sia le differenze individuali, considerando sia gli effetti fissi che quelli casuali. Pu√≤ quindi offrire una visione pi√π completa e realistica dei dati, tenendo conto della loro struttura gerarchica. In Bambi, questo modello pu√≤ essere specificato utilizzando la variabile Days come predittore e includendo Subject come effetto casuale.\n\nmodel_partial_pooling = bmb.Model(\n    \"Reaction ~ 1 + Days + (Days | Subject)\", data, categorical=\"Subject\"\n)\n\nEseguiamo il campionamento.\n\nresults_partial_pooling = model_partial_pooling.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\n\nmodel_partial_pooling.build()\nmodel_partial_pooling.graph()\n\n\n\n\n\n\n\n\nEsaminiamo i risultati.\n\naz.summary(results_partial_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\n1|Subject[308]\n10.02\n18.26\n-23.88\n45.32\n0.30\n0.24\n3801.21\n3296.70\n1.0\n\n\n1|Subject[309]\n-43.21\n20.82\n-81.90\n-2.40\n0.37\n0.26\n3192.01\n2770.58\n1.0\n\n\n1|Subject[310]\n-25.98\n19.01\n-60.23\n10.11\n0.34\n0.24\n3180.64\n2886.98\n1.0\n\n\n1|Subject[330]\n4.68\n17.93\n-28.33\n39.60\n0.28\n0.25\n4049.42\n3086.98\n1.0\n\n\n1|Subject[331]\n22.05\n18.80\n-12.81\n57.32\n0.32\n0.24\n3416.40\n2908.07\n1.0\n\n\n1|Subject[332]\n34.64\n19.83\n-1.54\n71.69\n0.38\n0.27\n2774.25\n2704.53\n1.0\n\n\n1|Subject[333]\n11.22\n18.56\n-22.97\n47.30\n0.28\n0.24\n4343.31\n3323.77\n1.0\n\n\n1|Subject[334]\n-22.66\n18.29\n-55.72\n13.01\n0.33\n0.25\n3106.34\n2785.24\n1.0\n\n\n1|Subject[335]\n1.42\n18.81\n-33.38\n37.33\n0.33\n0.28\n3188.72\n2799.45\n1.0\n\n\n1|Subject[337]\n26.62\n19.63\n-9.98\n63.52\n0.31\n0.25\n4073.78\n2966.54\n1.0\n\n\n1|Subject[349]\n-27.94\n19.23\n-68.63\n4.02\n0.33\n0.24\n3381.72\n3363.24\n1.0\n\n\n1|Subject[350]\n-17.37\n19.44\n-54.77\n19.69\n0.33\n0.25\n3549.86\n2998.39\n1.0\n\n\n1|Subject[351]\n-2.22\n18.12\n-35.17\n33.75\n0.29\n0.26\n3981.53\n3361.50\n1.0\n\n\n1|Subject[352]\n43.03\n19.80\n3.35\n78.09\n0.40\n0.28\n2495.13\n2423.89\n1.0\n\n\n1|Subject[369]\n-2.06\n18.31\n-35.31\n32.90\n0.31\n0.26\n3570.39\n2953.34\n1.0\n\n\n1|Subject[370]\n-25.09\n18.76\n-58.40\n10.74\n0.34\n0.26\n3062.92\n3093.42\n1.0\n\n\n1|Subject[371]\n-7.11\n18.62\n-45.12\n24.89\n0.30\n0.26\n3873.47\n3069.79\n1.0\n\n\n1|Subject[372]\n15.17\n18.60\n-20.32\n50.26\n0.30\n0.24\n3831.96\n3202.78\n1.0\n\n\n1|Subject_sigma\n31.56\n9.02\n16.45\n50.30\n0.24\n0.17\n1431.60\n1806.76\n1.0\n\n\nDays\n11.50\n1.93\n7.87\n15.22\n0.05\n0.04\n1283.13\n1993.22\n1.0\n\n\nDays|Subject[308]\n8.10\n3.28\n2.23\n14.54\n0.07\n0.05\n2528.98\n2551.19\n1.0\n\n\nDays|Subject[309]\n-8.34\n3.67\n-15.35\n-1.50\n0.07\n0.06\n2401.88\n2808.43\n1.0\n\n\nDays|Subject[310]\n-7.38\n3.41\n-13.66\n-0.92\n0.07\n0.05\n2466.36\n3249.44\n1.0\n\n\nDays|Subject[330]\n-2.28\n3.30\n-8.32\n4.07\n0.07\n0.05\n2202.51\n2665.53\n1.0\n\n\nDays|Subject[331]\n-3.20\n3.36\n-9.57\n2.86\n0.07\n0.05\n2415.10\n2643.60\n1.0\n\n\nDays|Subject[332]\n-4.02\n3.54\n-10.46\n2.85\n0.08\n0.05\n2179.69\n2644.19\n1.0\n\n\nDays|Subject[333]\n0.46\n3.34\n-6.16\n6.42\n0.07\n0.05\n2638.74\n2977.03\n1.0\n\n\nDays|Subject[334]\n3.18\n3.30\n-3.22\n9.10\n0.07\n0.05\n2469.34\n2803.19\n1.0\n\n\nDays|Subject[335]\n-11.26\n3.48\n-18.02\n-4.83\n0.07\n0.05\n2639.50\n2714.43\n1.0\n\n\nDays|Subject[337]\n9.74\n3.53\n2.88\n16.27\n0.06\n0.05\n3136.50\n3060.31\n1.0\n\n\nDays|Subject[349]\n1.56\n3.39\n-4.91\n7.90\n0.07\n0.05\n2458.79\n2962.88\n1.0\n\n\nDays|Subject[350]\n7.23\n3.41\n0.87\n13.50\n0.07\n0.05\n2588.63\n2942.92\n1.0\n\n\nDays|Subject[351]\n-2.24\n3.26\n-7.88\n4.24\n0.06\n0.05\n2652.33\n2599.26\n1.0\n\n\nDays|Subject[352]\n0.18\n3.47\n-6.29\n6.87\n0.08\n0.05\n2071.05\n2663.67\n1.0\n\n\nDays|Subject[369]\n1.52\n3.29\n-4.94\n7.61\n0.07\n0.05\n2545.95\n2919.43\n1.0\n\n\nDays|Subject[370]\n4.78\n3.31\n-1.58\n10.65\n0.07\n0.05\n2263.23\n2665.64\n1.0\n\n\nDays|Subject[371]\n0.05\n3.33\n-6.09\n6.48\n0.06\n0.05\n2652.55\n2772.53\n1.0\n\n\nDays|Subject[372]\n0.77\n3.41\n-5.43\n7.29\n0.07\n0.05\n2455.49\n2748.16\n1.0\n\n\nDays|Subject_sigma\n6.89\n1.64\n4.07\n9.97\n0.04\n0.03\n1596.04\n1911.24\n1.0\n\n\nIntercept\n245.40\n9.34\n228.41\n262.89\n0.18\n0.12\n2855.59\n2917.47\n1.0\n\n\nsigma\n26.06\n1.84\n22.59\n29.37\n0.03\n0.02\n2872.83\n2912.40\n1.0\n\n\n\n\n\n\n\n\nConsideriamo il soggetto 309. Per questo soggetto l‚Äôintercetta √®\n\n245.24 + -42.22\n\n203.02\n\n\ne la pendenza della retta di regressione √®\n\n11.34 + -8.27\n\n3.0700000000000003\n\n\nSi noti che questi valori sono diversi da quelli ottenuti con la procedura di no-pooling. Entrambi i modelli di no pooling e il modello gerarchico di partial pooling riconoscono che ci possono essere differenze tra i diversi gruppi (o soggetti) nel dataset, ma gestiscono queste differenze in modi diversi.\nNel modello di no pooling, ogni gruppo viene trattato in modo completamente indipendente dagli altri. Ogni intercetta e pendenza viene stimata separatamente per ogni gruppo, senza fare riferimento agli altri gruppi. In altre parole, si adatta una regressione lineare separata per ciascun gruppo. Ci√≤ significa che se si hanno molti gruppi, ci saranno molti parametri da stimare.\nQuesto approccio pu√≤ catturare le differenze tra i gruppi molto accuratamente se ci sono molte osservazioni in ogni gruppo, ma pu√≤ essere problematico se ci sono poche osservazioni per gruppo. Inoltre, non sfrutta le informazioni comuni tra i gruppi e pu√≤ portare a stime molto variabili.\nIl modello gerarchico di partial pooling, invece, riconosce che, anche se ci sono differenze tra i gruppi, questi potrebbero condividere alcune caratteristiche comuni. Invece di stimare le intercette e pendenze completamente separatamente per ogni gruppo, il modello gerarchico stima una media comune e una varianza comune per l‚Äôintercetta e la pendenza, e poi consente a ciascun gruppo di variare attorno a questi valori comuni.\nQuesto porta al concetto di ‚Äúshrinkage‚Äù. Le stime delle intercette e pendenze per ciascun gruppo tendono a essere ‚Äúcompresse‚Äù verso i valori medi. Se un gruppo ha poche osservazioni, la sua stima sar√† pi√π fortemente influenzata dalla media comune. Se ha molte osservazioni, la sua stima sar√† meno influenzata dalla media comune. In questo modo, il modello riesce a bilanciare tra due tendenze opposte: rendere conto delle differenze tra i gruppi e sfruttare le informazioni comuni.\nIn sintesi, la differenza principale tra il modello no-pooling e il modello gerarchico partial-pooling sta nel modo in cui gestiscono le intercette e pendenze individuali:\n\nIl modello no-pooling tratta ogni gruppo separatamente, stimando le intercette e pendenze individuali senza considerare gli altri gruppi.\nIl modello gerarchico partial-pooling stima le intercette e pendenze comuni e consente a ciascun gruppo di variare attorno a questi valori comuni, dando luogo al fenomeno dello shrinkage.\n\nIl modello di no pooling pu√≤ essere pi√π adatto se i gruppi sono veramente indipendenti e molto diversi tra loro, mentre il modello gerarchico √® maggiormente appropriato quando ci sono somiglianze tra i gruppi che possono essere sfruttate per ottenere stime pi√π precise e robuste.\n\n59.5.1 Modello Gerarchico e Distribuzione dei Coefficienti\nIn un contesto di modello gerarchico con partial pooling, gli effetti casuali, inclusi intercette e pendenze specifiche per ciascun gruppo o individuo, vengono trattati come esiti di variabili aleatorie. Questo approccio si distingue nettamente da quello adottato nei modelli di no pooling, nei quali ciascun coefficiente viene considerato come un parametro statico e indipendente.\nAll‚Äôinterno di un modello gerarchico, l‚Äôassunzione di base √® che questi effetti casuali siano distribuiti normalmente. Ci√≤ implica che ogni coefficiente specifico di un gruppo o individuo (come l‚Äôintercetta per un dato soggetto) √® visto come una manifestazione di una variabile aleatoria che segue una distribuzione normale. La distribuzione di queste variabili aleatorie, che rappresenta la popolazione degli effetti casuali, √® caratterizzata da una media e una varianza condivise tra tutti i gruppi o soggetti, le quali vengono inferite direttamente dai dati raccolti. Questo permette di modellare la variabilit√† intra-gruppo e inter-gruppo in modo pi√π flessibile e informato, offrendo una rappresentazione pi√π accurata della struttura dei dati e delle relazioni sottostanti.\nAd esempio, le intercette individuali \\(\\alpha_i\\) possono essere modellate come:\n\\[\n\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2),\n\\]\ndove \\(\\alpha\\) √® l‚Äôintercetta media per tutti i soggetti e \\(\\tau_\\alpha^2\\) √® la varianza delle intercette tra i soggetti. Analogamente, le pendenze individuali \\(\\beta_i\\) possono essere modellate come:\n\\[\n\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2),\n\\]\ndove \\(\\beta\\) √® la pendenza media e \\(\\tau_\\beta^2\\) √® la varianza delle pendenze.\n\n\n59.5.2 Implicazioni\nQuesta struttura ha diverse implicazioni importanti:\n\nShrinkage: Come discusso in precedenza, le stime dei coefficienti individuali tendono a essere ‚Äúcompresse‚Äù verso i valori medi. Questo aiuta a stabilizzare le stime, specialmente quando ci sono poche osservazioni per gruppo.\nScambio di informazioni tra i gruppi: Poich√© i coefficienti individuali sono considerati come estratti dalla stessa distribuzione, ci√≤ permette uno scambio di informazioni tra i gruppi. Se un gruppo ha molte osservazioni, pu√≤ aiutare a informare le stime per un gruppo con poche osservazioni.\nInterpretazione gerarchica: Il modello riconosce una struttura gerarchica nei dati, con osservazioni raggruppate all‚Äôinterno di gruppi, e gruppi che condividono caratteristiche comuni. Questa struttura pu√≤ riflettere una realt√† sottostante nella quale gli individui o i gruppi non sono completamente indipendenti l‚Äôuno dall‚Äôaltro.\n\nIn conclusione, il modello gerarchico di partial-pooling offre un quadro flessibile e potente per analizzare dati raggruppati o clusterizzati, riconoscendo sia le somiglianze che le differenze tra i gruppi e utilizzando una struttura probabilistica per modellare le relazioni tra di loro.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#interpretazione",
    "href": "chapters/linear_models/05_hier_regr.html#interpretazione",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.6 Interpretazione",
    "text": "59.6 Interpretazione\nIniziamo considerando le stime a posteriori degli effetti fissi.\n\naz.summary(results_partial_pooling, var_names=[\"Intercept\", \"Days\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n245.4\n9.34\n228.41\n262.89\n0.18\n0.12\n2855.59\n2917.47\n1.0\n\n\nDays\n11.5\n1.93\n7.87\n15.22\n0.05\n0.04\n1283.13\n1993.22\n1.0\n\n\n\n\n\n\n\n\nIn media, il tempo di reazione medio delle persone all‚Äôinizio dello studio √® compreso tra 227 e 264 millisecondi. Con ogni giorno aggiuntivo di privazione del sonno, i tempi di reazione medi aumentano, in media, tra 7.9 e 15.1 millisecondi.\nL‚Äôinterpretazione degli effetti fissi √® semplice. Ma quest‚Äôanalisi sarebbe incompleta e fuorviante se non valutiamo i termini specifici per i singoli soggetti che abbiamo aggiunto al modello. Questi termini ci dicono quanto i soggetti differiscono l‚Äôuno dall‚Äôaltro in termini di tempo di reazione iniziale e dell‚Äôassociazione tra giorni di privazione del sonno e tempi di reazione.\nDi seguito, utilizziamo ArviZ per ottenere un traceplot delle intercetti specifiche per i soggetti 1|Subject e delle pendenze Days|Subject. Questo traceplot contiene due colonne. A sinistra, abbiamo le distribuzioni posteriori e a destra abbiamo i trace-plots. L‚Äôaspetto casuale stazionario, o l‚Äôapparenza di rumore bianco, ci dice che il campionatore ha raggiunto la convergenza e le catene sono ben mescolate.\n\naz.plot_trace(\n    results_partial_pooling, combined=True, var_names=[\"1|Subject\", \"Days|Subject\"]\n)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nDall‚Äôampiezza delle distribuzioni a posteriori delle intercette per i singoli soggetti possiamo vedere che il tempo di reazione medio iniziale per un determinato soggetto pu√≤ differire notevolmente dalla media generale che abbiamo visto nella tabella precedente. C‚Äô√® anche una grande differenza nelle pendenze. Alcuni soggetti vedono aumentare rapidamente i loro tempi di reazione quando vengono deprivati del sonno, mentre altri hanno una tolleranza migliore e peggiorano pi√π lentamente.\nUna rappresentazione grafica della stima a posteriore dei parametri e dei dati si ottiene con az.plot_forest().\n\naz.plot_forest(data=results_partial_pooling, r_hat=False, combined=True, textsize=8);\n\n\n\n\n\n\n\n\nIn sintesi, il modello gerarchico cattura il comportamento che abbiamo visto nella fase di esplorazione dei dati. Le persone differiscono sia nei tempi di reazione iniziali che nel modo in cui questi tempi di reazione sono influenzati dai giorni di deprivazione del sonno. Possiamo dunque giungere alle seguenti conclusioni:\n\nIl tempo di reazione medio delle persone aumenta quando sono deprivate del sonno.\nI soggetti hanno tempi di reazione diversi all‚Äôinizio dello studio.\nAlcuni soggetti sono pi√π colpiti dalla privazione del sonno rispetto ad altri.\n\nMa c‚Äô√® un‚Äôaltra domanda a cui non abbiamo ancora risposto: I tempi di reazione iniziali sono associati a quanto la deprivazione del sonno influisce sull‚Äôevoluzione dei tempi di reazione?\nCreiamo un diagramma a dispersione per visualizzare le stime a posteriori congiunte delle intercette e delle pendenze specifiche per i soggetti. Questo grafico usa colori diversi per i soggetti. Se guardiamo il quadro generale, cio√® trascurando i ragruppamenti dei dati in base ai soggetti, possiamo concludere che non c‚Äô√® associazione tra l‚Äôintercetta e la pendenza. In altre parole, avere tempi di reazione iniziali pi√π bassi o pi√π alti non dice nulla su quanto la deprivazione del sonno influisca sul tempo di reazione medio di un determinato soggetto.\nD‚Äôaltra parte, se guardiamo la distribuzione a posteriori congiunta per un determinato individuo, possiamo vedere una correlazione negativa tra l‚Äôintercetta e la pendenza. Questo indica che, condizionalmente a un determinato soggetto, le stime a posteriori dell‚Äôintercetta e della pendenza non sono indipendenti.\n\n#  extract a subsample from the posterior and stack the chain and draw dims\nposterior = az.extract(results_partial_pooling, num_samples=500)\n\n_, ax = plt.subplots()\n\nresults_partial_pooling.posterior.plot.scatter(\n    x=\"1|Subject\", y=\"Days|Subject\",\n    hue=\"Subject__factor_dim\",\n    add_colorbar=False,\n    add_legend=False,\n    edgecolors=None,\n)\n\nax.axhline(c=\"0.25\", ls=\"--\")\nax.axvline(c=\"0.25\", ls=\"--\")\nax.set_xlabel(\"Subject-specific intercept\")\nax.set_ylabel(\"Subject-specific slope\");",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#confronto-dei-modelli",
    "href": "chapters/linear_models/05_hier_regr.html#confronto-dei-modelli",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.7 Confronto dei modelli",
    "text": "59.7 Confronto dei modelli\nUn aspetto finale e cruciale del nostro studio riguarda il confronto tra i diversi modelli che abbiamo esaminato. La nostra intenzione √® determinare quale modello fornisce una rappresentazione migliore dei dati, trovando un equilibrio appropriato tra l‚Äôaccuratezza del modello e la sua complessit√†, cio√® la parsimonia.\nPer raggiungere questo scopo, faremo uso della metrica ELPD (Expected Log Predictive Density), che abbiamo introdotto in precedenza. ELPD ci consente di valutare un modello in termini di adattamento ai dati, considerando sia l‚Äôaccuratezza delle previsioni che la complessit√† del modello.\n\n59.7.1 Utilizzo di az.compare()\nIn Python, possiamo sfruttare la funzione az.compare() per confrontare direttamente modelli bayesiani. Questa funzione accetta un dizionario contenente gli oggetti InferenceData, risultanti dalla funzione Model.fit(), e restituisce un dataframe. I modelli vengono ordinati dal migliore al peggiore in base ai criteri selezionati, e di default, ArviZ usa il criterio di convalida incrociata ‚Äúleave one out‚Äù (LOO).\n\n59.7.1.1 Convalida Incrociata ‚ÄúLeave One Out‚Äù (LOO)\nLOO √® una tecnica di convalida che addestra il modello su tutti i dati disponibili tranne uno, utilizzando il singolo punto escluso come dati di test. Questo processo viene ripetuto per ogni punto dati nel set, e la media delle misure di errore fornisce una stima accurata dell‚Äôerrore di generalizzazione del modello. Anche se computazionalmente impegnativa, LOO fornisce una valutazione affidabile delle prestazioni del modello. In ArviZ, la funzione loo implementa questo metodo seguendo un approccio bayesiano.\n\n\n59.7.1.2 Widely Applicable Information Criterion (WAIC)\nOltre a LOO, possiamo anche utilizzare il criterio WAIC (Widely Applicable Information Criterion). Il WAIC √® uno strumento per la selezione del modello che mira a trovare il modello ottimale in un insieme di candidati, equilibrando l‚Äôadattamento ai dati e la complessit√† del modello, evitando cos√¨ il sovradattamento. WAIC √® particolarmente utile nel contesto bayesiano, poich√© tiene conto dell‚Äôincertezza associata ai parametri del modello.\nSia LOO che WAIC possono essere visti come stime empiriche dell‚ÄôELPD, fornendo un quadro comprensivo delle prestazioni dei modelli.\nUtilizzando la funzione az.compare(), siamo in grado di effettuare una comparazione rapida ed efficace tra i diversi modelli, valutandoli secondo i criteri LOO e WAIC. Nel nostro caso specifico, il modello di ‚Äúpartial pooling‚Äù emerge come il migliore, presentando il valore ELPD stimato pi√π alto. Questo risultato conferma la validit√† del modello nel rappresentare la struttura dei dati, tenendo conto delle differenze individuali all‚Äôinterno dei cluster, e fornendo una stima coerente e informativa dell‚Äôeffetto della deprivazione del sonno sul tempo di reazione.\n\nmodels_dict = {\n    \"pooling\": results_pooling,\n    \"no_pooling\": results_no_pooling,\n    \"partial_pooling\": results_partial_pooling\n}\ndf_compare = az.compare(models_dict)\ndf_compare\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\npartial_pooling\n0\n-692.203378\n31.116753\n0.000000\n0.945524\n21.750623\n0.000000\nTrue\nlog\n\n\nno_pooling\n1\n-694.239760\n35.771777\n2.036382\n0.004772\n21.582485\n3.251708\nTrue\nlog\n\n\npooling\n2\n-772.176595\n3.066678\n79.973217\n0.049704\n9.054093\n20.322146\nFalse\nlog\n\n\n\n\n\n\n\n\n√à importante sottolineare che, per ottenere una stima dell‚ÄôELPD (Expected Log Predictive Density), √® necessario includere l‚Äôopzione idata_kwargs={\"log_likelihood\": True} all‚Äôinterno della funzione responsabile dell‚Äôesecuzione del campionamento MCMC.\nLa figura che segue illustra visivamente le informazioni rilevanti per il confronto tra i diversi modelli. In grigio √® indicata l‚Äôincertezza nella stima della differenza tra i valori ELPD dei diversi modelli.\n\n_ = az.plot_compare(df_compare, insample_dev=False)\n\n\n\n\n\n\n\n\nIl confronto tra i modelli guida il processo di selezione. In particolare, la comparazione tra il modello di partial-pooling e il modello completo di pooling √® resa chiara dall‚Äôelpd_diff di 80.17 e dal suo errore standard di 19.97. Questi valori indicano inequivocabilmente che il modello di partial-pooling √® superiore.\nLa situazione diventa pi√π sfumata quando confrontiamo il modello di partial-pooling con il modello di no-pooling. In questo caso, le stime dell‚ÄôELPD mostrano una grande sovrapposizione, suggerendo che non c‚Äô√® una differenza netta tra i due modelli in termini di adattamento ai dati.\nTuttavia, nonostante la vicinanza dei valori di ELPD, il modello di partial-pooling √® da preferire. La ragione risiede nelle sue propriet√†: esso fornisce stime pi√π robuste e conservative delle differenze individuali. A differenza del modello di no-pooling, che pu√≤ essere troppo sensibile alle variazioni all‚Äôinterno dei cluster, il modello di partial-pooling incorpora un equilibrio tra la condivisione delle informazioni all‚Äôinterno del gruppo e il riconoscimento delle differenze tra i gruppi. Questo lo rende pi√π resistente alle fluttuazioni nei dati e offre una rappresentazione pi√π affidabile delle relazioni sottostanti, rendendolo la scelta preferibile in questo contesto.\n\n\n59.7.1.3 PPC plots\nPer affrontare il tema della selezione di modelli, Johnson, Ott, e Dogucu (2022) usano anche il metodo dei posterior predictive checks. Creiamo dunque i PPC plots per i tre modelli.\n\nmodel_pooling_fitted = model_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_pooling.predict(model_pooling_fitted, kind=\"pps\")\n\n\n_ = az.plot_ppc(model_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_no_pooling_fitted = model_no_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_no_pooling.predict(model_no_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_no_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_partial_pooling_fitted = model_partial_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_partial_pooling.predict(model_partial_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_partial_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\nIn questo contesto specifico, l‚Äôanalisi tramite i PPC (Posterior Predictive Checks) plots non rivela differenze evidenti tra i tre modelli in esame: tutti sembrano egualmente adeguati nell‚Äôadattarsi ai dati. Di conseguenza, i PPC plots non forniscono ulteriori chiarimenti o conferme alle conclusioni gi√† raggiunte attraverso il confronto tra modelli basato sulla differenza ELPD (Expected Log Predictive Density). In altre parole, l‚Äôanalisi visiva tramite i PPC plots non aggiunge valore o informazioni supplementari a quanto gi√† dedotto dalle metriche di confronto.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#conclusioni",
    "href": "chapters/linear_models/05_hier_regr.html#conclusioni",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "59.8 Conclusioni",
    "text": "59.8 Conclusioni\nIn questo capitolo, abbiamo analizzato e confrontato tre modelli statistici - pooling, no pooling e partial pooling - applicandoli ai dati dello studio sul sonno (Belenky et al. 2003). Ogni modello presenta caratteristiche distintive: il pooling si basa su una struttura comune, il no pooling mantiene l‚Äôindipendenza tra i gruppi, mentre il partial pooling offre un equilibrato compromesso tra i due approcci.\nPer selezionare il modello pi√π appropriato, abbiamo utilizzato l‚Äôanalisi basata sulla differenza della densit√† predittiva logaritmica attesa (ELPD). Questo metodo fornisce una misura obiettiva della qualit√† di adattamento, facilitando la scelta del modello che meglio riflette la struttura sottostante dei dati, pur riconoscendo i vantaggi specifici di ciascun approccio.\nLe tecniche statistiche impiegate in questo esempio rivestono particolare rilevanza nel campo della psicologia contemporanea. La ricerca psicologica moderna, infatti, si focalizza sempre pi√π su interazioni complesse anzich√© su semplici relazioni lineari. Gli studiosi tendono a esaminare l‚Äôeffetto di manipolazioni su cambiamenti nel tempo, piuttosto che su livelli assoluti, o a investigare come gli effetti possano variare tra diversi gruppi. L‚Äôelevata variabilit√† inter-individuale, inoltre, rende preferibile, quando possibile, effettuare confronti intra-soggetto.\nQuesta complessit√† intrinseca alla ricerca psicologica moderna rende l‚Äôanalisi dei dati particolarmente impegnativa. Gelman e Brown (2024) evidenziano come sia relativamente facile ottenere risultati statisticamente significativi da errori correlati e come i risultati pubblicati tendono ad essere eccessivamente ottimistici riguardo alle dimensioni dell‚Äôeffetto a causa della bassa potenza statistica e della selezione basata sulla significativit√† statistica (Ioannidis 2008).\nIn questo contesto, la modellazione multilivello emerge non solo come soluzione statistica a problemi comuni nella ricerca psicologica, ma anche come un approccio la cui corretta comprensione e applicazione pu√≤ contribuire ad affrontare una delle sfide pi√π pressanti nella pratica scientifica contemporanea: la replicabilit√† dei risultati della ricerca (per una discussione di questo punto, si veda Gelman e Brown (2024)).\nIn conclusione, l‚Äôadozione di metodologie statistiche avanzate, come la modellazione multilivello, rappresenta un passo cruciale verso una ricerca psicologica pi√π robusta e affidabile, in grado di cogliere la complessit√† dei fenomeni studiati e di produrre risultati pi√π facilmente replicabili e interpretabili.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "59¬† Il modello lineare gerarchico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npingouin  : 0.5.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nbambi     : 0.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBelenky, Gregory, Nancy J Wesensten, David R Thorne, Maria L Thomas, Helen C Sing, Daniel P Redmond, Michael B Russo, e Thomas J Balkin. 2003. ¬´Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: A sleep dose-response study¬ª. Journal of Sleep Research 12 (1): 1‚Äì12.\n\n\nGelman, Andrew, e Nicholas JL Brown. 2024. ¬´How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology¬ª.\n\n\nIoannidis, John PA. 2008. ¬´Why most discovered true associations are inflated¬ª. Epidemiology 19 (5): 640‚Äì48.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMartin, Osvaldo. 2024. Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html",
    "href": "chapters/linear_models/06_stan_mixed_models.html",
    "title": "60¬† Modelli misti con Stan",
    "section": "",
    "text": "Introduzione\nQuesto capitolo descrive l‚Äôutilizzo di Stan nell‚Äôanalisi dei dati mediante modelli misti. Per un approfondimento, si veda Sorensen e Vasishth (2015).",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html#applicazione-pratica",
    "href": "chapters/linear_models/06_stan_mixed_models.html#applicazione-pratica",
    "title": "60¬† Modelli misti con Stan",
    "section": "60.1 Applicazione Pratica",
    "text": "60.1 Applicazione Pratica\nPer fornire un esempio pratico, esamineremo i dati discussi da Gibson e Wu (2013) relativi a uno studio sulla comprensione delle frasi nelle proposizioni relative di soggetto e di oggetto. Una proposizione relativa di soggetto √® una frase in cui un sostantivo (ad esempio, ‚Äúsenatore‚Äù) viene modificato da una proposizione relativa (ad esempio, ‚Äúche ha interrogato il giornalista‚Äù), e il sostantivo modificato √® il soggetto grammaticale della proposizione relativa. In una proposizione relativa di oggetto, il sostantivo modificato dalla proposizione relativa √® l‚Äôoggetto grammaticale della proposizione (per esempio, ‚ÄúIl senatore che il giornalista ha interrogato si √® dimesso‚Äù). In entrambi i casi, il sostantivo modificato (‚Äúsenatore‚Äù) √® chiamato il sostantivo principale.\nUn risultato comune per l‚Äôinglese √® che le proposizioni relative di soggetto sono pi√π facili da elaborare rispetto a quelle di oggetto. Le lingue naturali, in generale, includono proposizioni relative, e fino a poco tempo fa il vantaggio delle proposizioni di soggetto √® stato considerato valido a livello cross-linguistico. Tuttavia, le proposizioni relative in cinese rappresentano un interessante controesempio a questa generalizzazione. Ricerche recenti condotte da Hsiao e Gibson (2003) hanno suggerito che in cinese le proposizioni relative di oggetto sono pi√π facili da elaborare rispetto a quelle di soggetto in un punto specifico della frase (il sostantivo principale della proposizione relativa). Viene presentata un‚Äôanalisi di un insieme di dati, successivamente pubblicata da Gibson e Wu (2013), che valuta questa affermazione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html#i-dati",
    "href": "chapters/linear_models/06_stan_mixed_models.html#i-dati",
    "title": "60¬† Modelli misti con Stan",
    "section": "60.2 I Dati",
    "text": "60.2 I Dati\nLa variabile dipendente dell‚Äôesperimento di Gibson e Wu (2013) era il tempo di lettura (rt) in millisecondi del sostantivo principale della proposizione relativa. Questo √® stato registrato in due condizioni (proposizione relativa di soggetto e proposizione relativa di oggetto), con 37 soggetti e 15 item, presentati in un disegno standard a quadrato latino. Originariamente c‚Äôerano 16 item, ma uno √® stato rimosso, risultando in 37 √ó 15 = 555 punti dati. Tuttavia, otto punti dati da un soggetto (id 27) erano mancanti. Di conseguenza, abbiamo un totale di 555 - 8 = 547 punti dati. La condizione (object relative / subject relative) √® codificata dalla variabile so.\n\nfile_path = os.path.join(project_directory, \"data\", \"gibson_wu_2013.csv\")\ngibson_data = pd.read_csv(file_path)\ngibson_data.head()\n\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n0\n1\n13\nobj-ext\n8\nÁî∑‰∫∫\n-\n1561\nheadnoun\nobject relative\n1\n\n\n1\n1\n6\nsubj-ext\n8\nÂ•≥Â≠©\n-\n959\nheadnoun\nsubject relative\n-1\n\n\n2\n1\n5\nobj-ext\n8\nËΩéËªä\n-\n582\nheadnoun\nobject relative\n1\n\n\n3\n1\n9\nobj-ext\n8\nÊé¢Âì°\n-\n294\nheadnoun\nobject relative\n1\n\n\n4\n1\n14\nsubj-ext\n8\nÁ©∫ÊúçÂì°\n-\n438\nheadnoun\nsubject relative\n-1\n\n\n\n\n\n\n\n\n\ngibson_data.tail()\n\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n542\n9\n15\nobj-ext\n8\nÊºîÂì°\n-\n406\nheadnoun\nobject relative\n1\n\n\n543\n9\n16\nsubj-ext\n8\nË®òËÄÖ\n-\n342\nheadnoun\nsubject relative\n-1\n\n\n544\n9\n7\nobj-ext\n8\nÁãó\n-\n478\nheadnoun\nobject relative\n1\n\n\n545\n9\n8\nsubj-ext\n8\nÊ•≠È§òÈÅ∏Êâã\n-\n510\nheadnoun\nsubject relative\n-1\n\n\n546\n9\n11\nobj-ext\n8\nÁêÉÂì°\n-\n350\nheadnoun\nobject relative\n1\n\n\n\n\n\n\n\n\n\ngibson_data.shape\n\n(547, 10)\n\n\n\ngibson_data[\"RT\"] = gibson_data[\"rt\"] / 1000\n\n\n_ = sns.kdeplot(data=gibson_data, x='RT', hue='so', fill=True, common_norm=False, alpha=0.5)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html#modello-ad-effetti-fissi",
    "href": "chapters/linear_models/06_stan_mixed_models.html#modello-ad-effetti-fissi",
    "title": "60¬† Modelli misti con Stan",
    "section": "60.3 Modello ad effetti fissi",
    "text": "60.3 Modello ad effetti fissi\nIniziamo facendo l‚Äôassunzione che la variabile dipendente del tempo di lettura (rt) sul sostantivo principale sia distribuita approssimativamente in modo log-normale (Rouder, 2005). Questo presuppone che il logaritmo di rt sia distribuito approssimativamente in modo normale. Il logaritmo dei tempi di lettura, logrt, ha una media Œ≤0 sconosciuta. La media della distribuzione log-normale di rt √® la somma di Œ≤0 e di uno scarto Œ≤1so il cui valore dipende dal predittore categoriale so, che assume il valore di -1 quando rt proviene dalla condizione di proposizione relativa di soggetto, e 1 quando rt proviene dalla condizione di proposizione relativa di oggetto.\nIl modello del logaritmo dei tempi di lettura √® dunque il seguente:\n\\[\nlogrt_i = \\beta_0 + \\beta_1 so_i + \\epsilon_i.\n\\]\nQuesto √® un modello a effetti fissi. L‚Äôindice i rappresenta la i-esima riga nel frame dati (in questo caso, i ‚àà {1, . . . , 547}); il termine Œµi rappresenta l‚Äôerrore nella i-esima riga. Con la variabile so codificata come indicato sopra indicato, Œ≤0 rappresenta la media di log rt, indipendentemente dal tipo di proposizione relativa. Il parametro Œ≤1 √® lo scarto rispetto a Œ≤0 in modo che la media di log rt sia Œ≤0 + 1Œ≤1 quando log rt proviene dalla condizione di proposizione relativa di oggetto, e Œ≤0 - 1Œ≤1 quando log rt proviene dalla condizione di proposizione relativa di soggetto. In tali circostanze, 2Œ≤1 corrisponde alla differenza tra le medie nelle condizioni di proposizione relativa di oggetto e di soggetto. Insieme, Œ≤0 e Œ≤1 costituiscono le componenti del modello che caratterizzano l‚Äôeffetto della manipolazione sperimentale (il tipo di proposizione relativa) sulla variabile dipendente rt. Questo √® un modello ad effetti fissi perch√© i parametri Œ≤0 e Œ≤1 non variano da soggetto a soggetto o da item a item.\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"fixed_effects.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N;                // Number of data points\n  vector[N] rt;                  // Reading time\n  vector[N] so;                  // Predictor, constrained between -1 and 1\n}\nparameters {\n  vector[2] beta;                // Intercept and slope\n  real&lt;lower=0&gt; sigma_e;         // Error standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Define the model for mu using vectorized operations\n  mu = beta[1] + beta[2] * so;\n\n  // Vectorized likelihood\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\nCreiamo un dizionario che include i dati nel formato atteso dal precedente codice Stan.\n\nstan_data = {\n    \"N\" : gibson_data.shape[0],\n    \"rt\" : gibson_data[\"RT\"],\n    \"so\" : gibson_data[\"so\"] \n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo le tracce.\n\n_ = az.plot_trace(fit, var_names=([\"beta\", \"sigma_e\"]), compact=False)\n\n\n\n\n\n\n\n\nEsaminiamo le medie a posteriori e gli intervalli di credibilit√† dei parametri.\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.03\n-0.90\n-0.80\n0.0\n0.0\n3535.32\n2985.81\n1.0\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.01\n0.0\n0.0\n4901.41\n3327.06\n1.0\n\n\nsigma_e\n0.60\n0.02\n0.56\n0.63\n0.0\n0.0\n4436.39\n2709.09\n1.0\n\n\n\n\n\n\n\n\nL‚Äôanalisi della distribuzione di Œ≤1 indica che approssimativamente il 94% della densit√† di probabilit√† a posteriori √® al di sotto dello zero, suggerendo che, in cinese, ci sia qualche evidenza che le proposizioni relative oggetto siano pi√π facili da elaborare rispetto alle proposizioni relative soggetto, dati i dati di Gibson e Wu (2013). Tuttavia, poich√© l‚Äôintervallo di credibilit√† al 95% include lo zero, potremmo essere riluttanti a trarre questa conclusione, se vogliamo adottare un approccio ‚Äúquasi frequentista‚Äù di test di ipotesi.\nTuttavia, √® importante notare che il modello ad effetti fissi presentato qui non √® comunque appropriato per i dati attuali. L‚Äôassunzione di indipendenza degli errori viene violata, perch√© abbiamo misure ripetute per ciascun soggetto e per ciascun item. I modelli lineari misti estendono il modello lineare per risolvere precisamente questo problema.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html#modello-ad-intercette-casuali",
    "href": "chapters/linear_models/06_stan_mixed_models.html#modello-ad-intercette-casuali",
    "title": "60¬† Modelli misti con Stan",
    "section": "60.4 Modello ad Intercette Casuali",
    "text": "60.4 Modello ad Intercette Casuali\nIl modello degli effetti fissi non √® adatto per i dati di Gibson e Wu (2013) poich√© non tiene conto del fatto che abbiamo misurazioni multiple per ciascun soggetto e item. Come gi√† accennato, queste misurazioni multiple portano a una violazione dell‚Äôassunzione di indipendenza degli errori. Inoltre, i coefficienti degli effetti fissi Œ≤0 e Œ≤1 rappresentano medie su tutti i soggetti e gli item, ignorando il fatto che alcuni soggetti saranno pi√π veloci e alcuni pi√π lenti della media; allo stesso modo, alcuni item saranno letti pi√π rapidamente della media e altri pi√π lentamente.\nNei modelli lineari misti, prendiamo in considerazione questa variabilit√† per soggetto e per item aggiungendo i termini di correzione u0j e w0k, che aggiustano Œ≤0 per il soggetto j e l‚Äôitem k. Questo scompone parzialmente Œµi in una somma di termini u0j e w0k, che sono gli aggiustamenti dell‚Äôintercetta Œ≤0 per il soggetto j e l‚Äôitem k associato a rt_i. Se il soggetto j √® pi√π lento della media di tutti i soggetti, uj sar√† un numero positivo, e se l‚Äôitem k viene letto pi√π velocemente della durata media di tutti gli item, allora wk sar√† un numero negativo. Ogni soggetto j ha il proprio aggiustamento u0j, e ogni item ha il proprio aggiustamento w0k. Questi aggiustamenti u0j e w0k sono chiamati intercette casuali (random intercepts) da Pinheiro e Bates (2000) e intercette variabili (varying intercepts) da Gelman e Hill (2007), e aggiustando Œ≤0 con questi termini miglioriamo la nostra capacit√† di tener conto della variabilit√† per i soggetti e per gli item.\nIl modello statistico ad intercette casuali assume che questi aggiustamenti sono distribuiti normalmente intorno allo zero con deviazione standard sconosciuta:\n\\[\nu_0 \\sim N(0, \\sigma_u),\n\\]\n\\[\nw_0 ‚àº N(0, \\sigma_w).\n\\]\nAvendo specificato il modello in questo modo, ci sono tre fonti di varianza: la deviazione standard degli errori œÉe, la deviazione standard delle intercette casuali per i soggetti, œÉu, e la deviazione standard delle intercette casuali per gli item, œÉw. Ci riferiamo a questi valori come alle componenti della varianza.\nEsprimiamo ora il logaritmo del tempo di lettura, prodotto dai soggetti j ‚àà {1, . . . , 37} che leggono gli item k ‚àà {1,‚Ä¶, 15}, nelle condizioni i ‚àà {1, 2} (1 si riferisce alle proposizioni soggetto, 2 alle proposizioni oggetto), come la seguente somma.\n\\[\n\\log rt_{ijk} = \\beta_0 + \\beta_{1i} + u_{0j} + w_{0k} + \\varepsilon_{ijk}.\n\\]\nNotiamo che stiamo utilizzando un modo leggermente diverso per descrivere il modello, rispetto al modello degli effetti fissi. Stiamo utilizzando indici per soggetto, item e condizione per identificare ciascuna riga del data frame. Inoltre, anzich√© scrivere \\(\\beta_1 so_i\\), indicizziamo direttamente Œ≤1 in funzione della condizione i (essendo so \\(\\in \\{-1, 1\\}\\)).\nQuesto √® un modello √® un modello ad effetti misti, e pi√π specificamente un modello ad intercette casuali. Il coefficiente \\(\\beta_{1i}\\) √® quello di maggior interesse; avr√† un valore medio ‚àíŒ≤1 per le proposizioni soggetto e Œ≤1 per le proposizioni oggetto a causa della codifica del contrasto. Quindi, se la nostra media a posteriori per Œ≤1 √® negativa, ci√≤ suggerirebbe che le proposizioni oggetto vengono lette pi√π velocemente delle proposizioni soggetto.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_intercepts.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:33:49 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n12:34:01 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  vector[J] u;                     // Subject intercepts\n  vector[K] w;                     // Item intercepts\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  real&lt;lower=0&gt; sigma_u;           // Subject standard deviation\n  real&lt;lower=0&gt; sigma_w;           // Item standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Priors\n  beta ~ normal(0, 5);             // Assuming a weakly informative prior for beta\n  u ~ normal(0, sigma_u);\n  w ~ normal(0, sigma_w);\n  sigma_e ~ exponential(1);\n  sigma_u ~ exponential(1);\n  sigma_w ~ exponential(1);\n\n  // Likelihood\n  mu = beta[1] + beta[2] * so + u[subj] + w[item];  // Vectorized computation of mu\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\n\nstan_data = {\n    'subj': pd.factorize(gibson_data['subj'])[0] + 1,\n    'item': pd.factorize(gibson_data['item'])[0] + 1,\n    'rt': gibson_data['RT'].values,\n    'so': gibson_data['so'].values,\n    'N': len(gibson_data),\n    'J': gibson_data['subj'].nunique(),\n    'K': gibson_data['item'].nunique()\n}\n\n\nfit = model.sample(data=stan_data)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.97\n-0.70\n0.0\n0.0\n1101.73\n1576.57\n1.0\n\n\nbeta[1]\n-0.04\n0.02\n-0.08\n0.01\n0.0\n0.0\n9851.81\n3141.84\n1.0\n\n\nsigma_e\n0.52\n0.02\n0.49\n0.55\n0.0\n0.0\n7247.72\n2689.88\n1.0\n\n\nsigma_u\n0.25\n0.04\n0.17\n0.33\n0.0\n0.0\n3714.95\n2902.11\n1.0\n\n\nsigma_w\n0.20\n0.05\n0.11\n0.30\n0.0\n0.0\n3978.74\n2983.07\n1.0\n\n\n\n\n\n\n\n\nSi noti che rispetto al Modello ad effetti fissi, la stima di œÉe √® pi√π piccola; questo perch√© ora vengono stimate due componenti di varianza aggiuntive. Si noti inoltre che l‚Äôintervallo di credibilit√† al 95% per la stima di Œ≤1 include lo zero; quindi, c‚Äô√® ancora qualche evidenza che le proposizioni oggetto siano pi√π facili delle proposizioni soggetto, ma non possiamo escludere la possibilit√† che non ci sia una differenza credibile nei tempi di lettura tra i due tipi di proposizioni relative.\nIl presente modello con intercette casuali assume che l‚Äôeffetto della variabile so sia lo stesso per ciascun soggetto.Ma questo non √® necessariamente vero. Per consentire al modello di tenere conto che l‚Äôeffetto della variabile so possa variare tra i soggetti, dobbiamo estendere il presente modello e trasformarlo in un modello che include sia intercette sia pendenze casuali.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "href": "chapters/linear_models/06_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "title": "60¬† Modelli misti con Stan",
    "section": "60.5 Random Intercepts, Random Slopes Model",
    "text": "60.5 Random Intercepts, Random Slopes Model\nPer esprimere la struttura descritta sopra nel modello lineare misto, dobbiamo specificare le pendenze casuali. Il primo cambiamento consiste nel permettere che la dimensione dell‚Äôeffetto per so varii per soggetto e per item. Consentiamo che la dimensione dell‚Äôeffetto vari per soggetto e per item includendo nel modello pendenze variabili per soggetto e per item, che costituiscono degli scarti rispetto alla pendenza fissa Œ≤1, allo stesso modo in cui le intercette variabili per soggetto e per item aggiustano l‚Äôintercetta fissa Œ≤0. Questo aggiustamento della pendenza per soggetto e per item √® espresso aggiustando Œ≤1 tramite due termini u1j e w1k. Questi termini rappresentano le pendenze casuali. Aggiungendo al modello tali termini aggiuntivi possiamo rendere conto del fatto che l‚Äôeffetto del tipo di proposizione relativa varia per soggetto j e per item k.\nEsprimiamo il logaritmo del tempo di lettura, prodotto dal soggetto j che legge l‚Äôitem k, come la seguente somma.\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_{1i} + u_{1ij} + w_{1ik} + \\epsilon_{ijk},\n\\]\ndove il pedice \\(i\\) indica le condizioni. Questo √® un modello di intercette variabili e pendenze variabili.\nIl modello √® specificato in linguaggio Stan come indicato nel file random_slopes.stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_slopes.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:35:00 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n12:35:11 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  matrix[2,J] u;                   // Subject intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_u;      // Subject standard deviations\n  matrix[2,K] w;                   // Item intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_w;      // Item standard deviations\n}\nmodel {\n  // Priors\n  for (j in 1:J) {\n    u[1,j] ~ normal(0, sigma_u[1]); // Prior for subject intercepts\n    u[2,j] ~ normal(0, sigma_u[2]); // Prior for subject slopes\n  }\n  \n  for (k in 1:K) {\n    w[1,k] ~ normal(0, sigma_w[1]); // Prior for item intercepts\n    w[2,k] ~ normal(0, sigma_w[2]); // Prior for item slopes\n  }\n  \n  // Likelihood\n  for (i in 1:N) {\n    real mu = beta[1] + u[1, subj[i]] + w[1, item[i]]\n              + (beta[2] + u[2, subj[i]] + w[2, item[i]]) * so[i];\n    rt[i] ~ lognormal(mu, sigma_e);\n  }\n}\n\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    iter_sampling = 2000,\n    iter_warmup = 1000,\n)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.98\n-0.71\n0.00\n0.0\n706.84\n302.85\n1.01\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.02\n0.00\n0.0\n1982.52\n4756.68\n1.00\n\n\nsigma_e\n0.52\n0.02\n0.48\n0.55\n0.00\n0.0\n2288.99\n5672.93\n1.00\n\n\nsigma_u[0]\n0.25\n0.04\n0.18\n0.34\n0.00\n0.0\n712.02\n275.18\n1.01\n\n\nsigma_u[1]\n0.06\n0.04\n0.01\n0.12\n0.01\n0.0\n39.10\n29.54\n1.09\n\n\nsigma_w[0]\n0.20\n0.05\n0.11\n0.30\n0.00\n0.0\n4099.46\n5332.27\n1.00\n\n\nsigma_w[1]\n0.04\n0.03\n0.00\n0.11\n0.00\n0.0\n114.76\n68.32\n1.03\n\n\n\n\n\n\n\n\nAnche in questo caso, Sorensen e Vasishth (2015) commentano che l‚Äôintervallo di credibilit√† al 95% per \\(\\beta_1\\) include lo zero.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "href": "chapters/linear_models/06_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "title": "60¬† Modelli misti con Stan",
    "section": "60.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate",
    "text": "60.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate\nSorensen e Vasishth (2015), nell‚Äôapprofondire l‚Äôanalisi dei dati presentati da Gibson e Wu (2013), propongono un avanzamento metodologico nel modello preso in considerazione, introducendo un modello a effetti misti che incorpora intercette e pendenze casuali correlate. La logica dietro questo approccio consiste nell‚Äôesaminare la possibilit√† che vi sia una relazione tra la velocit√† di lettura dei soggetti (espressa attraverso intercette casuali) e la loro reazione alle diverse tipologie di proposizioni (oggetto vs.¬†soggetto), ipotizzando che soggetti con una velocit√† di lettura superiore alla media possano esperire un rallentamento maggiore nel leggere proposizioni oggetto rispetto alle proposizioni soggetto, e viceversa. Questa ipotesi suggerisce l‚Äôesistenza di correlazioni tra le intercette casuali (che rappresentano variazioni individuali nella velocit√† di base di lettura) e le pendenze casuali (che rappresentano la variazione nella risposta al tipo di proposizione).\nPer integrare questa struttura nel modello lineare misto (LMM), √® essenziale modellare la correlazione tra intercette casuali e pendenze casuali. La formula del modello, la quale rimane inalterata rispetto alla versione precedente, √® rappresentata come segue:\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_1 + u_{1ij} + w_{1ik} + \\epsilon_{ijk}.\n\\]\nL‚Äôintroduzione di correlazioni tra intercette e pendenze casuali trasforma il modello in un approccio di intercette e pendenze correlate, richiedendo la definizione di una matrice di varianza-covarianza per gli effetti casuali. Questo implica la necessit√† di stabilire una relazione di covarianza tra le intercette casuali (per soggetto e per item) e le pendenze casuali (per soggetto e per item), suggerendo che le pendenze per soggetto (u1) potrebbero correlare con le intercette per soggetto (u0), cos√¨ come le pendenze per item (w1) potrebbero correlare con le intercette per item (w0). Questo approccio offre una visione pi√π dettagliata e accurata della dinamica tra velocit√† di lettura individuale e reazione alle differenti strutture sintattiche, arricchendo significativamente l‚Äôanalisi statistica dei dati comportamentali.\nNel contesto di questo insegnamento, non approfondiremo la formulazione del modello Stan che include la correlazione tra pendenze e intercette, data la sua complessit√† tecnica. Tuttavia, √® importante sottolineare che √® possibile ottenere risultati analoghi con un approccio pi√π accessibile utilizzando il pacchetto Bambi per Python. Questo strumento consente di specificare modelli statistici in maniera intuitiva e diretta. Per esempio, per incorporare la correlazione tra pendenze e intercette nel nostro modello, possiamo utilizzare la seguente sintassi con Bambi:\nmodel = bmb.Model(\"rt ~ so + (so | subject) + (so | item)\", data)\nQuesta espressione crea un modello in cui rt (il tempo di risposta) √® modellato come una funzione del tipo di proposizione so, con pendenze e intercette casuali correlate sia per subject che per item. L‚Äôuso di (so | subject) e (so | item) permette di modellare specificamente le variazioni nelle risposte attribuibili a differenze individuali tra i soggetti e caratteristiche uniche degli item, rispettivamente. Questa sintassi semplifica notevolmente l‚Äôimplementazione di modelli complessi, rendendo l‚Äôanalisi accessibile anche a chi possiede una conoscenza di base della statistica bayesiana e della modellazione statistica.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "60¬† Modelli misti con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGibson, Edward, e H-H Iris Wu. 2013. ¬´Processing Chinese relative clauses in context¬ª. Language and Cognitive Processes 28 (1-2): 125‚Äì55.\n\n\nSorensen, Tanner, e Shravan Vasishth. 2015. ¬´Bayesian linear mixed models using Stan: A tutorial for psychologists, linguists, and cognitive scientists¬ª. arXiv preprint arXiv:1506.06201.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_specification_error.html",
    "href": "chapters/linear_models/07_specification_error.html",
    "title": "61¬† Errore di specificazione",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo l‚Äôerrore di specificazione nei modelli di regressione lineare. L‚Äôerrore di specificazione si verifica quando una variabile importante viene omessa dal modello, causando stime dei coefficienti che risultano sistematicamente distorte e inconsistenti.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_specification_error.html#dimostrazione",
    "href": "chapters/linear_models/07_specification_error.html#dimostrazione",
    "title": "61¬† Errore di specificazione",
    "section": "61.1 Dimostrazione",
    "text": "61.1 Dimostrazione\nLa dimostrazione algebrica dell‚Äôerrore di specificazione nel modello di regressione, in caso di omissione di una variabile rilevante, coinvolge l‚Äôanalisi delle conseguenze che questa omissione ha sulla stima dei coefficienti di regressione.\nQuando un modello di regressione omette una variabile rilevante che √® correlata sia con la variabile dipendente \\(Y\\) sia con almeno una delle variabili indipendenti incluse nel modello, il coefficiente stimato per le variabili indipendenti incluse pu√≤ essere sistematicamente distorto.\nPer comprendere il bias causato dall‚Äôomissione di una variabile rilevante in un modello di regressione, √® essenziale analizzare dettagliatamente il calcolo delle covarianze e varianze coinvolte. Di seguito viene fornita una spiegazione dei passaggi algebrici che portano alla formulazione del bias di omissione variabile (Omitted Variable Bias, OVB).\n\n61.1.1 Modello Completo e Modello Ridotto\n\nModello Completo:\n\\[\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon\n\\]\nQui, \\(Y\\) √® la variabile dipendente, \\(X\\) e \\(Z\\) sono variabili indipendenti, \\(\\beta_0, \\beta_1, \\beta_2\\) sono i coefficienti, e \\(\\epsilon\\) √® il termine di errore.\nModello Ridotto (con omissione di \\(Z\\)):\n\\[\nY = \\alpha_0 + \\alpha_1 X + u\n\\]\ndove \\(u = \\beta_2 Z + \\epsilon\\) rappresenta il nuovo termine di errore che ora include l‚Äôeffetto non osservato di \\(Z\\).\n\n\n\n61.1.2 Decomposizione di \\(X\\)\nIpotesi:\n\\[ X = \\gamma_0 + \\gamma_1 Z + V \\]\ndove \\(V\\) √® una parte di \\(X\\) indipendente da \\(Z\\), quindi \\(\\text{Cov}(V, Z) = 0\\).\n\n\n61.1.3 Sostituzione nel Modello Ridotto\nSostituendo la decomposizione di \\(X\\) nel modello ridotto, otteniamo:\n\\[ Y = \\alpha_0 + \\alpha_1 (\\gamma_0 + \\gamma_1 Z + V) + u \\]\n\\[ Y = \\alpha_0 + \\alpha_1 \\gamma_0 + \\alpha_1 \\gamma_1 Z + \\alpha_1 V + \\beta_2 Z + \\epsilon \\]\n\\[ Y = (\\alpha_0 + \\alpha_1 \\gamma_0) + (\\alpha_1 \\gamma_1 + \\beta_2) Z + \\alpha_1 V + \\epsilon \\]\n\n\n61.1.4 Calcolo della Covarianza \\(\\text{Cov}(Y, X)\\)\n\\[ \\text{Cov}(Y, X) = \\text{Cov}(\\beta_1 X + \\beta_2 Z + \\epsilon, X) \\]\n\\[ \\text{Cov}(Y, X) = \\beta_1 \\text{Var}(X) + \\beta_2 \\text{Cov}(Z, X) \\]\ndove si usa che \\(\\text{Cov}(\\epsilon, X) = 0\\) poich√© \\(\\epsilon\\) √® indipendente da \\(X\\).\n\n\n61.1.5 Calcolo della Varianza di \\(X\\)\n\\[ \\text{Var}(X) = \\text{Var}(\\gamma_0 + \\gamma_1 Z + V) \\]\n\\[ \\text{Var}(X) = \\gamma_1^2 \\text{Var}(Z) + \\text{Var}(V) \\]\nAncora, \\(\\text{Cov}(Z, V) = 0\\) perch√© \\(V\\) √® definito come indipendente da \\(Z\\).\n\n\n61.1.6 Formula del Coefficiente Stimato \\(\\hat{\\alpha}_1\\)\n\\[ \\hat{\\alpha}_1 = \\frac{\\text{Cov}(Y, X)}{\\text{Var}(X)} \\]\n\\[ \\hat{\\alpha}_1 = \\beta_1 + \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\n\n\n61.1.7 Interpretazione del Bias\nIl bias nel coefficiente stimato \\(\\alpha_1\\), rispetto al vero coefficiente \\(\\beta_1\\), √® dato da:\n\\[ \\text{Bias}(\\hat{\\alpha}_1) = \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\nQuesto risultato dimostra che il bias √® direttamente proporzionale al coefficiente \\(\\beta_2\\) della variabile omessa \\(Z\\) e al rapporto di covarianza tra \\(Z\\) e \\(X\\) diviso per la varianza di \\(X\\). Questo bias pu√≤ essere positivo o negativo a seconda della direzione della correlazione tra \\(X\\) e \\(Z\\), e della grandezza di \\(\\beta_2\\).\n\n\n61.1.8 Conclusioni\nIn sintesi, l‚Äôomissione di \\(Z\\) introduce un bias nella stima di \\(\\alpha_1\\) che non riflette accuratamente \\(\\beta_1\\) se \\(Z\\) √® correlata sia con \\(Y\\) che con \\(X\\). Questo errore di specificazione pu√≤ portare a conclusioni errate sull‚Äôeffetto di \\(X\\) su \\(Y\\) e compromettere l‚Äôaccuratezza delle inferenze tratte dal modello di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_specification_error.html#un-esempio-numerico",
    "href": "chapters/linear_models/07_specification_error.html#un-esempio-numerico",
    "title": "61¬† Errore di specificazione",
    "section": "61.2 Un esempio numerico",
    "text": "61.2 Un esempio numerico\nImmaginiamo di analizzare l‚Äôimpatto di due variabili indipendenti, la motivazione e l‚Äôansia, sulla prestazione in un compito specifico. Supponiamo che l‚Äôansia influenzi negativamente la prestazione, mentre la motivazione abbia un effetto positivo.\nLa nostra simulazione evidenzia due scenari distinti:\n\nModello Completo: Quando sia la motivazione che l‚Äôansia sono incluse nel modello di regressione, il coefficiente di regressione per l‚Äôansia viene stimato correttamente come negativo, riflettendo il suo impatto negativo sulla prestazione. Questo conferma che, quando tutte le variabili rilevanti sono presenti, la stima dei loro effetti √® accurata e non distorta.\nModello Ridotto (omissione della motivazione): Se la motivazione, che √® positivamente correlata alla prestazione e positivamente correlata all‚Äôansia, viene omessa dal modello, osserviamo un cambiamento notevole nel coefficiente di regressione per l‚Äôansia. In questo modello ridotto, il coefficiente per l‚Äôansia pu√≤ addirittura diventare positivo, suggerendo erroneamente che l‚Äôansia abbia un effetto benefico sulla prestazione. Questo fenomeno si verifica perch√© l‚Äôeffetto indiretto e non osservato della motivazione sull‚Äôansia porta a una stima distorta quando la motivazione non √® controllata nel modello.\n\n\n# Generiamo dati casuali\nnp.random.seed(42)\nn = 100  # Numero di osservazioni\n\n# Variabili indipendenti con correlazione negativa tra loro\nmotivazione = np.random.normal(100, 10, n)\nansia = 200 + 0.75 * motivazione + np.random.normal(0, 5, n)\n\n# Variabile dipendente, con peso maggiore sulla motivazione rispetto all'ansia\nprestazione = 5 * motivazione - 1 * ansia + np.random.normal(0, 50, n)\n\n# Creazione DataFrame\ndata = pd.DataFrame(\n    {\"Motivazione\": motivazione, \"Ansia\": ansia, \"Prestazione\": prestazione}\n)\n\n\nmodel_full = bmb.Model(\"Prestazione ~ Motivazione + Ansia\", data=data)\nresults_full = model_full.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_full, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n-1.12\n1.18\n-3.33\n1.01\n0.02\n0.02\n2347.49\n2341.41\n1.0\n\n\nIntercept\n-83.86\n250.01\n-521.27\n393.71\n4.87\n3.59\n2641.21\n2665.94\n1.0\n\n\nMotivazione\n6.21\n1.01\n4.38\n8.11\n0.02\n0.01\n2359.56\n2569.60\n1.0\n\n\nPrestazione_sigma\n54.19\n3.86\n47.05\n61.19\n0.06\n0.05\n3580.58\n2684.47\n1.0\n\n\n\n\n\n\n\n\n\n# Analisi di regressione con pingouin\nresults_full = pg.linear_regression(data[[\"Motivazione\", \"Ansia\"]], data[\"Prestazione\"])\nresults_full\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-84.058695\n244.261908\n-0.344133\n7.314908e-01\n0.467656\n0.456679\n-568.850966\n400.733576\n\n\n1\nMotivazione\n6.222523\n0.977770\n6.363994\n6.510176e-09\n0.467656\n0.456679\n4.281920\n8.163125\n\n\n2\nAnsia\n-1.122768\n1.143817\n-0.981597\n3.287403e-01\n0.467656\n0.456679\n-3.392928\n1.147393\n\n\n\n\n\n\n\n\n\nmodel_ansia_only = bmb.Model(\"Prestazione ~ Ansia\", data=data)\nresults_ansia_only = model_ansia_only.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_ansia_only, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n4.66\n0.84\n3.01\n6.13\n0.01\n0.01\n3797.94\n2688.34\n1.0\n\n\nIntercept\n-1055.09\n229.27\n-1470.97\n-615.01\n3.71\n2.65\n3810.32\n2766.51\n1.0\n\n\nPrestazione_sigma\n64.14\n4.66\n55.82\n73.16\n0.08\n0.06\n3209.37\n2678.96\n1.0\n\n\n\n\n\n\n\n\n\nresults_ansia_only = pg.linear_regression(data[[\"Ansia\"]], data[\"Prestazione\"])\nresults_ansia_only\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-1052.984249\n226.249178\n-4.654091\n1.020933e-05\n0.245386\n0.237686\n-1501.968379\n-604.000119\n\n\n1\nAnsia\n4.653853\n0.824399\n5.645148\n1.608208e-07\n0.245386\n0.237686\n3.017861\n6.289846\n\n\n\n\n\n\n\n\nQuesta dimostrazione mette in luce l‚Äôimportanza di includere tutte le variabili rilevanti in un modello di regressione per evitare conclusioni fuorvianti e garantire che le stime dei coefficienti riflettano veramente le relazioni causali tra le variabili.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "title": "61¬† Errore di specificazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.13.1\npymc      : 5.15.1\npingouin  : 0.5.4\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\narviz     : 0.18.0\nbambi     : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html",
    "href": "chapters/linear_models/08_causal_inference.html",
    "title": "62¬† Inferenza causale",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo √® di introdurre il modello di regressione multipla e di discutere come esso si collega all‚Äôanalisi causale.\nIl modello di regressione offre indubitabili vantaggi: i coefficienti parziali di regressione consentono di isolare l‚Äôeffetto di una variabile, al netto dell‚Äôinfluenza delle altre variabili nel modello. Questo approccio permette di ottenere quello che viene chiamato ‚Äúcontrollo statistico‚Äù. Nel capitolo precedente, abbiamo introdotto il concetto di errore di specificazione: se escludiamo dal modello di regressione una variabile che ha un effetto causale su \\(Y\\) ed √® correlata con gli altri predittori, le stime degli effetti causali fornite dal modello di regressione saranno sistematicamente distorte. Questo potrebbe suggerire che sia meglio aggiungere al modello quanti pi√π predittori possibile, per massimizzare il controllo statistico e minimizzare la possibilit√† di un errore di specificazione.\nTuttavia, questo approccio, che McElreath (2020) chiama ‚Äúinsalata causale‚Äù, produce pi√π effetti negativi di quanti problemi risolva. In questo capitolo, esploreremo come la selezione delle variabili indipendenti da inserire nel modello di regressione richieda una conoscenza approfondita della struttura causale del fenomeno che si desidera descrivere. Senza una tale conoscenza, l‚Äôuso del modello di regressione pu√≤ risultare pi√π dannoso che utile.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html#confondimento",
    "href": "chapters/linear_models/08_causal_inference.html#confondimento",
    "title": "62¬† Inferenza causale",
    "section": "62.1 Confondimento",
    "text": "62.1 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l‚Äôassociazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l‚Äôassociazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\n\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\n\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\n\nf\n\n\n\n\n\n\n\n\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un‚Äôassociazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale √® condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando cos√¨ l‚Äôinfluenza di \\(U\\) su \\(E\\). L‚Äôassegnazione casuale dell‚Äôistruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non pu√≤ essere eseguito. In assenza di esperimenti, √® necessaria una soluzione statistica che blocchi il percorso non causale. In assenza di esperimenti, si pu√≤ condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l‚Äôeffetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) √® la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l‚Äôinfluenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento pu√≤ distorcere l‚Äôassociazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili pu√≤ isolare il percorso causale, permettendo di misurare accuratamente l‚Äôeffetto di una variabile sull‚Äôaltra.\nQuesta discussione ha un‚Äôimplicazione importante per il modello di regressione. Nel caso dell‚Äôesempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata pu√≤ introdurre distorsioni nei risultati dell‚Äôanalisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non √® possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html#confondimento-1",
    "href": "chapters/linear_models/08_causal_inference.html#confondimento-1",
    "title": "62¬† Inferenza causale",
    "section": "62.2 Confondimento",
    "text": "62.2 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l‚Äôassociazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l‚Äôassociazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\nimport graphviz\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\nf\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un‚Äôassociazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale √® condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando cos√¨ l‚Äôinfluenza di \\(U\\) su \\(E\\). L‚Äôassegnazione casuale dell‚Äôistruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non pu√≤ essere eseguito. In assenza di esperimenti, √® necessaria una soluzione statistica che blocchi il percorso non causale. Si pu√≤ condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l‚Äôeffetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) √® la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l‚Äôinfluenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento pu√≤ distorcere l‚Äôassociazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili pu√≤ isolare il percorso causale, permettendo di misurare accuratamente l‚Äôeffetto di una variabile sull‚Äôaltra.\nQuesta discussione ha un‚Äôimplicazione importante per il modello di regressione. Nel caso dell‚Äôesempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata pu√≤ introdurre distorsioni nei risultati dell‚Äôanalisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non √® possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html#bloccare-i-percorsi-backdoor",
    "href": "chapters/linear_models/08_causal_inference.html#bloccare-i-percorsi-backdoor",
    "title": "62¬† Inferenza causale",
    "section": "62.3 Bloccare i percorsi backdoor",
    "text": "62.3 Bloccare i percorsi backdoor\nBloccare i percorsi di confondimento tra un predittore \\(X\\) e un risultato \\(Y\\) √® noto come ‚Äúchiudere un percorso backdoor‚Äù. Non vogliamo che nessuna associazione spuria entri attraverso un percorso non causale che coinvolge il predittore \\(X\\). Nell‚Äôesempio sopra, il percorso \\(E \\leftarrow U \\rightarrow W\\) √® un percorso di backdoor, poich√© entra in \\(E\\) con una freccia e collega \\(E\\) a \\(W\\). Questo percorso non √® causale: intervenire su \\(E\\) non provocher√† un cambiamento in \\(W\\) attraverso questo percorso, ma produrr√† comunque un‚Äôassociazione tra \\(E\\) e \\(W\\).\nLa buona notizia √® che, dato un grafo aciclico diretto (DAG) causale, √® sempre possibile determinare quali variabili controllare per chiudere tutti i percorsi di backdoor. √à anche possibile identificare quali variabili non controllare per evitare di creare nuovi confondimenti. Esistono quattro tipi fondamentali di relazioni causali che combinano tutti i possibili percorsi: la biforcazione, la catena, il collider e il discendente. Pertanto, √® necessario comprendere solo questi quattro concetti e come fluisce l‚Äôinformazione in ciascuno di essi.\n\nConfondente: Una variabile \\(U\\) che causa sia il predittore \\(X\\) sia il risultato \\(Y\\). Aggiustare per un confondente (fork) √® necessario per ottenere stime non distorte.\n\nEsempio: \\(X \\leftarrow U \\rightarrow Y\\).\n\nCatena: Una sequenza di variabili in cui una causa l‚Äôaltra, formando un percorso diretto. Non si dovrebbe aggiustare per le variabili lungo questo percorso, poich√© rappresenta il percorso causale.\n\nEsempio: \\(X \\rightarrow Z \\rightarrow Y\\).\n\nCollider: Una variabile che √® causata da due altre variabili. Aggiustare per un collider pu√≤ introdurre confondimento, poich√© si crea un‚Äôassociazione spuria tra i due predittori.\n\nEsempio: \\(X \\rightarrow Z \\leftarrow Y\\).\n\nDiscendente: Una variabile che √® causata sia dal predittore \\(X\\) sia dal risultato \\(Y\\). Condizionare su un discendente pu√≤ introdurre un bias, distorcendo l‚Äôassociazione tra \\(X\\) e \\(Y\\).\n\nEsempio: \\(X \\rightarrow W \\leftarrow Y\\) con \\(W\\) che ha un effetto su \\(Z\\) (discendente).\n\n\nComprendere queste relazioni e sapere come intervenire su di esse √® fondamentale per costruire modelli di regressione che riflettano accuratamente le relazioni causali tra le variabili. Questo approccio permette di isolare gli effetti causali e di evitare le distorsioni introdotte da percorsi di backdoor.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "href": "chapters/linear_models/08_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "title": "62¬† Inferenza causale",
    "section": "62.4 Tipi di relazioni elementari nei DAG",
    "text": "62.4 Tipi di relazioni elementari nei DAG\nOgni DAG, per quanto grande e complicato, √® costruito sulle quattro relazioni elementari descritte in precedenza. Esaminiamole in dettaglio.\n\n62.4.1 Confondimento\nLa configurazione detta ‚Äúfork‚Äù rappresenta un classico caso di confondimento. Nel confondimento, una variabile \\(Z\\) √® una causa comune di due variabili \\(X\\) e \\(Y\\), generando una correlazione tra loro: \\(X \\leftarrow Z \\rightarrow Y\\). Se condiamo su \\(Z\\), allora \\(X\\) e \\(Y\\) diventano indipendenti.\n\nfork = Digraph(comment='Forchetta')\nfork.node('X', 'X', shape='plaintext')\nfork.node('Y', 'Y', shape='plaintext')\nfork.node('Z', 'Z', shape='plaintext')\nfork.edge('Z', 'X')\nfork.edge('Z', 'Y')\nfork\n\n\n\n\n\n\n\n\n\n62.4.1.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôistruzione (\\(X\\)) sul salario (\\(Y\\)) con \\(Z\\) che rappresenta lo status socioeconomico.\n\n\n62.4.1.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso non causale, isolando l‚Äôeffetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Introduce confondimento, portando a una stima distorta dell‚Äôeffetto di \\(X\\) su \\(Y\\).\n\n\nn = 1000\nZ = np.random.normal(0, 1, n)\nX = 0.5 * Z + np.random.normal(0, 1, n)\nY = 0.8 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.02\n0.04\n-0.09\n0.05\n0.0\n0.0\n6310.32\n3060.06\n1.0\n\n\nX\n0.30\n0.03\n0.23\n0.36\n0.0\n0.0\n5784.06\n2927.95\n1.0\n\n\nsigma\n1.23\n0.03\n1.18\n1.28\n0.0\n0.0\n6424.03\n3165.63\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.03\n0.03\n-0.08\n0.03\n0.0\n0.0\n5749.64\n3042.71\n1.0\n\n\nX\n-0.04\n0.03\n-0.10\n0.02\n0.0\n0.0\n3711.94\n3112.96\n1.0\n\n\nZ\n0.84\n0.04\n0.77\n0.90\n0.0\n0.0\n3850.83\n3388.92\n1.0\n\n\nsigma\n0.99\n0.02\n0.95\n1.03\n0.0\n0.0\n5593.71\n2941.94\n1.0\n\n\n\n\n\n\n\n\n\n\n\n62.4.2 Catena\nIn una catena, una variabile \\(X\\), influenza un mediatore \\(Z\\), che a sua volta influenza l‚Äôesito \\(Y\\): \\(X \\rightarrow Z \\rightarrow Y\\). Condizionare su \\(Z\\) blocca il percorso da \\(X\\) a \\(Y\\).\n\npipe = Digraph(comment='Tubo')\npipe.node('X', 'X', shape='plaintext')\npipe.node('Y', 'Y', shape='plaintext')\npipe.node('Z', 'Z', shape='plaintext')\npipe.edge('X', 'Z')\npipe.edge('Z', 'Y')\npipe\n\n\n\n\n\n\n\n\n\n62.4.2.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôapprendimento (\\(X\\)) sulla comprensione (\\(Y\\)) mediato dalla conoscenza (\\(Z\\)).\n\n\n62.4.2.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso causale, fornendo solo l‚Äôeffetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Misura l‚Äôeffetto totale di \\(X\\) su \\(Y\\).\n\n\nX = np.random.normal(0, 1, n)\nZ = 5 * X + np.random.normal(0, 1, n)\nY = 3 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Z': Z, 'Y': Y})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.10\n-0.15\n0.23\n0.0\n0.0\n6356.32\n2949.31\n1.0\n\n\nX\n14.95\n0.10\n14.77\n15.13\n0.0\n0.0\n6321.33\n3376.27\n1.0\n\n\nsigma\n3.20\n0.07\n3.06\n3.33\n0.0\n0.0\n6103.86\n2993.17\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.03\n-0.03\n0.10\n0.0\n0.0\n3132.72\n2315.01\n1.0\n\n\nX\n0.23\n0.16\n-0.09\n0.52\n0.0\n0.0\n1234.56\n1621.51\n1.0\n\n\nZ\n2.95\n0.03\n2.89\n3.01\n0.0\n0.0\n1231.93\n1656.26\n1.0\n\n\nsigma\n1.03\n0.02\n0.99\n1.07\n0.0\n0.0\n2903.70\n2513.20\n1.0\n\n\n\n\n\n\n\n\n\n\n\n62.4.3 Collider\nIn un collider, due variabili \\(X\\) e \\(Y\\) influenzano una terza variabile \\(Z\\): \\(X \\rightarrow Z \\leftarrow Y\\). Condizionare su \\(Z\\) pu√≤ indurre una correlazione spuria tra \\(X\\) e \\(Y\\).\n\ncollider = Digraph(comment='Collider')\ncollider.node('X', 'X', shape='plaintext')\ncollider.node('Y', 'Y', shape='plaintext')\ncollider.node('Z', 'Z', shape='plaintext')\ncollider.edge('X', 'Z')\ncollider.edge('Y', 'Z')\ncollider\n\n\n\n\n\n\n\n\nIl bias di selezione si verifica quando il campione che analizziamo non √® rappresentativo della popolazione a causa del processo di selezione. Questo pu√≤ portare a correlazioni spurie perch√© il processo di selezione pu√≤ favorire involontariamente alcune caratteristiche.\nIl bias del collider (o bias di stratificazione del collider) si verifica quando due variabili, \\(X\\) e \\(Y\\), influenzano una terza variabile \\(Z\\) (il collider). Se ci condiamo su \\(Z\\), possiamo indurre un‚Äôassociazione spuria tra \\(X\\) e \\(Y\\), anche se queste variabili sono scorrelate nella popolazione.\nNell‚Äôesempio tratto da McElreath (2020)`, si suggerisce che sembra che gli studi scientifici pi√π degni di nota siano i meno affidabili. Pi√π √® probabile che uno studio sia interessante, se vero, meno √® probabile che sia vero. Pi√π noioso √® il tema, pi√π rigorosi sono i risultati. Come pu√≤ esistere questa correlazione negativa, ampiamente creduta da molti?\nIn realt√†, tutto ci√≤ che √® necessario affinch√© emerga una tale correlazione negativa √® che ci si preoccupin sia della rilevanza che dell‚Äôaffidabilit√†. Che si tratti di revisione di sovvenzioni o di riviste, se editori e revisori si preoccupano di entrambi gli aspetti, allora l‚Äôatto stesso della selezione √® sufficiente a rendere gli studi pi√π rilevanti i meno affidabili. Infatti, √® difficile immaginare come il processo di peer review possa evitare di creare questa correlazione negativa.\nEcco una semplice simulazione per illustrare il concetto. Supponiamo che un pannello di revisione delle sovvenzioni riceva 200 proposte di ricerca. Tra queste proposte, non vi √® alcuna correlazione tra affidabilit√† (rigore, erudizione, plausibilit√† del successo) e rilevanza (valore per il benessere sociale, interesse pubblico). Il pannello pesa in ugual misura l‚Äôaffidabilit√† e la rilevanza. Successivamente, classificano le proposte in base ai loro punteggi combinati e selezionano il 10% migliore per il finanziamento.\n\n# Numero di proposte da finanziare\nN = 200\n# Proporzione da selezionare\np = 0.1\n# Rilevanza non correlata\nnw = np.random.randn(N)\n# Affidabilit√† non correlata\ntw = np.random.randn(N)\ncorrelation = np.corrcoef(tw, nw)[0, 1]\nprint(correlation)\n\n0.026051430796600182\n\n\nNello script, il processo di selezione basato sul punteggio combinato s induce una correlazione spuria tra nw e tw. Sebbene nw e tw siano non correlati nell‚Äôintero dataset, essi appaiono correlati nel sottoinsieme selezionato.\n\n# Punteggio totale\ns = nw + tw\n# Soglia per il 10% migliore\nq = np.quantile(s, 1 - p)\n# Selezionati\nselected = s &gt;= q\n# Correlazione tra affidabilit√† e rilevanza nei selezionati\ncorrelation = np.corrcoef(tw[selected], nw[selected])[0, 1]\nprint(correlation)\n\n-0.7082917138754293\n\n\nSi noti che:\n\nIl punteggio combinato s agisce come un collider perch√© √® influenzato sia da nw che da tw.\nQuando selezioniamo le proposte basandoci su s (condizioniamo su s), introduciamo involontariamente una correlazione tra nw e tw nel sottoinsieme selezionato.\n\nIn altre parole, condizionando su una variabile (s) che √® influenzata sia da nw che da tw, induciamo una correlazione spuria tra queste due variabili non correlate. Questo √® un esempio specifico di bias del collider, dove il processo di selezione agisce come il collider.\nPer riassumere:\n\nBias di selezione: in questo esempio si verifica perch√© analizziamo solo il 10% delle proposte migliori.\nBias del collider: √® introdotto perch√© la variabile di selezione s (punteggio totale) √® influenzata sia da nw che da tw, portando a una correlazione spuria quando condiamo su s.\n\nQuindi, la correlazione spuria osservata nel sottoinsieme selezionato √® il risultato del bias del collider introdotto dal processo di selezione basato sul punteggio combinato.\nPerch√© la correlazione √® negativa nel sottoinsieme di dati selezionato? Perch√©, ad esempio, se una proposta selezionata ha una bassa affidabilit√† (tw), deve avere un‚Äôalta rilevanza (nw). Altrimenti, non sarebbe stata finanziata. Lo stesso vale al contrario: se una proposta ha una bassa rilevanza (nw), possiamo dedurre che deve avere un‚Äôaffidabilit√† superiore alla media. Altrimenti, non sarebbe stata selezionata per il finanziamento. Questo √® il concetto chiave da comprendere: quando condiamo su un collider, si creano associazioni statistiche, ma non necessariamente causali, tra le sue cause.\n\n\n62.4.4 Discendente\nUn discendente √® una variabile influenzata da un‚Äôaltra variabile. Condizionare su un discendente significa parzialmente condizionare sul suo genitore. Nel DAG seguente, condizionare su \\(D\\) condizioner√† anche, in una certa misura, su \\(Z\\).\n\ndescendant = Digraph(comment='Discendente')\ndescendant.node('X', 'X', shape='plaintext')\ndescendant.node('Y', 'Y', shape='plaintext')\ndescendant.node('Z', 'Z', shape='plaintext')\ndescendant.node('D', 'D', shape='plaintext')\ndescendant.edge('X', 'Z')\ndescendant.edge('Y', 'Z')\ndescendant.edge('Z', 'D')\ndescendant\n\n\n\n\n\n\n\n\nQuesto perch√© \\(D\\) contiene informazioni su \\(Z\\), che a sua volta √® un collider tra \\(X\\) e \\(Y\\). Condizionare su \\(D\\) pu√≤ aprire parzialmente il percorso da \\(X\\) a \\(Y\\) attraverso \\(Z\\), creando un‚Äôassociazione spuria tra \\(X\\) e \\(Y\\). Tuttavia, l‚Äôeffetto di condizionare su un discendente dipende dalla relazione tra il discendente e il suo genitore. I discendenti sono comuni nei modelli causali perch√© spesso non possiamo misurare una variabile direttamente e dobbiamo utilizzare un proxy per essa.\n\n62.4.4.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôintelligenza (\\(X\\)) sul punteggio del test (\\(Y\\)) tramite il tempo di apprendimento (\\(Z\\)) e il punteggio in una simulazione (\\(D\\)).\n\n\n62.4.4.2 Conseguenze del Controllo\n\nControllare \\(D\\): Pu√≤ introdurre bias, creando un percorso non causale da \\(X\\) a \\(Y\\) attraverso \\(Z\\).\nNon controllare \\(D\\): Mantiene il percorso causale corretto da \\(X\\) a \\(Y\\).\n\n\nI = np.random.normal(100, 15, n)\nT = 200 - I + np.random.normal(0, 1, n)\nS = 0.5 * I + 0.1 * T + np.random.normal(0, 1, n)\nD = 0.7 * S + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'I': I, 'T': T, 'S': S, 'D': D})\n\n# Modello senza controllo per D\nmod1 = bmb.Model('S ~ T', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n99.39\n0.24\n98.92\n99.82\n0.0\n0.0\n5831.85\n3060.37\n1.0\n\n\nT\n-0.39\n0.00\n-0.40\n-0.39\n0.0\n0.0\n5879.01\n3269.97\n1.0\n\n\nsigma\n1.10\n0.02\n1.05\n1.14\n0.0\n0.0\n6041.49\n3081.54\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per D\nmod2 = bmb.Model('S ~ T + D', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nD\n0.50\n0.02\n0.45\n0.54\n0.00\n0.00\n2526.07\n2095.97\n1.0\n\n\nIntercept\n64.78\n1.58\n61.69\n67.64\n0.03\n0.02\n2486.35\n2167.12\n1.0\n\n\nT\n-0.26\n0.01\n-0.27\n-0.24\n0.00\n0.00\n2490.85\n2271.87\n1.0\n\n\nsigma\n0.90\n0.02\n0.86\n0.94\n0.00\n0.00\n3237.43\n2629.65\n1.0",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "href": "chapters/linear_models/08_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "title": "62¬† Inferenza causale",
    "section": "62.5 Come aprire o chiudere un percorso nei DAG",
    "text": "62.5 Come aprire o chiudere un percorso nei DAG\nPer determinare quali variabili includere o escludere nel modello di regressione, √® necessario seguire questa procedura:\n\nElencare tutti i percorsi che collegano \\(X\\) (la potenziale causa di interesse) e \\(Y\\) (il risultato).\nClassificare ciascun percorso come aperto o chiuso. Un percorso √® aperto a meno che non contenga un collider.\nIdentificare i percorsi di backdoor. Un percorso di backdoor ha una freccia che entra in \\(X\\).\nChiudere i percorsi di backdoor aperti: Se ci sono percorsi di backdoor aperti, decidere su quali variabili condizionare per chiuderli, se possibile.\n\nCondizionare su una variabile significa includerla nel modello di regressione. Per chiudere un percorso di backdoor, identifichiamo la variabile di confondimento che crea l‚Äôassociazione spuria e la includiamo nel modello. Questo bloccher√† il percorso, impedendo che l‚Äôassociazione spuria influenzi il risultato.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_causal_inference.html#riflessioni-conclusive",
    "title": "62¬† Inferenza causale",
    "section": "62.6 Riflessioni conclusive",
    "text": "62.6 Riflessioni conclusive\nIn conclusione, le osservazioni precedenti dimostrano che l‚Äôinferenza causale non pu√≤ essere affrontata semplicemente applicando meccanicamente il modello statistico della regressione lineare. Senza ulteriori conoscenze, che non possono essere derivate esclusivamente dai dati osservati, non √® possibile ottenere stime non distorte degli effetti causali. L‚Äôinferenza causale va oltre le tecniche statistiche: essa richiede informazioni supplementari sulle caratteristiche del fenomeno studiato.\nPer trarre conclusioni corrette sui meccanismi causali, √® essenziale disporre di informazioni dettagliate sul processo generativo dei dati. Bench√© spesso queste informazioni non siano direttamente disponibili, i ricercatori possono adottare strategie per minimizzare il rischio di errori interpretativi. Un passo fondamentale consiste nell‚Äôidentificare ipotetici meccanismi causali prima di procedere con le stime degli effetti, utilizzando diagrammi causali come i grafici aciclici diretti per mappare le relazioni tra le variabili. Questo processo aiuta a determinare quali fattori includere nell‚Äôanalisi, seguendo il ‚Äúbackdoor criterion‚Äù proposto da Judea Pearl, per chiudere i percorsi indiretti tra esposizione ed esito che potrebbero introdurre confondimenti.\nIn assenza di una comprensione del fenomeno in esame, √® cruciale che i ricercatori prestino attenzione all‚Äôordine temporale dei fattori. Questo approccio, fondamentale per l‚Äôinferenza causale, implica che l‚Äôesposizione avvenga prima dell‚Äôesito per stabilire una relazione causale plausibile. Inoltre, √® importante che tutte le covariate considerate nell‚Äôanalisi precedano temporalmente l‚Äôesposizione per evitare potenziali bias di specificazione, specialmente nei contesti di collider e mediazione. Seguendo questi principi, i ricercatori possono ridurre il rischio di stime errate degli effetti causali.\n\n\n\n\n\n\n\nTermine Tecnico\nSpiegazione\n\n\n\n\n(1) Collider\nLa variabile \\(X\\), causa \\(Z\\), e l‚Äôesito, \\(Y\\), causa \\(Z\\). Aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.45X + 0.77Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)\n\n\n(2) Confounder\nLa variabile \\(Z\\) causa sia la variabile indipendente \\(X\\), sia l‚Äôesito, \\(Y\\). Non aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(Z \\sim \\mathcal{N}(0,1)\\), \\(X = Z + \\varepsilon_x\\), \\(\\varepsilon_x \\sim \\mathcal{N}(0,1)\\); \\(Y = 0.5X + Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(3) Mediator\nLa variabile \\(X\\) causa \\(Z\\) che a sua volta causa l‚Äôesito \\(Y\\). Aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene l‚Äôeffetto diretto, non aggiustando per \\(Z\\) si ottiene l‚Äôeffetto totale di \\(X\\) su \\(Y\\). L‚Äôeffetto diretto rappresenta la relazione tra \\(X\\) e \\(Y\\) indipendentemente da qualsiasi mediatore, mentre l‚Äôeffetto totale include sia l‚Äôeffetto diretto sia qualsiasi effetto indiretto mediato dal mediatore potenziale. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Z = X + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\); \\(Y = Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(4) Discendente\nLa variabile \\(X\\) e l‚Äôesito \\(Y\\) hanno una variabile discendente comune \\(Z\\). Non aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene una stima non distorta. Tuttavia, aggiustando per \\(Z\\), si introduce un bias. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.5X + 0.5Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "62¬† Inferenza causale",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnetworkx   : 3.3\npandas     : 2.2.2\nbambi      : 0.14.0\nseaborn    : 0.13.2\ngraphviz   : 0.20.3\nnumpy      : 1.26.4\narviz      : 0.18.0\nmatplotlib : 3.9.1\nstatsmodels: 0.14.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_missing.html",
    "href": "chapters/linear_models/09_missing.html",
    "title": "63¬† Dati mancanti",
    "section": "",
    "text": "Introduzione\nNel campo della data science, la gestione dei dati mancanti rappresenta una sfida cruciale e una competenza fondamentale per gli analisti e i ricercatori. I dati mancanti non sono solo una comune occorrenza nei dataset reali, ma possono anche avere un impatto significativo sulla qualit√† delle analisi, sulle inferenze tratte e sulle decisioni basate su tali dati. L‚Äôimportanza di affrontare correttamente i dati mancanti risiede nella necessit√† di mantenere l‚Äôintegrit√† delle analisi statistiche e di evitare conclusioni errate o distorte. Una gestione appropriata dei dati mancanti permette di migliorare l‚Äôaccuratezza dei modelli predittivi, di aumentare la robustezza delle analisi e di garantire che le decisioni basate sui dati siano informate e affidabili. Pertanto, comprendere le cause dei dati mancanti, conoscere le diverse tipologie di assenza dei dati, come classificato nella tassonomia di Rubin, e applicare le tecniche di trattamento pi√π adeguate sono competenze essenziali nella data science per massimizzare il valore estratto dai dati disponibili.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_missing.html#la-tassonomia-di-rubin",
    "href": "chapters/linear_models/09_missing.html#la-tassonomia-di-rubin",
    "title": "63¬† Dati mancanti",
    "section": "63.1 La tassonomia di Rubin",
    "text": "63.1 La tassonomia di Rubin\nLa tassonomia dei dati mancanti di Rubin introduce una classificazione che aiuta a comprendere e gestire le situazioni in cui i dati non sono completamente disponibili. Questa classificazione √® particolarmente rilevante in ambiti come la statistica, la ricerca scientifica e l‚Äôanalisi dei dati, dove la presenza di dati mancanti pu√≤ influenzare significativamente i risultati degli studi. La tassonomia identifica tre categorie principali: Dati Mancanti Completamente a Caso (MCAR), Dati Mancanti a Caso (MAR) e Dati Mancanti Non a Caso (MNAR). Ognuna di queste categorie si basa su specifiche assunzioni relative alla probabilit√† condizionata che un dato sia mancante. Vediamo nel dettaglio:\n\nDati Mancanti Completamente a Caso (MCAR): Questa categoria rappresenta la situazione meno problematica tra le tre. L‚Äôassunzione MCAR suggerisce che la mancanza di dati avviene in modo completamente casuale, senza alcuna relazione sia con i dati osservati che con quelli non osservati. La mancanza √® attribuibile a circostanze casuali e non legate alle caratteristiche dei dati stessi. In pratica, questo significa che la probabilit√† che un dato sia mancante √® la stessa per tutte le osservazioni. Quando i dati sono MCAR, le tecniche di analisi possono procedere senza introdurre distorsioni significative nei risultati.\nDati Mancanti a Caso (MAR): In questa categoria, la probabilit√† che un dato sia mancante pu√≤ dipendere dai dati osservati, ma non da quelli non osservati. Questo tipo di mancanza viene considerato ‚Äúignorabile‚Äù perch√©, conoscendo i dati osservati, √® possibile procedere con l‚Äôanalisi senza compromettere l‚Äôaffidabilit√† delle inferenze, sebbene possa esserci una perdita di precisione. Questa situazione si verifica quando la ragione della mancanza di dati √® correlata a qualche caratteristica osservabile nel dataset, permettendo di gestire la mancanza attraverso l‚Äôanalisi dei dati disponibili.\nDati Mancanti Non a Caso (MNAR): Questa √® la situazione pi√π complessa e potenzialmente problematica. I dati sono considerati MNAR quando la probabilit√† che un dato sia mancante dipende dalle informazioni non osservate. Ci√≤ significa che la mancanza di dati √® correlata a valori che non sono noti o osservabili, rendendo pi√π difficile l‚Äôimputazione e l‚Äôanalisi. Le tecniche standard di gestione dei dati mancanti potrebbero introdurre distorsioni significative nei risultati a causa del rischio di confondimento. La gestione dei dati MNAR richiede metodi avanzati e cautela nell‚Äôinterpretazione dei risultati.\n\nLe assunzioni su cui si basa questa tassonomia sono fondamentali per scegliere il metodo di trattamento dei dati mancanti pi√π appropriato. Tuttavia, √® importante notare che queste assunzioni sono intrinsecamente non verificabili. L‚Äôanalisi e le conclusioni di uno studio dipenderanno dalla plausibilit√† di queste assunzioni nel contesto specifico in cui vengono applicate. La scelta di come trattare i dati mancanti dovrebbe quindi essere attentamente considerata e giustificata nel contesto della ricerca.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_missing.html#un-esempio-empirico",
    "href": "chapters/linear_models/09_missing.html#un-esempio-empirico",
    "title": "63¬† Dati mancanti",
    "section": "63.2 Un Esempio Empirico",
    "text": "63.2 Un Esempio Empirico\nL‚Äôanalisi e il trattamento dei dati mancanti rivestono un ruolo cruciale nell‚Äôinterpretazione dei risultati di uno studio. Esaminiamo i diversi scenari di dati mancanti che hai delineato, prendendo spunto dall‚Äôesempio metaforico del ‚Äúcane che mangia i compiti‚Äù, presentato nel tutorial di Dustin Stansbury.\n\n63.2.1 1. Perdita di Dati Casuale e Indipendente dalle Cause\n\nEsempio: Il fenomeno del ‚Äúcane che mangia i compiti‚Äù avviene in maniera casuale.\nConseguenze: In questa situazione, la perdita di dati √® classificata come ‚ÄúMissing Completely At Random‚Äù (MCAR), ovvero l‚Äôassenza di dati non √® in alcun modo correlata n√© alle variabili osservate n√© a quelle non osservate.\nGestione: √à possibile eliminare i casi con dati mancanti senza introdurre distorsioni, bench√© ci√≤ possa ridurre l‚Äôefficienza dello studio a causa della diminuzione della dimensione del campione.\n\n\n# Helper function to plot regression line\ndef plot_regression_line(x, y, color, label, **plot_kwargs):\n    valid_idx = ~np.isnan(y)\n    \n    X = np.vstack((np.ones_like(x[valid_idx]), x[valid_idx])).T\n    intercept, slope = np.linalg.lstsq(X, y[valid_idx], rcond=None)[0]\n    \n    xs = np.linspace(x.min(), x.max(), 10)\n    ys = xs * slope + intercept\n    plt.plot(xs, ys, color=color, label=label, **plot_kwargs)\n\n# Function to plot dog homework data\ndef plot_dog_homework(S, H, Hstar, title=None):\n    \n    # Plot S vs H\n    plt.scatter(S, H, color='k', alpha=1, label='total', s=10)\n    plot_regression_line(S, H, label='total trend', color='k', alpha=.5)\n    \n    # Plot S vs Hstar\n    plt.scatter(S, Hstar, color='C0', alpha=.8, label='incomplete')\n    plot_regression_line(S, Hstar, label='incomplete trend', color='C0', alpha=.5)\n    \n    # Set labels and title\n    plt.xlabel(\"S\")\n    plt.ylabel(\"H\")\n    if title is not None:\n        plt.title(title)\n    plt.legend()\n\n    plt.show()  # Display the plot\n\n\nnp.random.seed(123)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 50% of of homework _at random_\nD = stats.bernoulli(0.5).rvs(size=n_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Random missing data\\ncauses loss of precision; little/no bias\")\n\n\n\n\n\n\n\n\nIn scenari di dati mancanti completamente a caso, si verifica una perdita di precisione, ma, mediamente, l‚Äôanalisi non risulta distorta.\n\n\n63.2.2 2. Perdita di Dati Condizionata dalle Cause\n\nEsempio: Il cane mangia i compiti in base alle abitudini di studio dello studente, ad esempio se lo studente trascura di nutrire il cane dopo aver studiato intensamente.\nConseguenze: Questo caso √® definito come ‚ÄúMissing At Random‚Äù (MAR), in cui la probabilit√† di perdita di dati √® correlata a variabili osservabili.\nGestione: √à necessario adeguare l‚Äôanalisi in base alla causa per prevenire distorsioni. L‚Äôimpiego di modelli statistici che considerano le variabili legate alla mancanza di dati pu√≤ risultare efficace.\n\nIn una prima simulazione, il trattamento (competenza dello studente) e l‚Äôeffetto (qualit√† del compito) hanno una relazione lineare. Questo scenario √® molto raro.\n\nnp.random.seed(12)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between student ability and homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats based on the student's ability\np_dog_eats_homework = np.where(S &gt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on common cause\\nmay work for linear relationships (rare) \")\n\n\n\n\n\n\n\n\nQuando l‚Äôassociazione tra abilit√† degli studenti e punteggio dei compiti √® lineare, l‚Äôadattamento dal campione completo e da quello incompleto pu√≤ risultare simile, con una perdita di precisione solo agli estremi del campione.\nConsideriamo ora il caso in cui il trattamento (capacit√† dello studente) e l‚Äôeffetto (caratteristiche del compito) non sono associati linearmente. Questo scenario √® molto pi√π comune.\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Nonlinear association between student ability and homework score\nmu_score = 1 - np.exp(-0.7 * S)\nH = stats.norm.rvs(mu_score)\n\n# Dog eats all the homework of above-average students\np_dog_eats_homework = np.where(S &gt; 0, 1, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data based on common cause\\nvery bady for non-linear relationships (common)\")\n\n\n\n\n\n\n\n\nIn un tale scenario, l‚Äôadattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l‚Äôanalisi del campione incompleto produce un risultato distorto.\n\n\n63.2.3 3. Perdita di Dati Condizionata dal Risultato\n\nEsempio: Il cane mangia i compiti in base al punteggio ottenuto.\nConseguenze: Questo scenario √® classificato come ‚ÄúMissing Not At Random‚Äù (MNAR), in cui la perdita di dati √® direttamente correlata al risultato mancante, complicando significativamente la gestione.\nGestione: Spesso, affrontare questa situazione richiede di modellare il processo causale alla base della perdita di dati, utilizzando tecniche come l‚Äôanalisi di sopravvivenza o l‚Äôimpiego di dati censurati.\n\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between ability and score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 90% of homework that is below average\np_dog_eats_homework = np.where(H &lt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on outcome state\\nusually not benign\")\n\n\n\n\n\n\n\n\nl‚Äôadattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l‚Äôanalisi del campione incompleto produce un risultato distorto. La situazione √® simile a quella precedene in cui la relazione tra cause e risultati non era lineare.\nSenza conoscere la relazione causale tra il risultato e la perdita di dati, e le forme funzionali di come X √® associato con Y, √® difficile tenere conto di questo scenario.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_missing.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/linear_models/09_missing.html#commenti-e-considerazioni-conclusive",
    "title": "63¬† Dati mancanti",
    "section": "63.3 Commenti e considerazioni conclusive",
    "text": "63.3 Commenti e considerazioni conclusive\nIn conclusione, la strategia di gestione dei dati mancanti varia a seconda della loro relazione con le variabili nel modello causale. Comprendere la natura della perdita di dati √® vitale per scegliere l‚Äôapproccio analitico corretto e per interpretare con precisione i risultati dello studio. Solo nel caso di dati mancanti completamente a caso, l‚Äôanalisi che ignora la mancanza di dati produce risultati affidabili.",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_missing.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_missing.html#informazioni-sullambiente-di-sviluppo",
    "title": "63¬† Dati mancanti",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib : 3.8.4\npandas     : 2.2.2\nstatsmodels: 0.14.2\narviz      : 0.18.0\nnumpy      : 1.26.4\nseaborn    : 0.13.2\nxarray     : 2024.5.0\nscipy      : 1.13.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli lineari",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_glm.html",
    "href": "chapters/glm/introduction_glm.html",
    "title": "64¬† Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo i modelli statistici che vanno oltre la regressione lineare, ossia quelli che fanno ipotesi distributive non gaussiane per la componente stocastica del modello, considerano una relazione non lineare tra il valore atteso della variabile di risposta e i predittori, e indeboliscono l‚Äôassunzione di indipendenza tra le osservazioni.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html",
    "href": "chapters/glm/01_robust_regr.html",
    "title": "65¬† Regressione robusta",
    "section": "",
    "text": "Introduzione\nNell‚Äôambito della psicologia, la gestione efficace dei dati anomali √® cruciale per garantire l‚Äôintegrit√† e l‚Äôaffidabilit√† delle inferenze statistiche. La regressione robusta bayesiana rappresenta un approccio metodologico avanzato, specificamente progettato per affrontare le sfide poste da distribuzioni dei dati caratterizzate da deviazioni significative dalla norma, comuni nei dataset psicologici. Questo capitolo si dedica all‚Äôesplorazione dettagliata della regressione robusta bayesiana, con un focus particolare sull‚Äôimpiego della distribuzione Student-t come modello di errore per accrescere la tolleranza ai dati anomali e sul Pareto Smoothed Importance Sampling (PSIS) per individuare la presenza di dati anomali.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "href": "chapters/glm/01_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "title": "65¬† Regressione robusta",
    "section": "65.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati",
    "text": "65.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati\nLe osservazioni anomale, comunemente note come outlier, ovvero i valori che si situano ai margini della distribuzione complessiva dei dati, hanno un ruolo fondamentale nell‚Äôanalisi statistica. La loro presenza, infatti, pu√≤ seriamente compromettere l‚Äôintegrit√† e la validit√† predittiva di un modello statistico, evidenziando una potenziale inadeguatezza del modello stesso nel rappresentare con precisione l‚Äôeterogeneit√† intrinseca dei dati. Questi valori estremi sono indicativi di limitazioni nel modello, suggerendo che esso potrebbe non essere configurato correttamente o che possa non essere in grado di catturare tutte le dinamiche sottostanti i dati. Pertanto, l‚Äôidentificazione e l‚Äôanalisi approfondita degli outlier sono essenziali per garantire che le inferenze e le previsioni generate da un modello statistico siano robuste e affidabili.\nIgnorare o rimuovere gli outlier senza un‚Äôaccurata valutazione delle loro cause e caratteristiche pu√≤ portare a interpretazioni errate dei dati. Tale pratica pu√≤ essere paragonata a un tentativo di ‚Äúcorrezione‚Äù dei dati piuttosto che a un miglioramento del modello, nascondendo di fatto i veri problemi anzich√© risolverli. Di conseguenza, la sfida principale consiste nel comprendere l‚Äôimpatto degli outlier sul modello e nel trovare strategie per integrare queste informazioni anzich√© escluderle, considerandoli un elemento informativo cruciale nell‚Äôanalisi complessiva.\nPer affrontare gli outlier in modo efficace, √® essenziale adottare approcci statistici robusti. Questi possono includere la modifica della funzione di verosimiglianza per aumentare la tolleranza nei confronti di variazioni estreme dei dati, l‚Äôimpiego di distribuzioni a priori che ammettano esplicitamente la presenza di deviazioni significative, o l‚Äôutilizzo di metodi specifici per identificare e analizzare gli outlier.\nIn sintesi, gli outlier non dovrebbero essere visti come un problema da evitare, ma piuttosto come un‚Äôoccasione per affinare e perfezionare i modelli statistici. La rimozione degli outlier senza un‚Äôadeguata analisi pu√≤ condurre a conclusioni fuorvianti e a previsioni poco affidabili. Al contrario, un esame dettagliato e l‚Äôintegrazione consapevole degli outlier possono arricchire la nostra comprensione del fenomeno studiato, migliorando la precisione e l‚Äôaffidabilit√† delle previsioni del modello.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#mistura-di-gaussiane",
    "href": "chapters/glm/01_robust_regr.html#mistura-di-gaussiane",
    "title": "65¬† Regressione robusta",
    "section": "65.2 Mistura di Gaussiane",
    "text": "65.2 Mistura di Gaussiane\nNel presente capitolo, esploreremo una metodologia avanzata per mitigare l‚Äôeffetto degli outlier attraverso l‚Äôottimizzazione della funzione di verosimiglianza, incrementando cos√¨ la sua robustezza nei confronti di deviazioni estreme nei dati. Una tattica particolarmente efficace per raggiungere tale obiettivo implica l‚Äôutilizzo della distribuzione t di Student nella modellazione dei dati. In particolare, nel contesto dell‚Äôanalisi di regressione, √® stato evidenziato come gli outlier possano influenzare negativamente la retta di regressione, facendola deviare dalle zone di maggiore densit√† dei dati. Attraverso l‚Äôutilizzo della distribuzione t di Student, la quale presenta code pi√π pesanti rispetto alla distribuzione Gaussiana (Normale), √® possibile ridurre l‚Äôimpatto distorsivo degli outlier sulla retta di regressione. Questo rappresenta un esempio classico di regressione robusta.\nLa distribuzione t di Student pu√≤ essere compresa concettualmente come una composizione di diverse distribuzioni gaussiane, ognuna con la propria varianza specifica. Questa caratteristica conferisce alla distribuzione una maggiore flessibilit√† nel trattare dati con varianze estreme, rendendola particolarmente adatta per l‚Äôuso in modelli statistici che richiedono una notevole resistenza agli outlier. Utilizzare questa distribuzione facilita l‚Äôesecuzione di analisi pi√π robuste e la generazione di previsioni pi√π accurate, migliorando il livello di inferenza in situazioni dove sono presenti dati anomali.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-6, 6, 100)\n\n# Inizializzazione dell'array per i PDF (Probability Density Function)\npdfs = []\n\n# Numero di gaussiane\nn_gaussians = 20\n\n# Ciclo per tracciare ogni gaussiana\nfor variance in np.linspace(.5, 5, n_gaussians):\n    label = \"Individual\\nGaussians\" if variance == .5 else None\n    pdf = stats.norm(0, variance).pdf(xs)\n    pdfs.append(pdf)\n    plt.plot(xs, pdf, color='k', label=label, alpha=.25)  # Usa matplotlib.pyplot.plot\n\n# Calcolo della somma dei PDFs\nsum_of_pdfs = np.array(pdfs).sum(axis=0)\nsum_of_pdfs /= sum_of_pdfs.max()\nsum_of_pdfs *= (1 - n_gaussians / 100)\n\n# Tracciare la somma dei PDFs\nplt.plot(xs, sum_of_pdfs, label='Mixture of\\nGaussian')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa natura della distribuzione t di Student come mistura di Gaussiane porta con s√© importanti conseguenze analitiche.\nLa caratteristica di essere una somma di distribuzioni gaussiane con varianze eterogenee si riflette nella presenza di code pi√π pesanti rispetto a una distribuzione gaussiana singola. Ci√≤ significa che la distribuzione t √® in grado di gestire pi√π efficacemente osservazioni estreme, rendendola una scelta preferenziale per dati che si discostano dalla normalit√†, soprattutto in presenza di outlier.\nIn numerosi ambiti si osserva frequentemente la presenza di dati provenienti da popolazioni con caratteristiche eterogenee, talvolta non immediatamente identificabili. Questa diversit√† pu√≤ essere il risultato di una variet√† di meccanismi sottostanti con varianze distinte. Essendo composta da diverse gaussiane, la distribuzione t di Student incorpora implicitamente l‚Äôeterogeneit√† non osservabile nei dati, che pu√≤ derivare da diverse fonti con varianze distinte.\nUn‚Äôaltra caratteristica distintiva della distribuzione t di Student √® la sua ridotta sensibilit√† agli outlier rispetto alla distribuzione gaussiana. Grazie alle sue code pi√π pesanti, la distribuzione t attribuisce una maggiore probabilit√† alle osservazioni estreme, riducendo l‚Äôeffetto distorsivo degli outlier sull‚Äôanalisi statistica.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-4, 4, 100)\n\n# Configurazione delle dimensioni del grafico\nplt.subplots(figsize=(6, 3))\n\n# Tracciare la distribuzione normale (Gaussiana)\nplt.plot(xs, stats.norm.pdf(xs), label='Gaussian')\n\n# Tracciare la distribuzione Student-t\nplt.plot(xs, stats.t(2).pdf(xs), color='C2', label='Student-t')\n\nplt.legend()\nplt.show()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#un-esempio-concreto",
    "href": "chapters/glm/01_robust_regr.html#un-esempio-concreto",
    "title": "65¬† Regressione robusta",
    "section": "65.3 Un esempio concreto",
    "text": "65.3 Un esempio concreto\nPer illustrare la capacit√† della distribuzione t di Student di mitigare l‚Äôeffetto degli outlier nell‚Äôanalisi di regressione, in questo capitolo considereremo un set di dati simulati, cos√¨ come illustrato nel tutorial fornito sul sito di Bambi.\n\nsize = 100\ntrue_intercept = 1\ntrue_slope = 2\n\nx = np.linspace(0, 1, size)\n# y = a + b*x\ntrue_regression_line = true_intercept + true_slope * x\n# add noise\ny = true_regression_line + np.random.normal(scale=0.5, size=size)\n\n# Add outliers\nx_out = np.append(x, [0.01, 0.1, 0.15])\ny_out = np.append(y, [12, 11, 13])\n\ndata = pd.DataFrame({\n    \"x\": x_out,\n    \"y\": y_out\n})\n\nSi noti che sono stati introdotti 3 valori anomali nel dataset, nonostante il vero meccanismo generativo dei dati implichi che la pendenza della retta di regressione sia pari a 2.\n\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(111, xlabel=\"x\", ylabel=\"y\", title=\"Generated data and underlying model\")\nax.plot(x_out, y_out, \"x\", label=\"sampled data\")\nax.plot(x, true_regression_line, label=\"true regression line\", lw=2.0)\nplt.legend(loc=0);\n\n\n\n\n\n\n\n\nQueste anomalie possono essere soggette ad un‚Äôanalisi rigorosa mediante l‚Äôapplicazione di metodi statistici avanzati. Un approccio per valutare l‚Äôimpatto di tali outlier sull‚Äôanalisi √® l‚Äôutilizzo della statistica PSIS \\(k\\), una tecnica che permette di quantificare l‚Äôinfluenza delle osservazioni estreme su una distribuzione.\nImplementiamo un modello di regressione lineare per analizzare la relazione tra y (variabile dipendente) e x. In questa analisi iniziale, l‚Äôipotesi sottostante √® che gli errori (o residui), seguano una distribuzione normale (gaussiana).\n\ngauss_model = bmb.Model(\"y ~ x\", data, family=\"gaussian\")\n\n\ngauss_model.build()\ngauss_model.graph()\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati. Si noti che l‚Äôargomento idata_kwargs={\"log_likelihood\": True} passato alla funzione fit √® usato per specificare le opzioni per la creazione dell‚Äôoggetto InferenceData che sar√† restituito. In questo caso, stiamo indicando che vogliamo che il logaritmo della verosimiglianza sia incluso nell‚Äôoggetto InferenceData. Il logaritmo della verosimiglianza pu√≤ essere utilizzato per ulteriori analisi e diagnostica, come il calcolo del LOO (Leave-One-Out Cross-Validation).\n\ngauss_fitted = gauss_model.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\nEsaminiamo visivamente i risultati dell‚Äôanalisi.\n\nax = bmb.interpret.plot_predictions(gauss_model, gauss_fitted, [\"x\"])\nplt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\nplt.show()\n\nDefault computed for conditional variable: x\n\n\n\n\n\n\n\n\n\nIpotizzando una distribuzione normale degli errori, l‚Äôanalisi produce una stima fortemente distorta della pendenza della retta di regressione.\n\n_ = az.plot_trace(gauss_fitted)\n\n\n\n\n\n\n\n\n\naz.summary(gauss_fitted, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n2.20\n0.34\n1.55\n2.82\n0.01\n0.00\n4349.92\n2742.88\n1.0\n\n\nsigma\n1.85\n0.13\n1.61\n2.09\n0.00\n0.00\n3745.05\n3016.41\n1.0\n\n\nx\n0.21\n0.61\n-0.88\n1.37\n0.01\n0.01\n4300.46\n2852.23\n1.0\n\n\n\n\n\n\n\n\n\nposterior_predictive = gauss_model.predict(gauss_fitted, kind=\"pps\")\nax = az.plot_ppc(gauss_fitted, num_pp_samples=100)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nIn un secondo modello assumiamo che gli errori seguano una distribuzione t di Student.\n\nt_model = bmb.Model(\"y ~ x\", data, family=\"t\")\n\n\nt_model.build()\nt_model.graph()\n\n\n\n\n\n\n\n\n\nt_fitted = t_model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\n\nax = bmb.interpret.plot_predictions(t_model, t_fitted, [\"x\"])\n_ = plt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\n\nDefault computed for conditional variable: x\n\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, la presenza degli outlier non ha distorto in alcun modo la stima della pendenza della retta di regressione. Nella regressione lineare gaussiana classica, i valori anomali hanno l‚Äôeffetto di ‚Äúspingere‚Äù la distribuzione a posteriori di \\(\\beta\\) verso lo zero. Invece, il modello student-t √® pi√π robusto e meno influenzato dai valori anomali.\n\naz.summary(t_fitted, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.19\n0.11\n0.99\n1.40\n0.00\n0.00\n3551.59\n2916.33\n1.0\n\n\nnu\n2.14\n0.46\n1.35\n3.03\n0.01\n0.01\n3267.18\n3114.44\n1.0\n\n\nsigma\n0.41\n0.05\n0.32\n0.50\n0.00\n0.00\n3212.53\n3022.28\n1.0\n\n\nx\n1.58\n0.18\n1.23\n1.92\n0.00\n0.00\n3818.50\n2914.77\n1.0\n\n\n\n\n\n\n\n\n\nposterior_predictive = t_model.predict(t_fitted, kind=\"pps\")\nax = az.plot_ppc(t_fitted, num_pp_samples=100)\nplt.xlim(-2, 5)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nNella figura successiva, esaminiamo la stima a posteriori della pendenza della retta di regressione per entrambi i modelli.\n\naz.plot_dist(t_fitted.posterior[\"x\"], color=\"C1\", label=\"Student-t Model\")\naz.plot_dist(gauss_fitted.posterior[\"x\"], label=\"Gaussian Model\");\n\n\n\n\n\n\n\n\nSi noti che, in presenza di outlier, l‚Äôimpiego della distribuzione t di Student ha portato a un adattamento del modello pi√π accurato, come evidenziato dai valori diagnostici Pareto \\(k\\).\n\naz.loo(gauss_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -218.24    29.86\np_loo       15.13        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100   97.1%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         1    1.0%\n   (1, Inf)   (very bad)    2    1.9%\n\n\n\naz.loo(t_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -112.62    16.34\np_loo        5.44        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      103  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#waic-e-psis",
    "href": "chapters/glm/01_robust_regr.html#waic-e-psis",
    "title": "65¬† Regressione robusta",
    "section": "65.4 WAIC e PSIS",
    "text": "65.4 WAIC e PSIS\nNella sezione seguente, approfondiremo il legame tra i valori diagnostici di Pareto \\(k\\) e il Watanabe-Akaike Information Criterion (WAIC), una metrica essenziale per valutare la qualit√† di un modello statistico. A differenza del pi√π tradizionale criterio di informazione di Akaike (AIC), impiegato nei contesti frequentisti, il WAIC estende il concetto di valutazione della qualit√† di un modello incorporando sia la sua capacit√† di adattamento ai dati sia la sua complessit√† intrinseca. Lo scopo √® prevenire l‚Äôeccesso di adattamento (overfitting), dove il modello √® troppo specifico ai dati di addestramento, e l‚Äôinsufficiente adattamento (underfitting), dove il modello √® troppo semplice per catturare la struttura sottostante dei dati. In termini pi√π accessibili, il WAIC stima l‚Äôefficacia con cui un modello pu√≤ prevedere dati non ancora osservati, basandosi sulla log-verosimiglianza dei dati e correggendo per la dimensione effettiva del modello. Un valore WAIC inferiore segnala una maggiore capacit√† previsionale del modello.\nPer calcolare il WAIC, si fa spesso ricorso all‚Äôimportance sampling, una tecnica per approssimare propriet√† di una distribuzione di probabilit√† campionando da una distribuzione alternativa. Il PSIS (Pareto Smoothed Importance Sampling), che migliora questo metodo, e i valori diagnostici di Pareto \\(k\\) giocano un ruolo cruciale nell‚Äôevaluazione della qualit√† dell‚Äôapproximation impiegata per il calcolo del WAIC. Il valore di Pareto \\(k\\) funge da termometro dell‚Äôefficacia dell‚Äôimportance sampling per un determinato modello e insieme di dati. Valori elevati di Pareto \\(k\\) (solitamente oltre 0.7) segnalano potenziali inaffidabilit√† nell‚Äôapprossimazione, il che pu√≤ tradursi in stime del WAIC distorte. Questo fenomeno suggerisce che il modello potrebbe non essere adeguatamente equipaggiato per prevedere specifiche osservazioni nei dati, spesso a causa della presenza di dati anomali o di una scarsa adattabilit√† del modello.\nStabilire un collegamento tra WAIC e i valori di Pareto \\(k\\) √® fondamentale, poich√© offre una panoramica pi√π dettagliata e affidabile della performance di un modello. Se da un lato il WAIC valuta l‚Äôadattabilit√† generale del modello ai dati e la sua gestione della complessit√†, dall‚Äôaltro, il valore di Pareto \\(k\\) fornisce insight preziosi sull‚Äôaffidabilit√† dell‚Äôapprossimazione usata per il suo calcolo. Insieme, queste metriche consentono una valutazione pi√π completa della qualit√† di un modello.\nQuando il calcolo del WAIC viene eseguito in modo puntiforme (pointwise=True), significa che la valutazione √® condotta separatamente per ciascuna osservazione all‚Äôinterno del dataset. Questa modalit√† di calcolo permette di identificare come ogni dato contribuisca al valore globale del WAIC, facilitando l‚Äôindividuazione di potenziali dati anomali o punti critici per il modello, diversamente da un calcolo aggregato che fornirebbe un unico valore di WAIC per tutto il modello. Questa analisi dettagliata √® particolarmente utile per affinare la comprensione della performance modello e per guidare eventuali miglioramenti.\n\ndef plot_loocv(inference, title=None, outliers_idx=[], divorce=None):\n    plt.subplots(figsize=(6, 3))\n    pareto_k = az.loo(inference, pointwise=True).pareto_k\n    waic = -az.waic(inference, pointwise=True).waic_i\n\n    plt.scatter(pareto_k, waic, color='C0', label=None)\n\n    # Assicurati che outliers_idx e divorce siano definiti\n    for oi in outliers_idx:\n        if divorce is not None and oi in divorce.index:\n            plt.annotate(divorce.loc[oi, \"Location\"], (pareto_k[oi] + .01, waic[oi]), fontsize=14)\n\n    plt.xlabel(\"PSIS Pareto K\")\n    plt.ylabel(\"WAIC\")\n    plt.title(title)\n    plt.show()\n\nCreiamo un grafico che mostra i valori di WAIC in funzione dei valori Pareto \\(k\\). Con questa rappresentazione possiamo esaminare come ogni osservazione influisca sulla performance del modello e sulla sua affidabilit√†. Se un punto ha un alto valore di Pareto \\(k\\) e un elevato impatto negativo sul WAIC (indicato da un alto valore negativo di WAIC), potrebbe essere un candidato per un‚Äôulteriore revisione o esclusione dal modello.\n\nplot_loocv(gauss_fitted, title=\"Gaussian Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\n\nplot_loocv(t_fitted, title=\"Student Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\n√à evidente che, per i dati in esame, quando si utilizza un modello di regressione lineare che assume una distribuzione degli errori t di Student, sia il WAIC che i valori diagnostici Pareto \\(k\\) risultano essere inferiori. Questa riduzione indica una maggiore efficienza del modello nella previsione dei dati.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#confronto-tra-modelli",
    "href": "chapters/glm/01_robust_regr.html#confronto-tra-modelli",
    "title": "65¬† Regressione robusta",
    "section": "65.5 Confronto tra Modelli",
    "text": "65.5 Confronto tra Modelli\nEseguiamo ora un‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) per confrontare i due modelli statistici, il modello gaussiano e il modello basato sulla distribuzione t di Student. L‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) √® una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacit√† previsionale. Questo metodo √® particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento.\nL‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) √® una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacit√† previsionale. Questo metodo √® particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento. Ecco una spiegazione dettagliata del processo e di come viene applicato per confrontare un modello gaussiano con un modello basato sulla distribuzione t di Student.\nNello specifico, la validazione incrociata LOO √® un caso particolare di validazione incrociata k-fold, dove \\(k\\) √® uguale al numero di osservazioni nel dataset. In pratica, questo significa che per un dataset di \\(n\\) osservazioni, il modello viene addestrato \\(n\\) volte, ogni volta usando \\(n-1\\) osservazioni come dati di addestramento e la singola osservazione restante come dato di test. Questo processo viene ripetuto per ogni osservazione nel dataset, permettendo cos√¨ di valutare la performance del modello su ogni punto dati una volta.\nUtilizzando az.compare, √® possibile confrontare i due modelli sulla base della loro performance previsionale, quantificata attraverso metriche specifiche derivate dalla validazione incrociata LOO. Queste metriche aiutano a determinare quale modello ha una migliore capacit√† di generalizzazione, prendendo in considerazione sia la qualit√† dell‚Äôadattamento ai dati che la complessit√† del modello.\n\ndf_comp_loo = az.compare({\"Gaussian Model\": gauss_fitted, \"Student t Model\": t_fitted})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nStudent t Model\n0\n-112.621991\n5.443246\n0.000000\n1.0\n16.341621\n0.00000\nFalse\nlog\n\n\nGaussian Model\n1\n-218.239844\n15.126661\n105.617853\n0.0\n29.860645\n16.48181\nTrue\nlog\n\n\n\n\n\n\n\n\n\naz.plot_compare(df_comp_loo, insample_dev=False);\n\n\n\n\n\n\n\n\nCome abbiamo visto in precedenza, la ELPD (Expected Log Predictive Density) √® una misura della performance predittiva di un modello statistico. Rappresenta il logaritmo della densit√† predittiva media attesa, calcolata attraverso la validazione incrociata LOO. Un valore pi√π alto di ELPD indica una migliore capacit√† del modello di adattarsi ai dati e di fare previsioni accurate su nuovi dati non visti.\n\nrank: Posizione del modello basata sull‚Äôelpd_loo.\nelpd_loo: Stima dell‚ÄôExpected Log Pointwise Predictive Density per LOO-CV. Valori pi√π alti indicano migliori capacit√† predittive.\np_loo: Stima della complessit√† effettiva del modello, che riflette il numero di parametri ‚Äúeffettivi‚Äù.\nelpd_diff: Differenza di elpd_loo tra il modello corrente e il miglior modello. Per il miglior modello, questo valore √® 0.\nweight: Peso basato sull‚Äôelpd_loo, indicando l‚Äôimportanza relativa del modello nel contesto di un ensemble di modelli.\nse (Standard Error): Errore standard dell‚Äôelpd_loo.\ndse (Differenza di Standard Error): Errore standard della differenza di elpd_loo tra due modelli.\nwarning: Se vero, indica potenziali problemi con la stima elpd_loo per il modello.\nscale: La scala utilizzata per misurare l‚Äôelpd_loo; in questo caso, ‚Äúlog‚Äù.\n\nIl modello Student t ha un elpd_loo di -102.284333, il che lo rende il modello con le migliori capacit√† predittive tra i due, poich√© ha il valore elpd_loo pi√π alto (meno negativo). Questo modello ha anche un p_loo di 5.894299, indicando una complessit√† inferiore rispetto al Gaussian Model. Non ci sono avvertimenti, il che suggerisce che la stima elpd_loo √® considerata affidabile. Ha ricevuto un peso di 1.000000, indicando che √® il modello preferito per le previsioni.\nIl modello gaussiano mostra un elpd_loo di -219.324176 con una differenza di elpd_loo (elpd_diff) di 117.039843 rispetto al miglior modello. Questo indica che ha prestazioni significativamente peggiori in termini di adattamento predittivo rispetto allo Student t Model. Il suo p_loo pi√π alto di 15.391340 riflette una maggiore complessit√† del modello, che non sembra tradursi in migliori capacit√† predittive in questo contesto. Il modello presenta anche un avvertimento, il che potrebbe indicare problemi con la stima LOO, suggerendo cautela nell‚Äôinterpretazione dei suoi risultati.\nBasandosi sull‚Äôoutput fornito, il modello Student t √® considerato il modello migliore tra i due per questi dati, dato il suo elpd_loo pi√π alto (meno negativo), la minore complessit√† (p_loo inferiore), e l‚Äôassenza di avvertimenti. Il Gaussian Model, nonostante una maggiore complessit√†, mostra prestazioni inferiori e problemi potenziali (come indicato dall‚Äôavvertimento), rendendolo meno preferibile per la predizione su questo set di dati.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/glm/01_robust_regr.html#commenti-e-considerazioni-conclusive",
    "title": "65¬† Regressione robusta",
    "section": "65.6 Commenti e considerazioni conclusive",
    "text": "65.6 Commenti e considerazioni conclusive\nNella pratica statistica, si incontrano spesso situazioni in cui l‚Äôeterogeneit√† non osservata - variazioni o differenze tra osservazioni in un insieme di dati che non sono spiegabili attraverso le variabili misurabili nel contesto dello studio - svolge un ruolo significativo. Questa eterogeneit√† si manifesta quando le differenze osservate tra i dati non possono essere attribuite completamente alle variabili note e misurabili. Al contrario, esistono fattori ignoti o non misurati che influenzano le osservazioni, che possono essere intrinseci alle unit√† di osservazione o dipendere da condizioni ambientali o contestuali non contemplate durante la progettazione dello studio o la raccolta dei dati.\nPer modellare questa eterogeneit√†, spesso si utilizzano miscele di distribuzioni gaussiane o Student-t. La scelta della distribuzione Student-t in particolare implica un modello che √® meno sensibile agli effetti dei valori estremi, o ‚Äúoutliers‚Äù, grazie alle sue code pi√π pesanti. Tuttavia, una sfida nella modellazione statistica risiede nel corretto posizionamento dei parametri dei gradi di libert√† della distribuzione Student-t, specialmente perch√© gli outliers sono eventi rari e quindi difficili da stimare accuratamente.\nIn assenza di una teoria solida per guidare la scelta del modello statistico, la regressione robusta, basata su una distribuzione Student-t, emerge come una strategia prudente. Questo approccio si contrappone alla metodologia gaussiana standard, che pu√≤ risultare inadeguata nel gestire gli effetti dei valori estremi e dell‚Äôeterogeneit√† non osservata.\n√à fondamentale, inoltre, valutare accuratamente la bont√† di adattamento del modello ai dati. Strumenti come il Pareto Smoothed Importance Sampling (PSIS) e i valori diagnostici Pareto $ k $ si rivelano preziosi in questo contesto. Il PSIS utilizza la stima di $ k $ per perfezionare l‚Äôadattamento del modello, mentre i valori di $ k $ funzionano come indicatori diagnostici per valutare la qualit√† dell‚Äôimportance sampling e l‚Äôadeguatezza del modello stesso. Questi metodi aiutano a sviluppare modelli pi√π robusti e precisi, specialmente quando si trattano dati complessi con caratteristiche quali outliers e eterogeneit√† non osservata.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/01_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "65¬† Regressione robusta",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\npandas    : 2.2.2\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\nbambi     : 0.14.0\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html",
    "href": "chapters/glm/02_stan_binomial_regr.html",
    "title": "66¬† Regressione binomiale con Stan",
    "section": "",
    "text": "Introduzione\nIl presente capitolo approfondisce il concetto di regressione binomiale, una metodologia analitica specifica utilizzata per esaminare le variabili dipendenti che rappresentano le proporzioni di successi derivanti da un numero \\(n\\) di tentativi. A differenza della regressione logistica, dove la variabile dipendente segue una distribuzione di Bernoulli con esiti binari, la regressione binomiale si concentra sulle variabili dipendenti che esprimono proporzioni. Questo rende il modello binomiale la scelta pi√π appropriata per analizzare dati di questo tipo. Sia nella regressione logistica che in quella binomiale, √® cruciale rispettare il principio di indipendenza delle osservazioni. Questo requisito √® essenziale per garantire la validit√† e l‚Äôaffidabilit√† delle analisi condotte.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#regressione-binomiale",
    "href": "chapters/glm/02_stan_binomial_regr.html#regressione-binomiale",
    "title": "66¬† Regressione binomiale con Stan",
    "section": "66.1 Regressione Binomiale",
    "text": "66.1 Regressione Binomiale\nNella regressione binomiale, l‚Äôattenzione √® focalizzata sui dati che si esprimono attraverso eventi dicotomici, ossia successi o insuccessi, in un determinato numero di prove. Un esempio classico √® il conteggio dei successi in una serie di tentativi, come ‚Äú3 successi su 7 tentativi‚Äù. Il modello matematico che descrive questo tipo di dati √®:\n\\[\ny_i \\sim \\text{Binomiale}(n_i, p_i)\n\\]\ndove: - \\(y_i\\) rappresenta il numero di successi osservati; - \\(n_i\\) √® il numero totale di tentativi per l‚Äôi-esima osservazione; - \\(p_i\\) indica la probabilit√† di successo in ogni tentativo per l‚Äôi-esima osservazione.\nNel contesto della regressione binomiale, l‚Äôobiettivo principale √® modellare e stimare la probabilit√† di successo \\(p_i\\) in funzione di una o pi√π variabili indipendenti (i predittori). Questo si realizza attraverso l‚Äôutilizzo di una funzione di collegamento che trasforma una combinazione lineare dei predittori in un valore che risiede nello spazio di probabilit√† \\([0,1]\\), rendendolo interpretabile come probabilit√† di successo.\nLa funzione logistica inversa, o logit inverso, √® la funzione di collegamento pi√π comunemente usata nella regressione binomiale. Questa trasforma la somma lineare dei predittori in una probabilit√†, usando la formula:\n\\[\np_i = \\text{InverseLogit}(\\beta_0 + \\beta_1 \\cdot x_{i1} + \\dots + \\beta_k \\cdot x_{ik})\n\\]\ndove: - \\(p_i\\) √® la probabilit√† stimata di successo per l‚Äôi-esima osservazione; - \\(x_{i1}, \\dots, x_{ik}\\) sono le variabili indipendenti; - \\(\\beta_0, \\beta_1, \\dots, \\beta_k\\) sono i parametri del modello da stimare, inclusa l‚Äôintercetta (\\(\\beta_0\\)) e i coefficienti per ciascun predittore (\\(\\beta_1, \\dots, \\beta_k\\)).\nLa funzione \\(\\text{InverseLogit}(\\eta) = \\frac{1}{1 + e^{-\\eta}}\\) assicura che il risultato sia sempre tra 0 e 1, permettendo di interpretarlo come probabilit√†. Questo √® cruciale perch√© ci consente di mantenere la coerenza interpretativa dei risultati nel contesto della probabilit√† di eventi dicotomici.\nIn conclusione, la regressione binomiale offre un framework robusto per analizzare e interpretare le relazioni tra variabili indipendenti e la probabilit√† di eventi binari, sfruttando la distribuzione binomiale e trasformazioni logistiche per collegare predittori lineari a probabilit√† comprese tra 0 e 1.\nAdottando un approccio bayesiano alla regressione binomiale, √® possibile incorporare le informazioni precedenti o le conoscenze priori sui parametri \\(\\beta\\), attraverso l‚Äôuso di distribuzioni a priori. Questo approccio permette di aggiornare le nostre credenze sui parametri del modello alla luce dei dati osservati, producendo una distribuzione a posteriori che riflette sia le informazioni apportate dai dati che le conoscenze pregresse.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#un-esempio-concreto",
    "href": "chapters/glm/02_stan_binomial_regr.html#un-esempio-concreto",
    "title": "66¬† Regressione binomiale con Stan",
    "section": "66.2 Un esempio concreto",
    "text": "66.2 Un esempio concreto\nSeguiamo il tutorial fornito sul sito ufficiale di PyMC e generiamo dei dati sintetici dove \\(y\\) indica il numero di successi in \\(n = 20\\) prove e \\(x\\) √® un predittore.\n\n# true params\nbeta0_true = 0.7\nbeta1_true = 0.4\n# number of yes/no questions\nn = 20\n\nsample_size = 30\nx = np.linspace(-10, 20, sample_size)\n# Linear model\nmu_true = beta0_true + beta1_true * x\n# transformation (inverse logit function = expit)\np_true = expit(mu_true)\n# Generate data\ny = rng.binomial(n, p_true)\n# bundle data into dataframe\ndata = pd.DataFrame({\"x\": x, \"y\": y})\ndisplay(data)\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-10.000000\n1\n\n\n1\n-8.965517\n0\n\n\n2\n-7.931034\n1\n\n\n3\n-6.896552\n2\n\n\n4\n-5.862069\n6\n\n\n5\n-4.827586\n7\n\n\n6\n-3.793103\n4\n\n\n7\n-2.758621\n14\n\n\n8\n-1.724138\n14\n\n\n9\n-0.689655\n9\n\n\n10\n0.344828\n12\n\n\n11\n1.379310\n11\n\n\n12\n2.413793\n17\n\n\n13\n3.448276\n19\n\n\n14\n4.482759\n20\n\n\n15\n5.517241\n20\n\n\n16\n6.551724\n18\n\n\n17\n7.586207\n20\n\n\n18\n8.620690\n20\n\n\n19\n9.655172\n20\n\n\n20\n10.689655\n20\n\n\n21\n11.724138\n19\n\n\n22\n12.758621\n20\n\n\n23\n13.793103\n20\n\n\n24\n14.827586\n20\n\n\n25\n15.862069\n20\n\n\n26\n16.896552\n20\n\n\n27\n17.931034\n20\n\n\n28\n18.965517\n20\n\n\n29\n20.000000\n20\n\n\n\n\n\n\n\n\nPer questi dati, il modello di regressione binomiale pu√≤ essere descritto come segue:\n\nModello lineare: \\[\n\\eta_i = \\beta_0 + \\beta_1 x_i\n\\]\nProbabilit√† di successo: \\[\np_i = \\text{logit}^{-1}(\\eta_i) = \\frac{1}{1 + \\exp(-\\eta_i)}\n\\]\nLikelihood: \\[\ny_i \\mid p_i \\sim \\text{Binomiale}(n, p_i)\n\\]\nPriori: \\[\n\\beta_0 \\sim \\mathcal{N}(0, 1)\n\\] \\[\n\\beta_1 \\sim \\mathcal{N}(0, 1)\n\\]\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"binomial_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; sample_size;  // Numero totale di osservazioni\n  vector[sample_size] x;     // Variabile indipendente\n  array[sample_size] int&lt;lower=0&gt; y;  // Successi per ogni tentativo\n  int&lt;lower=0&gt; n;           // Numero di tentativi per osservazione\n}\nparameters {\n  real beta0;  // Intercetta\n  real beta1;  // Pendenza\n}\ntransformed parameters {\n  vector[sample_size] eta = beta0 + beta1 * x;  // Modello lineare\n  vector[sample_size] p = inv_logit(eta);       // Probabilit√† di successo\n}\nmodel {\n  // Priori\n  beta0 ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n\n  // Likelihood\n  y ~ binomial(n, p);\n}\n\n\n\nCreiamo un dizionario nel formato richiesto per l‚Äôinput a CmdStan:\n\nstan_data = {\n    \"sample_size\": data.shape[0],\n    \"x\": data[\"x\"],\n    \"y\": data[\"y\"],\n    \"n\": 20\n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nPer visualizzare e descrivere la distribuzione a posteriori dei parametri √® possibile utilizzare ArviZ dopo aver fittato il modello con cmdstanpy. ArviZ utilizza un formato di dati chiamato InferenceData, che √® un formato ad alto livello per la memorizzazione di risultati statistici. cmdstanpy restituisce un oggetto CmdStanMCMC, che pu√≤ essere convertito in InferenceData utilizzando la funzione az.from_cmdstanpy.\n\nidata = az.from_cmdstanpy(fit)\n\nOtteniamo un riassunto delle statistiche posteriori:\n\nsummary = az.summary(fit, var_names=([\"beta0\", \"beta1\"]), hdi_prob=0.94)\nprint(summary)\n\n        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nbeta0  0.934  0.174   0.603    1.257      0.003    0.002    4147.0    4717.0   \nbeta1  0.462  0.043   0.381    0.543      0.001    0.000    4247.0    4317.0   \n\n       r_hat  \nbeta0    1.0  \nbeta1    1.0  \n\n\nMostriamo le distribuzioni a posteriori e le tracce di campionamento per i parametri:\n\n_ = az.plot_trace(fit, var_names=([\"beta0\", \"beta1\"]))\n\n\n\n\n\n\n\n\nNel pannello superiore della figura seguente vediamo il modello lineare nella sua forma non trasformata. Come si pu√≤ osservare, questo modello lineare genera valori che escono dall‚Äôintervallo [0, 1], sottolineando quindi la necessit√† di una funzione di collegamento inversa. Questa funzione ha il compito di mappare i valori dal dominio dei numeri reali all‚Äôintervallo [0, 1]. Come abbiamo visto, questa trasformazione √® realizzata mediante la funzione logistica inversa.\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={\"width_ratios\": [2, 1]})\n\n# Data space plot ========================================================\naz.plot_hdi(\n    data[\"x\"],\n    idata.posterior.p,\n    hdi_prob=0.95,\n    fill_kwargs={\"alpha\": 0.25, \"linewidth\": 0},\n    ax=ax[0],\n    color=\"C1\",\n)\n# posterior mean\npost_mean = idata.posterior.p.mean((\"chain\", \"draw\"))\nax[0].plot(data[\"x\"], post_mean, label=\"posterior mean\", color=\"C1\")\n# plot truth\nax[0].plot(data[\"x\"], p_true, \"--\", label=\"true\", color=\"C2\")\n# formatting\nax[0].set(xlabel=\"x\", title=\"Data space\")\nax[0].set_ylabel(\"proportion successes\", color=\"C1\")\nax[0].tick_params(axis=\"y\", labelcolor=\"C1\")\nax[0].legend()\n# instantiate a second axes that shares the same x-axis\nfreq = ax[0].twinx()\nfreq.set_ylabel(\"number of successes\")\nfreq.scatter(data[\"x\"], data[\"y\"], color=\"k\", label=\"data\")\n# get y-axes to line up\ny_buffer = 1\nfreq.set(ylim=[-y_buffer, n + y_buffer])\nax[0].set(ylim=[-(y_buffer / n), 1 + (y_buffer / n)])\nfreq.grid(None)\n# set both y-axis to have 5 ticks\nax[0].set(yticks=np.linspace(0, 20, 5) / n)\nfreq.set(yticks=np.linspace(0, 20, 5))\n\n# Parameter space plot ===================================================\naz.plot_kde(\n    az.extract(idata, var_names=\"beta0\"),\n    az.extract(idata, var_names=\"beta1\"),\n    ax=ax[1],\n)\nax[1].plot(beta0_true, beta1_true, \"C2o\", label=\"true\")\nax[1].set(xlabel=r\"$\\beta_0$\", ylabel=r\"$\\beta_1$\", title=\"Parameter space\")\nax[1].legend(facecolor=\"white\", frameon=True)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61676/1160461270.py:44: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/02_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "66¬† Regressione binomiale con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Regressione binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html",
    "href": "chapters/glm/03_stan_logistic_regr.html",
    "title": "67¬† Regressione logistica con Stan",
    "section": "",
    "text": "Introduzione\nLa regressione logistica √® un modello additivo utilizzato per dati binari, ossia dati \\(y\\) che assumono valori 0 o 1. Per modellare i dati binari, dobbiamo aggiungere due caratteristiche al modello base \\(y = a + bx\\): una trasformazione non lineare che vincola l‚Äôoutput tra 0 e 1 (a differenza di \\(a + bx\\), che √® illimitato), e un metodo per interpretare i numeri risultanti come probabilit√† che un evento si verifichi.\nIn questo capitolo, approfondiremo la regressione logistica bivariata, un modello statistico che ci consente di analizzare le relazioni tra una variabile di esito binaria e una singola variabile indipendente. Esploreremo il processo di stima dei coefficienti del modello attraverso un approccio bayesiano e forniremo un‚Äôinterpretazione dei risultati ottenuti. Mostreremo come i coefficienti influenzano la probabilit√† di successo della variabile binaria di esito, nonch√© come interpretare il loro segno e ampiezza.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.1 Modello di Regressione Logistica per Variabili Binarie",
    "text": "67.1 Modello di Regressione Logistica per Variabili Binarie\nIl modello di regressione logistica √® utilizzato per analizzare la relazione tra una variabile dipendente dicotomica, che assume i valori di ‚Äúsuccesso‚Äù e ‚Äúfallimento‚Äù, e una o pi√π variabili indipendenti, che possono essere sia quantitative che qualitative. Qui ci concentreremo sul caso di una sola variabile indipendente.\nConsideriamo \\(n\\) osservazioni i.i.d., dove \\(Y_i\\) indica l‚Äôosservazione \\(i\\)-esima della variabile risposta, per \\(i=1, \\dots, n\\). Ogni osservazione √® associata a un vettore di variabili esplicative \\((x_1, \\dots, x_p)\\). La relazione che vogliamo esaminare √® tra la probabilit√† di successo \\(\\pi_i\\) e la variabile esplicativa, espressa dalla formula:\n\\[\nP(Y=1 \\mid X=x_i) = \\pi_i.\n\\]\nIn questo contesto, la variabile dipendente \\(Y\\) segue una distribuzione di Bernoulli, con i seguenti possibili valori:\n\\[\ny_i =\n\\begin{cases}\n    1 & \\text{per un successo (per l'osservazione $i$-esima)},\\\\\n    0 & \\text{per un fallimento}.\n\\end{cases}\n\\]\nLe probabilit√† associate a questi valori sono rispettivamente \\(\\pi\\) per il successo e \\(1-\\pi\\) per il fallimento:\n\\[\n\\begin{aligned}\n    P(Y_i = 1) &= \\pi,\\\\\n    P(Y_i = 0) &= 1-\\pi.\n\\end{aligned}\n\\]\nQuesto modello permette di studiare come le variabili esplicative influenzino la probabilit√† di un evento binario, come il successo o il fallimento.\nLa media condizionata \\(\\mathbb{E}(Y \\mid X=x)\\) in una popolazione pu√≤ essere vista come la proporzione di valori 1 per un dato punteggio \\(x\\) sulla variabile esplicativa, ovvero la probabilit√† condizionata \\(\\pi_i\\) di osservare l‚Äôesito \\(Y = 1\\) in corrispondenza di un certo livello \\(X\\):\n\\[\n\\pi_i \\equiv P(Y = 1 \\mid X = x).\n\\]\nIl valore atteso diventa:\n\\[\n\\mathbb{E}(Y \\mid x) = \\pi_i.\n\\]\nSe \\(X\\) √® una variabile discreta, possiamo calcolare la proporzione di \\(Y=1\\) per ogni valore di \\(X=x\\) nel campione. Queste proporzioni rappresentano una stima non parametrica della funzione di regressione di \\(Y\\) su \\(X\\), e possono essere stimate tramite tecniche di smoothing.\nPer valori bassi della variabile \\(X\\), la proporzione condizionata di valori \\(Y=1\\) sar√† prossima allo 0. Per valori alti di \\(X\\), la proporzione di valori \\(Y=1\\) sar√† prossima a 1. A livelli intermedi di \\(X\\), la curva di regressione non parametrica gradualmente approssima i valori 0 e 1 seguendo un andamento sigmoidale.\nPer illustrare, generiamo dei dati simulati con una variabile dicotomica \\(Y\\) e una variabile discreta \\(X\\) nei quali la probabilit√† che \\(Y=1\\) aumenta con il valore di \\(X\\).\n\n# Simulate data\nnp.random.seed(42)  # For reproducibility\nn = 1000  # Number of samples\nX = np.random.randint(0, 10, size=n)  # Discrete independent variable with levels from 0 to 9\n\n# Define the logistic model\ndef logistic(x, beta0, beta1):\n    return expit(beta0 + beta1 * x)\n\nbeta0 = -2\nbeta1 = 1  # Increase the steepness of the curve\np = logistic(X, beta0, beta1)\n\n# Generate dichotomous outcome variable Y\nY = np.random.binomial(1, p, size=n)\n\n# Compute mean success rate and standard error for each level of X\ndf = pd.DataFrame({'X': X, 'Y': Y})\nmean_success_rate = df.groupby('X')['Y'].mean()\nstandard_error = df.groupby('X')['Y'].sem()\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit a non-parametric smoother (LOESS) and plot the curve\nlowess_smoothed = lowess(mean_success_rate.values, mean_success_rate.index, frac=0.3)\n\nplt.plot(lowess_smoothed[:, 0], lowess_smoothed[:, 1], color='red', label='Non-parametric Smoother')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.2 Modello Lineare nelle Probabilit√†",
    "text": "67.2 Modello Lineare nelle Probabilit√†\nPotremmo pensare di usare una funzione lineare per rappresentare la dipendenza di \\(Y\\) da \\(X\\). Introduciamo un modello lineare con le seguenti assunzioni standard:\n\\[\nY_i = \\alpha + \\beta X_i + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) segue una distribuzione normale con media 0 e varianza 1 (\\(\\varepsilon_i \\sim \\mathcal{N}(0, 1)\\)) e gli errori \\(\\varepsilon_i\\) e \\(\\varepsilon_j\\) sono indipendenti per ogni \\(i \\neq j\\). Il valore atteso di \\(Y_i\\) √® quindi \\(\\mathbb{E}(Y_i) = \\alpha + \\beta X_i\\), portando a:\n\\[\n\\pi_i = \\alpha + \\beta X_i.\n\\]\nQuesto √® noto come modello lineare nelle probabilit√† (linear probability model). Tuttavia, questo approccio presenta una limitazione significativa: non garantisce che i valori predetti di \\(\\pi_i\\) siano confinati nell‚Äôintervallo [0,1], come richiesto per le probabilit√†.\n\n67.2.1 Problemi di Normalit√†\nConsiderando che \\(Y_i\\) pu√≤ assumere solo i valori 0 o 1, i residui \\(\\varepsilon_i\\) risultano anch‚Äôessi dicotomici e quindi non possono seguire una distribuzione normale. Ad esempio, se \\(Y_i=1\\) con probabilit√† \\(\\pi_i\\), il residuo sar√†:\n\\[\n\\varepsilon_i = 1 - \\mathbb{E}(Y_i) = 1 - (\\alpha + \\beta X_i) = 1 - \\pi_i.\n\\]\nSe, invece, \\(Y_i=0\\) con probabilit√† \\(1-\\pi_i\\), il residuo sar√†:\n\\[\n\\varepsilon_i = 0 - \\mathbb{E}(Y_i) = 0 - (\\alpha + \\beta X_i) = - \\pi_i.\n\\]\nTuttavia, se la dimensione del campione √® grande, il teorema del limite centrale pu√≤ mitigare l‚Äôimportanza dell‚Äôassunzione di normalit√† per le stime dei minimi quadrati.\n\n\n67.2.2 Problematiche di Eteroschedasticit√†\nUtilizzare il metodo dei minimi quadrati pu√≤ essere inappropriato in questo contesto poich√© la varianza dei residui non √® costante ma dipende dalla media, e quindi dalla variabile \\(X\\). Assumendo che il modello sia lineare, abbiamo che \\(\\mathbb{E}(\\varepsilon_i)=0\\). Sfruttando le relazioni discusse in precedenza, la varianza dei residui si calcola come:\n\\[\n\\mathbb{V}(\\varepsilon_i) = (1-\\pi_i)\\pi_i.\n\\]\nConsideriamo che la varianza dei residui \\(\\varepsilon_i\\) pu√≤ essere espressa come:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2,\n\\]\ndove \\(\\mathbb{E}(\\varepsilon_i^2)\\) √® il valore atteso del quadrato dei residui e \\(\\mathbb{E}(\\varepsilon_i)^2\\) √® il quadrato del valore atteso dei residui.\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i^2) &= \\mathbb{E}[(Y_i - \\mathbb{E}(Y_i))^2] \\\\\n&= \\mathbb{E}[(Y_i - \\pi_i)^2] \\\\\n&= \\mathbb{E}[(Y_i^2 - 2Y_i\\pi_i + \\pi_i^2)] \\\\\n&= \\mathbb{E}(Y_i^2) - 2\\mathbb{E}(Y_i\\pi_i) + \\mathbb{E}(\\pi_i^2) \\\\\n&= \\mathbb{E}(Y_i) - 2\\mathbb{E}(Y_i\\pi_i) + \\pi_i^2 \\\\\n&= \\pi_i - 2\\pi_i^2 + \\pi_i^2 \\\\\n&= \\pi_i - \\pi_i^2 \\\\\n&= \\pi_i(1 - \\pi_i)\n\\end{align*}\n\\]\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i)^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i)^2 &= (\\mathbb{E}(Y_i - \\mathbb{E}(Y_i)))^2 \\\\\n&= (\\mathbb{E}(Y_i - \\pi_i))^2 \\\\\n&= (0)^2 \\\\\n&= 0\n\\end{align*}\n\\]\nQuindi, sostituendo questi risultati nella formula della varianza dei residui, otteniamo:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2 = \\pi_i(1 - \\pi_i)\n\\]\nQuindi, abbiamo dimostrato che la varianza dei residui nel modello lineare nelle probabilit√† pu√≤ essere espressa come \\((1-\\pi_i)\\pi_i\\).\nDato che \\(\\pi_i\\) dipende da \\(x\\), ci√≤ significa che la varianza non √® costante in funzione di \\(x\\). Questa eteroschedasticit√† dei residui rappresenta un problema per le stime dei minimi quadrati nel modello lineare, specialmente quando le probabilit√† \\(\\pi_i\\) sono vicine a 0 o 1.\n\n\n67.2.3 Linearit√†\nIl maggiore inconveniente connesso all‚Äôadozione del modello lineare nelle probabilit√† deriva dal fatto che la stima della probabilit√† di successo, \\(P(\\hat{Y}_i=1)=\\hat{\\pi}_i\\), non √® necessariamente compresa nell‚Äôintervallo \\((0,1)\\), ma pu√≤ essere sia negativa sia maggiore di 1. Nel caso dell‚Äôesempio in discussione, ci√≤ significa che la retta dei minimi quadrati produce valori attesi \\(\\hat{\\pi}\\) inferiori a 0 per bassi valori della variabile \\(X\\) e valori \\(\\hat{\\pi}\\) superiori a 1 per valori di \\(X\\) alti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†-vincolato",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†-vincolato",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.3 Modello Lineare nelle Probabilit√† Vincolato",
    "text": "67.3 Modello Lineare nelle Probabilit√† Vincolato\nUna soluzione per mantenere \\(\\pi\\) all‚Äôinterno dell‚Äôintervallo (0, 1) √® la seguente specificazione del modello:\n\\[\n\\pi=\n\\begin{cases}\n  0                           &\\text{se $\\alpha + \\beta X &lt; 0$},\\\\\n  \\alpha + \\beta X           &\\text{se $0 \\leq \\alpha + \\beta X \\leq 1$},\\\\\n  1 &\\text{se $\\alpha + \\beta X &gt; 1$}.\n\\end{cases}\n\\]\nQuesto modello lineare nelle probabilit√† vincolato mostra alcune instabilit√†, soprattutto a causa della sua dipendenza critica dai valori estremi di \\(\\pi\\), dove assume i valori 0 o 1. La linearit√† di \\(\\pi = \\alpha + \\beta X\\) si basa fortemente sui punti in cui si verificano questi estremi. In particolare, la stima di \\(\\pi = 0\\) pu√≤ essere influenzata dal valore minimo di \\(X\\) associato a \\(Y=1\\), mentre la stima di \\(\\pi = 1\\) pu√≤ dipendere dal valore massimo di \\(X\\) per cui \\(Y=0\\). Questi valori estremi tendono a variare significativamente tra diversi campioni e possono diventare pi√π estremi all‚Äôaumentare della dimensione del campione.\nLa presenza di pi√π variabili esplicative (\\(k \\geq 2\\)) complica ulteriormente la stima dei parametri del modello. Inoltre, il modello mostra un cambiamento brusco nella pendenza della curva di regressione ai punti estremi (0 e 1 di \\(\\pi\\)), risultando poco realistico in molte situazioni pratiche. Questo rende il modello meno adatto a descrivere relazioni complesse e gradualmente variabili tra \\(\\pi\\) e \\(X\\).\nUna funzione che modella una relazione pi√π fluida e continua tra \\(\\pi\\) e \\(X\\) sarebbe pi√π realistica e rappresentativa delle dinamiche osservate. Questo motiva la preferenza per modelli alternativi, come il modello di regressione logistica, che tende a fornire una rappresentazione pi√π accurata e realistica delle interazioni tra variabili dicotomiche e esplicative.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.4 Regressione Logistica",
    "text": "67.4 Regressione Logistica\nUn metodo efficace per gestire il problema del vincolo sulle probabilit√† √® specificare modelli non direttamente per le probabilit√† stesse, ma per una loro trasformazione che elimina tale vincolo. Invece di definire un modello lineare per la probabilit√† condizionata \\(\\pi_i\\), si pu√≤ specificare un modello lineare per il logaritmo degli odds (logit):\n\\[\n\\eta_i = \\log_e \\frac{\\pi_i}{1-\\pi_i} = \\alpha + \\beta x_i,\n\\]\nQuesto approccio non presenta problemi poich√© il logit \\(\\eta_i\\) √® sempre un numero reale, permettendo di modellare una trasformazione lineare di \\(\\pi_i\\). La trasformazione inversa, che ci permette di ottenere \\(\\pi_i\\) da \\(\\eta_i\\), √® data dalla funzione logistica:\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n\\]\n\n67.4.1 Vantaggi della Regressione Logistica\nLa regressione logistica presenta diversi vantaggi rispetto al modello lineare delle probabilit√†:\n\nVincolo delle Probabilit√†: La trasformazione logistica assicura che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell‚Äôintervallo [0,1].\nInterpretabilit√† degli Odds Ratio: Il coefficiente \\(\\beta\\) pu√≤ essere interpretato come il cambiamento logaritmico negli odds di successo associato a un incremento unitario di \\(X\\). In altre parole, \\(e^\\beta\\) rappresenta il fattore di aumento (o diminuzione) degli odds per un incremento unitario della variabile indipendente.\nGestione dell‚ÄôEteroschedasticit√†: La forma funzionale della varianza del modello di regressione logistica \\(\\pi_i (1 - \\pi_i)\\) √® intrinsecamente considerata nel processo di stima tramite il metodo della massima verosimiglianza.\n\n\n\n67.4.2 Esempio Pratico\nPer illustrare l‚Äôapplicazione della regressione logistica, consideriamo nuovamente i dati simulati precedentemente. Applichiamo il modello di regressione logistica ai dati e tracciamo la curva logistica risultante:\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit logistic regression model and plot logistic curve\nX_design = sm.add_constant(X)\nlogit_model = sm.Logit(Y, X_design).fit()\nx_vals = np.linspace(X.min(), X.max(), 100)\ny_vals = logit_model.predict(sm.add_constant(x_vals))\n\nplt.plot(x_vals, y_vals, color='red', label='Logistic Regression Curve')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()\n\nOptimization terminated successfully.\n         Current function value: 0.289256\n         Iterations 8\n\n\n\n\n\n\n\n\n\nQuesto esempio dimostra come la regressione logistica possa essere utilizzata per modellare una variabile dicotomica in funzione di una variabile indipendente. La curva logistica risultante rappresenta adeguatamente la relazione tra \\(X\\) e la probabilit√† di successo \\(Y\\), garantendo che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell‚Äôintervallo [0,1].\nNelle sezioni seguenti, descriveremo in dettaglio il modello di regressione logistica utilizzato per generare la curva logistica mostrata nella figura precedente. Inizieremo chiarendo i concetti di odds e logit e la loro relazione con le probabilit√†.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#probabilit√†-odds-e-logit",
    "href": "chapters/glm/03_stan_logistic_regr.html#probabilit√†-odds-e-logit",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.5 Probabilit√†, Odds e Logit",
    "text": "67.5 Probabilit√†, Odds e Logit\nLa relazione tra probabilit√†, odds e logit √® fondamentale per comprendere la regressione logistica. Questa relazione trasforma l‚Äôintervallo di probabilit√† (0, 1) in uno spettro pi√π ampio, rendendo possibile modellare le probabilit√† con un modello lineare.\nGli odds rappresentano il rapporto tra la probabilit√† di un evento e la probabilit√† del suo complemento. Il logit, invece, √® il logaritmo naturale degli odds, trasformando cos√¨ l‚Äôintervallo di probabilit√† in tutta la linea dei numeri reali. Quando la probabilit√† √® 0.5, gli odds sono 1 e il logit √® 0. Logit negativi indicano probabilit√† inferiori a 0.5, mentre logit positivi indicano probabilit√† superiori a 0.5.\n\n\n\n\n\n\n\n\nProbabilit√† (P)\nOdds (O)\nlogit (L)\n\n\n\n\n0.01\n0.01 / 0.99 = 0.0101\n\\(\\ln(\\frac{0.01}{0.99}) = -4.60\\)\n\n\n0.05\n0.05 / 0.95 = 0.0526\n\\(\\ln(\\frac{0.05}{0.95}) = -2.94\\)\n\n\n0.10\n0.10 / 90 = 0.1111\n\\(\\ln(\\frac{0.10}{0.90}) = -2.20\\)\n\n\n0.30\n0.30 / 0.70 = 0.4286\n\\(\\ln(\\frac{0.30}{0.70}) = -0.85\\)\n\n\n0.50\n0.50 / 0.50 = 1\n\\(\\ln(\\frac{0.50}{0.50}) = 0.00\\)\n\n\n0.70\n0.70 / 0.30 = 2.3333\n\\(\\ln(\\frac{0.70}{0.30}) = 0.85\\)\n\n\n0.90\n0.90 / 0.10 = 9\n\\(\\ln(\\frac{0.90}{0.10}) = 2.20\\)\n\n\n0.95\n0.95 / 0.05 = 19\n\\(\\ln(\\frac{0.95}{0.05}) = 2.94\\)\n\n\n0.99\n0.99 / 0.01 = 99\n\\(\\ln(\\frac{0.99}{0.01}) = 4.60\\)\n\n\n\n\n67.5.1 Trasformazione Inversa del Logit\nLa trasformazione inversa del logit, detta antilogit, consente di trasformare i logit in probabilit√†:\n\\[\n  \\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}}.\n\\]\nGrazie a questa trasformazione, possiamo passare dai logit alle probabilit√†. La trasformazione inversa del logit permette di specificare un modello non lineare per le probabilit√† \\(\\pi_i\\). Tale modello non lineare √® detto logit o modello di regressione logistica:\n\\[\n  \\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n\\]\nQuesto modello garantisce che le probabilit√† \\(\\pi_i\\) siano sempre comprese nell‚Äôintervallo [0,1], risolvendo i problemi del modello lineare nelle probabilit√† e fornendo una rappresentazione accurata della relazione tra la variabile indipendente \\(X\\) e la probabilit√† di successo \\(Y\\).\nLa funzione logistica ben rappresenta l‚Äôandamento sigmoidale delle proporzioni di casi \\(Y=1\\), ovvero \\(\\hat{\\pi}_i = E(Y \\mid x_i)\\) in funzione di livelli crescenti della variabile \\(X\\).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modelli-lineari-generalizzati",
    "href": "chapters/glm/03_stan_logistic_regr.html#modelli-lineari-generalizzati",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.6 Modelli Lineari Generalizzati",
    "text": "67.6 Modelli Lineari Generalizzati\nNel caso di una variabile risposta binaria, il modello classico di regressione lineare si scontra con sfide specifiche:\n\nDistribuzione Binomiale: \\(Y_i\\) segue una distribuzione binomiale (con indice \\(n_i\\), potenzialmente uguale a uno nel caso individuale), rendendo non applicabile l‚Äôipotesi di normalit√†.\nLimiti delle Probabilit√†: Utilizzando una specificazione lineare come \\(\\pi_i= \\beta_0 + \\beta_1 x_i\\), si possono ottenere stime di probabilit√† esterne all‚Äôintervallo 0-1.\nVarianze Non Costanti: La varianza di \\(\\varepsilon\\) varia in base alla specificazione del modello di probabilit√†, seguendo la formula \\(V(\\varepsilon_i)=\\pi_i(1-\\pi_i)\\).\n\nPer superare queste sfide, si utilizzano i Modelli Lineari Generalizzati (GLM). Questi modelli consentono l‚Äôuso di variabili risposta di diversa natura e includono:\n\nRegressione Lineare: Per variabili dipendenti continue e variabili esplicative continue o qualitative.\nRegressione Logistica: Per variabili risposta binarie.\nModello Loglineare di Poisson: Per modellare frequenze in tabelle di contingenza.\n\nI GLM allentano alcune ipotesi fondamentali del modello lineare classico, come linearit√†, normalit√† della componente erratica, e omoschedasticit√† delle osservazioni. Sono strutturati in tre componenti principali:\n\nComponente Aleatoria: Definisce la distribuzione di probabilit√† della variabile risposta \\(Y\\).\nComponente Sistematica: Specifica la relazione lineare tra le variabili esplicative e una trasformazione della variabile risposta.\nFunzione Legame: Trasforma la media attesa \\(\\mathbb{E}(Y)\\) in un formato che possa essere modellato linearmente rispetto alle variabili esplicative. Non √® la variabile risposta stessa ad essere modellizzata direttamente, ma una sua trasformazione, come il logit nel caso della regressione logistica.\n\nEsempi di combinazioni di componenti aleatorie, funzioni di legame e sistematiche nei GLM includono:\n\n\n\n\n\n\n\n\n\nComponente Aleatoria\nFunzione Legame\nComponente Sistematica\nModello\n\n\n\n\nGaussiana\nIdentit√†\nContinua\nRegressione\n\n\nGaussiana\nIdentit√†\nCategoriale\nAnalisi della varianza\n\n\nGaussiana\nIdentit√†\nMista\nAnalisi della covarianza\n\n\nBinomiale\nLogit\nMista\nRegressione logistica\n\n\nPoisson\nLogaritmo\nMista\nModello Loglineare\n\n\n\nQuesta struttura rende i GLM particolarmente flessibili e adatti a una vasta gamma di situazioni statistiche, superando i limiti del modello lineare classico.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.7 Componente Sistematica",
    "text": "67.7 Componente Sistematica\nLa componente sistematica mette in relazione un vettore (\\(\\eta_1, \\eta_2, \\dots, \\eta_k\\)) con le variabili esplicative mediante un modello lineare. Sia \\(X_{ij}\\) il valore della \\(j\\)-esima variabile esplicativa (\\(j=1, 2, \\dots, p\\)) per l‚Äô\\(i\\)-esima osservazione (\\(i=1, \\dots, k\\)). Allora\n\\[\n\\eta_i = \\sum_j \\beta_j X_{ij}.\n\\]\nQuesta combinazione lineare di variabili esplicative √® chiamata il predittore lineare. Un \\(X_{ij}=1, \\forall i\\) viene utilizzato per il coefficiente dell‚Äôintercetta del modello (talvolta denotata da \\(\\alpha\\)).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.8 Componente Aleatoria",
    "text": "67.8 Componente Aleatoria\nLa componente aleatoria del modello suppone l‚Äôesistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Si assume che \\(Y_i\\) abbia una distribuzione binomiale:\n\\[\nY_i \\sim Bin(n_i, \\pi_i)\n\\]\ncon parametri \\(n_i\\) e \\(\\pi_i\\). Per dati individuali (uno per ciascun valore \\(x_i\\)), \\(n_i=1,\n    \\forall i\\).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#funzione-legame",
    "href": "chapters/glm/03_stan_logistic_regr.html#funzione-legame",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.9 Funzione Legame",
    "text": "67.9 Funzione Legame\nLa funzione legame \\(g(\\cdot)\\) mette in relazione il valore atteso della variabile risposta \\(Y_i\\) con la componente sistematica \\(\\eta_i\\) del modello. Abbiamo visto che \\(\\mathbb{E}(Y_i)=\\pi_i\\). Che relazione c‚Äô√® tra \\(\\pi_i\\) e il predittore lineare \\(\\eta_i= \\alpha + \\sum_j  \\beta_j X_{ij}\\)? La risposta a questa domanda √® data dalla funzione legame:\n\\[\n\\eta_i = g(\\pi_i) = \\ln{\\frac{\\pi_i}{1-\\pi_i}}\n\\]\nSi noti che la funzione legame non trasforma la variabile risposta \\(Y_i\\) ma bens√¨ il suo valore atteso \\(\\pi_i\\).\nLa funzione legame √® invertibile: anzich√© trasformare il valore atteso nel predittore lineare si pu√≤ trasformare il predittore lineare nel valore atteso \\(\\pi_i\\):\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} =  \\frac{e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}{1+e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}.\n\\]\nSi ottiene cos√¨ un modello non lineare per le probabilit√† \\(\\pi_i\\).\nIn conclusione, la regressione logistica estende il concetto di regressione lineare per modellare le probabilit√† condizionate di esiti Bernoulliani $ Y \\(, adoperando la funzione logistica come collegamento per trasformare relazioni lineari tra predittori (\\) _i = _0 + 1 X{i} $) in probabilit√† nell‚Äôintervallo [0,1]. Questo metodo permette di passare dalla modellazione diretta della probabilit√† $ p $ alla modellazione di una funzione di tale probabilit√† attraverso una relazione lineare, impiegando la funzione logit come funzione di collegamento.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modelli-lineari-generalizzati-1",
    "href": "chapters/glm/03_stan_logistic_regr.html#modelli-lineari-generalizzati-1",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.10 Modelli Lineari Generalizzati",
    "text": "67.10 Modelli Lineari Generalizzati\nNel caso di una variabile risposta binaria, il modello classico di regressione lineare incontra alcune difficolt√† specifiche:\n\nDistribuzione Binomiale: \\(Y_i\\) segue una distribuzione binomiale, rendendo inapplicabile l‚Äôipotesi di normalit√†.\nLimiti delle Probabilit√†: Utilizzando una specificazione lineare come \\(\\pi_i = \\beta_0 + \\beta_1 x_i\\), si possono ottenere stime di probabilit√† al di fuori dell‚Äôintervallo 0-1.\nVarianze Non Costanti: La varianza dei residui \\(\\varepsilon_i\\) varia in base alla specificazione del modello di probabilit√†, seguendo la formula \\(V(\\varepsilon_i) = \\pi_i(1 - \\pi_i)\\).\n\nPer superare queste sfide, si utilizzano i Modelli Lineari Generalizzati (GLM). Questi modelli consentono l‚Äôuso di variabili risposta di diversa natura e includono:\n\nRegressione Lineare: Per variabili dipendenti continue.\nRegressione Logistica: Per variabili risposta binarie.\nModello Loglineare di Poisson: Per modellare frequenze in tabelle di contingenza.\n\nI GLM allentano alcune ipotesi fondamentali del modello lineare classico, come linearit√†, normalit√† della componente erratica e omoschedasticit√† delle osservazioni. Sono strutturati in tre componenti principali:\n\nComponente Aleatoria: Definisce la distribuzione di probabilit√† della variabile risposta \\(Y\\).\nComponente Sistematica: Specifica la relazione lineare tra le variabili esplicative e una trasformazione della variabile risposta.\nFunzione Legame: Trasforma la media attesa \\(\\mathbb{E}(Y)\\) in un formato che possa essere modellato linearmente rispetto alle variabili esplicative. Non √® la variabile risposta stessa ad essere modellata direttamente, ma una sua trasformazione, come il logit nel caso della regressione logistica.\n\n\n67.10.1 Combinazioni di Componenti nei GLM\nEsempi di combinazioni di componenti aleatorie, funzioni di legame e sistematiche nei GLM includono:\n\n\n\n\n\n\n\n\n\nComponente Aleatoria\nFunzione Legame\nComponente Sistematica\nModello\n\n\n\n\nGaussiana\nIdentit√†\nContinua\nRegressione\n\n\nBinomiale\nLogit\nContinua\nRegressione logistica\n\n\nPoisson\nLogaritmo\nContinua\nModello Loglineare\n\n\n\nQuesta struttura rende i GLM particolarmente flessibili e adatti a una vasta gamma di situazioni statistiche, superando i limiti del modello lineare classico.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica-1",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica-1",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.11 Componente Sistematica",
    "text": "67.11 Componente Sistematica\nLa componente sistematica mette in relazione un vettore \\((\\eta_1, \\eta_2, \\dots, \\eta_k)\\) con le variabili esplicative mediante un modello lineare. Sia \\(X_{i}\\) il valore della variabile esplicativa continua per l‚Äô\\(i\\)-esima osservazione (\\(i=1, \\dots, k\\)). Allora:\n\\[\n\\eta_i = \\beta_0 + \\beta_1 X_i.\n\\]\nQuesta combinazione lineare di variabili esplicative √® chiamata il predittore lineare.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria-1",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria-1",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.12 Componente Aleatoria",
    "text": "67.12 Componente Aleatoria\nLa componente aleatoria del modello suppone l‚Äôesistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Si assume che \\(Y_i\\) abbia una distribuzione binomiale:\n\\[\nY_i \\sim \\text{Bin}(1, \\pi_i),\n\\]\ncon parametro \\(\\pi_i\\). Per dati individuali, \\(n_i=1\\) per tutti \\(i\\).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#funzione-legame-1",
    "href": "chapters/glm/03_stan_logistic_regr.html#funzione-legame-1",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.13 Funzione Legame",
    "text": "67.13 Funzione Legame\nLa funzione legame \\(g(\\cdot)\\) mette in relazione il valore atteso della variabile risposta \\(Y_i\\) con la componente sistematica \\(\\eta_i\\) del modello. Abbiamo visto che \\(\\mathbb{E}(Y_i) = \\pi_i\\). La relazione tra \\(\\pi_i\\) e il predittore lineare \\(\\eta_i = \\beta_0 + \\beta_1 X_i\\) √® data dalla funzione legame:\n\\[\n\\eta_i = g(\\pi_i) = \\ln{\\frac{\\pi_i}{1 - \\pi_i}}.\n\\]\nSi noti che la funzione legame non trasforma la variabile risposta \\(Y_i\\) ma il suo valore atteso \\(\\pi_i\\).\nLa funzione legame √® invertibile: anzich√© trasformare il valore atteso nel predittore lineare, si pu√≤ trasformare il predittore lineare nel valore atteso \\(\\pi_i\\):\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\beta_0 + \\beta_1 X_i}}{1 + e^{\\beta_0 + \\beta_1 X_i}}.\n\\]\nSi ottiene cos√¨ un modello non lineare per le probabilit√† \\(\\pi_i\\).\n\n67.13.1 Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione\nUn aspetto cruciale per comprendere la relazione tra le variabili predittive e una variabile di risposta binaria √® l‚Äôinterpretazione dei coefficienti del modello.\n\n67.13.1.1 Interpretazione sui Logit\nNella regressione logistica, ogni coefficiente \\(\\beta_j\\) del modello pu√≤ essere interpretato direttamente in termini di log-odds, che sono i logaritmi delle probabilit√† di ottenere un evento con esito positivo (\\(y=1\\)). Quando interpretiamo i coefficienti:\n\nCoefficienti Positivi (\\(\\beta_j &gt; 0\\)): Un coefficiente positivo indica che c‚Äô√® una relazione diretta tra il predittore e l‚Äôaumento dei log-odds di osservare l‚Äôevento di interesse. Questo significa che all‚Äôaumentare del valore del predittore, la probabilit√† dell‚Äôevento di interesse aumenta.\nCoefficienti Negativi (\\(\\beta_j &lt; 0\\)): Al contrario, un coefficiente negativo indica una relazione inversa tra il predittore e la probabilit√† logistica dell‚Äôevento. Con l‚Äôaumentare del predittore, i log-odds e quindi la probabilit√† dell‚Äôevento diminuiscono.\n\n\n\n67.13.1.2 Interpretazione sugli Odds Ratio (OR)\nL‚Äôinterpretazione dei coefficienti nella regressione logistica pu√≤ estendersi agli odds ratio (OR), che forniscono informazioni sulla relazione tra i predittori e la probabilit√† dell‚Äôevento di interesse. Per esempio, consideriamo un modello con un predittore continuo \\(X\\) e un coefficiente \\(\\beta_1 = 0.50\\). Il logaritmo naturale dell‚Äôodds ratio, \\(\\log(OR) = 0.50\\), viene esponenziato per ottenere:\n\\[\nOR = e^{0.50} \\approx 1.65.\n\\]\nQuesto risultato indica che per un‚Äôunit√† di incremento in \\(X\\), l‚Äôodds di sperimentare l‚Äôevento di interesse √® circa 1.65 volte maggiore. In altre parole, l‚Äôincremento di una unit√† nel predittore \\(X\\) aumenta l‚Äôodds di sperimentare l‚Äôevento di interesse di circa il 65%. Viceversa, un coefficiente negativo indicherebbe una diminuzione dell‚Äôodds per un incremento di una unit√† in \\(X\\).\n\n\n67.13.1.3 Interpretazione sulla Scala delle Probabilit√†\nLa regressione logistica consente di interpretare i coefficienti non solo in termini di log-odds, ma anche relativamente alle variazioni di probabilit√†. Consideriamo un modello che predice la probabilit√† di superare un esame basandosi sul numero di ore di studio (\\(X\\)).\nSupponiamo che il coefficiente associato alle ore di studio sia \\(\\beta_1 = 0.5\\). Questo valore indica che ogni ora aggiuntiva di studio incrementa i log-odds di successo nell‚Äôesame. Per comprendere l‚Äôimpatto di un‚Äôora in pi√π di studio sulla probabilit√† di successo, possiamo utilizzare la seguente formula:\n\\[\n\\Delta p = \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot (X_1 + 1))}} - \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot X_1)}}.\n\\]\nQuesta formula calcola la differenza tra la probabilit√† di successo dopo aver aggiunto un‚Äôora di studio e la probabilit√† di successo prima di tale aggiunta. In termini pratici, \\(\\Delta p\\) rappresenta l‚Äôincremento della probabilit√† di superare l‚Äôesame attribuibile a un‚Äôora supplementare di studio. Questa interpretazione √® cruciale per valutare quantitativamente l‚Äôeffetto delle ore di studio sulla probabilit√† di superare l‚Äôesame.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#un-esempio-concreto",
    "href": "chapters/glm/03_stan_logistic_regr.html#un-esempio-concreto",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.14 Un esempio concreto",
    "text": "67.14 Un esempio concreto\nConsideriamo nuovamente i dati simulati in precedenza\n\ndf.head()\n\n\n\n\n\n\n\n\n\nX\nY\n\n\n\n\n0\n6\n1\n\n\n1\n3\n1\n\n\n2\n7\n1\n\n\n3\n4\n1\n\n\n4\n6\n1\n\n\n\n\n\n\n\n\nStimeremo ora i coefficienti del modello di regressione logistica usando Stan. Definiamo i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\" : df.shape[0],\n    \"y\" : df[\"Y\"],\n    \"x\" : df[\"X\"] \n}\n\nCompiliamo il modello di regressione logistica e stampiamo lo script Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"logistic_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:47:02 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n12:47:13 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  real alpha;\n  real beta;\n}\nmodel {\n  y ~ bernoulli_logit(alpha + beta * x);\n}\n\n\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n12:47:36 - cmdstanpy - INFO - CmdStan start processing\n12:47:36 - cmdstanpy - INFO - Chain [1] start processing\n12:47:36 - cmdstanpy - INFO - Chain [2] start processing\n12:47:36 - cmdstanpy - INFO - Chain [3] start processing\n12:47:36 - cmdstanpy - INFO - Chain [4] start processing\n12:47:37 - cmdstanpy - INFO - Chain [3] done processing\n12:47:37 - cmdstanpy - INFO - Chain [2] done processing\n12:47:37 - cmdstanpy - INFO - Chain [4] done processing\n12:47:37 - cmdstanpy - INFO - Chain [1] done processing\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(fit)\n\n\n\n\n\n\n\n\nOtteniamo le stime a posteriori dei parametri:\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-1.778\n0.18\n-2.132\n-1.436\n0.004\n0.003\n2261.0\n2634.0\n1.0\n\n\nbeta\n1.004\n0.07\n0.869\n1.144\n0.001\n0.001\n2305.0\n2682.0\n1.0\n\n\n\n\n\n\n\n\nCreiamo un nuovo DataFrame con 100 valori \\(x\\) nell‚Äôintervallo [0, 9]:\n\nnew_data = pd.DataFrame({\n    \"x\": np.linspace(0, 9, 100)\n})\nnew_data\n\n\n\n\n\n\n\n\n\nx\n\n\n\n\n0\n0.000000\n\n\n1\n0.090909\n\n\n2\n0.181818\n\n\n3\n0.272727\n\n\n4\n0.363636\n\n\n...\n...\n\n\n95\n8.636364\n\n\n96\n8.727273\n\n\n97\n8.818182\n\n\n98\n8.909091\n\n\n99\n9.000000\n\n\n\n\n100 rows √ó 1 columns\n\n\n\n\nOtteniamo le medie a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\nalpha = fit.stan_variable('alpha').mean()\nbeta = fit.stan_variable('beta').mean() \nprint(alpha, beta)\n\n-1.7784477 1.003503126\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilit√† √® una funzione lineare di $ x $:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\n\nlogit_p = alpha + new_data['x'] * beta\nlogit_p\n\n0    -1.778448\n1    -1.687220\n2    -1.595993\n3    -1.504765\n4    -1.413537\n        ...   \n95    6.888170\n96    6.979398\n97    7.070625\n98    7.161853\n99    7.253080\nName: x, Length: 100, dtype: float64\n\n\nEsaminiamo graficamente la relazione tra il logit \\(\\log \\left( \\frac{p}{1-p} \\right)\\) e \\(x\\):\n\nnew_data['logit_p'] = logit_p\n\nplt.plot(new_data['x'], new_data['logit_p'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Logit Predetti in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Logit')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilit√† √® una funzione lineare di $ x $. Per ottenere la probabilit√† $ p $ dalla trasformazione del logit, possiamo utilizzare la funzione logistica inversa. Svolgiamo la conversione:\n\nCalcoliamo il logit per ogni valore di $ x $:\n\\[\n\\text{logit}_p = \\alpha + \\beta x\n\\]\nApplichiamo la funzione logistica inversa (antilogit) per ottenere la probabilit√† $ p $:\n\\[\np = \\frac{e^{\\text{logit}_p}}{1 + e^{\\text{logit}_p}} = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}\n\\]\n\nQuesta formula ci permette di trasformare il logit in una probabilit√† compresa tra 0 e 1 per ogni valore di $ x $ nel dataset new_data.\n\nprob = np.exp(logit_p) / (1 + np.exp(logit_p))\n# Aggiungi le probabilit√† calcolate a `new_data`\nnew_data['prob'] = prob\nnew_data.head()\n\n\n\n\n\n\n\n\n\nx\nlogit_p\nprob\n\n\n\n\n0\n0.000000\n-1.778448\n0.144495\n\n\n1\n0.090909\n-1.687220\n0.156142\n\n\n2\n0.181818\n-1.595993\n0.168542\n\n\n3\n0.272727\n-1.504765\n0.181716\n\n\n4\n0.363636\n-1.413537\n0.195677\n\n\n\n\n\n\n\n\n\nplt.plot(new_data['x'], new_data['prob'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Probabilit√† Predetta in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Probabilit√† Predetta')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\n\n67.14.1 Interpretazione dei Coefficienti nella Regressione Logistica\nAbbiamo stimato i coefficienti \\(\\alpha\\) e \\(\\beta\\) dal modello di regressione logistica con i seguenti valori: - \\(\\alpha = -1.7784477\\) - \\(\\beta = 1.003503126\\)\nEsamineremo ora l‚Äôinterpretazione di questi coefficienti sulla scala dei logit, dell‚Äôodds ratio e delle probabilit√†.\n\n67.14.1.1 La regola del dividere per 4\nLa regola del dividere per 4 √® un metodo utile per interpretare i coefficienti della regressione logistica. Dividendo il coefficiente \\(\\beta\\) per 4, si ottiene un‚Äôapprossimazione della massima variazione nella probabilit√† \\(\\Pr(y = 1)\\) per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nLa curva logistica √® pi√π ripida al centro, dove $ + x = 0 $ e quindi $ ^{-1}(+ x) = 0.5 $. In questo punto, la pendenza della curva, ovvero la derivata della funzione logistica, √® massima e raggiunge il valore $ / 4 $.\nPer esempio, nel modello con $ = -1.778 $ e $ = 1.003 $, dividendo \\(\\beta\\) per 4 otteniamo circa 0.25. Questo valore rappresenta l‚Äôaumento massimo, in termini di probabilit√†, che possiamo aspettarci per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nIn sintesi, la regola del dividere per 4 semplifica l‚Äôinterpretazione dei coefficienti della regressione logistica, fornendo un‚Äôindicazione intuitiva di come la variabile indipendente influisce sulla probabilit√† dell‚Äôevento di interesse.\n\n\n67.14.1.2 Scala dei Logit\nNella regressione logistica, la funzione logit rappresenta una relazione lineare tra il logit della probabilit√† di successo e la variabile indipendente \\(X\\):\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\nCon i coefficienti stimati, la funzione logit diventa:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot x\n\\]\n\n\\(\\alpha = -1.7784477\\): Questo √® l‚Äôintercetta del modello, il valore del logit quando \\(x = 0\\). Indica che, quando \\(x\\) √® 0, il logit della probabilit√† di successo √® \\(-1.7784477\\).\n\\(\\beta = 1.003503126\\): Questo √® il coefficiente di \\(x\\) e rappresenta il cambiamento nel logit per ogni incremento unitario in \\(x\\). In altre parole, per ogni incremento di 1 unit√† in \\(x\\), il logit della probabilit√† di successo aumenta di circa \\(1.003503126\\).\n\n\n\n67.14.1.3 Odds Ratio\nL‚Äôodds ratio (OR) misura il cambiamento relativo nelle odds di successo per un incremento unitario in \\(x\\). √à ottenuto esponenziando il coefficiente \\(\\beta\\):\n\\[\n\\text{OR} = e^{\\beta} = e^{1.003503126} \\approx 2.728\n\\]\nUn odds ratio di circa \\(2.728\\) indica che, per ogni incremento unitario in \\(x\\), le odds di successo aumentano di circa \\(172.8\\%\\). In altre parole, l‚Äôodds di successo √® circa \\(2.728\\) volte maggiore per ogni unit√† aggiuntiva di \\(x\\).\n\n\n67.14.1.4 Scala delle Probabilit√†\nPer interpretare l‚Äôeffetto di \\(\\beta\\) sulla scala delle probabilit√†, possiamo considerare come la probabilit√† \\(p\\) cambia in corrispondenza di specifici valori di \\(x\\).\n\nQuando \\(x = 0\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-1.7784477}}{1 + e^{-1.7784477}} \\approx \\frac{0.169} {1 + 0.169} \\approx 0.144\n\\]\nQuindi, la probabilit√† di successo quando \\(x = 0\\) √® circa \\(14.4\\%\\).\n\nPer un incremento unitario in \\(x\\), diciamo \\(x = 1\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot 1 \\approx -0.774944574\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-0.774944574}}{1 + e^{-0.774944574}} \\approx \\frac{0.461} {1 + 0.461} \\approx 0.316\n\\]\nQuindi, la probabilit√† di successo quando \\(x = 1\\) √® circa \\(31.6\\%\\). Tuttavia questo incremento non √® costante per i diversi livelli \\(x\\) e il modo pi√π semplice per mostrare la relazione tra probabilit√† di successo e la variabile \\(X\\) √® quella di generare un grafico come quello che abbimo prodotto in precedenza.\n\n\n\n67.14.2 Riassunto\n\nScala dei Logit: Un incremento unitario in \\(x\\) aumenta il logit della probabilit√† di successo di \\(1.003503126\\).\nOdds Ratio: Le odds di successo aumentano di circa \\(2.728\\) volte per ogni incremento unitario in \\(x\\).\nScala delle Probabilit√†: Quando \\(x\\) passa da 0 a 1, la probabilit√† di successo aumenta da circa \\(14.4\\%\\) a \\(31.6\\%\\). Per la relazione tra ciascun livello \\(x\\) e la probabilit√† di successo √® necessario generare un grafico.\n\nQuesta analisi dimostra come i coefficienti del modello di regressione logistica possono essere interpretati su diverse scale, fornendo un quadro completo della relazione tra la variabile indipendente e la probabilit√† di successo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.15 Regressione logistica con solo l‚Äôintercetta",
    "text": "67.15 Regressione logistica con solo l‚Äôintercetta\nLa regressione lineare con solo l‚Äôintercetta √® equivalente a stimare una media e la regressione lineare con un singolo predittore binario √® equivalente a stimare una differenza tra medie. Allo stesso modo, la regressione logistica con solo l‚Äôintercetta √® equivalente alla stima di una proporzione.\nEcco un esempio. Un campione casuale di 50 persone viene testato e 10 di loro manifestano una certa caratteristica psicologica. La proporzione √® 0.20 con errore standard $ = 0.06 $. In alternativa, possiamo impostare questo come regressione logistica usando Bambi in Python:\n\n# Dati\ny = [0]*40 + [1]*10\ndf = pd.DataFrame({'y': y})\n\n# Modello\nmodel = bmb.Model('y ~ 1', data=df, family='bernoulli')\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.39\n0.35\n-2.05\n-0.73\n0.01\n0.01\n1524.26\n1636.18\n1.0\n\n\n\n\n\n\n\n\nPossiamo trasformare la previsione nella scala delle probabilit√† e ottenere un risultato che √® essenzialmente lo stesso della stima classica con incertezza di 0.20 ¬± 0.06.\n\n# Given values\nintercept = -1.4\nerror = 0.35\n\n# Calculate logit^-1(-1.41)\np_hat = expit(intercept)\n\n# Calculate logit^-1(-1.41 ¬± 0.36)\nlower_bound = expit(intercept - error)\nupper_bound = expit(intercept + error)\n\nprint(f'p_hat: {p_hat:.3f}, Lower bound: {lower_bound:.3f}, Upper bound: {upper_bound:.3f}')\n\np_hat: 0.198, Lower bound: 0.148, Upper bound: 0.259\n\n\nLe stime classiche e quelle della regressione logistica differiscono leggermente, in parte perch√© Bambi usa una distribuzione a priori e in parte perch√© l‚Äôerrore standard classico √® solo un‚Äôapprossimazione all‚Äôincertezza inferenziale derivante dai dati discreti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "title": "67¬† Regressione logistica con Stan",
    "section": "67.16 Regressione logistica con un singolo predittore binario",
    "text": "67.16 Regressione logistica con un singolo predittore binario\nLa regressione logistica su una variabile indicatrice √® equivalente a un confronto di proporzioni. Per un esempio semplice, consideriamo i test per una malattia su campioni provenienti da due popolazioni diverse, dove 10 su 50 individui della popolazione A risultano positivi, rispetto a 20 su 60 della popolazione B. La stima classica √® 0.13 con errore standard di 0.08. Ecco come impostare questo caso come regressione logistica utilizzando Bambi in Python:\n\n# Dati\nx = [0] * 50 + [1] * 60\ny = [0] * 40 + [1] * 10 + [0] * 40 + [1] * 20\ndf = pd.DataFrame({'x': x, 'y': y})\n\n# Definire il modello\nmodel = bmb.Model('y ~ x', data=df, family='bernoulli')\n\n# Adattare il modello con un seed\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Visualizzare i risultati del fit\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.41\n0.36\n-2.07\n-0.74\n0.01\n0.01\n2661.46\n2476.84\n1.0\n\n\nx\n0.71\n0.45\n-0.09\n1.60\n0.01\n0.01\n3115.18\n2554.46\n1.0\n\n\n\n\n\n\n\n\nPer ottenere l‚Äôinferenza per la differenza di probabilit√†, confrontiamo le previsioni sulla scala delle probabilit√† per $ x = 0 $ e $ x = 1 $:\n\n# Given values\nintercept = -1.41\nslope = 0.71\n\n# Calculate probabilities for x = 0 and x = 1\nlogit_0 = intercept\nlogit_1 = intercept + slope\n\nprob_0 = expit(logit_0)\nprob_1 = expit(logit_1)\n\n# Calculate the difference in probabilities\ndiff = prob_1 - prob_0\n\nprob_0, prob_1, diff\nprint(f'prob_0: {prob_0:.3f}, prob_1: {prob_1:.3f}, difference: {diff:.3f}')\n\nprob_0: 0.196, prob_1: 0.332, difference: 0.136\n\n\nPer l‚Äôerrore standard possiamo eseguire la seguente simulazione:\n\n# Given values\nintercept_mean = -1.41\nslope_mean = 0.71\nintercept_sd = 0.36\nslope_sd = 0.45\n\n# Number of simulations\nnum_simulations = 10000\n\n# Generate samples of the coefficients\nintercept_samples = np.random.normal(intercept_mean, intercept_sd, num_simulations)\nslope_samples = np.random.normal(slope_mean, slope_sd, num_simulations)\n\n# Calculate the corresponding probabilities\nprob_0_samples = expit(intercept_samples)\nprob_1_samples = expit(intercept_samples + slope_samples)\n\n# Calculate the difference in probabilities for each sample\ndiff_samples = prob_1_samples - prob_0_samples\n\n# Calculate the mean and standard deviation of the differences\nmean_diff = np.mean(diff_samples)\nstd_diff = np.std(diff_samples)\n\nmean_diff, std_diff\nprint(f'difference: {mean_diff:.3f}, standard error: {std_diff:.3f}')\n\ndifference: 0.140, standard error: 0.096\n\n\nSebbene abbiamo ottenuto un errore standard di circa 0.095, che √® leggermente diverso dall‚Äôerrore standard di 0.08 menzionato inizialmente, questo valore riflette l‚Äôincertezza nelle stime dei coefficienti fornite. Potrebbero esserci delle variazioni dovute al metodo di campionamento utilizzato. Tuttavia, questi calcoli dimostrano l‚Äôapproccio corretto per stimare l‚Äôerrore standard utilizzando la simulazione Monte Carlo con le deviazioni standard dei coefficienti stimati. ‚Äã",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "67¬† Regressione logistica con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz      : 0.18.0\nseaborn    : 0.13.2\nmatplotlib : 3.9.1\nscipy      : 1.14.0\nstatsmodels: 0.14.2\npandas     : 2.2.2\nnumpy      : 1.26.4\nbambi      : 0.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html",
    "href": "chapters/glm/04_stan_poisson_regr.html",
    "title": "68¬† Regressione di Poisson con Stan",
    "section": "",
    "text": "Introduzione\nIn questo tutorial, approfondiremo l‚Äôutilizzo di CmdStanPy per condurre un‚Äôanalisi di regressione di Poisson. La regressione di Poisson rappresenta una forma di modello lineare generalizzato impiegato nell‚Äôanalisi di regressione per modellare dati di conteggio. Essa si basa sull‚Äôassunzione che la variabile di risposta Y segua una distribuzione di Poisson, con il logaritmo del suo valore atteso modellabile attraverso una combinazione lineare di parametri sconosciuti.\nIn questo capitolo, dopo aver investigato il calcolo della media a posteriori e dell‚Äôincertezza correlata al tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, ci interrogheremo se vi siano evidenze di una tendenza all‚Äôaumento di tale tasso nel corso del tempo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "href": "chapters/glm/04_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "title": "68¬† Regressione di Poisson con Stan",
    "section": "68.1 Introduzione alla Regressione di Poisson",
    "text": "68.1 Introduzione alla Regressione di Poisson\nUna variabile casuale di Poisson viene utilizzata per modellare conteggi. Poich√© una variabile casuale di Poisson √® un conteggio, il suo valore minimo √® zero e, in teoria, il massimo √® illimitato. L‚Äôobiettivo √® modellare il parametro principale, Œª, il numero medio di occorrenze per unit√† di tempo o spazio, come funzione di una o pi√π covariate.\nIl modello di regressione di Poisson si basa sulla distribuzione di Poisson, una distribuzione probabilistica che descrive eventi con una probabilit√† costante di occorrenza in un intervallo di tempo o spazio definito. La funzione di probabilit√† della distribuzione di Poisson √® definita come:\n\\[ Pr(Y = y) = \\frac{\\mu^y e^{-\\mu}}{y!}, \\]\ndove \\(\\mu\\) rappresenta il numero atteso di eventi nell‚Äôintervallo considerato e \\(y\\) i possibili conteggi di eventi, assumendo valori interi non negativi (0, 1, 2, ‚Ä¶). √à importante notare che in questa distribuzione, il valore atteso \\(\\mu\\) coincide anche con la varianza.\nNel modello di regressione di Poisson, si cerca di collegare il valore atteso di un conteggio, \\(\\mu_i\\), a un insieme di variabili esplicative (come et√†, sesso, sintomi di depressione, ecc.) tramite una relazione funzionale. A differenza dei modelli lineari tradizionali, che possono produrre stime di conteggi negative e quindi non sensate, la regressione di Poisson utilizza una funzione di legame esponenziale per garantire che le stime dei conteggi siano sempre non negative. La relazione √® espressa come segue:\n\\[ \\mu_i = e^{\\beta_0 + \\beta_1 x_i}, \\]\ndove \\(\\beta_0\\) e \\(\\beta_1\\) sono i parametri del modello che devono essere stimati. Questi parametri quantificano l‚Äôeffetto delle variabili esplicative sui conteggi previsti. L‚Äôutilizzo della funzione esponenziale come legame assicura che il valore atteso \\(\\mu_i\\) sia sempre positivo.\nPer costruire il modello di regressione di Poisson:\n\nSi assume che il conteggio degli eventi per un dato livello della variabile esplicativa segua una distribuzione di Poisson, con un parametro di tasso (\\(\\mu_i\\)) specifico per ciascuna osservazione.\nSi definisce un predittore lineare, \\(\\eta_i\\), come una combinazione lineare dei coefficienti del modello (\\(\\beta\\)) e delle variabili esplicative (\\(x_i\\)).\nSi applica la funzione di legame esponenziale per stabilire che il tasso medio di eventi, \\(\\mu_i\\), sia determinato dal predittore lineare, cos√¨ che \\(\\mu_i = e^{\\eta_i} = e^{\\alpha + \\beta x_i}\\).\n\nQuesti passaggi consentono di costruire un modello che non solo predice accuratamente i conteggi, ma offre anche insight significativi sull‚Äôeffetto delle variabili esplicative studiate.\nConsideriamo il seguente esempio. Supponiamo di voler studiare il numero medio di episodi di comportamento aggressivo tra adolescenti in una scuola. In questo caso, il parametro \\(\\lambda_i\\) rappresenta il numero medio di episodi di comportamento aggressivo per lo studente \\(i\\), e ci aspettiamo di mostrare che la variabilit√† tra gli studenti di \\(\\lambda_i\\) pu√≤ essere spiegata da variabili come il livello di stress, il supporto familiare, o la presenza di sintomi depressivi. Utilizzando la regressione di Poisson, possiamo modellare il numero medio di episodi di comportamento aggressivo come:\n\\[ \\lambda_i = e^{\\beta_0 + \\beta_1 \\text{Stress}_i + \\beta_2 \\text{SupportoFamiliare}_i + \\beta_3 \\text{Depressione}_i}, \\]\ndove \\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\) e \\(\\beta_3\\) sono i parametri del modello che quantificano l‚Äôeffetto delle rispettive variabili esplicative sui conteggi di comportamenti aggressivi previsti.\n\n68.1.1 Assunzioni della Regressione di Poisson\nAnalogamente alla regressione lineare, l‚Äôuso della regressione di Poisson per fare inferenze richiede delle assunzioni sul modello:\n\nRisposta di Poisson: La variabile di risposta √® un conteggio per unit√† di tempo o spazio, descritta da una distribuzione di Poisson.\nIndipendenza: Le osservazioni devono essere indipendenti l‚Äôuna dall‚Äôaltra.\nMedia = Varianza: Per definizione, la media di una variabile casuale di Poisson deve essere uguale alla sua varianza.\nLinearit√†: Il logaritmo del tasso medio, log(Œª), deve essere una funzione lineare di \\(x\\).\n\n\n\n68.1.2 Un Esempio con Stan\nPer fare un esempio, consideriamo nuovamente i dati corrispondenti alle sparatorie mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1¬∞ gennaio 2015.\nImportiamo i dati.\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n\n\n\n\n\n\n\nid\ndate\nthreat_type\nflee_status\narmed_with\ncity\ncounty\nstate\nlatitude\nlongitude\nlocation_precision\nname\nage\ngender\nrace\nrace_source\nwas_mental_illness_related\nbody_camera\nagency_ids\n\n\n\n\n0\n3\n2015-01-02\npoint\nnot\ngun\nShelton\nMason\nWA\n47.246826\n-123.121592\nnot_available\nTim Elliot\n53.0\nmale\nA\nnot_available\nTrue\nFalse\n73\n\n\n1\n4\n2015-01-02\npoint\nnot\ngun\nAloha\nWashington\nOR\n45.487421\n-122.891696\nnot_available\nLewis Lee Lembke\n47.0\nmale\nW\nnot_available\nFalse\nFalse\n70\n\n\n2\n5\n2015-01-03\nmove\nnot\nunarmed\nWichita\nSedgwick\nKS\n37.694766\n-97.280554\nnot_available\nJohn Paul Quintero\n23.0\nmale\nH\nnot_available\nFalse\nFalse\n238\n\n\n3\n8\n2015-01-04\npoint\nnot\nreplica\nSan Francisco\nSan Francisco\nCA\n37.762910\n-122.422001\nnot_available\nMatthew Hoffman\n32.0\nmale\nW\nnot_available\nTrue\nFalse\n196\n\n\n4\n9\n2015-01-04\npoint\nnot\nother\nEvans\nWeld\nCO\n40.383937\n-104.692261\nnot_available\nMichael Rodriguez\n39.0\nmale\nH\nnot_available\nFalse\nFalse\n473\n\n\n\n\n\n\n\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1161\n2022    1095\n2021    1050\n2020    1020\n2019     996\n2015     995\n2018     992\n2017     984\n2016     959\nName: count, dtype: int64\n\n\n\nyears = year_counts.index.to_numpy()\nyear = years - 2019\nyear\n\narray([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)\n\n\n\ncounts = year_counts.values\ncounts\n\narray([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959])\n\n\nCreiamo un dizionario con i dati nel formato richiesto per CmdStan.\n\nstan_data = {\n    \"N\" : len(year),\n    \"y\" : counts,\n    \"x\" : year \n}\nstan_data\n\n{'N': 9,\n 'y': array([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959]),\n 'x': array([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)}\n\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;  // Numero di osservazioni\n  array[N] int&lt;lower=0&gt; y;  // Dati di conteggio (frequenze)\n  vector[N] x;  // Variabile predittore (anni, gi√† standardizzata)\n}\n\nparameters {\n  real alpha;  // Intercetta\n  real beta;  // Pendenza\n}\n\nmodel {\n  // Priors debolmente informativi\n  alpha ~ normal(0, 10);\n  beta ~ normal(0, 10);\n\n  // Modello di regressione di Poisson\n  y ~ poisson_log(alpha + beta * x);\n}\n\ngenerated quantities {\n  array[N] int&lt;lower=0&gt; y_pred = poisson_log_rng(alpha + beta * x);\n}\n\n\n\nQuesto modello Stan specifica una regressione di Poisson per dati di conteggio, dove l‚Äôobiettivo √® modellare il numero di eventi (espressi dalla variabile y) in funzione di una variabile predittiva x (in questo caso, anni standardizzati). Il modello √® strutturato in quattro blocchi principali: data, parameters, model, e generated quantities. Ecco una panoramica dettagliata di ciascuna sezione e il suo ruolo nel contesto del modello:\n\n\n68.1.3 Blocco data\n\nN: Un intero che specifica il numero totale di osservazioni nel dataset. Serve a definire le dimensioni degli array e dei vettori utilizzati nel modello.\ny: Un array di interi che rappresenta i dati di conteggio osservati. Ogni elemento in y corrisponde al numero di eventi registrati in ciascuna delle N unit√† di osservazione.\nx: Un vettore di lunghezza N che contiene i valori della variabile predittiva (ad esempio, anni).\n\n\n\n68.1.4 Blocco parameters\n\nalpha: Un parametro reale che rappresenta l‚Äôintercetta del modello. In un contesto di regressione di Poisson, alpha corrisponde al logaritmo del tasso atteso di eventi quando la variabile predittiva x √® zero.\nbeta: Un parametro reale che rappresenta la pendenza o il coefficiente della variabile predittiva x. Questo parametro indica come il logaritmo del tasso atteso di eventi cambia in risposta a variazioni di una unit√† in x.\n\n\n\n68.1.5 Blocco model\nI priors per alpha e beta sono definiti come distribuzioni normali con media 0 e deviazione standard 10, rappresentando priors debolmente informativi che permettono ai dati di guidare principalmente l‚Äôinferenza sui parametri.\nNella tradizionale regressione di Poisson, il parametro \\(\\mu_i\\) (il tasso medio di eventi per l‚Äôunit√† osservata) √® collegato alle variabili esplicative tramite una funzione esponenziale: \\(\\mu_i = e^{\\eta_i} = e^{\\beta_0 + \\beta_1 x_i}\\). Questa trasformazione assicura che il valore predetto di \\(\\mu_i\\) sia sempre positivo, indipendentemente dai valori assunti dalle variabili esplicative, una necessit√† quando si modellano conteggi che non possono essere negativi.\nLa funzione poisson_log, invece di lavorare direttamente con \\(\\mu_i\\) come nella forma esponenziale \\(e^{\\eta_i}\\), opera sul logaritmo di \\(\\mu_i\\). Questo significa che la funzione specifica il logaritmo del tasso medio di eventi come lineare rispetto ai predittori. In altre parole, anzich√© modellare \\(\\mu_i\\) direttamente e poi trasformarlo, si modella il logaritmo di \\(\\mu_i\\) (che √® \\(\\log(\\mu_i)\\)) come funzione lineare delle variabili esplicative: \\(\\log(\\mu_i) = \\eta_i = \\beta_0 + \\beta_1 x_i\\).\nQuesta specificazione ha diversi vantaggi:\n\nStabilit√† numerica: Lavorare con il logaritmo di \\(\\mu_i\\) pu√≤ ridurre i problemi di stabilit√† numerica che talvolta emergono quando si lavora con valori estremamente grandi o piccoli di \\(\\mu_i\\).\nInterpretazione diretta dei parametri: Poich√© si modella il logaritmo di \\(\\mu_i\\), i coefficienti (come \\(\\beta_1\\)) possono essere interpretati in termini di variazione percentuale. Un incremento di una unit√† in \\(x_i\\) √® associato a un moltiplicatore esponenziale di \\(e^{\\beta_1}\\) sul tasso medio di eventi.\n\nNel codice Stan, la linea y ~ poisson_log(alpha + beta * x); specifica quindi che i dati di conteggio y seguono una distribuzione di Poisson, con il logaritmo del parametro di tasso (\\(\\log(\\mu_i)\\)) modellato come una funzione lineare di x attraverso alpha + beta * x.\n\n\n68.1.6 Blocco generated quantities\n\ny_pred: Un array di interi che contiene valori predetti generati dalla distribuzione di Poisson. Per ogni osservazione, poisson_log_rng genera un valore di conteggio casuale basato sul tasso atteso calcolato come alpha + beta * x. Questi valori predetti possono essere utilizzati per verifiche predittive posteriori o per ottenere una distribuzione predittiva degli eventi.\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo un sommario della distribuzione a posteriori per i parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n6.934\n0.011\n6.911\n6.954\n0.0\n0.0\n2461.0\n2201.0\n1.0\n\n\nbeta\n0.020\n0.004\n0.012\n0.028\n0.0\n0.0\n4171.0\n3115.0\n1.0\n\n\n\n\n\n\n\n\nL‚Äôess_bulk (Effective Sample Size per il bulk dell‚Äôestimatore) e ess_tail (Effective Sample Size per la coda dell‚Äôestimatore) sono relativamente alti per entrambi i parametri, indicando che il campionamento ha fornito una buona approssimazione della distribuzione a posteriori. Inoltre, il valore di r_hat vicino a 1.0 per entrambi i parametri suggerisce che il campionamento ha raggiunto la convergenza, indicando che i risultati sono affidabili.\n\n\n68.1.7 Interpretazione del Parametro alpha\nIl parametro alpha √® una stima del logaritmo del tasso atteso di eventi (frequenze) quando il valore della variabile esplicativa x √® zero, ossia quando si trova nella sua media, che in questo contesto √® stata standardizzata e centrata sull‚Äôanno 2019. Il valore medio di alpha √® 6.934, indicando che il logaritmo naturale del tasso atteso di eventi quando x = 0 √® circa 6.934.\nL‚Äôintervallo di alta densit√† (HDI) del 95% per alpha va da 6.912 a 6.954, fornendo un intervallo di stime plausibili per il valore di alpha con un alto grado di certezza statistica.\nPer interpretare alpha in termini di tasso atteso di eventi, usiamo exp(alpha). Questo trasforma il logaritmo del tasso di eventi nel tasso effettivo. Ad esempio, exp(6.934) d√† il tasso atteso di eventi per l‚Äôanno di riferimento 2019.\n\nnp.exp(6.934)\n\n1026.5921464104808\n\n\n\n\n68.1.8 Interpretazione del Parametro beta\nIl parametro beta rappresenta la variazione logaritmica attesa nelle frequenze per ogni incremento unitario in x (l‚Äôanno, in questo caso). Un valore medio di beta pari a 0.020, con un HDI del 95% che va da 0.012 a 0.028, suggerisce una tendenza positiva: all‚Äôaumentare degli anni, ci si aspetta un incremento nelle frequenze degli eventi.\nUtilizzando il link logaritmico del modello, l‚Äôeffetto di un incremento di un anno su x si traduce in una moltiplicazione del tasso di frequenza per exp(beta). Quindi, un aumento di un anno implica che il tasso di frequenza sar√† moltiplicato per exp(0.020), che √® approssimativamente 1.02, indicando un aumento previsto del 2% nelle frequenze per ogni anno successivo.\n\nnp.exp([0.020, 0.012, 0.028])\n\narray([1.02020134, 1.01207229, 1.02839568])\n\n\n\n\n68.1.9 Calcolo dell‚ÄôAumento Effettivo in Frequenza\nPer calcolare l‚Äôaumento effettivo in frequenza per ogni anno, utilizziamo la seguente formula:\n\\[ \\text{Aumento atteso} = \\exp(\\alpha) \\times (\\exp(\\beta) - 1) \\]\n\nCalcolo del Fattore di Moltiplicazione: exp(beta) √® il fattore di moltiplicazione che descrive come cambia il tasso di frequenza con un incremento di un anno. Con beta = 0.020, exp(beta) √® circa 1.0202.\nDeterminazione dell‚ÄôAumento Attuale in Frequenza: exp(alpha) fornisce il tasso di base delle frequenze quando x = 0. Moltiplicando questo tasso di base per (\\exp(\\beta) - 1), otteniamo l‚Äôaumento effettivo in frequenza per ogni anno aggiuntivo. Sottraendo 1 a exp(beta), otteniamo l‚Äôincremento percentuale dovuto solamente all‚Äôaumento di un anno.\n\nQuesta metodologia fornisce un modo intuitivo e statistico per quantificare come le variabili nel tempo influenzano la frequenza degli eventi, permettendo di fare previsioni basate su modelli storici e tendenze osservate.\n\n# Parametri del modello\nalpha_mean = 6.934\nbeta_mean = 0.020\n\n# Calcolo del tasso di frequenza base per l'anno centrato (exp(alpha))\ntasso_base = np.exp(alpha_mean)\n\n# Calcolo del fattore di moltiplicazione per l'aumento (exp(beta))\nfattore_moltiplicazione = np.exp(beta_mean)\n\n# Aumento atteso in frequenza per un anno\naumento_atteso = tasso_base * (fattore_moltiplicazione - 1)\naumento_atteso\n\n20.738537018435174\n\n\nBasandosi sul modello di regressione di Poisson, si stima un incremento medio di circa 20.74 nel numero di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno aggiuntivo. In altre parole, il modello prevede che, anno dopo anno, il numero di tali incidenti potrebbe crescere di circa 21 casi. Questa previsione riflette una dinamica esponenziale tra il passare degli anni e l‚Äôaumento della frequenza assoluta di sparatorie fatali, come evidenziato dai dati analizzati.\n\n\n68.1.10 Posterior-Predictive Check\nEsaminiamo il posterior-predictive check per il modello esaminato:\n\ny_observed = stan_data[\"y\"]\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_pred',\n    observed_data={'y': y_observed}\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_pred'}, kind='cumulative')",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/04_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "68¬† Regressione di Poisson con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\nscipy     : 1.14.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_stan_rct.html",
    "href": "chapters/glm/05_stan_rct.html",
    "title": "69¬† Incorporare dati storici di controllo in una RCT",
    "section": "",
    "text": "Introduzione\nQuesto capitolo fornisce una trattazione semplificata di un importante problema affrontato da Frank Harrell in un suo intervento intitolato Incorporating Historical Control Data Into an RCT.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_stan_rct.html#studi-controllati-randomizzati",
    "href": "chapters/glm/05_stan_rct.html#studi-controllati-randomizzati",
    "title": "69¬† Incorporare dati storici di controllo in una RCT",
    "section": "69.1 Studi Controllati Randomizzati",
    "text": "69.1 Studi Controllati Randomizzati\nNella ricerca psicologica, ci troviamo di fronte a notevoli ostacoli nel reclutare un numero sufficiente di partecipanti per condurre studi controllati randomizzati (RCT), un problema che si acuisce quando si prevede l‚Äôassegnazione dei partecipanti a gruppi di controllo che ricevono trattamenti standard. Un‚Äôaltra difficolt√† sorge quando i potenziali partecipanti sono riluttanti a iscriversi agli studi a causa della possibilit√† di non ricevere il trattamento sperimentale. In questo contesto, l‚Äôutilizzo di Dati Storici (HD) per informare su possibili esiti nei gruppi di controllo assume un‚Äôimportanza vitale. Tuttavia, l‚Äôintegrazione di tali dati richiede strategie sofisticate per adeguare i bias e le disparit√† tra i diversi disegni di studio.\nStuart Pocock ha proposto un metodo nel quadro frequentista che valorizza la dimensione campionaria degli HD, pur ammettendo che questi possano riflettere realt√† diverse rispetto agli esiti attesi nei gruppi di controllo degli RCT prospettici. La discrepanza include sia la vera performance sconosciuta del gruppo di controllo sia il bias inerente agli HD.\nBj√∂rn Holzhauer ha ampliato questa visione attraverso lo sviluppo di approcci Bayesiani per l‚Äôappropriazione di dati, in particolare riguardo ai tassi di pericolo esponenziali, mediante l‚Äôutilizzo di simulazioni MCMC Bayesiane. Queste metodologie consentono l‚Äôelaborazione parallela di pi√π modelli e l‚Äôinclusione diretta dei dati grezzi degli HD nell‚Äôanalisi di nuovi dati sperimentali, affrontando direttamente le possibili discrepanze negli oggetti di stima tra HD e RCT.\nUna caratteristica fondamentale di queste tecniche √® l‚Äôaggregazione di dati grezzi da diverse fonti, facilitando un‚Äôanalisi pi√π precisa che considera l‚Äôintero spettro delle incertezze. Questo si contrappone agli approcci tradizionali, che spesso si basano su statistiche riassuntive e tendono a trascurare importanti variabilit√†, conferendo una fiducia ingiustificata nei dati storici. √à, inoltre, cruciale l‚Äôajustamento per covariate al fine di gestire l‚Äôeterogeneit√† degli esiti tra i trattamenti, aumentando cos√¨ l‚Äôaffidabilit√† e l‚Äôaccuratezza delle stime dell‚Äôeffetto del trattamento.\nProcedendo senza dati diretti per valutare il bias, ci affidiamo a una distribuzione a priori gaussiana con media zero e deviazione standard sigma per descriverlo. Un valore di sigma nullo implica l‚Äôassenza di bias, permettendo di integrare gli HD nell‚Äôanalisi allo stesso livello dei dati di controllo dello studio. Al contrario, un sigma infinito indica una completa ignoranza riguardo al bias, rendendo gli HD non informativi e pertanto trascurabili.\nIl focus principale, l‚Äôeffetto del trattamento delta, viene esaminato pi√π efficacemente attraverso l‚Äôanalisi di sigma. Un sigma inferiore a 2 rende lo studio informativo su delta, mentre un sigma superiore a 2 pu√≤ portare a conclusioni errate, specialmente quando gli HD hanno una media artificiosamente gonfiata. Questo sottolinea l‚Äôimportanza di una scelta accurata dei parametri analitici, in particolare nell‚Äôintegrazione dei dati storici con quelli dei nuovi studi clinici, per fornire una rappresentazione equilibrata e critica dell‚Äôintegrazione di tali dati nell‚Äôanalisi statistica contemporanea.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_stan_rct.html#creazione-di-un-braccio-di-controllo-con-hd",
    "href": "chapters/glm/05_stan_rct.html#creazione-di-un-braccio-di-controllo-con-hd",
    "title": "69¬† Incorporare dati storici di controllo in una RCT",
    "section": "69.2 Creazione di un Braccio di Controllo con HD",
    "text": "69.2 Creazione di un Braccio di Controllo con HD\nNel contesto di uno studio RCT condotto con un unico braccio sperimentale, dove i dati di controllo derivano unicamente da controlli storici non contemporanei, la sfida si amplifica. In queste circostanze, il bias intrinseco negli HD non pu√≤ essere quantificato direttamente. Invece, ci si affida completamente alla distribuzione di incertezza prescelta per il bias. Questo approccio offre un‚Äôanalisi che, pur essendo paragonabile a una verifica di sensibilit√†, si avvale del rigoroso quadro analitico Bayesiano. Quest‚Äôultimo, per sua natura flessibile, permette un‚Äôestensione naturale a include la meta-analisi di dati individuali dei pazienti e l‚Äôadeguamento per covariate, arricchendo cos√¨ la robustezza e l‚Äôaffidabilit√† delle inferenze tratte dallo studio.\nImportiamo e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"rct.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:00:16 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/rct.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/rct\n12:00:26 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/rct\n\n\ndata {\n  int&lt;lower=0&gt; Nb;  // # obs in RCT treatment B\n  int&lt;lower=0&gt; Nh;  // # obs in historical control data\n  vector[Nb] yb;    // vector of tx=B data\n  vector[Nh] yh;    // vector of historical data\n  real&lt;lower=0&gt; sigma;  // standard deviation of prior for bias\n}\nparameters {\n  real mua;  // unknown mean for tx=A\n  real mub;  // unknown mean for tx=B\n  real bias; // unknown bias\n}\ntransformed parameters {\n  real delta;\n  delta = mua - mub;\n}\nmodel {\n  yb   ~ normal(mub, 1.0);\n  yh   ~ normal(mua + bias, 1.0);\n  bias ~ normal(0., sigma);\n}\n\n\n\n\nCreiamo il dizionario che contiene i dati richiesti dal modello.\n\nNa = 20\nNb = 40\nNh = 500\nya = rng.normal(loc=10, scale=1, size=Na)\nyb = rng.normal(loc=5, scale=1, size=Nb)\nyh = rng.normal(loc=20, scale=1, size=Nh)\n\nstan_data = {\"Nb\": Nb, \"Nh\": Nh, \"yb\": yb, \"yh\": yh, \"sigma\": 1.0}\n\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo i risultati ottenuti.\n\nprint(fit.summary())\n\n             Mean      MCSE    StdDev         5%         50%        95%  \\\nlp__  -252.847000  0.035606  1.225860 -255.33900 -252.524000 -251.48100   \nmua     20.034200  0.028866  1.027280   18.35000   20.040900   21.69820   \nmub      5.216960  0.004029  0.160862    4.94483    5.216310    5.47481   \nbias    -0.044748  0.028869  1.026390   -1.71126   -0.042136    1.62836   \ndelta   14.817300  0.029354  1.038220   13.10640   14.832900   16.49740   \n\n         N_Eff  N_Eff/s    R_hat  \nlp__   1185.29  1727.83  1.00003  \nmua    1266.49  1846.20  1.00055  \nmub    1594.19  2323.89  1.00245  \nbias   1264.05  1842.64  1.00058  \ndelta  1250.95  1823.54  1.00088  \n\n\n\naz.summary(fit, var_names=([\"bias\", \"delta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbias\n-0.045\n1.026\n-1.990\n1.917\n0.029\n0.021\n1265.0\n1491.0\n1.0\n\n\ndelta\n14.817\n1.038\n12.911\n16.837\n0.029\n0.021\n1251.0\n1285.0\n1.0\n\n\n\n\n\n\n\n\n\n_ = az.plot_trace(fit, var_names=([\"bias\", \"delta\"]))\n\n\n\n\n\n\n\n\nSi noti l‚Äôutilit√† dei dati storici nella riduzione dell‚Äôincertezza associata a delta. Quando diminuisce sigma, diminuisce anche l‚Äôincertezza associata all‚Äôeffetto del trattamento.\n\nstan_data = {\n    \"Nb\" : Nb, \n    \"Nh\" : Nh, \n    \"yb\" : yb, \n    \"yh\" : yh,\n    \"sigma\" : 0.25\n}\n\n\nfit1 = model.sample(data=stan_data)\n\n\naz.summary(fit1, var_names=([\"bias\", \"delta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbias\n-0.006\n0.250\n-0.505\n0.468\n0.007\n0.005\n1337.0\n1404.0\n1.0\n\n\ndelta\n14.782\n0.304\n14.161\n15.335\n0.008\n0.006\n1483.0\n1538.0\n1.0",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_stan_rct.html#conclusioni",
    "href": "chapters/glm/05_stan_rct.html#conclusioni",
    "title": "69¬† Incorporare dati storici di controllo in una RCT",
    "section": "69.3 Conclusioni",
    "text": "69.3 Conclusioni\nPer stabilire la distribuzione a priori del bias, √® fondamentale considerare le informazioni disponibili riguardanti l‚Äôevoluzione delle pratiche terapeutiche, il bias di selezione dei pazienti e l‚Äôandamento della patologia di interesse. L‚Äôapproccio Bayesiano ci libera dalla necessit√† di conoscere con precisione l‚Äôentit√† del bias, indirizzandoci invece a definire la sua distribuzione di incertezza. In caso questa distribuzione sia modellata come gaussiana, ci si avvale dell‚Äôipotesi di simmetria per focalizzarsi sulla deviazione standard, sigma. Un metodo efficace per determinare sigma consiste nel fissarlo in modo che, per esempio, la probabilit√† che il bias si collochi entro un intervallo di \\([-c, c]\\) sia del 95%, per poi calcolare retrospettivamente il valore di sigma necessario a soddisfare questa condizione. Questo approccio garantisce una gestione pi√π mirata e scientificamente fondata dell‚Äôincertezza legata al bias, fondamentale per l‚Äôintegrazione ottimale dei dati storici nelle analisi statistiche avanzate.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_stan_rct.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/05_stan_rct.html#informazioni-sullambiente-di-sviluppo",
    "title": "69¬† Incorporare dati storici di controllo in una RCT",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nscipy     : 1.14.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_mediation.html",
    "href": "chapters/glm/06_stan_mediation.html",
    "title": "70¬† Modello di mediazione con Stan",
    "section": "",
    "text": "70.1 Preparazione del Notebook\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\nimport networkx as nx\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"stan_mediation\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"\nIl presente capitolo fornisce un riassunto della trattazione dei modelli misti fornita da {cite:t}sorensen2015bayesian, a cui si rimanda per gli approfondimenti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_mediation.html#domanda-della-ricerca",
    "href": "chapters/glm/06_stan_mediation.html#domanda-della-ricerca",
    "title": "70¬† Modello di mediazione con Stan",
    "section": "70.2 Domanda della Ricerca",
    "text": "70.2 Domanda della Ricerca\nLa questione scientifica riguarda la comprensione delle frasi nel caso di proposizioni relative di soggetto e di oggetto. Una proposizione relativa di soggetto √® una frase in cui un sostantivo (ad esempio, ‚Äúsenatore‚Äù) viene modificato da una proposizione relativa (ad esempio, ‚Äúche ha interrogato il giornalista‚Äù), e il sostantivo modificato √® il soggetto grammaticale della proposizione relativa. In una proposizione relativa di oggetto, il sostantivo modificato dalla proposizione relativa √® l‚Äôoggetto grammaticale della proposizione (per esempio, ‚ÄúIl senatore che il giornalista ha interrogato si √® dimesso‚Äù). In entrambi i casi, il sostantivo modificato (‚Äúsenatore‚Äù) √® chiamato il sostantivo principale.\nUn risultato comune per l‚Äôinglese √® che le proposizioni relative di soggetto sono pi√π facili da elaborare rispetto a quelle di oggetto. Le lingue naturali in generale includono proposizioni relative, e fino a poco tempo fa il vantaggio delle proposizioni di soggetto √® stato considerato valido a livello cross-linguistico. Tuttavia, le proposizioni relative in cinese rappresentano un interessante controesempio a questa generalizzazione; ricerche recenti condotte da Hsiao e Gibson (2003) hanno suggerito che in cinese, le proposizioni relative di oggetto sono pi√π facili da elaborare rispetto a quelle di soggetto in un punto specifico della frase (il sostantivo principale della proposizione relativa). Viene presentata un‚Äôanalisi di un insieme di dati successivamente pubblicata {cite:p}gibson2013processing che valuta questa affermazione.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_mediation.html#i-dati",
    "href": "chapters/glm/06_stan_mediation.html#i-dati",
    "title": "70¬† Modello di mediazione con Stan",
    "section": "70.3 I Dati",
    "text": "70.3 I Dati\nLa variabile dipendente dell‚Äôesperimento di {cite:t}gibson2013processing era il tempo di lettura (rt) in millisecondi del sostantivo principale della proposizione relativa. Questo √® stato registrato in due condizioni (proposizione relativa di soggetto e proposizione relativa di oggetto), con 37 soggetti e 15 item, presentati in un disegno standard a quadrato latino. Originariamente c‚Äôerano 16 item, ma uno √® stato rimosso, risultando in 37 √ó 15 = 555 punti dati. Tuttavia, otto punti dati da un soggetto (id 27) erano mancanti. Di conseguenza, abbiamo un totale di 555 - 8 = 547 punti dati. La condizione (object relative / subject relative) √® codificata dalla variabile so.\n\nhowell_data = pd.read_csv(\"../data/Howell1.csv\", sep=';')\nhowell_data.head()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\n\nhowell_data.tail()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n539\n145.415\n31.127751\n17.0\n1\n\n\n540\n162.560\n52.163080\n31.0\n1\n\n\n541\n156.210\n54.062497\n21.0\n0\n\n\n542\n71.120\n8.051258\n0.0\n1\n\n\n543\n158.750\n52.531624\n68.0\n1\n\n\n\n\n\n\n\n\n\nhowell_data.shape\n\n(544, 4)\n\n\n\n_ = sns.kdeplot(data=howell_data, x='weight', hue='male', fill=True, common_norm=False, alpha=0.5)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_mediation.html#pensare-scientificamente-prima-di-tutto",
    "href": "chapters/glm/06_stan_mediation.html#pensare-scientificamente-prima-di-tutto",
    "title": "70¬† Modello di mediazione con Stan",
    "section": "70.4 Pensare scientificamente prima di tutto",
    "text": "70.4 Pensare scientificamente prima di tutto\nDesideriamo prevedere il peso a partire da due predittori: genere e altezza. Pertanto, potremmo prevedere il peso utilizzando queste due variabili mediante un modello di regressione. {cite:t}McElreath_rethinking ci ricorda che il modello di regressione √® un ‚ÄúGolem‚Äù: √® potente e stupido. Se il nostro unico obiettivo √® ‚Äúprevedere‚Äù il valore del peso senza attribuire interpretazioni ai coefficienti del modello, questo potrebbe essere adeguato se funziona effettivamente. Tuttavia, il modello di regressione non considera la struttura causale sottostante il meccanismo di generazione dei dati. Se desideriamo comprendere qualcosa sulla struttura causale che lega questi dati, dobbiamo prima pensare in termini scientifici.\n\nCome sono causalmente correlati altezza, peso e sesso?\nCome sono statisticamente correlati altezza, peso e sesso?\n\n\n70.4.1 Le cause non sono nei dati\nL‚Äôaltezza dovrebbe influenzare il peso, e non il contrario: - ‚úÖ \\(H \\rightarrow W\\) - ‚ùå \\(W \\rightarrow H\\)\nIl sesso dovrebbe influenzare l‚Äôaltezza, e non il contrario: - ‚ùå \\(S \\rightarrow H\\) - ‚úÖ \\(H \\rightarrow S\\)\nQuesto ci porta a un modello di mediazione. In tale modello, il sesso influisce sul peso (\\(S \\rightarrow W\\)) cos√¨ come sull‚Äôaltezza (\\(S \\rightarrow H\\)). Inoltre, l‚Äôaltezza influisce sul peso (\\(H \\rightarrow W\\)). In questa struttura causale, possiamo distinguere tra effetti diretti, indiretti e l‚Äôeffetto totale.\nL‚Äôeffetto diretto del genere sul peso √® dato dal coefficiente del percorso \\(S \\rightarrow W\\). Questa √® la nostra principale questione di interesse. Tuttavia, c‚Äô√® un altro effetto diretto che influisce sul peso: \\(H \\rightarrow W\\). Se confrontiamo questi due effetti diretti, quale √® il pi√π significativo? In aggiunta, abbiamo l‚Äôeffetto diretto \\(S \\rightarrow H\\). Possiamo anche definire l‚Äôeffetto indiretto del sesso sul peso come \\(S \\rightarrow H \\rightarrow W\\). Infine, l‚Äôeffetto totale √® dato dalla somma degli effetti diretti e indiretti.\nTutto ci√≤ viene ignorato in un modello di regressione semplice. Solo quando disponiamo di un modello plausibile che descrive le relazioni causali tra le variabili possiamo costruire un modello statistico in grado di rappresentare adeguatamente la struttura causale ipotizzata, permettendoci di rispondere alle domande di interesse. In questo caso, quale √® l‚Äôeffetto pi√π rilevante sul peso? Altezza o genere? Per rispondere a questa domanda, possiamo implementare il modello di mediazione in Stan nel seguente modo.\n\n# Creazione del Directed Acyclic Graph (DAG) per il modello di mediazione\nG = nx.DiGraph()\n\n# Aggiunta dei nodi\nG.add_nodes_from([\"S\", \"W\", \"H\"])\n\n# Aggiunta degli archi che rappresentano le relazioni causali\nG.add_edges_from([(\"S\", \"W\"), (\"S\", \"H\"), (\"H\", \"W\")])\n\n# Posizionamento dei nodi usando il layout 'planar'\npos = nx.planar_layout(G)\n\n# Impostazioni per i nodi pi√π grandi e le dimensioni globali pi√π piccole\noptions = {\n    \"font_size\": 12,\n    \"node_size\": 2000,\n    \"node_color\": \"skyblue\",\n    \"edgecolors\": \"black\",\n    \"linewidths\": 2,\n    \"width\": 2,\n}\n\nplt.figure(figsize=(6, 4))  # Dimensioni globali pi√π piccole\nnx.draw(G, pos, **options, with_labels=True, arrowsize=20)\n\nplt.title(\"Mediation Model DAG\")\nplt.show()\n\n/opt/anaconda3/envs/stan_env/lib/python3.12/site-packages/IPython/core/pylabtools.py:152: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\nRileggiamo il modello Stan. √à da notare che i dati sono stati standardizzati per agevolare il campionamento e permettere un confronto diretto tra i diversi coefficienti.\n\nstan_file = os.path.join('stan', 'mediation_model.stan')\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of observations\n  array[N] int S; // Sex indicator (0 for F, 1 for M), Predictor\n  array[N] real H; // Height, Mediator\n  array[N] real W; // Weight, Outcome\n}\n\nparameters {\n  real alphaH; // Intercept for height model\n  real betaH; // Effect of sex on height\n  real alphaW; // Intercept for weight model\n  real betaW_H; // Effect of height on weight\n  real betaW_S; // Direct effect of sex on weight\n  real&lt;lower=0&gt; sigmaH; // Std dev for height model\n  real&lt;lower=0&gt; sigmaW; // Std dev for weight model\n}\n\nmodel {\n  // Priors\n  alphaH ~ normal(0, 1); // Less restrictive priors for intercepts and effects\n  betaH ~ normal(0, 1);\n  alphaW ~ normal(0, 1);\n  betaW_H ~ normal(0, 1);\n  betaW_S ~ normal(0, 1);\n  sigmaH ~ cauchy(0, 1); // Using a Cauchy distribution for sigma, more appropriate for std devs\n  sigmaW ~ cauchy(0, 1);\n  \n  // Mediation Model\n  for (i in 1:N) {\n    // A path: Effect of sex on height\n    H[i] ~ normal(alphaH + betaH * S[i], sigmaH);\n    \n    // B and C' path: Effect of height (and sex) on weight\n    W[i] ~ normal(alphaW + betaW_H * H[i] + betaW_S * S[i], sigmaW);\n  }\n}\n\n\n\nCreiamo un dizionario che include i dati nel formato atteso dal precedente codice Stan.\n\nhowell_data['H_standardized'] = (howell_data['height'] - howell_data['height'].mean()) / howell_data['height'].std()\nhowell_data['W_standardized'] = (howell_data['weight'] - howell_data['weight'].mean()) / howell_data['weight'].std()\n\nstan_data = {\n    \"N\": howell_data.shape[0],\n    \"S\": howell_data[\"male\"].to_numpy(),  # Ensuring this is an array if not already\n    \"H\": howell_data[\"H_standardized\"].to_numpy(),  # Use the standardized height\n    \"W\": howell_data[\"W_standardized\"].to_numpy()   # Use the standardized weight\n}\n\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model)\n\nCmdStanModel: name=mediation_model\n     stan_file=/Users/corradocaudek/_repositories/ds4p/chapter_5/stan/mediation_model.stan\n     exe_file=/Users/corradocaudek/_repositories/ds4p/chapter_5/stan/mediation_model\n     compiler_options=stanc_options={}, cpp_options={}\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data, adapt_delta = 0.95)\n\n\nprint(fit.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nEsaminiamo le tracce.\n\n_ = az.plot_trace(fit, var_names=([\"betaH\", \"betaW_H\", \"betaW_S\"]))\n\n\n\n\n\n\n\n\nEsaminiamo le medie a posteriori e gli intervalli di credibilit√† dei parametri.\n\naz.summary(fit, var_names=([\"betaH\", \"betaW_H\", \"betaW_S\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbetaH\n0.28\n0.09\n0.11\n0.44\n0.0\n0.0\n3139.90\n2705.84\n1.0\n\n\nbetaW_H\n0.94\n0.01\n0.91\n0.97\n0.0\n0.0\n4113.00\n2834.41\n1.0\n\n\nbetaW_S\n0.05\n0.03\n-0.01\n0.11\n0.0\n0.0\n2796.52\n2773.80\n1.0\n\n\n\n\n\n\n\n\nIl genere ha scarso o addirittura nullo impatto diretto sul peso. Piuttosto, √® principalmente l‚Äôaltezza ad avere un effetto causale sul peso.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_mediation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/06_stan_mediation.html#informazioni-sullambiente-di-sviluppo",
    "title": "70¬† Modello di mediazione con Stan",
    "section": "70.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "70.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Wed May 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.2\nIPython version      : 8.22.2\n\ncmdstanpy: 1.2.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.13.0\nnetworkx  : 3.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/introduction_entropy.html",
    "href": "chapters/entropy/introduction_entropy.html",
    "title": "71¬† Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esploreremo il tema cruciale della validazione di un modello statistico e del confronto tra modelli. Vedremo come sia necessario trovare un equilibrio tra due dimensioni: la capacit√† del modello di predire accuratamente i dati osservati nel campione e la sua capacit√† di generalizzarsi a campioni diversi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "72¬† Entropia",
    "section": "",
    "text": "Introduzione\nNel contesto della statistica bayesiana, √® cruciale confrontare diversi modelli predittivi per identificare quello che meglio si adatta ai dati disponibili. Una metrica essenziale in questo confronto √® la Expected Log Predictive Density (ELPD), che misura l‚Äôaccuratezza con cui un modello pu√≤ prevedere nuovi dati. Non essendo possibile calcolare direttamente l‚ÄôELPD, a causa della necessit√† di conoscere il meccanismo generatore dei dati \\(p_t(y)\\), ci affidiamo a una stima approssimativa fornita dalla distribuzione predittiva a posteriori del modello, \\(p(\\tilde{y} | y)\\).\nPer ottenere una stima pi√π accurata della capacit√† di generalizzazione di un modello su futuri set di dati, utilizziamo metodi di stima dell‚ÄôELPD basati sulla validazione incrociata. Questa tecnica consiste nell‚Äôaddestrare il modello su un sottoinsieme di dati e testarlo su un altro, isolando cos√¨ le prestazioni del modello dalle variazioni casuali presenti nei dati. Il risultato di questo processo √® l‚Äôindice di Leave-One-Out Cross-Validation (LOO-CV), fondamentale per comparare diversi modelli.\nLa differenza nei valori di Leave-One-Out Cross-Validation (LOO-CV) tra due modelli, accompagnata dal calcolo dell‚Äôerrore standard associato a questa differenza, ci consente di determinare se esiste una differenza robusta nelle prestazioni tra i due modelli. Se il rapporto tra questa differenza di LOO-CV e il relativo errore standard supera il valore di 2, possiamo concludere che i modelli mostrano differenze sostanziali. Questo indica che le variazioni osservate non sono casuali ma riflettono una superiorit√† effettiva di un modello rispetto all‚Äôaltro.\nIn questo capitolo, esploreremo il concetto di entropia, essenziale per quantificare l‚Äôincertezza nelle distribuzioni di probabilit√†. L‚Äôentropia di una variabile casuale rappresenta la media della sua imprevedibilit√†. Approfondiremo anche il modo in cui l‚Äôentropia pu√≤ essere impiegata per misurare la ‚Äúdistanza‚Äù tra un modello teorico e i dati osservati, introducendo il concetto di divergenza di Kullback-Leibler (\\(\\mathbb{KL}\\)). Questa metrica quantifica le discrepanze tra due distribuzioni probabilistiche, fornendo una misura di quanto efficacemente un modello rappresenti le osservazioni empiriche. Il capitolo successivo presenter√† un‚Äôanalisi della tecnica di Validazione Incrociata Leave-One-Out, impiegata per calcolare un‚Äôapprossimazione della divergenza \\(\\mathbb{KL}\\), nota come LOO-CV.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-generalizzabilit√†-dei-modelli-e-il-metodo-scientifico",
    "href": "chapters/entropy/01_entropy.html#la-generalizzabilit√†-dei-modelli-e-il-metodo-scientifico",
    "title": "72¬† Entropia",
    "section": "72.1 La Generalizzabilit√† dei Modelli e il Metodo Scientifico",
    "text": "72.1 La Generalizzabilit√† dei Modelli e il Metodo Scientifico\nLa generalizzabilit√† dei modelli √® un concetto chiave nella scienza, essendo uno dei fondamenti del metodo scientifico. Questo principio si riferisce alla capacit√† di un modello di applicarsi e produrre risultati validi oltre il contesto specifico o il set di dati in cui √® stato originariamente sviluppato o testato. Il valore scientifico di un modello √® quindi fortemente influenzato dalla sua capacit√† di generalizzarsi a nuovi dati.\nNella pratica, la generalizzabilit√† di un modello pu√≤ essere minacciata da due problemi principali: il sotto-adattamento e il sovra-adattamento. Il sotto-adattamento si verifica quando un modello √® troppo semplice per catturare adeguatamente la complessit√† dei dati, portando a prestazioni insoddisfacenti sia sui dati di addestramento che su nuovi insiemi di dati. Questo limita gravemente la sua utilit√† in applicazioni pratiche. Al contrario, il sovra-adattamento si manifesta quando un modello √® eccessivamente complesso, adattandosi troppo fedelmente al rumore o alle peculiarit√† specifiche del set di dati di addestramento a discapito della capacit√† di generalizzare a nuovi dati.\nL‚Äôapproccio bayesiano alla modellazione consente di gestire in modo efficace la necessit√† di un compromesso tra complessit√† del modello e adattamento ai dati. La selezione di modelli, come descritto da McElreath (2020), √® un processo che richiede di mediare tra la semplicit√† del modello e la sua capacit√† di rappresentare fedelmente la realt√† dei dati.\nUna pratica comune nella scelta tra modelli alternativi si basa sul principio del rasoio di Ockham, che predilige le spiegazioni pi√π semplici in presenza di multiple teorie equivalenti per un fenomeno. Tuttavia, questo principio da solo non √® sufficiente: √® essenziale che il modello scelto descriva accuratamente i dati.\nLa metodologia prevalente nella selezione dei modelli √® spesso centrata sull‚Äôuso dei valori-p, ma come evidenziato da McElreath (2020), questo approccio √® problematico e privo di una solida giustificazione teorica.\nUn metodo pi√π robusto e fondato scientificamente impiega invece la divergenza di Kullback-Leibler, una misura che valuta quanto un modello approssimi efficacemente la distribuzione reale dei dati, offrendo una stima quantitativa della sua aderenza al processo generativo sottostante. Questo capitolo pone le basi per comprendere il concetto di entropia, essenziale per affrontare nel prossimo capitolo la divergenza di Kullback-Leibler e le sue implicazioni nella selezione di modelli.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#cos√®-lentropia-dellinformazione",
    "href": "chapters/entropy/01_entropy.html#cos√®-lentropia-dellinformazione",
    "title": "72¬† Entropia",
    "section": "72.2 Cos‚Äô√® l‚ÄôEntropia dell‚ÄôInformazione?",
    "text": "72.2 Cos‚Äô√® l‚ÄôEntropia dell‚ÄôInformazione?\nL‚Äôentropia dell‚Äôinformazione, un concetto introdotto da Claude Shannon, rappresenta uno dei fondamenti della teoria dell‚Äôinformazione. Questa grandezza matematica quantifica l‚Äôincertezza o la sorpresa associata alla ricezione di un messaggio, misurando quanto sia sorprendente un evento in base alla sua probabilit√†. Gli eventi che si verificano con alta probabilit√† sono considerati meno sorprendenti perch√© prevedibili; al contrario, quelli meno probabili, essendo inaspettati, trasmettono pi√π sorpresa.\nLa sorpresa di un evento, determinata dalla sua probabilit√† \\(p\\), si calcola con la formula:\n\\[ H(p) = -\\log_2(p) = \\log_2 \\left(\\frac{1}{p}\\right). \\]\nL‚Äôuso del logaritmo in questa formula ha diverse giustificazioni:\n\nIl logaritmo converte la moltiplicazione delle probabilit√† in una somma. Questo semplifica l‚Äôanalisi di eventi complessi formati da pi√π eventi indipendenti.\nLa base del logaritmo (in questo caso, 2) corrisponde all‚Äôunit√† di misura dell‚Äôinformazione. La base 2 √® utilizzata perch√© l‚Äôinformazione viene misurata in bit, che rappresentano decisioni binarie.\nLa scala logaritmica riflette meglio la percezione umana dell‚Äôinformazione e della sorpresa. Eventi con probabilit√† molto basse hanno un impatto informativo molto maggiore rispetto a variazioni di probabilit√† in range pi√π alti.\n\n√à importante notare che la base del logaritmo pu√≤ variare: non ci sono unit√† intrinseche per misurare la sorpresa. Ad esempio, l‚Äôuso della base 2, comune nelle telecomunicazioni, porta a misurare l‚Äôinformazione in ‚Äúbit‚Äù. Al contrario, l‚Äôadozione della base \\(e\\), tipica nella fisica statistica, porta a misurazioni in ‚Äúnats‚Äù, o ‚Äúcifre naturali‚Äù.\nPer illustrare, consideriamo alcuni esempi pratici.\n\ndef calcola_entropia(p):\n    if p == 0 or p == 1:\n        return 0  # Non c'√® incertezza se l'evento √® certo o impossibile\n    else:\n        return -p * math.log2(p)\n\n# Esempi di probabilit√†\nprobabilit√† = [0.0, 0.1, 0.5, 0.9, 1.0]\n\n# Calcolo dell'entropia per ciascuna probabilit√†\nentropie = {p: calcola_entropia(p) for p in probabilit√†}\n\nprint(entropie)\n\n{0.0: 0, 0.1: 0.33219280948873625, 0.5: 0.5, 0.9: 0.13680278410054494, 1.0: 0}\n\n\nL‚Äôoutput di questo script mostra che l‚Äôentropia √® massima per eventi con probabilit√† intermedia (0.5) e minima (zero) per eventi certi o impossibili.\nIn generale, possiamo dunque dire che l‚Äôentropia raggiunge il suo valore massimo in condizioni di completa equiprobabilit√†, ovvero quando ogni esito possibile di un evento ha esattamente la stessa probabilit√† di verificarsi. Questa condizione rappresenta il massimo grado di imprevedibilit√†, poich√© non esistono indizi che possano aiutare a prevedere quale esito si verificher√†.\nAl contrario, l‚Äôentropia √® minima, assumendo un valore di zero, quando l‚Äôesito di un evento √® completamente certo. Questo avviene quando uno degli esiti possibili ha una probabilit√† di 1, eliminando qualsiasi forma di incertezza o sorpresa. In pratica, ci√≤ significa che non c‚Äô√® alcuna informazione da guadagnare nell‚Äôosservare l‚Äôevento, poich√© l‚Äôesito √® gi√† noto in anticipo.\n\n72.2.1 Additivit√† dell‚ÄôEntropia per Eventi Indipendenti\nL‚Äôentropia mostra una propriet√† di additivit√† nel caso di eventi indipendenti. Questo significa che, se due o pi√π eventi indipendenti si verificano, l‚Äôentropia totale associata alla loro combinazione √® uguale alla somma delle entropie di ciascun evento preso singolarmente. Questa caratteristica deriva dalla propriet√† additiva dei logaritmi, che permette di sommare le entropie individuali per ottenere l‚Äôentropia complessiva.\n\n\n72.2.2 Entropia di Variabili Casuali\nL‚Äôinformazione di Shannon misura la sorpresa di un singolo evento, ma √® possibile estendere questo concetto al caso di una distribuzione di probabilit√†, ovvero al caso di una variabile casuale discreta o continua. L‚Äôentropia fornisce una misura complessiva dell‚Äôincertezza o della sorpresa associata a una variabile casuale.\n\n72.2.2.1 Entropia di una Variabile Casuale Discreta\nConsideriamo una variabile casuale discreta \\(X\\) che pu√≤ assumere i valori \\(a_1, a_2, \\ldots, a_n\\) con le relative probabilit√† \\(p_1, p_2, \\ldots, p_n\\), dove la somma totale delle probabilit√† √® 1. L‚Äôentropia di $ X $ √® calcolata come la somma pesata delle entropie di ciascun possibile esito:\n\\[ H(X) = -\\sum_{i=1}^{n} p_i \\log_2(p_i). \\]\nLa formula somma le informazioni di tutti i possibili esiti, pesando ciascun termine con la probabilit√† \\(p_i\\) dell‚Äôesito stesso. Questo significa che gli esiti pi√π probabili influenzano maggiormente l‚Äôentropia totale rispetto a quelli meno probabili.\nIl logaritmo converte la moltiplicazione delle probabilit√† in una somma, semplificando i calcoli per eventi indipendenti.\nIl segno negativo √® necessario perch√© i logaritmi delle probabilit√†, essendo numeri minori di 1, sono negativi. Il segno negativo inverte questi valori, trasformandoli in quantit√† positive che rappresentano correttamente l‚Äôinformazione o la sorpresa. Inoltre, esiti pi√π probabili, avendo \\(p_i\\) maggiori, producono logaritmi negativi meno estremi, riflettendo la loro minore sorpresa.\nIn sintesi, l‚Äôentropia \\(H(X)\\) misura l‚Äôincertezza complessiva di una variabile casuale discreta, tenendo conto delle probabilit√† di tutti i suoi possibili esiti. Ogni termine della somma \\(-p_i \\log_2(p_i)\\) rappresenta la quantit√† di sorpresa o informazione associata a ciascun esito, ponderata dalla probabilit√† di quell‚Äôesito.\n\n\n72.2.2.2 Entropia di una Variabile Casuale Continua\nNel caso delle variabili casuali continue, il concetto di entropia viene generalizzato sostituendo la somma con un integrale. Questo √® necessario perch√© le variabili continue possono assumere un numero infinito di valori all‚Äôinterno di un intervallo.\nPer una variabile casuale continua \\(X\\) con una funzione di densit√† di probabilit√† \\(p(x)\\), l‚Äôentropia (nota anche come entropia differenziale) √® definita dalla seguente formula:\n\\[ H(X) = -\\int p(x) \\log_2(p(x)) \\, dx, \\]\ndove:\n\n\\(p(x)\\) √® la funzione di densit√† di probabilit√† di \\(X\\),\nl‚Äôintegrale √® calcolato su tutto il dominio di \\(X\\).\n\nL‚Äôentropia di una variabile casuale continua fornisce una misura dell‚Äôincertezza o della sorpresa associata alla distribuzione della variabile. Come nel caso discreto, l‚Äôentropia continua quantifica l‚Äôincertezza associata a \\(X\\). Una PDF molto concentrata (ad esempio, una distribuzione con picchi stretti) implica bassa entropia, poich√© l‚Äôevento √® pi√π prevedibile. Una PDF distribuita uniformemente implica alta entropia, poich√© l‚Äôevento √® meno prevedibile.\nIl segno negativo assicura che l‚Äôentropia sia una quantit√† positiva, in quanto \\(\\log_2(p(x))\\) √® negativo per \\(p(x)\\) compreso tra 0 e 1.\n\n\n\n72.2.3 Applicazioni Psicologiche\nL‚Äôentropia dell‚Äôinformazione trova applicazioni anche in psicologia, per esempio nello studio dell‚Äôeffetto della sorpresa sull‚Äôumore. La sorpresa, o entropia, √® stata documentata sia in laboratorio che in contesti naturali come un fattore significativo che influenza le emozioni.\nAd esempio, Spector (1956) osserv√≤ l‚Äôeffetto della probabilit√† a priori sulla soddisfazione dei soggetti in risposta a una promozione lavorativa. I risultati indicano che gli esiti meno probabili a priori (e quindi pi√π sorprendenti quando si verificano) hanno un impatto maggiore sull‚Äôumore. In altre parole, quando un evento inatteso e sorprendente si verifica, esso tende a influenzare l‚Äôumore in modo pi√π forte rispetto a eventi previsti e probabili.\n\n\n72.2.4 Divergenza di Kullback-Leibler: Uno Strumento per Confrontare Distribuzioni Probabilistiche\nLa divergenza \\(\\mathbb{KL}\\), introdotta da Kullback e Leibler nel 1951, estende il concetto di entropia di Shannon. Mentre l‚Äôentropia misura l‚Äôincertezza di una singola distribuzione di probabilit√†, la divergenza \\(\\mathbb{KL}\\) valuta quanto una distribuzione di probabilit√† \\(Q\\) differisca da un‚Äôaltra distribuzione di riferimento \\(P\\). Entrambe le distribuzioni devono descrivere la stessa variabile aleatoria \\(X\\).\n\n72.2.4.1 Calcolo della Divergenza \\(\\mathbb{KL}\\)\nSupponiamo che la variabile casuale \\(X\\) segua la distribuzione \\(P\\). L‚Äôentropia di Shannon, che quantifica la sorpresa media risultante dall‚Äôosservazione di esiti distribuiti secondo \\(P\\), si calcola come:\n\\[\nH(P) = -\\sum_x p(x) \\log(p(x)).\n\\]\nPer valutare quanto sarebbe sorprendente osservare \\(P\\) attraverso la lente di una distribuzione diversa \\(Q\\), calcoliamo l‚Äôentropia incrociata, definita come:\n\\[\nH(P, Q) = -\\sum_x p(x) \\log(q(x)).\n\\]\nQuesta misura rappresenta la sorpresa attesa se utilizzassimo \\(Q\\) anzich√© \\(P\\) per descrivere la variabile aleatoria \\(X\\).\nLa divergenza \\(\\mathbb{KL}\\), che √® la differenza tra l‚Äôentropia di \\(P\\) e l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\), si esprime come:\n\\[\nD_{\\mathbb{KL}}(P \\parallel Q) = \\sum_x p(x) \\big(\\log(p(x)) - \\log(q(x))\\big).\n\\]\nAlternativamente, la formula precedente pu√≤ essere riscritta utilizzando il rapporto tra i logaritmi:\n\\[\nD_{\\mathbb{KL}}(P \\parallel Q) = \\sum_x p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right).\n\\]\nIn queste formule\n\\[\\log(p(x)) - \\log(q(x))\\]\nrappresenta il ‚Äúcosto‚Äù di sorpresa per ciascun esito \\(x\\), ponderato dalla probabilit√† \\(p(x)\\) di tale esito secondo la distribuzione originale \\(P\\). Questo costo quantifica quanto \\(Q\\) sia inadeguata a modellare o descrivere \\(P\\).\nLa divergenza \\(\\mathbb{KL}\\) quantifica ‚Äúquanto siamo sorpresi‚Äù nell‚Äôutilizzare \\(Q\\) per prevedere eventi distribuiti secondo \\(P\\) e riflette l‚Äôinformazione che viene ‚Äúpersa‚Äù quando \\(Q\\) √® usata al posto di \\(P\\).\nIn conclusione, la divergenza \\(\\mathbb{KL}\\) si basa su due misure fondamentali:\n\nEntropia di \\(P\\): Misura l‚Äôincertezza interna di \\(P\\).\nEntropia incrociata tra \\(P\\) e \\(Q\\): Quantifica l‚Äôincertezza quando \\(Q\\) √® utilizzata per stimare \\(P\\).\n\nCos√¨, la divergenza \\(\\mathbb{KL}\\) rappresenta la differenza tra l‚Äôentropia di \\(P\\) e l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\), e mette in evidenza quanto l‚Äôuso di \\(Q\\) al posto di \\(P\\) incrementi l‚Äôincertezza o la sorpresa.\n\nEsempio 72.1 Per fare un esempio, supponiamo che \\(P\\) e \\(Q\\) siano due distribuzioni di probabilit√† su un insieme finito di possibili esiti, ad esempio {0, 1, 2}. Per semplicit√†, consideriamo che \\(P\\) e \\(Q\\) siano definite come segue:\n\n\\(P\\) √® la distribuzione ‚Äúvera‚Äù: \\(P = [0.1, 0.6, 0.3]\\);\n\\(Q\\) √® una distribuzione alternativa che usiamo per la stima: \\(Q = [0.2, 0.5, 0.3]\\).\n\n\n# Definizione delle distribuzioni\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.2, 0.5, 0.3])\n\n# Calcolo della divergenza KL da P a Q\nKL_divergence = np.sum(kl_div(P, Q))\n\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.0401\n\n\nNel codice precedente, kl_div(P, Q) calcola la divergenza \\(\\mathbb{KL}\\) elemento per elemento dell‚Äôarray. Essa calcola \\(\\sum_x p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) per ogni esito \\(x\\), che √® esattamente il termine \\(p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) descritto nella formula della divergenza \\(\\mathbb{KL}\\). Utilizziamo poi np.sum per sommare tutti i contributi individuali e ottenere il valore totale della divergenza \\(\\mathbb{KL}\\).\nQuesto esempio fornisce un calcolo diretto della divergenza \\(\\mathbb{KL}\\) tra due distribuzioni, mostrando come una distribuzione \\(Q\\) possa essere inadeguata nel modellare una distribuzione \\(P\\), con un focus sul ‚Äúcosto‚Äù di sorpresa per ogni esito.\n\n\nEsempio 72.2 In un due altri esempi, rendiamo via via \\(Q\\) pi√π diverso da \\(P\\). Notiamo come la divergenza \\(\\mathbb{KL}\\) aumenta.\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.35, 0.3, 0.35])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.2444\n\n\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.6, 0.3, 0.1])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.5663\n\n\n\n\n\n\n72.2.5 Applicazione della Divergenza \\(\\mathbb{KL}\\) nella Selezione di Modelli\nLa divergenza \\(\\mathbb{KL}\\) √® un indice fondamentale nella selezione di modelli statistici. L‚Äôobiettivo √® identificare il modello \\(Q\\) che minimizza \\(D_{\\mathbb{KL}}(P \\parallel Q)\\), ovvero ridurre al minimo la differenza \\(H(P) - H(P, Q)\\). Questo significa minimizzare l‚Äôerrore introdotto nell‚Äôapprossimare la distribuzione vera \\(P\\) con il modello \\(Q\\).\n\n72.2.5.1 Propriet√† Importanti\n\nNon-negativit√†: \\(D_{\\mathbb{KL}}(P \\parallel Q) \\geq 0\\). Il valore √® zero solamente quando \\(P\\) e \\(Q\\) sono identiche, indicando una perfetta corrispondenza.\nAsimmetria: \\(D_{\\mathbb{KL}}(P \\parallel Q) \\neq D_{\\mathbb{KL}}(Q \\parallel P)\\). Questa propriet√† evidenzia che la ‚Äúdistanza‚Äù percepita dal modello \\(Q\\) verso \\(P\\) non √® equivalente se misurata nella direzione inversa.\n\n\n\n72.2.5.2 Selezione dei Modelli Statistici\nNella selezione dei modelli statistici, l‚Äôobiettivo principale √® scegliere il modello \\(Q\\) che minimizzi la divergenza \\(\\mathbb{KL}\\) rispetto alla distribuzione ‚Äúvera‚Äù \\(P\\) dei dati. Tuttavia, \\(P\\) √® spesso sconosciuta o non direttamente osservabile.\nA causa di questa incertezza, i ricercatori e gli statistici utilizzano criteri approssimativi per stimare indirettamente la divergenza \\(\\mathbb{KL}\\). Nel capitolo successivo, esploreremo come questi criteri valutano sia la bont√† di adattamento del modello che la sua complessit√†.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "72¬† Entropia",
    "section": "72.3 Riflessioni Conclusive",
    "text": "72.3 Riflessioni Conclusive\nIn questo capitolo, abbiamo esaminato il concetto di entropia, evidenziando il suo ruolo fondamentale nel quantificare l‚Äôincertezza all‚Äôinterno delle distribuzioni di probabilit√†. Abbiamo anche affrontato la questione di come l‚Äôentropia possa essere impiegata per valutare la ‚Äúdistanza‚Äù tra un modello teorico e i dati reali. A tale scopo, abbiamo introdotto la divergenza \\(\\mathbb{KL}\\), una misura che quantifica le discrepanze tra due distribuzioni di probabilit√†.\nNel capitolo successivo, approfondiremo ulteriormente il tema della divergenza \\(\\mathbb{KL}\\). Esploreremo come questo strumento possa essere utilizzato per confrontare modelli teorici con dati empirici e ci concentreremo su come possa fornirci una comprensione pi√π dettagliata dell‚Äôadattamento di un modello alla realt√† che intende rappresentare. Questa esplorazione ci permetter√† di valutare pi√π accuratamente la validit√† e la generalizzabilit√† dei modelli scientifici nel loro tentativo di catturare e interpretare la complessit√† dei fenomeni oggetto di studio.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#esercizi",
    "href": "chapters/entropy/01_entropy.html#esercizi",
    "title": "72¬† Entropia",
    "section": "72.4 Esercizi",
    "text": "72.4 Esercizi\n\nEsercizio 72.1 Cosideriamo due distribuzioni di probabilit√† discrete, \\(p\\) e \\(q\\):\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\nSi calcoli l‚Äôentropia di \\(p\\), l‚Äôentropia incrociata tra \\(p\\) e \\(q\\), la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).\nSi consideri q = np.array([0.2, 0.55, 0.25]) e si calcoli di nuovo a divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). Si confronti con il risultato precedente e si interpreti.\n\n\nEsercizio 72.2 Sia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\). Sia \\(q_1\\) una approssimazione a \\(p\\): q1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01]). Sia \\(q_2\\) una distribuzione uniforme: q2 = [0.2] * 5. Si calcoli la divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) e da \\(q_2\\) da \\(p\\) e si interpretino i risultati.\n\n\nEsercizio 72.3 La Divergenza \\(\\mathbb{KL}\\) √® spesso paragonata a una ‚Äúdistanza‚Äù tra due distribuzioni di probabilit√†, ma √® fondamentale capire che non √® simmetrica. Questo significa che la misura di quanto \\(p\\) √® diversa da \\(q\\) non √® la stessa di quanto \\(q\\) √® diversa da \\(p\\). Questa asimmetria riflette la differenza nella perdita di informazione quando si sostituisce una distribuzione con l‚Äôaltra.\nPer le seguenti distribuzioni\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\nsi calcoli l‚Äôentropia di p, l‚Äôentropia incrociata da p a q, la divergenza KL da p a q, l‚Äôentropia di q, l‚Äôentropia incrociata da q a p, e la divergenza KL da q a p.¬†Si commenti.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "title": "72¬† Entropia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nscipy     : 1.14.0\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nSpector, Aaron J. 1956. ¬´Expectations, fulfillment, and morale¬ª. The Journal of Abnormal and Social Psychology 52 (1): 51‚Äì56.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html",
    "href": "chapters/entropy/02_kl.html",
    "title": "73¬† Divergenza KL e ELPD",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo in dettaglio due concetti fondamentali per la valutazione e il confronto di modelli statistici nel contesto bayesiano: la Divergenza di Kullback-Leibler (\\(\\mathbb{KL}\\)) e la Densit√† Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD). Questi strumenti ci permettono di quantificare l‚Äôadattamento dei modelli ai dati e la loro capacit√† predittiva.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#confronto-di-modelli-utilizzando-la-divergenza-mathbbkl",
    "href": "chapters/entropy/02_kl.html#confronto-di-modelli-utilizzando-la-divergenza-mathbbkl",
    "title": "73¬† Divergenza KL e ELPD",
    "section": "73.1 Confronto di Modelli Utilizzando la Divergenza \\(\\mathbb{KL}\\)",
    "text": "73.1 Confronto di Modelli Utilizzando la Divergenza \\(\\mathbb{KL}\\)\n\n73.1.1 La Distribuzione Predittiva Posteriori\nLa distribuzione predittiva posteriori, indicata come \\(Q(\\tilde{y} \\mid y)\\), rappresenta le previsioni su nuovi dati \\(\\tilde{y}\\) basate su un modello statistico \\(Q\\) e i dati osservati \\(y\\). Questa distribuzione combina:\n\nLe previsioni del modello per un dato set di parametri \\(\\theta\\), ovvero \\(Q(\\tilde{y} \\mid \\theta)\\).\nLa distribuzione posteriore di questi parametri dati i dati osservati, cio√® \\(P(\\theta \\mid y)\\).\n\nQuesta combinazione permette di fare previsioni che tengono conto sia dell‚Äôincertezza nei parametri che della struttura del modello.\n\n\n73.1.2 Misurazione della Divergenza \\(\\mathbb{KL}\\)\nLa divergenza \\(\\mathbb{KL}\\) quantifica quanto bene la distribuzione predittiva del modello \\(Q\\) si avvicina alla distribuzione vera \\(P\\) che ha generato i dati. Matematicamente, questo √® espresso come \\(\\mathbb{KL}(P \\parallel Q)\\).\nInterpretazione:\n\nUn valore basso di \\(\\mathbb{KL}\\) indica che \\(Q\\) √® una buona approssimazione di \\(P\\).\nUn valore alto indica una maggiore discrepanza tra le due distribuzioni.\n\n\n\n73.1.3 Confronto Pratico tra Modelli\nPoich√© non conosciamo direttamente \\(P\\), la vera distribuzione che ha generato i dati, utilizziamo la divergenza \\(\\mathbb{KL}\\) per confrontare diversi modelli. La formula generale per la divergenza \\(\\mathbb{KL}\\) tra due distribuzioni \\(P\\) e \\(Q\\) √®:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\mathbb{E}_P[\\log P] - \\mathbb{E}_P[\\log Q],\n\\]\ndove \\(\\mathbb{E}_P\\) indica il valore atteso calcolato sotto la distribuzione \\(P\\).\nPer distribuzioni discrete, questa si esprime come:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\sum_{i=1}^n p_i (\\log p_i - \\log q_i),\n\\]\ndove \\(p_i\\) e \\(q_i\\) rappresentano le probabilit√† degli eventi \\(i\\) per le distribuzioni \\(P\\) e \\(Q\\) rispettivamente.\nLa divergenza \\(\\mathbb{KL}\\) pu√≤ essere riformulata in termini di valore atteso come segue:\n\nTermine \\(\\log P\\): \\[\n\\mathbb{E}_P[\\log P(X)] = \\sum_{i=1}^n p_i \\log p_i\n\\] Questo termine rappresenta l‚Äôentropia negativa di \\(P\\).\nTermine \\(\\log Q\\): \\[\n\\mathbb{E}_P[\\log Q(X)] = \\sum_{i=1}^n p_i \\log q_i\n\\] Questo termine rappresenta l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\).\n\nQuindi, la divergenza \\(\\mathbb{KL}\\) si riduce a:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\mathbb{E}_P[\\log P(X)] - \\mathbb{E}_P[\\log Q(X)]\n\\]\nPer variabili continue, la formula diventa:\n\\[\n\\mathbb{KL}(P \\parallel Q) = \\int p(x) (\\log p(x) - \\log q(x)) \\, dx.\n\\]\nNella pratica del confronto tra modelli, il termine \\(\\mathbb{E}_P[\\log P]\\) rimane costante per tutti i modelli confrontati e pu√≤ quindi essere omesso. Ci concentriamo dunque sul termine:\n\\[\n-\\mathbb{E}_P[\\log Q(y)]\n\\]\nche misura l‚Äôadattabilit√† del modello ai dati osservati. Questo si calcola come:\n\\[\n-\\int p(y) \\log Q(y) \\, dy,\n\\]\nindicando quale modello \\(Q\\) rappresenti meglio la distribuzione \\(P\\) secondo la quantit√† di informazione che si perderebbe utilizzandolo per descrivere i dati osservati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#expected-log-predictive-density-elpd",
    "href": "chapters/entropy/02_kl.html#expected-log-predictive-density-elpd",
    "title": "73¬† Divergenza KL e ELPD",
    "section": "73.2 Expected Log Predictive Density (ELPD)",
    "text": "73.2 Expected Log Predictive Density (ELPD)\nL‚ÄôELPD √® una misura avanzata usata nei metodi bayesiani per valutare quanto bene un modello pu√≤ prevedere nuovi dati. √à come se stessimo chiedendo al modello: ‚ÄúQuanto sei sicuro delle tue previsioni per dati che non hai mai visto?‚Äù\nLa formula dell‚ÄôELPD √®:\n\\[ \\text{ELPD} = \\sum_{i=1}^n \\log p(y_i | \\mathbf{y}_{-i}), \\]\ndove:\n\n\\(y_i\\) √® l‚Äôi-esima osservazione,\n\\(\\mathbf{y}_{-i}\\) rappresenta tutte le osservazioni eccetto \\(y_i\\).\n\nInterpretazione:\n\nL‚ÄôELPD misura quanto bene il modello pu√≤ prevedere ogni singola osservazione basandosi su tutte le altre.\nUn ELPD pi√π alto indica un modello con migliori capacit√† predittive.\n\n\n73.2.1 Collegamento con la Divergenza \\(\\mathbb{KL}\\)\nIl collegamento tra \\(-\\mathbb{E}_P[\\log Q(y)]\\) e l‚ÄôELPD √® che entrambi misurano la capacit√† predittiva di un modello, ma in modi leggermente diversi:\n\n\\(-\\mathbb{E}_P[\\log Q(y)]\\) misura la divergenza tra la vera distribuzione \\(P\\) e la distribuzione del modello \\(Q\\), indicando quanto bene \\(Q\\) approssima \\(P\\).\nL‚ÄôELPD, d‚Äôaltra parte, misura direttamente la capacit√† del modello di prevedere nuove osservazioni, utilizzando un approccio di convalida incrociata leave-one-out.\n\nL‚ÄôELPD si focalizza sulla capacit√† di un modello di predire nuovi dati, offrendo una misura della sua capacit√† di generalizzazione. Matematicamente, l‚ÄôELPD √® definito come il valore atteso del logaritmo della densit√† predittiva di un modello, calcolato sotto la vera distribuzione dei dati futuri:\n\\[\n\\text{ELPD} = \\mathbb{E}_{y \\sim p(y)} [\\log p(y \\mid \\theta)]\n\\]\nMentre \\(-\\int p(y) \\log Q(y) \\, dy\\) quantifica quanto bene un modello descrive la distribuzione attuale dei dati, l‚ÄôELPD stima quanto efficacemente il modello pu√≤ essere utilizzato per prevedere nuovi dati. Questo rende l‚ÄôELPD una misura complementare alla \\(\\mathbb{KL}\\), enfatizzando non solo l‚Äôadattabilit√† ma anche la predittivit√† di un modello.\nIn conclusione, utilizzare l‚ÄôELPD come criterio di valutazione tende a favorire modelli che non solo si adattano bene ai dati esistenti ma sono anche robusti contro l‚Äôoverfitting. La combinazione di Divergenza \\(\\mathbb{KL}\\) ed ELPD fornisce una valutazione completa dei modelli, considerando sia la loro capacit√† di adattarsi ai dati osservati che la loro abilit√† nel fare previsioni accurate su nuovi dati.\n\nEsempio 73.1 Consideriamo un esempio utilizzando la distribuzione binomiale per illustrare il concetto di ELPD. Immaginiamo un esperimento in cui lanciamo una moneta 10 volte e contiamo il numero di teste. Supponiamo che la vera probabilit√† di ottenere testa sia 0.6 (anche se nella realt√† non la conosceremmo).\n\nLa vera distribuzione dei dati segue una Binomiale(n=10, p=0.6): \\(y \\sim \\text{Binomiale}(10, 0.6)\\)\nIl nostro modello stima \\(p=0.5\\) (ipotizziamo una moneta equa): \\(p(y|\\theta) = \\text{Binomiale}(10, 0.5)\\)\n\nCalcoliamo l‚ÄôELPD:\n\n# Parametri\nn = 10  # numero di lanci\np_true = 0.6  # vera probabilit√† di testa\np_model = 0.5  # probabilit√† stimata dal modello\n\n# Calcolo ELPD\nelpd = 0\nfor y in range(n + 1):\n    # Probabilit√† di y secondo la vera distribuzione\n    p_true_y = binom.pmf(y, n, p_true)\n\n    # Log della densit√† predittiva del modello\n    log_p_model_y = binom.logpmf(y, n, p_model)\n\n    # Somma pesata\n    elpd += p_true_y * log_p_model_y\n\nprint(f\"ELPD del modello che stima p=0.5: {elpd:.4f}\")\n\n# Per confronto, calcoliamo l'ELPD per il modello \"vero\"\nelpd_true = 0\nfor y in range(n + 1):\n    p_true_y = binom.pmf(y, n, p_true)\n    log_p_true_y = binom.logpmf(y, n, p_true)\n    elpd_true += p_true_y * log_p_true_y\n\nprint(f\"ELPD del modello vero (con p=0.6): {elpd_true:.4f}\")\n\nELPD del modello che stima p=0.5: -2.0549\nELPD del modello vero (con p=0.6): -1.8536\n\n\nL‚ÄôELPD del modello vero √® maggiore (meno negativo) di quello del nostro modello stimato, indicando una migliore capacit√† predittiva.\nQuesto esempio illustra come l‚ÄôELPD quantifica la capacit√† predittiva di un modello:\n\nConsidera tutti i possibili risultati (da 0 a 10 teste).\nPer ogni risultato, calcola:\n\nLa probabilit√† di quel risultato secondo la vera distribuzione.\nIl logaritmo della densit√† predittiva del nostro modello per quel risultato.\n\nMoltiplica questi due valori e somma su tutti i possibili risultati.\n\nIn conclusione, l‚ÄôELPD ci permette di confrontare modelli diversi: un valore pi√π alto (meno negativo) indica una migliore capacit√† predittiva. Nel nostro caso, il vero modello (p=0.6) ha un ELPD maggiore del modello stimato (p=0.5).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#metodi-di-approssimazione-per-la-stima-dellelpd",
    "href": "chapters/entropy/02_kl.html#metodi-di-approssimazione-per-la-stima-dellelpd",
    "title": "73¬† Divergenza KL e ELPD",
    "section": "73.3 Metodi di Approssimazione per la Stima dell‚ÄôELPD",
    "text": "73.3 Metodi di Approssimazione per la Stima dell‚ÄôELPD\nL‚ÄôELPD √® un importante indicatore della qualit√† di un modello statistico. Tuttavia, poich√© la vera distribuzione dei dati √® sconosciuta, non possiamo calcolare direttamente l‚ÄôELPD. Per superare questa limitazione, utilizziamo metodi di approssimazione noti come ‚Äúcriteri di informazione‚Äù.\n\n73.3.1 Obiettivo dei Criteri di Informazione\nI criteri di informazione ci aiutano a bilanciare due aspetti cruciali nella valutazione di un modello:\n\nL‚Äôadattamento del modello ai dati osservati\nLa complessit√† del modello\n\nEsaminiamo alcuni dei criteri pi√π comuni utilizzati per approssimare l‚ÄôELPD.\n\n\n73.3.2 Errore Quadratico Medio (MSE)\nL‚ÄôErrore Quadratico Medio (Mean Squared Error o MSE) misura la discrepanza media tra le previsioni del modello e i valori reali.\nFormula:\n\\[ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2, \\]\ndove:\n\n\\(n\\) √® il numero totale di osservazioni,\n\\(y_i\\) sono i valori reali,\n\\(\\hat{y}_i\\) sono i valori previsti dal modello.\n\nUn MSE inferiore indica un migliore adattamento del modello ai dati.\n\n\n73.3.3 Criterio di Informazione di Akaike (AIC)\nIl Criterio di Informazione di Akaike (AIC) va oltre l‚ÄôMSE, considerando sia l‚Äôadattamento del modello che la sua complessit√†.\nFormula:\n\\[ AIC = -2 \\sum \\log p(y_i \\mid \\hat{\\theta}_{\\text{mle}}) + 2k, \\]\ndove:\n\n\\(\\hat{\\theta}_{\\text{mle}}\\) sono i parametri stimati del modello,\n\\(k\\) √® il numero di parametri del modello.\n\nL‚ÄôAIC bilancia la bont√† di adattamento (primo termine) con la complessit√† del modello (secondo termine). Un valore pi√π basso di AIC indica una minor perdita di informazione, suggerendo un modello preferibile.\nVantaggi e Limitazioni:\n\nFacile e veloce da calcolare.\nPu√≤ essere meno accurato per campioni piccoli o modelli complessi.\nFornisce un‚Äôapprossimazione asintoticamente corretta dell‚ÄôELPD per modelli regolari e campioni grandi.\n\n\n\n73.3.4 Criterio di Informazione Bayesiano (BIC)\nIl Criterio di Informazione Bayesiano (BIC) √® definito come:\n\\[\nBIC = \\ln(n)k - 2\\ln(L),\n\\]\ndove \\(n\\) √® il numero di osservazioni.\nIl BIC impone una penalit√† maggiore per l‚Äôincremento dei parametri, rendendolo particolarmente adeguato per dataset di grandi dimensioni.\n\n\n73.3.5 Widely Applicable Information Criterion (WAIC)\nIl WAIC √® una versione avanzata dell‚ÄôAIC, particolarmente utile nel contesto bayesiano. Considera l‚Äôintera distribuzione a posteriori dei parametri anzich√© solo la stima puntuale.\nFormula:\n\\[ WAIC = -2\\left[ \\sum_{i=1}^{n} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i|\\theta^{(s)}) \\right) - \\sum_{i=1}^{n} \\text{Var}_{\\theta^{(s)}} \\left( \\log p(y_i|\\theta^{(s)}) \\right) \\right], \\]\ndove:\n\n\\(S\\) √® il numero di campioni dalla distribuzione a posteriori,\n\\(\\text{Var}_{\\theta^{(s)}}\\) √® la varianza della log-verosimiglianza.\n\nCaratteristiche del WAIC:\n\nCalcola il logaritmo della densit√† predittiva per ogni punto dati.\nPenalizza la complessit√† del modello basandosi sulla variabilit√† delle sue predizioni.\nLa somma delle varianze a posteriori del logaritmo della densit√† predittiva converge al numero effettivo di parametri del modello.\n\n\n\n73.3.6 Leave-One-Out Cross-Validation (LOO-CV)\nIl LOO-CV √® un metodo robusto che massimizza l‚Äôutilizzo dei dati disponibili, rendendolo ideale per modelli complessi e campioni di dimensioni ridotte.\nProcedura:\n\nRimuove un‚Äôosservazione alla volta.\nAdatta il modello sui dati rimanenti.\nValuta la densit√† predittiva per l‚Äôosservazione esclusa.\n\nFormula:\n\\[ \\text{Stima dell'ELPD} = \\sum_{i=1}^N \\log p(y_i \\mid y_{-i}), \\]\ndove:\n\n\\(y_i\\) √® il dato escluso,\n\\(y_{-i}\\) rappresenta tutti gli altri dati.\n\nVantaggi e Limitazioni:\n\nFornisce una stima robusta dell‚ÄôELPD.\nParticolarmente utile per set di dati non molto ampi.\nComputazionalmente intensivo.\n\n\n\n73.3.7 Valutazione Comparativa e Applicazioni Pratiche\nQuesti metodi forniscono diverse prospettive sulla stima dell‚ÄôELPD. Il LOO-CV √® particolarmente prezioso per modelli complessi o set di dati limitati, mentre AIC e WAIC offrono approcci pi√π rapidi e meno computazionalmente intensivi, adatti per valutazioni preliminari o quando si dispone di grandi set di dati.\nIn conclusione, la selezione del modello ottimale richiede un equilibrio tra adattamento ai dati e semplicit√†. L‚Äôutilizzo combinato di tecniche di validazione incrociata e criteri di informazione permette di costruire modelli che:\n\nsi adattano bene ai dati attuali,\nsono in grado di fare previsioni affidabili su nuovi dati,\ncatturano le tendenze importanti senza perdersi nel rumore.\n\nL‚Äôobiettivo finale non √® creare il modello pi√π complesso o quello che si adatta perfettamente ai dati di addestramento, ma trovare un equilibrio ottimale tra semplicit√† e accuratezza.\n\nEsempio 73.2 Il seguente script Python dimostra come calcolare l‚ÄôAIC per un modello binomiale. Ecco una breve spiegazione del codice:\n\nDefiniamo una funzione per la log-verosimiglianza negativa del modello binomiale.\nImplementiamo una funzione per calcolare l‚ÄôAIC dato il valore di log-verosimiglianza e il numero di parametri.\nUtilizziamo scipy.optimize.minimize per trovare il parametro che massimizza la verosimiglianza.\nCalcoliamo l‚ÄôAIC per il modello binomiale.\n\n\n# Dati di esempio \nn_trials = 100\ntrue_p = 0.7\ndata = np.random.binomial(n_trials, true_p, size=50)\n\n# Funzione di log-verosimiglianza negativa\ndef neg_log_likelihood(p, data, n):\n    return -np.sum(binom.logpmf(data, n, p))\n\n# Funzione per calcolare l'AIC\ndef calculate_aic(log_likelihood, k):\n    return 2 * k - 2 * log_likelihood\n\n# Ottimizzazione per trovare la massima verosimiglianza\nresult = minimize(\n    neg_log_likelihood,\n    x0=[0.5],\n    args=(data, n_trials),\n    method=\"L-BFGS-B\",\n    bounds=[(0, 1)],\n)\n\n# Estrai il parametro ottimale e la log-verosimiglianza\np_mle = result.x[0]\nmax_log_likelihood = -result.fun\n\n# Calcola l'AIC\nk = 1  # numero di parametri (solo p in questo caso)\naic = calculate_aic(max_log_likelihood, k)\n\nprint(f\"Parametro stimato (p): {p_mle:.4f}\")\nprint(f\"Log-verosimiglianza massimizzata: {max_log_likelihood:.4f}\")\nprint(f\"AIC: {aic:.4f}\")\n\nParametro stimato (p): 0.5000\nLog-verosimiglianza massimizzata: -567.8227\nAIC: 1137.6453\n\n\nQuesto esempio mostra come calcolare l‚ÄôAIC. Questo indice pu√≤ essere utilizzato per confrontare modelli con diversi livelli di complessit√†. Il modello con l‚ÄôAIC pi√π basso √® generalmente considerato il migliore in termini di compromesso tra adattamento ai dati e complessit√† del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#considerazioni-conclusive",
    "href": "chapters/entropy/02_kl.html#considerazioni-conclusive",
    "title": "73¬† Divergenza KL e ELPD",
    "section": "73.4 Considerazioni Conclusive",
    "text": "73.4 Considerazioni Conclusive\nL‚ÄôELPD e la divergenza \\(\\mathbb{KL}\\) sono strumenti complementari per la valutazione dei modelli statistici:\n\nELPD: Misura la capacit√† predittiva su nuovi dati. Pi√π alto √® l‚ÄôELPD, migliori sono le previsioni.\nDivergenza \\(\\mathbb{KL}\\): Quantifica la differenza tra la distribuzione vera dei dati e quella del modello. Una divergenza KL minore indica una migliore approssimazione.\n\nRelazione tra ELPD e divergenza \\(\\mathbb{KL}\\):\n\nUn alto ELPD generalmente corrisponde a una bassa divergenza \\(\\mathbb{KL}\\).\nMassimizzare l‚ÄôELPD equivale a minimizzare la divergenza \\(\\mathbb{KL}\\).\nEntrambi guidano verso modelli che catturano meglio la realt√† dei dati.\n\nNella pratica:\n\nLa divergenza \\(\\mathbb{KL}\\) valuta l‚Äôadattamento ai dati osservati.\nL‚ÄôELPD e i suoi metodi di approssimazione (LOO-CV, AIC, WAIC) misurano la capacit√† di generalizzazione a dati futuri.\n\nIn conclusione, l‚ÄôELPD, la divergenza \\(\\mathbb{KL}\\) e i relativi metodi di approssimazione forniscono un framework essenziale per la valutazione e la selezione di modelli statistici, bilanciando efficacemente l‚Äôadattamento ai dati con la capacit√† predittiva su nuove osservazioni.\n\nEsempio 73.3 Consideriamo un esempio numerico per confrontare AIC con la divergenza \\(\\mathbb{KL}\\). Supponiamo di avere un set di dati e due modelli statistici: il primo modello si adatta bene ai dati (modello vero), mentre il secondo √® un po‚Äô pi√π distante dalla realt√† (modello alternativo, ne considereremo 5). Calcoleremo la divergenza \\(\\mathbb{KL}\\) tra le distribuzioni previste da questi modelli e il Criterio di Informazione di Akaike per valutare la qualit√† di adattamento dei modelli.\nPer questo esempio, supponiamo di avere un set di dati e due modelli statistici: il primo modello si adatta bene ai dati (modello vero), mentre il secondo √® un po‚Äô pi√π distante dalla realt√† (modello alternativo). Calcoleremo la divergenza \\(\\mathbb{KL}\\) tra le distribuzioni previste da questi modelli e il Criterio di Informazione di Akaike per valutare la qualit√† di adattamento dei modelli.\n\nSupponiamo che i dati siano generati da una distribuzione normale con media vera \\(\\mu = 0\\) e deviazione standard \\(\\sigma = 1\\).\nAssumiamo che il modello vero conosca i parametri della distribuzione.\nAssumiamo che questo modello abbia una deviazione standard leggermente diversa (considereremo 5 modelli diversi: \\(\\sigma\\) = 1.5 fino a 5.0).\n\n\n# Generazione dei dati simulati\nnp.random.seed(42)\ndata = np.random.normal(loc=0, scale=1, size=1000)\n\n# Parametri del modello vero\nmu_true, sigma_true = 0, 1\n\n# Variazione di sigma_alt\nsigma_alts = np.linspace(1.5, 5.0, 5)\nKL_divergences = []\nAIC_values = []\n\n# Calcolo della divergenza KL e AIC per ogni sigma_alt\nfor sigma_alt in sigma_alts:\n    p_true = stats.norm.pdf(data, mu_true, sigma_true)\n    p_alt = stats.norm.pdf(data, mu_true, sigma_alt)\n    KL_divergence = np.sum(p_true * np.log(p_true / p_alt))\n    KL_divergences.append(KL_divergence)\n\n    log_likelihood_alt = np.sum(np.log(stats.norm.pdf(data, mu_true, sigma_alt)))\n    AIC_alt = (\n        2 * 2 - 2 * log_likelihood_alt\n    )  # 2 parametri (mu e sigma), nessuna esponenziale\n    AIC_values.append(AIC_alt)\n\n# Creazione del grafico\nplt.plot(sigma_alts, KL_divergences, label=\"Divergenza KL\", marker=\"o\")\nplt.plot(sigma_alts, AIC_values, label=\"AIC\", marker=\"x\")\nplt.xlabel(\"Sigma Alternativo\")\nplt.ylabel(\"Valore\")\nplt.title(\"Divergenza KL e AIC al variare di Sigma Alternativo\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi vede che, anche se la scala di misura √® diversa tra la divergenza \\(\\mathbb{KL}\\) e il criterio AIC, all‚Äôaumentare della differenza tra la distribuzione vera \\(P\\) e la distribuzione alternativa \\(Q\\), entrambi aumentano.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "title": "73¬† Divergenza KL e ELPD",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Divergenza KL e ELPD</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_stan_loo.html",
    "href": "chapters/entropy/03_stan_loo.html",
    "title": "76¬† Validazione Incrociata Leave-One-Out",
    "section": "",
    "text": "Introduzione\nCome evidenziato nel precedente capitolo, uno dei metodi pi√π efficaci e ampiamente utilizzati per stimare la Densit√† Predittiva Logaritmica Attesa (ELPD) √® la validazione incrociata Leave-One-Out (LOO-CV). Rispetto ad altri approcci che utilizzano l‚Äôintero set di dati per valutare le performance del modello, il metodo LOO-CV esclude una singola osservazione alla volta dal dataset, addestra il modello sui dati rimanenti e successivamente valuta la sua capacit√† di predire l‚Äôosservazione esclusa. Questo procedimento viene ripetuto per ogni osservazione presente nel dataset, fornendo cos√¨ un‚Äôanalisi dettagliata e approfondita della capacit√† del modello di generalizzare al di fuori dei dati osservati. Nel presente capitolo, esamineremo attentamente la metodologia LOO-CV e illustreremo come essa possa essere utilizzata per calcolare l‚ÄôELPD.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_stan_loo.html#il-problema-del-sovra-adattamento",
    "href": "chapters/entropy/03_stan_loo.html#il-problema-del-sovra-adattamento",
    "title": "76¬† Validazione Incrociata Leave-One-Out",
    "section": "76.1 Il Problema del Sovra-adattamento",
    "text": "76.1 Il Problema del Sovra-adattamento\nQuando costruiamo un modello statistico, uno dei problemi pi√π comuni che possiamo incontrare √® il sovra-adattamento (in inglese, ‚Äúoverfitting‚Äù). Ma cosa significa esattamente?\nImmaginate di provare a disegnare una linea che passi attraverso un gruppo di punti su un grafico. Se la linea passa esattamente per ogni singolo punto, potrebbe sembrare perfetta, vero? In realt√†, questo potrebbe essere un esempio di sovra-adattamento.\nIl sovra-adattamento si verifica quando un modello si adatta troppo bene ai dati che abbiamo usato per crearlo (chiamati ‚Äúdati di addestramento‚Äù). In questo processo, il modello inizia a catturare non solo le tendenze generali nei dati (il ‚Äúsegnale‚Äù), ma anche le fluttuazioni casuali o gli errori (il ‚Äúrumore‚Äù).\n\n76.1.1 Perch√© il sovra-adattamento √® un problema?\nUn modello sovra-adattato funzioner√† benissimo con i dati di addestramento, ma avr√† prestazioni scarse quando lo useremo con nuovi dati. √à come se il modello avesse ‚Äúimparato a memoria‚Äù i dati di addestramento invece di capire le regole generali che li governano.\nPer evitare il sovra-adattamento, dobbiamo trovare un equilibrio tra la capacit√† del modello di adattarsi ai dati di addestramento e la sua capacit√† di generalizzare a nuovi dati. Questo √® ci√≤ che chiamiamo il ‚Äútrade-off‚Äù tra bias e varianza.\n\n\n76.1.2 Tecniche di Validazione\nPer assicurarci che il nostro modello non stia sovra-adattandosi, usiamo delle tecniche chiamate ‚Äútecniche di validazione‚Äù. Una delle pi√π importanti √® la validazione incrociata (cross-validation).\n\n\n76.1.3 Validazione Incrociata (Cross-Validation)\nLa validazione incrociata √® come fare un ‚Äútest di realt√†‚Äù per il nostro modello. Invece di usare tutti i dati per addestrare il modello e poi testarlo, dividiamo i dati in parti e usiamo alcune parti per l‚Äôaddestramento e altre per il test, in modo ripetuto.\nCi sono diversi tipi di validazione incrociata, ma vediamo due dei pi√π comuni:\n\nK-fold cross-validation:\n\nImmaginate di avere un mazzo di carte. Le mescolate e le dividete in K gruppi (chiamate ‚Äúfold‚Äù).\nPrendete K-1 gruppi per addestrare il modello e usate il gruppo rimanente per testarlo.\nRipetete questo processo K volte, ogni volta usando un gruppo diverso per il test.\nAlla fine, fate la media dei risultati di tutti i test.\n\nPer esempio, se K = 5, dividerete i dati in 5 parti, addestrerete il modello su 4 parti e lo testerete sulla quinta, ripetendo questo processo 5 volte.\nLeave-one-out cross-validation (LOO-CV):\n\nQuesta √® una versione estrema della K-fold, dove K √® uguale al numero totale di osservazioni.\nPrendete tutti i dati tranne uno per addestrare il modello, e usate quello lasciato fuori per testarlo.\nRipetete questo processo per ogni singola osservazione nel dataset.\n\n√à come se steste giocando a ‚Äúindovina chi‚Äù con i vostri dati, cercando di prevedere ogni singola osservazione basandovi su tutte le altre.\n\nQueste tecniche ci aiutano a capire quanto bene il nostro modello si comporter√† con dati nuovi, che non ha mai visto prima.\n\n\n76.1.4 Criteri di Informazione\nOltre alla validazione incrociata, usiamo anche i ‚Äúcriteri di informazione‚Äù per valutare i nostri modelli. Questi criteri ci aiutano a bilanciare due aspetti importanti:\n\nquanto bene il modello si adatta ai dati;\nquanto √® complesso il modello.\n\nNel capitolo precedente abbiamo visto alcuni dei criteri pi√π comuni: il MSE, AIC, WAIC e LOO-CV.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_stan_loo.html#applicazioni-pratiche",
    "href": "chapters/entropy/03_stan_loo.html#applicazioni-pratiche",
    "title": "76¬† Validazione Incrociata Leave-One-Out",
    "section": "76.2 Applicazioni Pratiche",
    "text": "76.2 Applicazioni Pratiche\nNel contesto dell‚Äôinferenza bayesiana, la selezione del modello si basa principalmente sul confronto delle stime dell‚ÄôExpected Log Predictive Density (ELPD) ottenute attraverso la Cross-Validazione Leave-One-Out (LOO-CV). Questo processo pu√≤ essere efficacemente implementato utilizzando le funzioni fornite dal pacchetto ArviZ.\nPunti Chiave:\n\nConfronto dei Modelli:\n\nSi utilizzano le stime ELPD calcolate tramite LOO-CV.\nIl pacchetto ArviZ fornisce gli strumenti necessari per questi confronti.\n\nValidit√† dei Confronti:\n\nL‚Äôaffidabilit√† di questi confronti dipende dall‚Äôadeguatezza dei dati.\n√à cruciale che i modelli forniscano un adattamento sufficiente ai dati del campione.\n\nValutazione dell‚ÄôAdattamento:\n\nUn aspetto fondamentale √® il calcolo dei valori diagnostici Pareto \\(k\\).\nQuesti valori aiutano a valutare la qualit√† dell‚Äôadattamento del modello ai dati.\n\n\nNell‚Äôesempio successivo, vedremo come applicare questi concetti utilizzando cmdstan. Questo approccio pratico illustrer√† l‚Äôintero processo di selezione e valutazione del modello. Questo framework fornisce un metodo robusto per selezionare il modello pi√π appropriato, considerando sia la sua capacit√† predittiva che la sua adeguatezza ai dati osservati.\n\nEsempio 76.1 Generiamo un set di dati artificiali seguendo una distribuzione normale con una media (loc) di 5 e una deviazione standard (scale) di 2. Scegliamo una dimensione (size) del campione di 100.\n\ny = np.random.normal(loc=5, scale=2, size=100)\nprint(y[0:10])\n\n[4.4683817  6.45280554 8.60973205 5.47134851 7.02579291 5.90298401\n 5.43248972 5.47579654 5.03030772 3.19422982]\n\n\nUtilizziamo cmdstan per adattare un modello normale ai dati. Stimiamo la media (mu) e la deviazione standard (sigma) del modello attraverso il campionamento MCMC.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian-mod-log-lik.stan')\n\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Priors\n  mu ~ normal(5, 2);         // Prior for mu, centered around the known mean with some uncertainty\n  sigma ~ normal(0, 2);      // Half-normal prior for sigma (implying positive values)\n  \n  // Likelihood\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  for (n in 1:N)\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n}\n\n\n\n\nstan_data = {\n    'N': len(y), \n    'y': y\n}\n\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n5.22\n0.20\n4.84\n5.6\n0.0\n0.0\n6710.00\n5164.47\n1.0\n\n\nsigma\n2.01\n0.15\n1.75\n2.3\n0.0\n0.0\n7198.11\n5271.80\n1.0",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_stan_loo.html#valori-diagnostici-pareto-k",
    "href": "chapters/entropy/03_stan_loo.html#valori-diagnostici-pareto-k",
    "title": "76¬† Validazione Incrociata Leave-One-Out",
    "section": "76.3 Valori Diagnostici Pareto \\(k\\)",
    "text": "76.3 Valori Diagnostici Pareto \\(k\\)\nI valori diagnostici Pareto \\(k\\) sono essenziali nell‚Äôanalizzare l‚Äôaffidabilit√† delle stime dell‚ÄôELPD ottenute tramite la validazione incrociata Leave-One-Out (LOO-CV). Questi valori indicano la precisione con cui la LOO-CV approssima l‚ÄôELPD, fornendo una misura di quanto ci possiamo fidare della stima rispetto a quella che otterremmo con un calcolo diretto e completo.\nLa LOO-CV √® una tecnica che stima come un modello statistico si comporterebbe nel prevedere nuovi dati basandosi su quelli esistenti. Il valore Pareto \\(k\\) ci dice quanto affidabile sia questa stima:\n\n\\(k &lt; 0.5\\): Mostra che l‚Äôapprossimazione √® eccellente e l‚Äôerrore nella stima dell‚ÄôELPD √® trascurabile.\n\\(0.5 \\leq k &lt; 0.7\\): Indica che l‚Äôapprossimazione √® accettabile, ma potrebbe essere opportuno esaminare pi√π a fondo il modello e i dati.\n\\(0.7 \\leq k &lt; 1\\): Suggerisce che l‚Äôapprossimazione sta diventando mediocre, rendendo i risultati della LOO-CV meno affidabili e potenzialmente inadeguati.\n\\(k \\geq 1\\): Un valore cos√¨ alto segnala un‚Äôapprossimazione inadeguata e suggerisce che i risultati ottenuti potrebbero essere molto lontani dalla realt√†, indicando la presenza di problemi nel modello o nella metodologia.\n\nIl valore di Pareto \\(k\\) si basa sulla distribuzione di Pareto per valutare le discrepanze nelle log-verosimiglianze, ovvero le differenze tra la log-verosimiglianza calcolata eliminando un dato e quella ottenuta sull‚Äôintero dataset. Valori elevati di \\(k\\) indicano che ci sono code pi√π pesanti del previsto nella distribuzione delle discrepanze, suggerendo che l‚Äôapprossimazione potrebbe non essere precisa.\nIn sintesi, i valori di Pareto \\(k\\) offrono un indicatore affidabile dell‚Äôaccuratezza dell‚Äôapprossimazione fornita dalla LOO-CV e sono utili per identificare eventuali problemi nel modello statistico o nella metodologia impiegata.\nConvertiamo l‚Äôoggetto creato da cmdstanpy nella classe InferenceData richiesta da ArviZ:\n\nfit_az = az.from_cmdstanpy(posterior=fit)\n\nEseguiamo LOO-CV usando ArviZ:\n\nloo_result = az.loo(fit_az)\nprint(loo_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -212.67     6.84\np_loo        1.90        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_stan_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "href": "chapters/entropy/03_stan_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "title": "76¬† Validazione Incrociata Leave-One-Out",
    "section": "76.4 Il Ruolo dell‚ÄôELPD nella Valutazione Comparativa dei Modelli",
    "text": "76.4 Il Ruolo dell‚ÄôELPD nella Valutazione Comparativa dei Modelli\nL‚ÄôELPD √® fondamentale per il confronto di diversi modelli statistici. Utilizzando metodologie come la LOO-CV per stimare l‚ÄôELPD, possiamo ottenere una valutazione oggettiva dell‚Äôadeguatezza di ciascun modello rispetto ai dati. Questo √® cruciale nella scelta del modello pi√π adatto tra diverse alternative o nel decidere se un modello pi√π complesso offre un miglior adattamento rispetto a uno pi√π semplice.\nIn conclusione, l‚ÄôELPD agisce come un indicatore affidabile della capacit√† predittiva di un modello. La LOO-CV, a sua volta, fornisce un modo efficace per stimare questa metrica, permettendo analisi precise e robuste delle prestazioni di diversi modelli. L‚Äôautomazione di queste procedure di valutazione attraverso software come PyMC e Arviz rende l‚Äôapproccio ancora pi√π pratico e accessibile, consolidandone il ruolo come strumento essenziale per la selezione e la validazione di modelli statistici.\n\n76.4.1 Simulazione\nPer illustrare il confronto tra modelli utilizzando la LOO-CV, procediamo con una simulazione. Genereremo dati sintetici in cui esiste una relazione lineare tra le variabili \\(x\\) e \\(y\\). In questo scenario, potremmo essere interessati a confrontare un modello lineare con un modello pi√π semplice, che considera solo il termine di intercetta. Utilizzeremo la LOO-CV per stabilire quale dei due modelli si adatta meglio ai dati in questione. La stima dell‚ÄôELPD servir√† come criterio quantitativo per orientare questa scelta di modello.\n\n# Generate synthetic data\nnp.random.seed(42)\nx = np.linspace(0, 10, 100)\ny_true = 3 + 2 * x\ny_obs = y_true + np.random.normal(scale=3, size=100)\nzx = stats.zscore(x)\nzy = stats.zscore(y_obs)\nprint(np.mean(zy), np.std(zy))\n\n-2.19824158875781e-16 1.0\n\n\nAdattiamo ai dati un modello che rispecchia il vero meccanismo generativo dei dati.\nSi noti che, per calcolare LOO e WAIC, ArviZ ha bisogno di accedere alla log-likelihood per ogni campione posteriore. Possiamo trovarla tramite compute_log_likelihood(). In alternativa, possiamo passare idata_kwargs={\"log_likelihood\": True} a sample() per farla calcolare automaticamente alla fine del campionamento.\n\nstan_lin_reg_file = os.path.join(\n    project_directory, 'stan', 'linear-regression.stan')\n\nmodel_lin_reg = CmdStanModel(stan_file=stan_lin_reg_file)\nprint(model_lin_reg.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha + beta * x[n], sigma);\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\n\n# Prepare the stan_data dictionary\nstan_data = {\n    'N': len(zx),\n    'x': zx,\n    'y': zy\n}\nprint(stan_data)\n\n{'N': 100, 'x': array([-1.71481604, -1.68017329, -1.64553055, -1.6108878 , -1.57624505,\n       -1.5416023 , -1.50695955, -1.4723168 , -1.43767406, -1.40303131,\n       -1.36838856, -1.33374581, -1.29910306, -1.26446031, -1.22981757,\n       -1.19517482, -1.16053207, -1.12588932, -1.09124657, -1.05660382,\n       -1.02196108, -0.98731833, -0.95267558, -0.91803283, -0.88339008,\n       -0.84874733, -0.81410459, -0.77946184, -0.74481909, -0.71017634,\n       -0.67553359, -0.64089084, -0.6062481 , -0.57160535, -0.5369626 ,\n       -0.50231985, -0.4676771 , -0.43303435, -0.39839161, -0.36374886,\n       -0.32910611, -0.29446336, -0.25982061, -0.22517786, -0.19053512,\n       -0.15589237, -0.12124962, -0.08660687, -0.05196412, -0.01732137,\n        0.01732137,  0.05196412,  0.08660687,  0.12124962,  0.15589237,\n        0.19053512,  0.22517786,  0.25982061,  0.29446336,  0.32910611,\n        0.36374886,  0.39839161,  0.43303435,  0.4676771 ,  0.50231985,\n        0.5369626 ,  0.57160535,  0.6062481 ,  0.64089084,  0.67553359,\n        0.71017634,  0.74481909,  0.77946184,  0.81410459,  0.84874733,\n        0.88339008,  0.91803283,  0.95267558,  0.98731833,  1.02196108,\n        1.05660382,  1.09124657,  1.12588932,  1.16053207,  1.19517482,\n        1.22981757,  1.26446031,  1.29910306,  1.33374581,  1.36838856,\n        1.40303131,  1.43767406,  1.4723168 ,  1.50695955,  1.5416023 ,\n        1.57624505,  1.6108878 ,  1.64553055,  1.68017329,  1.71481604]), 'y': array([-1.25369697, -1.51410888, -1.12264904, -0.69018101, -1.46541976,\n       -1.43451905, -0.57172677, -0.91324793, -1.44980379, -0.95462592,\n       -1.38523884, -1.35540634, -0.99984973, -1.95770364, -1.84039662,\n       -1.27613083, -1.45193071, -0.81222207, -1.34206267, -1.54251469,\n       -0.19132131, -0.9363926 , -0.77094195, -1.42465105, -0.98987813,\n       -0.65835464, -1.20638283, -0.47509892, -0.89211361, -0.71948769,\n       -0.83081717,  0.32587522, -0.49918168, -0.94733587, -0.05384951,\n       -0.96038888, -0.27359788, -1.23754931, -0.91695414, -0.18642458,\n        0.09293748, -0.13633347, -0.23711307, -0.29130011, -0.80056374,\n       -0.42161671, -0.27180948,  0.4553774 ,  0.15894085, -0.77662445,\n        0.21176558, -0.082681  , -0.18567329,  0.43638204,  0.65964551,\n        0.64479105, -0.13655587,  0.13748445,  0.46220469,  0.78867095,\n        0.15219165,  0.31773898, -0.07374059, -0.08407726,  0.86834951,\n        1.14867904,  0.52434286,  1.04865616,  0.78507034,  0.35410049,\n        0.84674641,  1.41743978,  0.72630189,  1.49143251, -0.3973201 ,\n        1.21247617,  0.90624433,  0.76002975,  0.97019317,  0.04716531,\n        0.88910552,  1.18460649,  1.72967356,  0.84479898,  0.7425482 ,\n        0.91416098,  1.59519538,  1.35695436,  0.99399369,  1.50339012,\n        1.34335048,  1.77408719,  1.03852468,  1.24117485,  1.24250254,\n        0.78187315,  1.62002314,  1.63482977,  1.54830613,  1.46923337])}\n\n\n\nfit2 = model_lin_reg.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit2, var_names=['beta', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta\n0.91\n0.04\n0.82\n0.99\n0.0\n0.0\n7552.03\n5699.11\n1.0\n\n\nsigma\n0.42\n0.03\n0.37\n0.48\n0.0\n0.0\n7001.46\n5200.57\n1.0\n\n\n\n\n\n\n\n\nReplichiamo i risultati usando le funzioni di pingouin:\n\n# Create a DataFrame\ndf = pd.DataFrame({\n    \"x\": zx,\n    \"y\": zy\n})\n\n# Perform linear regression using pingouin\nregression_results = pg.linear_regression(df[['x']], df['y'])\n\n# Print the regression results\nprint(regression_results)\n\n       names          coef        se             T          pval        r2  \\\n0  Intercept -2.220446e-16  0.041834 -5.307754e-15  1.000000e+00  0.828492   \n1          x  9.102152e-01  0.041834  2.175778e+01  2.661609e-39  0.828492   \n\n     adj_r2  CI[2.5%]  CI[97.5%]  \n0  0.826742 -0.083018   0.083018  \n1  0.826742  0.827197   0.993233  \n\n\nTroviamo ELPD con il metodo LOO-CV per il modello lineare.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit2_az = az.from_cmdstanpy(posterior=fit2)\n# Perform LOO-CV using ArviZ\nloo2_result = az.loo(fit2_az)\nprint(loo2_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -56.81     6.89\np_loo        2.87        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nAdattiamo ora un secondo modello che non tiene conto della relazione lineare tra \\(x\\) e \\(y\\).\n\nstan_lin_reg_file_only_alpha = os.path.join(\n    project_directory, 'stan', 'linear-regression-only-alpha.stan')\n\nmodel_lin_reg_only_alpha = CmdStanModel(stan_file=stan_lin_reg_file_only_alpha)\nprint(model_lin_reg_only_alpha.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha, sigma);\n  alpha ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha, sigma);\n    y_rep[n] = normal_rng(alpha, sigma);\n  }\n}\n\n\n\n\nfit3 = model_lin_reg_only_alpha.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit3, var_names=['alpha', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.00\n0.10\n-0.19\n0.20\n0.0\n0.0\n6612.61\n5300.73\n1.0\n\n\nsigma\n1.02\n0.07\n0.88\n1.15\n0.0\n0.0\n6998.01\n5550.97\n1.0\n\n\n\n\n\n\n\n\nTroviamo ora ELPD con il metodo LOO-CV per il modello che ignora la relazione lineare.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit3_az = az.from_cmdstanpy(posterior=fit3)\n# Perform LOO-CV using ArviZ\nloo3_result = az.loo(fit3_az)\nprint(loo3_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -143.63     4.52\np_loo        1.40        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nInfine, calcoliamo eldp_diff. L‚Äôincertezza di questa quantit√† √® espressa dall‚Äôerrore standard. Se il rapporto tra eldp_diff e il suo errore standard √® almeno uguale a 2, allora possiamo concludere che vi √® una differenza credibile tra di due modelli.\n\ndf_comp_loo = az.compare({\"linear_model\": loo2_result, \"intercept_model\": loo3_result})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nlinear_model\n0\n-56.814716\n2.873961\n0.000000\n1.000000e+00\n6.890641\n0.000000\nFalse\nlog\n\n\nintercept_model\n1\n-143.633507\n1.403145\n86.818792\n2.428635e-11\n4.516124\n7.956892\nFalse\nlog\n\n\n\n\n\n\n\n\nNel caso presente, sappiamo che il modello che include una relazione lineare tra le due variabili √® quello che rispecchia il modo in cui i dati sono stati generati. Infatti, troviamo che il rapporto tra eldp_diff e il suo errore standard √® molto maggiore di 2, il che conferma che, per questi dati, il modello lineare √® da preferire al modello che include solo l‚Äôintercetta.\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_stan_loo.html#riflessioni-conclusive",
    "href": "chapters/entropy/03_stan_loo.html#riflessioni-conclusive",
    "title": "76¬† Validazione Incrociata Leave-One-Out",
    "section": "76.5 Riflessioni Conclusive",
    "text": "76.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il metodo della Validazione Incrociata LOO-CV come strumento efficace per stimare l‚ÄôELPD. Abbiamo illustrato come la LOO-CV possa essere applicata utilizzando il framework cmdstan, evidenziando il suo ruolo cruciale nella pratica della modellazione statistica.\nUn aspetto centrale che abbiamo esaminato √® l‚Äôimportanza della LOO-CV nel contesto del confronto tra diversi modelli statistici. Questo metodo non solo aiuta a valutare la capacit√† predittiva di un singolo modello, ma si rivela anche essenziale quando si tratta di selezionare il modello pi√π adatto tra un insieme di alternative, fornendo una base di confronto oggettiva e affidabile.\nInoltre, abbiamo discusso il ruolo dei valori diagnostici Pareto \\(k\\) nell‚Äôinterpretazione delle stime ottenute tramite LOO-CV. Abbiamo sottolineato come questi valori siano fondamentali per valutare l‚Äôaffidabilit√† delle stime di ELPD derivate dalla LOO-CV, offrendo una misura della precisione e della robustezza di queste stime.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_stan_loo.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/03_stan_loo.html#informazioni-sullambiente-di-sviluppo",
    "title": "76¬† Validazione Incrociata Leave-One-Out",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html",
    "title": "75¬† Introduzione",
    "section": "",
    "text": "Uno degli sviluppi pi√π importanti della psicologia contemporanea, soprattutto nel campo della psicologia clinica, √® l‚Äôapplicazione di teorie formali per formulare ipotesi sui meccanismi sottostanti i deficit cognitivi che caratterizzano le psicopatologie. Un esempio molto noto √® l‚Äôutilizzo del modello di apprendimento per rinforzo per spiegare i bias cognitivi in varie patologie, tra cui la depressione, i disturbi alimentari e il disturbo ossessivo-compulsivo. Questo campo di studio all‚Äôavanguardia, che non si limita agli esempi citati, √® noto come psichiatria computazionale. In questo capitolo verr√† fornita un‚Äôintroduzione al pi√π famoso di questi modelli: il modello di apprendimento associativo di Rescorla-Wagner.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "",
    "text": "Introduzione\nIn questa sezione delle dispense abbiamo esaminato il modello di regressione. Sebbene il modello di regressione sia estremamente popolare in psicologia e nelle scienze sociali, presenta dei limiti sostanziali. √à utile per descrivere le associazioni tra variabili, ma non √® adatto per scoprire nessi causali, che rappresentano l‚Äôobiettivo principale delle teorie scientifiche. Come afferma Richard McElreath:\nTrovare associazioni nei dati osservazionali non √® un buon metodo per costruire teorie. Abbiamo bisogno di una motivazione per esaminare determinate variabili, poich√© le associazioni tra variabili non sono rare, ma raramente sono causali. Il fatto che nessuno abbia esaminato l‚Äôassociazione tra certe variabili in precedenza non √® un buon motivo per farlo in un nuovo progetto di ricerca.\nUn approccio preferibile, che una volta era comune, √® utilizzare una teoria formale per sviluppare aspettative sui dati osservati, misurare le variabili corrette e utilizzare modelli statistici specifici per testare la teoria, non solo regressioni.\nIn questo capitolo, forniremo un esempio di questo approccio implementando un modello che rappresenta un processo cognitivo sottostante, piuttosto che limitarsi a descrivere le associazioni tra variabili. Nello specifico, esamineremo uno dei modelli psicologici pi√π influenti: il modello di apprendimento di Rescorla-Wagner. Analizzeremo la definizione del modello, il significato dei suoi parametri e i metodi per stimarli dai dati osservati, con particolare attenzione all‚Äôuso della massima verosimiglianza e del software Stan.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#introduzione",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#introduzione",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "",
    "text": "Le persone una volta facevano teoria. Ora fanno solo regressioni.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#lapprendimento-per-rinforzo-imparare-dallesperienza",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#lapprendimento-per-rinforzo-imparare-dallesperienza",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.1 L‚Äôapprendimento per rinforzo: imparare dall‚Äôesperienza",
    "text": "76.1 L‚Äôapprendimento per rinforzo: imparare dall‚Äôesperienza\nImmagina un robot alle prese con un videogioco, privo di istruzioni precise ma con un obiettivo ben chiaro: ottenere il punteggio pi√π alto. Attraverso tentativi ed errori, il robot sperimenta diverse azioni, scoprendo quali lo avvicinano al successo e quali no. Questo √® il principio fondamentale dell‚Äôapprendimento per rinforzo (RL), un metodo di intelligenza artificiale ispirato al modo in cui gli esseri viventi imparano.\n\n76.1.1 Il meccanismo alla base dell‚Äôapprendimento per rinforzo\nNell‚Äôapprendimento per rinforzo, un ‚Äúagente‚Äù (che sia un robot, un modello matematico o una persona) interagisce con un ‚Äúambiente‚Äù. L‚Äôagente compie azioni e riceve in cambio ‚Äúricompense‚Äù positive o negative, a seconda di quanto le sue azioni sono vicine al raggiungimento del suo obiettivo. L‚Äôobiettivo dell‚Äôagente √® imparare a scegliere le azioni che gli permetteranno di ottenere il maggior numero di ricompense positive nel tempo.\n\n\n76.1.2 Esplorazione e sfruttamento\nUno dei dilemmi principali che gli agenti di apprendimento per rinforzo si trovano ad affrontare √® il bilanciamento tra esplorazione e sfruttamento. Da un lato, l‚Äôagente ha bisogno di esplorare l‚Äôambiente, provare nuove azioni e scoprire nuove strategie per ottenere ricompense. Dall‚Äôaltro lato, desidera anche sfruttare la conoscenza gi√† acquisita, scegliendo le azioni che ha gi√† scoperto essere efficaci in passato.\n\n\n76.1.3 L‚Äôapprendimento per rinforzo nella ricerca sull‚Äôintelligenza artificiale\nDalla fine degli anni ‚Äô60, molti ricercatori nel campo dell‚Äôintelligenza artificiale hanno ipotizzato che non esistano principi generali da scoprire, e che l‚Äôintelligenza derivi piuttosto dalla conoscenza di un vasto numero di trucchi, procedure ed euristiche specializzati. L‚Äôintelligenza artificiale moderna dedica invece molta attenzione alla ricerca di principi generali di apprendimento e processo decisionale. In questo senso, la ricerca sull‚Äôapprendimento per rinforzo rappresenta sicuramente un ritorno verso principi di intelligenza artificiale pi√π semplici e universali.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#un-esempio-pratico-il-problema-dei-two-armed-bandits",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#un-esempio-pratico-il-problema-dei-two-armed-bandits",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.2 Un esempio pratico: il problema dei two-armed bandits",
    "text": "76.2 Un esempio pratico: il problema dei two-armed bandits\nImmaginiamo un giocatore di fronte a due slot machine. Ogni volta che sceglie una slot, pu√≤ vincere (ottenendo un premio) o perdere (non ottenendo nulla). La probabilit√† di vincita varia tra le due slot machine, ma il giocatore non le conosce all‚Äôinizio. Il suo obiettivo √® massimizzare le vincite scegliendo la slot machine con la maggiore probabilit√† di vincita il pi√π spesso possibile.\nQuesto semplice problema illustra il dilemma fondamentale dell‚Äôapprendimento per rinforzo: esplorare entrambe le slot machine per scoprire quale √® la migliore (esplorazione) o sfruttare la slot machine che ha gi√† scoperto essere la pi√π vincente (sfruttamento)?\nIl modello di apprendimento di Rescorla-Wagner affronta proprio questo problema del ‚Äútwo-armed bandits‚Äù. In questo scenario, un partecipante deve compiere ripetutamente delle scelte tra due opzioni o azioni. Dopo ogni scelta, riceve una ricompensa numerica estratta da una distribuzione di probabilit√† che dipende dall‚Äôazione selezionata. L‚Äôobiettivo del partecipante √® massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte.\nUna metafora comune per descrivere questa situazione √® quella di un giocatore che deve fare una serie di scelte tra due slot machine (‚Äútwo-armed bandits‚Äù) per massimizzare le sue vincite. Se nella scelta \\(t\\) viene selezionata la slot machine \\(k\\), il partecipante ottiene una ricompensa \\(r_t\\). Questa ricompensa ha valore 1 con una probabilit√† di successo \\(\\mu^k_t\\) specifica per quella slot machine, altrimenti ha valore 0.\nIn altre parole:\n\nOgni volta che il partecipante sceglie una slot machine, pu√≤ vincere (ottenendo una ricompensa di 1) o perdere (ottenendo una ricompensa di 0).\nLa probabilit√† di vincita varia tra le due diverse slot machine.\nQueste probabilit√† di successo sono inizialmente sconosciute al partecipante.\n\nNella versione pi√π semplice di questo problema, le probabilit√† di successo \\(\\mu^k_t\\) rimangono costanti nel tempo. Questo significa che la probabilit√† di vincere su una determinata slot machine non cambia durante il periodo di osservazione.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#simulare-lapprendimento",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#simulare-lapprendimento",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.3 Simulare l‚ÄôApprendimento",
    "text": "76.3 Simulare l‚ÄôApprendimento\nNel problema del two-armed bandit, ogni azione (cio√® la scelta di una specifica slot machine) ha un valore associato che rappresenta la ricompensa attesa quando quella specifica azione viene selezionata. Questo valore √® chiamato ‚Äúvalore dell‚Äôazione‚Äù. Conoscendo il valore di ogni azione, il problema di apprendimento si riduce a scegliere sempre l‚Äôazione con il valore pi√π alto per massimizzare la ricompensa totale.\n\n76.3.1 Parametri del Problema\nPer simulare il problema, dobbiamo considerare tre parametri principali:\n\nIl numero di tentativi, \\(T\\): Questo rappresenta quante volte il partecipante far√† una scelta. Ad esempio, se \\(T = 100\\), il partecipante far√† 100 scelte.\nIl numero di slot machine, \\(K\\): Questo indica quante opzioni di scelta sono disponibili. Ad esempio, se \\(K = 2\\), ci sono due slot machine tra cui scegliere.\nLe probabilit√† di ricompensa delle diverse opzioni, \\(\\mu^k_t\\): Queste sono le probabilit√† che ogni slot machine offra una ricompensa. Queste probabilit√† possono variare nel tempo, ma nella versione pi√π semplice del problema, rimangono costanti.\n\n\n\n76.3.2 Esempio Pratico\nIn questo tutorial, simuleremo il comportamento di un partecipante che sceglie tra due slot machine, utilizzando il modello di apprendimento di Rescorla-Wagner. Ecco come configureremo la simulazione:\n\nImposteremo il numero di tentativi a \\(T = 100\\). Questo significa che il partecipante far√† 100 scelte.\nImposteremo il numero di slot machine a \\(K = 2\\). Ci saranno quindi due slot machine tra cui scegliere.\nImposteremo le probabilit√† di ricompensa delle slot machine a \\(\\mu = [0.2, 0.8]\\). Questo significa che la slot machine 1 ha una probabilit√† del 20% di offrire una ricompensa, mentre la slot machine 2 ha una probabilit√† dell‚Äô80% di offrire una ricompensa.\n\nOgni azione ha un valore che rappresenta la ricompensa attesa. In altre parole, il valore dell‚Äôazione √® la media delle ricompense che ci si aspetta di ottenere scegliendo quella particolare azione. Se si conosce questo valore per ogni azione, il partecipante dovrebbe sempre scegliere l‚Äôazione con il valore pi√π alto per massimizzare le sue ricompense.\nL‚Äôobiettivo di questo tutorial √® mostrare come si pu√≤ simulare il processo di apprendimento e come si possono usare modelli come quello di Rescorla-Wagner per capire meglio come le persone prendono decisioni in situazioni di incertezza. Attraverso la simulazione, vedremo come il partecipante pu√≤ apprendere e adattarsi alle probabilit√† di ricompensa delle slot machine per massimizzare le sue vincite nel corso del tempo.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#imparare-il-rinforzo-i-componenti-chiave",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#imparare-il-rinforzo-i-componenti-chiave",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.4 Imparare il rinforzo: i componenti chiave",
    "text": "76.4 Imparare il rinforzo: i componenti chiave\nL‚Äôapprendimento per rinforzo √® simile a come gli esseri viventi imparano attraverso l‚Äôesperienza: provando e sbagliando, imparano ad associare le loro azioni a conseguenze positive o negative.\nPer comprendere meglio il funzionamento dell‚Äôapprendimento per rinforzo, √® fondamentale analizzare i suoi quattro componenti chiave.\n1. La politica (o strategia) Il robot non agisce a caso. Ha una strategia, un piano d‚Äôazione che cambia nel tempo in base ai risultati ottenuti. Inizialmente, potrebbe scegliere le slot casualmente (50% leva A, 50% leva B). Ma con l‚Äôesperienza, impara a preferire la leva che gli ha dato pi√π vincite. In termini tecnici, la strategia √® rappresentata dalla funzione œÄ (pi), che associa le azioni possibili (tirare la leva A o B) ai diversi stati del gioco (vincita, perdita). All‚Äôinizio, œÄ potrebbe essere casuale. Ma con il tempo, si aggiorna in base alle ricompense ricevute, aumentando la probabilit√† di scegliere la leva vincente.\n2. La ricompensa La ricompensa √® un segnale che indica all‚Äôagente la bont√† o meno delle sue azioni. La ricompensa pu√≤ essere positiva (rinforzo) se l‚Äôazione √® stata vantaggiosa, o negativa (punizione) se l‚Äôazione √® stata dannosa. L‚Äôobiettivo dell‚Äôagente √® massimizzare la ricompensa cumulativa nel lungo periodo. In termini tecnici, la funzione di ricompensa R assegna un valore numerico a ogni stato del gioco: 1 per la vincita e 0 per la perdita. Il robot √® ‚Äúmotivato‚Äù a massimizzare la ricompensa cumulativa, ovvero la somma totale delle vincite ottenute nel tempo.\n3. La funzione di valore Per ogni leva, il robot calcola la ricompensa media che si aspetta di ricevere in futuro. In altre parole, cerca di capire quale slot √® pi√π ‚Äúgenerosa‚Äù nel lungo periodo. In termini tecnici, la funzione di valore Q stima la ricompensa media attesa per ogni stato del gioco. Il robot utilizza questa stima per scegliere l‚Äôazione che lo porter√† nello stato con il valore Q pi√π alto, ovvero la slot machine che ha maggiori probabilit√† di fargli ottenere una vincita nel lungo periodo.\n4. Il modello dell‚Äôambiente In alcuni casi, il robot pu√≤ avere un asso nella manica: un modello dell‚Äôambiente, ovvero una simulazione dell‚Äôambiente che permette all‚Äôagente di prevedere le conseguenze delle sue azioni prima di compierle. In termini tecnici, il modello dell‚Äôambiente M √® una simulazione delle slot machine che permette al robot di prevedere la probabilit√† di vincita per ogni leva. Il robot pu√≤ utilizzare questa informazione per aggiornare la sua funzione di valore e scegliere l‚Äôazione che massimizza la ricompensa attesa.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#modello-di-apprenimento-di-rescorla-wagner",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#modello-di-apprenimento-di-rescorla-wagner",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.5 Modello di Apprenimento di Rescorla-Wagner",
    "text": "76.5 Modello di Apprenimento di Rescorla-Wagner\nIl modello di apprendimento di Rescorla-Wagner, sviluppato per comprendere come gli esseri viventi apprendono le associazioni tra eventi, √® particolarmente utile nel descrivere l‚Äôapprendimento associativo, come il condizionamento classico. Il modello si basa sull‚Äôidea che l‚Äôapprendimento avvenga attraverso l‚Äôaggiornamento continuo delle aspettative sulla base degli errori di previsione. In altre parole, la differenza tra ci√≤ che ci si aspetta di ricevere e ci√≤ che viene effettivamente osservato determina come modifichiamo le nostre aspettative per il futuro.\n\n76.5.1 Aspettativa di Valore\nImmaginiamo un problema con due bandit a due braccia: ogni braccio rappresenta un‚Äôazione con una specifica ricompensa media associata. Il valore di un‚Äôazione corrisponde alla sua ricompensa media attesa.\nIndichiamo con:\n\n\\(A_t\\): l‚Äôazione scelta al tempo \\(t\\);\n\\(R_t\\): la ricompensa ottenuta dopo aver scelto l‚Äôazione \\(A_t\\);\n\\(q^{*}(a)\\): il valore atteso dell‚Äôazione \\(a\\) (ovvero la ricompensa media attesa se scegliamo \\(a\\)).\n\nSe conoscessimo il valore esatto di ogni azione, il problema del bandit a due braccia sarebbe banale: basterebbe scegliere sempre l‚Äôazione con il valore pi√π alto. Tuttavia, in realt√†, non conosciamo con certezza i valori delle azioni, ma possiamo solo stimarli.\nIndichiamo con \\(Q_t(a)\\) la stima del valore dell‚Äôazione \\(a\\) al tempo t. L‚Äôobiettivo √® far s√¨ che \\(Q_t(a)\\) si avvicini il pi√π possibile al valore reale \\(q^{*}(a)\\).\n\n\n76.5.2 La Regola di Apprendimento\nSecondo il modello Rescorla-Wagner, il valore atteso di un‚Äôazione viene aggiornato dopo ogni tentativo usando la seguente regola:\n\\[Q_k(t + 1) = Q_k(t) + \\alpha (R_k - Q_k(t))\\]\ndove:\n\n\\(Q_k(t)\\): valore atteso dell‚Äôazione k al tempo t\n\\(\\alpha\\): tasso di apprendimento, un valore compreso tra 0 e 1 che determina la velocit√† di aggiornamento delle aspettative. Un valore pi√π alto di Œ± implica un apprendimento pi√π rapido, mentre uno pi√π basso implica un apprendimento pi√π lento.\n\\(R_k\\): ricompensa ottenuta dopo aver scelto l‚Äôazione k al tempo t\n\\(R_k - Q_k(t)\\): errore di previsione, la differenza tra la ricompensa ottenuta e quella attesa\n\nIn parole semplici, l‚Äôerrore di previsione guida l‚Äôaggiornamento delle nostre aspettative: se la ricompensa √® maggiore del previsto, il valore dell‚Äôazione viene aumentato; se la ricompensa √® minore del previsto, il valore dell‚Äôazione viene diminuito.\n\n\n76.5.3 La Regola Decisionale\nPer decidere quale azione intraprendere, utilizziamo la regola softmax, che bilancia l‚Äôesplorazione di nuove opzioni con la scelta dell‚Äôazione con il valore atteso pi√π alto. La regola softmax trasforma i valori attesi Q in probabilit√† di scelta:\n\\[p_k(t) = \\frac{exp(\\theta Q_k(t))}{\\sum_{i=1}^K exp(\\theta Q_i(t))}\\]\ndove:\n\n\\(p_k(t)\\): probabilit√† di scegliere l‚Äôazione k al tempo t\n\\(\\theta\\): parametro temperatura che controlla il livello di esplorazione. Valori alti di \\(\\theta\\) portano a scelte pi√π deterministiche (quasi sempre l‚Äôazione con il valore pi√π alto), mentre valori bassi portano a scelte pi√π casuali.\n\n\n76.5.3.1 Esempio di Calcolo della Softmax\nPer capire come funziona la softmax, consideriamo alcuni valori di \\(Q\\) e \\(\\theta\\).\n\ndef softmax(Q, theta):\n    p = np.exp(theta * Q) / np.sum(np.exp(theta * Q))\n    return p\n\nQ = np.array([0.25, 0.75])\ntheta = 3.5\nprint(softmax(Q, theta))\n\n[0.1480472 0.8519528]\n\n\n\ntheta = 0.5\nprint(softmax(Q, theta))\n\n[0.4378235 0.5621765]\n\n\nLa funzione softmax trasforma i valori \\(Q\\) e \\(\\theta\\) in una distribuzione di probabilit√†, mostrando come la probabilit√† di scelta cambia al variare di \\(\\theta\\).\n\n\n\n76.5.4 Variazione di \\(\\theta\\) con Valori Fissi di \\(Q\\)\nManteniamo fissi i valori di \\(Q\\) e facciamo variare \\(\\theta\\):\n\nQ = np.array([0.1, 0.75])\ntheta_values = np.linspace(0, 5, 100)\n\nprobabilities_list = []\nfor theta in theta_values:\n    probabilities = softmax(Q, theta)\n    probabilities_list.append(probabilities)\n    \nprobabilities_array = np.array(probabilities_list).T\n\noption_labels = ['Opzione 1', 'Opzione 2']\n\nplt.figure()\nfor i in range(len(option_labels)):\n    plt.plot(theta_values, probabilities_array[i], label=option_labels[i])\n\nplt.xlabel('Theta')\nplt.ylabel('Probabilit√†')\nplt.title('Funzione Softmax - Modello Rescorla-Wagner')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico risultante mostra come le probabilit√† di scelta cambiano al variare del parametro \\(\\theta\\). Quando \\(\\theta\\) √® vicino a zero, la scelta √® quasi casuale. Quando \\(\\theta\\) √® molto grande, la scelta √® quasi sempre l‚Äôopzione con il valore pi√π alto.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.6 Simulazione del Modello di Rescorla-Wagner",
    "text": "76.6 Simulazione del Modello di Rescorla-Wagner\nCombiniamo la regola di apprendimento e la regola decisionale per simulare il comportamento del partecipante:\n\ndef simulate_RescorlaWagner(params, T, mu, noisy_choice=True):\n\n    alpha, theta = params\n    \n    # Un array di zeri di lunghezza T\n    c = np.zeros((T), dtype=int)\n    r = np.zeros((T), dtype=int)\n\n    # Un array multidimensionale di zeri di dimensione 2xT\n    Q_stored = np.zeros((2, T), dtype=float)\n    \n    # Inizializza Q per t == 0\n    Q = [0.5, 0.5]\n\n    for t in range(T):\n\n        # Salva i valori Q per Q_{t+1}\n        Q_stored[:, t] = Q\n\n        # Calcola le probabilit√† di scelta\n        p0 = np.exp(theta*Q[0]) / (np.exp(theta*Q[0]) + np.exp(theta*Q[1]))\n        p1 = 1 - p0\n        \n        # Se noisy_choice √® vero, viene simulato un comportamento di scelta rumoroso in \n        # cui l'opzione 0 √® scelta con probabilit√† p0, mentre l'opzione 1 √® scelta con \n        # probabilit√† 1-p0.\n        if noisy_choice:\n            if np.random.random_sample(1) &lt; p0:\n                c[t] = 0\n            else:\n                c[t] = 1\n        else:  # la scelta viene effettuata senza rumore\n            c[t] = np.argmax([p0, p1])\n\n        # Genera la ricompensa sulla base delle probabilit√† di ricompensa\n        r[t] = np.random.rand() &lt; mu[c[t]]\n\n        # Aggiorna le aspettative di valore\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    return c, r, Q_stored\n\nSimuliamo T = 100 prove utilizzando il modello generativo dei dati definito in precedenza.\n\nT = 100\nK = 2\nmu = [0.2, 0.8]\n\n\nc, r, Q = simulate_RescorlaWagner([.1, 2.5], T=T, mu=mu)\n\nRappresentiamo graficamente i risultati ottenuti dalla simulazione.\n\nplt.plot(range(T), r, 'r--', alpha=.6)\nplt.plot(range(T), c, '+', label='scelta')\nplt.xlabel('Prove')\nplt.ylabel('Feedback (1=Ricompensa,\\n 0=Nessuna ricompensa)')\nplt.title(f'Apprendimento di Rescorla-Wagner')\nplt.show()\n\n\n\n\n\n\n\n\nCome possiamo osservare, le scelte per la slot machine che produce meno ricompense diventano meno frequenti nel corso delle prove.\nPossiamo anche rappresentare graficamente le aspettative di valore \\(Q\\) delle due slot machine nel corso delle prove.\n\nplt.plot(range(T), Q[1, :], 'r--', alpha=.6, label='80% machine')\nplt.plot(range(T), Q[0, :], 'm-', alpha=.6, label='20% machine')\nplt.plot(range(T), c, 'b+', label='choice')\nplt.xlabel('trials')\nplt.ylabel('value')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi noti come nel corso delle prove i valori delle slot macchine convergano lentamente verso le probabilit√† di ricompensa (20% e 80%).\nIn sintesi, il modello di Rescorla-Wagner ci permette di simulare come le persone apprendono e prendono decisioni basate su ricompense. Utilizzando la regola di apprendimento (\\(\\delta\\)-rule) e la regola decisionale softmax, possiamo vedere come le aspettative di valore e le scelte cambiano nel tempo in risposta alle ricompense ottenute.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#adattamento-del-modello",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#adattamento-del-modello",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.7 Adattamento del Modello",
    "text": "76.7 Adattamento del Modello\nDopo aver visto come funziona il modello di Rescorla-Wagner, il passo successivo √® stimare i parametri del modello a partire dai dati osservati. Questo processo √® fondamentale nella modellazione computazionale perch√© ci permette di capire quali valori dei parametri descrivono meglio il comportamento osservato. Esistono diversi metodi per stimare i parametri, ma ci concentreremo sull‚Äôapproccio della Massima Verosimiglianza.\n\n76.7.1 La Massima Verosimiglianza\nL‚Äôapproccio della massima verosimiglianza cerca di trovare i valori dei parametri del modello che massimizzano la probabilit√† dei dati osservati. In altre parole, vogliamo trovare i parametri \\((\\alpha, \\theta)\\) che rendono i dati osservati \\(d_{1:T}\\) pi√π probabili secondo il modello Rescorla-Wagner.\n\n\n76.7.2 Calcolo del Logaritmo della Verosimiglianza\nMassimizzare la verosimiglianza √® spesso pi√π facile se si lavora con il logaritmo della verosimiglianza, perch√© le moltiplicazioni di probabilit√† diventano somme. La log-verosimiglianza pu√≤ essere espressa come:\n\\[\n\\log \\mathcal{L} = \\log p(d_{1:T} | (\\alpha, \\theta)_m, m) = \\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nIn questa equazione:\n\n\\(\\log \\mathcal{L}\\) √® il logaritmo della verosimiglianza.\n\\(p(d_{1:T} | (\\alpha, \\theta)_m, m)\\) √® la probabilit√† dei dati osservati dato il modello e i parametri.\n\\(p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\\) √® la probabilit√† di ogni singola scelta \\(c_t\\) data la storia delle scelte e dei feedback fino al tempo \\(t\\) e i parametri del modello.\n\n\n\n76.7.3 Minimizzazione del Logaritmo Negativo della Verosimiglianza\nIn pratica, massimizzare la log-verosimiglianza √® equivalente a minimizzare il logaritmo negativo della verosimiglianza. Questo ci porta alla seguente equazione:\n\\[\n-\\log \\mathcal{L} = -\\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nPer applicare questa procedura al modello di Rescorla-Wagner, dobbiamo definire la funzione di log-verosimiglianza negativa specifica per il nostro modello. Questa funzione ci permette di calcolare quanto bene i parametri \\(\\alpha\\) e \\(\\theta\\) spiegano i dati osservati. Durante il processo di stima, l‚Äôobiettivo √® minimizzare questa funzione per trovare i valori ottimali dei parametri.\n\n\n76.7.4 Esempio Pratico\nImmaginiamo di avere dati osservati da un esperimento in cui un partecipante ha fatto 100 scelte tra due slot machine. Il nostro obiettivo √® stimare i parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura) che meglio spiegano queste scelte. Per fare ci√≤, utilizziamo il metodo della massima verosimiglianza.\nLa seguente funzione negll_RescorlaWagner calcola il negativo della log-verosimiglianza per il modello di apprendimento di Rescorla-Wagner. Questo ci permette di capire quanto bene i parametri del modello (\\(\\alpha\\) e \\(\\theta\\)) spiegano le scelte osservate. Ecco una spiegazione passo passo per capire come funziona questa funzione.\nI parametri della Funzione sono:\n\nparams: una lista che contiene i valori dei parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura).\nc: un array che contiene le scelte effettuate dal partecipante (0 o 1).\nr: un array che contiene le ricompense ricevute dopo ogni scelta (1 per ricompensa, 0 per nessuna ricompensa).\n\nEsaminiamo ora il corpo della funzione.\n\nInizializzazione dei Parametri\nalpha, theta = params\nQ = [0.5, 0.5]\nT = len(c)\nchoiceProb = np.zeros((T), dtype=float)\n\nalpha e theta sono estratti dalla lista params.\nQ √® una lista che tiene traccia delle aspettative di valore per le due slot machine, inizializzate a 0.5.\nT √® il numero di scelte effettuate.\nchoiceProb √® un array che memorizza la probabilit√† di ogni scelta effettuata.\n\nCalcolo delle Probabilit√† di Scelta e Aggiornamento dei Valori\nfor t in range(T):\n    p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n    p = [p0, 1 - p0]\n    choiceProb[t] = p[c[t]]\n    delta = r[t] - Q[c[t]]\n    Q[c[t]] = Q[c[t]] + alpha * delta\n\nCalcolo delle Probabilit√† di Scelta:\n\np0 √® la probabilit√† di scegliere la prima slot machine.\np √® una lista delle probabilit√† di scegliere ciascuna delle due slot machine.\nchoiceProb[t] memorizza la probabilit√† della scelta effettivamente fatta al tempo \\(t\\).\n\nAggiornamento delle Aspettative di Valore:\n\ndelta √® la differenza tra la ricompensa effettiva r[t] e l‚Äôaspettativa di valore Q[c[t]] per la scelta fatta.\nQ[c[t]] viene aggiornata secondo la regola di Rescorla-Wagner: il nuovo valore atteso √® il vecchio valore atteso pi√π una frazione (determinata da \\(\\alpha\\)) dell‚Äôerrore di previsione.\n\n\nCalcolo del Negativo della Log-Verosimiglianza\nnegLL = -np.sum(np.log(choiceProb))\nreturn negLL\n\nLog-Verosimiglianza:\n\nnp.log(choiceProb) calcola il logaritmo delle probabilit√† di scelta.\nnp.sum(np.log(choiceProb)) somma questi logaritmi.\n\nNegativo della Log-Verosimiglianza:\n\nIl risultato √® moltiplicato per -1 per ottenere il negativo della log-verosimiglianza, poich√© nella stima dei parametri cerchiamo di minimizzare questa funzione.\n\n\n\nIn sintesi, la funzione negll_RescorlaWagner:\n\nCalcola le probabilit√† di scelta basate sui parametri \\(\\alpha\\) e \\(\\theta\\).\nAggiorna le aspettative di valore in base alle scelte e alle ricompense osservate.\nCalcola il negativo della log-verosimiglianza per valutare quanto bene i parametri spiegano i dati osservati.\n\nEcco la funzione completa con commenti per facilitarne la comprensione:\n\ndef negll_RescorlaWagner(params, c, r):\n    alpha, theta = params\n    Q = [0.5, 0.5]\n    T = len(c)\n    choiceProb = np.zeros((T), dtype=float)\n\n    for t in range(T):\n        # Calcola le probabilit√† di scelta per k = 2\n        p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n        # \"p\" √® una lista di probabilit√† di scelta per le due opzioni disponibili\n        p = [p0, 1 - p0]\n\n        # Memorizza la probabilit√† della scelta effettuata\n        choiceProb[t] = p[c[t]]\n\n        # Aggiorna le aspettative di valore secondo la regola di Rescorla-Wagner\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    # Calcola il negativo della log-verosimiglianza\n    negLL = -np.sum(np.log(choiceProb))\n\n    return negLL\n\nSimuliamo ora un set di dati.\n\n# simulate choices from RW Model\nalpha = .2\ntheta = 1.5\nc, r, Q2 = simulate_RescorlaWagner([alpha, theta], T=T, mu=[.2, .8])\n\nPer fare un esempio, valutiamo la log-verosimiglianza negativa per i dati simulati in corrispondenza dei valori alpha e theta indicati di seguito.\n\nalpha_hat = 0.3\ntheta_hat = 2.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.3 2.5 67.02432583559954\n\n\n\nalpha_hat = 0.2\ntheta_hat = 1.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.2 1.5 62.40238018291291\n\n\nUn metodo per trovare i parametri di massima verosimiglianza √® effettuare una ricerca esaustiva su tutto lo spazio dei parametri. Questo significa selezionare i valori di alpha e theta per i quali la funzione negLL assume il valore pi√π basso.\nPer illustrare questo metodo, applichiamolo a un set di dati simulato. Per semplicit√†, assumiamo di conoscere il valore di \\(\\theta\\) e di dover trovare solo il valore di \\(\\alpha\\).\n\nnLL = []\nalpha_vals = np.linspace(0, 0.5, 1000)\nfor alpha_val in alpha_vals:\n    nLL.append(negll_RescorlaWagner([alpha_val, theta], c, r))\n\nplt.figure()\nplt.plot(alpha_vals, nLL, '-')\nplt.plot(\n    alpha_vals[np.argmin(nLL)], nLL[np.argmin(nLL)],\n    'X', label=r'optimal $\\hat \\alpha$'\n)\nplt.ylabel('negative log likelihood')\nplt.xlabel(fr'learning rate, $\\hat \\alpha$')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n76.7.5 Validazione\nUna volta stabilito un metodo per stimare i parametri del modello dai dati, dobbiamo valutare quanto accuratamente queste stime riflettano i veri valori dei parametri del modello. Per rispondere a questa domanda, possiamo condurre uno studio di simulazione.\nI parametri della simulazione sono i seguenti.\n\nT = 250\nmu = [0.2, 0.8]\nnum_subjects = 20\n\nCalcolimo i valori di massima verosimiglianza dei parametri alpha e theta usando la funzione minimize per minimizzare la funzione di log-verosimiglianza. Simuliamo i dati di un soggetto.\nSpecifichiamo poi le stime iniziali per i valori dei parametri e i valori margine delle possibili soluzioni. I risultati saranno salvati nell‚Äôoggetto result. Le stime dei due parametri si estraggono con result.x.\n\nc, r, Q = simulate_RescorlaWagner([0.15, 1.5], T=T, mu=mu)\n\ninit_guess = (0.1, 0.1)\n\n# minimize neg LL\nresult = minimize(\n    negll_RescorlaWagner,\n    init_guess,\n    (c, r),\n    bounds=((0, 1), (0, 10)),\n)\nprint(result.x)\n\n[0.1093135  1.27704408]\n\n\nSimuliamo i dati per 500 soggetti, con 250 osservazioni ciascuno, utilizzando valori casuali di alpha e theta. Successivamente, eseguiamo la stima di massima verosimiglianza per i dati di ogni soggetto, inizializzando casualmente i parametri per ciascuno di essi. Infine, salviamo i risultati ottenuti nel DataFrame df. Ecco il codice corrispondente:\n\nNREP = 500\ndf = pd.DataFrame(\n    index=range(0, NREP), columns=[\"true_alpha\", \"alpha\", \"true_theta\", \"theta\"]\n)\n\n# loop through subjects\nfor index in range(NREP):\n\n    true_alpha = 0.95 * np.random.random()\n    true_theta = 4.0 * np.random.random()\n\n    c, r, Q = simulate_RescorlaWagner([true_alpha, true_theta], T=250, mu=mu)\n\n    init_guess = (0.2 * np.random.random(), 1.0 * np.random.random())\n    # minimize neg LL\n    param_fits = minimize(\n        negll_RescorlaWagner,\n        init_guess,\n        (c, r),\n        bounds=((0, 1), (0, 10)),\n    )\n\n    # store in dataframe\n    df.at[index, \"true_alpha\"] = true_alpha\n    df.at[index, \"true_theta\"] = true_theta\n    df.at[index, \"alpha\"] = param_fits.x[0]\n    df.at[index, \"theta\"] = param_fits.x[1]\n\nLa figura successiva mostra una corrispondenza tra i valori stimati di alpha e i valori veri. √à importante notare che la corrispondenza non √® perfetta a causa della presenza di una componente di casualit√† nei dati. Inoltre, in alcuni casi si possono osservare valori stimati di alpha pari a 0 o 1, che corrispondono a risultati spurii dell‚Äôalgoritmo. Il numero di risultati spurii aumenta con il diminuire del numero di osservazioni per ciascun soggetto.\n\nplt.plot(df.true_alpha, df.alpha, 'ob', alpha=.4)\nplt.xlabel('True alpha')\nplt.ylabel('Estimated alpha')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nUn discorso analogo si pu√≤ fare per theta, anche se in questo caso vi √® una migliore corrispondenza tra i valori stimati e i valori veri.\n\nplt.plot(df.true_theta, df.theta, 'or', alpha=.4)\nplt.xlabel('True theta')\nplt.ylabel('Estimated theta')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, possiamo affermare che il metodo della massima verosimiglianza √® in grado di recuperare i valori simulati dei parametri \\(\\alpha\\) e \\(\\theta\\) del modello di Rescorla-Wagner, ma solo quando il numero di osservazioni per soggetto √® considerevole. Tuttavia, √® importante notare che questo metodo pu√≤ produrre risultati imprecisi in determinate circostanze.\nEsistono altri metodi di stima che offrono risultati migliori anche con un numero inferiore di osservazioni per soggetto. Tra questi, il metodo gerarchico bayesiano √® ampiamente utilizzato nella pratica. Va precisato che l‚Äôobiettivo di questo tutorial era principalmente illustrare in modo semplice come sia possibile ottenere con buona accuratezza i parametri del modello di Rescorla-Wagner dai dati generati da una simulazione, considerando condizioni ottimali in cui i valori dei parametri del modello sono noti.\n√à importante sottolineare che, nella pratica, la stima dei parametri pu√≤ essere un processo complesso e che l‚Äôaccuratezza delle stime dipende da molteplici fattori, come la dimensione del campione e la natura dei dati osservati. Pertanto, √® sempre consigliabile valutare attentamente i risultati e considerare l‚Äôutilizzo di approcci pi√π sofisticati, come il metodo gerarchico bayesiano, per ottenere stime pi√π affidabili dei parametri del modello.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#stima-con-stan",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#stima-con-stan",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "76.8 Stima con Stan",
    "text": "76.8 Stima con Stan\nConsideriamo ora la stima dei parametri del modello Rescorla-Wagner usando un metodo bayesiano, ovvero mediante Stan. Compiliamo il modello e stampiamo il codice Stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"rescorla_wagner.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:57:16 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/rescorla_wagner.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/rescorla_wagner\n12:57:27 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/rescorla_wagner\n\n\ndata {\n  int&lt;lower=1&gt; nTrials; // numero di tentativi\n  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)\n  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)\n}\ntransformed data {\n  vector[2] initV; // valori iniziali per V\n  initV = rep_vector(0.5, 2); // inizializzati a 0.5\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento\n  real&lt;lower=0&gt; theta; // temperatura\n}\nmodel {\n  vector[2] v; // valori attesi\n  real delta; // errore di previsione\n  \n  // Priori\n  alpha ~ beta(1, 1); // prior uniforme su [0, 1]\n  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10\n  \n  v = initV;\n  \n  for (t in 1 : nTrials) {\n    // Calcolo delle probabilit√† di scelta usando la funzione softmax con limitazione\n    vector[2] logits;\n    logits = theta * v;\n    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow\n    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow\n    \n    choice[t] ~ categorical_logit(logits);\n    \n    // Errore di previsione\n    delta = reward[t] - v[choice[t]];\n    \n    // Aggiornamento dei valori attesi (apprendimento)\n    v[choice[t]] = v[choice[t]] + alpha * delta;\n  }\n}\n\n\n\n\n76.8.1 Sezione data\nQuesta sezione definisce i dati che vengono forniti al modello:\ndata {\n  int&lt;lower=1&gt; nTrials; // numero di tentativi\n  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)\n  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)\n}\n\nnTrials: Il numero totale di tentativi o scelte effettuate dal partecipante.\nchoice: Un array che contiene le scelte effettuate dal partecipante in ciascun tentativo (1 o 2).\nreward: Un array che contiene le ricompense ricevute per ciascun tentativo (0 o 1).\n\n\n\n76.8.2 Sezione transformed data\nQuesta sezione prepara alcuni dati iniziali trasformati per il modello:\ntransformed data {\n  vector[2] initV; // valori iniziali per V\n  initV = rep_vector(0.5, 2); // inizializzati a 0.5\n}\n\ninitV: Un vettore di lunghezza 2 che rappresenta i valori iniziali delle aspettative di ricompensa per le due opzioni, entrambi inizializzati a 0.5.\n\n\n\n76.8.3 Sezione parameters\nQuesta sezione definisce i parametri del modello che Stan cercher√† di stimare:\nparameters {\n  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento\n  real&lt;lower=0&gt; theta; // temperatura\n}\n\nalpha: Il tasso di apprendimento, che determina quanto rapidamente il partecipante aggiorna le proprie aspettative. Questo valore √® compreso tra 0 e 1.\ntheta: La temperatura, che controlla il livello di esplorazione (quanto spesso il partecipante sceglie l‚Äôopzione con il valore atteso pi√π alto rispetto a esplorare altre opzioni). Questo valore √® positivo.\n\n\n\n76.8.4 Sezione model\nQuesta √® la sezione principale che definisce come il modello effettua le stime e aggiorna i valori:\nmodel {\n  vector[2] v; // valori attesi\n  real delta; // errore di previsione\n  \n  // Priori\n  alpha ~ beta(1, 1); // prior uniforme su [0, 1]\n  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10\n  \n  v = initV;\n  \n  for (t in 1 : nTrials) {\n    // Calcolo delle probabilit√† di scelta usando la funzione softmax con limitazione\n    vector[2] logits;\n    logits = theta * v;\n    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow\n    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow\n    \n    choice[t] ~ categorical_logit(logits);\n    \n    // Errore di previsione\n    delta = reward[t] - v[choice[t]];\n    \n    // Aggiornamento dei valori attesi (apprendimento)\n    v[choice[t]] = v[choice[t]] + alpha * delta;\n  }\n}\n\nv: Un vettore che contiene i valori attesi delle ricompense per le due opzioni.\ndelta: La differenza tra la ricompensa ricevuta e il valore atteso (errore di previsione).\n\n\n76.8.4.1 Priori\nLe distribuzioni prior definiscono le nostre convinzioni iniziali sui parametri prima di vedere i dati:\n\nalpha ~ beta(1, 1): Una distribuzione beta uniforme per alpha, che assegna uguale probabilit√† a tutti i valori tra 0 e 1.\ntheta ~ normal(0, 10): Una distribuzione normale per theta con media 0 e deviazione standard 10.\n\n\n\n76.8.4.2 Ciclo sui Tentativi\nPer ogni tentativo, il modello:\n\nCalcola le probabilit√† di scelta utilizzando la funzione softmax, limitando i valori per evitare overflow numerici:\nlogits = theta * v;\nlogits = fmin(logits, 20);\nlogits = fmax(logits, -20);\nchoice[t] ~ categorical_logit(logits);\n\nlogits = theta * v;: logits √® un vettore che contiene i valori trasformati theta * v.\ntheta √® la temperatura, che controlla quanto il partecipante esplora rispetto a sfruttare (scegliere l‚Äôopzione con il valore atteso pi√π alto).\nv sono i valori attesi delle ricompense per le due opzioni.\nlogits = fmin(logits, 20);: Questa funzione assicura che nessun valore in logits sia maggiore di 20. Se un valore √® maggiore di 20, viene impostato a 20.\nlogits = fmax(logits, -20);: Questa funzione assicura che nessun valore in logits sia minore di -20. Se un valore √® minore di -20, viene impostato a -20.\nchoice[t] ~ categorical_logit(logits);: categorical_logit(logits) √® una distribuzione che assegna probabilit√† alle scelte (1 o 2) in base ai valori logits.\n\nMotivazione: Limitare i valori dei logits √® importante per evitare problemi numerici (overflow) quando si calcolano le probabilit√†. Valori estremi di theta * v possono causare risultati non definiti o infiniti, quindi li limitiamo a un intervallo ragionevole (-20 a 20).\nFunzionamento della Funzione categorical_logit:\n\ncategorical_logit(logits) utilizza la funzione softmax per convertire i logits in probabilit√†.\nLa funzione softmax √® definita come:\n\\[\n\\text{softmax}(z_i) = \\frac{\\exp(z_i)}{\\sum_{j=1}^{K} \\exp(z_j)},\n\\]\ndove z_i sono i logits per ciascuna opzione.\nQuesta funzione garantisce che le probabilit√† siano comprese tra 0 e 1 e che la loro somma sia 1.\n\nEsempio Pratico:\nSupponiamo che theta = 1 e i valori attesi siano v = [0.3, 0.7]. I logits sarebbero calcolati come:\nlogits = theta * v; // logits = [1 * 0.3, 1 * 0.7] = [0.3, 0.7]\nlogits = fmin(logits, 20); // nessun valore √® maggiore di 20, quindi rimane [0.3, 0.7]\nlogits = fmax(logits, -20); // nessun valore √® minore di -20, quindi rimane [0.3, 0.7]\nApplicando la funzione softmax:\n\\[\n\\text{softmax}(0.3, 0.7) = \\left( \\frac{\\exp(0.3)}{\\exp(0.3) + \\exp(0.7)}, \\frac{\\exp(0.7)}{\\exp(0.3) + \\exp(0.7)} \\right)\n\\]\nCalcolando le esponenziali e le probabilit√†:\n\\[\n\\exp(0.3) \\approx 1.35, \\quad \\exp(0.7) \\approx 2.01\n\\]\n\\[\n\\text{softmax}(0.3, 0.7) \\approx \\left( \\frac{1.35}{1.35 + 2.01}, \\frac{2.01}{1.35 + 2.01} \\right) = \\left( 0.40, 0.60 \\right)\n\\]\nQuindi, le probabilit√† di scegliere l‚Äôopzione 1 e l‚Äôopzione 2 sono circa 0.40 e 0.60, rispettivamente. Il modello usa queste probabilit√† per determinare quale scelta viene effettivamente fatta al tempo t.\nCalcola l‚Äôerrore di previsione come la differenza tra la ricompensa ricevuta e il valore atteso:\ndelta = reward[t] - v[choice[t]];\nAggiorna i valori attesi utilizzando l‚Äôerrore di previsione e il tasso di apprendimento alpha:\nv[choice[t]] = v[choice[t]] + alpha * delta;\n\nIn sintesi,\n\nI logits sono valori calcolati come theta * v e limitati tra -20 e 20 per evitare problemi numerici.\ncategorical_logit(logits) converte questi logits in probabilit√† utilizzando la funzione softmax.\nLa scelta al tempo t (choice[t]) √® modellata come una variabile categoriale con queste probabilit√†, riflettendo la probabilit√† che il partecipante scelga ciascuna delle opzioni.\nL‚Äôerrore di previsione (delta) √® calcolato come la differenza tra la ricompensa ricevuta e il valore atteso.\nI valori attesi (v) vengono aggiornati utilizzando l‚Äôerrore di previsione e il tasso di apprendimento (alpha).\n\nQuesto modello Stan implementa il processo di apprendimento del modello di Rescorla-Wagner. Utilizza le scelte e le ricompense osservate per stimare i parametri alpha e theta, aggiornando le aspettative di ricompensa in base ai risultati di ogni tentativo.\n\n\n\n76.8.5 Inferenza\nCompiliamo il modello Stan:\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nDefiniamo i parametri della simulazione:\n\nparams = [0.1, 2.5]  # alpha, theta\nT = 300  # numero di tentativi\nmu = [0.2, 0.8]  # probabilit√† di ricompensa per le due opzioni\n\nSimuliamo i dati:\n\nchoices, rewards, Q_stored = simulate_RescorlaWagner(params, T, mu)\n\nPrepariamo i dati per Stan. Si noti che abbiamo sommato 1 a choices per adattarsi agli indici di Stan che partono da 1.\n\nc = choices + 1\n\nstan_data = {\n    'nTrials': T,\n    'choice': c.tolist(),\n    'reward': rewards.tolist()\n}\nprint(stan_data)\n\n{'nTrials': 300, 'choice': [1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2], 'reward': [1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n12:58:12 - cmdstanpy - INFO - CmdStan start processing\n12:58:12 - cmdstanpy - INFO - Chain [1] start processing\n12:58:12 - cmdstanpy - INFO - Chain [2] start processing\n12:58:12 - cmdstanpy - INFO - Chain [3] start processing\n12:58:12 - cmdstanpy - INFO - Chain [4] start processing\n12:58:14 - cmdstanpy - INFO - Chain [3] done processing\n12:58:14 - cmdstanpy - INFO - Chain [1] done processing\n12:58:15 - cmdstanpy - INFO - Chain [2] done processing\n12:58:15 - cmdstanpy - INFO - Chain [4] done processing\n\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\alpha\\) e \\(\\theta\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\n\n\n76.8.6 Interpretazione delle Stime dei Parametri\nUtilizzando az.summary(trace, hdi_prob=0.94, round_to=2), otteniamo un riassunto delle stime dei parametri del modello, che include la media, la deviazione standard, gli intervalli di credibilit√† (HDI) e altre statistiche diagnostiche:\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.12\n0.06\n0.02\n0.24\n0.00\n0.00\n2582.93\n2151.18\n1.0\n\n\ntheta\n2.36\n0.35\n1.77\n2.96\n0.01\n0.01\n2578.16\n1868.05\n1.0\n\n\n\n\n\n\n\n\nCon 300 prove, le stime dei parametri fornite dal modello sono adeguate:\n\nL‚Äôintervallo di credibilit√† al 94% (hdi_3% - hdi_97%) include il valore simulato del parametro. Questo significa che le stime del modello sono coerenti con i parametri originali usati nella simulazione.\nLa deviazione standard della stima a posteriori √® relativamente piccola, indicando che le stime sono precise.\nI valori di r_hat sono vicini a 1, indicando che le catene di campionamento sono ben mescolate e hanno ottenuto la convergenza.\n\nQuesti risultati suggeriscono che il modello di apprendimento di Rescorla-Wagner ha stimato correttamente i parametri \\(\\alpha\\) e \\(\\theta\\) dai dati simulati.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/cognitive_models/01_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "title": "76¬† Apprendimento per rinforzo",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "77¬† Introduzione",
    "section": "",
    "text": "Nell‚Äôinferenza statistica esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati, stimare quantit√† sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono nell‚Äôinterpretazione della probabilit√† e nell‚Äôintegrazione di conoscenze precedenti ed evidenze.\nLa statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica utilizzando il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione √® trattato come una variabile casuale, che viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, utilizzabile per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nD‚Äôaltra parte, la statistica frequentista interpreta la probabilit√† come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "",
    "text": "Introduzione\nCi sono due approcci principali per l‚Äôinferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l‚Äôanalisi dei dati. Entrambi gli approcci sono usati per stimare quantit√† sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilit√† e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilit√† viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l‚Äôutilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD‚Äôaltra parte, la statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica attraverso l‚Äôuso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione √® trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che pu√≤ essere utilizzata per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell‚Äôinferenza statistica frequentista.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "78.1 I Frequentisti sono Razzisti?",
    "text": "78.1 I Frequentisti sono Razzisti?\nNel Capitolo 26, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all‚Äôinterpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il ‚Äúlato luminoso‚Äù del liberalismo moderno.\nLe origini culturali dell‚Äôapproccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la ‚Äúparte oscura‚Äù della modernit√†. Si potrebbe dire che l‚Äôavversione per la soggettivit√† abbia guidato l‚Äôascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, eredit√≤ una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplor√≤ l‚ÄôAfrica, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli ‚Äúanticicloni‚Äù. Tuttavia, il suo contributo pi√π significativo riguard√≤ l‚Äôuso della statistica nello studio degli esseri umani, in particolare nell‚Äôanalisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all‚ÄôUniversity College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come ‚Äúregressione verso la media‚Äù, da lui chiamato ‚Äúregressione verso la mediocrit√†‚Äù.\nIl suo interesse per l‚Äôereditariet√† del talento lo port√≤ a scrivere il libro ‚ÄúHereditary Genius‚Äù, in cui esaminava come i pensatori brillanti spesso si concentrassero in determinate famiglie. Coni√≤ l‚Äôespressione ‚Äúnature and nurture‚Äù per riferirsi ai due fattori che influenzano lo sviluppo umano: l‚Äôereditariet√† (quello che oggi chiamiamo genetica) e l‚Äôambiente.\nTuttavia, Galton non si limit√≤ a osservare e documentare fatti sulla distribuzione dell‚Äôintelligenza. Il suo obiettivo era creare una scienza dell‚Äôallevamento umano, che egli denomin√≤ ‚Äúeugenetica‚Äù. Egli sosteneva l‚Äôincoraggiamento della riproduzione tra le famiglie di maggior successo e lo scoraggiamento tra quelle meno fortunate.\nGalton era anche estremamente razzista. In una lettera al Times di Londra, defin√¨ gli africani ‚Äúinferiori‚Äù e ‚Äúselvaggi pigri e chiacchieroni‚Äù, descrisse gli arabi come ‚Äúpoco pi√π che consumatori della produzione altrui‚Äù e sostenne che l‚ÄôAfrica orientale dovesse essere consegnata ai cinesi, poich√© questi, nonostante fossero ‚Äúinclini alla menzogna e alla servilit√†‚Äù, erano per natura ‚Äúindustriosi e amanti dell‚Äôordine‚Äù. Per Galton, gli anglosassoni erano la migliore razza esistente, sebbene ritenesse che gli antichi ateniesi fossero stati i migliori di tutti i tempi.\nIl lavoro di Galton ispir√≤ una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, un poliedrico studioso, divenne professore di matematica applicata all‚ÄôUCL nel 1885, seguendo le orme di Galton. Alla morte di quest‚Äôultimo, eredit√≤ la cattedra di eugenismo finanziata da Galton stesso. Pearson fond√≤ la rivista di statistica ‚ÄúBiometrika‚Äù e svilupp√≤ il test del chi quadrato, oltre a coniare il termine ‚Äúdeviazione standard‚Äù.\nRonald Fisher, pi√π giovane, succedette a Pearson come professore di eugenismo all‚ÄôUCL. Fisher √® considerato un gigante della teoria statistica, avendo inventato o esteso numerosi strumenti statistici moderni, tra cui l‚Äôanalisi della varianza (ANOVA), il concetto di ‚Äúsignificativit√† statistica‚Äù e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall‚Äôapproccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell‚Äôeugenismo.\n√à interessante chiedersi se le idee di Galton, Pearson e Fisher sull‚Äôeugenismo abbiano influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e dell‚Äôeugenismo sono strettamente intrecciate. Fisher e, in misura minore, Pearson respingevano l‚Äôidea del bayesianesimo perch√© cercavano di assegnare un fondamento ‚Äúoggettivo‚Äù alle loro idee eugenetiche. Se fosse stata la scienza a stabilire che alcune razze erano inferiori e altre superiori, o che si dovesse scoraggiare la riproduzione tra i poveri, allora queste idee sarebbero state incontestabili. Il bayesianesimo, con la sua intrinseca soggettivit√†, minava questa pretesa di oggettivit√†.\nQuanto di tutto ci√≤ dobbiamo tenere a mente quando esaminiamo la statistica frequentista? Chivers (2024) risponde in questo modo. √à certo che parte dell‚Äôideologia razziale nazista pu√≤ essere ricondotta senza troppe difficolt√† a Galton. Tuttavia, questa considerazione, per quanto estremamente importante dal punto di vista storico ed etico, non √® direttamente rilevante in ambito statistico. La domanda cruciale in termini statistici rimane: ‚ÄúQuale approccio √® corretto?‚Äù o, pi√π accuratamente, ‚ÄúQuale √® pi√π utile?‚Äù, piuttosto che ‚ÄúQuale ha avuto i sostenitori pi√π disgustosi?‚Äù.\nD‚Äôaltra parte, personalmente ritengo che la risposta di Chivers (2024) sia fondamentalmente inadeguata. Consideriamo uno scenario ipotetico: all‚Äôinterno di una ‚Äútorre d‚Äôavorio‚Äù - che sia la statistica, l‚Äôaccademia o la scienza in generale - la teoria A si dimostra pi√π efficace della teoria B. Tuttavia, al di fuori di questo ambito ristretto, la teoria A, a differenza della B, comporta implicazioni etiche inaccettabili.\nDobbiamo davvero accettare A solo perch√© funziona meglio all‚Äôinterno di questo microcosmo artificiale? Assolutamente no.\nInnanzitutto, le cosiddette ‚Äútorri d‚Äôavorio‚Äù sono mere costruzioni ideologiche. Non esiste una vera demarcazione tra ‚Äúdentro‚Äù e ‚Äúfuori‚Äù questi ambiti. La scienza e l‚Äôetica non operano in compartimenti stagni, ma si influenzano reciprocamente in un continuo dialogo.\nInoltre, nel caso specifico del frequentismo, √® evidente - come dimostreremo in seguito - che questo metodo √® intrinsecamente fallace, indipendentemente dal contesto in cui lo si applichi. La sua presunta efficacia all‚Äôinterno di un ambito ristretto √® illusoria e non giustifica in alcun modo le sue implicazioni problematiche. Non possiamo e non dobbiamo separare l‚Äôefficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce non solo sul piano morale, ma anche su quello scientifico, rendendo la sua difesa insostenibile su tutti i fronti.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "78.2 Stime, stimatori e parametri",
    "text": "78.2 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si √® interessati a una quantit√† a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantit√† sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore √® una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune propriet√† della popolazione di cui il campione √® rappresentativo. Il parametro rappresenta la misura di tali propriet√†, ma spesso non √® possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima √® quindi l‚Äôapprossimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore √® la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilit√† del campionamento. In questo capitolo esamineremo come l‚Äôapproccio frequentista quantifica l‚Äôincertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "78.3 Distribuzione campionaria",
    "text": "78.3 Distribuzione campionaria\nIn questo capitolo, affronteremo il problema dell‚Äôutilizzo della media di un campione casuale per stimare il parametro \\(\\mu\\) corrispondente alla media della popolazione da cui √® stato estratto il campione. Per caratterizzare l‚Äôincertezza della stima di un parametro, l‚Äôapproccio frequentista utilizza lo strumento statistico della distribuzione campionaria.\nPer comprendere il concetto di distribuzione campionaria, considereremo il caso di una popolazione finita di dimensioni ridotte. Tuttavia, le stesse propriet√† che esamineremo si applicano alle popolazioni di qualsiasi dimensione.\nIn questa simulazione, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL‚Äôistogramma sottostante descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nPrendiamo ora in considerazione l‚Äôestrazione di tutti i campioni possibili di dimensione \\(n\\) = 2 dalla popolazione.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nPer ottenere un array con tutte le possibili coppie di valori estratti dall‚Äôarray x, possiamo utilizzare la funzione product del modulo itertools. Impostiamo l‚Äôargomento repeat a 2 per indicare che vogliamo coppie di valori. Successivamente, convertiamo la lista di tuple risultante in un array NumPy utilizzando la funzione np.array, e infine stampiamo il risultato. L‚Äôoutput ottenuto sar√† un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie di valori che possono essere estratti dall‚Äôarray x.\nCalcoliamo il numero totale di campioni di ampiezza \\(n\\) = 2.\n\nlen(list(itertools.product(x, x)))\n\n16\n\n\nOra procediamo al calcolo della media per ciascun campione. Questo insieme di valori rappresenta la distribuzione campionaria delle medie dei campioni con dimensione \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), utilizziamo la funzione mean del modulo NumPy e la applichiamo lungo l‚Äôasse delle colonne dell‚Äôarray di coppie di valori. In questo modo otteniamo un array unidimensionale contenente la media di ciascuna coppia di valori.\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x. Sappiamo che, se la variabile aleatoria \\(X\\) √® distribuita con media \\(\\mu\\) e varianza \\(\\sigma^2\\), allora la media della distribuzione dei campioni casuali indipendenti di ampiezza \\(n\\) = 2 sar√†:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu.\n\\]\nVerifichiamo che ci√≤ sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\nVerifichiamo che la varianza della distribuzione dei campioni casuali indipendenti di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione \\(X\\) con varianza \\(\\sigma^2\\) sia \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\).\nConsiderando la definizione di varianza, possiamo scrivere:\n\\[\n\\begin{aligned}\n\\mathbb{V}(\\bar{X}) &= \\mathbb{E}[(\\bar{X}-\\mu_{\\bar{X}})^2] \\\\\n&= \\mathbb{E}[(\\bar{X} - \\mu)^2] \\\\\n&= \\mathbb{E}[(X_1+X_2)/2 - \\mu)^2] \\\\\n&= \\mathbb{E}[((X_1 - \\mu) + (X_2 - \\mu))/2)^2] \\\\\n&= \\mathbb{E}[(X_1 - \\mu)^2/4 + (X_2 - \\mu)^2/4 + (X_1 - \\mu)(X_2 - \\mu)/2)] \\\\\n&= \\frac{1}{4}\\mathbb{E}[(X_1 - \\mu)^2] + \\frac{1}{4}\\mathbb{E}[(X_2 - \\mu)^2] + \\frac{1}{2}\\mathbb{E}[(X_1 - \\mu)(X_2 - \\mu)] \\\\\n&= \\frac{1}{4}\\mathbb{V}(X_1) + \\frac{1}{4}\\mathbb{V}(X_2) + \\frac{1}{2}\\mathbb{C}(X_1,X_2) \\\\\n&= \\frac{\\sigma^2}{4} + \\frac{\\sigma^2}{4} + 0 \\\\\n&= \\frac{\\sigma^2}{2}\n\\end{aligned}\n\\]\nDove \\(\\mu_{\\bar{X}}\\) √® la media della distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) e \\(\\mathbb{C}(X_1,X_2)\\) √® la covarianza tra \\(X_1\\) e \\(X_2\\). In questo caso, dato che i campioni sono estratti in modo casuale e indipendente, la covarianza tra \\(X_1\\) e \\(X_2\\) √® 0. Pertanto, abbiamo dimostrato che \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\) per \\(n=2\\).\nIl valore teorico della varianza delle medie dei campioni √® dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione √® diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, si presti attenzione a due aspetti importanti:\n\nla media della distribuzione delle medie campionarie √® uguale alla media della popolazione,\nla varianza della distribuzione delle medie campionarie √® minore della varianza della popolazione, ovvero √® pari alla varianza della popolazione divisa per l‚Äôampiezza campionaria.\n\nQuesti due risultati che abbiamo ottenuto empiricamente nella simulazione possono essere espressi in maniera formale dicendo che la media di campioni casuali estratti con ripetizione da una popolazione finita (oppure da una popolazione infinita) di media \\(\\mu\\) e varianza \\(\\sigma^2\\) ha valore atteso $ ({X}_n) = $ e varianza $ ({X}_n) = . $\nInoltre, se la popolazione segue una distribuzione normale, allora per le propriet√† della distribuzione normale, anche la distribuzione delle medie dei campioni seguir√† una distribuzione normale. Al contrario, se la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all‚Äôaumentare delle dimensioni del campione, la distribuzione delle medie dei campioni tender√† a una distribuzione normale.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "78.4 Teorema del Limite Centrale",
    "text": "78.4 Teorema del Limite Centrale\nEsaminiamo ora pi√π in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostr√≤ il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 78.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tender√† a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC pu√≤ essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l‚Äôaltezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalit√† della distribuzione risultante. Questa √® la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\nPer illustrare il TLC, utilizziamo una simulazione. Consideriamo una popolazione iniziale fortemente asimmetrica, come una distribuzione Beta(2, 1). Estraiamo da questa popolazione 50,000 campioni di ampiezza \\(n\\) e costruiamo la distribuzione campionaria di tali campioni.\n\n# parameters of the beta\na=2\nb=1\n\ndef plotSamples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n          v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together \n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(sample_means)\n    ax2 = ax.twinx()\n    sns.lineplot(x=x,y=y, ax=ax2, color='black')\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l‚Äôampiezza campionaria √® 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplotSamples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non √® certamente Normale, inizia ad avvicinarsi alla gaussianit√†.\n\nplotSamples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c‚Äô√® ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l‚Äôapprossimazione migliora.\n\nplotSamples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplotSamples(30)\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) mostra che, salvo per campioni molto piccoli, la distribuzione campionaria della media dei campioni pu√≤ essere ben approssimata dalla Normale, indipendentemente dalla forma della distribuzione della popolazione. Ci√≤ significa che, per campioni sufficientemente grandi, il TLC ci fornisce una formula esplicita per la forma della distribuzione campionaria della media dei campioni, anche in assenza di conoscenze sulla popolazione di media \\(\\mu\\) e deviazione standard \\(\\sigma\\): \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).\nIl risultato del TLC ha una grande utilit√† in molti ambiti. Infatti, ci aiuta a comprendere perch√© i risultati degli esperimenti con un grande numero di osservazioni sono pi√π affidabili rispetto a quelli con un numero ridotto di osservazioni. Inoltre, il TLC ci fornisce una formula esplicita per l‚Äôerrore standard (\\(\\sigma/\\sqrt{n}\\)), che ci consente di valutare l‚Äôaffidabilit√† degli esperimenti al variare della dimensione del campione.\nNegli esperimenti psicologici, molti dei fenomeni che vogliamo misurare sono in realt√† medie di molteplici variabili (ad esempio, l‚Äôintelligenza ‚Äúgenerale‚Äù misurata dal QI √® una media di un gran numero di abilit√† specifiche), e in questi casi la quantit√† media segue una distribuzione normale. Questa legge matematica ci permette di osservare spesso la distribuzione normale nei dati degli esperimenti psicologici e in molte altre discipline scientifiche.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "78.5 Distribuzioni campionarie di altre statistiche",
    "text": "78.5 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax)\nax2 = ax.twinx()\n_ = sns.lineplot(x=x, y=y, ax=ax2, color=\"black\")\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Per calcolare la varianza, iniziamo usando la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCreiamo ora un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza, usando la procedura descritta in precedenza.\nSappiamo che la varianza della popolazione √® uguale a \\(15^2 = 225\\). Tuttavia, calcolando la varianza con la formula della statistica descrittiva otteniamo, in media, un valore minore. Dunque, l‚Äôutilizzo della formula precedente conduce a una stima troppo piccola della varianza della popolazione. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n176.76365773544788\n\n\n\n\n\n\n\n\n\nQuesta dimostrazione ci fa dunque capire come\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nnon sia uno stimatore adeguato per la varianza della popolazione.\nAbbiamo gi√† visto per√≤ che questo problema trova una semplice soluzione nel momento in cui usiamo usiamo il seguente stimatore per la varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\nVerifichiamo.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n224.19924816630638\n\n\n\n\n\n\n\n\n\nLa discrepanza tra la stima di un parametro e il suo vero valore √® definita come errore di stima. Uno stimatore √® considerato non distorto (unbiased) se, in media, le sue stime su diversi campioni ipotetici coincidono con il valore del parametro che si intende stimare, ossia se l‚Äôerrore medio di stima √® nullo.\nNel corso di questo capitolo, abbiamo osservato che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) costituisce uno stimatore non distorto di \\(\\mu\\), mentre \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo implica che lo stimatore \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) presenta una distribuzione campionaria centrata sul vero valore del parametro \\(\\sigma^2\\).",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#considerazioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#considerazioni-conclusive",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "78.6 Considerazioni conclusive",
    "text": "78.6 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "78¬† Introduzione all‚Äôinferenza frequentista",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nseaborn   : 0.13.2\narviz     : 0.18.0\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\n\n\n\n\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, Edwin T. 2003. Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "79¬† Intervallo di confidenza",
    "section": "",
    "text": "Introduzione\nGli intervalli di confidenza sono un pilastro nell‚Äôapproccio frequentista all‚Äôinferenza statistica, fornendo un mezzo per gestire l‚Äôincertezza associata ai risultati delle analisi statistiche. Questo capitolo si propone di esplorare in profondit√† gli intervalli di confidenza, analizzandone il calcolo e la loro interpretazione dal punto di vista frequentista. Sar√† messa in luce la sfida nell‚Äôinterpretare correttamente tali intervalli.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "title": "79¬† Intervallo di confidenza",
    "section": "79.1 Inferenza Statistica Frequentista: L‚ÄôIntervallo di Confidenza",
    "text": "79.1 Inferenza Statistica Frequentista: L‚ÄôIntervallo di Confidenza\nL‚Äôintervallo di confidenza √® un concetto fondamentale nell‚Äôapproccio frequentista alla statistica. Questo strumento √® impiegato per valutare la variabilit√† della stima di un parametro di interesse all‚Äôinterno di una popolazione, partendo da un campione di essa.\nAl centro di questo metodo si trova l‚Äôerrore standard, che misura la deviazione standard della distribuzione campionaria di uno stimatore. Questo indice quantifica quanto la stima del parametro si discosta, in media, dal valore effettivo del parametro nella popolazione. Gli statistici frequentisti sfruttano l‚Äôerrore standard per definire l‚Äôintervallo di confidenza, che rappresenta un intervallo di valori entro cui si ritiene si trovi il vero valore del parametro, come ad esempio la media della popolazione.\nPer comprendere l‚Äôintervallo di confidenza da una prospettiva frequentista √® essenziale il concetto di ‚Äúprocedura di stima‚Äù. In base a questo approccio, l‚Äôintervallo di confidenza viene costruito in modo che, se la medesima procedura fosse ripetuta su diversi campioni della stessa popolazione, una determinata percentuale degli intervalli di confidenza (ad esempio, il 95%) includerebbe il vero valore del parametro della popolazione.\nIn terminologia frequentista, quindi, non si afferma che un dato intervallo di confidenza possieda una probabilit√† del 95% di contenere il vero valore del parametro. Piuttosto, si sostiene che, seguendo lo stesso metodo di stima, il 95% degli intervalli di confidenza derivati da campioni differenti racchiuderebbe il vero valore del parametro.\nIn questo quadro, l‚Äôintervallo di confidenza non √® una dichiarazione sulla probabilit√† che un particolare intervallo includa il valore del parametro, ma piuttosto un‚Äôaffermazione sulla regolarit√† con cui gli intervalli calcolati in un determinato modo riescono a catturare il valore del parametro quando si ripete il medesimo processo su vari campioni. Questa distinzione √® cruciale per una corretta comprensione dell‚Äôapproccio frequentista all‚Äôinferenza statistica.\nMentre quest‚Äôinterpretazione dell‚Äôintervallo di confidenza pu√≤ apparire controintuitiva e talvolta poco pratica, riflette il contrasto con l‚Äôapproccio bayesiano, il quale enfatizza l‚Äôaggiornamento delle probabilit√† sulla base di nuove informazioni, a differenza dell‚Äôapproccio frequentista, che si basa sulla ripetizione degli esperimenti e sulla valutazione della variabilit√† campionaria.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "href": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "title": "79¬† Intervallo di confidenza",
    "section": "79.2 Determinazione dell‚Äôintervallo di Confidenza per una Media",
    "text": "79.2 Determinazione dell‚Äôintervallo di Confidenza per una Media\nNei casi in cui la distribuzione delle statistiche campionarie si avvicina a una distribuzione Normale, l‚Äôintervallo di confidenza al 95% √® calcolato come:\n\\[\n\\hat{\\theta} \\pm 1.96 \\cdot \\text{SE},\n\\]\ndove \\(\\hat{\\theta}\\) rappresenta la stima del parametro e SE l‚Äôerrore standard.\n\n79.2.1 Derivazione dell‚ÄôIntervallo di Confidenza per una Popolazione Normale con Varianza Nota\nConsideriamo una popolazione che segue una distribuzione normale con una media nota \\(\\mu\\) e varianza \\(\\sigma^2\\). Prendiamo un campione casuale di dimensione \\(n\\) da questa popolazione, indicato come \\(X_1, X_2, \\dots, X_n\\). Grazie alle propriet√† delle distribuzioni normali, la media campionaria \\(\\bar{X}\\) segue anch‚Äôessa una distribuzione normale, nello specifico \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)\\).\n\n79.2.1.1 Passo 1: Standardizzazione della Media Campionaria\n\nPer standardizzare la media campionaria in una variabile distribuita normalmente standard, sottraiamo la media della popolazione \\(\\mu\\) e dividiamo per lo scarto standard della media campionaria \\(\\sigma/\\sqrt{n}\\). Ci√≤ porta alla seguente trasformazione:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0, 1).\n\\]\n\n\n\n79.2.1.2 Passo 2: Stabilire il Livello di Confidenza\n\nDefiniamo un livello di confidenza \\(\\gamma = 1 - \\alpha\\), ad esempio \\(\\gamma = 0.95\\) per un livello di confidenza del 95%.\nIdentifichiamo il valore critico \\(z\\), corrispondente al quantile \\((1 - \\alpha/2)\\) della distribuzione normale standard. Il valore \\(z\\) rappresenta il punto di taglio alle estremit√† della distribuzione:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\n\n\n\n79.2.1.3 Passo 3: Formulazione dell‚ÄôIntervallo di Confidenza\n\nCon il valore \\(z\\) definito, formuliamo l‚Äôintervallo di confidenza per la media della popolazione:\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\n\n\n\n79.2.1.4 Passo 4: Manipolazione Algebrica per Definire i Limiti\n\nRielaboriamo la disuguaglianza per esporre i limiti dell‚Äôintervallo di confidenza:\n\\[\n\\begin{align}\nP\\bigg(-z \\leq &\\frac{ \\bar{X} - \\mu } {\\sigma} \\sqrt{n} \\leq z\\bigg) = \\gamma\\notag\\\\\nP\\bigg(-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq  &\\bar{X} - \\mu \\leq z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\nP\\bigg(-\\bar{X}-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq &-\\mu \\leq -\\bar{X} + z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\nP\\bigg(\\bar{X}+z \\frac{\\sigma}{\\sqrt{n}} \\geq &\\mu \\geq  \\bar{X} -z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma.\\notag\n\\end{align}\n\\]\n\n\n\n79.2.1.5 Passo 5: Specificazione dei Limiti dell‚ÄôIntervallo\n\nDefiniamo i limiti dell‚Äôintervallo di confidenza, \\(\\hat{a}\\) e \\(\\hat{b}\\), come segue:\n\\[\n\\hat{a} = \\bar{X} - z \\frac{\\sigma}{\\sqrt{n}},\n\\quad \\hat{b} = \\bar{X} + z \\frac{\\sigma}{\\sqrt{n}},\n\\]\ncon \\(P(\\hat{a} \\leq \\mu \\leq \\hat{b}) = \\gamma\\).\n\n\n\n79.2.1.6 Conclusione:\n\nL‚Äôintervallo di confidenza \\((\\hat{a}, \\hat{b})\\) racchiude il vero valore della media della popolazione \\(\\mu\\) con una probabilit√† \\(\\gamma\\).\n\n\n\n\n79.2.2 Stima dell‚ÄôIntervallo di Confidenza per Popolazioni Normali con Varianza Incognita\nIn contesti reali, quando si preleva un campione \\(X_1, \\dots, X_n\\) da una popolazione, la varianza \\(\\sigma^2\\) della popolazione √® spesso incognita. Questo aggiunge incertezza riguardo alla media della popolazione \\(\\mu\\), che √® il parametro di interesse. In questi casi, si adotta la distribuzione t di Student per la stima dell‚Äôintervallo di confidenza della media \\(\\mu\\), a causa della varianza incognita.\n\n79.2.2.1 Passo 1: Impiego della Distribuzione t di Student\n\nApplichiamo la formula seguente per calcolare l‚Äôintervallo:\n\\[\nP\\left(‚àít^{\\ast} \\leq \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}} \\leq t^{\\ast}\\right) = \\gamma,\n\\]\ndove \\(\\gamma = 1 - \\alpha\\) √® il livello di confidenza, \\(s\\) √® la stima della deviazione standard \\(\\sigma\\) della popolazione, e \\(t^{\\ast}\\) √® il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione t con \\(n‚àí1\\) gradi di libert√†.\n\n\n\n79.2.2.2 Passo 2: Determinazione dei Limiti dell‚ÄôIntervallo di Confidenza\n\nCalcoliamo i limiti inferiore \\(\\hat{a}\\) e superiore \\(\\hat{b}\\) dell‚Äôintervallo di confidenza cos√¨:\n\\[\n\\hat{a} = \\bar{X} - t^{\\ast} \\frac{s}{\\sqrt{n}},\n\\quad \\hat{b} = \\bar{X} + t^{\\ast} \\frac{s}{\\sqrt{n}}.\n\\]\n\nIn queste circostanze, si sostituisce la varianza sconosciuta \\(\\sigma^2\\) con la sua stima \\(s\\) e si utilizza la distribuzione t di Student invece della normale.\nApplicabilit√† e Limitazioni:\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e √® valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non √® normalmente distribuita e la dimensione del campione √® ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell‚Äôintervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "79¬† Intervallo di confidenza",
    "section": "79.3 Livello di Copertura",
    "text": "79.3 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia √® fondamentale considerare il concetto di ‚Äúlivello di copertura‚Äù. Questo livello indica la frequenza con cui l‚Äôintervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura: - Se il livello di copertura √® del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterr√† il valore vero del parametro. - Importante: Questo non implica che ci sia una probabilit√† del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione √® un valore fisso e non soggetto a probabilit√†; piuttosto, l‚Äôincertezza risiede nell‚Äôintervallo di fiducia stesso.\nCome Funziona la Copertura: - Nel contesto frequentista, la ‚Äúprobabilit√†‚Äù si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell‚Äôesperimento. - Nel caso degli intervalli di fiducia, l‚Äô‚Äúesperimento‚Äù √® l‚Äôestrazione di un campione dalla popolazione, e l‚Äô‚Äúevento‚Äù √® la generazione di un intervallo di fiducia che contiene il valore vero del parametro. - Il livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilit√† a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n79.3.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm¬≤.\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l‚Äôintervallo di fiducia al 95% usando la formula:\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) √® la media campionaria, \\(s\\) √® la deviazione standard campionaria e \\(t\\) √® il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libert√† al livello di significativit√† \\(\\alpha/2 = 0.025\\).\nRegistriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\n\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIniziamo generando 1000 campioni casuali di dimensione \\(n=30\\) da una distribuzione normale con media \\(175\\) e deviazione standard \\(7\\).\n\nmu = 175\nsigma = 7\nn = 30\nn_samples = 1000\n\nsamples = np.stack([np.random.normal(loc=mu, scale=sigma, size=n) for i in range(n_samples)])\nsamples.shape\n\n(1000, 30)\n\n\nIl primo campione di ampiezza \\(n\\) = 30 che abbiamo ottenuto √® il seguente.\n\nprint(samples[1, :])\n\n[164.73077142 178.36458698 178.37872685 174.13939428 171.93750167\n 183.62660835 166.47855379 166.14290722 190.11028319 178.59315899\n 171.1696638  173.70591366 170.78474733 175.70917764 168.69153018\n 177.18965061 184.68306022 180.57048893 182.54977759 179.74984648\n 167.07981468 185.24317632 176.86968895 177.70411011 171.09097822\n 166.88189761 176.52572538 175.31383448 173.88320882 169.05527411]\n\n\nStampiamo qui di seguito le medie dei primi dieci campioni.\n\nxbar = samples.mean(axis=1)\nprint(xbar[0:10])\n\n[176.37407572 175.23180193 174.58152045 176.40365999 176.74312635\n 174.17121749 174.48572499 174.18025492 175.07399899 176.36952714]\n\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con (30-1) gradi di libert√†.\n\nalpha = 0.05\nt = st.t.ppf(1 - alpha/2, n-1)\nt\n\n2.0452296421327034\n\n\nUtilizzando le informazioni precedenti, calcoliamo 1000 intervalli di confidenza per la media della popolazione.\n\ninterval_width = t * samples.std(axis=1, ddof=1) / np.sqrt(n)\nCI_low = samples.mean(axis=1) - interval_width\nCI_high = samples.mean(axis=1) + interval_width\n\nTroviamo ora il livello di copertura, ovvero il numero di volte in cui l‚Äôintervallo di confidenza calcolato contiene il vero valore del parametro.\n\ncoverage_p = np.sum(np.logical_and(CI_low &lt; mu, mu &lt; CI_high)) / samples.shape[0]\ncoverage_p\n\n0.958\n\n\nIn conclusione, ripetendo la simulazione per 1000 volte, abbiamo ottenuto una proporzione di intervalli di confidenza del 95% che contengono il parametro (ovvero il livello di copertura) molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\).\n\n\n79.3.2 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l‚Äôapproccio frequentista, l‚Äôintervallo di confidenza si deve considerare come una metodologia: - Se ripetiamo l‚Äôesperimento (estrarre un campione e calcolare l‚Äôintervallo di confidenza) molte volte, il metodo produce un intervallo che coprir√† il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n79.3.3 Un Malinteso Comune nell‚ÄôInterpretazione degli Intervalli di Confidenza\n√à inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilit√† del 95%. Questo √® un errore diffuso, persino tra i ricercatori, che spesso interpretano l‚Äôintervallo di confidenza come indicativo della probabilit√† che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all‚Äôinterno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta √® la seguente: - ‚ÄúLa metodologia impiegata per calcolare l‚Äôintervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilit√† di generare un intervallo che include il vero valore del parametro‚Äù. - Ci√≤ significa che l‚Äôintervallo di confidenza non esprime una probabilit√† circa la posizione precisa del parametro, ma riflette la probabilit√† che la procedura adottata per determinarlo generi un intervallo che lo includa.\nIn conclusione, l‚Äôintervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilit√† del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n\n79.3.4 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, {cite}hoekstra2014robust evidenziano come, nonostante l‚Äôampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l‚Äôinferenza statistica. Anche l‚ÄôAmerican Psychological Association (APA) suggerisce che gli intervalli di confidenza siano ‚Äúin generale, la migliore strategia di reportistica‚Äù. Tuttavia, {cite}hoekstra2014robust sottolineano che queste raccomandazioni non considerano la difficolt√† nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l‚Äôinterpretazione degli intervalli di confidenza, Hoekstra et al.¬†hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL‚Äôesperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, {cite}hoekstra2014robust ricordano qual √® l‚Äôinterpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, {cite:t}hoekstra2014robust hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l‚Äôinterpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: ‚ÄúThe 95% confidence interval for the mean ranges from 0.1 to 0.4.‚Äù Please mark each of the statements below as ‚Äòtrue‚Äô or ‚Äòfalse‚Äô.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe ‚Äúnull hypothesis‚Äù that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non √® stata rilevata una differenza di rilievo nell‚Äôinterpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l‚Äôesperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l‚Äôesperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull‚Äôefficacia degli intervalli di confidenza frequentisti e suggerisce che gli ‚Äúintervalli di credibilit√†‚Äù bayesiani possano rappresentare un‚Äôalternativa pi√π vantaggiosa. Quest‚Äôultimi tendono ad essere pi√π intuitivi e di pi√π facile interpretazione corretta.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "79¬† Intervallo di confidenza",
    "section": "79.4 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "79.4 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l‚Äôintervallo di confidenza frequentista e l‚Äôintervallo di credibilit√† bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo √® stimare la media della popolazione da cui sono state tratte queste osservazioni. Per farlo, simuliamo 20 valori casuali da una popolazione che segue una distribuzione normale con media 50 e deviazione standard 10, rappresentata da \\(\\mathcal{N}(50, 10)\\).\n\nsample_size = 20\nmu = 50\nsigma = 10\nsample_data = np.random.normal(loc=mu, scale=sigma, size=n)\nprint(sample_data)\n\n[40.13038118 67.14138507 58.15372819 61.87080597 70.28823876 58.64307551\n 55.41941724 67.9643939  42.76867878 58.37573589 51.38804991 46.78454195\n 36.63322195 44.69934389 56.11884628 40.82879678 45.90438324 45.45382291\n 40.89898539 49.55213524 64.12932274 50.47661058 53.19291531 52.46171204\n 47.98108743 41.26631945 66.63886733 58.25433261 50.31265781 60.7856227 ]\n\n\n\n_ = plt.hist(sample_data, density=True)\n\n\n\n\n\n\n\n\n\n79.4.1 Intervallo di Confidenza Frequentista\nQuando ci si avvicina al problema di stimare la media della popolazione, \\(\\mu\\), attraverso un approccio frequentista, uno dei metodi pi√π comuni √® la stima puntuale. Questo metodo consiste nell‚Äôutilizzare un unico valore, solitamente la media del campione, per rappresentare il parametro della popolazione che non conosciamo.\nLa media campionaria, indicata come \\(\\hat{\\mu}\\), √® una scelta frequente per la stima puntuale della media della popolazione, \\(\\mu\\). Si calcola sommando tutti i valori osservati nel campione, ovvero \\(X_1, X_2, ..., X_n\\), e dividendo questa somma per il numero totale di osservazioni nel campione, \\(n\\):\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nApplicando questa formula ai dati del nostro esempio, otteniamo\n\nsample_mean = np.mean(sample_data)\nsample_mean\n\n52.81724720110726\n\n\nMentre le stime puntuali offrono un valore specifico per rappresentare il parametro della popolazione, non riescono da sole a descrivere completamente l‚Äôincertezza associata a questa stima. Per affrontare questa lacuna, l‚Äôapproccio frequentista si avvale degli intervalli di confidenza. Un intervallo di confidenza fornisce una gamma di valori all‚Äôinterno dei quali si presume che il vero parametro della popolazione cada, basandosi sui dati osservati. Questo intervallo viene definito aggiungendo e sottraendo un margine di errore alla stima puntuale:\n\\[\\hat{\\mu} \\pm m = [\\hat{\\mu} - m, \\hat{\\mu} + m].\\]\nIl margine di errore, che riflette la variabilit√† dei dati del campione, dipende sia dal livello di confidenza scelto, indicato come \\(1-\\alpha\\), sia dalla dimensione del campione, \\(n\\). Ad esempio, un intervallo di confidenza del 95% significa che ci si aspetta che l‚Äôintervallo includa il vero parametro della popolazione nel 95% delle applicazioni di questa procedura.\nIl margine di errore si calcola normalmente attraverso l‚Äôerrore standard (SE) della stima puntuale, e viene definito da:\n\\[m = t_{1-\\frac{\\alpha}{2}, n-1} \\times SE,\\]\ndove \\(t_{1-\\frac{\\alpha}{2}, n-1}\\) rappresenta il valore critico dalla distribuzione t per il livello di confidenza desiderato e \\(n-1\\) gradi di libert√†.\nL‚Äôerrore standard della media campionaria si ottiene dividendo la deviazione standard del campione, \\(\\sigma\\), per la radice quadrata della dimensione del campione:\n\\[SE = \\frac{\\sigma}{\\sqrt{n}}.\\]\nApplicando questa formula ai dati del nostro esempio, la deviazione standard del campione risulta\n\nsample_stddev = np.std(sample_data, ddof=1)\nsample_stddev\n\n9.359341680068068\n\n\nL‚Äôerrore standard della media √®\n\nstandard_error = sample_stddev / np.sqrt(sample_size)\nprint(standard_error)\n\n2.092812422127929\n\n\nL‚Äôerrore standard della media rappresenta una stima della deviazione standard della distribuzione delle medie campionarie per campioni di dimensione \\(n\\) (in questo caso, \\(n\\) = 20).\nSupponiamo di voler avere un livello di confidenza del 95%. Per trovare il valore critico della distribuzione \\(t\\) di Student, dobbiamo trovare il valore della statistica \\(T\\) che lascia il 2.5% dell‚Äôarea sotto la coda a sinistra e il 2.5% dell‚Äôarea sotto la coda a destra della distribuzione \\(t\\) di Student con 19 gradi di libert√†.\n\ndegrees_of_freedom = sample_size - 1\nt_val = st.t.ppf(0.975, degrees_of_freedom)\nprint(t_val)\n\n2.093024054408263\n\n\nIl margine d‚Äôerrore √® uguale a\n\\[t \\cdot SE\\]\novvero\n\nmargin_of_error = t_val * standard_error\nprint(margin_of_error)\n\n4.380306740878175\n\n\nL‚Äôintervallo di confidenza frequentista √® uguale a\n\\[\\text{stima del parametro} \\pm \\text{margine d'errore}\\]\novvero\n\\[\\bar{x} \\pm t_{\\text{critico}} \\frac{s}{\\sqrt{n}}.\\]\nPer i dati dell‚Äôesempio otteniamo\n\nconfidence_interval_lower = sample_mean - margin_of_error\nconfidence_interval_upper = sample_mean + margin_of_error\nconfidence_interval = [confidence_interval_lower, confidence_interval_upper]\nprint(confidence_interval)\n\n[48.43694046022908, 57.19755394198543]\n\n\nInterpretiamo questo risultato dicendo che la procedura utilizzata per calcolare l‚Äôintervallo \\([42.99, 53.23]\\) include \\(\\mu\\) nel 95% dei casi.\nLa figura successiva mostra la distribuzione dei dati, la stima di \\(\\mu\\) (ovvero, la media del campione) e l‚Äôintervalli di confidenza al 95%.\n\ndef visualize_output(sample_data, sample_mean, interval, type_interval):\n    plt.hist(sample_data, density=True, alpha=0.5)\n    plt.axvline(x=sample_mean, linestyle='dashed', linewidth=2)\n    plt.axvline(x=interval[0], linewidth=2)\n    plt.axvline(x=interval[1], linewidth=2)\n    plt.legend(['Sample Mean', f'{type_interval} interval'])\n\n\nvisualize_output(sample_data, sample_mean, confidence_interval, 'confidence')\n\n\n\n\n\n\n\n\n\n\n79.4.2 Intervallo di Credibilit√† Bayesiano\nPer determinare l‚Äôintervallo di credibilit√† bayesiano, impieghiamo un modello statistico basato sulla distribuzione Normale, integrando distribuzioni a priori che forniscono informazioni iniziali limitate sui parametri. Questa strategia ci consente di inserire delle conoscenze preliminari, pur essendo vaghe, nell‚Äôanalisi statistica.\nDettagli sulle scelte delle distribuzioni a priori: - Per il parametro \\(\\mu\\), impostiamo una distribuzione a priori centrata intorno allo zero, con una deviazione standard piuttosto ampia. Come alternativa, si potrebbe considerare di centrare la distribuzione a priori sulla media campionaria. - Per il parametro \\(\\sigma\\), adottiamo una distribuzione Normale troncata, posizionata anch‚Äôessa intorno allo zero, ma con una deviazione standard notevolmente grande.\nLa scelta di centrare le distribuzioni a priori sullo zero √® volta a evitare l‚Äôintroduzione di bias nell‚Äôanalisi, tendendo verso una stima conservativa, ossia una stima del parametro incline allo zero. La decisione di usare deviazioni standard molto ampie riflette la debolezza delle informazioni preliminari che abbiamo incorporato nel modello.\nCi√≤ detto, abbiamo introdotto alcune conoscenze iniziali nell‚Äôanalisi: in particolare, l‚Äôassunzione che valori eccessivamente elevati, sia positivi che negativi, per la media del campione siano improbabili. Questa considerazione riflette una cautela nell‚Äôestimare il parametro, evitando di considerare valori estremi come plausibili.\n\nmodel = pm.Model()\n\nwith model:\n    mu = pm.Normal(\"mu\", mu=0, sigma=200)\n    sigma = pm.HalfNormal(\"sigma\", 100)\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=sample_data)\n\n\nwith model:\n    idata = pm.sample(nuts_sampler=\"numpyro\")\n\n\naz.summary(idata, hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n52.89\n1.84\n49.26\n56.53\n0.04\n0.03\n2432.99\n2087.60\n1.0\n\n\nsigma\n9.77\n1.31\n7.47\n12.45\n0.03\n0.02\n2652.84\n2492.04\n1.0\n\n\n\n\n\n\n\n\nSi noti che, dati i dati specifici e la formulazione del modello bayesiano in uso, l‚Äôintervallo di credibilit√† ottenuto si mostra molto simile all‚Äôintervallo di confidenza calcolato secondo l‚Äôapproccio frequentista. Tuttavia, l‚Äôinterpretazione di questi due intervalli differisce in maniera sostanziale.\nNel caso dell‚Äôintervallo di credibilit√† bayesiano, possiamo affermare che, in base al nostro grado di credenza soggettiva del 95%, la media della popolazione si trova all‚Äôinterno dell‚Äôintervallo specificato. Questo √® un‚Äôaffermazione diretta sulla probabilit√† che la media della popolazione rientri in un determinato intervallo, basata sulle informazioni priori e sui dati osservati.\nIn contrasto, l‚Äôintervallo di confidenza frequentista non permette un‚Äôinterpretazione diretta riguardo alla probabilit√† della media della popolazione di cadere in un dato intervallo. Invece, l‚Äôinterpretazione frequentista indica che, se ripetessimo il processo di campionamento molte volte, il 95% degli intervalli di confidenza calcolati conterrebbe la vera media della popolazione.\nQuindi, mentre l‚Äôintervallo di credibilit√† bayesiano fornisce una misura diretta della credenza nella posizione della media della popolazione, l‚Äôintervallo di confidenza frequentista fornisce una misura di affidabilit√† del processo di stima nel lungo termine.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "79¬† Intervallo di confidenza",
    "section": "79.5 Riflessioni Conclusive",
    "text": "79.5 Riflessioni Conclusive\nCome sottolineato da {cite:t}hoekstra2014robust, √® comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il ‚Äúlivello di confidenza del 95%‚Äù √® da interpretarsi come la probabilit√† a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non √® possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all‚Äôinterno di un dato intervallo di fiducia non √® garantita per ogni singolo caso analizzato.\n√à inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia pi√π ristretto implichi maggiore precisione. Nella prospettiva frequentista, la ‚Äúprecisione‚Äù √® strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realt√† essere significativamente lontano dal valore vero del parametro non noto.\n√à importante sottolineare che l‚Äôapproccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell‚Äôintervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\n\nIntervallo di confidenza per la differenza tra due medie:\nSe abbiamo due campioni indipendenti di dimensione $ n_1 $ e $ n_2 $, con medie $ {x}_1 $ e $ {x}_2 $ e deviazioni standard $ s_1 $ e $ s_2 $, l‚Äôintervallo di confidenza per la differenza tra le medie √® calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n\\]\nDove $ t_{/2} $ √® il valore critico della distribuzione t di Student con $ /2 $ di probabilit√† di coda e gradi di libert√† $ df = n_1 + n_2 - 2 $.\nIntervallo di confidenza per una proporzione:\nPer stimare l‚Äôintervallo di confidenza per una proporzione $ p $ in un campione binomiale di dimensione $ n $, la formula √®:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nDove $ $ √® la proporzione campionaria e $ z_{/2} $ √® il valore critico della distribuzione normale standard con $ /2 $ di probabilit√† di coda.\nIntervallo di confidenza per la differenza tra due proporzioni:\nPer stimare l‚Äôintervallo di confidenza per la differenza tra due proporzioni $ p_1 $ e $ p_2 $ in due campioni binomiali di dimensioni $ n_1 $ e $ n_2 $, la formula √®:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}\n\\]\nDove $ _1 $ e $ 2 $ sono le proporzioni campionarie e $ z{/2} $ √® il valore critico della distribuzione normale standard con $ /2 $ di probabilit√† di coda.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "79¬† Intervallo di confidenza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun May 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.4\narviz     : 0.18.0\nnumpy     : 1.26.4\nscipy     : 1.13.0\npandas    : 2.2.2\npymc      : 5.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html",
    "title": "80¬† Significativit√† statistica",
    "section": "",
    "text": "Introduzione\nIl test di ipotesi √® un metodo ampiamente utilizzato nella ricerca per fare inferenze sui parametri della popolazione basandosi sui dati campionari. Nel contesto della psicologia, questo metodo √® spesso impiegato per valutare l‚Äôefficacia di interventi psicologici, confrontare diverse teorie o approcci, esplorare le influenze di variabili psicologiche su comportamenti e processi cognitivi, e comprendere meglio i meccanismi sottostanti a fenomeni psicologici complessi come l‚Äôapprendimento, la memoria e le emozioni.\nIn questo capitolo, ci concentreremo sul test di ipotesi frequentista, una procedura ancora comunemente utilizzata. Tuttavia, √® fondamentale sottolineare che la comunit√† statistica sconsiglia l‚Äôuso esclusivo del test di ipotesi frequentista come criterio decisionale per stabilire la validit√† di un risultato sperimentale.\nTradizionalmente, un risultato √® considerato ‚Äústatisticamente significativo‚Äù se √® improbabile che sia dovuto al caso, suggerendo che il risultato sia stabile o reale. Al contrario, i risultati ‚Äúnon significativi‚Äù vengono spesso etichettati come rumorosi e visti con scetticismo. Questa visione semplificata della significativit√† statistica pu√≤ portare a fraintendimenti e conclusioni errate.\nAnalizzeremo come l‚Äôapproccio frequentista, in pratica, non mantenga sempre la sua ‚Äúpromessa‚Äù e come l‚Äôuso della procedura della significativit√† statistica, nella pratica scientifica, possa spesso produrre risultati opposti a quelli desiderati. La significativit√† statistica dipende fortemente dalle dimensioni del campione e da altri fattori. Un risultato non significativo non implica necessariamente che l‚Äôeffetto osservato sia nullo o irrilevante. Inoltre, la significativit√† statistica pu√≤ essere influenzata dalla scelta dei livelli di confidenza e dai test statistici utilizzati, portando a interpretazioni soggettive dei risultati che possono essere fuorvianti.\nPertanto, anzich√© concentrarsi esclusivamente sulla significativit√† statistica, √® preferibile valutare l‚Äôeffetto osservato nel contesto scientifico pi√π ampio e alla luce dei risultati di altre analisi, utilizzando un approccio pi√π completo e critico.\nInfine, in questo capitolo esamineremo il caso specifico della media del campione come stimatore della media della popolazione, esplorando i suoi limiti e le sue applicazioni nella statistica inferenziale di tipo frequentista.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi",
    "title": "80¬† Significativit√† statistica",
    "section": "80.1 Il Test di Ipotesi",
    "text": "80.1 Il Test di Ipotesi\nIl test di ipotesi √® un metodo statistico utilizzato per valutare se i dati sono coerenti con l‚Äôipotesi nulla (\\(H_0\\)). L‚Äôipotesi nulla solitamente afferma che non vi √® alcun effetto o differenza significativa, mentre l‚Äôipotesi alternativa (\\(H_1\\)) rappresenta l‚Äôaffermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l‚Äôipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n80.1.1 La procedura di Test di Ipotesi\nPasso 1: Formulare l‚Äôipotesi nulla (\\(H_0\\)) e l‚Äôipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nNOTA: Decidiamo un‚Äôipotesi non direzionale (nota anche come ipotesi bilaterale) quando testiamo effetti in entrambe le direzioni (la pi√π comune), altrimenti un‚Äôipotesi direzionale (nota anche come ipotesi unilaterale).\nPasso 2: Stabilire un livello di significativit√†, Œ± (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nNOTA: Esistono due tipi fondamentali di test statistici, parametrici e non parametrici. I test parametrici (ad esempio, t-test, ANOVA) dipendono da assunzioni sulla distribuzione del parametro studiato. I test non parametrici (ad esempio, test di Mann-Whitney U, test di Kruskal-Wallis) utilizzano un metodo di ordinamento delle misure e non richiedono tali assunzioni. Tuttavia, i test non parametrici sono tipicamente meno potenti dei test parametrici.\nPasso 4: Decidere se il risultato √® ‚Äústatisticamente significativo‚Äù secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL‚Äôapproccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto √® un insieme di valori per il test statistico per i quali l‚Äôipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l‚Äôipotesi nulla.\nL‚Äôapproccio del valore-p.¬†Il valore-p √® la probabilit√† di ottenere i risultati osservati, o risultati ancora pi√π estremi, se l‚Äôipotesi nulla √® vera.\n\nConfrontiamo il valore-p calcolato con il livello di significativit√† Œ±:\n\nSe il valore-p &lt; Œ±, si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).\nSe il valore-p ‚â• Œ±, non si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "80¬† Significativit√† statistica",
    "section": "80.2 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "80.2 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, √® essenziale chiarire cosa si intende per valore-p.\nL‚ÄôAmerican Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione pu√≤ risultare difficile da comprendere perch√© contiene concetti complessi come ‚Äúprobabilit√†‚Äù e ‚Äúmodello statistico specificato‚Äù. Per capire meglio cosa rappresenta un valore-p, √® necessario esaminare attentamente entrambi questi concetti. Questo ci porter√† anche a una comprensione pi√π profonda di altri concetti fondamentali per l‚Äôinferenza frequentista e ci aiuter√† a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l‚Äôapproccio frequentista e quello bayesiano riguarda l‚Äôinterpretazione della probabilit√†: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla ‚Äúcertezza soggettiva‚Äù o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilit√† assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilit√† sia implicita nella definizione del valore-p fornita dall‚ÄôASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell‚ÄôASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o pi√π grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l‚Äôapproccio frequentista pu√≤ essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "80¬† Significativit√† statistica",
    "section": "80.3 Applicazione alla Media Campionaria",
    "text": "80.3 Applicazione alla Media Campionaria\nIn questo capitolo, esploreremo come applicare il processo del test di ipotesi frequentista alla media campionaria. Analizzeremo come utilizzare la media di un campione per fare inferenze sulla media della popolazione, discutendo i limiti e le applicazioni di questo approccio nell‚Äôinferenza statistica frequentista.\nPer comprendere meglio il concetto di valori-p e l‚Äôapplicazione della verifica del test di ipotesi, √® utile ricorrere a delle simulazioni. Queste permettono di replicare condizioni sperimentali ipotetiche e osservare la variabilit√† dei risultati.\n\n80.3.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo gi√† dimostrato che, se la popolazione √® normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguir√† una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) √® la deviazione standard della popolazione e \\(n\\) √® la dimensione del campione).\n\n\n80.3.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall‚Äôipotesi nulla. Questo processo ci permette di valutare la plausibilit√† di \\(\\mu_0\\) come vera media della popolazione.\n\n\n80.3.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall‚Äôipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata √® incompatibile con \\(\\mu_0\\), portando al rigetto dell‚Äôipotesi nulla.\n\n80.3.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\).\nLa simulazione pu√≤ essere eseguita come segue:\n\n# To make the simulation reproducible\nnp.random.seed(123)\n\nmu_0 = 100\nsigma = 15\nn = 30\nn_sim = 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means = np.random.normal(loc=mu_0, scale=sigma / np.sqrt(n), size=n_sim)\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value = np.sum(sample_means &gt; 105) / n_sim\n\n# Print the p-value\nprint(p_value)\n\n0.0348\n\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l‚Äôipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilit√† di osservare un valore di \\(\\bar{X}\\) cos√¨ estremo (o pi√π estremo) se l‚Äôipotesi nulla fosse vera.\nIl risultato della simulazione pu√≤ essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) √® calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l‚Äôarea sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\nZ = (105 - 100) / (15 / np.sqrt(30))\nprint(Z)\n\n1.8257418583505538\n\n\n\n# Calculate the upper tail probability\nupper_tail_prob = stats.norm.sf(Z)\n\nprint(upper_tail_prob)\n\n0.033944577430914495\n\n\nOppure, in maniera equivalente\n\nupper_tail_prob = 1 - stats.norm.cdf(105, loc=100, scale=15 / np.sqrt(30))\nprint(upper_tail_prob)\n\n0.0339445774309145\n\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 √® 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l‚Äôipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione pu√≤ essere quantificata dalla ‚Äúsorpresa‚Äù indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l‚Äôesperimento viene ripetuto numerose volte sotto l‚Äôipotesi nulla. Questo suggerisce che un risultato del genere √® altamente improbabile se l‚Äôipotesi nulla fosse vera.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#applicazioni-pratiche",
    "title": "80¬† Significativit√† statistica",
    "section": "80.4 Applicazioni pratiche",
    "text": "80.4 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poich√© di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo cos√¨ la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi pu√≤ dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† se il campione casuale √® stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un‚Äôipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† e un livello di significativit√† predefinito, possiamo determinare se i dati osservati supportano o respingono l‚Äôipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-statistiche",
    "title": "80¬† Significativit√† statistica",
    "section": "80.5 Ipotesi statistiche",
    "text": "80.5 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l‚Äôipotesi statistica come una dichiarazione riguardante la distribuzione di probabilit√† di una variabile casuale. Tale ipotesi pu√≤ riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l‚Äôipotesi che riguarda i parametri di una o pi√π popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l‚Äôipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) √® un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L‚Äôipotesi nulla pu√≤ essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene pi√π di un elemento.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "80¬† Significativit√† statistica",
    "section": "80.6 I passi di un test di ipotesi",
    "text": "80.6 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l‚Äôipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un‚Äôipotesi riguardante una propriet√† di una popolazione di interesse e si pu√≤ descrivere nel modo seguente.\nIniziamo formulando l‚Äôipotesi nulla \\(H_0\\), che rappresenta un‚Äôaffermazione specifica sulla popolazione. L‚Äôipotesi alternativa \\(H_1\\) viene formulata come l‚Äôevento complementare rispetto all‚Äôevento specificato dall‚Äôipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l‚Äôipotesi nulla √® vera.\nSuccessivamente, suddividiamo l‚Äôinsieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la ‚Äúregione di accettazione‚Äù \\(\\mathcal{A}\\) e la sua regione complementare, la ‚Äúregione di rifiuto‚Äù \\(\\mathcal{R}\\). La regione di accettazione rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere sotto l‚Äôipotesi nulla, mentre la regione di rifiuto rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere se l‚Äôipotesi nulla √® falsa.\nInfine, selezioniamo un livello di significativit√† \\(\\alpha\\), che rappresenta la massima probabilit√† di respingere erroneamente l‚Äôipotesi nulla quando questa √® vera. Se l‚Äôosservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l‚Äôipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell‚Äôipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l‚Äôipotesi nulla a favore dell‚Äôipotesi alternativa.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-alternativa",
    "title": "80¬† Significativit√† statistica",
    "section": "80.7 Ipotesi alternativa",
    "text": "80.7 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l‚Äôipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative pi√π comuni si suddividono in tre tipi:\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\\(H_1: \\theta &gt; \\theta_0\\),\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell‚Äôipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell‚Äôipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell‚Äôintervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell‚Äôintervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#valore-p",
    "title": "80¬† Significativit√† statistica",
    "section": "80.8 Valore-p",
    "text": "80.8 Valore-p\nIl valore-p √® definito come la probabilit√† che la statistica del test assuma un valore uguale o pi√π estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l‚Äôipotesi nulla. La significativit√† statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l‚Äôevidenza osservata √® improbabile da ottenere se l‚Äôipotesi nulla √® vera. Se il risultato osservato non raggiunge la significativit√† statistica, significa che la stima non √® statisticamente significativa e che il valore osservato pu√≤ essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#un-esempio-motivante",
    "title": "80¬† Significativit√† statistica",
    "section": "80.9 Un esempio motivante",
    "text": "80.9 Un esempio motivante\nPer esplorare il concetto di significativit√† statistica, possiamo prendere in considerazione uno studio svolto da Mehr, Song, e Spelke (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica √® una forma d‚Äôarte presente in molte attivit√† quotidiane e pu√≤ trasmettere informazioni relative alla cultura e all‚Äôappartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr, Song, e Spelke (2016) √® emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale √® un elemento chiave nella preferenza dei bambini, oltre alla familiarit√† con la canzone.\n\n80.9.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr, Song, e Spelke (2016) si √® concentrata sullo studio dell‚Äôinfluenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l‚Äôipotesi principale non pu√≤ essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l‚Äôipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l‚Äôesperimento condotto sui bambini da Mehr, Song, e Spelke (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video ‚Äúfamiliare‚Äù rispetto al tempo di fissazione totale. Poich√© l‚Äôipotesi principale non pu√≤ essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoich√© nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr, Song, e Spelke (2016), l‚Äôipotesi della ricerca non pu√≤ essere valutata direttamente, √® necessario stabilire una connessione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sar√† uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l‚Äôipotesi statistica sar√† \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilit√† casuale.\nInfine, una terza possibilit√† √® che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l‚Äôipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell‚Äôesperimento di Mehr, Song, e Spelke (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di et√†. Ogni bambino avr√† una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video ‚Äúfamiliare‚Äù. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video ‚Äúfamiliare‚Äù e possono essere messi in relazione con il modello statistico.\n\n\n80.9.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica √® cruciale durante il test delle ipotesi. L‚Äôipotesi della ricerca riguarda l‚Äôaffermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l‚Äôipotesi statistica riguarda il modello generativo dei dati, ovvero le propriet√† della popolazione. Nel caso dell‚Äôesperimento condotto da Mehr e colleghi, l‚Äôipotesi della ricerca afferma che la preferenza sociale dei bambini √® influenzata dalla musica e, in particolare, dalla familiarit√† con i materiali musicali. L‚Äôipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video ‚Äúfamiliare‚Äù sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ci√≤ significa che se l‚Äôesperimento non viene condotto nella maniera appropriata, il collegamento tra l‚Äôipotesi statistica e la domanda della ricerca pu√≤ essere spezzato. Ad esempio, se l‚Äôattore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l‚Äôaltro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell‚Äôipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù √® maggiore di 0.5, ma ci√≤ non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "80¬† Significativit√† statistica",
    "section": "80.10 Ipotesi nulla e ipotesi alternativa",
    "text": "80.10 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento √® stato semplice: il ricercatore ha un‚Äôipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un‚Äôipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le propriet√† suggerite dall‚Äôipotesi della ricerca, allora il ricercatore pu√≤ aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, per√≤, il ragionamento diventa contro-intuitivo perch√© non √® possibile verificare direttamente l‚Äôipotesi statistica che corrisponde alla domanda della ricerca.\n\n80.10.1 Apagogia\nIn linea di principio, non √® mai possibile dimostrare direttamente la verit√† di una proposizione. Tuttavia, possiamo dimostrare la sua verit√† in modo indiretto, ovvero provando la falsit√† della sua proposizione complementare.\nL‚Äôesempio classico √® il seguente. Consideriamo la seguente proposizione: ‚ÄúTutti i cigni sono bianchi‚Äù (questo √® l‚Äôesempio ornitologico preferito da Popper). L‚Äôosservazione di un numero qualsiasi di cigni bianchi non √® sufficiente a dimostrare la verit√† di questa proposizione ‚Äì infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c‚Äô√®). D‚Äôaltra parte, invece, l‚Äôosservazione di un solo cigno che non sia bianco (ovvero, per esempio, l‚Äôosservazione di un cigno nero proveniente dall‚ÄôAustralia) pu√≤ falsificare la proposizione considerata. Questa √® la logica del falsificazionismo di Popper.\nQuesto modo di pensare √® stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l‚Äôipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l‚Äôobiettivo di dimostrare falso l‚Äôevento complementare a quello specificato dall‚Äôipotesi statistica associata alla domanda della ricerca. L‚Äôipotesi statistica che vorremmo falsificare si chiama ‚Äúipotesi nulla‚Äù e viene denotata con \\(H_0\\). Nel caso dell‚Äôesempio che stiamo discutendo, l‚Äôipotesi nulla √®: \\(\\mu \\leq 0.5\\). Si noti che l‚Äôipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che √® associata all‚Äôipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ci√≤ che stiamo facendo √® dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere √® che l‚Äôobiettivo di un test di ipotesi frequentista non √® quello di dimostrare che l‚Äôipotesi alternativa √® (probabilmente) vera; l‚Äôobiettivo √® mostrare che l‚Äôipotesi nulla √® (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n\n80.10.2 La similitudine del processo penale\nUn test di ipotesi √® spesso comparato ad un processo penale, dove l‚Äôipotesi nulla rappresenta l‚Äôimputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Cos√¨ come in un processo penale, anche in un test di ipotesi c‚Äô√® una presunzione di innocenza, dove l‚Äôipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di l√† di ogni ragionevole dubbio, che √® falsa. Il ricercatore progetta l‚Äôesperimento in modo da massimizzare la possibilit√† che i dati producano una condanna dell‚Äôipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l‚Äôipotesi nulla. In particolare, sono studiate per garantire che la probabilit√† di una condanna sia bassa se l‚Äôipotesi nulla √® effettivamente vera. √à importante sottolineare che l‚Äôipotesi nulla deve essere protetta, poich√© il ricercatore sta cercando di dimostrare che essa √® falsa.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#due-tipi-di-errori",
    "title": "80¬† Significativit√† statistica",
    "section": "80.11 Due tipi di errori",
    "text": "80.11 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico √® utile capire la logica su cui esso √® basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere pi√π espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, per√≤, questo non √® possibile: a volte il ricercatore √® sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, pu√≤ succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ci√≤ sembra fornire una prova molto forte del fatto che la moneta √® sbilanciata, ma c‚Äô√® una possibilit√† su 1024 che ci√≤ accada anche se la moneta √® equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilit√† che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l‚Äôobiettivo dei test delle ipotesi statistiche non √® quello di eliminare completamente gli errori (questo √® impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per ‚Äúerrori‚Äù. Iniziamo con il rendere esplicito quello che √® ovvio: l‚Äôipotesi nulla pu√≤ essere vera o falsa, e il nostro test ci pu√≤ condurre a rifiutare l‚Äôipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l‚Äôipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L‚Äôerrore di I tipo, denotato con \\(\\alpha\\), √® quello che commettiamo se rigettiamo l‚Äôipotesi nulla quando essa √® vera; l‚Äôerrore di II tipo, denotato con \\(\\beta\\), √® quello che commettiamo se accettiamo l‚Äôipotesi nulla mentre invece √® vera l‚Äôipotesi alternativa.\n\n\n80.11.1 Errore di I tipo: la protezione dei diritti dell‚Äôimputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell‚Äôimputato ‚Äúoltre ogni ragionevole dubbio‚Äù. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilit√† di condannare ingiustamente un imputato innocente: il processo penale √® progettato (almeno in teoria) per proteggere i diritti dell‚Äôimputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L‚Äôerrore che consiste nel punire un innocente viene considerato assai pi√π grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilit√† di un errore di I tipo, con l‚Äôobiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilit√†, denotata con \\(\\alpha\\), viene chiamata ‚Äúlivello di significativit√† del test‚Äù. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significativit√† \\(\\alpha\\) se il tasso di errore di I tipo non √® pi√π grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n\n80.11.2 Errore di II tipo: l‚Äôasimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realt√†, vorremmo tenere anche quello sotto controllo e denotiamo la probabilit√† di un errore di II tipo con \\(\\beta\\). Il livello d‚Äôerrore \\(\\beta\\) viene raramente discusso ed √® molto pi√π comune fare riferimento alla potenza del test, che √® la probabilit√† dell‚Äôevento complementare, ovvero la probabilit√† con cui rifiutiamo l‚Äôipotesi nulla quando √® realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto ‚Äúpotente‚Äù quando √® caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilit√† prefissata.\nSi noti l‚Äôasimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente √® preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) ‚Äì questo si ottiene utilizzando un campione sufficientemente grande ‚Äì ma nella logica della costruzione del test di ipotesi questo aspetto √® secondario rispetto alla necessit√† di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "80¬† Significativit√† statistica",
    "section": "80.12 Come si costruisce un test di ipotesi?",
    "text": "80.12 Come si costruisce un test di ipotesi?\nRitorniamo all‚Äôesempio relativo allo studio di Mehr, Song, e Spelke (2016). In questo caso, sulla base all‚Äôipotesi della ricerca, l‚Äôipotesi nulla pu√≤ essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di et√† media pari a 5.6 mesi, Mehr, Song, e Spelke (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video ‚Äúfamiliare‚Äù nel 56% del tempo totale di fissazione. Dunque, la media campionaria √® \\(\\bar{X} = 0.56\\) Questo √® il valore campionario rilevante per il test dell‚Äôipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall‚Äôipotesi nulla. Nel caso presente, l‚Äôipotesi nulla non specifica un unico valore \\(\\mu\\) ma bens√¨ un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non √® incluso nell‚Äôintervallo specificato da \\(H_0\\). Questo √® incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient‚Äôaltro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c‚Äô√® bisogno di eseguire alcun test statistico ‚Äì abbiamo gi√† trovato la risposta alla domanda della ricerca.\n\n80.12.1 La variabilit√† campionaria\nNel caso dell‚Äôesperimento di Mehr, Song, e Spelke (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell‚Äôintervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) √® falsa? Non cos√¨ presto. Non √® sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cio√® positiva, nel nostro caso). √à anche necessario tenere in considerazione il fenomeno della variabilit√† campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) √® una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumer√† un valore diverso da campione a campione. Le statistiche campionarie ‚Äì nel nostro caso la media \\(\\bar{X}\\) ‚Äì sono di necessit√† diverse dai parametri. Ci√≤ a cui noi siamo interessati √® la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non pu√≤ essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, √® ragionevole pensare che, indipendentemente dal fatto che l‚Äôipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sar√† positive mentre in altri campioni sar√† negativa. Dobbiamo dunque trovare una procedura che riduca la possibilit√† di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n\n80.12.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall‚Äôapproccio frequentista per affrontare questo problema √® quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l‚Äôipotesi nulla. Questo √® il concetto pi√π contro-intuitivo di tutta la procedura di test di ipotesi dell‚Äôapproccio frequentista. Esaminiamolo pi√π in dettaglio.\nLo scopo della procedura di test statistici dell‚Äôapproccio frequentista non √® quello di verificare l‚Äôipotesi alternativa: questo non √® logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all‚Äôipotesi nulla, l‚Äôapproccio frequentista si pone l‚Äôobiettivo di determinare se ci siano indizi sufficienti per ‚Äúcondannare‚Äù l‚Äôipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la ‚Äúpresunzione di innocenza‚Äù di \\(H_0\\) corrisponde all‚Äôidea che dobbiamo assumere come vera l‚Äôipotesi nulla fino a prova contraria.\nNell‚Äôesempio che stiamo discutendo, assumere come vera l‚Äôipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell‚Äôesempio presente, √® possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, √® possibile stabilire quanto sia ‚Äúdistante‚Äù dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) √® la media del campione (nel nostro caso, 0.56), \\(s\\) √® la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) √® l‚Äôampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT = (0.56 - 0.50) / (0.179 / np.sqrt(32))\nprint(T)\n\n1.8961522623996823\n\n\n\n\n80.12.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l‚Äôinsieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) √® sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n\n80.12.4 Quando rifiutare l‚Äôipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l‚Äôipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l‚Äôipotesi nulla in favore dell‚Äôipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto √® costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale √® stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto √® situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l‚Äôipotesi alternativa non √® menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cio√® sulla probabilit√† della statistica test condizionata all‚Äôipotesi nulla \\(H_0\\). L‚Äôipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n\n\n80.12.5 Specificazione delle regioni di rifiuto\nL‚Äôipotesi alternativa \\(H_1\\) pu√≤ assumere forme diverse e ci√≤ conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell‚Äôipotesi alternativa \\(H_1\\).\n\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) √® un generico parametro e \\(\\theta_0\\) √® uno specifico valore del parametro), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([-\\infty, \\theta_0]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di sinistra della distribuzione.\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([\\theta_0, \\infty]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilit√† pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilit√† pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n\n80.12.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il ‚Äúrisultato osservato‚Äù ha una ‚Äòpiccola‚Äô probabilit√† subordinatamente all‚Äôipotesi assunta, respingiamo l‚Äôipotesi. (p.¬†441)\n\nOvviamente l‚Äôipotesi a cui von Mises fa riferimento √® l‚Äôipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l‚Äôipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) ‚Äì i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilit√† di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l‚Äôipotesi nulla √® vera. Se il valore-\\(p\\) √® minore del livello di significativit√† \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ci√≤ conduce al rifiuto dell‚Äôipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l‚Äôesempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libert√†. Il valore-p corrisponde dunque all‚Äôarea sottesa ad una \\(t_{31}\\) nell‚Äôintervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\np = 1 - stats.t.cdf(T, 31)\nprint(p)\n\n0.033647093369739034\n\n\nDato che il valore-p √® minore di \\(\\alpha = 0.05\\), Mehr, Song, e Spelke (2016) rifiutano \\(H_0\\) (cio√® che la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#potenza-del-test",
    "title": "80¬† Significativit√† statistica",
    "section": "80.13 Potenza del test",
    "text": "80.13 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significativit√† e la potenza del test vengono usati per quantificare la qualit√† dell‚Äôinferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa √® vera e dovrebbe respingere \\(H_0\\) in favore dell‚Äôalternativa quando \\(H_1\\) √® vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilit√† indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all‚Äôipotesi che descrive l‚Äôevento ‚Äúnulla di interessante sta succedendo‚Äù ‚Äì ad esempio, ‚Äúla moneta √® bilanciata‚Äù, ‚Äúil trattamento non √® migliore del placebo‚Äù, ecc. ‚Äì e pensare ad \\(H_1\\) come al caso contrario, ovvero: ‚Äústa accadendo qualcosa di interessante‚Äù. Quindi la potenza del test, ovvero la probabilit√† \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa √® falsa, corrisponde alla probabilit√† di rilevare qualcosa di interessante, quando qualcosa di interessante √® effettivamente successo, mentre il livello di significativit√† corrisponde alla probabilit√† di affermare che qualcosa di interessante si √® verificato, quando in realt√† non √® successo nulla di interessante.\nIl calcolo della potenza di un test √® spesso difficile, perch√© richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando √® vera l‚Äôipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosit√† del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale √® importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n80.13.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non √® lineare, poich√© Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una ‚Äúverit√† definitiva‚Äù su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un‚Äôunica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilit√† di osservare, sotto l‚Äôipotesi nulla, il risultato ottenuto o uno ancora pi√π estremo. Se il valore-\\(p\\) √® piccolo, Fisher rifiutava l‚Äôipotesi nulla. Tuttavia, poich√© non venivano formulate altre ipotesi, non c‚Äôera modo di ‚Äúaccettare l‚Äôalternativa‚Äù.\nAl contrario, Neyman adottava un approccio pi√π formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l‚Äôipotesi nulla o l‚Äôalternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l‚Äôipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilit√† del risultato del test o di uno pi√π estremo sotto l‚Äôipotesi nulla, ma forniva una descrizione astratta dei ‚Äúpossibili test‚Äù che portavano all‚Äôaccettazione dell‚Äôipotesi nulla o dell‚Äôalternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un‚Äôipotesi nulla e un‚Äôipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l‚Äôipotesi alternativa, mentre altri sono pi√π vaghi in merito, adottando l‚Äôapproccio di Fisher. Inoltre, c‚Äô√® disaccordo tra i ricercatori riguardo alla possibilit√† di ‚Äúaccettare l‚Äôalternativa‚Äù, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il ‚Äúpeccato originale‚Äù della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi pi√π specifici per cui questo approccio, noto come significativit√† statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilit√† dei risultati della ricerca in psicologia e in altri campi. Nel capitolo Capitolo 86 esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "80¬† Significativit√† statistica",
    "section": "80.14 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "80.14 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l‚Äôanalisi della procedura dei test di ipotesi statistici esaminando l‚Äôevento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell‚Äôinferenza statistica, focalizzata sul test dell‚Äôipotesi nulla. Questo episodio √® descritto dettagliatamente da Etz et al. (2018). L‚Äôaneddoto riguarda un t√® che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contest√≤ il metodo adottato da Fisher, asserendo che il t√® avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell‚Äôacqua bollente. Per verificare l‚Äôaffermazione della Dr.ssa Bristol, Fisher ide√≤ un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del t√® in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalit√† di preparazione? Per risolvere questa questione, Fisher elabor√≤ la sua metodologia per il test dell‚Äôipotesi nulla. Utilizz√≤ un valore-\\(p\\) calcolato sulla base della probabilit√† dell‚Äôevento osservato, nonch√© di qualsiasi altro evento pi√π estremo che potrebbe verificarsi sotto l‚Äôipotesi nulla.\nTuttavia, √® stato fatto notare che l‚Äôapproccio di Fisher al test dell‚Äôipotesi nulla pu√≤ essere insufficiente e portare a conclusioni errate Etz et al. (2018). Una delle questioni fondamentali riguarda la definizione di un evento ‚Äúpi√π estremo‚Äù rispetto a quello osservato. Ad esempio, se Fisher avesse preparato esattamente sei t√® e la Dr.¬†Bristol ne avesse identificati correttamente cinque, il valore-\\(p\\) calcolato sarebbe stato 0.109, che non √® statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l‚Äôipotesi nulla che la Dr.¬†Bristol stesse semplicemente indovinando.\nTuttavia, se Fisher avesse continuato a servire t√® fino a quando la Dr.¬†Bristol non avesse raggiunto cinque risposte corrette (un risultato che, per coincidenza, si √® verificato dopo sei tentativi), il valore-\\(p\\) calcolato sarebbe stato 0.031, che √® statisticamente significativo. In quest‚Äôultimo caso, l‚Äôipotesi nulla sarebbe stata respinta.\nQuello che emerge √® che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni diverse a causa delle diverse modalit√† di campionamento impiegate. Questa variabilit√† √® problematica poich√© il valore-\\(p\\), e quindi la nostra valutazione delle capacit√† discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell‚Äôipotesi nulla come strumento fondamentale per l‚Äôinferenza scientifica.\nPer risolvere il problema discusso in precedenza, utilizzeremo due specifiche distribuzioni statistiche: la distribuzione binomiale e la distribuzione geometrica negativa. L‚Äôanalisi sar√† condotta utilizzando Python come strumento di calcolo.\n\n80.14.1 Distribuzione Binomiale\nLa distribuzione binomiale diventa pertinente quando il numero di tentativi √® prefissato e conosciuto a priori. Nel contesto dell‚Äôesempio del t√®, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilit√† di registrare esattamente $ k $ successi in $ n $ tentativi √® la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) √® la probabilit√† di un singolo successo (ossia di indovinare correttamente la preparazione del t√®), e \\((1-p)\\) √® la probabilit√† di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilit√† di ottenere un risultato di 5 o pi√π successi su un totale di 6 tentativi.\n\n\n80.14.2 Distribuzione Geometrica Negativa\nNel caso in cui continuiamo a servire t√® fino a quando non vengono raggiunti cinque successi, utilizziamo una variante della distribuzione geometrica chiamata distribuzione geometrica negativa. In questo contesto, il valore-\\(p\\) √® calcolato considerando la probabilit√† di avere un certo numero di fallimenti \\(k\\) prima di ottenere cinque successi. In particolare, abbiamo sommato le probabilit√† per \\(k\\) che varia da 0 a \\((6 - 5)\\).\nLa formula per la probabilit√† in una distribuzione geometrica negativa di avere $ k $ fallimenti prima di $ n $ successi √® la seguente:\n\\[\nP(X = k) = \\binom{k+n-1}{k} \\times (1-p)^{k} \\times p^n\n\\]\nDove \\(k\\) rappresenta il numero di fallimenti e \\(n\\) il numero di successi. Il valore-\\(p\\) √® stato calcolato sommando queste probabilit√†.\nQuesto approccio ci permette di calcolare un valore-\\(p\\) che tiene conto del numero di fallimenti prima del quinto successo.\n\n# Parametri\nn_binomial = 6  # Numero fisso di tentativi per la distribuzione binomiale\nn_success = 5  # Numero di successi desiderato\np = 0.5  # Probabilit√† di successo (indovinare la tazza di t√®)\n\n# Calcolo del p-value per la distribuzione binomiale\np_value_binomial = 1 - binom.cdf(n_success - 1, n_binomial, p)\n\n# Calcolo del p-value per la distribuzione geometrica negativa\np_value_geom_corrected = 0\nfor k in range(n_binomial - n_success):  # Numero di fallimenti prima del 5¬∞ successo\n    p_value_geom_corrected += (\n        comb(k + n_success - 1, k) * ((1 - p) ** k) * (p**n_success)\n    )\n\np_value_binomial, p_value_geom_corrected\n\n(0.109375, 0.03125)\n\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value √® \\(0.109\\), che non √® statisticamente significativo (dato che √® maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l‚Äôipotesi nulla che Dr.¬†Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value √® \\(0.031\\), che √® statisticamente significativo (dato che √® minore di 0.05); in questo caso, dovremmo rigettare l‚Äôipotesi nulla, suggerendo che Dr.¬†Bristol non sta semplicemente indovinando.\n\nLa presente discussione dimostra che, in base alla procedura del test dell‚Äôipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) pu√≤ portare a conclusioni diverse a seconda delle ipotesi sul processo di campionamento.\n\n\n80.14.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un‚Äôalternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire ‚Äúrisultati pi√π estremi‚Äù che non sono stati osservati. L‚Äôapproccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilit√† iniziali (o ‚Äúa priori‚Äù) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilit√† a Priori: Iniziamo assegnando una distribuzione di probabilit√† a priori a tutti i possibili tassi di successo che la Dr.¬†Bristol potrebbe avere. Questo include una probabilit√† specifica per l‚Äôipotesi nulla, che suggerisce che la Dr.¬†Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilit√† con Dati Osservati: Utilizziamo i dati raccolti nell‚Äôesperimento per aggiornare le nostre probabilit√† a priori. Questo aggiornamento √® fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilit√† delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l‚Äôipotesi alternativa rispetto all‚Äôipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato √® risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto pi√π compatibili con l‚Äôipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del t√®, piuttosto che con l‚Äôipotesi che stia indovinando.\nEtz et al. (2018) concludono che l‚Äôapproccio bayesiano offre un quadro pi√π robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di ‚Äúrisultati pi√π estremi‚Äù non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l‚Äôapproccio bayesiano una soluzione pi√π solida per valutare le ipotesi scientifiche.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "80¬† Significativit√† statistica",
    "section": "80.15 Malintesi sul valore-p",
    "text": "80.15 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p.¬†Ne esaminiamo qui quelli pi√π comuni.\nMalinteso 1: Un valore p non significativo significa che l‚Äôipotesi nulla √® vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l‚Äôassenza di effetto o la verit√† dell‚Äôipotesi nulla √® diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilit√† dei dati osservati sotto l‚Äôipotesi nulla, e non la probabilit√† dell‚Äôipotesi stessa. Un valore p elevato non dimostra che l‚Äôipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l‚Äôipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significativit√† statistica.\nInvece di concludere affrettatamente l‚Äôassenza di effetto da un valore p non significativo, dovremmo riconoscere l‚Äôambiguit√† e considerare altre possibilit√†. Dichiarazioni come ‚Äúnon c‚Äôera differenza‚Äù dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell‚Äôesistenza di un effetto reale.\nL‚Äôapproccio bayesiano offre una prospettiva diversa che pu√≤ essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilit√† dei dati sotto l‚Äôipotesi nulla, l‚Äôinferenza bayesiana permette di calcolare direttamente la probabilit√† delle ipotesi date i dati.\nL‚Äôapproccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l‚Äôipotesi nulla, ma quantifica la forza dell‚Äôevidenza a favore di un‚Äôipotesi rispetto all‚Äôaltra, fornendo una conclusione pi√π informativa rispetto al semplice ‚Äúnon posso rifiutare l‚Äôipotesi nulla‚Äù.\nMalintesto 2: Un valore p significativo significa che l‚Äôipotesi nulla √® falsa.\nCome spiegato in precedenza, il valore-p quantifica la ‚Äúsorpresa‚Äù suscitata dai dati, alla luce dell‚Äôipotesi nulla. Non ci dice niente sull‚Äôipotesi che abbiamo assunto per quantificare la ‚Äúsorpresa‚Äù.\nMalinteso 3: Un valore p significativo significa che √® stato scoperto un effetto importante.\nLa distinzione tra ‚Äúsignificativit√† statistica‚Äù e ‚Äúrilevanza pratica‚Äù √® fondamentale: mentre la prima indica semplicemente che un risultato √® improbabile sotto l‚Äôipotesi nulla, la seconda valuta l‚Äôeffetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l‚Äôeffetto abbia un impatto pratico notevole o utile.\nInoltre, al di l√† della significativit√† pratica, l‚Äôabitudine di molti psicologi di escludere i predittori che non risultano ‚Äústatisticamente significativi‚Äù √® un grossolano errore: la significativit√† statistica non pu√≤ essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l‚Äôipotesi nulla √® vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perch√© i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. √à principalmente l‚Äôetichetta verbale ‚Äúsignificativo‚Äù che causa confusione qui: in un contesto frequentista, un effetto ‚Äúsignificativo‚Äù √® un effetto ‚Äúsorprendente‚Äù alla luce di \\(H_0\\), non √® necessariamente un effetto ‚Äúimportante‚Äù.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilit√† che abbiate commesso un errore di Tipo 1 (un falso positivo) √® del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilit√† del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilit√† del 5% si riferisce al tasso di errore di Tipo 1, che √® la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l‚Äôipotesi nulla se questa fosse vera, su molteplici ripetizioni dell‚Äôesperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l‚Äôipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che ‚Äúla probabilit√† che questo particolare risultato sia un errore di Tipo 1 √® del 5%‚Äù. In realt√†, in quel momento specifico, l‚Äôevento (commettere un errore di Tipo 1) √® gi√† accaduto o non √® accaduto; la probabilit√† associata a quel singolo risultato non √® pi√π applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato √®, per cos√¨ dire, una realt√† fissa: o abbiamo rilevato un effetto che in realt√† non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione √® cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l‚Äôimportanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p √® la probabilit√† che l‚Äôeffetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilit√† di replicazione di un effetto √® un malinteso diffuso. In realt√†, la probabilit√† di replicazione di un effetto non pu√≤ essere direttamente calcolata dal valore p di un singolo studio a causa della complessit√† dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell‚Äôeffetto, dalla dimensione del campione e dal livello di significativit√† Œ±, fornisce una stima della probabilit√† di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilit√† del 97% che tale effetto si replichi in studi futuri. La possibilit√† di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilit√† di un effetto √® influenzata da molti fattori e non pu√≤ essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l‚Äôinterpretazione corrette della replicabilit√† richiedono un‚Äôanalisi dettagliata della potenza statistica e della dimensione dell‚Äôeffetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "80¬† Significativit√† statistica",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon May 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy : 1.13.0\nxarray: 2024.3.0\nnumpy : 1.26.4\narviz : 0.18.0\npymc  : 5.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nEtz, Alexander, Quentin F Gronau, Fabian Dablander, Peter A Edelsbrunner, e Beth Baribault. 2018. ¬´How to become a Bayesian in eight easy steps: An annotated reading list¬ª. Psychonomic bulletin & review 25 (1): 219‚Äì34.\n\n\nMehr, S. A., L. A. Song, e E. S. Spelke. 2016. ¬´For 5-month-old infants, melodies are social¬ª. Psychological Science 27 (4): 486‚Äì501.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html",
    "title": "81¬† Test t di Student per campioni indipendenti",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo il test \\(t\\) di Student per campioni indipendenti, uno dei test statistici frequentisti pi√π ampiamente utilizzati nella pratica.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "81¬† Test t di Student per campioni indipendenti",
    "section": "81.1 Applicazioni del Test t di Student",
    "text": "81.1 Applicazioni del Test t di Student\nIl test t di Student per due campioni indipendenti √® un metodo statistico utilizzato per determinare se le medie di due campioni indipendenti sono significativamente diverse. Questo test si applica quando i due campioni sono estratti da popolazioni diverse e non vi √® alcuna correlazione tra le osservazioni di un campione e quelle dell‚Äôaltro.\nPer condurre il test t di Student per due campioni indipendenti, calcoliamo la differenza tra le medie dei due campioni e le stime delle varianze campionarie delle rispettive popolazioni. L‚Äôipotesi nulla del test √® che le medie dei due campioni siano uguali, mentre l‚Äôipotesi alternativa a due code √® che le medie dei due campioni siano diverse. La statistica del test t viene calcolata come il rapporto tra la differenza delle medie campionarie e la deviazione standard media campionaria.\nSuccessivamente, confrontiamo la statistica t con la distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libert√†, dove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni. Calcoliamo quindi il valore-p dalla distribuzione t per determinare la significativit√† del test.\nEsistono due approcci per stimare la varianza. Se assumiamo che le due popolazioni abbiano la stessa varianza (omoschedasticit√†), utilizziamo una stima pooled della varianza. Questo metodo √® considerato efficiente quando l‚Äôomoschedasticit√† √® verificata (argomento correction = False in pg.ttest()). Invece, se supponiamo che le due popolazioni abbiano varianze diverse, utilizziamo due stime separate delle varianze per i due campioni, chiamato test di Welch (argomento correction = True in pg.ttest()). Questo approccio √® pi√π robusto quando le varianze dei due gruppi sono significativamente diverse.\nLe principali assunzioni del test t di Student per due campioni indipendenti sono l‚Äôindipendenza dei due campioni e la normalit√† della distribuzione delle popolazioni da cui sono stati estratti i campioni.\nDi seguito √® riportato il calcolo della stima della deviazione standard pooled, utilizzata per standardizzare la differenza tra le medie dei due campioni quando l‚Äôassunzione di omoschedasticit√† √® verificata:\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(s_p\\) √® la deviazione standard pooled, \\(n\\) e \\(m\\) sono le dimensioni dei due campioni, \\(s^2_0\\) e \\(s^2_1\\) sono le varianze campionarie dei due gruppi.\nLa statistica del test t √® quindi calcolata come:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{1/n_1 + 1/n_2}},\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie campionarie dei due gruppi.\n\n81.1.1 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, supponiamo di avere due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\) che sono estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da: \\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j\n\\]\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono entrambe stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono date da:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\n\\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m}\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le propriet√† di varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y})\n\\]\ndato che i termini incrociati si annullano per l‚Äôindipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\) abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m}\n\\]\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right)\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie √® una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti dobbiamo considerare l‚Äôincertezza aggiuntiva che deriva dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore di stimare \\(\\sigma\\) √® quello di utilizzare le due deviazioni standard dei campioni (calcolate come stimatori della varianza della popolazione) ponderate per i rispettivi gradi di libert√†, come indicato in precedenza per la deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosit√† dei due campioni.\n\n\n81.1.2 Un esempio concreto\nEsaminiamo un esempio concreto. Supponiamo di disporre di nove misure del peso per un gruppo di donne e di nove misure di peso per un gruppo di uomini. Ci chiediamo se, nella popolazione, la media del peso dei due gruppi sia diversa.\nCreiamo due array con i dati e li inseriamo in un DataFrame.\n\nwomen_weight = np.array([38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5])\nmen_weight = np.array([67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4])\n\nweight = np.concatenate((women_weight, men_weight))\nprint(weight)\n\n[38.9 61.2 73.3 21.8 63.4 64.6 48.4 48.8 48.5 67.8 60.  63.4 76.  89.4\n 73.3 67.3 61.3 62.4]\n\n\nCreaiamo una variabile che specifica l‚Äôappartenenza al gruppo.\n\nis_female = np.repeat([1, 0], 9)\nis_female\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\ndf = pd.DataFrame({\"is_female\": is_female, \"weight\": weight})\ndf\n\n\n\n\n\n\n\n\n\nis_female\nweight\n\n\n\n\n0\n1\n38.9\n\n\n1\n1\n61.2\n\n\n2\n1\n73.3\n\n\n3\n1\n21.8\n\n\n4\n1\n63.4\n\n\n5\n1\n64.6\n\n\n6\n1\n48.4\n\n\n7\n1\n48.8\n\n\n8\n1\n48.5\n\n\n9\n0\n67.8\n\n\n10\n0\n60.0\n\n\n11\n0\n63.4\n\n\n12\n0\n76.0\n\n\n13\n0\n89.4\n\n\n14\n0\n73.3\n\n\n15\n0\n67.3\n\n\n16\n0\n61.3\n\n\n17\n0\n62.4\n\n\n\n\n\n\n\n\nQui sotto √® riportato un KDE plot per i dati di tutto il campione.\n\ndensity = gaussian_kde(df[\"weight\"])\nx_vals = np.linspace(min(df[\"weight\"]), max(df[\"weight\"]), 1000)\ndensity = density.evaluate(x_vals)\n\nplt.plot(x_vals, density)\nplt.xlabel('Weight')\n_ = plt.ylabel('Density')\n\n\n\n\n\n\n\n\nDal DataFrame estraiamo due array contenenti i valori dei pesi dei due gruppi.\n\nweight_f = df.loc[df[\"is_female\"] == 1, \"weight\"]\nweight_m = df.loc[df[\"is_female\"] == 0, \"weight\"]\n\nCalcoliamo la deviazione standard pooled.\n\ns_pool_num = np.sum(\n    [\n        (len(weight_f) - 1) * np.std(weight_f, ddof=1) ** 2,\n        (len(weight_m) - 1) * np.std(weight_m, ddof=1) ** 2,\n    ]\n)\ns_pool_denom = len(weight_f) + len(weight_m) - 2\n\ns_pool = np.sqrt(np.divide(s_pool_num, s_pool_denom))\ns_pool\n\n12.86771368796942\n\n\nCalcoliamo la statistica test.\n\nt_num = np.mean(weight_f) - np.mean(weight_m)\nt_denom = s_pool * np.sqrt(1 / len(weight_f) + 1 / len(weight_m))\nT = np.divide(t_num, t_denom)\nT\n\n-2.7842353699254567\n\n\nI gradi di libert√† sono:\n\nlen(weight_f) + len(weight_m) - 2\n\n16\n\n\nIl valore-p √® uguale a\n\nstats.t.cdf(T, df=16) * 2\n\n0.013265602643801042\n\n\nRifacciamo ora i calcoli usando la funzione ttest del pacchatto pingouin. L‚Äôargomento paired = False specifica che i due campioni sono indipendenti; l‚Äôargomento correction=False specifica che non verr√† usata la correzione di Welch per varianze separate.\n\nres = pg.ttest(weight_m, weight_f, paired=False, correction=False)\nprint(res)\n\n               T  dof alternative     p-val          CI95%   cohen-d   BF10  \\\nT-test  2.784235   16   two-sided  0.013266  [4.03, 29.75]  1.312501  4.251   \n\n           power  \nT-test  0.743519  \n\n\nIl risultato conferma quanto trovato in precedenza attraverso i calcoli effettuati. Il valore-\\(p\\) indica che possiamo rifiutare l‚Äôipotesi nulla di uguaglianza delle medie delle due popolazioni. Quindi, possiamo concludere con un livello di confidenza del 95% che la media del peso dei maschi nella popolazione √® superiore alla media del peso delle femmine nella popolazione.\nSe vogliamo un test pi√π robusto, che non assume l‚Äôomogeneit√† delle varianze, usiamo la correzione di Welch:\n\nres = pg.ttest(weight_m, weight_f, paired=False, correction=True)\nprint(res)\n\n               T        dof alternative     p-val         CI95%   cohen-d  \\\nT-test  2.784235  13.113752   two-sided  0.015384  [3.8, 29.98]  1.312501   \n\n         BF10     power  \nT-test  4.251  0.743519  \n\n\nLa statistica test resta immutata. Quello che cambiano sono i gradi di libert√†. Con questa correzione dei gradi di libert√†, il p-valore diventa pi√π grande.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#interpretazione-dei-risultati",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#interpretazione-dei-risultati",
    "title": "81¬† Test t di Student per campioni indipendenti",
    "section": "81.2 Interpretazione dei Risultati",
    "text": "81.2 Interpretazione dei Risultati\nIl test t di Student per campioni indipendenti ha generato un p-valore di 0.013, inferiore alla soglia di significativit√† di Œ± = 0.05. Questo indica che la differenza osservata tra i gruppi √® statisticamente significativa. Tuttavia, anzich√© limitarci a etichettare il risultato come ‚Äústatisticamente significativo‚Äù, √® importante considerare cosa implica questo esito nel contesto della ricerca.\nIn sostanza, il basso p-valore ci porta a rifiutare l‚Äôipotesi nulla, suggerendo che √® improbabile che le differenze osservate nei dati siano dovute al caso. Questo ci permette di concludere con una certa fiducia che esiste una differenza reale tra le medie delle popolazioni da cui i campioni sono stati estratti. Questa interpretazione apre la strada a ulteriori indagini sulle cause di tale differenza e sulle loro implicazioni teoriche o pratiche.\nSe il p-valore fosse stato superiore alla soglia di significativit√† Œ±, avremmo interpretato il risultato in modo diverso. Un p-valore maggiore di Œ± indica che i dati osservati non sono incompatibili con l‚Äôipotesi nulla. In altre parole, non avremmo avuto motivi statistici sufficienti per rifiutare l‚Äôipotesi nulla. Tuttavia, √® importante sottolineare che questo non equivale a dimostrare che l‚Äôipotesi nulla sia vera; piuttosto, i dati non forniscono evidenza sufficiente per confutarla.\nIn pratica, la non rifiutazione dell‚Äôipotesi nulla significa che i dati sono compatibili sia con l‚Äôipotesi nulla sia con altre possibili ipotesi sulle caratteristiche della popolazione. Di conseguenza, in assenza di evidenza contraria, ci asteniamo dal fare affermazioni conclusive e manteniamo una posizione di neutralit√† riguardo l‚Äôipotesi nulla, rimanendo aperti alla possibilit√† di ulteriori indagini e dati futuri che potrebbero chiarire meglio la questione.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#riportare-i-risultati",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#riportare-i-risultati",
    "title": "81¬† Test t di Student per campioni indipendenti",
    "section": "81.3 Riportare i risultati",
    "text": "81.3 Riportare i risultati\nPer riportare i risultati si pu√≤ usare un testo come quello seguente:\n\nAbbiamo condotto un test \\(t\\) di Student per campioni indipendenti per confrontare le medie dei due gruppi. I risultati indicano una differenza tra le medie dei gruppi (\\(t\\)(16) = 2.78, \\(p\\) = 0.013). L‚Äôintervallo di confidenza al 95% per la differenza delle medie √® tra 4.03 e 29.75. L‚Äôampiezza dell‚Äôeffetto, misurata con Cohen‚Äôs \\(d\\), √® stata di 1.31, indicando un effetto grande secondo le convenzioni comunemente accettate. La potenza statistica del test, calcolata post hoc, √® stata del 74.4%, indicando una buona probabilit√† di rilevare un effetto, se presente.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "title": "81¬† Test t di Student per campioni indipendenti",
    "section": "81.4 Test Unidirezionali e Bidirezionali",
    "text": "81.4 Test Unidirezionali e Bidirezionali\nIl criterio secondo il quale un p-valore inferiore a Œ± indica una ‚Äúsignificativit√† statistica‚Äù √® comune sia nei test bidirezionali sia nei test unidirezionali, ma l‚Äôapplicazione differisce a seconda della natura dell‚Äôipotesi testata.\n\n81.4.1 Test Bidirezionale\nNel caso di un test bidirezionale, le ipotesi sono formulate come segue: - Ipotesi nulla (H‚ÇÄ): \\(\\mu_1 = \\mu_2\\) (cio√®, \\(\\mu_1 - \\mu_2 = 0\\)); si assume uguaglianza delle varianze (\\(\\sigma^2_1 = \\sigma^2_2\\)). - Ipotesi alternativa (H‚ÇÅ): \\(\\mu_1 \\neq \\mu_2\\); ancora con uguaglianza delle varianze.\nLa statistica test √® calcolata come $ {Y}_1 - {Y}_2 $, dove \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) sono le medie campionarie dei due gruppi. La regione di rifiuto dell‚Äôipotesi nulla √® equamente divisa tra le due code della distribuzione della statistica test, con Œ±/2 per coda.\n\n\n81.4.2 Test Unidirezionale\nPer i test unidirezionali, la direzione della differenza che si sta testando √® cruciale:\n\nQuando si testa se \\(\\mu_1\\) √® minore di \\(\\mu_2\\):\n\nIpotesi nulla (H‚ÇÄ): \\(\\mu_1 \\geq \\mu_2\\);\nIpotesi alternativa (H‚ÇÅ): \\(\\mu_1 &lt; \\mu_2\\).\n\nLa statistica test √® calcolata come $ {Y}_1 - {Y}_2 $. Se questa differenza √® significativamente negativa (cio√® cade nella coda sinistra oltre il valore critico), supporta H‚ÇÅ.\nQuando si testa se \\(\\mu_1\\) √® maggiore di \\(\\mu_2\\):\n\nIpotesi nulla (H‚ÇÄ): \\(\\mu_1 \\leq \\mu_2\\);\nIpotesi alternativa (H‚ÇÅ): \\(\\mu_1 &gt; \\mu_2\\).\n\nAnche qui, la statistica test √® $ {Y}_1 - {Y}_2 $. Un risultato che supera il valore critico nella coda destra indica supporto per H‚ÇÅ.\n\nIn ogni tipo di test unidirezionale, la regione di rifiuto occupa l‚Äôintero Œ± dell‚Äôarea sotto la curva di densit√†, ma √® posizionata completamente nella coda specificata dall‚Äôipotesi alternativa.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "title": "81¬† Test t di Student per campioni indipendenti",
    "section": "81.5 Considerazioni sugli Errori di Tipo I e Tipo II",
    "text": "81.5 Considerazioni sugli Errori di Tipo I e Tipo II\nLa scelta di un livello di significativit√† \\(\\alpha = 0.05\\) implica che, nel contesto di un test d‚Äôipotesi, esiste una probabilit√† del 5% di commettere un errore di Tipo I. Questo tipo di errore si verifica quando l‚Äôipotesi nulla √® vera ma, a causa della variabilit√† casuale nei dati del campione, otteniamo risultati abbastanza estremi da rifiutare erroneamente \\(H_0\\).\nUn errore di Tipo II, invece, si verifica quando l‚Äôipotesi nulla √® falsa, ma i dati del campione non sono sufficientemente estremi da giustificare il suo rifiuto. La probabilit√† di commettere un errore di Tipo II √® spesso influenzata dalla dimensione del campione: campioni pi√π piccoli tendono ad avere una potenza statistica inferiore, aumentando il rischio di non rifiutare \\(H_0\\) quando sarebbe appropriato farlo. La potenza statistica di un test, che rappresenta la probabilit√† di rifiutare correttamente l‚Äôipotesi nulla quando √® falsa, pu√≤ essere stimata, ma questa stima pu√≤ diventare complessa.\nPer i modelli statistici complessi, la stima della potenza pu√≤ essere particolarmente difficile. Non solo i calcoli possono essere intricati, ma non esiste un metodo unico e standardizzato per effettuare tali stime, richiedendo l‚Äôintroduzione di diverse assunzioni.\nLa funzione ttest del pacchetto pingouin offre un modo per calcolare la potenza di un test in contesti di test statistici relativamente semplici.",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "81¬† Test t di Student per campioni indipendenti",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npingouin  : 0.5.4\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza frequentista",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "82¬† Introduzione",
    "section": "",
    "text": "In psicologia, nelle scienze sociali e in altre discipline √® in corso una Riforma Metodologica, nata da una profonda crisi che ha colpito la scienza contemporanea: la Crisi di Replicazione dei risultati delle ricerche. Questa crisi mina la credibilit√† della ricerca scientifica e ha motivato una profonda revisione della metodologia alla base della ricerca psicologica e non solo. La crisi di replicazione ha molte cause: frode, pratiche di ricerca disoneste e incentivi distorti forniti dal sistema accademico. Una delle cause della crisi di replicazione √® particolarmente rilevante per un corso sull‚Äôanalisi dei dati psicologici: l‚Äôutilizzo delle tecniche inferenziali di stampo frequentista, che ha portato alla proliferazione di pubblicazioni contenenti falsi positivi.\nIn questa sezione della dispensa, metteremo in evidenza i limiti dell‚Äôinferenza frequentista, riconosciuti negli ultimi decenni come una delle principali cause della crisi della riproducibilit√† dei risultati della ricerca (Baker 2016). Infine, discuteremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman e Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista.\n\n\n\n\nBaker, Monya. 2016. ¬´Reproducibility Crisis¬ª. Nature 533 (7604): 452‚Äì54.\n\n\nGelman, Andrew, e John Carlin. 2014. ¬´Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors¬ª. Perspectives on Psychological Science 9 (6): 641‚Äì51.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Introduzione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "83¬† La Crisi della Replicazione",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, viene presentata un‚Äôintroduzione al fenomeno scientifico e culturale della crisi della replicazione. Si discutono alcune delle cause principali e si sottolinea l‚Äôimportanza dell‚Äôapproccio statistico frequentista in questa crisi.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "href": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.1 Feeling the Future",
    "text": "83.1 Feeling the Future\nIl 2011 segn√≤ un punto di svolta per la comunit√† scientifica, sebbene l‚Äôimpatto non fosse immediatamente percepibile a tutti. In quell‚Äôanno emerse la cosiddetta ‚Äúcrisi della replicazione‚Äù, un fenomeno che, pur non influenzando direttamente la vita quotidiana della maggior parte delle persone, compresi molti psicologi il cui campo fu il pi√π colpito, avrebbe avuto profonde ripercussioni sul mondo della ricerca. Tuttavia, per coloro che possedevano anche solo di una basilare comprensione della statistica e erano pi√π interessati alla ricerca della verit√† che all‚Äôaccumulo di citazioni o all‚Äôavanzamento di carriera, quell‚Äôanno assunse le caratteristiche di un vero e proprio ‚ÄúAnno Zero‚Äù. Questo momento cruciale mise in luce problematiche fondamentali nei metodi di ricerca e nell‚Äôinterpretazione dei risultati, gettando le basi per un rinnovamento delle pratiche scientifiche.\n\n83.1.1 La Scoperta di Frodi e Risultati Controversi\n\n83.1.1.1 Il Caso Diederik Stapel\nUno dei primi segnali della crisi fu la scoperta della frode scientifica commessa da Diederik Stapel, una stella nascente della psicologia sociale e professore presso l‚ÄôUniversit√† di Tilburg nei Paesi Bassi, aveva attirato l‚Äôattenzione con una serie di articoli sensazionali: uno suggeriva che mangiare carne rendeva le persone pi√π antisociali; un altro sosteneva che le persone sono pi√π inclini al razzismo se l‚Äôambiente circostante √® pieno di rifiuti. Tuttavia, si scopr√¨ che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti n√© raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati.\n\n\n83.1.1.2 Lo Studio ‚ÄúFeeling the Future‚Äù di Daryl Bem\nNello stesso anno, Daryl Bem della Cornell University pubblic√≤ uno studio intitolato ‚ÄúFeeling the Future‚Äù (Bem 2011), che avrebbe scosso ulteriormente le fondamenta della psicologia sociale. Lo studio di Bem si inseriva nella tradizione degli esperimenti di ‚Äúpriming‚Äù, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ‚Äô70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio √® lo studio di John Bargh del 1996, che dimostr√≤ come l‚Äôesposizione a parole associate all‚Äôet√† avanzata inducesse i soggetti a camminare pi√π lentamente (Bargh, Chen, e Burrows 1996). Un altro studio del 2006 rivel√≤ che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilit√† della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali. Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in met√† delle prove, il priming avveniva dopo che i soggetti avevano gi√† visto e valutato l‚Äôimmagine (Bem 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano pi√π veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l‚Äôipotesi nulla.\nBem interpret√≤ questi risultati come prova della chiaroveggenza, una conclusione che suscit√≤ notevoli controversie e ridicolizz√≤ la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l‚Äôordine temporale invertito, mostrarono risultati altrettanto significativi.\nQuesti risultati ponevano la comunit√† scientifica di fronte a un dilemma: accettare l‚Äôesistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validit√† dei suoi risultati come prova dell‚Äôesistenza di capacit√† precognitive.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "href": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.2 Pratiche di Ricerca Disoneste e Loro Conseguenze",
    "text": "83.2 Pratiche di Ricerca Disoneste e Loro Conseguenze\nLo studio di Bem, che portava a conclusioni insensate, si rivel√≤ un catalizzatore per un esame critico delle pratiche di ricerca in psicologia, innescando un dibattito che avrebbe avuto profonde ripercussioni sull‚Äôintera disciplina (Ritchie, Wiseman, e French 2012).\nGi√† nel 2005, John Ioannidis dell‚ÄôUniversit√† di Stanford aveva previsto la crisi imminente nel suo articolo ‚ÄúWhy Most Published Research Findings Are False‚Äù (Ioannidis 2005). Il nucleo della critica di Ioannidis riguardava l‚Äôapproccio interpretativo dei dati sperimentali. Secondo la sua analisi, il problema fondamentale risiedeva nel fatto che molti scienziati non valutavano correttamente la probabilit√† che la loro ipotesi fosse vera alla luce dei dati raccolti. Al contrario, seguendo l‚Äôapproccio tradizionale ispirato ai lavori di Bernoulli e Fisher, si concentravano sulla probabilit√† di ottenere i dati osservati nell‚Äôipotesi che la loro teoria fosse falsa.\n\n83.2.1 P-hacking e HARKing\nLa psicologia, come molte altre discipline scientifiche, si trova spesso a confrontarsi con le ‚Äúquestionable research practices‚Äù (pratiche di ricerca discutibili), ovvero quell‚Äôinsieme di comportamenti o azioni adottate dai ricercatori durante il processo di conduzione e comunicazione della ricerca scientifica che possono compromettere l‚Äôintegrit√† e l‚Äôaffidabilit√† dei risultati ottenuti. Queste pratiche includono il ‚ÄúP-hacking‚Äù, in cui i ricercatori manipolano i dati o le analisi statistiche per ottenere risultati significativi; il ‚ÄúHARKing‚Äù (Hypothesizing After Results are Known), in cui le ipotesi vengono formulate retrospettivamente per adattarsi ai risultati ottenuti; e la ‚Äúpresentazione selettiva dei risultati‚Äù, dove vengono presentati solo i risultati che supportano le ipotesi, tralasciando quelli non significativi o contraddittori.\nLa pressione per ottenere risultati ‚Äústatisticamente significativi‚Äù, insieme all‚Äôuso di campioni di piccole dimensioni, porta alla proliferazione di falsi positivi come conseguenza dell‚Äôadozione di pratiche di ricerca discutibili. Simmons, Nelson e Simonsohn hanno dimostrato come, attraverso l‚Äôimpiego di tali pratiche, sia semplice ottenere risultati statisticamente significativi (Nelson, Simmons, e Simonsohn 2018).\nL‚Äôuso di queste pratiche √® molto diffuso nella ricerca e l‚Äôapproccio statistico frequentista √® particolarmente vulnerabile a tali manipolazioni.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.3 La Cultura della Frode nel Sistema Accademico",
    "text": "83.3 La Cultura della Frode nel Sistema Accademico\nIl sistema accademico stesso, con i suoi incentivi alla pubblicazione e al finanziamento, incoraggia indirettamente queste pratiche.\n\n83.3.1 Il Caso Brian Wansink\nUn caso emblematico √® quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l‚Äôamministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di pi√π in presenza di donne o sull‚Äôeffetto dei nomi ‚Äúattraenti‚Äù dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero ‚Äúespressioni di preoccupazione‚Äù, e quindici furono corretti. Nel 2019, Wansink si dimise da Cornell dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n\n83.3.2 Il Caso Sylvain Lesn√©\nUn altro esempio rilevante riguarda Sylvain Lesn√© e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell‚Äôipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesn√©.\nNel 2022, il neuroscienziato Matthew Schrag scopr√¨ immagini manipolate in questo e in molti altri articoli di Lesn√©, inclusi quelli che sostenevano l‚Äôipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell‚Äôarticolo del 2006 alla fine accettarono di ritirarlo, ma non Lesn√© stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesn√© continui a essere finanziato dal National Institutes of Health e impiegato presso l‚ÄôUniversit√† del Minnesota, dimostra un fallimento sistemico nell‚Äôaffrontare la cattiva condotta scientifica.\n\n\n83.3.3 Altri Casi di Rilievo\nHo controllato il contenuto e ho notato che ci sono effettivamente alcune ripetizioni e inconsistenze. Hai ragione nel sospettare che i casi di Dan Ariely e Francesca Gino siano stati trattati separatamente, mentre in realt√† sono parte dello stesso scandalo. Inoltre, il caso di Marc Tessier-Lavigne √® menzionato due volte. Ecco una versione riscritta e migliorata del testo:\nNel mondo accademico, recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all‚Äôindagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonest√† e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonest√†.\nFrancesca Gino, docente presso la Harvard Business School, √® stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che √® in ‚Äúadministrative leave‚Äù.\n\n\nL‚Äôinefficacia delle istituzioni accademiche nel gestire la frode scientifica riflette una corruzione culturale sistemica. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell‚Äôintegrit√† scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene spesso premiato con finanziamenti, promozioni e prestigio accademico. In sintesi, la crisi della riproducibilit√† e la cultura della frode sono problemi diffusi e profondamente radicati nel mondo accademico.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilit√†",
    "href": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilit√†",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.4 Il Progetto di Riproducibilit√†",
    "text": "83.4 Il Progetto di Riproducibilit√†\n\n83.4.1 L‚ÄôIniziativa di Brian Nosek\nNel 2011, Brian Nosek dell‚ÄôUniversit√† della Virginia avvi√≤ il Progetto di Riproducibilit√† (Collaboration 2015), coinvolgendo 270 ricercatori nel tentativo di replicare cento studi di psicologia. L‚Äôobiettivo era ripetere gli esperimenti originali, utilizzando gli stessi metodi ma con nuovi campioni, per verificare la solidit√† e la replicabilit√† dei risultati precedentemente pubblicati.\nI risultati di questo imponente lavoro, pubblicati nel 2015, furono a dir poco sconvolgenti. Dei cento studi esaminati, ben novantasette avevano inizialmente riportato risultati statisticamente significativi. Tuttavia, il team di Nosek riusc√¨ a replicare questi risultati solo in trentasei casi. Non solo: le dimensioni degli effetti nelle replicazioni risultarono, in media, dimezzate rispetto agli studi originali. Inoltre, pi√π della met√† di queste dimensioni degli effetti cadeva al di fuori degli intervalli di confidenza al 95% riportati nei lavori originali.\n\n\n83.4.2 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca pi√π recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell‚Äôarco di vent‚Äôanni. Questa ricerca suggerisce che poco pi√π della met√† di questi articoli di psicologia non supererebbe i test di replicazione (Youyou, Yang, e Uzzi 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilit√† (Collaboration 2015). Questo dato √® in linea con il lavoro di Youyou, Yang, e Uzzi (2023), che ha mostrato come la replicabilit√† degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente pi√π incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i pi√π bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalit√† hanno mostrato tassi leggermente pi√π incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilit√† dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell‚Äôapparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilit√† che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilit√† di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, pi√π in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilit√† di molti risultati ritenuti consolidati, ma anche la necessit√† di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche √® ancora in atto.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.5 Cause Profonde della Crisi della Replicazione",
    "text": "83.5 Cause Profonde della Crisi della Replicazione\nLa crisi della replicazione in psicologia e in altre scienze ha radici profonde e non pu√≤ essere attribuita esclusivamente a pratiche di ricerca disoneste. Diverse cause immediate sono state identificate, tra cui:\n\nPressione a pubblicare (‚Äúpublish or perish‚Äù): L‚Äôintensa pressione sui ricercatori a pubblicare prolificamente √® un fattore importante che pu√≤ contribuire a molti dei problemi legati alla crisi della replicazione. La cultura del ‚Äúpublish or perish‚Äù mette i ricercatori sotto stress continuo per produrre risultati significativi e pubblicarli rapidamente (Gopalakrishna et al. 2022; Grimes, Bauch, e Ioannidis 2018).\nRicerca della novit√† a ogni costo e incentivi accademici distorti: La ricerca di risultati innovativi e il valore eccessivo attribuito alle scoperte significative incentivano pratiche di ricerca distorte. Questo include la sovrarappresentazione dei risultati positivi e la mancanza di rigore metodologico (Ferguson e Heene 2012; Ware e Munaf√≤ 2015).\nBassa potenza statistica e scarsit√† di sforzi di replicazione: Molti studi soffrono di bassa potenza statistica, il che rende difficile ottenere risultati affidabili. Inoltre, la mancanza di sforzi di replicazione contribuisce a mantenere e diffondere risultati non replicabili.\nMancanza di trasparenza nella reportistica: La reportistica selettiva e la flessibilit√† non dichiarata nei metodi e nei dati sono pratiche comuni che compromettono l‚Äôintegrit√† scientifica. Inoltre, la riluttanza a condividere dati e materiali e il bias di pubblicazione, per cui i risultati nulli hanno meno probabilit√† di essere pubblicati rispetto a quelli statisticamente significativi, aggravano il problema (Bruton et al. 2020; Nosek, Spies, e Motyl 2012).\n\n\n83.5.1 La Probabilit√† Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora pi√π profonda e risieda nell‚Äôapproccio statistico stesso, ampiamente adottato dalla comunit√† scientifica (Chivers 2024; Gelman e Loken 2014; Loken e Gelman 2017). Questo punto di vista suggerisce che le difficolt√† nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un‚Äôinterpretazione e un‚Äôapplicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L‚Äôapproccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilit√† di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilit√† di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso ‚Äúp-value‚Äù √® un esempio di questa logica: esso indica la probabilit√† di ottenere risultati estremi quanto o pi√π estremi di quelli osservati, supponendo che l‚Äôipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto √® probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una ‚Äúprobabilit√† inferenziale‚Äù, cio√® la probabilit√† che l‚Äôipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l‚Äôapproccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilit√† inferenziale. L‚Äôapproccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le ‚Äúprior‚Äù) relative all‚Äôipotesi in esame.\nLa differenza tra questi due approcci √® cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l‚Äôipotesi nulla √® vera, l‚Äôapproccio bayesiano ci fornisce la probabilit√† che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n\n83.5.2 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L‚Äôuso esclusivo dell‚Äôapproccio frequentista pu√≤ portare a sovrastimare la forza delle evidenze a favore di un‚Äôipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significativit√† statistica, rendendo pi√π difficile dichiarare un risultato ‚Äúsignificativo‚Äù.\nRichiedere la preregistrazione delle ipotesi per prevenire l‚ÄôHARKing (Hypothesizing After Results are Known).\nFar s√¨ che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo ‚Äúpositivi‚Äù o ‚Äúnuovi‚Äù.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell‚Äôinterpretazione delle evidenze statistiche. L‚Äôadozione di un approccio bayesiano offre una soluzione pi√π radicale, fornendo un quadro pi√π completo e realistico della forza delle evidenze a favore o contro un‚Äôipotesi scientifica.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "href": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.6 Guardare i Dati",
    "text": "83.6 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua, quella di osservare i risultati man mano che vengono raccolti all‚Äôinterno dell‚Äôapproccio frequentista, possa avere conseguenze enormi sulle conclusioni dello studio, in particolare sulla probabilit√† di ottenere un risultato statisticamente significativo. Nella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l‚Äô‚Äúipotesi nulla‚Äù √® vera: non c‚Äô√® differenza tra le medie delle popolazioni di partenza. Tuttavia, a causa della variabilit√† campionaria, si noter√† come il p-valore sia fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\ndef simulate_t_tests(seed, max_sample_size, mu=0, sigma=1):\n    # Imposta il seme per la riproducibilit√†\n    np.random.seed(seed)\n\n    # Intervallo di grandezza campionaria\n    sample_sizes = range(2, max_sample_size + 1, 2)\n    p_values = []\n\n    # Genera due campioni grandi iniziali da una distribuzione normale\n    full_sample1 = np.random.normal(mu, sigma, max_sample_size)\n    full_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n    # Simulazione\n    for n in sample_sizes:\n        # Estrai sottoinsiemi incrementali dai campioni completi\n        sample1 = full_sample1[:n]\n        sample2 = full_sample2[:n]\n\n        # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n        t_stat, p_value = ttest_ind(sample1, sample2)\n        p_values.append(p_value)\n\n    color_fill = \"#b97c7c\"\n    color_edge = \"#8f2727\"\n\n    # Crea il grafico del p-valore in funzione della grandezza campionaria\n    plt.plot(sample_sizes, p_values, marker=\"\", linestyle=\"-\", color=color_fill)\n    plt.axhline(y=0.05, color=color_edge, linestyle=\"--\", label=\"Significativit√† a 0.05\")\n    plt.xlabel(\"Grandezza Campionaria\")\n    plt.ylabel(\"P-valore\")\n    plt.title(\"P-valore in funzione della grandezza campionaria\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambia progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). √à evidente come il p-valore vari drasticamente con l‚Äôaggiunta di nuove osservazioni ai campioni. Si noti inoltre che, per alcune configurazioni dei due campioni, il p-valore pu√≤ scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato ‚Äústatisticamente significativo‚Äù. Tuttavia, questa simulazione non mostra altro che rumore: i due campioni sono stati estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed=12, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\n\nsimulate_t_tests(seed=42, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\nLa simulazione evidenzia una limitazione fondamentale dell‚Äôapproccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questa pratica rende il processo decisionale estremamente volatile, poich√©, teoricamente, ad ogni nuovo studio si ‚Äúdimentica‚Äù tutta l‚Äôinformazione derivante dagli studi precedenti.\n\n83.6.1 Analisi Bayesiana\nL‚Äôapproccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cio√®, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l‚Äôinformazione a priori (ci√≤ che sapevamo prima dell‚Äôesperimento) con la verosimiglianza (ci√≤ che i dati ci dicono). Questo equilibrio √® particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l‚Äôinformazione a priori assume un ruolo pi√π rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l‚Äôanalisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l‚Äôapproccio frequentista, forniscono un risultato ‚Äústatisticamente significativo‚Äù, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilit√† al 95% compreso tra -0.52 e 1.12. Poich√© questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c‚Äô√® una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l‚Äôapproccio bayesiano √® pi√π resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l‚Äôanalisi bayesiana fornisce una rappresentazione pi√π sfumata e realistica dell‚Äôincertezza associata alle nostre conclusioni.\nInoltre, l‚Äôapproccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\nnp.random.seed(12)\nmu=0\nsigma=2\nmax_sample_size=50\nfull_sample1 = np.random.normal(mu, sigma, max_sample_size)\nfull_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n\nstan_data = {\n    \"N1\": len(full_sample1),\n    \"N2\": len(full_sample2),\n    \"y1\": full_sample1,\n    \"y2\": full_sample2,\n}\nstan_data\n\n{'N1': 50,\n 'N2': 50,\n 'y1': array([ 0.94597166, -1.36285176,  0.48487899, -3.40147127,  1.50628567,\n        -3.06944268,  0.01025416, -0.24045534, -1.61396376,  5.74363879,\n        -1.19564584,  0.94491399,  2.19191224, -2.4303376 ,  2.68471274,\n        -0.24429958,  2.02503095, -1.82773829, -2.05906041,  2.4195929 ,\n         1.00374461,  0.27769235,  1.28152223,  1.05466533, -2.30872047,\n        -4.42666696, -3.36351302, -3.5761885 , -4.43706989, -1.29486156,\n        -1.05680864, -0.07841835,  0.4299519 , -0.76871761, -0.50780816,\n         0.14650415, -1.99440767, -1.42771258,  0.07083269, -1.35589073,\n        -1.14376212, -0.21172463,  2.67166268,  0.63733058, -0.6751905 ,\n        -1.17053656, -0.22983988,  4.48363559, -6.29483304,  1.07027179]),\n 'y2': array([ 0.46498088,  1.7352239 , -2.29642543,  4.22868848,  2.00188552,\n        -0.10282999,  0.3195754 , -1.43252717,  0.10104565, -0.28667483,\n         1.88715078,  0.71528845, -0.16689841,  1.35561221,  1.11212075,\n         0.44543892, -3.05797096,  2.05842235, -2.33251752, -2.0191233 ,\n        -0.21053598,  1.02404432,  2.81545553, -3.37539266,  2.94246799,\n         3.27292581, -0.92278987, -0.40272454, -1.14363346, -1.20659823,\n        -2.67877844, -3.37930584, -0.39865468,  0.51554517,  3.65764143,\n        -2.00200309, -4.18338243,  0.29311941, -0.9327022 ,  0.71244601,\n        -0.79575947, -2.51844703, -1.37775738,  1.6052609 ,  0.54478208,\n        -1.938353  ,  1.74393624, -2.89271889, -1.07296253,  0.39584103])}\n\n\n\nstan_file = os.path.join(project_directory, \"stan\", \"two_means_diff.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n13:52:36 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n13:52:47 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n\n\ndata {\n  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\n  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\n  vector[N1] y1; // Dati del gruppo 1\n  vector[N2] y2; // Dati del gruppo 2\n}\nparameters {\n  real mu1; // Media del gruppo 1\n  real delta; // Differenza tra le medie\n  real&lt;lower=0&gt; sigma; // Deviazione standard comune\n  real&lt;lower=0&gt; nu; // Gradi di libert√† per la distribuzione t\n}\ntransformed parameters {\n  real mu2; // Media del gruppo 2\n  mu2 = mu1 + delta;\n}\nmodel {\n  // Priori\n  mu1 ~ normal(0, 5);\n  delta ~ normal(0, 2); // Priore su delta\n  sigma ~ cauchy(0, 5);\n  nu ~ gamma(2, 0.1); // Priore sulla t-student\n  \n  // Verosimiglianza\n  y1 ~ student_t(nu, mu1, sigma);\n  y2 ~ student_t(nu, mu2, sigma);\n}\ngenerated quantities {\n  real diff; // Differenza tra le medie (alias di delta per chiarezza)\n  diff = delta;\n}\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    iter_sampling=2_000,\n    iter_warmup=1_000,\n    show_progress=False,\n    show_console=False,\n)\n\n13:53:34 - cmdstanpy - INFO - CmdStan start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] start processing\n13:53:34 - cmdstanpy - INFO - Chain [2] start processing\n13:53:34 - cmdstanpy - INFO - Chain [3] start processing\n13:53:34 - cmdstanpy - INFO - Chain [4] start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] done processing\n13:53:34 - cmdstanpy - INFO - Chain [2] done processing\n13:53:34 - cmdstanpy - INFO - Chain [4] done processing\n13:53:34 - cmdstanpy - INFO - Chain [3] done processing\n13:53:34 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nConsider re-running with show_console=True if the above output is unclear!\n\n\n\naz.summary(\n    fit,\n    var_names=[\"mu1\", \"mu2\", \"delta\"],\n    round_to=2,\n    hdi_prob=0.95\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu1\n-0.43\n0.30\n-1.03\n0.15\n0.00\n0.0\n4961.74\n4696.27\n1.0\n\n\nmu2\n-0.15\n0.30\n-0.73\n0.42\n0.00\n0.0\n9396.35\n6530.40\n1.0\n\n\ndelta\n0.28\n0.42\n-0.52\n1.12\n0.01\n0.0\n4850.37\n5211.27\n1.0\n\n\n\n\n\n\n\n\n\n# Estrai i campioni di delta\ndelta_samples = fit.stan_variable(\"delta\")\n\n# Disegna la distribuzione a posteriori di delta\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(delta_samples, bins=30, density=True, alpha=0.75, color=color_fill)\nplt.axvline(\n    np.mean(delta_samples),\n    color=color_edge,\n    linestyle=\"--\",\n    label=f\"Mean: {np.mean(delta_samples):.2f}\",\n)\nplt.xlabel(\"delta\")\nplt.ylabel(\"Density\")\nplt.title(\"Posterior distribution of delta\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "href": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.7 Il Giardino dei Sentieri che si Biforcano",
    "text": "83.7 Il Giardino dei Sentieri che si Biforcano\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: ‚ÄúGli studenti appassionati di cucina hanno una maggiore probabilit√† di essere figli unici?‚Äù o ‚ÄúGli studenti provenienti da famiglie battiste sono pi√π inclini a partecipare a club politici scolastici?‚Äù. Meehl evidenzi√≤ che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno ‚ÄúIl Giardino dei Sentieri che si Biforcano‚Äù [Garden of Forking Paths; Gelman e Loken (2013)], riferendosi ai molteplici gradi di libert√† a disposizione del ricercatore nell‚Äôanalisi dei dati. Come nell‚Äôesempio di Meehl, √® possibile esaminare le differenze intergruppo (se questo √® l‚Äôoggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno ‚Äústatisticamente significative‚Äù. Ci√≤ indica che, in quello specifico campione, quel particolare aspetto dei dati √® rilevante. Tuttavia, questa differenza ‚Äústatisticamente significativa‚Äù non sar√† necessariamente generalizzabile ad un altro campione, il quale presenter√† le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman, l‚Äôapproccio basato sul test dell‚Äôipotesi nulla si limita a ‚Äúdescrivere il rumore‚Äù. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all‚Äôavanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un‚Äôottica di inferenza statistica, questo problema √® riconducibile al concetto di ‚Äúp-hacking‚Äù o ‚Äúdata dredging‚Äù, dove l‚Äôesplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati pu√≤ portare a falsi positivi e a una sovrastima della significativit√† statistica.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "href": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "title": "83¬† La Crisi della Replicazione",
    "section": "83.8 Garbage In, Garbage Out",
    "text": "83.8 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l‚Äôipotesi nulla o non la si rifiuta. Ci√≤ implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, √® inevitabile trovare qualche effetto, anche se di minima entit√†.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell‚Äôeffetto e di fornire una distribuzione di probabilit√†. Una distribuzione di probabilit√† √® una rappresentazione grafica delle diverse possibilit√† che potrebbero verificarsi. In questo contesto, si tratta della ‚Äúprobabilit√† inversa‚Äù, ovvero della plausibilit√† dell‚Äôipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed √® il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l‚Äôaggiornamento bayesiano. Il parametro \\(\\delta\\) √® la nostra ipotesi sulla differenza tra le due medie, e l‚Äôinferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL‚Äôapproccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell‚Äôipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di ‚Äúsignificativit√† statistica‚Äù, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l‚Äôapproccio frequentista sia spesso considerato ‚Äúingenuo‚Äù da molti ricercatori, adottare l‚Äôapproccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualit√†. Un principio fondamentale della ricerca √® ‚ÄúGarbage in, garbage out‚Äù. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualit√† delle misurazioni √® insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, pu√≤ trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "83¬† La Crisi della Replicazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jul 29 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBargh, John A, Mark Chen, e Lara Burrows. 1996. ¬´Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action.¬ª Journal of personality and social psychology 71 (2): 230‚Äì244.\n\n\nBem, Daryl J. 2011. ¬´Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect¬ª. Journal of Personality and Social Psychology 100 (3): 407‚Äì25.\n\n\nBruton, Samuel V, Mary Medlin, Mitch Brown, e Donald F Sacco. 2020. ¬´Personal motivations and systemic incentives: Scientists on questionable research practices¬ª. Science and Engineering Ethics 26 (3): 1531‚Äì47.\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, Open Science. 2015. ¬´Estimating the reproducibility of psychological science¬ª. Science 349 (6251): aac4716.\n\n\nFerguson, Christopher J, e Moritz Heene. 2012. ¬´A vast graveyard of undead theories: Publication bias and psychological science‚Äôs aversion to the null¬ª. Perspectives on Psychological Science 7 (6): 555‚Äì61.\n\n\nGelman, Andrew, e Eric Loken. 2013. ¬´The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ‚Äúfishing expedition‚Äù or ‚Äúp-hacking‚Äù and the research hypothesis was posited ahead of time¬ª. Department of Statistics, Columbia University 348 (1-17): 3.\n\n\n‚Äî‚Äî‚Äî. 2014. ¬´The statistical crisis in science¬ª. American scientist 102 (6): 460‚Äì65.\n\n\nGopalakrishna, Gowri, Gerben Ter Riet, Gerko Vink, Ineke Stoop, Jelte M Wicherts, e Lex M Bouter. 2022. ¬´Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands¬ª. PloS one 17 (2): e0263023.\n\n\nGrimes, David Robert, Chris T Bauch, e John PA Ioannidis. 2018. ¬´Modelling science trustworthiness under publish or perish pressure¬ª. Royal Society open science 5 (1): 171511.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nLakens, Dani√´l. 2015. ¬´On the challenges of drawing conclusions from p-values just below 0.05¬ª. PeerJ 3: e1142.\n\n\nLoken, Eric, e Andrew Gelman. 2017. ¬´Measurement Error and the Replication Crisis¬ª. Science 355 (6325): 584‚Äì85.\n\n\nMeehl, Paul E. 2012. ¬´Why summaries of research on psychological theories are often uninterpretable¬ª. In Improving inquiry in social science, 13‚Äì59. Routledge.\n\n\nNelson, Leif D, Joseph Simmons, e Uri Simonsohn. 2018. ¬´Psychology‚Äôs renaissance¬ª. Annual review of psychology 69 (1): 511‚Äì34.\n\n\nNosek, Brian A, Jeffrey R Spies, e Matt Motyl. 2012. ¬´Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability¬ª. Perspectives on Psychological Science 7 (6): 615‚Äì31.\n\n\nRitchie, Stuart J, Richard Wiseman, e Christopher C French. 2012. ¬´Failing the future: Three unsuccessful attempts to replicate Bem‚Äôs ‚ÄòRetroactive Facilitation of Recall‚ÄôEffect¬ª. PloS one 7 (3): e33423.\n\n\nWare, Jennifer J, e Marcus R Munaf√≤. 2015. ¬´Significance chasing in research practice: causes, consequences and possible solutions¬ª. Addiction 110 (1): 4‚Äì8.\n\n\nYouyou, Wu, Yang Yang, e Brian Uzzi. 2023. ¬´A discipline-wide investigation of the replicability of Psychology papers over the past two decades¬ª. Proceedings of the National Academy of Sciences 120 (6): e2208863120.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "",
    "text": "84.1 L‚Äôuso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo ‚ÄúStatistical Errors‚Äù (2014), Nuzzo evidenzia i limiti dell‚Äôapproccio NHST nella pratica scientifica Nuzzo (2014). Infatti, sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ‚Äô20, egli non lo ha mai concepito come un test formale. Invece, Fisher lo considerava uno strumento informale per valutare se l‚Äôevidenza empirica fosse significativa in un senso colloquiale, ovvero meritevole di attenzione. In pratica, Fisher suggeriva di assumere un‚Äôipotesi nulla e di calcolare la probabilit√† di osservare un risultato altrettanto estremo o pi√π estremo di quello trovato, se il risultato fosse completamente dovuto alla sola variabilit√† campionaria. Sebbene sia possibile calcolare il valore-\\(p\\) tramite una procedura matematica, per Fisher esso era solo uno strumento da utilizzare all‚Äôinterno di un processo decisionale non numerico, in grado di combinare le evidenze empiriche attuali con le conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) rappresentava uno strumento da utilizzare all‚Äôinterno del processo decisionale, non la conclusione del processo decisionale stesso.\nVerso la fine degli anni ‚Äô20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l‚Äôobiettivo di renderle ‚Äúrigorose e oggettive‚Äù. In particolare, introdussero i concetti di potere statistico e di falso positivo, ma non utilizzarono la nozione di valore-\\(p\\) come aveva fatto Fisher.\nLe divergenze tra i tre autori portarono a un acceso dibattito, in cui Neyman critic√≤ il lavoro di Fisher come matematicamente ‚Äúpeggiore dell‚Äôinutilit√†‚Äù, mentre Fisher defin√¨ l‚Äôapproccio di Neyman ‚Äúinfantile‚Äù e ‚Äúorribile per la libert√† intellettuale dell‚Äôoccidente‚Äù.\nDurante questo dibattito, altri autori iniziarono a scrivere manuali di statistica per fornire uno strumento di lavoro ai ricercatori. Poich√© molti di questi autori non erano statistici e avevano solo una comprensione superficiale della distinzione tra i vari approcci, crearono un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher all‚Äôinterno del ‚Äúsistema rigoroso‚Äù proposto da Neyman e Pearson. √à in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita come ‚Äústatisticamente significativa‚Äù.\nTuttavia, dal punto di vista storico, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso da quello che viene attribuito oggi nel mondo della ricerca. Come abbiamo visto, il valore-\\(p\\) era solo uno strumento informale utilizzato da Fisher all‚Äôinterno di un processo decisionale pi√π ampio, e il suo uso all‚Äôinterno del sistema ibrido creato dai manuali di statistica era privo di giustificazione e fondamento.\nNel 2016 l‚ÄôAmerican Statistical Association ha pubblicato un articolo nel quale si esprime una grande preoccupazione per l‚Äôuso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna Wasserstein e Lazar (2016):\nL‚Äôarticolo prosegue affermando che:",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "",
    "text": "\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\n\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical ‚Äúbright-line‚Äù rules (such as ‚Äú\\(p &lt; 0.05\\)‚Äù) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‚Äòtrue‚Äô on one side of the divide and ‚Äòfalse‚Äô on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‚Äòyes-no‚Äô decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of ‚Äústatistical significance‚Äù (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "84.2 \\(P\\)-hacking",
    "text": "84.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta la principale fallacia associata all‚Äôutilizzo del valore-\\(p\\) ed √® nota anche come ‚Äú\\(P\\)-hacking‚Äù, ‚Äúdata-dredging‚Äù, ‚Äúsnooping‚Äù, ‚Äúfishing‚Äù, ‚Äúsignificance-chasing‚Äù o ‚Äúdouble-dipping‚Äù. Secondo Uri Simonsohn, docente presso l‚ÄôUniversit√† della Pennsylvania, il \\(P\\)-hacking consiste nel tentativo di provare diverse ipotesi finch√© non si ottiene il risultato desiderato. Ad esempio, si potrebbe dire: ‚ÄúQuel risultato sembra essere stato ottenuto attraverso il \\(p\\)-hacking, gli autori hanno eliminato una delle condizioni in modo che il valore-\\(p\\) complessivo fosse inferiore a 0.05‚Äù oppure ‚ÄúLei √® una \\(p\\)-hacker, controlla sempre i dati mentre vengono raccolti‚Äù.\nQuesta pratica ha l‚Äôeffetto di trasformare uno studio esplorativo, che dovrebbe essere sempre interpretato con cautela, in uno studio (apparentemente) confermativo, il cui risultato appare ‚Äúrobusto‚Äù, ma che in realt√† ha una probabilit√† pressoch√© nulla di essere replicato in studi successivi. Secondo le simulazioni di Simonsohn, il cambiamento di poche decisioni nel processo di analisi dei dati pu√≤ aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nIl \\(P\\)-hacking √® diffuso soprattutto negli studi che tentano di dimostrare piccoli effetti usando dati molto rumorosi. Un‚Äôanalisi della letteratura psicologica ha mostrato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia minima dello 0.05. Questo risultato pu√≤ essere interpretato come conseguenza della pratica del \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovare uno che risulta ‚Äústatisticamente significativo‚Äù e poi riportano solo quello. Come mostra la figura seguente, questa pratica non riguarda solo la psicologia, ma √® diffusa in tutti i campi della ricerca scientifica.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "84.3 Critiche al valore-\\(p\\)",
    "text": "84.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) √® stato paragonato a creature noiose e ostinate come le zanzare, ai vestiti nuovi dell‚Äôimperatore, ovvero alla tendenza di non voler riconoscere evidenti problemi, ma preferire di far finta di nulla, o ad un intellectual rake sterile, che non porta alcun frutto. Si √® anche ironizzato sul fatto che la procedura di statistical hypothesis inference testing venga chiamata cos√¨ solo per l‚Äôacronimo che produce.\nIl valore-\\(p\\) incoraggia un modo di pensare errato, spostando l‚Äôattenzione dal problema centrale della ricerca, ovvero la forza della manipolazione sperimentale, alla dimostrazione di una falsa ipotesi che si sa a priori essere falsa (l‚Äôipotesi nulla). Ad esempio, uno studio con pi√π di 19.000 individui ha dimostrato che coloro che incontrano il loro partner online hanno una probabilit√† minore di divorziare (\\(p &lt;\\) 0,002) e sono pi√π soddisfatti della loro vita matrimoniale (\\(p &lt;\\) 0,001) rispetto a chi non si √® conosciuto online. Questo pu√≤ sembrare un risultato interessante, ma senza considerare la dimensione dell‚Äôeffetto, ovvero il tasso di divorzio che scende dal 7.67% al 5.96% e l‚Äôaumento dell‚Äôindice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti, il risultato perde di interesse. In generale, la domanda cruciale non √® ‚Äúc‚Äô√® un effetto o no?‚Äù ma piuttosto ‚Äúqual √® la dimensione dell‚Äôeffetto?‚Äù.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "84.4 L‚Äôeffetto sperimentale √® esattamente nullo?",
    "text": "84.4 L‚Äôeffetto sperimentale √® esattamente nullo?\nUna delle critiche pi√π frequenti alla logica di verifica delle ipotesi statistiche riguarda l‚Äôassunzione irrealistica che l‚Äôeffetto della manipolazione sperimentale sia ‚Äúesattamente‚Äù nullo. Ad esempio, la fisica ci insegna che lo spostamento di un grammo di massa in una stella distante qualche anno luce dalla Terra pu√≤ influenzare il movimento delle molecole di un gas sulla Terra Borel (1914). Questo ci suggerisce che ogni manipolazione sperimentale produca, in qualche modo, un effetto. Pertanto, secondo Andrew Gelman, il problema non √® dimostrare falsa l‚Äôipotesi nulla, ovvero che la manipolazione sperimentale non produca alcun effetto, ma piuttosto valutare se la dimensione dell‚Äôeffetto √® sufficientemente grande da avere un impatto pratico e se l‚Äôeffetto sia riproducibile. In questo senso, la logica di verifica dell‚Äôipotesi nulla pu√≤ essere problematica, soprattutto quando si lavora con piccoli campioni e piccoli effetti, come nella maggior parte degli studi in psicologia, poich√© pu√≤ portare ad una sovrastima della dimensione dell‚Äôeffetto e ad una visione binaria del risultato (vero/falso), invece di concentrarsi sulla stima non distorta della dimensione effettiva dell‚Äôeffetto.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "84.5 Attenti al valore-\\(p\\)!",
    "text": "84.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l‚Äôipotesi nulla dell‚Äôeguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual √® la probabilit√† che i due campioni siano tratti da distribuzioni con la stessa media?\n\n\\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\n\nLa risposta corretta √®: (e) sconosciuta. La statistica frequentista definisce le probabilit√† dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilit√† di un‚Äôipotesi.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "84.6 La crisi della riprodicibilit√† dei risultati della ricerca",
    "text": "84.6 La crisi della riprodicibilit√† dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilit√† dei risultati della ricerca - inclusa la ricerca psicologica - √® diventata un tema di grande rilevanza. In questo contesto, √® stato evidenziato che alcuni aspetti del metodo scientifico, in particolare il concetto di valore-p e la pratica di verificare la significativit√† dell‚Äôipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a questa ‚Äúcrisi della ricerca scientifica‚Äù. Un‚Äôanalisi pi√π approfondita di questo problema √® stata fornita da Gelman (2016), il quale sostiene che la pratica della NHST sia intrinsecamente problematica. Infatti, essa incoraggia il ricercatore a cercare di rigettare un‚Äôipotesi ‚Äúfantoccio‚Äù (straw-man) che √® certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un‚Äôipotesi alternativa che il ricercatore preferisce. In generale, sembra pi√π ragionevole affermare che la differenza tra due condizioni sia molto piccola, piuttosto che affermare che sia esattamente uguale a zero.\nSpesso nei libri di statistica viene trasmesso il messaggio che la NHST sia una forma di ‚Äúalchimia‚Äù che cerca di trasformare la casualit√† in una sorta di certezza, con l‚Äôuso di termini come ‚Äúconfidenza‚Äù e ‚Äúsignificativit√†‚Äù Gelman (2016). Il processo di raccolta dei dati, analisi e inferenza statistica che ne segue viene poi riassunto in una conclusione espressa in termini di valore-p e di intervallo di confidenza che escludono lo zero. Tuttavia, ci√≤ pu√≤ dare l‚Äôimpressione errata che il ricercatore abbia una comprensione completa delle propriet√† del fenomeno in questione. Il problema principale della NHST √® che spesso produce risultati ‚Äústatisticamente significativi‚Äù in situazioni in cui le caratteristiche del fenomeno non giustificano la conclusione a cui il ricercatore arriva. Questo pu√≤ portare alla non replicabilit√† dei risultati della ricerca.\nLa comunit√† degli statistici ha evidenziato come la non replicabilit√† dei risultati delle ricerche sia particolarmente evidente quando i ricercatori, utilizzando la metodologia NHST, giungono a conclusioni errate basate sull‚Äôosservazione di piccoli campioni con effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono estremamente problematica l‚Äôapplicazione della NHST. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia.\nLa statistica √® stata definita come un metodo per prendere decisioni razionali in situazioni di incertezza. Gli statistici consigliano ai ricercatori di non solo diventare esperti nelle tecniche statistiche, ma anche di imparare a convivere con l‚Äôincertezza, nonostante la sempre crescente sofisticazione delle tecniche disponibili. Convivere con l‚Äôincertezza implica evitare di pensare che ottenere un valore-\\(p\\) ‚Äústatisticamente significativo‚Äù significhi risolvere un problema scientifico. Come possiamo allora avere fiducia in ci√≤ che abbiamo appreso dai dati? Una possibile strategia √® la replicazione e la convalida esterna, ma nella ricerca in psicologia e nelle scienze sociali, questo pu√≤ spesso essere difficile da perseguire a causa degli oneri elevati che comporta. Il problema di quali strumenti metodologici e metodi statistici siano pi√π appropriati per indagare sui fenomeni psicologici, senza essere ingannati, rimane dunque un problema aperto.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "84¬† Limiti dell‚Äôinferenza frequentista",
    "section": "84.7 Commenti e considerazioni finali",
    "text": "84.7 Commenti e considerazioni finali\nNon possiamo concludere senza sottolineare la controversia che circonda la nozione di valore-\\(p\\). Pur essendo ancora ampiamente utilizzato e spesso interpretato erroneamente, il valore-\\(p\\) conferisce solo una patina di legittimit√† ai risultati di studi dubbi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Inoltre, √® difficile comprendere appieno il significato di questa nozione. Anche gli esperti, quando chiamati a fornire una definizione di valore-\\(p\\), spesso sbagliano la risposta. Ci√≤ che i ricercatori vogliono sapere √® se i risultati della ricerca sono corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell‚Äôeffetto, sulla forza dell‚Äôevidenza o sulla probabilit√† che il risultato sia stato ottenuto casualmente. Quindi, qual √® il suo significato? Stuart Buck risponde cos√¨:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won‚Äôt tell you whether the coin is fair, but it will tell you the probability that you‚Äôd get at least as many heads as you did if the coin was fair. That‚Äôs it ‚Äì nothing more.\n\nIn sintesi, possiamo concludere che il valore-\\(p\\) risponde a una domanda molto specifica che non ha alcuna rilevanza per la validit√† scientifica dei risultati della ricerca. In un‚Äôepoca in cui la crisi della riproducibilit√† dei risultati √® sempre pi√π evidente Baker (2016), il test dell‚Äôipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema, spingendo molti ricercatori a cercare soluzioni alternative.\n\n\n\n\nBaker, Monya. 2016. ¬´Reproducibility Crisis¬ª. Nature 533 (7604): 452‚Äì54.\n\n\nBorel, Emile. 1914. Introduction G√©om√©trique. G. Villars, New York.\n\n\nGelman, Andrew. 2016. ¬´Commentary on ‚ÄúCrisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science‚Äù¬ª. Journal of Statistical Research 48-50 (1): 11‚Äì12.\n\n\nNuzzo, Regina. 2014. ¬´Statistical Errors¬ª. Nature 506 (7487): 150‚Äì52.\n\n\nWasserstein, Ronald L, e Nicole A Lazar. 2016. ¬´The ASA‚Äôs statement on p-values: context, process, and purpose¬ª. The American Statistician 70 (2): 129‚Äì33.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "85¬† La grandezza dell‚Äôeffetto",
    "section": "",
    "text": "Introduzione\nLa dimensione dell‚Äôeffetto (effect size) √® un concetto fondamentale nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura rappresenta l‚Äôentit√† dell‚Äôeffetto di un intervento o di un trattamento in modo standardizzato, descrivendo in termini quantitativi l‚Äôimportanza di un fenomeno osservato.\n√à cruciale distinguere tra la dimensione dell‚Äôeffetto e la significativit√† statistica. Un risultato pu√≤ essere ‚Äústatisticamente significativo‚Äù pur avendo un effetto di piccole dimensioni, e viceversa. La conoscenza di uno di questi concetti non fornisce automaticamente informazioni sull‚Äôaltro, evidenziando la necessit√† di considerare entrambi gli aspetti nell‚Äôanalisi dei dati.\nL‚Äôimportanza della dimensione dell‚Äôeffetto √® ampiamente riconosciuta nel campo della ricerca scientifica. Il manuale dell‚ÄôAmerican Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di riportare questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all‚ÄôAPA include la dimensione dell‚Äôeffetto, generalmente indicata tra parentesi accanto al valore di p.\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell‚Äôeffetto. Molti ricercatori si limitano a comunicare questi valori senza esaminarli approfonditamente, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza rivela una sottovalutazione sistematica e una diffusa incomprensione delle dimensioni dell‚Äôeffetto, anche tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "85¬† La grandezza dell‚Äôeffetto",
    "section": "85.1 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni",
    "text": "85.1 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni\nTra le metriche pi√π adottate per quantificare la dimensione dell‚Äôeffetto si annoverano il \\(d\\) di Cohen e l‚Äô\\(r\\) di Pearson. Il \\(d\\) di Cohen √® prevalentemente impiegato per descrivere le differenze tra le medie di gruppi sperimentali, quantificando questa differenza in termini di una deviazione standard aggregata.\nLa differenza standardizzata delle medie tra due gruppi pu√≤ essere calcolata con la seguente formula (equazione 5.1, Glass, McGaw, e Smith 1981),\n\\[\nd_p = \\frac{M_1 - M_2}{S_p}.\n\\]\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 √® maggiore della media del gruppo 2. Dividere la differenza delle medie per la deviazione standard combinata, \\(S_p\\), √® la formulazione classica del \\(d\\) di Cohen. La deviazione standard combinata, \\(S_p\\), pu√≤ essere calcolata come la radice quadrata della varianza media (ponderata per i gradi di libert√†, \\(df = n-1\\)) del gruppo 1 e del gruppo 2 (pp.¬†108, Glass, McGaw, e Smith 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}}.\n\\]\nSi noti che il termine varianza si riferisce al quadrato della deviazione standard (\\(S^2\\)). Il \\(d_p\\) di Cohen √® correlato alla statistica t di un test t per campioni indipendenti. Infatti, possiamo calcolare il valore di \\(d_p\\) a partire dalla statistica \\(t\\) con la seguente formula (equazione 5.3, Glass, McGaw, e Smith 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL‚Äôerrore standard corrispondente di \\(d_p\\) √®,\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nLa statistica \\(r\\) di Pearson, d‚Äôaltro canto, viene utilizzato per esprimere il grado di previsione di una variabile attraverso un‚Äôaltra, fornendo una misura della correlazione. √à interessante notare come queste due misure possano essere convertite l‚Äôuna nell‚Äôaltra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "title": "85¬† La grandezza dell‚Äôeffetto",
    "section": "85.2 Interpretare la Dimensione dell‚ÄôEffetto",
    "text": "85.2 Interpretare la Dimensione dell‚ÄôEffetto\nL‚Äôinterpretazione delle dimensioni dell‚Äôeffetto solitamente avviene in due modi comuni: uno √® privo di significato e l‚Äôaltro √® seriamente fuorviante.\n\nGli Standard di Cohen. Funder (2019) affermano che l‚Äôinterpretazione pi√π ampiamente utilizzata ma priva di senso delle dimensioni dell‚Äôeffetto richiama gli standard stabiliti da Jacob Cohen (1977, 1988). Cohen ha fissato i valori di r di .10, .30 e .50 come soglie per effetti piccoli, medi e grandi, rispettivamente. Tuttavia, Cohen stesso ha dichiarato che queste soglie dovrebbero essere utilizzate solo in assenza di una base migliore e in seguito ha espresso rammarico per averle proposte.\nI termini ‚Äúpiccolo‚Äù, ‚Äúmedio‚Äù e ‚Äúgrande‚Äù sono privi di significato senza un contesto di riferimento. √à necessario rispondere a due domande fondamentali: (a) piccolo, medio o grande rispetto a cosa? e (b) piccolo, medio o grande a quale scopo?\nElevare al Quadrato la Correlazione. Secondo Funder e Ozer (2019), un altro metodo comune per valutare la dimensione dell‚Äôeffetto √® ancora pi√π problematico: elevare al quadrato il valore di r. Ad esempio, un r di .30 elevato al quadrato produce .09, interpretato come ‚Äúproporzione di varianza spiegata‚Äù. Questa conversione spesso viene riportata con la parola ‚Äúsolo‚Äù, come in ‚Äúla correlazione di .30 ha spiegato solo il 9% della varianza‚Äù.\nNon esiste una giustificazione valida per considerare r¬≤ come una misura appropriata della dimensione dell‚Äôeffetto. La statistica r corrisponde alla pendenza di regressione quando entrambe le variabili sono standardizzate, mentre r¬≤ √® molto meno interpretabile perch√© riflette la proporzione di varianza in una variabile spiegata da un‚Äôaltra.\nUn esempio illustrativo √® fornito da Darlington (1990). Immaginiamo un gioco in cui si lanciano prima un nickel (5¬¢) e poi un dime (10¬¢), ricevendo un pagamento di 5¬¢ o 10¬¢ rispettivamente se la moneta mostra testa. Le correlazioni tra il valore del nickel e il pagamento (r = .4472) e tra il valore del dime e il pagamento (r = .8944) sono calcolate. Elevando al quadrato queste correlazioni, si ottiene che i nickel spiegano il 20% della varianza nel pagamento, mentre i dime spiegano l‚Äô80%. Tuttavia, interpretare questi valori come indicazione che i dime contano quattro volte tanto quanto i nickel √® fuorviante. Le correlazioni originali (.8944 √® esattamente il doppio di .4472) offrono un confronto pi√π informativo. In conclusione, elevare al quadrato r per valutare la dimensione dell‚Äôeffetto non solo √® poco informativo, ma pu√≤ anche essere fuorviante.\n\n\n85.2.1 Alternative migliori\n√à cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder e Ozer (2019) propongono due strategie principali: l‚Äôadozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l‚Äôentit√† di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l‚Äôaltezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell‚Äôimportanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking pu√≤ includere l‚Äôanalisi di risultati considerati ‚Äúclassici‚Äù nel campo di interesse o la considerazione di dimensioni dell‚Äôeffetto per risultati che hanno ottenuto un solido consenso nella comunit√† psicologica.\nIn un‚Äôottica pi√π ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell‚Äôeffetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell‚Äôeffetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio √® l‚Äôefficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l‚Äôeffetto degli anti-infiammatori non steroidei (come l‚Äôibuprofene) sul dolore √® di \\(r = .14\\).\n\nTali confronti illustrano come l‚Äôinterpretazione delle dimensioni dell‚Äôeffetto possa essere notevolmente approfondita e resa pi√π significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto pi√π vasto, favorendo una valutazione pi√π consapevole della loro rilevanza relativa.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "href": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "title": "85¬† La grandezza dell‚Äôeffetto",
    "section": "85.3 Raccomandazioni per la Pratica di Ricerca",
    "text": "85.3 Raccomandazioni per la Pratica di Ricerca\nFunder e Ozer (2019) concludono il loro articolo con una serie di raccomandazioni per migliorare la pratica di riportare le dimensioni degli effetti negli studi scientifici.\nRiportare sempre e in modo evidente le dimensioni degli effetti. Ogni studio dovrebbe evidenziare chiaramente le dimensioni degli effetti. Una conseguenza di questa raccomandazione √® che la dimensione del campione di uno studio deve essere adeguata affinch√© la stima della dimensione dell‚Äôeffetto sia affidabile.\nCondurre studi con campioni ampi. Studi con campioni ampi sono ideali. Sebbene questo non sia sempre fattibile con certi tipi di ricerca o popolazioni specifiche, dovrebbe essere una priorit√† aumentare il pi√π possibile la dimensione del campione.\nRiportare le dimensioni degli effetti in termini utili nel contesto. Il coefficiente di correlazione \\(r\\) di Pearson, essendo una misura standardizzata della dimensione dell‚Äôeffetto, non fornisce informazioni sulle unit√† di misura dello studio. Pertanto, √® necessario utilizzare misure delle dimensioni degli effetti che siano utili nel contesto specifico dello studio, come differenze medie o coefficienti di regressione grezzi, accanto a misure standardizzate, quando possibile.\nEvitare terminologia vuota. Si dovrebbe smettere di elevare al quadrato i valori di \\(r\\) per minimizzare l‚Äôapparente piccola percentuale di varianza spiegata e di utilizzare senza riflettere le linee guida di J. Cohen (1977, 1988), che lo stesso Cohen ha successivamente disconosciuto. Idealmente, termini come ‚Äúpiccolo‚Äù e ‚Äúgrande‚Äù dovrebbero essere eliminati dal vocabolario delle dimensioni degli effetti, poich√© sono etichette soggettive e spesso arbitrarie che non aggiungono informazioni utili ai risultati quantitativi.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "title": "85¬† La grandezza dell‚Äôeffetto",
    "section": "85.4 Commenti e considerazioni finali",
    "text": "85.4 Commenti e considerazioni finali\nLa sovrastima della grandezza dell‚Äôeffetto in psicologia costituisce un problema diffuso. Un principio fondamentale della psicologia sociale e dell‚Äôeconomia comportamentale, almeno come viene presentato nei media e insegnato in molte scuole di business, √® che piccoli ‚Äúnudge‚Äù o spinte gentili, spesso cose che potremmo pensare non ci influenzino affatto, possono avere grandi effetti sul comportamento. Questo ha portato a numerose affermazioni sensazionalistiche, come l‚Äôidea che le elezioni siano decise da partite di football, o che la presentazione subliminale di una faccina sorridente possa causare enormi cambiamenti negli atteggiamenti verso l‚Äôimmigrazione.\nIl modello di mondo alla base di queste affermazioni non √® solo ‚Äúl‚Äôeffetto farfalla‚Äù, ovvero che piccoli cambiamenti possono avere grandi effetti, ma piuttosto che piccoli cambiamenti possono avere effetti grandi e prevedibili. √à quello che a volte viene chiamato il modello ‚Äúa pulsante‚Äù delle scienze sociali: l‚Äôidea che se fai X, puoi aspettarti di vedere Y.\nTuttavia, questa visione presenta diversi problemi:\n\nSovrastima degli effetti: Molti studi riportano effetti sorprendentemente grandi per interventi minimi, che spesso non vengono replicati in studi successivi.\nMancanza di considerazione delle interazioni: Se esistessero molti effetti grandi e prevedibili sul comportamento, questi interferirebbero tra loro, rendendo difficile osservare effetti coerenti nei dati osservazionali.\nInstabilit√†: Un sistema sociale con molti effetti grandi e prevedibili sarebbe instabile e difficile da studiare.\nGeneralizzazione eccessiva: Spesso si tende a generalizzare risultati ottenuti in condizioni di laboratorio molto specifiche a contesti pi√π ampi e complessi della vita reale.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilit√† di essere pubblicati, creando una rappresentazione distorta della realt√†.\n\n√à importante sottolineare che la psicologia descrive molti fenomeni robusti, per esempio nella psicologia clinica e nella psicologia della percezione. Tuttavia, √® fondamentale adottare un approccio pi√π cauto e sfumato nell‚Äôinterpretazione e nella comunicazione dei risultati della ricerca psicologica. La consapevolezza di questo problema ha portato a una maggiore enfasi sulla replicabilit√† degli studi, sull‚Äôuso di campioni pi√π ampi e su metodi statistici pi√π robusti. Inoltre, sta emergendo un approccio pi√π critico e riflessivo nella comunit√† scientifica, che riconosce la complessit√† dei fenomeni psicologici e la necessit√† di evitare semplificazioni eccessive.\nIn conclusione, mentre la psicologia offre preziose intuizioni sul comportamento umano, √® essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realt√† √® spesso pi√π complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi.\n\n\n\n\nFunder, David C, e Daniel J Ozer. 2019. ¬´Evaluating effect size in psychological research: Sense and nonsense¬ª. Advances in Methods and Practices in Psychological Science 2 (2): 156‚Äì68.\n\n\nGlass, Gene V., Barry McGaw, e Mary L. Smith. 1981. Meta-analysis in Social Research. Beverly Hills, CA: Sage Publications.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "86¬† Errori di segno e errori di grandezza",
    "section": "",
    "text": "Introduzione\nIn questo capitolo verr√† esaminata la relazione tra la crisi della replicabilit√† e la procedura di decisione statistica dell‚Äôapproccio frequentista. In particolare, verranno discussi gli errori di tipo M (magnitude) e di tipo S (sign) che sono stati discussi da Loken e Gelman (2017).",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "title": "86¬† Errori di segno e errori di grandezza",
    "section": "86.1 Il Filtro della Significativit√† Statistica",
    "text": "86.1 Il Filtro della Significativit√† Statistica\nNel Capitolo 83 abbiamo esaminato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle notevoli implicazioni economiche legate alla pubblicazione su riviste scientifiche prestigiose. Questo problema √® frequentemente sottovalutato, poich√© le riviste sono riluttanti ad ammettere la necessit√† di correzioni o ritrattazioni degli articoli gi√† pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilit√† dei risultati, pilastro fondamentale del metodo scientifico. Tuttavia, le difficolt√† nel replicare i risultati pubblicati non sono attribuibili esclusivamente alla frode o a ‚Äúpratiche di ricerca disoneste‚Äù (Nelson, Simmons, e Simonsohn 2018). Un problema intrinseco riguarda il metodo statistico ampiamente adottato dai ricercatori: l‚Äôapproccio del test di ipotesi nulla e della significativit√† statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la ‚Äúsignificativit√† statistica‚Äù dovrebbero essere scartati, mentre quelli che la superano possono essere considerati credibili, basandosi unicamente su questo criterio (Wagenmakers et al. 2008).\nTuttavia, l‚Äôidea che la significativit√† statistica sia un filtro affidabile per distinguere i risultati di ricerca ‚Äúvalidi‚Äù da quelli ‚Äúnon validi‚Äù √® fondamentalmente errata. Numerose evidenze dimostrano la fallacia di questo approccio. Per approfondire questo aspetto, esamineremo lo studio di Loken e Gelman (2017), che mette in luce la relazione tra la crisi della replicabilit√† e la procedura di decisione statistica dell‚Äôapproccio frequentista.\nUno dei principali problemi evidenziati dallo studio di Loken e Gelman (2017) √® che, in contesti di ricerca complessi, la significativit√† statistica fornisce prove molto deboli riguardo al segno o all‚Äôentit√† di eventuali effetti sottostanti. In altre parole, il raggiungimento della significativit√† statistica non garantisce n√© la rilevanza n√© la consistenza dei risultati ottenuti.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "86¬† Errori di segno e errori di grandezza",
    "section": "86.2 Errori di tipo M e S",
    "text": "86.2 Errori di tipo M e S\nPer evidenziare le implicazioni del processo decisionale basato sulla significativit√† statistica, gli autori di Loken e Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno immaginato una ricerca ipotetica in cui un effetto reale, seppur molto debole, era presente, ma difficilmente individuabile senza una grande quantit√† di dati. I ricercatori hanno quindi cercato di rilevare questo effetto utilizzando l‚Äôapproccio frequentista e valutando la significativit√† statistica.\nI risultati della simulazione hanno rivelato che, anche quando un effetto reale ma debole era presente, l‚Äôapproccio frequentista tendeva a individuare un effetto significativo solo in una piccola percentuale dei casi. Inoltre, quando veniva individuato un effetto significativo, la sua stima di grandezza risultava molto imprecisa e instabile.\nIn altre parole, la significativit√† statistica fornisce solo un‚Äôindicazione generale sulla presenza o assenza di un effetto, ma non offre informazioni precise sulla sua dimensione o replicabilit√†. Questo problema diventa ancora pi√π evidente quando si considera che molte ricerche in psicologia e scienze sociali utilizzano campioni relativamente piccoli, e gli effetti osservati in tali studi tendono ad essere molto modesti. In tali contesti, l‚Äôapproccio frequentista rischia di fornire prove molto deboli e instabili riguardo alla presenza o assenza di un effetto, mettendo a rischio la replicabilit√† e l‚Äôaffidabilit√† dei risultati della ricerca.\nRiproduciamo qui, in maniera semplificata, la simulazione condotta da Loken e Gelman (2017). Iniziamo ad importare le librerie necessarie.\nSupponiamo di considerare due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\) rispettivamente. La dimensione effettiva dell‚Äôeffetto per la differenza tra le medie di questi due campioni √® rappresentata da \\(d\\), calcolato attraverso la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) sono le medie campionarie dei due gruppi, mentre \\(s_p\\) √® la deviazione standard combinata definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ncon \\(s_1\\) e \\(s_2\\) rappresentanti le deviazioni standard campionarie dei due gruppi.\nNel caso specifico preso in esame, la dimensione effettiva dell‚Äôeffetto √® molto piccola, indicando che la differenza osservata tra le medie manca di significativit√† pratica. Questo suggerisce che la distinzione tra i due gruppi non ha un impatto sostanziale nella pratica.\n\nmu_1 = 102\nmu_2 = 100\nsigma = 10\nn1 = 20\nn2 = 25\n\n\nmean_difference = abs(mu_1 - mu_2)\npooled_sd = np.sqrt(((n1 - 1) * sigma**2 + (n2 - 1) * sigma**2) / (n1 + n2 - 2))\ncohen_d = mean_difference / pooled_sd\n\nprint(\"Cohen's d effect size:\", cohen_d)\n\nCohen's d effect size: 0.2\n\n\nEsaminiamo ora quali sarebbero le conclusioni derivanti dall‚Äôapproccio frequentista mediante la procedura di decisione statistica in queste circostanze. Consideriamo una simulazione in cui vengono estratti due campioni: uno composto da 20 osservazioni dalla prima popolazione e l‚Äôaltro da 25 osservazioni dalla seconda popolazione. Successivamente, viene eseguito il test \\(t\\) di Student.\nNell‚Äôapproccio frequentista, se il valore-\\(p\\) risulta essere superiore a 0.05, i risultati vengono considerati non significativi e quindi scartati. Al contrario, se il valore-\\(p\\) √® inferiore a 0.05, il risultato √® considerato ‚Äúpubblicabile‚Äù e si conclude che esiste una differenza significativa tra i due gruppi.\nPer comprendere appieno le conclusioni ottenute mediante la procedura frequentista in questa situazione, √® necessario ripetere il processo sopra descritto per un ampio numero di iterazioni, ad esempio 50,000 volte. Questo implica che il processo di estrazione dei campioni e il calcolo dei valori-\\(p\\) vengono ripetuti numerose volte al fine di ottenere una visione completa delle possibili distribuzioni dei risultati.\n\nn_samples = 50000\n\nres = []\n\nfor i in range(n_samples):\n    # Get random samples \n    y1 = np.random.normal(loc=mu_1, scale=sigma, size=n1)\n    y2 = np.random.normal(loc=mu_2, scale=sigma, size=n2)\n    # Compute effect size\n    y1bar = y1.mean()\n    y2bar = y2.mean()\n    v1 = np.var(y1, ddof=1)\n    v2 = np.var(y2, ddof=1)\n    s = np.sqrt(((n1-1)*v1 + (n2-1)*v2) / (n1 + n2 - 2))\n    efsize = (y1bar - y2bar) / s\n    # Compute p-value\n    out = stats.ttest_ind(a=y1, b=y2, equal_var=True)\n    # Save effect size only for 'statistically significant' results\n    if out.pvalue &lt; 0.05:\n        res.append(efsize)\n\nEsaminiamo un istogramma dei casi nei quali il valore-\\(p\\) √® stato &lt; 0.05.\n\nplt.hist(res, bins=20)\nplt.axvline(\n    x=0.2, color=\"red\", linestyle=\"dashed\", linewidth=2, label=\"True Effect Size\"\n)\nplt.xlabel(\"Effect Size\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of Effect Sizes for 'Statistically Significant' Results\")\nplt.legend()\n_ = plt.show()\n\n\n\n\n\n\n\n\nCome sottolineato da Loken e Gelman (2017), l‚Äôutilizzo dell‚Äôapproccio frequentista nella procedura di decisione statistica pu√≤ portare a due tipi di errori significativi. Il primo errore, noto come ‚Äúmagnitude‚Äù, si manifesta nel fatto che i risultati pubblicati tendono a sovrastimare la vera grandezza dell‚Äôeffetto. Nella simulazione effettuata, sebbene la vera grandezza dell‚Äôeffetto fosse modesta (0.2), la media della grandezza dell‚Äôeffetto per i risultati dichiarati ‚Äústatisticamente significativi‚Äù era di circa 0.8, indicando una grandezza dell‚Äôeffetto ‚Äúampia‚Äù.\nIl secondo errore, denominato ‚Äúsegno‚Äù, si verifica in alcune situazioni in cui, a causa della variabilit√† campionaria, viene commesso un errore nella direzione dell‚Äôeffetto. In tali circostanze, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realt√† non √® cos√¨. √à importante notare che, anche in questi casi, la grandezza dell‚Äôeffetto viene sovrastimata in termini assoluti.\n√à interessante notare che le stesse conclusioni si applicherebbero anche se avessimo considerato l‚Äôintervallo di confidenza per la differenza tra le medie. In sintesi, l‚Äôapproccio frequentista introduce un errore sistematico nella stima della grandezza dell‚Äôeffetto, che √® la quantit√† pi√π importante che il ricercatore deve stimare. In alcune situazioni, pu√≤ persino causare errori nella stima della direzione dell‚Äôeffetto.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#considerazioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#considerazioni-conclusive",
    "title": "86¬† Errori di segno e errori di grandezza",
    "section": "86.3 Considerazioni conclusive",
    "text": "86.3 Considerazioni conclusive\nIn conclusione, l‚Äôapproccio frequentista non fornisce un metodo affidabile per valutare i risultati della ricerca e determinare la loro attendibilit√† o la necessit√† di scartarli [gelman2014beyond; Loken e Gelman (2017)]. Questa mancanza di affidabilit√† deriva dall‚Äôintroduzione di errori sistematici nella stima delle dimensioni dell‚Äôeffetto, che pu√≤ anche portare a errori nella direzione dell‚Äôeffetto in alcune circostanze. Di conseguenza, non sembra esserci motivo valido per continuare a impiegare questo approccio.\nAl contrario, l‚Äôadozione dell‚Äôapproccio bayesiano sembra offrire risultati pi√π precisi e affidabili nella valutazione dei dati di ricerca. Tale approccio considera la probabilit√† delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell‚Äôapproccio frequentista e fornendo una base pi√π solida per le decisioni sulla validit√† dei risultati.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "86¬† Errori di segno e errori di grandezza",
    "section": "86.4 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "86.4 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\narviz     : 0.18.0\nscipy     : 1.13.0\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nLoken, Eric, e Andrew Gelman. 2017. ¬´Measurement Error and the Replication Crisis¬ª. Science 355 (6325): 584‚Äì85.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nNelson, Leif D, Joseph Simmons, e Uri Simonsohn. 2018. ¬´Psychology‚Äôs renaissance¬ª. Annual review of psychology 69 (1): 511‚Äì34.\n\n\nWagenmakers, Eric-Jan, Michael Lee, Tom Lodewyckx, e Geoffrey J Iverson. 2008. ¬´Bayesian versus frequentist inference¬ª. Bayesian evaluation of informative hypotheses, 181‚Äì207.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_integrity.html",
    "href": "chapters/replication_crisis/05_integrity.html",
    "title": "87¬† Integrit√† della ricerca",
    "section": "",
    "text": "Introduzione\nL‚Äôintegrit√† della ricerca si basa su principi e standard professionali che mirano a garantire l‚Äôaffidabilit√† e la qualit√† della ricerca, distinguendosi dall‚Äôetica della ricerca, che si focalizza su principi morali. La condivisione dei dati, il consenso informato, e la trasparenza nelle pratiche di ricerca sono elementi chiave. I codici di condotta sono essenziali per orientare i comportamenti etici, tanto dei ricercatori quanto delle istituzioni. Le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio, e la gestione dei conflitti di interesse sono sfide da affrontare per mantenere l‚Äôintegrit√† della ricerca. √à fondamentale promuovere una cultura di ricerca che privilegi l‚Äôonest√†, la trasparenza e il rispetto dei principi etici.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "href": "chapters/replication_crisis/05_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "title": "87¬† Integrit√† della ricerca",
    "section": "87.1 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca",
    "text": "87.1 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca\nNel campo della ricerca, √® essenziale aderire a principi di condotta responsabile. Questi principi, comunemente definiti come buone pratiche di ricerca, stabiliscono gli standard professionali che mirano a ottimizzare qualit√† e affidabilit√† degli studi condotti. Se √® vero che le idee di base su cosa costituisca una buona pratica di ricerca rimangono relativamente stabili nel tempo, la loro applicazione pratica si evolve in risposta ai cambiamenti sociali, politici e tecnologici. Un esempio lampante di questo adattamento √® la crescente enfasi sulla condivisione dei dati di ricerca, facilitata oggi dall‚Äôesistenza di repository online gratuiti, che ha portato a un‚Äôaspettativa diffusa di massima trasparenza e accessibilit√† dei dati raccolti. Molto incoraggiata √® anche la ‚Äúbuona pratica‚Äù corrispondente alla condivisione del codice utilizzato dai ricercatori per analizzare i dati raccolti.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_integrity.html#differenziazione-tra-integrit√†-e-etica-della-ricerca",
    "href": "chapters/replication_crisis/05_integrity.html#differenziazione-tra-integrit√†-e-etica-della-ricerca",
    "title": "87¬† Integrit√† della ricerca",
    "section": "87.2 Differenziazione tra Integrit√† e Etica della Ricerca",
    "text": "87.2 Differenziazione tra Integrit√† e Etica della Ricerca\nL‚Äôintegrit√† della ricerca si fonda su standard professionali e si distingue nettamente dall‚Äôetica della ricerca, che si basa su principi morali quali l‚Äôautonomia, la beneficenza, la non-maleficenza e la giustizia. Questi ultimi si traducono in pratiche specifiche, come il consenso informato e la garanzia di verit√† e confidenzialit√† nei confronti dei partecipanti. L‚Äôadozione di tali principi etici implica l‚Äôobbligo per i ricercatori di evitare studi che possano arrecare danno o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l‚Äôintegrit√† della ricerca variano leggermente tra le diverse fonti. Ad esempio, Il codice di condotta europeo per l‚ÄôintegritaÃÄ della ricerca enfatizza l‚Äôimportanza di principi come l‚Äôonest√†, la trasparenza, l‚Äôaccuratezza, la responsabilit√†, l‚Äôaffidabilit√†, il rispetto e l‚Äôindipendenza. Questi principi sono interpretati in termini di comportamenti specifici attesi sia dai ricercatori sia dalle istituzioni di ricerca, come la condivisione dei dati di ricerca nel rispetto delle normative sulla protezione dei dati, come il GDPR europeo.\nUn esempio pratico della variazione degli standard nei codici di condotta √® rappresentato dall‚Äôevoluzione della condivisione dei dati di ricerca. In precedenza, la condivisione dei dati poteva essere limitata dalla mancanza di infrastrutture adeguate. Oggi, l‚Äôaccesso facilitato attraverso i repository online e la pressione esercitata dalle riviste scientifiche e dai finanziatori della ricerca hanno reso la condivisione dei dati una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza nella ricerca.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/05_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "87¬† Integrit√† della ricerca",
    "section": "87.3 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta",
    "text": "87.3 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta\nNonostante l‚Äôesistenza di questi codici, i ricercatori, specialmente quelli in fase iniziale della loro carriera, possono trovarsi sotto pressione da parte dei supervisori per adottare comportamenti che si discostano dagli standard stabiliti, spesso a causa della competitivit√† nel campo scientifico e del sistema di valutazione basato sul numero di pubblicazioni. Queste dinamiche possono indurre a pratiche di ricerca discutibili (PRD), che includono la pubblicazione selettiva dei risultati e l‚Äôuso di analisi dei dati flessibili per aumentare artificialmente la probabilit√† di ottenere risultati statisticamente significativi.\nPer mantenere l‚Äôintegrit√† della ricerca, √® fondamentale creare un ambiente di lavoro che valorizzi l‚Äôapertura, l‚Äôinclusivit√† e la discussione franca delle pressioni e delle sfide etiche. Questo implica non solo l‚Äôadesione ai codici di condotta esistenti ma anche l‚Äôimpegno attivo delle istituzioni di ricerca nel promuovere la formazione etica e l‚Äôintegrit√† tra i ricercatori. Attraverso un tale approccio, la comunit√† scientifica pu√≤ aspirare a una ricerca di alta qualit√† che sia sia eticamente responsabile sia metodologicamente solida.",
    "crumbs": [
      "Crisi della replicazione",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian\nModeling. Boca Raton, Florida: CRC Press.\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications\nin r. Chapman; Hall/CRC.\n\n\nAngrist, Joshua D, and J√∂rn-Steffen Pischke. 2010. ‚ÄúThe\nCredibility Revolution in Empirical Economics: How Better Research\nDesign Is Taking the Con Out of Econometrics.‚Äù Journal of\nEconomic Perspectives 24 (2): 3‚Äì30.\n\n\nBaker, Monya. 2016a. ‚Äú1,500 Scientists Lift the Lid on\nReproducibility.‚Äù Nature 533 (7604).\n\n\n‚Äî‚Äî‚Äî. 2016b. ‚ÄúReproducibility Crisis.‚Äù Nature 533\n(7604): 452‚Äì54.\n\n\nBargh, John A, Mark Chen, and Lara Burrows. 1996. ‚ÄúAutomaticity of\nSocial Behavior: Direct Effects of Trait Construct and Stereotype\nActivation on Action.‚Äù Journal of Personality and Social\nPsychology 71 (2): 230‚Äì244.\n\n\nBaribault, Beth, and Anne GE Collins. 2023. ‚ÄúTroubleshooting\nBayesian Cognitive Models.‚Äù Psychological Methods.\n\n\nBelenky, Gregory, Nancy J Wesensten, David R Thorne, Maria L Thomas,\nHelen C Sing, Daniel P Redmond, Michael B Russo, and Thomas J Balkin.\n2003. ‚ÄúPatterns of Performance Degradation and Restoration During\nSleep Restriction and Subsequent Recovery: A Sleep Dose-Response\nStudy.‚Äù Journal of Sleep Research 12 (1): 1‚Äì12.\n\n\nBem, Daryl J. 2011. ‚ÄúFeeling the Future: Experimental Evidence for\nAnomalous Retroactive Influences on Cognition and Affect.‚Äù\nJournal of Personality and Social Psychology 100 (3): 407‚Äì25.\n\n\nBetancourt, Michael. 2016. ‚ÄúDiagnosing Suboptimal Cotangent\nDisintegrations in Hamiltonian Monte Carlo.‚Äù arXiv Preprint\narXiv:1604.00695.\n\n\nBishop, Dorothy. 2019. ‚ÄúThe Psychology of Experimental\nPsychologists: Overcoming Cognitive Constraints to Improve\nResearch.‚Äù\n\n\nBland, J Martin, and Douglas G Altman. 2011. ‚ÄúComparisons Within\nRandomised Groups Can Be Very Misleading.‚Äù Bmj 342.\n\n\nBorel, Emile. 1914. Introduction\ng√©om√©trique. G. Villars, New York.\n\n\nBox, G. E., A. Luceno, and M. del Carmen Paniagua-Quinones. 2011.\nStatistical Control by Monitoring and Adjustment. John Wiley;\nSons.\n\n\nBrownstein, Naomi C, Thomas A Louis, Anthony O‚ÄôHagan, and Jane\nPendergast. 2019. ‚ÄúThe Role of Expert Judgment in Statistical\nInference and Evidence-Based Decision-Making.‚Äù The American\nStatistician 73 (sup1): 56‚Äì68.\n\n\nBruton, Samuel V, Mary Medlin, Mitch Brown, and Donald F Sacco. 2020.\n‚ÄúPersonal Motivations and Systemic Incentives: Scientists on\nQuestionable Research Practices.‚Äù Science and Engineering\nEthics 26 (3): 1531‚Äì47.\n\n\nButton, Katherine S, John PA Ioannidis, Claire Mokrysz, Brian A Nosek,\nJonathan Flint, Emma SJ Robinson, and Marcus R Munaf√≤. 2013.\n‚ÄúPower Failure: Why Small Sample Size Undermines the Reliability\nof Neuroscience.‚Äù Nature Reviews Neuroscience 14 (5):\n365‚Äì76.\n\n\nByrnes, Jarrett EK, and Laura E Dee. 2024. ‚ÄúCausal Inference with\nObservational Data and Unobserved Confounding Variables.‚Äù\nbioRxiv, 2024‚Äì02.\n\n\nChivers, Tom. 2024. Everything Is Predictable: How Bayesian\nStatistics Explain Our World. Simon; Schuster.\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and\nthe Crisis of Modern Science. Columbia University Press.\n\n\nCollaboration, Open Science. 2015. ‚ÄúEstimating the Reproducibility\nof Psychological Science.‚Äù Science 349 (6251): aac4716.\n\n\nComtois, Katherine Anne, Karin E Hendricks, Christopher R DeCou,\nSamantha A Chalker, Amanda H Kerbrat, Jennifer Crumlish, Tierney K\nHuppert, and David Jobes. 2023. ‚ÄúReducing Short Term Suicide Risk\nAfter Hospitalization: A Randomized Controlled Trial of the\nCollaborative Assessment and Management of Suicidality.‚Äù\nJournal of Affective Disorders 320: 656‚Äì66.\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth.\n1987. ‚ÄúHybrid Monte Carlo.‚Äù Physics Letters B 195\n(2): 216‚Äì22.\n\n\nEtz, Alexander, Quentin F Gronau, Fabian Dablander, Peter A\nEdelsbrunner, and Beth Baribault. 2018. ‚ÄúHow to Become a Bayesian\nin Eight Easy Steps: An Annotated Reading List.‚Äù Psychonomic\nBulletin & Review 25 (1): 219‚Äì34.\n\n\nFerguson, Christopher J, and Moritz Heene. 2012. ‚ÄúA Vast Graveyard\nof Undead Theories: Publication Bias and Psychological Science‚Äôs\nAversion to the Null.‚Äù Perspectives on Psychological\nScience 7 (6): 555‚Äì61.\n\n\nFinetti, Bruno de. 1970. Teoria Delle Probabilit√†. Torino: G.\nEinaudi.\n\n\nFishburn, Peter C. 1986. ‚ÄúThe Axioms of Subjective\nProbability.‚Äù Statistical Science 1 (3): 335‚Äì45.\n\n\nFox, John. 2015. Applied Regression Analysis and Generalized Linear\nModels. Sage publications.\n\n\nFunder, David C, and Daniel J Ozer. 2019. ‚ÄúEvaluating Effect Size\nin Psychological Research: Sense and Nonsense.‚Äù Advances in\nMethods and Practices in Psychological Science 2 (2): 156‚Äì68.\n\n\nGelman, Andrew. 2016. ‚ÄúCommentary on ‚ÄòCrisis in Science? Or\nCrisis in Statistics! Mixed Messages in Statistics with Impact on\nScience‚Äô.‚Äù Journal of Statistical Research 48-50\n(1): 11‚Äì12.\n\n\nGelman, Andrew, and Nicholas JL Brown. 2024. ‚ÄúHow Statistical\nChallenges and Misreadings of the Literature Combine to Produce\nUnreplicable Science: An Example from Psychology.‚Äù\n\n\nGelman, Andrew, and John Carlin. 2014. ‚ÄúBeyond Power Calculations:\nAssessing Type s (Sign) and Type m (Magnitude) Errors.‚Äù\nPerspectives on Psychological Science 9 (6): 641‚Äì51.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and\nOther Stories. Cambridge University Press.\n\n\nGelman, Andrew, and Eric Loken. 2013. ‚ÄúThe Garden of Forking\nPaths: Why Multiple Comparisons Can Be a Problem, Even When There Is No\n‚ÄòFishing Expedition‚Äô or ‚Äòp-Hacking‚Äô and the\nResearch Hypothesis Was Posited Ahead of Time.‚Äù Department of\nStatistics, Columbia University 348 (1-17): 3.\n\n\n‚Äî‚Äî‚Äî. 2014. ‚ÄúThe Statistical Crisis in Science.‚Äù\nAmerican Scientist 102 (6): 460‚Äì65.\n\n\nGelman, Andrew, and Cosma Rohilla Shalizi. 2013. ‚ÄúPhilosophy and\nthe Practice of Bayesian Statistics.‚Äù British Journal of\nMathematical and Statistical Psychology 66 (1): 8‚Äì38.\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob\nCarpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian\nB√ºrkner, and Martin Modr√°k. 2020. ‚ÄúBayesian Workflow.‚Äù\narXiv Preprint arXiv:2011.01808.\n\n\nGeman, Stuart, and Donald Geman. 1984. ‚ÄúStochastic Relaxation,\nGibbs Distributions, and the Bayesian\nRestoration of Images.‚Äù IEEE Transactions on Pattern Analysis\nand Machine Intelligence 6: 721‚Äì41.\n\n\nGibson, Edward, and H-H Iris Wu. 2013. ‚ÄúProcessing Chinese\nRelative Clauses in Context.‚Äù Language and Cognitive\nProcesses 28 (1-2): 125‚Äì55.\n\n\nGill, Jeff. 2015. Bayesian Methods: A Social and Behavioral Sciences\nApproach. 3rd Edition. Chapman; Hall/CRC.\n\n\nGlass, Gene V., Barry McGaw, and Mary L. Smith. 1981. Meta-Analysis\nin Social Research. Beverly Hills, CA: Sage Publications.\n\n\nGopalakrishna, Gowri, Gerben Ter Riet, Gerko Vink, Ineke Stoop, Jelte M\nWicherts, and Lex M Bouter. 2022. ‚ÄúPrevalence of Questionable\nResearch Practices, Research Misconduct and Their Potential Explanatory\nFactors: A Survey Among Academic Researchers in the Netherlands.‚Äù\nPloS One 17 (2): e0263023.\n\n\nGrimes, David Robert, Chris T Bauch, and John PA Ioannidis. 2018.\n‚ÄúModelling Science Trustworthiness Under Publish or Perish\nPressure.‚Äù Royal Society Open Science 5 (1): 171511.\n\n\nHardt, Moritz, and Benjamin Recht. 2022. Patterns, Predictions, and\nActions: Foundations of Machine Learning. Princeton, NJ: Princeton\nUniversity Press.\n\n\nHastings, W. Keith. 1970. ‚ÄúMonte Carlo\nSampling Methods Using Markov Chains and Their\nApplications.‚Äù Biometrika 57 (1): 97‚Äì109.\n\n\nHealy, Kieran. 2018. Data Visualization: A Practical\nIntroduction. Princeton University Press.\n\n\nHempel, Carl Gustav. 1970. La Formazione Dei Concetti e Delle Teorie\nNella Scienza Empirica. Feltrinelli.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ‚ÄúThe No-u-Turn\nSampler: Adaptively Setting Path Lengths in Hamiltonian Monte\nCarlo.‚Äù Journal of Machine Learning Research 15 (1):\n1593‚Äì623.\n\n\nHoffmann, Tabea, Abe Hofman, and Eric-Jan Wagenmakers. 2022.\n‚ÄúBayesian Tests of Two Proportions: A Tutorial with r and\nJASP.‚Äù Methodology 18 (4): 239‚Äì77.\n\n\nHowson, Colin, and Peter Urbach. 2006. Scientific Reasoning: The\nBayesian Approach. Open Court Publishing.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC.\n\n\nIoannidis, John PA. 2005. ‚ÄúWhy Most Published Research Findings\nAre False.‚Äù PLoS Medicine 2 (8): e124.\n\n\n‚Äî‚Äî‚Äî. 2008. ‚ÄúWhy Most Discovered True Associations Are\nInflated.‚Äù Epidemiology 19 (5): 640‚Äì48.\n\n\nJaynes, Edwin T. 2003. Probability Theory: The Logic of\nScience. Cambridge University Press.\n\n\nJohnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with\nR. CRC Press.\n\n\nJohnson, Kaneesha R. 2021. ‚ÄúTwo Regimes of Prison Data\nCollection.‚Äù Harvard Data Science Review 3 (3): 10‚Äì1162.\n\n\nKaplan, David. 2023. Bayesian Statistics for the Social\nSciences. Guilford Publications.\n\n\nKorbmacher, Max, Flavio Azevedo, Charlotte R Pennington, Helena\nHartmann, Madeleine Pownall, Kathleen Schmidt, Mahmoud Elsherif, et al.\n2023. ‚ÄúThe Replication Crisis Has Led to Positive Structural,\nProcedural, and Community Changes.‚Äù Communications\nPsychology 1 (1): 3.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A\nTutorial with R, JAGS, and Stan. Academic\nPress.\n\n\nLabatut, Benjamƒ±ÃÅn. 2021. Quando Abbiamo Smesso Di Capire Il\nMondo. Adelphi Edizioni spa.\n\n\nLakens, Dani√´l. 2015. ‚ÄúOn the Challenges of Drawing Conclusions\nfrom p-Values Just Below 0.05.‚Äù PeerJ 3: e1142.\n\n\nLilienfeld, Scott O, and Adele N Strother. 2020. ‚ÄúPsychological\nMeasurement and the Replication Crisis: Four Sacred Cows.‚Äù\nCanadian Psychology/Psychologie Canadienne 61 (4): 281‚Äì288.\n\n\nLindley, Dennis V. 2013. Understanding Uncertainty. John Wiley\n& Sons.\n\n\nLoken, Eric, and Andrew Gelman. 2017. ‚ÄúMeasurement Error and the\nReplication Crisis.‚Äù Science 355 (6325): 584‚Äì85.\n\n\nMartin, Osvaldo. 2024. Bayesian Analysis with Python. Packt\nPublishing Ltd.\n\n\nMartin, Osvaldo A, Ravin Kumar, and Junpeng Lao. 2022. Bayesian\nModeling and Computation in Python. CRC Press.\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and\nR. 1st Edition. New York, NY: Manning Publications.\n\n\nMaul, Andrew, David Torres Irribarra, and Mark Wilson. 2016. ‚ÄúOn\nthe Philosophical Foundations of Psychological Measurement.‚Äù\nMeasurement 79: 311‚Äì20.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. \" O‚ÄôReilly\nMedia, Inc.\".\n\n\nMeehl, Paul E. 1967. ‚ÄúTheory-Testing in Psychology and Physics: A\nMethodological Paradox.‚Äù Philosophy of Science 34 (2):\n103‚Äì15.\n\n\n‚Äî‚Äî‚Äî. 2012. ‚ÄúWhy Summaries of Research on Psychological Theories\nAre Often Uninterpretable.‚Äù In Improving Inquiry in Social\nScience, 13‚Äì59. Routledge.\n\n\nMehr, S. A., L. A. Song, and E. S. Spelke. 2016. ‚ÄúFor 5-Month-Old\nInfants, Melodies Are Social.‚Äù Psychological Science 27\n(4): 486‚Äì501.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth,\nAugusta H. Teller, and Edward Teller. 1953. ‚ÄúEquation of State\nCalculations by Fast Computing Machines.‚Äù The Journal of\nChemical Physics 21 (6): 1087‚Äì92.\n\n\nMunger, Kevin. 2023. ‚ÄúTemporal Validity as Meta-Science.‚Äù\nResearch & Politics 10 (3): 20531680231187271.\n\n\nNelson, Leif D, Joseph Simmons, and Uri Simonsohn. 2018.\n‚ÄúPsychology‚Äôs Renaissance.‚Äù Annual Review of\nPsychology 69 (1): 511‚Äì34.\n\n\nNobles, Melissa. 2000. Shades of Citizenship: Race and the Census in\nModern Politics. Stanford University Press.\n\n\nNosek, Brian A, Jeffrey R Spies, and Matt Motyl. 2012. ‚ÄúScientific\nUtopia: II. Restructuring Incentives and Practices to Promote Truth over\nPublishability.‚Äù Perspectives on Psychological Science 7\n(6): 615‚Äì31.\n\n\nNuzzo, Regina. 2014. ‚ÄúStatistical Errors.‚Äù Nature\n506 (7487): 150‚Äì52.\n\n\nO‚ÄôHagan, Anthony. 2019. ‚ÄúExpert Knowledge Elicitation: Subjective\nbut Scientific.‚Äù The American Statistician 73 (sup1):\n69‚Äì81.\n\n\nOberauer, Klaus, and Stephan Lewandowsky. 2019. ‚ÄúAddressing the\nTheory Crisis in Psychology.‚Äù Psychonomic Bulletin &\nReview 26: 1596‚Äì1618.\n\n\nPearl, Judea. 1995. ‚ÄúCausal Diagrams for Empirical\nResearch.‚Äù Biometrika 82 (4): 669‚Äì88.\n\n\n‚Äî‚Äî‚Äî. 2009. Causality. Cambridge University Press.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. John Wiley &\nSons.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New\nScience of Cause and Effect. Basic books.\n\n\nPress, S James. 2009. Subjective and Objective Bayesian Statistics:\nPrinciples, Models, and Applications. John Wiley & Sons.\n\n\nRafaeli, Eshkol, and William Revelle. 2006. ‚ÄúA Premature\nConsensus: Are Happiness and Sadness Truly Opposite Affects?‚Äù\nMotivation and Emotion 30: 1‚Äì12.\n\n\nRamsey, Frank P. 1926. ‚ÄúTruth and Probability.‚Äù In\nReadings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.\n\n\nRiederer, Emily. 2021. ‚ÄúCausal Design Patterns for Data\nAnalysts,‚Äù January. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nRitchie, Stuart J, Richard Wiseman, and Christopher C French. 2012.\n‚ÄúFailing the Future: Three Unsuccessful Attempts to Replicate\nBem‚Äôs ‚ÄòRetroactive Facilitation of Recall‚Äôeffect.‚Äù PloS\nOne 7 (3): e33423.\n\n\nRohrer, Julia M. 2018. ‚ÄúThinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational Data.‚Äù\nAdvances in Methods and Practices in Psychological Science 1\n(1): 27‚Äì42.\n\n\nRoss, Cody T, Bruce Winterhalder, and Richard McElreath. 2021.\n‚ÄúRacial Disparities in Police Use of Deadly Force Against Unarmed\nIndividuals Persist After Appropriately Benchmarking Shooting Data on\nViolent Crime Rates.‚Äù Social Psychological and Personality\nScience 12 (3): 323‚Äì32.\n\n\nSchennach, Susanne M. 2016. ‚ÄúRecent Advances in the Measurement\nError Literature.‚Äù Annual Review of Economics 8 (1):\n341‚Äì77.\n\n\nSchoot, Van Rens de, Duco Veen, Laurent Smeets, and Sonja Winter. 2020.\n‚ÄúA Tutorial on Using the WAMBS Checklist to Avoid the Misuse of\nBayesian Statistics.‚Äù Routledge.\n\n\nSimmons, Joseph P, Leif D Nelson, and Uri Simonsohn. 2011.\n‚ÄúFalse-Positive Psychology: Undisclosed Flexibility in Data\nCollection and Analysis Allows Presenting Anything as\nSignificant.‚Äù Psychological Science 22 (11): 1359‚Äì66.\n\n\nSorensen, Tanner, and Shravan Vasishth. 2015. ‚ÄúBayesian Linear\nMixed Models Using Stan: A Tutorial for Psychologists, Linguists, and\nCognitive Scientists.‚Äù arXiv Preprint arXiv:1506.06201.\n\n\nSpector, Aaron J. 1956. ‚ÄúExpectations, Fulfillment, and\nMorale.‚Äù The Journal of Abnormal and Social Psychology\n52 (1): 51‚Äì56.\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, and Marek McGann.\n2024. ‚ÄúMost Psychological Researchers Assume Their Samples Are\nErgodic: Evidence from a Year of Articles in Three Major\nJournals.‚Äù Collabra: Psychology 10 (1).\n\n\nStevens, Stanley Smith. 1946. ‚ÄúOn the Theory of Scales of\nMeasurement.‚Äù Science 103 (2684): 677‚Äì80.\n\n\nStigler, Stephen. 1986. The History of Statistics.\nMassachusetts: Belknap Harvard.\n\n\nVan Dongen, Noah, Riet van Bork, Adam Finnemann, Jonas Haslbeck, Han LJ\nvan der Maas, Donald J Robinaugh, Jill de Ron, Jan Sprenger, and Denny\nBorsboom. 2024. ‚ÄúProductive Explanation: A Framework for\nEvaluating Explanations in Psychological Science.‚Äù\nPsychological Review.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and\nPaul-Christian B√ºrkner. 2021. ‚ÄúRank-Normalization, Folding, and\nLocalization: An Improved r ÃÇ for Assessing Convergence of MCMC (with\nDiscussion).‚Äù Bayesian Analysis 16 (2): 667‚Äì718.\n\n\nWagenmakers, Eric-Jan, Michael Lee, Tom Lodewyckx, and Geoffrey J\nIverson. 2008. ‚ÄúBayesian Versus Frequentist Inference.‚Äù\nBayesian Evaluation of Informative Hypotheses, 181‚Äì207.\n\n\nWard, Andrew, and Traci Mann. 2022. ‚ÄúControl Yourself: Broad\nImplications of Narrowed Attention.‚Äù Perspectives on\nPsychological Science 17 (6): 1692‚Äì1703.\n\n\nWare, Jennifer J, and Marcus R Munaf√≤. 2015. ‚ÄúSignificance Chasing\nin Research Practice: Causes, Consequences and Possible\nSolutions.‚Äù Addiction 110 (1): 4‚Äì8.\n\n\nWasserstein, Ronald L, and Nicole A Lazar. 2016. ‚ÄúThe\nASA‚Äôs Statement on p-Values: Context, Process, and\nPurpose.‚Äù The American Statistician 70 (2): 129‚Äì33.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O‚ÄôReilly Media, Inc.\".\n\n\nWilke, Claus O. 2019. Fundamentals of Data Visualization: A Primer\non Making Informative and Compelling Figures. O‚ÄôReilly Media.\n\n\nWilms, Rafael, E M√§thner, Lothar Winnen, and Ralf Lanwehr. 2021.\n‚ÄúOmitted Variable Bias: A Threat to Estimating Causal\nRelationships.‚Äù Methods in Psychology 5: 100075.\n\n\nYouyou, Wu, Yang Yang, and Brian Uzzi. 2023. ‚ÄúA Discipline-Wide\nInvestigation of the Replicability of Psychology Papers over the Past\nTwo Decades.‚Äù Proceedings of the National Academy of\nSciences 120 (6): e2208863120.\n\n\nYu, Bin, and Rebecca L Barter. 2024. Veridical Data Science: The\nPractice of Responsible Data Analysis and Decision Making. MIT\nPress.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, and Babette Renneberg. 2019.\n‚ÄúFuture Expectations in Clinical Depression: Biased or\nRealistic?‚Äù Journal of Abnormal Psychology 128 (7): 678.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon\nSchwab, and Steven N Goodman. 2023. ‚ÄúA New Look at p Values for\nRandomized Clinical Trials.‚Äù NEJM Evidence 3 (1):\nEVIDoa2300003.",
    "crumbs": [
      "Bibliografia"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html",
    "href": "chapters/appendix/a00_installation.html",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1 Guida all‚ÄôInstallazione Locale dei Jupyter Notebook\nPer facilitare l‚Äôapprendimento e l‚Äôapplicazione delle tecniche di analisi dei dati discusse in questo corso, utilizzeremo i Jupyter Notebook come strumento principale. I Jupyter Notebook sono documenti interattivi che consentono di combinare codice, testo narrativo, visualizzazioni grafiche e altri elementi multimediali, rendendoli ideali per documentare e condividere analisi di dati in modo trasparente e riproducibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "href": "chapters/appendix/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1.1 Prerequisiti per l‚ÄôUso dei Jupyter Notebook\nPer utilizzare i Jupyter Notebook, √® necessario soddisfare alcuni prerequisiti:\n\nInstallare Python: √à il linguaggio di programmazione fondamentale per il nostro corso e deve essere installato sul vostro computer.\nGestione degli Ambienti Virtuali con conda: Utilizzeremo conda per creare e gestire ambienti virtuali, che permettono di isolare e gestire le dipendenze del progetto.\nInstallazione dei Pacchetti Python Necessari: Dovrete installare specifici pacchetti Python, inclusi PyMC per l‚Äôanalisi bayesiana, e altri pacchetti utili, all‚Äôinterno dell‚Äôambiente virtuale creato per questo corso.\nInterfaccia per l‚ÄôUso dei Jupyter Notebook: Avrete bisogno di un IDE (Integrated Development Environment) che supporti i Jupyter Notebook, come Visual Studio Code, per scrivere e eseguire i vostri notebook.\n\n\n\nA.1.2 Installazione di Anaconda\nLa maggior parte dei requisiti elencati pu√≤ essere agevolmente soddisfatta tramite l‚Äôinstallazione di Anaconda, una distribuzione di Python che include conda e facilita la gestione degli ambienti virtuali e l‚Äôinstallazione dei pacchetti.\n\n\n\n\n\n\nSe Anaconda √® gi√† stata installata, potrebbero sorgere problemi dopo l‚Äôaggiornamento del sistema operativo. In tal caso, sar√† indispensabile procedere con una nuova installazione di Anaconda.\n\n\n\n\nA.1.2.1 Per Utenti macOS\nSe lavorate su macOS, potreste trovare pi√π pratico utilizzare conda direttamente dal Terminale o da un‚Äôapplicazione terminale moderna come Warp, piuttosto che attraverso Anaconda Navigator. In questo caso, potete optare per installare una versione di Visual Studio Code indipendente da quella fornita con Anaconda, per un maggiore controllo e flessibilit√†.\n\n\nA.1.2.2 Per Utenti Windows\nPer coloro che utilizzano Windows, l‚Äôuso di Jupyter Notebook tramite Anaconda Navigator potrebbe risultare la scelta pi√π semplice e diretta, grazie all‚Äôintegrazione e alla facilit√† d‚Äôuso fornite da Anaconda in ambienti Windows.\n\n\n\nA.1.3 Creazione e Configurazione dell‚ÄôAmbiente Virtuale\nIndipendentemente dal sistema operativo, √® fondamentale installare e configurare conda, che vi permetter√† di creare {ref}appendix-virtual-env dedicati. All‚Äôinterno di questi ambienti, installerete cmdstanpy (o PyMC) e gli altri pacchetti richiesti per il corso. La strada pi√π semplice per soddisfare questi requisiti √® attraverso l‚Äôinstallazione di Anaconda, che semplifica notevolmente il processo di configurazione iniziale e gestione degli ambienti virtuali.\nQuesta guida all‚Äôinstallazione locale mira a fornirvi tutti gli strumenti necessari per iniziare a utilizzare i Jupyter Notebook nel contesto del nostro corso, facilitando un apprendimento efficiente e la condivisione dei risultati delle vostre analisi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#guida-allinstallazione-di-anaconda",
    "href": "chapters/appendix/a00_installation.html#guida-allinstallazione-di-anaconda",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.2 Guida all‚ÄôInstallazione di Anaconda",
    "text": "A.2 Guida all‚ÄôInstallazione di Anaconda\nAnaconda √® una distribuzione popolare per la programmazione in Python. Ecco una guida passo-passo per l‚Äôinstallazione:\n\nScaricare Anaconda:\n\nVisitate il sito ufficiale di Anaconda: https://www.anaconda.com/.\nScegliete la versione adatta al vostro sistema operativo (Windows, macOS o Linux).\nOptate per il download dell‚Äôultima versione disponibile, che include l‚Äôultima versione di Python.\n\nInstallare Anaconda:\n\nEseguite il file di installazione scaricato.\nSeguite le istruzioni visualizzate, mantenendo le impostazioni predefinite, a meno che non abbiate esigenze specifiche.\n\nAggiungere Anaconda al ‚ÄòPATH‚Äô del Sistema:\n\nDurante l‚Äôinstallazione, vi sar√† chiesto se desiderate aggiungere Anaconda al ‚ÄòPATH‚Äô del sistema. Questo passaggio √® cruciale poich√© consente di utilizzare Python da qualunque parte del computer.\nVi consiglio di selezionare questa opzione (altri metodi sono possibili, ma questo ha dimostrato di funzionare senza problemi).\n\nConfermare l‚ÄôInstallazione:\n\nAl termine dell‚Äôinstallazione, aprite PowerShell all‚Äôinterno di Anaconda Navigagor (Windows) o il terminale (macOS/Linux) e digitate python --version per verificare se l‚Äôinstallazione √® riuscita. Se compare la versione di Python, tutto √® andato a buon fine.\n\n\nAnaconda include il Navigator, un‚Äôinterfaccia utente grafica per gestire ambienti di sviluppo, installare librerie aggiuntive e lanciare strumenti come Jupyter Notebook, che consente (in alternativa a VS Code) di scrivere ed eseguire codice Python.\n\n\n\n\n\n\nIstruzioni Specifiche per Utenti Windows:\n\nScaricare Anaconda:\n\nScaricate la versione ‚Äú64-Bit Graphical Installer‚Äù dal sito di Anaconda.\n\nInstallare Anaconda:\n\nAvviate l‚Äôinstaller scaricato e seguite le istruzioni visualizzate.\nDurante l‚Äôinstallazione, selezionate ‚ÄúJust Me‚Äù (solo per l‚Äôutente corrente).\nMantenete il percorso di installazione predefinito.\n\nIncludere Anaconda nel ‚ÄòPATH‚Äô:\n\nIMPORTANTE: Selezionate l‚Äôopzione per aggiungere Anaconda al PATH e impostarlo come installazione di Python di default. Di default, questa opzione √® deselezionata.\n\nVerifica dell‚ÄôInstallazione:\n\nCercate ‚ÄúAnaconda Navigator‚Äù nel menu Start. Se si apre correttamente, l‚Äôinstallazione √® riuscita.\nAprite ‚ÄúAnaconda Prompt‚Äù (o ‚ÄúPowerShell‚Äù) dal menu Start di Anaconda Navigator e digitate conda --version per confermare l‚Äôinstallazione di conda.\n\n\nSeguite attentamente queste istruzioni per garantire un‚Äôinstallazione senza problemi.\nPer maggiori dettagli, consultate il tutorial su come installare Anaconda su Windows: Tutorial Installazione di Anaconda su Windows. Questo tutorial offre spiegazioni dettagliate e una guida passo-passo.\n\n\n\nUna volta installato Anaconda, potrete utilizzare Anaconda Navigator per gestire progetti Python, installare librerie necessarie e avviare strumenti come Jupyter Notebook.\n\n\n\n\n\n\n√à necessario comprendere la differenza tra applicazione (App) e installer.\nCos‚Äô√® un‚ÄôApplicazione (App)\nUn‚Äôapplicazione, comunemente chiamata ‚Äúapp‚Äù, √® un software che funziona sul vostro computer o dispositivo mobile per uno scopo specifico, come navigare in internet, inviare messaggi, elaborare testi o fare calcoli. Esempi includono browser web come Google Chrome, programmi di elaborazione testi come Microsoft Word, o sistemi come Anaconda Navigator.\nCos‚Äô√® un Installer\nUn installer √® un software che installa un‚Äôapplicazione sul vostro computer. Tipicamente, quando scaricate un‚Äôapplicazione da internet, scaricate in realt√† l‚Äôinstaller. L‚Äôinstaller ha il compito di: - Copiare i file dell‚Äôapp nella corretta cartella del computer. - Creare scorciatoie per l‚Äôapp, come icone sul desktop o voci nel menu Start. - Configurare impostazioni iniziali per il corretto funzionamento dell‚Äôapp.\nDopo l‚ÄôInstallazione\nDopo che l‚Äôinstaller ha completato il suo lavoro, l‚Äôapplicazione sar√† pronta all‚Äôuso e l‚Äôinstaller pu√≤ essere eliminato.\nIn sintesi, l‚Äôapplicazione √® il software che userete per svolgere compiti specifici, mentre l‚Äôinstaller √® lo strumento temporaneo per installare l‚Äôapplicazione sul vostro computer. Capire questa distinzione √® fondamentale nel mondo dell‚Äôinformatica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#sec-virtual-environment",
    "href": "chapters/appendix/a00_installation.html#sec-virtual-environment",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.3 L‚ÄôAmbiente Virtuale in Python",
    "text": "A.3 L‚ÄôAmbiente Virtuale in Python\nDopo aver installato Python tramite Anaconda, un aspetto fondamentale da considerare √® la creazione di un ambiente virtuale. Un ambiente virtuale rappresenta uno spazio dedicato sul vostro computer, dove √® possibile installare e gestire le librerie Python necessarie per il corso, inclusi quelle per l‚Äôanalisi statistica. La creazione di un ambiente virtuale √® estremamente vantaggiosa poich√© contribuisce all‚Äôorganizzazione del lavoro e previene possibili conflitti tra diverse librerie. Le istruzioni dettagliate per la configurazione di un ambiente virtuale sono disponibili nel Appendice E`.\nL‚Äôesecuzione delle fasi precedentemente delineate, ossia l‚Äôinstallazione di Anaconda, la configurazione di Visual Studio Code e la creazione di un ambiente virtuale, assicurer√† la completa preparazione di un ambiente di sviluppo locale ottimizzato per l‚Äôutilizzo dei Jupyter Notebook nelle vostre attivit√† legate alla data science all‚Äôinterno di questo corso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#la-shell",
    "href": "chapters/appendix/a00_installation.html#la-shell",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.4 La Shell",
    "text": "A.4 La Shell\nPer la creazione e la gestione dell‚Äôambiente di calcolo, l‚Äôuso di una shell √® indispensabile. Questa pu√≤ essere approfondita nella sezione {ref}appendix-shell. La shell permette di interagire con il sistema operativo attraverso l‚Äôuso di comandi in un terminale. Diverse soluzioni software sono disponibili per facilitare questa interazione.\n\nA.4.1 Unix (MacOS, Linux)\nIn ambienti Unix come MacOS e Linux, ci sono diverse shell tra cui scegliere. Una scelta popolare √® Bash, che √® comunemente preinstallata su molti sistemi Unix. Un‚Äôaltra opzione moderna √® Zsh, nota per la sua facilit√† di personalizzazione e funzionalit√† avanzate. Per un‚Äôesperienza di terminale migliorata, warp √® un‚Äôopzione innovativa che offre un‚Äôinterfaccia utente ricca di funzionalit√† e supporto per i comandi intelligenti.\n\n\nA.4.2 Windows\nSu Windows, la shell predefinita √® il Prompt dei Comandi, ma non √® cos√¨ potente o flessibile come le shell disponibili su Unix. PowerShell √® un‚Äôopzione pi√π avanzata disponibile su Windows, che combina la gestione della configurazione e l‚Äôautomazione delle attivit√† con un linguaggio di scripting.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#lavorare-con-visual-studio-code",
    "href": "chapters/appendix/a00_installation.html#lavorare-con-visual-studio-code",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.5 Lavorare con Visual Studio Code",
    "text": "A.5 Lavorare con Visual Studio Code\nPer utilizzare Visual Studio Code con Python e Jupyter Notebook, √® essenziale installare le relative estensioni. Per fare ci√≤, √® sufficiente seguire alcuni semplici passaggi:\n\nAvvia Visual Studio Code sul tuo computer.\nNella barra laterale sinistra, trova e clicca sull‚Äôicona con quattro quadrati, di cui uno disallineato. Questo √® il menu delle estensioni.\nNella barra di ricerca all‚Äôinterno del menu delle estensioni, digita ‚ÄúPython‚Äù e premi Invio. Troverai diverse estensioni relative a Python.\nTrova l‚Äôestensione ufficiale di Python sviluppata da Microsoft e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\nSuccessivamente, cerca ‚ÄúJupyter‚Äù nella barra di ricerca delle estensioni e premi Invio.\nTrova l‚Äôestensione ‚ÄúJupyter‚Äù nell‚Äôelenco dei risultati e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\n\nUna volta completati questi passaggi, avrai installato con successo le componenti aggiuntive necessarie per lavorare con Python e Jupyter Notebook all‚Äôinterno di Visual Studio Code. Potrai quindi iniziare a scrivere, eseguire e testare il tuo codice Python e i tuoi notebook Jupyter direttamente nell‚Äôambiente di sviluppo di Visual Studio Code.\nQuando apri un file con estensione .ipynb in Visual Studio Code ricorda di selezionare l‚Äôambiente virtuale che desiderate utilizzare. Puoi farlo tramite la ‚ÄúCommand Palette‚Äù (‚áß‚åòP), utilizzando l‚Äôistruzione Python: Select Interpreter. In alternativa, puoi fare clic sull‚Äôicona Select kernel di Visual Studio Code, che si trova nell‚Äôangolo in alto a destra, sotto l‚Äôicona degli ingranaggi (‚öôÔ∏è).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#google-colab",
    "href": "chapters/appendix/a00_installation.html#google-colab",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.6 Google Colab",
    "text": "A.6 Google Colab\nUtilizzando il link √® possibile accedere a Google Colab e iniziare a scrivere codice Python direttamente dal proprio browser, senza dover effettuare alcuna installazione. Basta selezionare l‚Äôopzione ‚ÄúNuovo notebook‚Äù per creare un nuovo ambiente di lavoro. Per avere un‚Äôintroduzione completa sulle funzionalit√† di Colab, si pu√≤ consultare la guida disponibile al seguente link. √à possibile salvare ogni notebook nella propria cartella di Google Drive per una facile gestione e condivisione dei file.\n\nA.6.1 Uso dei Comandi Speciali in Colab\nNell‚Äôambiente Google Colab, √® possibile utilizzare il comando\n!pip list -v\nper visualizzare un elenco dettagliato di tutte le librerie preinstallate. Questo comando fornisce informazioni utili per comprendere quali strumenti sono immediatamente disponibili per l‚Äôuso, comprese le versioni delle librerie e i percorsi di installazione.\nIl prefisso ! indica un comando speciale, noto anche come comando ‚Äúshell‚Äù, che consente di interagire con il sistema sottostante di Colab direttamente dalla cella del notebook, eseguendo operazioni al di fuori dell‚Äôambiente Python standard.\n\n\nA.6.2 Installazione di Librerie Supplementari\nSe necessario aggiungere ulteriori librerie all‚Äôambiente Colab, come pymc, bambi, e arviz, √® possibile farlo facilmente mediante l‚Äôuso dei comandi pip. Ad esempio, per installare queste tre librerie, si possono eseguire i seguenti comandi uno dopo l‚Äôaltro:\n!pip install bambi\n!pip install pymc\n!pip install arviz\nQuesti comandi non solo installeranno le librerie specificate ma gestiranno anche automaticamente l‚Äôinstallazione delle dipendenze necessarie, tra cui numpy, pandas, matplotlib, seaborn, scipy, e statsmodels, assicurando cos√¨ che tutto l‚Äôambiente di lavoro sia pronto per l‚Äôuso.\n\n\nA.6.3 Google Drive\n\nA.6.3.1 Collegare Google Drive a Colab\nPer accedere alla propria cartella di Google Drive durante l‚Äôutilizzo di Colab, √® possibile seguire i seguenti passaggi:\n\nDalla pagina iniziale, fare clic sull‚Äôicona a forma di cartella (Files) situata nel menu in alto a sinistra.\n\n\n\nSi aprir√† un menu con diverse opzioni.\n\n\n\nSelezionare la terza icona tra le quattro disposte orizzontalmente. Apparir√† l‚Äôistruzione ‚ÄúRun this cell to mount your Google Drive‚Äù. Fare clic sull‚Äôicona del triangolo contenuta in un cerchio grigio.\nA questo punto, fare clic sull‚Äôicona ‚Äúdrive‚Äù e successivamente su ‚ÄúMyDrive‚Äù per accedere alle cartelle e ai file salvati sul proprio Google Drive.\n\n√à importante tenere presente che la versione gratuita del runtime di Google Colaboratory non salva le informazioni in modo permanente, il che significa che tutto il lavoro svolto verr√† eliminato una volta terminata la sessione. Pertanto, √® necessario reinstallare le librerie utilizzate in precedenza ogni volta che ci si connette a Colab. Al contrario, i Jupyter Notebook possono essere salvati nella propria cartella di Google Drive.\nPer salvare un Jupyter Notebook su Google Drive utilizzando Colab, √® possibile seguire i seguenti passaggi:\n\nFare clic su File nella barra del menu di Colab.\nSelezionare Save a copy in Drive. Di default, Colab salver√† il Notebook nella cartella Colab Notebooks/.ipynb_checkpoints con un nome simile a Untitled7.ipynb.\nDopo aver salvato il Notebook, √® consigliabile rinominarlo facendo clic con il pulsante destro del mouse sul file nella cartella di Google Drive e selezionando Rename. In questo modo sar√† possibile assegnare un nome pi√π significativo al Notebook.\nPer organizzare i file, √® possibile trascinare il Notebook nella cartella desiderata all‚Äôinterno di Google Drive.\n\nSeguendo questi passaggi, sar√† possibile salvare e organizzare i Jupyter Notebook nella propria cartella di Google Drive, consentendo di accedervi facilmente e mantenerli in modo permanente anche dopo la sessione di Colab.\n\n\n\n\n\n\n√à possibile accedere a un breve tutorial video su come utilizzare Colab e come leggere i dati da un file esterno in un Notebook di Jupyter in Colab. Il video tutorial pu√≤ essere trovato seguendo il link fornito.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html",
    "href": "chapters/appendix/a01_markdown.html",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "B.1 Configurazione Locale per Jupyter Notebook\nPer iniziare a lavorare con i Jupyter Notebook nel proprio ambiente di sviluppo locale, √® necessario completare alcuni passaggi preliminari che assicurano una configurazione ottimale:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "href": "chapters/appendix/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "Installazione di Python tramite Anaconda: Anaconda √® una distribuzione di Python che include gi√† Jupyter e altre librerie utili per la data science e l‚Äôanalisi di dati. Seguendo le istruzioni dettagliate disponibili sul sito di Anaconda (e fornite in precedenza in questa dispensa), si pu√≤ facilmente installare Python e Jupyter sul proprio sistema.\nSelezione di un Ambiente di Sviluppo Integrato (IDE): Visual Studio Code (VS Code) rappresenta una scelta eccellente per chi cerca un IDE versatile e gratuito. Disponibile al download dal sito ufficiale, VS Code supporta Python tramite l‚Äôinstallazione di una specifica estensione. Dopo aver installato VS Code, √® possibile aggiungere il supporto per Python e per i Jupyter Notebook installando l‚Äôestensione ‚ÄúPython‚Äù disponibile nella sezione ‚ÄúExtensions‚Äù, identificabile dall‚Äôicona dei quattro quadrati. Per una completa integrazione dei notebook Jupyter, potrebbe essere necessario installare anche la libreria ipykernel.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#celle",
    "href": "chapters/appendix/a01_markdown.html#celle",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.2 Celle",
    "text": "B.2 Celle\nI Jupyter Notebook sono organizzati in celle, elementi discreti che possono contenere codice o testo (markdown). La possibilit√† di cambiare il tipo di una cella tramite il menu ‚ÄúCell‚Äù o la barra degli strumenti, selezionando ‚ÄúCode‚Äù per codice Python o ‚ÄúMarkdown‚Äù per annotazioni testuali, rende i notebook estremamente versatili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#formattazione-del-testo-con-markdown",
    "href": "chapters/appendix/a01_markdown.html#formattazione-del-testo-con-markdown",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.3 Formattazione del Testo con Markdown",
    "text": "B.3 Formattazione del Testo con Markdown\nMarkdown permette di arricchire le celle di testo con formattazioni varie, creando un documento strutturato e leggibile. Ecco alcuni esempi:\n\nTitoli: # Titolo per un titolo di primo livello, ## Sottotitolo per un secondo livello, e cos√¨ via.\nElenchi: - Elemento per elenchi puntati, 1. Elemento per elenchi numerati.\nCollegamenti: [Testo del link](URL) per inserire un link.\nEnfasi: **grassetto** per il testo in grassetto, *corsivo* per il corsivo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "href": "chapters/appendix/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.4 Comandi Magici in Jupyter Notebook",
    "text": "B.4 Comandi Magici in Jupyter Notebook\nI Jupyter Notebook supportano i ‚Äúcomandi magici‚Äù, comandi speciali che iniziano con % (per comandi su una singola riga) o %% (per comandi che occupano un‚Äôintera cella). Questi comandi offrono funzionalit√† avanzate come:\n\n%run: esegue un file Python esterno.\n%timeit: valuta il tempo di esecuzione di una singola riga di codice.\n%matplotlib inline: integra grafici Matplotlib direttamente nel notebook.\n%load: carica il codice da un file esterno in una cella.\n%reset: cancella tutte le variabili definite nel notebook.\n%pwd e %cd: gestiscono il percorso della directory di lavoro.\n\nDigitando %lsmagic in una cella, si pu√≤ accedere all‚Äôelenco completo dei comandi magici disponibili, esplorando cos√¨ ulteriori strumenti e funzionalit√† offerte da Jupyter Notebook.\nIn conclusione, i Jupyter Notebook rappresentano uno strumento indispensabile per chi lavora nel campo della programmazione e dell‚Äôanalisi dati, grazie alla loro capacit√† di unire codice, visualizzazione dei dati, e annotazioni testuali in un unico documento interattivo e facilmente condivisibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html",
    "href": "chapters/appendix/a02_shell.html",
    "title": "Appendice C ‚Äî La Shell",
    "section": "",
    "text": "C.1 Che cos‚Äô√® una Shell?\nUna shell √® un programma che riceve comandi dall‚Äôutente tramite tastiera (o da file) e li passa al sistema operativo per l‚Äôesecuzione. Pu√≤ essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#che-cos√®-una-shell",
    "href": "chapters/appendix/a02_shell.html#che-cos√®-una-shell",
    "title": "Appendice C ‚Äî La Shell",
    "section": "",
    "text": "C.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nC.1.2 Windows vs macOS/Linux\n\nWindows 10: √à possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l‚Äôambiente preferito √® solitamente PowerShell.\nmacOS/Linux: Zsh √® la shell predefinita in entrambi i sistemi. √à consigliabile sfruttare l‚Äôapplicazione warp per un‚Äôesperienza utente moderna e ottimizzata.\n\n\n\nC.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nC.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nC.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless/more: Visualizza il contenuto dei file con possibilit√† di navigazione.\ncat: Mostra l‚Äôintero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nC.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l‚Äôutilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilit√† nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma pi√π potente perch√© pu√≤ rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nC.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nC.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilit√† di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l‚Äôintero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\n√à cruciale familiarizzarsi con l‚Äôutilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L‚Äôimpiego dei percorsi relativi rende il processo di navigazione pi√π intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l‚Äôutilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: √à importante evitare l‚Äôinserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, ), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l‚Äôuso del trattino (-) pu√≤ causare problemi; quindi √® consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilit√† con alcuni sistemi operativi o applicazioni, rendendo pi√π complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, √® consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, √® possibile ottimizzare notevolmente l‚Äôorganizzazione e la gestione dei propri file, migliorando l‚Äôefficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarit√† con la shell √® fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_colab_tutorial.html",
    "href": "chapters/appendix/a03_colab_tutorial.html",
    "title": "Appendice D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "D.1 Preparazione su Google Drive\nPer iniziare, √® necessario effettuare alcune operazioni preliminari su Google Drive:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_colab_tutorial.html#preparazione-su-google-drive",
    "href": "chapters/appendix/a03_colab_tutorial.html#preparazione-su-google-drive",
    "title": "Appendice D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "Salvataggio dei file necessari: Accedi al tuo account Google Drive e salva i file di interesse, come un dataset e un Jupyter Notebook. Per esempio, potresti creare un Jupyter Notebook con Visual Studio Code e salvarlo con l‚Äôestensione .ipynb. In questo esempio, il file STAR.csv √® stato salvato nella cartella drive/MyDrive/teaching/psicometria/2024.\nPosizionamento dei file: Assicurati di conoscere con precisione il percorso della cartella in cui hai salvato i tuoi file. √à possibile salvare il notebook in qualsiasi cartella, ma √® importante ricordare dove si trova. Nel nostro esempio, anche il notebook import_data.ipynb √® stato salvato nella stessa cartella del dataset.\n\n\nD.1.1 Collegamento a Google Colab\nPer collegare il tuo Google Drive a Colab, inserisci il seguente codice nella prima cella del tuo Jupyter Notebook su Colab:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nEsegui questa cella per iniziare il processo di autenticazione. Ti verr√† richiesto di inserire le tue credenziali (si consiglia di utilizzare l‚Äôaccount istituzionale) e di concedere i permessi necessari a Colab per accedere al tuo Drive.\n\n\nD.1.2 Verifica del file\nPrima di procedere, √® utile verificare che il file desiderato si trovi effettivamente nel percorso specificato. Usa un comando simile al seguente per elencare i file presenti nella cartella:\n!ls drive/MyDrive/teaching/psicometria/2024\nSe il comando mostra il file STAR.csv, significa che √® presente nella cartella e pronto per essere utilizzato.\n\n\nD.1.3 Importazione dei pacchetti e del dataset\nPrima di importare i dati, importa i pacchetti Python necessari per la tua analisi:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSuccessivamente, puoi importare i dati direttamente dal file CSV specificando il percorso completo:\ndf = pd.read_csv(\"drive/MyDrive/teaching/psicometria/2024/STAR.csv\")\n√à fondamentale usare il percorso completo dal punto di montaggio drive fino al nome del file. Il percorso varier√† a seconda dell‚Äôutente e della struttura del suo Drive.\n\n\nD.1.4 Visualizzazione dei dati\nCon i dati ora disponibili in df, puoi procedere con l‚Äôanalisi. Per esempio, per creare un istogramma della variabile reading, puoi usare il seguente codice:\n_ = sns.histplot(data=df, x=\"reading\", stat='density')\nQuesto ti permetter√† di visualizzare la distribuzione dei dati relativi alla lettura nel dataset STAR.csv.\nSeguendo questi passaggi, puoi facilmente lavorare con i file salvati su Google Drive direttamente all‚Äôinterno di un Jupyter Notebook su Google Colab.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html",
    "href": "chapters/appendix/a04_virtual_env.html",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "",
    "text": "E.1 Concetto di Ambiente Virtuale\nUn ambiente virtuale √® uno spazio di lavoro isolato sul vostro computer, dove potete installare e utilizzare librerie Python senza interferire con il sistema principale. Questo isolamento consente di gestire le versioni delle librerie in modo efficiente, mantenendo il sistema organizzato e sicuro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "href": "chapters/appendix/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali",
    "text": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali\n\nIsolamento: Permette di selezionare e mantenere versioni specifiche di Python e delle librerie, garantendo la compatibilit√† e la stabilit√† del progetto.\nOrdine e Sicurezza: Mantiene separato l‚Äôambiente virtuale dal sistema principale, evitando conflitti e assicurando che le modifiche non influenzino altri programmi.\nRiproducibilit√† del Codice: Consente di condividere il codice in modo che funzioni correttamente su altri computer, garantendo coerenza e riproducibilit√† del lavoro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "href": "chapters/appendix/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda",
    "text": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda\nPer creare e gestire ambienti virtuali, √® possibile utilizzare conda, uno strumento incluso in Anaconda. Seguire i seguenti passaggi:\n\nAssicurarsi di avere Anaconda correttamente installato sul sistema.\nUtilizzare il terminale su macOS/Linux o PowerShell su Windows.\nEvitare di installare pacchetti direttamente nell‚Äôambiente base di Conda.\nCreare un nuovo ambiente virtuale usando il comando conda create.\nAttivare l‚Äôambiente virtuale appena creato utilizzando conda activate.\nInstallare i pacchetti necessari all‚Äôinterno dell‚Äôambiente virtuale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "href": "chapters/appendix/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.4 Gestione dell‚ÄôAmbiente Virtuale",
    "text": "E.4 Gestione dell‚ÄôAmbiente Virtuale\nPer una gestione pi√π efficiente degli ambienti virtuali, √® consigliabile utilizzare la linea di comando anzich√© l‚Äôinterfaccia grafica di Anaconda. Questo offre maggiore controllo e flessibilit√† nel processo di creazione e gestione degli ambienti.\nSeguendo correttamente questi passaggi, √® possibile sfruttare appieno i vantaggi degli ambienti virtuali, garantendo un ambiente di sviluppo Python pulito e ben organizzato.\n\n\n\n\n\n\n√à fondamentale evitare l‚Äôinstallazione diretta di pacchetti nell‚Äôambiente base di Conda. Assicuratevi sempre di seguire attentamente i seguenti passaggi:\n\nDisattivate l‚Äôambiente base.\nCreate un nuovo ambiente virtuale.\nAttivate il nuovo ambiente appena creato.\n\nSolo dopo aver completato questi passaggi, √® sicuro procedere con l‚Äôinstallazione dei pacchetti necessari. √à possibile verificare l‚Äôambiente attivo osservando il nome visualizzato all‚Äôinizio del prompt nel terminale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "href": "chapters/appendix/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali",
    "text": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali\n\nDisattivare l‚ÄôAmbiente Virtuale Corrente: Se siete in un ambiente virtuale e desiderate uscirne, utilizzate il comando:\nconda deactivate\nSe non siete in un ambiente virtuale, potete procedere al passaggio successivo.\nCreare un Nuovo Ambiente Virtuale: Per utilizzare il campionatore CmdStan e il linguaggio di programmazione probabilistica Stan, adottate l‚Äôambiente virtuale cmdstan_env. Se si utilizza conda, √® possibile installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge tramite la seguente procedura:\nconda create -n cmdstan_env -c conda-forge cmdstanpy\nConda richieder√† la conferma digitando y. Questo passaggio crea l‚Äôambiente e installa cmdstanpy insieme alle dipendenze necessarie.\nAttivare il Nuovo Ambiente: Per utilizzare l‚Äôambiente appena creato, attivatelo tramite:\nconda activate cmdstan_env\nInstallare le Librerie Richieste: All‚Äôinterno dell‚Äôambiente, installate altre librerie necessarie. Ecco come installare le librerie che utilizzeremo:\nconda install -c conda-forge jax numpyro bambi arviz seaborn jupyter-book ipywidgets watermark pingouin networkx -y \nNota: Gli utenti Windows potrebbero dover utilizzare nutpie come alternativa a jax.\nComandi Utili per Gestire Ambienti e Librerie:\n\nElencare gli ambienti virtuali disponibili e verificare quello attivo:\nconda env list\nRimuovere un ambiente virtuale specifico, ad esempio my_env:\nconda env remove -n my_env\nRimuovere una libreria da un ambiente specifico, ad esempio package_name:\nconda remove -n nome_ambiente package_name\n\n\nSeguendo attentamente questi passaggi e utilizzando i comandi di gestione, sarete in grado di creare e gestire efficacemente gli ambienti virtuali con Conda, garantendo una gestione pulita e ordinata delle dipendenze dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#conda-forge",
    "href": "chapters/appendix/a04_virtual_env.html#conda-forge",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.6 Conda Forge",
    "text": "E.6 Conda Forge\n√à consigliato aggiungere Conda Forge come canale aggiuntivo da cui Conda pu√≤ cercare e installare i pacchetti. Conda Forge √® una collezione di pacchetti gestita dalla community.\n\nE.6.1 Aggiungere Conda Forge\nPer aggiungere Conda Forge come canale, eseguire i seguenti comandi:\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\nconda config --add channels conda-forge: Aggiunge Conda Forge come canale aggiuntivo per la ricerca e l‚Äôinstallazione dei pacchetti.\nconda config --set channel_priority strict: Imposta la priorit√† dei canali su ‚Äústrict‚Äù, dando priorit√† ai pacchetti trovati nei canali elencati per primi nel file di configurazione .condarc.\n\n\n\nE.6.2 Vantaggi dell‚ÄôUso di Conda Forge\n\nAmpia Disponibilit√† di Pacchetti: Conda Forge offre un numero maggiore di pacchetti rispetto al canale predefinito di Conda, aumentando le possibilit√† di trovare il pacchetto necessario senza ricorrere ad altre soluzioni.\nAggiornamenti Frequenti: I pacchetti su Conda Forge vengono aggiornati pi√π frequentemente, rendendo pi√π probabile trovare le versioni pi√π recenti.\nCoerenza e Compatibilit√†: Utilizzando la priorit√† ‚Äústrict‚Äù e Conda Forge, si aumenta la coerenza e la compatibilit√† tra i pacchetti, riducendo il rischio di conflitti tra dipendenze.\n\nAggiungere Conda Forge come canale e impostare la priorit√† dei canali su ‚Äústrict‚Äù sono pratiche consigliate per migliorare la gestione dei pacchetti con Conda. Questo approccio aiuta a mantenere l‚Äôambiente stabile, aggiornato e compatibile con le ultime versioni dei pacchetti disponibili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "href": "chapters/appendix/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.7 Utilizzo di Graphviz (Opzionale)",
    "text": "E.7 Utilizzo di Graphviz (Opzionale)\nPer utilizzare il pacchetto Python graphviz, √® necessario installare prima Graphviz sul vostro computer. Le istruzioni specifiche per l‚Äôinstallazione variano a seconda del sistema operativo e sono disponibili sul sito ufficiale di Graphviz.\n\nE.7.1 Installazione di Graphviz\n\nInstallazione di Graphviz: Seguire le istruzioni sul sito di Graphviz per installare il software sul vostro sistema operativo (Windows, macOS, Linux).\nVerifica dell‚ÄôInstallazione: Dopo l‚Äôinstallazione, assicuratevi che Graphviz sia correttamente installato eseguendo il seguente comando nel terminale:\ndot -V\nQuesto comando dovrebbe restituire la versione di Graphviz installata.\n\n\n\nE.7.2 Installazione del Pacchetto Python graphviz\nDopo aver installato Graphviz, potete procedere con l‚Äôinstallazione del pacchetto Python graphviz nel vostro ambiente virtuale. Seguite questi passaggi:\n\nAttivare l‚ÄôAmbiente Virtuale: Attivate l‚Äôambiente virtuale in cui avete installato pymc (ad esempio, pymc_env) nella vostra console:\nconda activate pymc_env\nInstallare il Pacchetto Python graphviz: Eseguite il seguente comando per installare il pacchetto graphviz tramite Conda Forge:\nconda install -c conda-forge graphviz\n\n\n\nE.7.3 Vantaggi dell‚ÄôUtilizzo di Graphviz\nL‚Äôinstallazione di Graphviz e del relativo pacchetto Python consente di creare e visualizzare grafici e diagrammi all‚Äôinterno del vostro ambiente Python. Questo pu√≤ essere particolarmente utile per visualizzare strutture di dati complesse, flussi di lavoro o grafi probabilistici.\nSeguendo questi passaggi, sarete in grado di utilizzare le funzionalit√† di Graphviz nel vostro ambiente Python, migliorando le capacit√† di visualizzazione e analisi dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a10_math_symbols.html",
    "href": "chapters/appendix/a10_math_symbols.html",
    "title": "Appendice F ‚Äî Simbologia di base",
    "section": "",
    "text": "Per una scrittura pi√π sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL‚Äôoperatore logico booleano \\(\\land\\) significa ‚Äúe‚Äù (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa ‚Äúo‚Äù (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire ‚Äúesiste almeno un‚Äù e indica l‚Äôesistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicit√† \\(\\exists!\\) (‚Äúesiste soltanto un‚Äù) indica l‚Äôesistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l‚Äôesistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire ‚Äúper ogni.‚Äù\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) √® un elemento dell‚Äôinsieme \\(A\\).\nL‚Äôimplicazione logica ‚Äú\\(\\Rightarrow\\)‚Äù significa ‚Äúimplica‚Äù (se ‚Ä¶allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) √® condizione sufficiente per la verit√† di \\(Q\\) e che \\(Q\\) √® condizione necessaria per la verit√† di \\(P\\).\nL‚Äôequivalenza matematica ‚Äú\\(\\iff\\)‚Äù significa ‚Äúse e solo se‚Äù e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge ‚Äútale che.‚Äù\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge ‚Äúuguale per definizione.‚Äù\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge ‚Äúproporzionale a.‚Äù\nIl simbolo \\(\\approx\\) si legge ‚Äúcirca.‚Äù\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire ‚Äúappartiene‚Äù e indica l‚Äôappartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire ‚Äúnon appartiene.‚Äù\nIl simbolo \\(\\subseteq\\) si legge ‚Äú√® un sottoinsieme di‚Äù (pu√≤ coincidere con l‚Äôinsieme stesso). Il simbolo \\(\\subset\\) si legge ‚Äú√® un sottoinsieme proprio di.‚Äù\nIl simbolo \\(\\#\\) indica la cardinalit√† di un insieme.\nIl simbolo \\(\\cap\\) indica l‚Äôintersezione di due insiemi. Il simbolo \\(\\cup\\) indica l‚Äôunione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l‚Äôinsieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l‚Äôinsieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) √® l‚Äôinsieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore pi√π alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densit√† di probabilit√†.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilit√† o densit√† di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) √® una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilit√† di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilit√† di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "",
    "text": "G.1 Numeri binari\nI numeri binari costituiscono la forma pi√π fondamentale di sistema numerico in informatica, essendo composto esclusivamente da due simboli, ovvero 0 e 1. Questo sistema √® frequentemente impiegato per rappresentare dualit√† logiche, come vero/falso o presenza/assenza, in virt√π della sua innata semplicit√† binaria. La sua applicazione √® particolarmente efficace nell‚Äôelaborazione di dati per generare statistiche sintetiche in modo efficiente e rapido.\nImmaginiamo di porre la seguente domanda a 10 studenti: ‚ÄúTi piacciono i mirtilli?‚Äù Le risposte potrebbero essere le seguenti:\nopinion = (True, False, True, True, True, False, True, True, True, False)\nopinion\n\n(True, False, True, True, True, False, True, True, True, False)\nIn questo caso, abbiamo utilizzato i numeri binari 0 e 1 per rappresentare risposte diverse, dove False indica ‚ÄúNo‚Äù e True indica ‚ÄúSi‚Äù. Questa rappresentazione binaria ci consente di ottenere facilmente una panoramica delle preferenze degli studenti riguardo i mirtilli.\nIn Python True equivale a 1 e False a zero. Possiamo dunque calcolare la proporzione di risposte positive nel modo seguente:\nsum(opinion) / len(opinion)\n\n0.7",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.2 Numeri interi",
    "text": "G.2 Numeri interi\nI numeri interi sono numeri privi di decimali e comprendono sia i numeri naturali utilizzati per il conteggio, come 1, 2, ‚Ä¶, sia i numeri con il segno, necessari per rappresentare grandezze negative. L‚Äôinsieme dei numeri naturali √® indicato con il simbolo \\(\\mathbb{N}\\). L‚Äôinsieme numerico dei numeri interi relativi si rappresenta come \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.3 Numeri razionali",
    "text": "G.3 Numeri razionali\nI numeri razionali sono numeri frazionari rappresentabili come \\(m/n\\), dove \\(m\\) e \\(n\\) sono numeri interi e \\(n\\) √® diverso da zero. Gli elementi dell‚Äôinsieme dei numeri razionali sono quindi dati da \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). √à importante notare che l‚Äôinsieme dei numeri naturali √® incluso in quello dei numeri interi, che a sua volta √® incluso in quello dei numeri razionali, ovvero \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Per rappresentare solo i numeri razionali non negativi, utilizziamo il simbolo \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.4 Numeri irrazionali",
    "text": "G.4 Numeri irrazionali\nTuttavia, alcune grandezze non possono essere esprimibili come numeri interi o razionali. Questi numeri sono noti come numeri irrazionali e sono rappresentati dall‚Äôinsieme \\(\\mathbb{R}\\). Essi comprendono numeri illimitati e non periodici, che non possono essere scritti come frazioni. Ad esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\(\\pi = 3.141592\\ldots\\) sono esempi di numeri irrazionali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.5 Numeri reali",
    "text": "G.5 Numeri reali\nI numeri razionali rappresentano solo una parte dei punti sulla retta \\(r\\). Per rappresentare ogni possibile punto sulla retta, √® necessario introdurre i numeri reali. L‚Äôinsieme dei numeri reali comprende numeri positivi, negativi e nulli, e contiene come casi particolari i numeri interi, razionali e irrazionali. In statistica, il numero di decimali spesso indica il grado di precisione della misurazione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli",
    "href": "chapters/appendix/a11_numbers.html#intervalli",
    "title": "Appendice G ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "G.6 Intervalli",
    "text": "G.6 Intervalli\nQuesto ci porta a esplorare gli intervalli, una struttura matematica che ci aiuta a definire sottoinsiemi specifici sulla retta numerica. Gli intervalli aperti, che escludono i punti di inizio e fine. D‚Äôaltro canto, gli intervalli chiusi includono sia il punto di inizio che quello di fine, fornendo una copertura di valori senza tralasciare i confini. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\n\nIntervallo\n\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri binari, interi, razionali, irrazionali e reali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice H ‚Äî Simbolo di somma (sommatorie)",
    "section": "",
    "text": "H.1 Manipolazione di somme\n√à conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l‚Äôoperatore della sommatoria.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Simbolo di somma (sommatorie)</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice H ‚Äî Simbolo di somma (sommatorie)",
    "section": "",
    "text": "H.1.1 Propriet√† 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) √® pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\nH.1.2 Propriet√† 2 (propriet√† distributiva)\nNel caso in cui l‚Äôargomento contenga una costante, √® possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\n√® possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nH.1.3 Propriet√† 3 (propriet√† associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\n√à dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nH.1.4 Propriet√† 4\nSe deve essere eseguita un‚Äôoperazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull‚Äôargomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nH.1.5 Propriet√† 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Simbolo di somma (sommatorie)</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice H ‚Äî Simbolo di somma (sommatorie)",
    "section": "H.2 Doppia sommatoria",
    "text": "H.2 Doppia sommatoria\n√à possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell‚Äôindice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria √® il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi pu√≤ osservare che nella sommatoria interna (quella che dipende dall‚Äôindice \\(j\\)), la quantit√† \\(x_i\\) √® costante, ovvero non dipende dall‚Äôindice (che √® \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall‚Äôoperatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si pu√≤ osservare che nell‚Äôargomento della sommatoria esterna la quantit√† costituita dalla sommatoria in \\(j\\) non dipende dall‚Äôindice \\(i\\) e quindi questa quantit√† pu√≤ essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n}¬†x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto cos√¨ ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Simbolo di somma (sommatorie)</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "",
    "text": "I.1 Diagrammi di Eulero-Venn\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le propriet√† delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19¬∞ secolo John Venn, anche se rappresentazioni simili erano gi√† state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, √® possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le propriet√† degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all‚Äôinterno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.2 Appartenenza ad un insieme",
    "text": "I.2 Appartenenza ad un insieme\nUsiamo ora Python.\n\nSet1 = {1, 2}\nprint(Set1)\nprint(type(Set1))\n\n{1, 2}\n&lt;class 'set'&gt;\n\n\n\nmy_list = [1, 2, 3, 4]\nmy_set_from_list = set(my_list)\nprint(my_set_from_list)\n\n{1, 2, 3, 4}\n\n\nL‚Äôappartenenza ad un insieme si verifica con in e not in.\n\nmy_set = set([1, 3, 5])\nprint(\"Ecco il mio insieme:\", my_set)\nprint(\"1 appartiene all'insieme:\", 1 in my_set)\nprint(\"2 non appartiene all'insieme:\", 2 in my_set)\nprint(\"4 NON appartiene all'insieme:\", 4 not in my_set)\n\nEcco il mio insieme: {1, 3, 5}\n1 appartiene all'insieme: True\n2 non appartiene all'insieme: False\n4 NON appartiene all'insieme: True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.3 Relazioni tra insiemi",
    "text": "I.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l‚Äôinsieme universo e l‚Äôinsieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv = set([x for x in range(11)])\nSuper = set([x for x in range(11) if x % 2 == 0])\nDisj = set([x for x in range(11) if x % 2 == 1])\nSub = set([4, 6])\nNull = set([x for x in range(11) if x &gt; 10])\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\", Univ)\nprint(\"Tutti gli interi positivi pari fino a 10:\", Super)\nprint(\"Tutti gli interi positivi dispari fino a 10:\", Disj)\nprint(\"Insieme di due elementi, 4 e 6:\", Sub)\nprint(\"Un isieme vuoto:\", Null)\n\nInsieme Universo (tutti gli interi positivi fino a 10): {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nTutti gli interi positivi pari fino a 10: {0, 2, 4, 6, 8, 10}\nTutti gli interi positivi dispari fino a 10: {1, 3, 5, 7, 9}\nInsieme di due elementi, 4 e 6: {4, 6}\nUn isieme vuoto: set()\n\n\n\nprint('√à \"Super\" un sovrainsieme di \"Sub\"?', Super.issuperset(Sub))\nprint('√à \"Super\" un sottoinsieme di \"Univ\"?', Super.issubset(Univ))\nprint('√à \"Sub\" un sovrainsieme di \"Super\"?', Sub.issuperset(Super))\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?', Sub.isdisjoint(Disj))\n\n√à \"Super\" un sovrainsieme di \"Sub\"? True\n√à \"Super\" un sottoinsieme di \"Univ\"? True\n√à \"Sub\" un sovrainsieme di \"Super\"? False\nSono \"Super\" e \"Disj\" insiemi disgiunti? True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.4 Operazioni tra insiemi",
    "text": "I.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cio√®\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l‚Äôinsieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l‚Äôinsieme differenza \\(A \\setminus B\\) √® detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) √® una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare √® data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) √® la regione delimitata dal rettangolo, \\(L\\) √® la regione all‚Äôinterno del cerchio di sinistra e \\(R\\) √® la regione all‚Äôinterno del cerchio di destra. La regione evidenziata mostra l‚Äôinsieme indicato sotto ciascuna figura.\n\n\n\nDiagrammi di Venn\n\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\n\nLeggi di DeMorgan\n\n\nVediamo ora come si eseguono le operazioni tra insiemi con Python.\nEguaglianza e differenza.\n\nS1 = {1, 2}\nS2 = {2, 2, 1, 1, 2}\nprint(\n    \"S1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\nS1==S2: True\n\n\n\nS1 = {1, 2, 3, 4, 5, 6}\nS2 = {1, 2, 3, 4, 0, 6}\nprint(\n    \"S1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\nS1==S2: False\n\n\nIntersezione. Si noti che il connettivo logico & corrisponde all‚Äôintersezione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\n\nS1: {9, 3, 6}\n\n\n\nS2 = set([x for x in range(1, 7)])\nprint(\"S2:\", S2)\n\nS2: {1, 2, 3, 4, 5, 6}\n\n\n\nS_intersection = S1.intersection(S2)\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nS_intersection = S1 & S2\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\n\n\n\nS3 = set([x for x in range(6, 10)])\nprint(\"S3:\", S3)\nS1_S2_S3 = S1.intersection(S2).intersection(S3)\nprint(\"Intersection of S1, S2, and S3:\", S1_S2_S3)\n\nS3: {8, 9, 6, 7}\nIntersection of S1, S2, and S3: {6}\n\n\nUnione. Si noti che il connettivo logico | corrisponde all‚Äôunione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\nS2 = set([x for x in range(1, 5)])\nprint(\"S2:\", S2)\n\nS_union = S1.union(S2)\nprint(\"Unione di S1 e S2:\", S_union)\nS_union = S1 | S2\nprint(\"Unione di S1 e S2:\", S_union)\n\nS1: {9, 3, 6}\nS2: {1, 2, 3, 4}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\n\n\nInsieme complementare.\n\nS = set([x for x in range(21) if x % 2 == 0])\nprint(\"S √® l'insieme dei numeri interi pari tra 0 e 20:\", S)\n\nS √® l'insieme dei numeri interi pari tra 0 e 20: {0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20}\n\n\n\nS_complement = set([x for x in range(21) if x % 2 != 0])\nprint(\"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\", S_complement)\n\nS_complement √® l'insieme dei numeri interi dispari tra 0 e 20: {1, 3, 5, 7, 9, 11, 13, 15, 17, 19}\n\n\n\nprint(\n    \"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\",\n    S.union(S_complement) == set([x for x in range(21)]),\n)\n\n√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20? True\n\n\nDifferenza tra insiemi.\n\nS1 = set([x for x in range(31) if x % 3 == 0])\nprint(\"Set S1:\", S1)\n\nSet S1: {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\n\n\n\nS2 = set([x for x in range(31) if x % 5 == 0])\nprint(\"Set S2:\", S2)\n\nSet S2: {0, 5, 10, 15, 20, 25, 30}\n\n\n\nS_difference = S2 - S1\nprint(\"Differenza tra S2 e S1, i.e. S2\\S1:\", S_difference)\n\nS_difference = S1.difference(S2)\nprint(\"Differenza tra S1 e S2, i.e. S1\\S2:\", S_difference)\n\nDifferenza tra S1 e S2 i.e. S2\\S1: {25, 10, 20, 5}\nDifferenza tra S2 e S1 i.e. S1\\S2: {3, 6, 9, 12, 18, 21, 24, 27}\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Œî, √® un‚Äôoperazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all‚Äôunione tra i due insiemi meno la loro intersezione.\n\nprint(\"S1\", S1)\nprint(\"S2\", S2)\nprint(\"Differenza simmetrica\", S1 ^ S2)\nprint(\"Differenza simmetrica\", S2.symmetric_difference(S1))\n\nS1 {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\nS2 {0, 5, 10, 15, 20, 25, 30}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.5 Coppie ordinate e prodotto cartesiano",
    "text": "I.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) √® l‚Äôinsieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) √® la prima componente (o prima coordinata) e \\(y\\) la seconda. L‚Äôinsieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPi√π in generale, un prodotto cartesiano di \\(n\\) insiemi pu√≤ essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento √® una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non √® dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento √® possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all‚Äôn-esimo. Il prodotto cartesiano prende il nome da Ren√© Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA = set([\"a\", \"b\", \"c\"])\nS = {1, 2, 3}\n\n\ndef cartesian_product(S1, S2):\n    result = set()\n    for i in S1:\n        for j in S2:\n            result.add(tuple([i, j]))\n    return result\n\n\nC = cartesian_product(A, S)\nprint(f\"Prodotto cartesiano di A e S\\n{A} x {S} = {C}\")\n\nProdotto cartesiano di A e S\n{'Head', 'Tail'} x {1, 2, 3} = {('Tail', 1), ('Head', 2), ('Head', 1), ('Tail', 3), ('Tail', 2), ('Head', 3)}\n\n\nSi definisce cardinalit√† (o potenza) di un insieme finito il numero degli elementi dell‚Äôinsieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalit√† dell'insieme prodotto cartesiano √®:\", len(C))\n\nLa cardinalit√† dell'insieme prodotto cartesiano √®: 9\n\n\nInvece di scrivere funzioni noi stessi, √® possibile usare la libreria itertools di Python. Si ricordi di trasformare l‚Äôoggetto risultante in una lista per la visualizzazione e la successiva elaborazione.\n\nfrom itertools import product as prod\n\n\nA = set([x for x in range(1, 7)])\nB = set([x for x in range(1, 7)])\np = list(prod(A, B))\n\nprint(\"A √® l'insieme di tutti i possibili lanci di un dado:\", A)\nprint(\"B √® l'insieme di tutti i possibili lanci di un dado:\", B)\nprint(\n    \"\\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\\n\",\n    p,\n)\n\nA √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\nB √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\n\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\n [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLa cardinalit√† (cio√® il numero di elementi) del prodotto cartesiano tra due o pi√π insiemi √® uguale al prodotto delle cardinalit√† degli insiemi considerati: card(A √ó B) = card(A) ¬∑ card(B).\nUsando itertools √® facile calcolare la cardinalit√† del prodotto cartesiano di un insieme per se stesso. Consideriamo il quadrato dell‚Äôinsieme costituito dai risultati del lancio di una moneta. L‚Äôinsieme risultante avr√† cardinalit√† \\(2 \\cdot 2 = 4\\).\n\nA = {\"Head\", \"Tail\"} \np2 = list(prod(A, repeat=2))  \nprint(f\"Il quadrato dell'insieme A √® un insieme che contiene {len(p2)} elementi: {p2}\")\n\nIl quadrato dell'insieme A √® un insieme che contiene 4 elementi: [('Head', 'Head'), ('Head', 'Tail'), ('Tail', 'Head'), ('Tail', 'Tail')]\n\n\nL‚Äôinsieme \\(A\\) elevato alla terza potenza produce un insieme la cui cardinalit√† √®\n\np3 = list(prod(A, repeat=3))  \nprint(f\"L'insieme A elevato alla terza potenza √® costituito da {len(p3)} elementi: {p3}\")\n\nL'insieme A elevato alla terza potenza √® costituito da 8 elementi: [('Head', 'Head', 'Head'), ('Head', 'Head', 'Tail'), ('Head', 'Tail', 'Head'), ('Head', 'Tail', 'Tail'), ('Tail', 'Head', 'Head'), ('Tail', 'Head', 'Tail'), ('Tail', 'Tail', 'Head'), ('Tail', 'Tail', 'Tail')]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "",
    "text": "J.1 Principio del prodotto\nI metodi di base del calcolo combinatorio applicano due principi: la regola del prodotto e la regola della somma. Consideriamo il principio del prodotto.\nIn generale, una scelta pu√≤ essere effettuata in pi√π fasi, ad esempio \\(k\\). Supponiamo che per ogni \\(i = 1, \\dots, k\\) la scelta da compiere al \\(i\\)-esimo stadio possa essere effettuata in \\(n_i\\) modi. Secondo il principio del prodotto, il numero totale di possibili scelte √® dato dal prodotto dei singoli numeri, ovvero:\n\\[\nn_{\\text{tot}} = n_1 \\cdot  n_2 \\cdots n_{k-1} \\cdot n_k.\n\\]\nEsempio 1. Ho a disposizione 2 paia di scarpe, 3 paia di pantaloni e 5 magliette. In quanti modi diversi mi posso vestire?\n\\[\n2 \\cdot 3 \\cdot 5 = 30\n\\]\nEsempio 2. In Minnesota le targhe delle automobili sono costituite da tre lettere (da A a Z) seguite da tre numeri (da 0 a 9). Qual √® la proporzione di targhe che iniziano con GZN?\nLa soluzione √® data dal numero di targhe che iniziano con GZN diviso per il numero totale di targhe possibili.\nIl numero totale di targe √® \\(26 \\cdot 26 \\cdot 26 \\cdot 10 \\cdot 10 \\cdot 10 = 17,576,000\\). Per calcolare il numero di targhe che iniziano con GZN, consideriamo le targhe che hanno la forma GZN _ _ _. Per i tre simboli mancanti ci sono \\(10 \\cdot 10 \\cdot 10\\) possibilit√†. Dunque la proporzione cercata √®\n\\[\n10^3/(26^3 \\cdot 10^3) = 1/26^3 = 0.0000569.\n\\]\n10**3 / (26**3 * 10**3)\n\n5.689576695493855e-05",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.2 Principio della somma",
    "text": "J.2 Principio della somma\nIl principio della somma afferma che se un insieme pu√≤ essere suddiviso in due o pi√π sottoinsiemi disgiunti, allora il numero totale di elementi nell‚Äôinsieme √® dato dalla somma dei numeri di elementi in ciascun sottoinsieme.\nIn altre parole, se si vuole determinare il numero totale di modi in cui √® possibile realizzare un certo evento, e questo evento pu√≤ essere realizzato in modo esclusivo in modo A oppure B, allora il numero totale di modi in cui √® possibile realizzare l‚Äôevento √® dato dalla somma dei modi in cui pu√≤ essere realizzato in modo A e dei modi in cui pu√≤ essere realizzato in modo B.\nAd esempio, se si vuole determinare il numero totale di modi in cui √® possibile scegliere un dolce da una tavola con due tipi di dolci (ad esempio torta e biscotti), il principio della somma afferma che il numero totale di modi √® dato dalla somma del numero di modi in cui √® possibile scegliere la torta e del numero di modi in cui √® possibile scegliere i biscotti.\nEsempio 3. L‚Äôurna \\(A\\) contiene \\(5\\) palline numerate da \\(1\\) a \\(5\\), l‚Äôurna \\(B\\) contiene \\(6\\) palline numerate da \\(6\\) a \\(11\\), l‚Äôurna \\(C\\) contiene \\(3\\) palline numerate da \\(12\\) a \\(14\\) e l‚Äôurna \\(D\\) contiene \\(2\\) palline numerate \\(15\\) e \\(16\\). Quanti insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, si possono formare?\nIl numero di insiemi di tipo \\(AB\\) √® dato dal prodotto delle palline che possono essere estratte dall‚Äôurna \\(A\\) (5) e da quelle che possono essere estratte dall‚Äôurna \\(B\\) (6), ovvero \\(5 \\cdot 6 = 30\\). In modo analogo, si ottengono 15 insiemi di tipo \\(AC\\), 10 di tipo \\(AD\\), 18 di tipo \\(BC\\), 12 di tipo \\(BD\\), 6 di tipo \\(CD\\). Quindi, per la regola della somma, il numero totale di insiemi distinti che si possono formare con due palline provenienti dalle quattro urne √® dato dalla somma di questi valori, ovvero \\(30 + 15 + 10 + 18 + 12 + 6 = 91\\). Pertanto, ci sono 91 insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, che si possono formare.\nIn conclusione, il principio del prodotto e il principio della somma sono due concetti fondamentali del calcolo combinatorio. In generale, il principio del prodotto si applica quando si tratta di eventi indipendenti che si verificano in successione, mentre il principio della somma si applica quando si tratta di eventi mutuamente esclusivi (cio√® non possono accadere contemporaneamente) e si cerca di calcolare il numero totale di possibili risultati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.3 Il modello dell‚Äôurna",
    "text": "J.3 Il modello dell‚Äôurna\nI problemi di combinatoria spesso coinvolgono l‚Äôestrazione di palline da urne, le quali rappresentano dei modelli delle corrispondenti situazioni considerate. Una procedura comune per rappresentare queste situazioni √® il modello dell‚Äôurna, che consiste nell‚Äôestrazione di \\(k\\) palline da un‚Äôurna contenente \\(n\\) palline. Le palline possono essere tutte diverse, oppure alcune palline possono essere indistinguibili tra loro. Tra le possibili modalit√† di estrazione, sono particolarmente importanti:\n\nL‚Äôestrazione Bernoulliana di \\(k\\) palline, che si ottiene estraendo una pallina alla volta e rimettendola nell‚Äôurna dopo ogni estrazione;\nL‚Äôestrazione senza ripetizione di \\(k\\) palline, che si ottiene estraendo una pallina alla volta senza rimetterla nell‚Äôurna dopo l‚Äôestrazione;\nL‚Äôestrazione in blocco di \\(k\\) palline, che si ottiene estraendo \\(k\\) palline contemporaneamente.\n\nPer esempio, nel caso di campioni di ampiezza 2 estratti da un‚Äôurna con tre elementi \\(\\{1, 2, 3\\}\\), abbiamo i seguenti quattro casi:\n\ncampionamento con reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{2,  1\\}, \\{3,  1\\}, \\{1,  2\\}, \\{2,  2\\}, \\{3,  2\\}, \\{1,  3\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento con reimmissione senza tenere conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{1,  2\\}, \\{1,  3\\}, \\{2,  2\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento senza reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  2\\}, \\{2,  1\\}, \\{1,  3\\}, \\{3,  1\\}, \\{2,  3\\}, \\{3,  2\\}\\);\ncampionamento senza reimmissione e senza tenere conto dell‚Äôordine di estrazione: \\(\\{1 , 2\\}, \\{1,  3\\}, \\{2, 3\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.4 Permutazioni semplici",
    "text": "J.4 Permutazioni semplici\nLe permutazioni semplici sono il risultato di uno scambio dell‚Äôordine degli elementi di un insieme che contiene elementi distinti tra loro. Queste permutazioni sono indicate con il simbolo \\(P_n\\), e il numero di permutazioni semplici di \\(n\\) elementi distinti √® pari al fattoriale di \\(n\\), cio√® \\(n!\\), come espresso dall‚Äôeq. {eq}eq-permsem:\n\\[\nP_n = n!\n\\] (eq-permsem)\ndove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed √® uguale al prodotto di \\(n\\) numeri interi decrescenti da \\(n\\) fino a 1. Per definizione, il fattoriale di 0 √® 1.\nIl numero di permutazioni di \\(n\\) elementi distinti pu√≤ essere visto come l‚Äôestrazione senza rimessa di \\(n\\) elementi diversi da un‚Äôurna contenente gli \\(n\\) oggetti. Questo ci consente di applicare il principio del prodotto, il quale afferma che il numero di modi in cui √® possibile combinare o disporre un insieme di oggetti √® dato dal prodotto del numero di scelte possibili per ciascuna categoria di oggetti. Nel caso delle permutazioni, il principio del prodotto si applica nel seguente modo: se abbiamo \\(n\\) oggetti distinti da disporre in un ordine particolare, il numero di permutazioni possibili √® dato dal prodotto del numero di scelte possibili per la prima posizione, per la seconda posizione, per la terza posizione, e cos√¨ via, fino alla \\(n\\)-esima posizione.\nPer esempio, consideriamo il caso di disporre tre oggetti, A, B e C. Ci sono tre modi per scegliere il primo oggetto: A, B o C. Una volta scelto il primo oggetto, ci sono due modi per scegliere il secondo oggetto. Infine, rimane un solo modo per scegliere l‚Äôultimo oggetto. Possiamo concettualizzare questo processo come un albero, dove il numero totale di foglie √® uguale al numero di permutazioni. Per calcolare il numero di foglie, basta moltiplicare sequenzialmente il numero di rami a ogni livello, cio√® \\(3 \\times 2 \\times 1\\).\nEsempio 4. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Calcoliamo il numero di permutazioni semplici.\nLe permutazioni semplici di \\(A\\) sono: \\(\\{a, b, c\\}\\), \\(\\{a, c, b\\}\\), \\(\\{b, c, a\\}\\), \\(\\{b, a, c\\}\\), \\(\\{c, a, b\\}\\), \\(\\{c, b, a\\}\\), ovvero 6. Applichiamo l‚Äôeq. {ref}eq-permsem:\n\\[\nP_n = P_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6.\n\\]\nLo strumento principale che usiamo in Python per trovare le permutazioni di un insieme √® una libreria specificamente progettata per iterare sugli oggetti in modi diversi, ovvero itertools. Con itertools.permutations() generiamo le permutazioni.\n\nA = {\"A\", \"B\", \"C\"}\nprint(A)\n\n{'A', 'B', 'C'}\n\n\n\npermutations = it.permutations(A)\n\nPer visualizzare il risultato dobbiamo trasformarlo in una tupla:\n\ntuple(permutations)\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nLo stesso risultato si ottiene con\n\npermutations = it.permutations(\"ABC\")\npermutations = tuple(permutations)\npermutations\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nPossiamo ora contare quanti elementi ci sono nella tupla usando la funzione len():\n\nlen(permutations)\n\n6\n\n\nOppure, possiamo appliare la formula {eq}eq-permsem mediante la funzione factorial() contenuta nella libreria math di Numpy:\n\nmath.factorial(3)\n\n6\n\n\nEsempio 5. Gli anagrammi sono le permutazioni che si ottengono da una parola variando l‚Äôordine delle lettere. Le permutazioni semplici si applicano al caso di parole costituite da lettere tutte diverse tra loro. Ad esempio, con la parola NUMERO si ottengono \\(P_6 = 6! = 6\\cdot5\\cdot4\\cdot3\\cdot2\\cdot1 = 720\\) anagrammi.\n\npermutations = it.permutations(\"NUMERO\")\npermutations = tuple(permutations)\npermutations[1:10]\n\n(('N', 'U', 'M', 'E', 'O', 'R'),\n ('N', 'U', 'M', 'R', 'E', 'O'),\n ('N', 'U', 'M', 'R', 'O', 'E'),\n ('N', 'U', 'M', 'O', 'E', 'R'),\n ('N', 'U', 'M', 'O', 'R', 'E'),\n ('N', 'U', 'E', 'M', 'R', 'O'),\n ('N', 'U', 'E', 'M', 'O', 'R'),\n ('N', 'U', 'E', 'R', 'M', 'O'),\n ('N', 'U', 'E', 'R', 'O', 'M'))\n\n\n\nlen(permutations)\n\n720\n\n\n\nmath.factorial(6)\n\n720\n\n\nEsempio 6. Un altro esempio riguarda i giochi di carte. Ci sono 52! \\(\\approx 8 \\times 10^{67}\\) modi di ordinare un mazzo di carte da poker; questo numero √® ‚Äúquasi‚Äù grande come il numero di atomi dell‚Äôuniverso che si stima essere uguale a circa \\(10^{80}\\).\n\nmath.factorial(52)\n\n80658175170943878571660636856403766975289505440883277824000000000000\n\n\n\nprint(\"{:.2e}\".format(math.factorial(52)))\n\n8.07e+67\n\n\nEsempio 7. Le cifre 1, 2, 3, 4 e 5 sono disposte in ordine casuale per formare un numero di cinque cifre.\n\nQuanti diversi numeri di cinque cifre possono essere formati?\nQuanti diversi numeri di cinque cifre sono dispari?\n\nIniziamo a creare una tupla con le cinque cifre:\n\ntuple(range(1, 6))\n\n(1, 2, 3, 4, 5)\n\n\nCome in precedenza, possiamo usare it.permutations():\n\npermutations = it.permutations(range(1, 6))\npermutations = tuple(permutations)\npermutations[1:10]\n\n((1, 2, 3, 5, 4),\n (1, 2, 4, 3, 5),\n (1, 2, 4, 5, 3),\n (1, 2, 5, 3, 4),\n (1, 2, 5, 4, 3),\n (1, 3, 2, 4, 5),\n (1, 3, 2, 5, 4),\n (1, 3, 4, 2, 5),\n (1, 3, 4, 5, 2))\n\n\nCi sono 120 permutazioni.\n\nlen(permutations)\n\n120\n\n\nPer trovare i numeri dispari tra queste 120 permutazioni utilizziamo la funzione sum() in Python abbinato alle espressioni for e in. Accediamo al quinto elemento di una permutazione utilizzando la notazione [4] (il primo elemento √® indicato con 0, quindi il quinto √® 4):\n\nsum(permutation[4] % 2 for permutation in permutations)\n\n72\n\n\nPossiamo controllare questo teoricamente: nel caso presente, ci sono tre possibili cifre dispari per l‚Äôultima posizione di un numero di cinque cifre: 1, 3 e 5. Dopo aver scelto una di queste, le cifre rimanenti nelle prime quattro posizioni possono essere formate in 4! modi. Pertanto:\n\nmath.factorial(4) * 3\n\n72",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.5 Disposizioni semplici",
    "text": "J.5 Disposizioni semplici\nLe disposizioni semplici rappresentano tutti i modi in cui un insieme di oggetti pu√≤ essere disposto in sequenza, tenendo conto dell‚Äôordine in cui gli oggetti vengono scelti e senza permettere la scelta di un oggetto pi√π di una volta.\nQuindi, se abbiamo un insieme di \\(n\\) oggetti distinti e vogliamo selezionarne \\(k\\) per formare una sequenza, le disposizioni semplici rappresentano tutti i sottoinsiemi di \\(k\\) oggetti distinti che possono essere selezionati dall‚Äôinsieme di \\(n\\) oggetti distinti in modo tale che l‚Äôordine in cui vengono selezionati sia importante.\nAd esempio, se abbiamo l‚Äôinsieme di oggetti \\({a,b,c}\\) e vogliamo selezionare due oggetti per formare una sequenza, le disposizioni semplici sarebbero: \\(ab\\), \\(ba\\), \\(ac\\), \\(ca\\), \\(bc\\), \\(cb\\). Nota che, in questo caso, l‚Äôordine in cui gli oggetti vengono scelti √® importante e ogni oggetto viene scelto una sola volta.\nIl numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® indicato con \\(D_{n,k}\\) e pu√≤ essere calcolato dividendo il numero di permutazioni di \\(n\\) oggetti distinti per il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti, poich√© ogni disposizione semplice pu√≤ essere ottenuta come una permutazione di un sottoinsieme di \\(k\\) oggetti distinti.\nQuindi, il numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® dato da\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!},\n\\] (eq_disp_simple)\ndove \\(n!\\) rappresenta il numero di permutazioni di \\(n\\) oggetti distinti e \\((n-k)!\\) rappresenta il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti.\nEsempio 8. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Qual √® il numero di disposizioni semplici di classe 2? Come abbiamo visto sopra, le disposizioni semplici di classe 2 sono \\(\\{a, b\\}\\), \\(\\{b, a\\}\\), \\(\\{a, c\\}\\), \\(\\{c, a\\}\\), \\(\\{b, c\\}\\), \\(\\{c, b\\}\\), ovvero 6.\nApplichiamo l‚Äôeq. {eq}eq_disp_simple:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} = 3 \\cdot 2 = 6.\n\\]\nIn maniera equivalente possiamo trovare il risultato usando itertools.permutations(iterable, k). Tale istruzione ci consente di trovare il numero di permutazioni possibili di tutti i sottoinsiemi di \\(k\\) elementi distinti, ovvero il numero di diverse sequenze ordinate che possiamo ottenere scegliendo \\(k\\) oggetti dall‚Äôinsieme.\n\ntuple(it.permutations(\"ABC\", 2))\n\n(('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B'))\n\n\n\nres = tuple(it.permutations(\"ABC\", 2))\nlen(res)\n\n6\n\n\nOppure possiamo implementare l‚Äôeq. {eq}eq_disp_simple:\n\ndef simple_disp(n, k):\n    return math.factorial(n) / math.factorial(n - k)\n\n\nsimple_disp(3, 2)\n\n6.0",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sec-combinazione-semplice",
    "href": "chapters/appendix/a14_combinatorics.html#sec-combinazione-semplice",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.6 Combinazioni semplici",
    "text": "J.6 Combinazioni semplici\nLe combinazioni sono simili alle permutazioni, ma ignorano l‚Äôordine degli elementi. In altre parole, le combinazioni rappresentano i modi di scegliere \\(k\\) elementi distinti da\\(n\\)elementi senza considerare l‚Äôordine. Ad esempio, scegliendo 2 elementi da 3 (A, B e C), le permutazioni sono 6 (AB, BA, AC, CA, BC, CB), mentre le combinazioni sono 3 (AB, AC, BC).\nPer calcolare le combinazioni, prima calcoliamo le permutazioni \\(D_{n,k}\\) e poi dividiamo per \\(k!\\). Questo perch√© ci sono \\(k!\\) modi per disporre \\(k\\) elementi in ordine diverso, ma tutte queste disposizioni contano come una singola combinazione. La formula generale per le combinazioni √®:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{D_{n,k}}{P_k} = \\frac{n!}{k!(n-k)!},\n\\] (eq_combsemp)\nche √® spesso indicata con il simbolo \\(\\binom{n}{k}\\) e viene chiamato ‚Äúcoefficiente binomiale‚Äù. In sintesi, le combinazioni semplici rappresentano il numero di sottoinsiemi di \\(k\\) elementi distinti scelti da un insieme di \\(n\\) elementi distinti senza considerare l‚Äôordine di estrazione.\nEsempio 9. Per l‚Äôinsieme \\(A = \\{a, b, c\\}\\) si trovino le combinazioni semplici di classe 2.\nLe combinazioni semplici dell‚Äôinsieme \\(A\\) sono \\(\\{a, b\\}\\), \\(\\{a, c\\}\\), \\(\\{b, c\\}\\), ovvero 3. Applichiamo l‚Äôeq. {eq}eq_combsemp:\n\\[\nC_{n,k} = \\binom{n}{k} = \\binom{3}{2} = 3.\n\\]\nUsiamo itertools:\n\nc_nk = tuple(it.combinations(\"ABC\", 2))\nc_nk\n\n(('A', 'B'), ('A', 'C'), ('B', 'C'))\n\n\n\nlen(c_nk)\n\n3\n\n\nLa soluzione si trova anche usando la funzione comb() della libreria math.\n\nmath.comb(3, 2)\n\n3\n\n\nOppure usando la funzione comb() della libreria scipy.special.\n\nimport scipy.special as sp\n\nsp.comb(3, 2)\n\n3.0\n\n\nEsempio 10. Quanti gruppi di 2 si possono formare con 5 individui?\n\nc_nk = tuple(it.combinations(range(5), 2))\nc_nk\n\n((0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (1, 2),\n (1, 3),\n (1, 4),\n (2, 3),\n (2, 4),\n (3, 4))\n\n\n\nlen(c_nk)\n\n10\n\n\novvero\n\nmath.comb(5, 2)\n\n10\n\n\nEsempio 11. Ho un‚Äôassociazione con 50 soci. Devo scegliere 5 membri che compongano il comitato direttivo. Quante possibili scelte?\n\nmath.comb(50, 5)\n\n2118760\n\n\nEsempio 12. Una gelateria offre 15 gusti di gelato differenti. Quante coppe diverse posso formare se ognuna contiene 3 gusti di gelato differenti tra loro?\n\nmath.comb(15, 3)\n\n455\n\n\nEsempio 13. Uno studente deve rispondere a 5 domande su 10. Solo 5 su 10. Quante possibili scelte ha?\n\nmath.comb(10, 5)\n\n252\n\n\nEsempio 14. Consideriamo un incidente del 2009 quando il Governatore della California Arnold Schwarzenegger invi√≤ un messaggio all‚Äôassemblea statale riguardo il veto al disegno di legge 1176. Questo messaggio formava un acrostico volgare con le prime lettere di ogni riga.\n\n\n\n\n\n\nFigura¬†J.1\n\n\n\nCi possiamo chiedere quale sia la probabilit√† che questo acrostico sia stato casuale. Per rispondere a questa domanda, calcoliamo le combinazioni di due diversi eventi.\nIl messaggio di Arnold Schwarzenegger √® composto da 85 parole. Supponiamo che il messaggio sia stato diviso in 7 righe in modo casuale. Per creare 7 righe, dobbiamo inserire 6 interruzioni di riga. Queste interruzioni di riga possono essere inserite in qualsiasi posizione tra le parole.\nPoich√© ci sono 85 parole, ci sono 84 spazi tra le parole (prima della seconda parola, terza parola, e cos√¨ via). Il numero di modi in cui possiamo inserire 6 interruzioni di riga in 84 spazi √® dato dalla combinazione:\n\\[\n\\binom{84}{6} = \\frac{84!}{6!(78!)} \\approx 406,481,544.\n\\]\nCalcoliamo ora il numero di modi in cui questo particolare acrostico pu√≤ essere ottenuto.\nSupponiamo che l‚Äôacrostico ‚ÄúFUCKYOU‚Äù possa essere formato solo in un numero limitato di combinazioni specifiche. Per calcolare queste combinazioni, dobbiamo considerare le parole che iniziano con ciascuna delle lettere dell‚Äôacrostico e le posizioni in cui possono essere inserite le interruzioni di riga.\n\nIdentificazione delle parole chiave:\n\nF: ‚ÄúFor‚Äù\nU: ‚Äúunnecessary‚Äù\nC: ‚Äúconversation‚Äù\nK: ‚Äúkeeping‚Äù\nY: ‚Äúyou‚Äù\nO: ‚Äúover‚Äù\nU: ‚Äúuntil‚Äù\n\nDeterminazione delle possibili interruzioni di riga: Per formare l‚Äôacrostico, dobbiamo posizionare le interruzioni di riga in modo che le parole chiave siano all‚Äôinizio delle righe. Le interruzioni possono essere inserite tra le parole chiave, con un certo numero di parole tra di esse.\nConteggio delle combinazioni:\n\nTra ‚ÄúFor‚Äù e ‚Äúunnecessary‚Äù: 11 possibilit√†\nTra ‚Äúunnecessary‚Äù e ‚Äúconversation‚Äù: 3 possibilit√†\nTra ‚Äúconversation‚Äù e ‚Äúkeeping‚Äù: 9 possibilit√†\nTra ‚Äúkeeping‚Äù e ‚Äúyou‚Äù: 2 possibilit√†\nTra ‚Äúyou‚Äù e ‚Äúover‚Äù: 2 possibilit√†\nTra ‚Äúover‚Äù e ‚Äúuntil‚Äù: 1 possibilit√†\n\nQuindi, il numero totale di combinazioni √®:\n\\[\n11 \\times 3 \\times 9 \\times 2 \\times 2 \\times 1 = 1,188.\n\\]\n\nIn conclusione, la probabilit√† che l‚Äôacrostico volgare si verifichi casualmente √® data dal rapporto tra il numero di combinazioni specifiche che formano l‚Äôacrostico (1,188) e il numero totale di modi per inserire 6 interruzioni di riga in 84 spazi (406,481,544):\n\\[\n\\frac{1,188}{406,481,544} \\approx 2.92 \\times 10^{-6} \\approx 1 \\text{ su } 342,000.\n\\]\nQuesta analisi ci mostra che √® estremamente improbabile che l‚Äôacrostico volgare sia stato il risultato di una divisione casuale delle righe del messaggio. In altre parole, la probabilit√† che questo acrostico sia stato generato casualmente √® trascurabile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice K ‚Äî Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "K.1 Introduzione ai logaritmi\nIl logaritmo √® una funzione matematica che risponde alla domanda: ‚Äúquante volte devo moltiplicare un certo numero (chiamato‚Äùbase‚Äù) per ottenere un altro numero?‚Äù Matematicamente, questo √® espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perch√© \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano pi√π grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo √® utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio: - \\(\\log(1) = 0\\) - \\(\\log(0.1) = -1\\) - \\(\\log(0.01) = -2\\) - \\(\\log(0.001) = -3\\)\nCome si pu√≤ vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle propriet√† pi√π utili dei logaritmi √® che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta propriet√† √® estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilit√† potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn‚Äôaltra propriet√† utile dei logaritmi √® che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa propriet√† √® molto utilizzata in matematica, specialmente in situazioni in cui √® necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare pi√π agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli pi√π gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#watermark",
    "href": "chapters/appendix/a15_calculus.html#watermark",
    "title": "Appendice K ‚Äî Per liberarvi dai terrori preliminari",
    "section": "K.2 Watermark",
    "text": "K.2 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Feb 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\nnumpy     : 1.26.4\narviz     : 0.17.0\nscipy     : 1.12.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a20_kde_plot.html",
    "href": "chapters/appendix/a20_kde_plot.html",
    "title": "Appendice L ‚Äî Kernel Density Estimation",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport scipy.stats as st\nfrom scipy.constants import golden\nimport arviz as az\n\n\n%config InlineBackend.figure_format = 'retina'\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\naz.style.use(\"arviz-darkgrid\")\nsns.set_theme(palette=\"colorblind\")\n\nConsideriamo in maggiore dettaglio la procedura di costruzione di un Kernel Density plot.\nUn istogramma divide i dati in intervalli discreti, conta il numero di punti che rientrano in ciascun intervallo e visualizza i risultati in un modo intuitivo. Nell‚Äôistruzione seguente, se specifichiamo il parametro density=True, l‚Äôarea totale delle barre dell‚Äôistogramma diventa uguale a 1.\nPer fare un esempio, definisco una funzione che simula dei dati estratti da una distribuzione bimodale.\n\ndef make_data(N, f=0.3, rseed=1):\n    rand = np.random.RandomState(rseed)\n    x = rand.randn(N)\n    x[int(f * N) :] += 5\n    return x\n\n\nx = make_data(1000)\nhist = plt.hist(x, bins=30, density=True)\n\n\n\n\n\n\n\n\nGenero ora un numero pi√π piccolo di dati.\n\nx = make_data(20, f=0.3, rseed=10)\nx\n\narray([ 1.3315865 ,  0.71527897, -1.54540029, -0.00838385,  0.62133597,\n       -0.72008556,  5.26551159,  5.10854853,  5.00429143,  4.82539979,\n        5.43302619,  6.20303737,  4.03493433,  6.02827408,  5.22863013,\n        5.44513761,  3.86339779,  5.13513688,  6.484537  ,  3.92019511])\n\n\nIl primo dei due istrogrammi seguenti chiarisce che si tratta di una distribuzione bimodale. Quello successivo, invece, mostra una distribuzione unimodale con una lunga coda. Senza vedere il codice, probabilmente non ci verrebbe in mente che questi due istogrammi sono stati costruiti dagli stessi dati. Il problema degli istogrammi, infatti, √® che, a seconda della scelta dell‚Äôampiezza degli intervalli, il profilo dell‚Äôistogramma pu√≤ cambiare anche in maniera drastica. La domanda √®: come possiamo ottenere un risultato migliore?\n\nhist = plt.hist(x, bins=12, density=True)\nplt.plot(x, np.full_like(x, -0.01), \"|k\", markeredgewidth=1);\n\n\n\n\n\n\n\n\n\nhist = plt.hist(x, bins=4, density=True)\nplt.plot(x, np.full_like(x, -0.01), \"|k\", markeredgewidth=1);\n\n\n\n\n\n\n\n\nL‚Äôistogramma conta quante osservazioni sono contenute in ciascun intervallo. Il Kernel Density Plot (KDE) fa una cosa simile, ma sostituisce alle frequenze assolute (o relative) un metodo diverso. Immaginiamo di posizionare la curva densit√† di una distribuzione gaussiana (con un‚Äôopportuna deviazione standard) in corrispondenza di ciascun punto della distribuzione. I punti sono rappresentati, nelle figure precedenti dai ‚Äúticks‚Äù evidenziati sotto l‚Äôistogramma. Per ciascun valore dell‚Äôasse \\(X\\), le ordinate di queste funzioni di densit√† vengono sommate. I punti cos√¨ ottenuti sono congiunti da una curva. Il processo √® descritto nella cella seguente.\n\nx_d = np.linspace(-4, 8, 1000)\ndensity = sum(st.norm(xi).pdf(x_d) for xi in x)\ndensity[0:10]\n\narray([0.02160887, 0.02227584, 0.02296033, 0.02366267, 0.02438324,\n       0.02512238, 0.02588048, 0.02665789, 0.02745499, 0.02827215])\n\n\nIl risultato √® il cosiddetto KDE plot, ovvero un istogramma ‚Äúlisciato‚Äù.\n\nplt.fill_between(x_d, density, alpha=0.5)\nplt.plot(x, np.full_like(x, -0.1), \"|k\", markeredgewidth=1)\n\nplt.axis([-4, 8, -0.2, 5]);\n\n\n\n\n\n\n\n\nUn risultato equivalente si ottiene con la funzione kdeplot() di seaborn. Si noti l‚Äôargomento bw_adjust che determina la deviazione standard delle gaussiane che vengono sommate.\n\n_ = sns.kdeplot(x, bw_adjust=0.6);\n\n\n\n\n\n\n\n\nIn generale, questo tipo di rappresentazione di una distribuzione empirica di frequenza √® pi√π informativa di un istogramma.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>¬† <span class='chapter-title'>Kernel Density Estimation</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a30_prob_tutorial.html",
    "href": "chapters/appendix/a30_prob_tutorial.html",
    "title": "Appendice M ‚Äî Esercizi di probabilit√† discreta",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport math\nimport seaborn as sns\nfrom collections import defaultdict\nimport arviz as az\n\n\n%config InlineBackend.figure_format = 'retina'\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\naz.style.use(\"arviz-viridish\")\n\nConsidereremo qui alcuni esempi che illustrano come, generando delle liste che corrispondono a spazi campione ed eventi, sia possibile calcolare la probabilit√† associata agli eventi definiti sullo spazio campione di un esperimento casuale. In questo capitolo ci focalizzeremo su tre esperimenti casuali che producono uno spazio campione discreto: lancio di monete, lancio di dadi, estrazione di carte da un mazzo ben mescolato. Inizieremo ad esaminare il caso del lancio di uno o pi√π dadi e i giochi di carte. In seguito esamineremo delle funzioni specializzate che possono essere usate per modellare l‚Äôesperimento casuale corrispondene ad una serie di lanci di una moneta. Prima di fare questo, per√≤, esamineremo alcune funzioni Python utili per il calcolo delle probabilit√†.\nProbabilit√† di ottenere un numero minore di 4 dal lancio di un dado\nAbbiamo gi√† visto in precedenza come generare lo spazio campione dell‚Äôesperimento aleatorio che corrisponde al lancio di un dado equilibrato a 6 facce.\n\nsample = [dice1 for dice1 in range(1, 7)]\nlist(sample)\n\n[1, 2, 3, 4, 5, 6]\n\n\nSu tale spazio campione definiamo un evento.\n\nevent = [roll for roll in sample if roll &lt; 4]\nprint(list(event))\n\n[1, 2, 3]\n\n\nCalcoliamo la probabilit√† di osservare l‚Äôevento che abbiamo definito.\n\nprint(f\"La probabilit√† dell'evento √® {len(event)}/{len(sample)}.\")\n\nLa probabilit√† dell'evento √® 3/6.\n\n\nLa probabilit√† di ottenere almeno un 6 dal lancio di due dadi\nConsideriamo un caso un po‚Äô pi√π complesso, ma che abbiamo gi√† incontrato in precedenza. Iniziamo nuovamente a definire lo spazio campione dell‚Äôesperimento casuale. Si noti la sintassi della list comprehension.\n\nsample = [(dice1, dice2) for dice1 in range(1, 7) for dice2 in range(1, 7)]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\nL‚Äôevento definito dal problema si verifica se √® vera la condizione roll[0] == 6 (si ottiene un 6 con il primo dado) oppure se si verifica la condizione roll[1] (si ottiene un 6 con il secondo dado), oppure se si verificano entrambe. Si noti il connettivo logico or.\n\nevent = [roll for roll in sample if roll[0] == 6 or roll[1] == 6]\nevent\n\n[(1, 6),\n (2, 6),\n (3, 6),\n (4, 6),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n11 / 36\n\n\nLa probabilit√† di non ottenere neppure un 6 dal lancio di due dadi\nLa soluzione di questo problema richiede che si neghino le due condizioni definite in precedenza.\n\nevent = [roll for roll in sample if roll[0] != 6 and roll[1] != 6]\nevent\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5)]\n\n\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n25 / 36\n\n\nIn maniera equivalente, la soluzione √® data dalla probabilit√† dell‚Äôevento complementare a quello definito dal problema precedente: 1 - 11/36.\nLa probabilit√† che lanciando contemporaneamente due dadi a 6 facce la somma faccia 4\nIn questo caso la condizione logica che viene definita nella list comprehension √® if sum(roll) == 4.\n\nevent = [roll for roll in sample if sum(roll) == 4]\nevent\n\n[(1, 3), (2, 2), (3, 1)]\n\n\nTroviamo la probabilit√†.\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n3 / 36\n\n\nLa probabilit√† che lanciando contemporaneamente tre dadi a 6 facce la somma faccia 10\nQuesto problema √® solo una variante del problema precedente. L‚Äôunica differenza di rilievo √® che dobbiamo costruire uno spazio campione corrispondente al prodotto cartesiano dell‚Äôinsieme dei punti di un dado elevato alla terza potenza.\n\nr = range(1, 7)\nsample = [(i, j, k) for i in r for j in r for k in r]\nevent = [roll for roll in sample if sum(roll) == 10]\nprint(event)\nprint(f\"{len(event)} / {len(sample)}\")\n\n[(1, 3, 6), (1, 4, 5), (1, 5, 4), (1, 6, 3), (2, 2, 6), (2, 3, 5), (2, 4, 4), (2, 5, 3), (2, 6, 2), (3, 1, 6), (3, 2, 5), (3, 3, 4), (3, 4, 3), (3, 5, 2), (3, 6, 1), (4, 1, 5), (4, 2, 4), (4, 3, 3), (4, 4, 2), (4, 5, 1), (5, 1, 4), (5, 2, 3), (5, 3, 2), (5, 4, 1), (6, 1, 3), (6, 2, 2), (6, 3, 1)]\n27 / 216\n\n\nLa probabilit√† che lanciando contemporaneamente quattro dadi a 6 facce la somma faccia 13\nLa struttura logica √® identica alla precedente, aumenta solo la dimensione dello spazio campione.\n\nr = range(1, 7)\nsample = [(i, j, k, l) for i in r for j in r for k in r for l in r]\nevent = [roll for roll in sample if sum(roll) == 13]\nprint(f\"{len(event)} / {len(sample)}\")\n\n140 / 1296\n\n\nLa probabilit√† di ottenere un 6 e un altro numero (diverso da 6) nel lancio di due dadi a 6 facce\nQuesto problema introduce un nuovo modo per valutare una condizione logica in riferimento allo spazio campione. Il problema dice che dobbiamo ottenere solo un 6, con il primo o con il secondo dado, ma non con entrambi. Dobbiamo dunque esaminare ciascun punto dello spazio campione (una tupla di due elementi) e verificare se contiene un solo 6. Per fare questo definiamo la funzione numsix() che prende come argomento una tupla e ritorna il numero di 6 che ha trovato. Avendo definito questa funzione, la applichiamo a tutti i punti dello spazio campione e estraiamo gli elementi nei quali la funzione ritorna 1 (ovvero, i punti campione nei quali c‚Äô√® un solo 6).\n\nsample = [(i, j) for i in r for j in r]\n\n\ndef numsix(roll):\n    return len([dice for dice in roll if dice == 6])\n\n\nevent = [roll for roll in sample if numsix(roll) == 1]\nprint(event)\n\n[(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n\n\nLa probabilit√† cercata √® dunque 10/36.\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n10 / 36\n\n\nLa probabilit√† di ottenere un 6 e un altro numero (diverso da 6) nel lancio di quattro dadi a 6 facce\nQuesto problema √® simile al precedente, ma considera uno spazio campione pi√π grande.\n\nsample = [(i, j, k, l) for i in r for j in r for k in r for l in r]\n\nevent = [roll for roll in sample if numsix(roll) == 1]\nprint(f\"{len(event)} / {len(sample)}\")\n\n500 / 1296\n\n\nLa probabilit√† di ottenere tre 6 e un altro numero (diverso da 6) nel lancio di quattro dadi a 6 facce\nQui cambia solo la quantificazione della condizione logica usata prima.\n\nevent = [roll for roll in sample if numsix(roll)==3]\nprint(f\"{len(event)} / {len(sample)}\")\n\n20 / 1296\n\n\nEsaminiamo ora alcuni esempio relativi ai giochi di carte. Per questi scopi abbiamo bisogno di generare degli spazi campione che corrispondono a selezioni di elementi nelle quali l‚Äôordine non conta e gli elementi non possono essere ripetuti. Questa √® la definizione di una combinazione semplice ‚Äì si veda la sezione {ref}combinazione-semplice-section. Importiamo la funzione combinations da itertools.\n\nfrom itertools import combinations, product\n\nPer chiarire la procedura, iniziamo a considerare un mazzo di carte molto piccolo, in cui abbiamo solo due semi e tre numeri. Generiamo il mazzo di carte.\n\ncards = list(product(range(1,3), range(1,4)))\ncards\n\n[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3)]\n\n\nDiciamo che il primo valore di ciascuna delle precedenti coppie di numeri corrisponde al seme e il secondo valore corrisponde al numero. Se vogliamo, possiamo immaginare cuori e picche con i numeri 1, 2, 3.\nIniziamo a chiederci quante mani di due carte siano possibili per questo mazzo di carte. Ci sono 15 possibilit√†. Usiamo la formula delle combinazioni semplici.\n\nmath.comb(6, 2)\n\n15\n\n\nElenchiamo tutte le possibili combinazioni semplici.\n\nsample = list(combinations(cards, 2))\nsample\n\n[((1, 1), (1, 2)),\n ((1, 1), (1, 3)),\n ((1, 1), (2, 1)),\n ((1, 1), (2, 2)),\n ((1, 1), (2, 3)),\n ((1, 2), (1, 3)),\n ((1, 2), (2, 1)),\n ((1, 2), (2, 2)),\n ((1, 2), (2, 3)),\n ((1, 3), (2, 1)),\n ((1, 3), (2, 2)),\n ((1, 3), (2, 3)),\n ((2, 1), (2, 2)),\n ((2, 1), (2, 3)),\n ((2, 2), (2, 3))]\n\n\n\nlen(sample)\n\n15\n\n\nChiediamoci ora quale sia la probabilit√† di una coppia di assi. Ovviamente nello spazio campione precedente c‚Äô√® solo un modo di ottenere una coppia di assi: ((1, 1), (2, 1)). Ma poniamoci il problema di trovare questa soluzione in maniera algoritmica.\n\ndef numval(hand, val):\n    return len([card for card in hand if card[1] == val])\n\n\ndef numace(hand):\n    return numval(hand, 1)\n\n\nevent = [hand for hand in sample if numace(hand) == 2]\nprint(f\"{len(event)} / {len(sample)}\")\n\n1 / 15\n\n\nLa probabilit√† di un pocker d‚Äôassi\nOra che abbiamo capito come fare, possiamo usare la procedura descritta sopra per calcolare un evento pi√π interessante, ovvero la probabilit√† di ottenere un pocker d‚Äôassi in un regolare mazzo da pocker di 52 carte. Iniziamo trovando il numero di possibili di mani di 5 carte:\n\ncards = list(product(range(1,5), range(1,14)))\nsample = list(combinations(cards, 5))\nlen(sample)\n\n2598960\n\n\nTroviamo ora la probabilit√† di un pocker d‚Äôassi.\n\nevent = [hand for hand in sample if numace(hand) == 4]\nprint(f\"{len(event)} / {len(sample)}\")\n\n48 / 2598960\n\n\nLa probabilit√† di una coppia d‚Äôassi e una coppia di Jack\nIn una variante di questo problema, troviamo la probabilit√† di una coppia d‚Äôassi e una coppia di Jack:\n\ndef numjack(hand):\n    return numval(hand, 11)\n\n\nevent = [hand for hand in sample if numace(hand) == 2 and numjack(hand) == 2]\nprint(f\"{len(event)} / {len(sample)}\")\n\n1584 / 2598960\n\n\nConcludiamo con alcuni esempi discussi nel secondo capitolo del testo di {cite:t}unpingco2022python.\nConsideriamo nuovamente l‚Äôesperimento casuale corrispondente al lancio di due dati equilibrati. Sia \\(X\\) la v.c. corrispondente alla somma dei punti prodotti dai due lanci. Poniamoci il problema di trovare la distribuzione di massa di probabilit√† di \\(X\\) e la probabilit√† associata a diversi eventi. Vedremo qui una procedura alternativa per risolvere questo problema rispetto quella discussa in precedenza.\nPer affrontare questo problema, {cite:t}unpingco2022python inizia a costruire un dizionario Python i cui elementi sono i punti del prodotto cartesiano i cui elementi sono della forma (a,b), dove \\(a\\) appartiene ad \\(A\\) = {1, 2, 3, 4, 5, 6} (punti del primo dado) e \\(b\\) appartiene a \\(B\\) = {1, 2, 3, 4, 5, 6} (punti del secondo dado).\n\nd = {(i, j): i + j for i in range(1, 7) for j in range(1, 7)}\nd\n\n{(1, 1): 2,\n (1, 2): 3,\n (1, 3): 4,\n (1, 4): 5,\n (1, 5): 6,\n (1, 6): 7,\n (2, 1): 3,\n (2, 2): 4,\n (2, 3): 5,\n (2, 4): 6,\n (2, 5): 7,\n (2, 6): 8,\n (3, 1): 4,\n (3, 2): 5,\n (3, 3): 6,\n (3, 4): 7,\n (3, 5): 8,\n (3, 6): 9,\n (4, 1): 5,\n (4, 2): 6,\n (4, 3): 7,\n (4, 4): 8,\n (4, 5): 9,\n (4, 6): 10,\n (5, 1): 6,\n (5, 2): 7,\n (5, 3): 8,\n (5, 4): 9,\n (5, 5): 10,\n (5, 6): 11,\n (6, 1): 7,\n (6, 2): 8,\n (6, 3): 9,\n (6, 4): 10,\n (6, 5): 11,\n (6, 6): 12}\n\n\nIl passo successivo √® quello di raccogliere tutte le coppie (a,b) la cui somma corrisponde a ciascuno dei possibili valori da 2 a 12. Per fare questo, {cite:t}unpingco2022python utilizza la funzione defaultdict():\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\ndinv\n\ndefaultdict(list,\n            {2: [(1, 1)],\n             3: [(1, 2), (2, 1)],\n             4: [(1, 3), (2, 2), (3, 1)],\n             5: [(1, 4), (2, 3), (3, 2), (4, 1)],\n             6: [(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)],\n             7: [(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)],\n             8: [(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)],\n             9: [(3, 6), (4, 5), (5, 4), (6, 3)],\n             10: [(4, 6), (5, 5), (6, 4)],\n             11: [(5, 6), (6, 5)],\n             12: [(6, 6)]})\n\n\nA questo punto √® possibile ottenere una lista di tutte le coppie la cui somma √® 7, per esempio:\n\ndinv[7]\n\n[(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)]\n\n\nIl passo successivo consiste nel calcolare la probabilit√† misurata per ciascun elemento di dinv. Utilizzando l‚Äôipotesi di indipendenza, ci√≤ significa che dobbiamo calcolare la somma dei prodotti delle probabilit√† dei singoli elementi in dinv. Poich√© sappiamo che ogni risultato √® ugualmente probabile, la probabilit√† di ogni termine nella somma √® uguale a 1/36. Pertanto, tutto ci√≤ che dobbiamo fare √® contare il numero di elementi nell‚Äôelenco corrispondente per ogni key in dinv e dividere per 36. Ad esempio, dinv[11] contiene [(5, 6), (6, 5)]. La probabilit√† di 5+6=6+5=11 √® la probabilit√† di questo insieme, che √® composto dalla somma delle probabilit√† dei singoli elementi {(5,6),(6,5)}. In questo caso, abbiamo P(11) = P({(5, 6)}) + P({(6, 5)}) = 1/36 + 1/36 = 2/36. Ripetendo questa procedura per tutti gli elementi, deriviamo la funzione di massa di probabilit√† come mostrato di seguito:\n\nX = {i: len(j) / 36.0 for i, j in dinv.items()}\nX\n\n{2: 0.027777777777777776,\n 3: 0.05555555555555555,\n 4: 0.08333333333333333,\n 5: 0.1111111111111111,\n 6: 0.1388888888888889,\n 7: 0.16666666666666666,\n 8: 0.1388888888888889,\n 9: 0.1111111111111111,\n 10: 0.08333333333333333,\n 11: 0.05555555555555555,\n 12: 0.027777777777777776}\n\n\n{cite:t}unpingco2022python afferma che questo esempio mostra quali sono gli elementi della teoria della probabilit√† che sono in gioco in questo semplice problema, sopprimendo deliberatamente alcuni dei dettagli tecnici pi√π fastidiosi.\nEsaminiamo con pi√π attenzione la funzione defaultdict(). Si noti che, nell‚Äôesempio sopra, essa prende come argomento list. Consideriamo con il seguente problema. Vogliamo contare quante volte ciascuna parola compare in un testo. Un primo modo per affrontare il problema √® il seguente: creiamo un dizionario a cui aggiungiamo come key ciascuna parola (se non √® gi√† presente nel dizionario) e, come valore, il numero di occorrenze:\n\ntext = \"Suppose I need to count the number of word occurrences in a text. How could I do that? Python provides us with multiple ways to do this same thing.\"\nword_count_dict = {}\nfor w in text.split(\" \"):\n    if w in word_count_dict:\n        word_count_dict[w]+=1\n    else:\n        word_count_dict[w]=1\n\nword_count_dict\n\n{'Suppose': 1,\n 'I': 2,\n 'need': 1,\n 'to': 2,\n 'count': 1,\n 'the': 1,\n 'number': 1,\n 'of': 1,\n 'word': 1,\n 'occurrences': 1,\n 'in': 1,\n 'a': 1,\n 'text.': 1,\n 'How': 1,\n 'could': 1,\n 'do': 2,\n 'that?': 1,\n 'Python': 1,\n 'provides': 1,\n 'us': 1,\n 'with': 1,\n 'multiple': 1,\n 'ways': 1,\n 'this': 1,\n 'same': 1,\n 'thing.': 1}\n\n\nLo stesso risultato si ottiene con defaultdict(). In questo caso\n\nword_count_dict = defaultdict(int)\nfor w in text.split(\" \"):\n    word_count_dict[w] += 1\n\nword_count_dict\n\ndefaultdict(int,\n            {'Suppose': 1,\n             'I': 2,\n             'need': 1,\n             'to': 2,\n             'count': 1,\n             'the': 1,\n             'number': 1,\n             'of': 1,\n             'word': 1,\n             'occurrences': 1,\n             'in': 1,\n             'a': 1,\n             'text.': 1,\n             'How': 1,\n             'could': 1,\n             'do': 2,\n             'that?': 1,\n             'Python': 1,\n             'provides': 1,\n             'us': 1,\n             'with': 1,\n             'multiple': 1,\n             'ways': 1,\n             'this': 1,\n             'same': 1,\n             'thing.': 1})\n\n\nCi√≤ rende chiaro che, in questo caso, defaultdict() viene usato per creare un dizionario dove associamo a ciascuna key la frequenza con la quale essa √® presente nell‚Äôoggetto text. In questo secondo esempio, defaultdict() prende come argomento int perch√© ritorner√† un integer.\nNel caso del lancio dei due dadi, invece, l‚Äôargomento di defaultdict() √® list, perch√© a ciascuna key verr√† associata una lista. d.items() sono i dict_items.\n\nd.items()\n\ndict_items([((1, 1), 2), ((1, 2), 3), ((1, 3), 4), ((1, 4), 5), ((1, 5), 6), ((1, 6), 7), ((2, 1), 3), ((2, 2), 4), ((2, 3), 5), ((2, 4), 6), ((2, 5), 7), ((2, 6), 8), ((3, 1), 4), ((3, 2), 5), ((3, 3), 6), ((3, 4), 7), ((3, 5), 8), ((3, 6), 9), ((4, 1), 5), ((4, 2), 6), ((4, 3), 7), ((4, 4), 8), ((4, 5), 9), ((4, 6), 10), ((5, 1), 6), ((5, 2), 7), ((5, 3), 8), ((5, 4), 9), ((5, 5), 10), ((5, 6), 11), ((6, 1), 7), ((6, 2), 8), ((6, 3), 9), ((6, 4), 10), ((6, 5), 11), ((6, 6), 12)])\n\n\nIl ciclo for i, j in d.items(): fa riferimento a ciascuno degli elementi del dizionario d.\n\nfor i, j in d.items():\n    print(i,j)\n\n(1, 1) 2\n(1, 2) 3\n(1, 3) 4\n(1, 4) 5\n(1, 5) 6\n(1, 6) 7\n(2, 1) 3\n(2, 2) 4\n(2, 3) 5\n(2, 4) 6\n(2, 5) 7\n(2, 6) 8\n(3, 1) 4\n(3, 2) 5\n(3, 3) 6\n(3, 4) 7\n(3, 5) 8\n(3, 6) 9\n(4, 1) 5\n(4, 2) 6\n(4, 3) 7\n(4, 4) 8\n(4, 5) 9\n(4, 6) 10\n(5, 1) 6\n(5, 2) 7\n(5, 3) 8\n(5, 4) 9\n(5, 5) 10\n(5, 6) 11\n(6, 1) 7\n(6, 2) 8\n(6, 3) 9\n(6, 4) 10\n(6, 5) 11\n(6, 6) 12\n\n\nL‚Äôindice i indica le coppie\n\nfor i, j in d.items():\n    print(i)\n\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n(2, 1)\n(2, 2)\n(2, 3)\n(2, 4)\n(2, 5)\n(2, 6)\n(3, 1)\n(3, 2)\n(3, 3)\n(3, 4)\n(3, 5)\n(3, 6)\n(4, 1)\n(4, 2)\n(4, 3)\n(4, 4)\n(4, 5)\n(4, 6)\n(5, 1)\n(5, 2)\n(5, 3)\n(5, 4)\n(5, 5)\n(5, 6)\n(6, 1)\n(6, 2)\n(6, 3)\n(6, 4)\n(6, 5)\n(6, 6)\n\n\nMentre j fa riferimento alla somma\n\nfor i, j in d.items():\n    print(j)\n\n2\n3\n4\n5\n6\n7\n3\n4\n5\n6\n7\n8\n4\n5\n6\n7\n8\n9\n5\n6\n7\n8\n9\n10\n6\n7\n8\n9\n10\n11\n7\n8\n9\n10\n11\n12\n\n\nOra possiamo usare defaultdict(list). Per ciascun valore della somma (j), appendiamo alla lista ad esso associata gli elementi (i) che producono tale somma:\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\nAvendo ottenuto il risultato riportato sopra, {cite:t}unpingco2022python si pone un altra domanda: qual √® la probabilit√† che la met√† del prodotto dei punti prodotti da tre dadi superi la loro somma? Possiamo risolverlo usando lo stesso metodo del seguente. Innanzitutto, si crea lo spazio campione dell‚Äôesperimento casuale, ovvero un dizionario a cui, per ciascun punto dello spazio campione si aggiunge una variabile booleana che √® True se la condizione specificata √® soddisfatta ed √® False altrimenti.\n\nd = {\n    (i, j, k): ((i * j * k) / 2 &gt; i + j + k)\n    for i in range(1, 7)\n    for j in range(1, 7)\n    for k in range(1, 7)\n}\nd\n\n{(1, 1, 1): False,\n (1, 1, 2): False,\n (1, 1, 3): False,\n (1, 1, 4): False,\n (1, 1, 5): False,\n (1, 1, 6): False,\n (1, 2, 1): False,\n (1, 2, 2): False,\n (1, 2, 3): False,\n (1, 2, 4): False,\n (1, 2, 5): False,\n (1, 2, 6): False,\n (1, 3, 1): False,\n (1, 3, 2): False,\n (1, 3, 3): False,\n (1, 3, 4): False,\n (1, 3, 5): False,\n (1, 3, 6): False,\n (1, 4, 1): False,\n (1, 4, 2): False,\n (1, 4, 3): False,\n (1, 4, 4): False,\n (1, 4, 5): False,\n (1, 4, 6): True,\n (1, 5, 1): False,\n (1, 5, 2): False,\n (1, 5, 3): False,\n (1, 5, 4): False,\n (1, 5, 5): True,\n (1, 5, 6): True,\n (1, 6, 1): False,\n (1, 6, 2): False,\n (1, 6, 3): False,\n (1, 6, 4): True,\n (1, 6, 5): True,\n (1, 6, 6): True,\n (2, 1, 1): False,\n (2, 1, 2): False,\n (2, 1, 3): False,\n (2, 1, 4): False,\n (2, 1, 5): False,\n (2, 1, 6): False,\n (2, 2, 1): False,\n (2, 2, 2): False,\n (2, 2, 3): False,\n (2, 2, 4): False,\n (2, 2, 5): True,\n (2, 2, 6): True,\n (2, 3, 1): False,\n (2, 3, 2): False,\n (2, 3, 3): True,\n (2, 3, 4): True,\n (2, 3, 5): True,\n (2, 3, 6): True,\n (2, 4, 1): False,\n (2, 4, 2): False,\n (2, 4, 3): True,\n (2, 4, 4): True,\n (2, 4, 5): True,\n (2, 4, 6): True,\n (2, 5, 1): False,\n (2, 5, 2): True,\n (2, 5, 3): True,\n (2, 5, 4): True,\n (2, 5, 5): True,\n (2, 5, 6): True,\n (2, 6, 1): False,\n (2, 6, 2): True,\n (2, 6, 3): True,\n (2, 6, 4): True,\n (2, 6, 5): True,\n (2, 6, 6): True,\n (3, 1, 1): False,\n (3, 1, 2): False,\n (3, 1, 3): False,\n (3, 1, 4): False,\n (3, 1, 5): False,\n (3, 1, 6): False,\n (3, 2, 1): False,\n (3, 2, 2): False,\n (3, 2, 3): True,\n (3, 2, 4): True,\n (3, 2, 5): True,\n (3, 2, 6): True,\n (3, 3, 1): False,\n (3, 3, 2): True,\n (3, 3, 3): True,\n (3, 3, 4): True,\n (3, 3, 5): True,\n (3, 3, 6): True,\n (3, 4, 1): False,\n (3, 4, 2): True,\n (3, 4, 3): True,\n (3, 4, 4): True,\n (3, 4, 5): True,\n (3, 4, 6): True,\n (3, 5, 1): False,\n (3, 5, 2): True,\n (3, 5, 3): True,\n (3, 5, 4): True,\n (3, 5, 5): True,\n (3, 5, 6): True,\n (3, 6, 1): False,\n (3, 6, 2): True,\n (3, 6, 3): True,\n (3, 6, 4): True,\n (3, 6, 5): True,\n (3, 6, 6): True,\n (4, 1, 1): False,\n (4, 1, 2): False,\n (4, 1, 3): False,\n (4, 1, 4): False,\n (4, 1, 5): False,\n (4, 1, 6): True,\n (4, 2, 1): False,\n (4, 2, 2): False,\n (4, 2, 3): True,\n (4, 2, 4): True,\n (4, 2, 5): True,\n (4, 2, 6): True,\n (4, 3, 1): False,\n (4, 3, 2): True,\n (4, 3, 3): True,\n (4, 3, 4): True,\n (4, 3, 5): True,\n (4, 3, 6): True,\n (4, 4, 1): False,\n (4, 4, 2): True,\n (4, 4, 3): True,\n (4, 4, 4): True,\n (4, 4, 5): True,\n (4, 4, 6): True,\n (4, 5, 1): False,\n (4, 5, 2): True,\n (4, 5, 3): True,\n (4, 5, 4): True,\n (4, 5, 5): True,\n (4, 5, 6): True,\n (4, 6, 1): True,\n (4, 6, 2): True,\n (4, 6, 3): True,\n (4, 6, 4): True,\n (4, 6, 5): True,\n (4, 6, 6): True,\n (5, 1, 1): False,\n (5, 1, 2): False,\n (5, 1, 3): False,\n (5, 1, 4): False,\n (5, 1, 5): True,\n (5, 1, 6): True,\n (5, 2, 1): False,\n (5, 2, 2): True,\n (5, 2, 3): True,\n (5, 2, 4): True,\n (5, 2, 5): True,\n (5, 2, 6): True,\n (5, 3, 1): False,\n (5, 3, 2): True,\n (5, 3, 3): True,\n (5, 3, 4): True,\n (5, 3, 5): True,\n (5, 3, 6): True,\n (5, 4, 1): False,\n (5, 4, 2): True,\n (5, 4, 3): True,\n (5, 4, 4): True,\n (5, 4, 5): True,\n (5, 4, 6): True,\n (5, 5, 1): True,\n (5, 5, 2): True,\n (5, 5, 3): True,\n (5, 5, 4): True,\n (5, 5, 5): True,\n (5, 5, 6): True,\n (5, 6, 1): True,\n (5, 6, 2): True,\n (5, 6, 3): True,\n (5, 6, 4): True,\n (5, 6, 5): True,\n (5, 6, 6): True,\n (6, 1, 1): False,\n (6, 1, 2): False,\n (6, 1, 3): False,\n (6, 1, 4): True,\n (6, 1, 5): True,\n (6, 1, 6): True,\n (6, 2, 1): False,\n (6, 2, 2): True,\n (6, 2, 3): True,\n (6, 2, 4): True,\n (6, 2, 5): True,\n (6, 2, 6): True,\n (6, 3, 1): False,\n (6, 3, 2): True,\n (6, 3, 3): True,\n (6, 3, 4): True,\n (6, 3, 5): True,\n (6, 3, 6): True,\n (6, 4, 1): True,\n (6, 4, 2): True,\n (6, 4, 3): True,\n (6, 4, 4): True,\n (6, 4, 5): True,\n (6, 4, 6): True,\n (6, 5, 1): True,\n (6, 5, 2): True,\n (6, 5, 3): True,\n (6, 5, 4): True,\n (6, 5, 5): True,\n (6, 5, 6): True,\n (6, 6, 1): True,\n (6, 6, 2): True,\n (6, 6, 3): True,\n (6, 6, 4): True,\n (6, 6, 5): True,\n (6, 6, 6): True}\n\n\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\ndinv\n\ndefaultdict(list,\n            {False: [(1, 1, 1),\n              (1, 1, 2),\n              (1, 1, 3),\n              (1, 1, 4),\n              (1, 1, 5),\n              (1, 1, 6),\n              (1, 2, 1),\n              (1, 2, 2),\n              (1, 2, 3),\n              (1, 2, 4),\n              (1, 2, 5),\n              (1, 2, 6),\n              (1, 3, 1),\n              (1, 3, 2),\n              (1, 3, 3),\n              (1, 3, 4),\n              (1, 3, 5),\n              (1, 3, 6),\n              (1, 4, 1),\n              (1, 4, 2),\n              (1, 4, 3),\n              (1, 4, 4),\n              (1, 4, 5),\n              (1, 5, 1),\n              (1, 5, 2),\n              (1, 5, 3),\n              (1, 5, 4),\n              (1, 6, 1),\n              (1, 6, 2),\n              (1, 6, 3),\n              (2, 1, 1),\n              (2, 1, 2),\n              (2, 1, 3),\n              (2, 1, 4),\n              (2, 1, 5),\n              (2, 1, 6),\n              (2, 2, 1),\n              (2, 2, 2),\n              (2, 2, 3),\n              (2, 2, 4),\n              (2, 3, 1),\n              (2, 3, 2),\n              (2, 4, 1),\n              (2, 4, 2),\n              (2, 5, 1),\n              (2, 6, 1),\n              (3, 1, 1),\n              (3, 1, 2),\n              (3, 1, 3),\n              (3, 1, 4),\n              (3, 1, 5),\n              (3, 1, 6),\n              (3, 2, 1),\n              (3, 2, 2),\n              (3, 3, 1),\n              (3, 4, 1),\n              (3, 5, 1),\n              (3, 6, 1),\n              (4, 1, 1),\n              (4, 1, 2),\n              (4, 1, 3),\n              (4, 1, 4),\n              (4, 1, 5),\n              (4, 2, 1),\n              (4, 2, 2),\n              (4, 3, 1),\n              (4, 4, 1),\n              (4, 5, 1),\n              (5, 1, 1),\n              (5, 1, 2),\n              (5, 1, 3),\n              (5, 1, 4),\n              (5, 2, 1),\n              (5, 3, 1),\n              (5, 4, 1),\n              (6, 1, 1),\n              (6, 1, 2),\n              (6, 1, 3),\n              (6, 2, 1),\n              (6, 3, 1)],\n             True: [(1, 4, 6),\n              (1, 5, 5),\n              (1, 5, 6),\n              (1, 6, 4),\n              (1, 6, 5),\n              (1, 6, 6),\n              (2, 2, 5),\n              (2, 2, 6),\n              (2, 3, 3),\n              (2, 3, 4),\n              (2, 3, 5),\n              (2, 3, 6),\n              (2, 4, 3),\n              (2, 4, 4),\n              (2, 4, 5),\n              (2, 4, 6),\n              (2, 5, 2),\n              (2, 5, 3),\n              (2, 5, 4),\n              (2, 5, 5),\n              (2, 5, 6),\n              (2, 6, 2),\n              (2, 6, 3),\n              (2, 6, 4),\n              (2, 6, 5),\n              (2, 6, 6),\n              (3, 2, 3),\n              (3, 2, 4),\n              (3, 2, 5),\n              (3, 2, 6),\n              (3, 3, 2),\n              (3, 3, 3),\n              (3, 3, 4),\n              (3, 3, 5),\n              (3, 3, 6),\n              (3, 4, 2),\n              (3, 4, 3),\n              (3, 4, 4),\n              (3, 4, 5),\n              (3, 4, 6),\n              (3, 5, 2),\n              (3, 5, 3),\n              (3, 5, 4),\n              (3, 5, 5),\n              (3, 5, 6),\n              (3, 6, 2),\n              (3, 6, 3),\n              (3, 6, 4),\n              (3, 6, 5),\n              (3, 6, 6),\n              (4, 1, 6),\n              (4, 2, 3),\n              (4, 2, 4),\n              (4, 2, 5),\n              (4, 2, 6),\n              (4, 3, 2),\n              (4, 3, 3),\n              (4, 3, 4),\n              (4, 3, 5),\n              (4, 3, 6),\n              (4, 4, 2),\n              (4, 4, 3),\n              (4, 4, 4),\n              (4, 4, 5),\n              (4, 4, 6),\n              (4, 5, 2),\n              (4, 5, 3),\n              (4, 5, 4),\n              (4, 5, 5),\n              (4, 5, 6),\n              (4, 6, 1),\n              (4, 6, 2),\n              (4, 6, 3),\n              (4, 6, 4),\n              (4, 6, 5),\n              (4, 6, 6),\n              (5, 1, 5),\n              (5, 1, 6),\n              (5, 2, 2),\n              (5, 2, 3),\n              (5, 2, 4),\n              (5, 2, 5),\n              (5, 2, 6),\n              (5, 3, 2),\n              (5, 3, 3),\n              (5, 3, 4),\n              (5, 3, 5),\n              (5, 3, 6),\n              (5, 4, 2),\n              (5, 4, 3),\n              (5, 4, 4),\n              (5, 4, 5),\n              (5, 4, 6),\n              (5, 5, 1),\n              (5, 5, 2),\n              (5, 5, 3),\n              (5, 5, 4),\n              (5, 5, 5),\n              (5, 5, 6),\n              (5, 6, 1),\n              (5, 6, 2),\n              (5, 6, 3),\n              (5, 6, 4),\n              (5, 6, 5),\n              (5, 6, 6),\n              (6, 1, 4),\n              (6, 1, 5),\n              (6, 1, 6),\n              (6, 2, 2),\n              (6, 2, 3),\n              (6, 2, 4),\n              (6, 2, 5),\n              (6, 2, 6),\n              (6, 3, 2),\n              (6, 3, 3),\n              (6, 3, 4),\n              (6, 3, 5),\n              (6, 3, 6),\n              (6, 4, 1),\n              (6, 4, 2),\n              (6, 4, 3),\n              (6, 4, 4),\n              (6, 4, 5),\n              (6, 4, 6),\n              (6, 5, 1),\n              (6, 5, 2),\n              (6, 5, 3),\n              (6, 5, 4),\n              (6, 5, 5),\n              (6, 5, 6),\n              (6, 6, 1),\n              (6, 6, 2),\n              (6, 6, 3),\n              (6, 6, 4),\n              (6, 6, 5),\n              (6, 6, 6)]})\n\n\n\nX = {i: len(j) / 6.0**3 for i, j in dinv.items()}\nprint(X)\n\n{False: 0.37037037037037035, True: 0.6296296296296297}\n\n\n\nd = pd.DataFrame(\n    index=[(i, j) for i in range(1, 7) for j in range(1, 7)],\n    columns=[\"sm\", \"d1\", \"d2\", \"pd1\", \"pd2\", \"p\"],\n)\nd\n\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nd.d1 = [i[0] for i in d.index]\nd.d2 = [i[1] for i in d.index]\n\nd.head(), d.tail()\n\n(         sm  d1  d2  pd1  pd2    p\n (1, 1)  NaN   1   1  NaN  NaN  NaN\n (1, 2)  NaN   1   2  NaN  NaN  NaN\n (1, 3)  NaN   1   3  NaN  NaN  NaN\n (1, 4)  NaN   1   4  NaN  NaN  NaN\n (1, 5)  NaN   1   5  NaN  NaN  NaN,\n          sm  d1  d2  pd1  pd2    p\n (6, 2)  NaN   6   2  NaN  NaN  NaN\n (6, 3)  NaN   6   3  NaN  NaN  NaN\n (6, 4)  NaN   6   4  NaN  NaN  NaN\n (6, 5)  NaN   6   5  NaN  NaN  NaN\n (6, 6)  NaN   6   6  NaN  NaN  NaN)\n\n\n\nd[\"sm\"] = d[\"d1\"] + d[\"d2\"]\nd.head()\n\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\n2\n1\n1\nNaN\nNaN\nNaN\n\n\n(1, 2)\n3\n1\n2\nNaN\nNaN\nNaN\n\n\n(1, 3)\n4\n1\n3\nNaN\nNaN\nNaN\n\n\n(1, 4)\n5\n1\n4\nNaN\nNaN\nNaN\n\n\n(1, 5)\n6\n1\n5\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nd[\"pd1\"] = 1/6\nd[\"pd2\"] = 1/6\nd[\"p\"] = d[\"pd1\"] * d[\"pd2\"]\nd.head()\n\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\n2\n1\n1\n0.166667\n0.166667\n0.027778\n\n\n(1, 2)\n3\n1\n2\n0.166667\n0.166667\n0.027778\n\n\n(1, 3)\n4\n1\n3\n0.166667\n0.166667\n0.027778\n\n\n(1, 4)\n5\n1\n4\n0.166667\n0.166667\n0.027778\n\n\n(1, 5)\n6\n1\n5\n0.166667\n0.166667\n0.027778\n\n\n\n\n\n\n\n\n\nd[\"p\"].sum()\n\n1.0\n\n\n\nd.groupby('sm')['p'].sum()\n\nsm\n2     0.027778\n3     0.055556\n4     0.083333\n5     0.111111\n6     0.138889\n7     0.166667\n8     0.138889\n9     0.111111\n10    0.083333\n11    0.055556\n12    0.027778\nName: p, dtype: float64",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>¬† <span class='chapter-title'>Esercizi di probabilit√† discreta</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html",
    "href": "chapters/appendix/a40_rng.html",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "",
    "text": "N.1 Distribuzione uniforme\nConsideriamo la distribuzione uniforme: rng.uniform([low, high, size]). Genero un singolo valore:\nLo genero una seconda volta:\nrng.uniform(0, 1, size=1)\n\narray([0.77395605])\nGenero 20 valori:\nrng.uniform(0, 1, size=20)\n\narray([0.43887844, 0.85859792, 0.69736803, 0.09417735, 0.97562235,\n       0.7611397 , 0.78606431, 0.12811363, 0.45038594, 0.37079802,\n       0.92676499, 0.64386512, 0.82276161, 0.4434142 , 0.22723872,\n       0.55458479, 0.06381726, 0.82763117, 0.6316644 , 0.75808774])\nCreo un istogramma.\nn_samples = 1000000\n_ = plt.hist(rng.uniform(0, 1, size=n_samples), bins=50, density=True)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-normale",
    "href": "chapters/appendix/a40_rng.html#distribuzione-normale",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.2 Distribuzione normale",
    "text": "N.2 Distribuzione normale\nEstraiamo ora dei campioni casuali dalla distribuzione Gaussiana, rng.normal([loc, scale, size]). Per esempio, generiamo 10 valori dalla distribuzione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\):\n\nx = rng.normal(loc=100, scale=15, size=10)\nprint(x)\n\n[ 88.39130723 106.85972149 112.68284617  98.40757644  59.28402571\n  83.63194152 127.29102032  91.32585446 109.21359401 103.23261596]\n\n\nOra generiamo un grande numero (1000000) di valori casuali dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). Con questi valori creiamo un istogramma e a tale istogramma sovrapponiamo la funzione di densit√† \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). In questo modo possiamo accertarci che i numeri casuali che abbiamo ottenuto si riferiscano veramente alla densit√† desiderata. Per trovare la densit√† della distribuzione normale, uso norm.pdf da scipy.stats.\n\nn_samples = 1000000\nmu = 100\nsigma = 15\n# create x's\nxs = np.linspace(55, 145, n_samples)\ny_pdf = stats.norm.pdf(xs, mu, sigma)\n# create random samples\nsamps = rng.normal(loc=mu, scale=sigma, size=n_samples)\n# plot them\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=50, density=True)\nplt.title(\"Distribuzione Normale $\\mathcal{N}(\\mu=100, \\sigma=15)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(40, 160);\n\n\n\n\n\n\n\n\nLa stessa procedura pu√≤ essere usata per tutte le distribuzioni implementate da NumPy. Esaminiamo alcuni esempi qui sotto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-beta",
    "href": "chapters/appendix/a40_rng.html#distribuzione-beta",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.3 Distribuzione Beta",
    "text": "N.3 Distribuzione Beta\nPer estrarre dei campioni casuali dalla distribuzione Beta usiamo il generatore rng.beta(a, b[, size]); per la densit√† Beta usiamo stats.beta.pdf(x, a, b).\n\n# Definisci il numero di campioni\nn_samples = 1000000\na = 3\nb = 9\n\n# Crea un array di valori x\nxs = np.linspace(0, 1, n_samples)\n\n# Calcola la densit√† di probabilit√† (PDF) della distribuzione Beta\ny_pdf = stats.beta.pdf(xs, a, b)\n\n# Genera i campioni casuali\nsamps = rng.beta(a, b, size=n_samples)\n\n# Traccia il grafico\nplt.plot(xs, y_pdf, label=\"Densit√† Beta(3,9)\")\nplt.hist(samps, bins=50, density=True, label=\"Campioni\")\nplt.title(\"Confronto tra la Distribuzione Beta(3,9) e Campioni Casuali\")\nplt.ylabel(\"Densit√†\")\nplt.xlabel(\"Valore\")\n_ = plt.legend()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-binomiale",
    "href": "chapters/appendix/a40_rng.html#distribuzione-binomiale",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.4 Distribuzione binomiale",
    "text": "N.4 Distribuzione binomiale\nPer estrarre dei campioni casuali dalla distribuzione Binomiale usiamo rng.binomial(n, p[, size]); per la distribuzione di massa Binomiale usiamo stats.binom.pmf(r, n, p).\n\nn_samples = 1000000\n\nn = 10\np = 0.3\n# create r values\nr_values = list(range(n + 1))\n# pmf\ny_pmf = [stats.binom.pmf(r, n, p) for r in r_values]\n# create random samples\nr_samps = rng.binomial(n=n, p=p, size=n_samples)\nplt.plot(r_values, y_pmf, \"x\")\nplt.hist(r_samps, bins=np.arange(-0.5, 11.5, 1), density=True)\nplt.title(\"Distribuzione Binomiale($n$=10, $p$=0.3)\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\");",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-t-di-student",
    "href": "chapters/appendix/a40_rng.html#distribuzione-t-di-student",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.5 Distribuzione \\(t\\) di Student",
    "text": "N.5 Distribuzione \\(t\\) di Student\nPer estrarre dei campioni casuali dalla distribuzione \\(t\\) di Student uso il generatore rng con standard_t(df, size=None); per la densit√† \\(t\\) di Student uso t.pdf da scipy.stats.\n\nn_samples = 100000\ndf = 4\n# create x's\nxs = np.linspace(-4, 4, n_samples)\ny_pdf = stats.t.pdf(xs, df=df)\n# create random samples\nsamps = rng.standard_t(df=df, size=n_samples)\n# plot them\nfig, ax = plt.subplots()\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=400, density=True)\nplt.title(\"Distribuzione $t(\\\\nu=4)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(-4, 4);",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "href": "chapters/appendix/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.6 Distribuzione arbitraria di una variabile casuale distreta",
    "text": "N.6 Distribuzione arbitraria di una variabile casuale distreta\nCon la funzione random.choices √® possible specificare i valori di una variabile casuale discreta con una distribuzione di massa di probabilit√† arbitraria.\n\n# Define the set of values\nx_rv = [1, 2, 3, 4]\n# Define the weights for each value\nweights = [0.1, 0.1, 0.3, 0.5]\n\nx_sample = rng.choice(x_rv, size=100, p=weights)\nprint(f\"Random Sample: {x_sample}\")\n\nRandom Sample: [1 1 4 3 1 4 1 4 3 3 4 4 1 4 4 4 4 2 4 2 1 4 4 2 1 3 2 4 1 4 4 3 4 2 4 4 1\n 4 3 4 4 4 4 3 1 4 3 3 2 4 3 4 4 3 3 4 4 1 3 4 4 4 3 2 1 4 4 4 4 4 3 4 3 2\n 3 4 4 3 3 4 4 3 4 2 4 3 4 3 1 2 4 4 1 1 4 3 1 4 4 4]\n\n\nNell‚Äôesempio, i pesi weights indicano che, nella distribuzione, il valore 4 √® presente con una frequenza di cinque volte maggiore dei valori 1 e 2.\nSe aggiungiamo l‚Äôargomento k possiamo definire i pesi (indirettamente, le probabilit√†) dei diversi valori della variabile casuale che sono stati specificati. Nell‚Äôesempio, i pesi [1, 1, 3, 6] indicano che, nella distribuzione, il valore 4 √® presente con una frequenza di sei volte maggiore dei valori 1 e 2.\n\nn_samples = 100000\nx = rng.choice(x_rv, size=n_samples, p=weights)\nbins = plt.hist(x, density=True)\nplt.title(\"Distribuzione arbitraria di massa di probabilit√†\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xticks(x_rv);\n\n\n\n\n\n\n\n\n\nrng.binomial(10, .1, size=4)\n\narray([3, 0, 3, 1])",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#commenti-e-considerazioni-finali",
    "href": "chapters/appendix/a40_rng.html#commenti-e-considerazioni-finali",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.7 Commenti e Considerazioni Finali",
    "text": "N.7 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esaminato l‚Äôutilizzo della funzione rng = np.random.default_rng() per generare un campione di numeri pseudo-casuali da una distribuzione. Dopo aver inizializzato rng con rng = np.random.default_rng(RANDOM_SEED), possiamo generare campioni casuali da diverse distribuzioni di massa e di densit√† di probabilit√†:\n\nDistribuzione uniforme: rng.uniform(min, max, size)\nDistribuzione normale: rng.normal(loc, scale, size)\nDistribuzione t di Student: rng.standard_t(df, size)\nDistribuzione beta: rng.beta(alpha, beta, size)\nDistribuzione binomiale: rng.binomial(n, p, size)\n\nNei capitoli precedenti, nello specifico nei notebook {ref}discr_distr_notebook e {ref}cont-rv-distr-notebook, abbiamo invece approfondito l‚Äôutilizzo di varie funzioni della libreria scipy.stats per manipolare le distribuzioni di probabilit√†. In particolare, abbiamo illustrato come sia possibile utilizzare:\n\n.pdf per ottenere i valori della funzione di densit√† di probabilit√† o .pmf per ottenere i valori della distribuzione di massa di probabilit√†.\n.ppf per calcolare i quantili della distribuzione.\n.cdf per calcolare la probabilit√† associata a un valore specifico. Nel caso di una variabile casuale continua, questo corrisponde al valore della funzione di ripartizione, che rappresenta l‚Äôarea sotto la curva di densit√† nella coda sinistra. Nel caso di una variabile casuale discreta, corrisponde alla somma delle probabilit√† dalla distribuzione di massa di probabilit√† dal valore minimo fino al valore specificato (incluso).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html",
    "href": "chapters/appendix/a44_montecarlo.html",
    "title": "Appendice O ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "O.1 Stima dell‚Äôintegrale di un cerchio\nImmaginiamo un quadrato di lato 2 centrato sull‚Äôorigine. Genereremo punti casuali uniformemente distribuiti all‚Äôinterno di questo quadrato. Per ogni punto \\((x, y)\\), verificheremo se cade all‚Äôinterno del cerchio di raggio unitario inscritto nel quadrato, cio√® se la distanza dall‚Äôorigine √® minore di 1:\n\\[\n\\sqrt{x^2 + y^2} &lt; 1,\n\\]\nche si semplifica a:\n\\[\nx^2 + y^2 &lt; 1.\n\\]\nLa proporzione di tali punti rappresenta la proporzione dell‚Äôarea del quadrato occupata dal cerchio. Poich√© il quadrato ha un‚Äôarea di 4, l‚Äôarea del cerchio √® pari a 4 volte la proporzione dei punti che cadono all‚Äôinterno del cerchio.\nQuindi, se generiamo un numero sufficiente di punti casuali e contiamo quanti di essi cadono all‚Äôinterno del cerchio, possiamo stimare \\(\\pi\\) come:\n\\[\n\\pi \\approx 4 \\times \\frac{\\text{numero di punti dentro il cerchio}}{\\text{numero totale di punti}}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "href": "chapters/appendix/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "title": "Appendice O ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "O.1.1 Codice Stan\nEsaminiamo il corrispondente codice Stan.\ngenerated quantities {\n  real&lt;lower=-1, upper=1&gt; x = uniform_rng(-1, 1);\n  real&lt;lower=-1, upper=1&gt; y = uniform_rng(-1, 1);\n  int&lt;lower=0, upper=1&gt; inside = x^2 + y^2 &lt; 1;\n  real&lt;lower=0, upper=4&gt; pi = 4 * inside;\n}\n\nVariabili x e y:\n\nVengono generate casualmente e uniformemente nell‚Äôintervallo \\((-1, 1)\\). Questo significa che stiamo campionando punti all‚Äôinterno di un quadrato di lato 2 centrato sull‚Äôorigine.\n\nVariabile inside:\n\n√à un indicatore che verifica se il punto \\((x, y)\\) cade all‚Äôinterno del cerchio unitario. La condizione \\(x^2 + y^2 &lt; 1\\) √® vera se il punto \\((x, y)\\) √® all‚Äôinterno del cerchio di raggio 1 centrato sull‚Äôorigine, e falsa altrimenti.\nSe la condizione √® vera, inside √® impostato a 1, altrimenti a 0.\n\nVariabile pi:\n\npi viene calcolata come 4 volte il valore di inside.\n\n\nIl programma Stan genera punti casuali, verifica se cadono all‚Äôinterno del cerchio e usa la proporzione di punti che cadono all‚Äôinterno del cerchio per stimare \\(\\pi\\). Moltiplicando il valore indicatore per 4, otteniamo una stima di \\(\\pi\\) basata su ciascun punto generato. La stima finale di \\(\\pi\\) sar√† la media di queste stime su molti punti campionati.\n\n\nO.1.2 Media Campionaria dell‚ÄôIndicatore\nDopo aver generato un numero sufficiente di punti casuali e aver verificato quanti di essi cadono all‚Äôinterno del cerchio, calcoliamo la media campionaria dell‚Äôindicatore inside. Questo indicatore √® uguale a 1 se il punto √® dentro il cerchio e a 0 se √® fuori. La media di questi valori ci d√† la proporzione dei punti che cadono dentro il cerchio.\nQuesta proporzione √® una stima della probabilit√† che un punto casuale sia all‚Äôinterno del cerchio. Moltiplicando questa proporzione per 4, otteniamo una stima di \\(\\pi\\).\nMatematicamente, possiamo scrivere questo processo come segue:\n\\[\n\\mathbb{E}[4 \\cdot \\textrm{I}(\\sqrt{X^2 + Y^2} \\leq 1)] = \\int_{-1}^1 \\int_{-1}^1 4 \\cdot \\textrm{I}(x^2 + y^2 &lt; 1) \\, \\textrm{d}x \\, \\textrm{d}y = \\pi,\n\\]\ndove \\(\\textrm{I}()\\) √® l‚Äôindicatore che ritorna 1 se il suo argomento √® vero e 0 altrimenti.\nIn altre parole, stiamo calcolando l‚Äôaspettativa di 4 volte l‚Äôindicatore che un punto casuale \\((x, y)\\) cade dentro il cerchio unitario. Questo valore atteso √® uguale a \\(\\pi\\), il che ci permette di stimare \\(\\pi\\) usando i metodi Monte Carlo.\n\n\nO.1.3 Compilazione e Campionamento\nCompiliamo e poi campioniamo dal modello, prendendo un campione di dimensione \\(M = 10,000\\) estrazioni.\n\nM = 10_000\nmodel = CmdStanModel(stan_file=\"../../stan/monte-carlo-pi.stan\")\n\nsample = model.sample(\n    chains=1,\n    iter_warmup=1,\n    iter_sampling=M,\n    show_progress=False,\n    show_console=False,\n    seed=123,\n)\n\nx_draws = sample.stan_variable(\"x\")\ny_draws = sample.stan_variable(\"y\")\ninside_draws = sample.stan_variable(\"inside\")\npi_draws = sample.stan_variable(\"pi\")\n\ndf = pd.DataFrame({\"N\": 1000, \"x\": x_draws, \"y\": y_draws, \"inside\": inside_draws})\n\nplt.figure(figsize=(5, 5))\nplt.scatter(df[\"x\"], df[\"y\"], c=df[\"inside\"], cmap=\"coolwarm\", s=1)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Monte Carlo Simulation of Pi Estimation\")\nplt.gca().set_aspect(\"equal\", adjustable=\"box\")\nplt.show()\n\n\n\n\n\n\n\n\nSuccessivamente, calcoliamo la media campionaria dell‚Äôindicatore dentro-il-cerchio, che produce una stima della probabilit√† che un punto sia dentro il cerchio:\n\nPr_is_inside = np.mean(inside_draws)\npi_hat = np.mean(pi_draws)\nprint(f\"Pr[Y is inside circle] = {Pr_is_inside:.3f};\")\nprint(f\"estimate for pi = {pi_hat:.3f}\")\n\nPr[Y is inside circle] = 0.786;\nestimate for pi = 3.144\n\n\nIl valore esatto di \\(\\pi\\) fino a tre cifre decimali √® \\(3.142\\). Con il nostro metodo, ci avviciniamo a questo valore, ma non lo raggiungiamo esattamente, il che √® tipico dei metodi Monte Carlo. Aumentando il numero di estrazioni, l‚Äôerrore diminuisce. Teoricamente, con un numero sufficiente di estrazioni, possiamo ottenere qualsiasi precisione desiderata; tuttavia, in pratica, dobbiamo accontentarci di pochi decimali di accuratezza nelle nostre stime Monte Carlo. Questo di solito non √® un problema, poich√© l‚Äôincertezza statistica tende a dominare rispetto all‚Äôimprecisione numerica nella maggior parte delle applicazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a45_mcmc.html",
    "href": "chapters/appendix/a45_mcmc.html",
    "title": "Appendice P ‚Äî Catene di Markov",
    "section": "",
    "text": "P.1 Struttura e Dinamica delle Catene di Markov\nNelle catene di Markov, le variabili casuali si muovono all‚Äôinterno di uno ‚Äúspazio degli stati‚Äù, che pu√≤ essere discreto o continuo. In questo contesto, ci focalizziamo su spazi degli stati discreti e finiti, generalmente rappresentati come \\(\\{1, 2, \\ldots, M\\}\\).\nLa dinamica interna delle catene di Markov √® governata dalle ‚Äúprobabilit√† di transizione‚Äù tra gli stati, riassunte in una ‚Äúmatrice di transizione‚Äù. Ogni elemento $ (i, j) $ di questa matrice indica la probabilit√† di passare dallo stato $ i $ allo stato $ j $ in un singolo passo della catena.\nIn sintesi, le catene di Markov offrono un framework robusto e versatile per la modellazione di dipendenze tra variabili casuali, rivelandosi essenziali in molti settori della statistica e della scienza dei dati, inclusa la metodologia MCMC, che √® centrale in algoritmi come quello di Metropolis.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a45_mcmc.html#terminologia",
    "href": "chapters/appendix/a45_mcmc.html#terminologia",
    "title": "Appendice P ‚Äî Catene di Markov",
    "section": "P.2 Terminologia",
    "text": "P.2 Terminologia\nCatene di Markov omogenee\nUna catena di Markov √® detta ‚Äúomogenea‚Äù quando le probabilit√† di transizione tra gli stati sono indipendenti dal tempo. In termini pi√π semplici, la dinamica della catena √® regolata da una matrice di transizione fissa che rimane costante nel tempo. Ci√≤ significa che la probabilit√† di passare da uno stato all‚Äôaltro √® sempre la stessa, indipendentemente dal momento in cui avviene questa transizione.\nCatene di Markov irriducibili\nUna catena di Markov √® ‚Äúirriducibile‚Äù quando √® possibile raggiungere qualsiasi stato partendo da qualsiasi altro stato in un numero finito di passaggi. In altre parole, non esistono stati isolati che intrappolano la catena indefinitamente.\nStati ricorrenti\nIn una catena di Markov, uno stato √® considerato ‚Äúricorrente‚Äù se viene rivisitato ripetutamente. Gli stati possono ulteriormente essere classificati come ‚Äúpositivamente ricorrenti‚Äù se esiste un tempo limitato per tornare allo stato, e ‚Äúnullamente ricorrenti‚Äù in caso contrario. Gli stati ‚Äúricorrenti di Harris‚Äù sono quelli che vengono visitati infinite volte mentre il tempo tende all‚Äôinfinito.\nAperiodicit√†\nGli stati ‚Äúaperiodici‚Äù in una catena di Markov sono quelli senza cicli deterministici, il che significa che la catena non rimane bloccata in un ciclo fisso di stati.\nStazionariet√†\nNella teoria delle catene di Markov, la ‚Äúdistribuzione marginale‚Äù √® semplicemente la distribuzione delle probabilit√† degli stati della catena in un certo momento. In altre parole, √® una descrizione delle probabilit√† di trovarsi in ciascuno degli stati possibili in un determinato istante di tempo. Se stiamo parlando, ad esempio, di una catena di Markov con tre stati (A, B, C), una possibile distribuzione marginale potrebbe essere \\([0.4, 0.5, 0.1]\\), indicando che la probabilit√† di trovarsi nello stato A √® del 40%, nello stato B del 50% e nello stato C del 10%.\nUna catena di Markov √® definita come ‚Äústazionaria‚Äù quando questa distribuzione marginale rimane invariata nel tempo. In altre parole, le probabilit√† di essere in ogni stato possibile non cambiano, anche se la catena passa da uno stato all‚Äôaltro seguendo le probabilit√† di transizione.\nLa stazionariet√† √® un concetto cruciale perch√© rende possibile analizzare il comportamento a lungo termine della catena senza dover tener conto di tutti i dettagli delle transizioni individuali. In pratica, una volta che la catena √® stazionaria, sappiamo che la sua distribuzione marginale non cambier√† pi√π, e questo √® spesso ci√≤ che ci interessa nelle applicazioni reali.\nErgodicit√†\nL‚Äôergodicit√† √® un‚Äôaltra propriet√† fondamentale che descrive come una catena di Markov si comporta nel limite quando il numero di passaggi tende all‚Äôinfinito. Una catena ergodica √® una catena che √® sia aperiodica (non ha cicli fissi) sia irriducibile (ogni stato √® raggiungibile da ogni altro stato) e positivamente ricorrente secondo Harris (ogni stato viene visitato infinite volte in un tempo finito). Ci√≤ significa che mentre il numero di passaggi tende all‚Äôinfinito, la distribuzione marginale della catena rimane stabile. Pertanto, se campioniamo da una catena di Markov stazionaria a intervalli ampiamente distanziati, questi campioni possono essere considerati indipendenti.\nNella teoria ergodica, si discute spesso di ‚Äúburn-in‚Äù, che √® il periodo di tempo necessario perch√© la catena si avvicini alla distribuzione stazionaria, e di ‚Äúthinning‚Äù, che √® la pratica di prendere campioni a intervalli ampiamente distanziati per minimizzare la correlazione tra i campioni.\nConvergenza\nNel contesto della convergenza, le propriet√† di irriducibilit√† e aperiodicit√† garantiscono che la catena di Markov si stabilizzer√† in un equilibrio a lungo termine, specificamente convergendo verso una distribuzione stazionaria $ s $. In questo scenario, ‚Äúconvergenza‚Äù implica che con l‚Äôincrementare indefinito del numero di passaggi $ n $, la distribuzione marginale della catena tende sempre pi√π verso la distribuzione stazionaria $ s $.\nTale convergenza √® di natura probabilistica e avviene a prescindere dalle condizioni iniziali, cio√® dall‚Äôeffettivo stato da cui la catena √® partita. Detto in modo pi√π semplice, con un tempo sufficientemente lungo, il comportamento della catena di Markov diventa prevedibile e stabile, in accordo con la distribuzione stazionaria $ s $.\nQuindi, i concetti di convergenza e stazionariet√† sono strettamente correlati: la convergenza rappresenta il percorso che la catena percorre per raggiungere uno stato di equilibrio, mentre la stazionariet√† fornisce una descrizione formale di questo stato di equilibrio al quale la catena tender√† nel lungo periodo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html",
    "href": "chapters/appendix/a46_stan.html",
    "title": "Appendice Q ‚Äî Linguaggio Stan",
    "section": "",
    "text": "Q.1 Interfacce e pacchetti\n√à possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#interfacce-e-pacchetti",
    "href": "chapters/appendix/a46_stan.html#interfacce-e-pacchetti",
    "title": "Appendice Q ‚Äî Linguaggio Stan",
    "section": "",
    "text": "CmdStanPy - integrazione con il linguaggio di programmazione Python;\nPyStan - integrazione con il linguaggio di programmazione Python;\nCmdStan - eseguibile da riga di comando,\nRStan - integrazione con il linguaggio \\(\\mathsf{R}\\);\nMatlabStan - integrazione con MATLAB;\nStan.jl - integrazione con il linguaggio di programmazione Julia;\nStataStan - integrazione con Stata.\nScalaStan - integrazione con Scala.\n\n\n\nArviz - ArviZ √® una libreria Python per l‚Äôanalisi esplorativa dei modelli bayesiani. Essa funge da strumento indipendente dal backend per diagnosticare e visualizzare l‚Äôinferenza bayesiana.\nshinystan - interfaccia grafica interattiva per l‚Äôanalisi della distribuzione a posteriori e le diagnostiche MCMC in \\(\\mathsf{R}\\);\nbayesplot - insieme di funzioni utilizzabili per creare grafici relativi all‚Äôanalisi della distribuzione a posteriori, ai test del modello e alle diagnostiche MCMC in \\(\\mathsf{R}\\);\nbrms - fornisce un‚Äôampia gamma di modelli lineari e non lineari specificando i modelli statistici mediante la sintassi usata in \\(\\mathsf{R}\\);\nrstanarm - fornisce un sostituto per i modelli frequentisti forniti da base \\(\\mathsf{R}\\) e lme4 utilizzando la sintassi usata in \\(\\mathsf{R}\\) per la specificazione dei modelli statistici;\ncmdstanr - un‚Äôinterfaccia \\(\\mathsf{R}\\) per CmdStan.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#interfaccia-cmdstanpy",
    "href": "chapters/appendix/a46_stan.html#interfaccia-cmdstanpy",
    "title": "Appendice Q ‚Äî Linguaggio Stan",
    "section": "Q.2 Interfaccia cmdstanpy",
    "text": "Q.2 Interfaccia cmdstanpy\nNegli esempi di questa dispensa verr√† utilizzata l‚Äôinterfaccia cmdstanpy. CmdStanPy √® una interfaccia di Stan per gli utenti Python, che fornisce gli oggetti e le funzioni necessarie per condurre l‚Äôinferenza bayesiana su un modello di probabilit√† e dei dati. Essa racchiude l‚Äôinterfaccia a riga di comando di CmdStan in un piccolo insieme di classi Python, le quali offrono metodi per analizzare e gestire l‚Äôinsieme risultante di modello, dati e stime a posteriori.\nPer l‚Äôinstallazione di CmdStanPy, si segua il link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#codice-stan",
    "href": "chapters/appendix/a46_stan.html#codice-stan",
    "title": "Appendice Q ‚Äî Linguaggio Stan",
    "section": "Q.3 Codice Stan",
    "text": "Q.3 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina √® stato generato), l‚Äôutente pu√≤ utilizzare l‚Äôinterfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan √® costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono: data, transformed data, parameters, transformed parameters, model, e generated quantities.\n\nQ.3.1 Blocco data\nNel blocco data vengono specificate le variabili di input che saranno utilizzate nel modello Stan. Per ciascuna variabile, √® necessario definire il tipo di dato e le dimensioni, oltre a eventuali vincoli sui valori che le variabili possono assumere.\nPer esempio\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y; // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior; // Parametro beta per il prior Beta\n}\nEcco una sintesi dei tipi di dati e delle specifiche che possono essere dichiarate:\n\nint: rappresenta numeri interi.\nreal: designa numeri reali, inclusi quelli con parte decimale.\nvector: si riferisce a un vettore unidimensionale di numeri reali.\nmatrix: indica una matrice bidimensionale di numeri reali.\narray: descrive una sequenza ordinata di elementi che possono essere di qualsiasi tipo specificato, e pu√≤ avere pi√π di una dimensione.\n\n√à importante dichiarare le dimensioni di ciascuna variabile e, se necessario, applicare vincoli sui valori che queste possono assumere (ad esempio, specificando lower=0 e upper=1 per vincolare i valori tra 0 e 1). Questi vincoli sono utili per ottimizzare la stima dei parametri e garantire che il modello sia ben definito.\n\nQ.3.1.1 Interi\nGli interi non vincolati vengono dichiarati utilizzando la parola chiave int. Ad esempio, la variabile N viene dichiarata come un intero nel seguente modo.\nint N;\nI tipi di dati interi possono essere vincolati per consentire valori solo in un intervallo specificato fornendo un limite inferiore, un limite superiore o entrambi. Ad esempio, per dichiarare N come un intero positivo, si utilizza quanto segue.\nint&lt;lower=1&gt; N;\n\n\nQ.3.1.2 Reali\nLe variabili reali non vincolate vengono dichiarate utilizzando la parola chiave real. Ad esempio,\nreal theta;\nLe variabili reali possono essere limitate utilizzando la stessa sintassi degli interi. Per esempio, la variabile sigma pu√≤ essere dichiarata come non negativa come segue.\nreal&lt;lower=0&gt; sigma;\n\n\nQ.3.1.3 Tipi di dati vettoriali e matriciali\nStan fornisce tre tipi di oggetti contenitore: array, vettori e matrici. I vettori e le matrici sono tipi di strutture dati pi√π limitati rispetto agli array. I vettori sono collezioni intrinsecamente unidimensionali di valori reali o complessi, mentre le matrici sono intrinsecamente bidimensionali. I vettori, le matrici e gli array non sono assegnabili tra loro, anche se le loro dimensioni sono identiche. Una matrice 3√ó4 √® un tipo di oggetto diverso in Stan rispetto a un array 3√ó4.\nI vettori e le matrici non possono essere tipizzati per restituire valori interi. Sono limitati a valori reali e complessi.\n\n\nQ.3.1.4 Indicizzazione da 1\nVettori e matrici, cos√¨ come gli array, sono indicizzati a partire da uno (1) in Stan.\n\n\nQ.3.1.5 Tipi di dati array\nStan supporta array di dimensioni arbitrarie. I valori in un array possono essere di qualsiasi tipo, in modo che gli array possano contenere valori che sono semplici reali o interi, vettori, matrici o altri array. Gli array sono l‚Äôunico modo per memorizzare sequenze di interi, e alcune funzioni in Stan, come le distribuzioni discrete, richiedono argomenti interi.\nUn array bidimensionale √® semplicemente un array di array. Quando viene fornito un indice a un array, restituisce il valore in quell‚Äôindice. Quando vengono forniti pi√π di un indice, questa operazione di indicizzazione √® concatenata. Ad esempio, se a √® un array bidimensionale, allora a[m, n] √® solo una abbreviazione per a[m][n].\n\n\nQ.3.1.6 Dichiarazione di variabili array\nGli array sono dichiarati con la parola chiave array seguita dalle dimensioni racchiuse tra parentesi quadre, il tipo di elemento e il nome della variabile.\nPer esempio, la variabile n viene dichiarata come un array di cinque interi come segue.\narray[5] int n;\nUn array bidimensionale di valori interi con tre righe e quattro colonne viene dichiarato come segue.\narray[3, 4] int a;\nUn array di N numeri reali vincolati tra 0 e 1 viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] real&lt;lower=0, upper=1&gt; y;\nUn array di N interi positivi viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] int&lt;lower=0&gt; x;\n\n\nQ.3.1.7 Vettori\nI vettori in Stan sono vettori colonna. I vettori sono dichiarati con una dimensione (cio√®, una dimensionalit√†). Ad esempio, un vettore reale tridimensionale di dimensione 3 viene dichiarato con la parola chiave vector, come segue.\nvector[3] u;\n\nQ.3.1.7.1 Matrici\nLe matrici sono dichiarate con la parola chiave matrix insieme a un numero di righe e un numero di colonne. Ad esempio,\nmatrix[3, 3] A;\nmatrix[M, N] B;\ndichiara A come una matrice 3√ó3 e B come una matrice M√óN. Perch√© la seconda dichiarazione sia ben formata, le variabili M e N devono essere dichiarate come interi nel blocco dati o dati trasformati e prima della dichiarazione della matrice.\n\n\nQ.3.1.7.2 Miscelazione di tipi di array, vettore e matrice\nArray, vettori riga, vettori colonna e matrici non sono interscambiabili in Stan. Quindi una variabile di uno qualsiasi di questi tipi fondamentali non √® assegnabile a nessuno degli altri, anche se le loro dimensioni sono identiche, n√© pu√≤ essere utilizzata come argomento dove √® richiesto l‚Äôaltro.\n\n\nQ.3.1.7.3 Dizionari\n√à fondamentale che i dati forniti a Stan tramite CmdStanPy siano organizzati in un oggetto di tipo dizionario. In Python, un dizionario √® una collezione di coppie chiave-valore che permette di associare a ogni chiave (unica) un valore specifico. Quando si preparano i dati per un modello Stan utilizzando CmdStanPy, si crea un dizionario dove:\n\nOgni chiave corrisponde al nome di una variabile dichiarata nel blocco data del modello Stan.\nIl valore associato a ciascuna chiave rappresenta i dati effettivi da passare al modello per quella variabile.\n\nQuesta struttura consente di mappare direttamente le variabili definite nel modello Stan ai dati che si desidera analizzare, facilitando il processo di assegnazione dei dati e assicurando che ogni variabile riceva i dati corretti.\n\n\n\n\nQ.3.2 Blocco parameters\nI parametri da stimare sono definiti all‚Äôinterno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilit√†. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell‚Äôintervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\nCerto, ecco il testo corretto e migliorato:\n\n\nQ.3.3 Sezione model\nNella sezione model, vengono definite le relazioni tra i dati osservati e i parametri del modello, insieme alle distribuzioni a priori di tali parametri.\nA titolo di esempio, il seguente codice assegna una distribuzione a priori Beta ai parametri alpha_prior e beta_prior per il parametro theta. La verosimiglianza specifica che il meccanismo generatore dei dati osservati y √® binomiale, con parametri ntrials e theta.\nmodel {\n  // Prior\n  theta ~ beta(alpha_prior, beta_prior);\n  \n  // Likelihood\n  y ~ binomial(ntrials, theta);\n}\nIl simbolo ~ √® chiamato tilde. In generale, possiamo leggerlo come ‚Äú√® distribuito come‚Äù, e questa notazione viene utilizzata come abbreviazione per definire distribuzioni. Pertanto, l‚Äôesempio sopra pu√≤ essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta)\n\\]\nQuesta notazione compatta facilita la definizione delle relazioni probabilistiche nel modello.\nSe non specificata, Stan utilizza una distribuzione a priori uniforme tra meno infinito e pi√π infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, √® possibile consultare questo link.\n\n\nQ.3.4 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. √à possibile trasformare i parametri del modello; solitamente ci√≤ viene fatto nel caso dei modelli pi√π avanzati per consentire un campionamento MCMC pi√π efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantit√† che non fa parte del modello ma pu√≤ essere calcolata a partire dai parametri del modello, per ogni iterazione dell‚Äôalgoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\nQ.3.5 Sintassi\nSi noti che il codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos‚Äôaltro. I punti e virgola non sono invece richiesti all‚Äôinizio di un ciclo o di un‚Äôistruzione condizionale, dove non viene assegnato nulla.\nIn STAN, qualsiasi stringa che segue // denota un commento e viene ignorata dal programma.\nUna descrizione dettagliata della sintassi del linguaggio Stan √® disponibile al seguente link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice R ‚Äî La funzione lineare",
    "section": "",
    "text": "La funzione lineare √® definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di questa funzione √® una retta, dove il parametro \\(b\\) rappresenta il coefficiente angolare e il parametro \\(a\\) rappresenta l‚Äôintercetta con l‚Äôasse delle \\(y\\). In altre parole, la retta interseca l‚Äôasse \\(y\\) nel punto \\((0,a)\\) se \\(b \\neq 0\\).\nPossiamo dare un‚Äôinterpretazione geometrica alle costanti \\(a\\) e \\(b\\) considerando la funzione:\n\\[\ny = b x.\n\\]\nQuesta funzione rappresenta un caso speciale, la proporzionalit√† diretta tra \\(x\\) e \\(y\\). Nel caso generale della funzione lineare:\n\\[\ny = a + b x,\n\\]\naggiungiamo una costante \\(a\\) a ciascun valore \\(y = b x\\). Nella funzione lineare, se il coefficiente \\(b\\) √® positivo, il valore di \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) √® negativo, il valore di \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\), la retta √® orizzontale e il valore di \\(y\\) non varia al variare di \\(x\\).\nConsideriamo ora il coefficiente \\(b\\) in modo pi√π dettagliato. Prendiamo un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\), come mostrato nella figura. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono chiamate ‚Äúincrementi‚Äù di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) √® definito come il rapporto\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Per dare un‚Äôinterpretazione geometrica al coefficiente angolare (o pendenza) della retta, possiamo semplificare assumendo \\(\\Delta x = 1\\). In questo caso, \\(b\\) √® uguale a \\(\\Delta y\\).\n\n\n\n\n\n\nFigura¬†R.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nPossiamo dunque dire che la pendenza \\(b\\) di un retta √® uguale all‚Äôincremento \\(\\Delta y\\) associato ad un incremento unitario nella \\(x\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>¬† <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_reglin_1.html",
    "href": "chapters/appendix/a51_reglin_1.html",
    "title": "Appendice S ‚Äî Regressione lineare bivariata",
    "section": "",
    "text": "S.1 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di trovare una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L‚Äôequazione lineare che descrive la relazione tra le due variabili √® della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) √® il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo √® che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo √® che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo √® quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) √® piatto, cio√® le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ci√≤ significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) √®\n\\[\na = \\bar{y} - b \\bar{x}.\n\\]\nLa formula per il coefficiente \\(b\\) √®\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) √® la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) √® la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\nNel caso dell‚Äôesempio presente, tali coefficienti sono uguali a:\ncov_xy = np.cov(kidiq[\"kid_score\"], kidiq[\"mom_iq\"], ddof=1)[0][1]\nvar_x = np.var(kidiq[\"mom_iq\"], ddof=1)\nb = cov_xy / var_x\nb\n\n0.6099745717307855\na = np.mean(kidiq[\"kid_score\"]) - b * np.mean(kidiq[\"mom_iq\"])\na\n\n25.79977784996293\nVerifichiamo i risultati trovati usando funzione optimize.curve_fit. Questa √® una funzione molto potente, in quanto pu√≤ adattarsi non solo alle funzioni lineari, ma anche alle funzioni non lineari. Qui la usiamo per la retta di regressione.\ndef func(x, a, b):\n    y = a + b*x\n    return y\n  \noptimize.curve_fit(func, xdata = kidiq.mom_iq, ydata = kidiq.kid_score)[0]\n\narray([25.7997779 ,  0.60997457])",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_reglin_1.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/appendix/a51_reglin_1.html#stima-dei-coefficienti-di-regressione",
    "title": "Appendice S ‚Äî Regressione lineare bivariata",
    "section": "",
    "text": "S.1.1 Interpretazione\nIl coefficiente \\(a\\) indica l‚Äôintercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l‚Äôasse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non √® di particolare interesse poich√© corrisponde al valore della retta di regressione quando l‚Äôintelligenza della madre √® pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come √® possibile trasformare i dati per fornire un‚Äôinterpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) √® positivo) o diminuisce (se \\(b\\) √® negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri √® associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ci√≤ significa che non √® in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unit√† di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\n√à importante comprendere che il modello statistico di regressione lineare non √® in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima √® basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\), per tutte le osservazioni del campione √® fornito dalla figura seguente.\n\n_, ax = plt.subplots()\n_ = ax.plot(kidiq[\"mom_iq\"], a + b * kidiq[\"mom_iq\"], \"o\", alpha=0.4)\n\n\n\n\n\n\n\n\nIl diagramma precedente presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). Si vede che i valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nprint(kidiq[\"kid_score\"][0])\n\n65\n\n\nIl QI della madre √®\n\nkidiq[\"mom_iq\"][0]\n\n121.11752860260343\n\n\nPer questo bambino, il valore predetto dal modello di regressione √®\n\na + b * kidiq[\"mom_iq\"][0]\n\n99.67839048842711\n\n\nL‚Äôerrore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) √®\n\nkidiq[\"kid_score\"][0] - (a + b * kidiq[\"mom_iq\"][0])\n\n-34.67839048842711\n\n\nPer tutte le osservazioni abbiamo\n\nres = kidiq[\"kid_score\"] - (a + b * kidiq[\"mom_iq\"])\nres\n\n0     -34.678390\n1      17.691747\n2     -11.217173\n3      -3.461529\n4      32.627697\n         ...    \n429    16.427159\n430    -6.521552\n431   -33.661788\n432     3.120144\n433   -11.461993\nLength: 434, dtype: float64\n\n\n√à una propriet√† del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nnp.sum(res)\n\n-2.7284841053187847e-12\n\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che √® predicibile da \\(x_i\\), √® data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, √® dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\npd.DataFrame(\n    {\n        \"kid_score\": kidiq[\"kid_score\"],\n        \"mom_iq\": kidiq[\"mom_iq\"],\n        \"y_hat\": a + b * kidiq[\"mom_iq\"],\n        \"e\": kidiq[\"kid_score\"] - (a + b * kidiq[\"mom_iq\"]),\n        \"y_hat + e\": (a + b * kidiq[\"mom_iq\"])\n        + (kidiq[\"kid_score\"] - (a + b * kidiq[\"mom_iq\"])),\n    }\n).head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\ny_hat\ne\ny_hat + e\n\n\n\n\n0\n65\n121.117529\n99.678390\n-34.678390\n65.0\n\n\n1\n98\n89.361882\n80.308253\n17.691747\n98.0\n\n\n2\n85\n115.443165\n96.217173\n-11.217173\n85.0\n\n\n3\n83\n99.449639\n86.461529\n-3.461529\n83.0\n\n\n4\n115\n92.745710\n82.372303\n32.627697\n115.0\n\n\n\n\n\n\n\n\n\n\nS.1.2 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l‚Äôintercetta del modello di regressione lineare non ha un‚Äôinterpretazione utile. Questo perch√© l‚Äôintercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore ‚Äú0‚Äù di \\(x\\) √® arbitrario e non corrisponde ad un ‚Äúassenza‚Äù della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un‚Äôassenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre √® 0 non √® di alcun interesse.\nPer fornire all‚Äôintercetta del modello di regressione un‚Äôinterpretazione pi√π utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq[\"xd\"] = kidiq[\"mom_iq\"] - np.mean(kidiq[\"mom_iq\"])\nkidiq\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\nxd\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n21.117529\n\n\n1\n98\n1.0\n89.361882\n4\n25\n-10.638118\n\n\n2\n85\n1.0\n115.443165\n4\n27\n15.443165\n\n\n3\n83\n1.0\n99.449639\n3\n25\n-0.550361\n\n\n4\n115\n1.0\n92.745710\n4\n27\n-7.254290\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n429\n94\n0.0\n84.877412\n4\n21\n-15.122588\n\n\n430\n76\n1.0\n92.990392\n4\n23\n-7.009608\n\n\n431\n50\n0.0\n94.859708\n2\n24\n-5.140292\n\n\n432\n88\n1.0\n96.856624\n2\n21\n-3.143376\n\n\n433\n70\n1.0\n91.253336\n2\n25\n-8.746664\n\n\n\n\n434 rows √ó 6 columns\n\n\n\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n_, ax = plt.subplots()\nax.plot(kidiq[\"xd\"], kidiq[\"kid_score\"], \"o\", alpha=0.4)\nb, a = np.polyfit(kidiq[\"xd\"], kidiq[\"kid_score\"], 1)\nplt.plot(kidiq[\"xd\"], a + b * kidiq[\"xd\"])\nax.set_xlabel(\"QI della madre (scarti dalla media)\")\n_ = ax.set_ylabel(\"QI del bambino\")\n\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l‚Äôasse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l‚Äôorigine dell‚Äôasse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L‚Äôunica cosa che cambia √® il valore dell‚Äôintercetta della linea di regressione, che ora ha un‚Äôinterpretazione pi√π significativa.\n\nresult = stats.linregress(kidiq.xd, kidiq.kid_score)\nresult.intercept, result.slope\n\n(86.79723502304148, 0.6099745717307856)\n\n\nL‚Äôintercetta rappresenta il punto in cui la retta di regressione incontra l‚Äôasse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l‚Äôasse \\(x\\) di una quantit√† pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell‚Äôintercetta viene influenzato dalla trasformazione. In particolare, poich√© \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l‚Äôintercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l‚Äôintercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.\n\n\nS.1.3 Il metodo dei minimi quadrati\nPer calcolare i coefficienti di regressione \\(a\\) e \\(b\\), si deve minimizzare la somma dei quadrati degli scarti tra i valori osservati \\(y_i\\) e quelli previsti dal modello \\(a + bx_i\\) per ogni osservazione \\(i\\). In altre parole, si vuole trovare i valori di \\(a\\) e \\(b\\) che permettono di ottenere la retta di regressione che si avvicina il pi√π possibile ai dati osservati.\nPer calcolare i coefficienti di regressione tramite una simulazione, supponiamo che uno dei due parametri sia noto, ad esempio \\(a\\), cos√¨ da avere una sola incognita. Creiamo una griglia di valori b_grid possibili, ad esempio:\n\nb_grid = np.linspace(0, 1, 1001)\n\nDefiniamo una funzione che calcola la somma dei quadrati dei residui \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\):\n\ndef sse(a, b, x, y):\n    return np.sum((y - (a + b * x)) ** 2)\n\nCalcoliamo la somma degli errori quadratici per ciascun possibile valore b_grid. Per semplificaer il problema, considerato noto \\(a = 25.79978\\).\n\na = 25.79978\nsse_vals = [sse(a, b, kidiq[\"mom_iq\"], kidiq[\"kid_score\"]) for b in b_grid]\n\nEsaminiamo il risultato ottenuto.\n\nplt.plot(b_grid, sse_vals, '-')\nplt.plot(\n    b_grid[np.argmin(sse_vals)], sse_vals[np.argmin(sse_vals)],\n    'X', label=r'Stima dei minimi quadrati, $\\hat \\beta$'\n)\nplt.ylabel('SSE')\nplt.xlabel(fr'Possibili valori $\\hat \\beta$')\nplt.title(f'Minimizzazione dei residui quadratici')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIl risultato ottenuto con la simulazione riproduce quello ottenuto per via analitica.\n\nb_grid[np.argmin(sse_vals)]\n\n0.61\n\n\nAbbiamo mostrato un esempio di simulazione per stimare uno dei coefficienti del modello lineare. Tuttavia, una simulazione pi√π complessa, ma computazionalmente pi√π costosa, pu√≤ essere utilizzata per stimare simultaneamente entrambi i coefficienti del modello lineare. Ci√≤ che abbiamo fatto qui √® solo una dimostrazione del concetto di base, ovvero il metodo di minimizzazione dei residui quadrati, che viene utilizzato per stimare i coefficienti del modello lineare.\n\n\nS.1.4 L‚Äôerrore standard della regressione\nIl secondo obiettivo del modello di regressione lineare √® quello di misurare quanto della variabilit√† di \\(y\\) possa essere spiegata dalla variabilit√† di \\(x\\) per ogni osservazione. L‚Äôindice di bont√† di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche ‚Äúerrore standard della stima‚Äù, \\(s_e\\). Per calcolare \\(s_e\\), si utilizza una formula che prevede di sommare i quadrati dei residui \\(e_i\\) per ogni osservazione e di dividere per \\(n-2\\), dove \\(n\\) rappresenta la numerosit√† del campione e \\(2\\) rappresenta il numero di coefficienti stimati nel modello di regressione. L‚Äôerrore standard della stima \\(s_e\\) possiede la stessa unit√† di misura di \\(y\\) ed √® una stima della deviazione standard dei residui nella popolazione di cui il campione √® stato estratto. In altre parole, l‚Äôerrore standard della stima rappresenta una stima della media dei residui, che indica quanto lontane le previsioni del modello di regressione lineare possono essere dalle osservazioni effettive.\nVerifichiamo quanto detto con i dati a disposizione. I residui possono essere trovati nel modo seguente.\n\ne = kidiq.kid_score - (a + b * kidiq.mom_iq)\ne[0:10]\n\n0   -34.678393\n1    17.691744\n2   -11.217175\n3    -3.461531\n4    32.627695\n5     6.382843\n6   -41.521043\n7     3.864879\n8    26.414384\n9    11.208066\ndtype: float64\n\n\nCalcoliamo il residuo medio, prendendo il valore assoluto.\n\nnp.mean(np.abs(e))\n\n14.46860267547228\n\n\nL‚Äôerrore standard della regressione √®\n\nnp.sqrt(sum(e**2) / (len(e) - 2))\n\n18.2661227922994\n\n\nSi noti che i due valori non sono uguali, ma hanno lo stesso ordine di grandezza.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_reglin_1.html#indice-di-determinazione",
    "href": "chapters/appendix/a51_reglin_1.html#indice-di-determinazione",
    "title": "Appendice S ‚Äî Regressione lineare bivariata",
    "section": "S.2 Indice di determinazione",
    "text": "S.2 Indice di determinazione\nUn importante risultato dell‚Äôanalisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione √® descritta mediante l‚Äôindice di determinazione \\(R^2\\), che fornisce una misura della bont√† di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) pu√≤ essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) pu√≤ quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. L‚Äôindice di determinazione \\(R^2\\) √® definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) √® spiegata dalla variabile indipendente \\(x\\).\nPer l‚Äôesempio in discussione abbiamo quanto segue. La devianza totale √®\n\ndev_t = np.sum((kidiq.kid_score - np.mean(kidiq.kid_score)) ** 2)\ndev_t\n\n180386.15668202768\n\n\nLa devianza spiegata √®\n\ndev_r = np.sum(((a + b * kidiq.mom_iq) - np.mean(kidiq.kid_score)) ** 2)\ndev_r\n\n36248.820197060355\n\n\nL‚Äôindice di determinazione √®\n\nR2 = dev_r / dev_t\nround(R2, 3)\n\n0.201\n\n\nVerifichiamo.\n\nX = sm.add_constant(kidiq[\"mom_iq\"])\nmod = sm.OLS(kidiq[\"kid_score\"], X)\nres = mod.fit()\nprint(res.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              kid_score   R-squared:                       0.201\nModel:                            OLS   Adj. R-squared:                  0.199\nMethod:                 Least Squares   F-statistic:                     108.6\nDate:                Thu, 29 Feb 2024   Prob (F-statistic):           7.66e-23\nTime:                        08:43:14   Log-Likelihood:                -1875.6\nNo. Observations:                 434   AIC:                             3755.\nDf Residuals:                     432   BIC:                             3763.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         25.7998      5.917      4.360      0.000      14.169      37.430\nmom_iq         0.6100      0.059     10.423      0.000       0.495       0.725\n==============================================================================\nOmnibus:                        7.545   Durbin-Watson:                   1.645\nProb(Omnibus):                  0.023   Jarque-Bera (JB):                7.735\nSkew:                          -0.324   Prob(JB):                       0.0209\nKurtosis:                       2.919   Cond. No.                         682.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nIl risultato ottenuto si pu√≤ interpretare dicendo che circa il 20% della variabilit√† dei punteggi del QI dei bambini pu√≤ essere predetto conoscendo il QI delle madri.\n\nS.2.1 Inferenza sul modello di regressione\nIl paragrafo precedente discute l‚Äôapproccio ‚Äúclassico‚Äù al modello di regressione lineare, che si basa sulle stime dei minimi quadrati. Questo approccio non tiene conto delle distribuzioni a priori dei parametri \\(\\alpha\\) e \\(\\beta\\). Se imponiamo distribuzioni a priori uniformi (non informative) sui parametri, le stime di massima verosimiglianza coincidono con il massimo a posteriori bayesiano. Tuttavia, in un contesto bayesiano, √® possibile imporre distribuzioni a priori debolmente o informativamente. In questo caso, la scelta della distribuzione a priori ha un effetto sulla regolarizzazione dei dati.\nNell‚Äôapproccio frequentista, l‚Äôinferenza viene effettuata calcolando la distribuzione campionaria dei parametri e gli intervalli di fiducia per i parametri. Ad esempio, se si vuole determinare se la pendenza della retta di regressione √® maggiore di zero, si calcola l‚Äôintervallo di fiducia al 95% per il parametro \\(\\beta\\). Se l‚Äôintervallo non include lo zero e se il limite inferiore dell‚Äôintervallo √® maggiore di zero, si conclude che c‚Äô√® evidenza di un‚Äôassociazione lineare positiva tra \\(x\\) e \\(y\\) con un grado di confidenza del 95%.\nIn un‚Äôottica bayesiana, l‚Äôintervallo di credibilit√† al 95% per il parametro \\(\\beta\\) pu√≤ essere calcolato. Se usiamo una distribuzione a priori uniforme, gli intervalli di credibilit√† e di fiducia sono identici. Tuttavia, se usiamo una distribuzione a priori debolmente o informativamente, i due intervalli possono differire. Solitamente si usa una distribuzione a priori debolmente informativa centrata sullo zero, che ha l‚Äôeffetto di regolarizzare i dati. Il prossimo capitolo spiegher√† come effettuare l‚Äôinferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_reglin_1.html#commenti-e-considerazioni-finali",
    "href": "chapters/appendix/a51_reglin_1.html#commenti-e-considerazioni-finali",
    "title": "Appendice S ‚Äî Regressione lineare bivariata",
    "section": "S.3 Commenti e considerazioni finali",
    "text": "S.3 Commenti e considerazioni finali\nIl modello lineare bivariato √® uno strumento fondamentale per analizzare la relazione tra due variabili. Non solo ci permette di capire se esiste una correlazione tra le due variabili, ma ci permette anche di determinare il grado di intensit√† di tale correlazione e di fare previsioni sull‚Äôandamento futuro.\nIn pratica, il modello lineare ci consente di rispondere a domande del tipo: se il valore della variabile indipendente aumenta di una certa quantit√†, di quanto aumenter√† il valore della variabile dipendente? Oppure, se il valore della variabile indipendente diminuisce, di quanto diminuir√† il valore della variabile dipendente?\nQuesti sono solo alcuni esempi di come il modello lineare bivariato possa essere utilizzato per fare previsioni. La bellezza di questo modello sta nella sua semplicit√†: si tratta di una formula matematica che ci permette di descrivere la relazione tra le due variabili in modo chiaro e preciso. Inoltre, il modello lineare pu√≤ essere utilizzato anche in contesti pi√π complessi, ad esempio quando ci sono pi√π variabili indipendenti che influenzano la variabile dipendente.\nInsomma, il modello lineare bivariato √® uno strumento fondamentale per analizzare e comprendere le relazioni tra le variabili, e ci permette di fare previsioni utili per prendere decisioni informate e ottimizzare i nostri risultati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>¬† <span class='chapter-title'>Regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html",
    "href": "chapters/appendix/a60_ttest_exercises.html",
    "title": "Appendice T ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "",
    "text": "T.1 Inferenza statistica su una singola media",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "href": "chapters/appendix/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "title": "Appendice T ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "",
    "text": "T.1.1 Test \\(t\\) di Student a un campione\nPer descrivere l‚Äôinferenza su una singola media consideriamo il seguente esempio. √à stato condotto uno studio di ricerca al fine di esaminare le differenze tra gli adulti anziani e quelli giovani sulla percezione della soddisfazione nella vita. Per testare questa ipotesi, √® stato effettuato uno studio pilota su dati ipotetici. Il test √® stato somministrato a dieci adulti anziani (oltre i 70 anni) e dieci adulti giovani (tra i 20 e i 30 anni). La scala di valutazione utilizzata ha un range di punteggi da 0 a 60, dove punteggi elevati indicano una maggiore soddisfazione nella vita e punteggi bassi indicano una minore soddisfazione. √à stata scelta una scala con elevata affidabilit√† e validit√†. I dati (fittizi) raccolti sono riportati di seguito.\n\nyounger = np.array([45, 38, 52, 48, 25, 39, 51, 46, 55, 46])\nolder = np.array([34, 33, 36, 38, 37, 40, 42, 43, 32, 36])\n\nPer ora, esaminiamo soltanto il gruppo degli adulti pi√π anziani. Si suppponga che studi precedenti indichino che, per questo gruppo d‚Äôet√†, la soddisfazione della vita misurata con questo test sia pari a 60. Svolgiamo il test t di Student usando l‚Äôipotesi nulla che nella popolazione la media sia effettivamente uguale a 40.\nInziamo a svolgere l‚Äôesercizio applicando la funzione ttest del modulo pingouin. Per l‚Äôesempio presente, poniamo \\(\\mu_0\\), la media dell‚Äôipotesi nulla, uguale a 40. Svolgiamo l‚Äôesercizio con ttest.\n\nres = pg.ttest(older, 40)\n\nEsaminiamo il risultato.\n\nprint(res)\n\n               T  dof alternative     p-val           CI95%   cohen-d   BF10  \\\nT-test -2.481666    9   two-sided  0.034896  [34.46, 39.74]  0.784772  2.319   \n\n           power  \nT-test  0.599895  \n\n\nInterpretazione. Dato che il valore-p √® minore di \\(\\alpha\\) = 0.05, ovvero in modo equivalente, dato che la statistica test cade nella regione di rifiuto, rifiutiamo \\(H_0: \\mu = 40\\).\nProcediamo ora con i calcoli passo-passo utilizzando la formula del test t di Student. La statistica \\(T\\) calcolata dal test √® definita come:\n\\[\nT = \\frac{\\bar{X} - \\mathbb{E}(\\bar{X})}{s / \\sqrt{n}} = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) √® la media campionaria, \\(\\mu_0\\) √® l‚Äôipotesi nulla sulla media della popolazione, \\(s\\) √® la deviazione standard campionaria e \\(n\\) √® la dimensione del campione. Tale statistica ha una semplice interpretazione: essa corrisponde alla standardizzazione della media del campione all‚Äôinterno della distribuzione campionaria delle medie di ampiezza \\(n\\) = 10. La distribuzione campionaria delle medie di ampiezza \\(n\\) = 10 ha media \\(\\mu_{\\bar{X}} = \\mu\\) e varianza \\(\\sigma^2_{\\bar{X}} = \\frac{\\sigma^2}{n}\\), dove \\(\\mu\\) √® la media della popolazione e \\(\\sigma^2\\) √® la varianza della popolazione da cui il campione √® stato estratto. Tuttavia, poich√© i parametri della popolazione sono sconosciuti, l‚Äôapproccio frequentista utilizza la media \\(\\mu_0\\) ipotizzata dall‚Äôipotesi nulla \\(H_0\\) al posto della media sconosciuta della popolazione e stima il parametro sconosciuto \\(\\sigma\\) con la deviazione standard \\(s\\) del campione. In queste circostanze, la statistica \\(T\\) segue la distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† se il campione √® stato estratto da una popolazione normale.\nSvolgiamo i calcoli con Python.\n\nT = (np.mean(older) - 40) / (np.std(older, ddof=1) / np.sqrt(len(older)))\nT\n\n-2.481665888425312\n\n\nI gradi di libert√† sono \\(n-1\\).\n\ndf = len(older) - 1\nprint(df)\n\n9\n\n\nTroviamo il valore-p, ovvero l‚Äôarea sottesa alla distribuzione t di Student con 9 gradi di libert√† nei due intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\).\n\n# Set up the x-axis values for the t-distribution plot\nx = np.linspace(st.t.ppf(0.001, df), st.t.ppf(0.999, df), 1000)\n\n# Set up the y-axis values for the t-distribution plot\ny = st.t.pdf(x, df)\n\n# Create the t-distribution plot\nplt.plot(x, y, label=\"t-distribution\")\n\n# Shade the areas [-infinity, -T] and [T, +infinity]\nplt.fill_between(x[x &lt;= -T], y[x &lt;= -T], color=\"red\", alpha=0.2)\nplt.fill_between(x[x &gt;= T], y[x &gt;= T], color=\"red\", alpha=0.2)\n\n# Add vertical lines for T and -T\nplt.axvline(x=T, color=\"black\", linestyle=\"--\")\nplt.axvline(x=-T, color=\"black\", linestyle=\"--\")\n\n\n# Set the plot title and axis labels\nplt.title(f\"Distribuzione t di Student con {df} gradi di libert√†\")\nplt.xlabel(\"Valore t\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.show()\n\n\n\n\n\n\n\n\n\nst.t.cdf(T, df=len(older) - 1) * 2\n\n0.03489593108658913\n\n\n\n\nT.1.2 Intervallo di confidenza per una media\nCalcoliamo ora l‚Äôintervallo di confidenza al livello di fiducia del 95%. Come visto in precedenza, la procedura ttest ha calcolato l‚Äôintervallo di confidenza del 95% per la media della popolazione che va da 34.46 a 39.74. Questo intervallo pu√≤ essere interpretato come segue: se la stessa procedura venisse applicata molte volte, in circa il 95% dei casi l‚Äôintervallo ottenuto conterr√† il vero valore della media della popolazione.\nIniziamo a trovare il valore critico della distribuzione \\(t\\) di Student che lascia \\(\\alpha/2\\) in ciascuna coda.\n\nalpha = 0.05\ndf # 9\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.262157162854099\n\n\nL‚Äôintervallo di confidenza √® dato da\n\\[\n\\bar{X} \\pm t_{n-1} \\frac{s}{\\sqrt{n}}.\n\\]\nSvolgiamo i calcoli.\n\nci_lower = np.mean(older) - t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nci_upper = np.mean(older) + t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nprint(\"L'intervallo di confidenza al 95% per la media della popolazione √®: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la media della popolazione √®: [34.46, 39.74].",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "href": "chapters/appendix/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "title": "Appendice T ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "T.2 Confronto tra medie per campioni indipendenti",
    "text": "T.2 Confronto tra medie per campioni indipendenti\n\nT.2.1 Test \\(t\\) di Student per campioni indipendenti\nPer eseguire il test t di Student per due campioni indipendenti, iniziamo svolgendo i calcoli con la funzione ttest del modulo pingouin. L‚Äôipotesi nulla √® che la differenza tra le medie delle due popolazioni sia uguale a 0: \\(\\mu_1 - \\mu_2 = 0\\). La funzione ttest implementa la seguente formula:\n\\[\nT = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\n    \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}.\n}},\n\\]\n\nres = pg.ttest(younger, older, paired=False)\nprint(res)\n\n               T  dof alternative    p-val          CI95%  cohen-d   BF10  \\\nT-test  2.479867   18   two-sided  0.02326  [1.13, 13.67]  1.10903  2.849   \n\n           power  \nT-test  0.650317  \n\n\nSvolgiamo i calcoli passo-passo.\n\nt_num = np.mean(younger) - np.mean(older)\nt_denom = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nT = np.divide(t_num, t_denom)\nT\n\n2.479866520313643\n\n\nLa statistica \\(T\\) calcolata sopra si distribuisce con \\((n_1 - 1) + (n_2 - 1)\\), ovvero \\(n_1 + n_2 - 2\\), gradi di libert√†.\n\ndf = len(younger) + len(older) - 2\nprint(df)\n\n18\n\n\nIl valore-p √® uguale all‚Äôarea sottesa alla funzione t di Student con \\(n_1 + n_2 - 2\\) negli intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\). Nel caso presente abbiamo\n\n(1 - st.t.cdf(T, df=df)) * 2\n\n0.023260241301116924\n\n\n\n\nT.2.2 Intervallo di confidenza per la differenza tra due medie\nCalcoliamo ora l‚Äôintervallo di confidenza al livello di fiducia del 95% per la differenza tra le due medie. Iniziamo a calcolare il valore critico \\(t\\).\n\nalpha = 0.05\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.10092204024096\n\n\nTroviamo l‚Äôerrore standard della differenza tra le due medie.\n\nse_diff = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nse_diff\n\n2.9840315756446754\n\n\nTroviamo i limiti inferiore e superiore dell‚Äôintervallo di confidenza al 95%.\n\nci_lower = (np.mean(younger) - np.mean(older)) - (t_c * se_diff)\nci_upper = (np.mean(younger) - np.mean(older)) + (t_c * se_diff)\nprint(\"L'intervallo di confidenza al 95% per la differenza tra le due medie √®: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la differenza tra le due medie √®: [1.13, 13.67].\n\n\nSi noti che i gradi di libert√† sono \\(n_1+n_2-2\\) quando le varianze delle due popolazioni sono uguali. La formula di Welch-Satterthwaite viene usata per approssimare i gradi di libert√† quando le due varianze non sono uguali:\n\\[\n\\nu \\approx \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1 - 1} + \\frac{(s_2^2/n_2)^2}{n_2 - 1}}\n\\]\ndove \\(\\nu\\) rappresenta i gradi di libert√† approssimati, \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie delle due popolazioni, \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\nNel caso di varianze diverse, l‚Äôargomento correction=True produce una correzione dei gradi di liberta con l‚Äôapprossimazione di Welch-Satterthwaite e il corrispondente valore-p.\n\nres1 = pg.ttest(younger, older, paired=False, correction=True)\nprint(res1)\n\n               T        dof alternative     p-val          CI95%  cohen-d  \\\nT-test  2.479867  12.156852   two-sided  0.028738  [0.91, 13.89]  1.10903   \n\n         BF10     power  \nT-test  2.849  0.650317  \n\n\nConsideriamo ora la statistica \\(d\\) di Cohen. Il \\(d\\) di Cohen √® una misura di effetto comunemente utilizzata per valutare la differenza tra le medie di due gruppi indipendenti. La formula del \\(d\\) di Cohen per la differenza di due medie indipendenti √® la seguente:\n\\[\nd = \\frac{\\bar{X}_1 - \\bar{X}_2}{s},\n\\]\ndove \\(\\bar{X}_1\\) e \\(\\bar{X}_2\\) sono le medie dei due gruppi, e \\(s\\) √® la deviazione standard raggruppata (pooled standard deviation), definita come:\n\\[\ns = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi e \\(s_1\\) e \\(s_2\\) sono le deviazioni standard dei due gruppi. Il \\(d\\) di Cohen pu√≤ essere interpretato come la differenza tra le medie dei due gruppi in unit√† di deviazioni standard raggruppate. Un valore di \\(d\\) di Cohen di 0.2 √® considerato un effetto piccolo, un valore di 0.5 √® considerato un effetto medio e un valore di 0.8 o superiore √® considerato un effetto grande.\nLa funzione ttest ha trovato un valore di 1.10903. Svolgiamo i calcoli passo-passo.\nIniziamo a calcolare la deviazione standard raggruppata (pooled standard deviation).\n\ns_pool_num = np.sum(\n    [\n        (len(younger) - 1) * np.std(younger, ddof=1) ** 2,\n        (len(older) - 1) * np.std(older, ddof=1) ** 2,\n    ]\n)\ns_pool_denom = len(younger) + len(older) - 2\n\ns_pool = np.sqrt(np.divide(s_pool_num, s_pool_denom))\ns_pool\n\n6.672497450147301\n\n\nTroviamo ora il \\(d\\) di Cohen.\n\nd = (np.mean(younger) - np.mean(older)) / s_pool\nprint(d)\n\n1.1090300229094336\n\n\nInterpretazione. Il risultato dell‚Äôanalisi suggerisce che la differenza nella soddisfazione nella vita tra i due gruppi di et√†, misurata tramite l‚Äôindice \\(d\\) di Cohen, √® considerevole in termini di dimensione dell‚Äôeffetto.\n\n\nT.2.3 PyMC\nSvolgiamo ora lo stesso esercizio usando l‚Äôinferenza Bayesiana. Utilizzeremo distribuzioni a priori ampie per garantire un risultato simile all‚Äôanalisi frequentista. Inseriamo i dati in un DataFrame.\n\ny = np.concatenate((younger, older))\nx = np.concatenate((np.repeat(1, len(younger)), np.repeat(0, len(older))))\ndf = pd.DataFrame({\"y\": y, \"x\": x})\ndf.head()\n\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n0\n45\n1\n\n\n1\n38\n1\n\n\n2\n52\n1\n\n\n3\n48\n1\n\n\n4\n25\n1\n\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n15\n40\n0\n\n\n16\n42\n0\n\n\n17\n43\n0\n\n\n18\n32\n0\n\n\n19\n36\n0\n\n\n\n\n\n\n\n\n\nsns.scatterplot(x=df[\"x\"], y=df[\"y\"])\nsns.regplot(x=df[\"x\"], y=df[\"y\"], ci=False)\n\n\n\n\n\n\n\n\nCreaimo il modello statistico corrispondente ad un modello di regressione con un predittore dicotomico codificato con 0 per il primo gruppo e con 1 per il secondo gruppo. Iniziamo con l‚Äôanalisi predittiva a priori per determinare se le distribuzioni a priori sono adeguate.\n\nwith Model() as model_p:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=100)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata_p = pm.sample_prior_predictive(samples=50)\n\nSampling: [Y_obs, alpha, beta, sigma]\n\n\nUtilizzo lo script fornito dal sito di PyMC per generare casualmente un campione di rette di regressione dal modello utilizzando le distribuzioni a priori specificate.\n\n_, ax = plt.subplots()\n\nxp = xr.DataArray(np.linspace(0, 1, 11), dims=[\"plot_dim\"])\nprior = idata_p.prior\nyp = prior[\"alpha\"] + prior[\"beta\"] * xp\n\nax.plot(xp, yp.stack(sample=(\"chain\", \"draw\")), c=\"k\", alpha=0.4)\n\nax.set_ylabel(\"Soddisfazione della vita\")\nax.set_xlabel(\"Gruppo (codificato con 0 e 1)\")\nax.set_title(\"Distribuzione predittiva a priori\");\n\n\n\n\n\n\n\n\nSi noti che prior[\"alpha\"] √® un array che contiene 50 valori generati casualmente dal modello per il parametro alpha.\n\nprior[\"alpha\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'alpha' (chain: 1, draw: 50)&gt; Size: 400B\narray([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'alpha'chain: 1draw: 5027.91 -9.761 21.89 -14.57 68.4 ... -74.84 -16.03 -8.952 -12.09 0.6241array([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nLo stesso si pu√≤ dire per beta.\n\nprior[\"beta\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'beta' (chain: 1, draw: 50)&gt; Size: 400B\narray([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'beta'chain: 1draw: 5036.25 -7.924 78.12 -77.3 -2.919 ... -61.35 -116.8 -28.46 82.94 6.628array([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL‚Äôarray xp √® un vettore unidimensionale di 11 elementi compresi tra 0 e 1.\n\nxp.shape\n\n(11,)\n\n\n\nxp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (plot_dim: 11)&gt; Size: 88B\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])\nDimensions without coordinates: plot_dimxarray.DataArrayplot_dim: 110.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nSi noti che l‚Äôxarray yp ha coordinate chain e draw.\n\nyp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (chain: 1, draw: 50, plot_dim: 11)&gt; Size: 4kB\narray([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49\nDimensions without coordinates: plot_dimxarray.DataArraychain: 1draw: 50plot_dim: 1127.91 31.54 35.16 38.79 42.41 46.04 ... 4.601 5.264 5.927 6.59 7.252array([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL‚Äôistruzione yp = prior[\"alpha\"] + prior[\"beta\"] * xp genera i valori y per una serie di rette con coefficienti prior[\"alpha\"] e prior[\"beta\"]. Nel nostro caso, stiamo generando 50 rette perch√© abbiamo selezionato 50 valori di alpha e 50 valori di beta dalle distribuzioni a posteriori.\nNel contesto della modellazione bayesiana, il termine ‚Äúchain‚Äù si riferisce alla catena di campionamento di Markov Monte Carlo (MCMC). Durante il processo di campionamento, vengono eseguiti diversi passaggi successivi per ottenere campioni indipendenti dalla distribuzione a posteriori. Ogni passaggio viene chiamato ‚Äúdraw‚Äù o ‚Äúsample‚Äù. Pertanto, ‚Äúchain‚Äù rappresenta le catene di campionamento e ‚Äúdraw‚Äù rappresenta i singoli campioni all‚Äôinterno di ciascuna catena.\nL‚Äôistruzione yp.stack(sample=(\"chain\", \"draw\")) viene utilizzata per combinare le dimensioni ‚Äúchain‚Äù e ‚Äúdraw‚Äù al fine di ottenere un array multidimensionale che rappresenta i campioni di parametri estratti dalla distribuzione a posteriori. Ci√≤ facilita la visualizzazione e l‚Äôanalisi dei campioni.\nNotiamo che le pendenze delle rette di regressione generate casualmente dal modello, utilizzando le distribuzioni a priori specificate, presentano un intervallo pi√π ampio rispetto alle pendenze trovate nel campione osservato. Inoltre, il valore medio della variabile dipendente \\(y\\) nel campione √® incluso nella distribuzione a priori. Questo suggerisce che le scelte delle distribuzioni a priori siano appropriate per il modello.\nAvendo determinato le distribuzioni a priori, eseguiamo il campionamento MCMC.\n\nwith Model() as model:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=50)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, beta, sigma]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 16 seconds.\n\n\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(idata, combined=True)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nNel contesto di un modello di regressione in cui i gruppi ‚Äúolder‚Äù e ‚Äúyounger‚Äù sono codificati rispettivamente come 0 e 1, la media del gruppo ‚Äúolder‚Äù pu√≤ essere interpretata come il valore di riferimento o l‚Äôintercetta del modello. In termini matematici, la media del gruppo ‚Äúolder‚Äù corrisponde al coefficiente Œ± (alpha) del modello di regressione. La differenza tra le medie dei due gruppi √® invece uguale al coefficiente beta.\nPer verificare, troviamo la media del gruppo ‚Äúolder‚Äù (codificato con x = 0).\n\nnp.mean(older)\n\n37.1\n\n\nCalcoliamo la differenza tra le medie dei due campioni.\n\nnp.mean(younger) - np.mean(older)\n\n7.399999999999999\n\n\nEsaminiamo ora le stime a posteriori dei due coefficienti del modello e gli intervalli di credibilit√† al 95%.\n\naz.summary(idata, hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n37.067\n2.260\n32.572\n41.284\n0.048\n0.034\n2210.0\n2191.0\n1.0\n\n\nbeta\n7.406\n3.250\n1.230\n14.012\n0.070\n0.050\n2142.0\n2151.0\n1.0\n\n\nsigma\n7.178\n1.278\n4.916\n9.771\n0.028\n0.020\n2183.0\n2007.0\n1.0\n\n\n\n\n\n\n\n\nI coefficienti alpha e beta nel modello di regressione assumono i valori previsti. L‚Äôintervallo di credibilit√† per il coefficiente beta pu√≤ essere interpretato nel seguente modo: si pu√≤ affermare con una certezza soggettiva del 95% che il gruppo ‚Äúyounger‚Äù tende ad avere una soddisfazione della vita che √® almeno 1.1 punti superiore e non pi√π di 14.1 punti superiore rispetto al gruppo ‚Äúolder‚Äù.\nUsiamo ora la funzione dedicata di PyMC per campionare le distribuzioni a posteriori per generare il posterior predictive check. La funzione sample_posterior_predictive estrarr√† casualmente 40000 campioni dei parametri del modello dalla traccia MCMC. Successivamente, per ogni campione, verranno estratti 100 numeri casuali da una distribuzione normale specificata dai valori di mu e sigma in quel campione:\n\nwith model:\n    pm.sample_posterior_predictive(idata, extend_inferencedata=True, random_seed=rng)\n\nSampling: [Y_obs]\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôoggetto xarray ‚Äúposterior_predictive‚Äù in ‚Äúidata‚Äù conterr√† ora 40000 insiemi di dati (ciascuno contenente 100 valori), i quali sono stati generati utilizzando una diversa configurazione dei parametri dalle distribuzioni a posteriori di alpha e beta:\n\nidata.posterior_predictive\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 648kB\nDimensions:      (chain: 4, draw: 1000, Y_obs_dim_2: 20)\nCoordinates:\n  * chain        (chain) int64 32B 0 1 2 3\n  * draw         (draw) int64 8kB 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999\n  * Y_obs_dim_2  (Y_obs_dim_2) int64 160B 0 1 2 3 4 5 6 ... 13 14 15 16 17 18 19\nData variables:\n    Y_obs        (chain, draw, Y_obs_dim_2) float64 640kB 56.93 45.38 ... 29.89\nAttributes:\n    created_at:                 2024-05-07T04:19:22.885544+00:00\n    arviz_version:              0.18.0\n    inference_library:          pymc\n    inference_library_version:  5.14.0xarray.DatasetDimensions:chain: 4draw: 1000Y_obs_dim_2: 20Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Y_obs_dim_2(Y_obs_dim_2)int640 1 2 3 4 5 6 ... 14 15 16 17 18 19array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19])Data variables: (1)Y_obs(chain, draw, Y_obs_dim_2)float6456.93 45.38 44.72 ... 47.46 29.89array([[[56.93119105, 45.38112552, 44.71705033, ..., 36.6533742 ,\n         26.7945236 , 43.70073916],\n        [48.59795404, 49.14921972, 36.26414691, ..., 33.9800401 ,\n         43.64123915, 27.04789784],\n        [46.20305509, 37.31314497, 24.9156855 , ..., 34.63748569,\n         43.68189988, 25.00128306],\n        ...,\n        [41.88456655, 46.6706999 , 42.15297999, ..., 33.78602401,\n         45.84205574, 30.18639455],\n        [42.50078136, 51.06733118, 58.90315575, ..., 25.58896962,\n         23.22293853, 36.39028755],\n        [37.25135731, 33.72155053, 49.35109368, ..., 38.50069572,\n         43.37827239, 40.12896516]],\n\n       [[69.89704936, 44.89150638, 35.56737805, ..., 40.56827667,\n         24.40992124, 38.77930154],\n        [41.05292868, 34.71488032, 44.81629245, ..., 42.46278301,\n         44.84971018, 50.22855624],\n        [47.57661051, 44.39864842, 34.75311598, ..., 37.36811349,\n         52.05518433, 60.44519465],\n...\n        [46.36530415, 46.82141194, 43.99908701, ..., 33.36542914,\n         38.30912878, 24.24702688],\n        [58.0412549 , 40.54760807, 44.01622446, ..., 17.3388618 ,\n         29.39961152, 36.3022488 ],\n        [45.5066708 , 40.26978451, 45.96019551, ..., 27.45048685,\n         31.34425973, 27.56274796]],\n\n       [[49.10864016, 50.6347884 , 33.25334531, ..., 41.79996363,\n         56.15275593, 32.58161595],\n        [61.01484177, 45.19326455, 47.63829417, ..., 48.95528758,\n         33.60197361, 36.22097782],\n        [46.69327667, 52.18230406, 43.11523761, ..., 27.3596807 ,\n         41.88385917, 38.33724321],\n        ...,\n        [44.95070411, 36.79029201, 46.02741174, ..., 24.30896316,\n         21.17478346, 30.58681844],\n        [44.15401203, 43.59896216, 50.40780036, ..., 45.82617659,\n         29.65260042, 20.27135168],\n        [40.78029668, 41.79302778, 37.94651275, ..., 30.31091397,\n         47.45717734, 29.89154143]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Y_obs_dim_2PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64', name='Y_obs_dim_2'))Attributes: (4)created_at :2024-05-07T04:19:22.885544+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.14.0\n\n\nPossiamo utilizzare questi dati per verificare se il modello √® in grado di riprodurre le caratteristiche osservate nel campione. Per fare ci√≤, possiamo utilizzare la funzione plot_ppc fornita da ArviZ:\n\naz.plot_ppc(idata, num_pp_samples=200);\n\n\n\n\n\n\n\n\nOsserviamo che i dati generati dal modello seguono l‚Äôandamento dei dati osservati, indicando che il modello √® adeguato per i dati considerati. Inoltre, notiamo che il modello produce campioni di dati molto diversi tra loro. Questa variazione √® coerente considerando che il campione osservato era di dimensioni ridotte e quindi vi √® un‚Äôampia incertezza associata alle caratteristiche dei campioni futuri.\nEseguiamo ora l‚Äôanalisi di regressione sugli stessi dati usando il metodo dei minimi quadrati. A questo fine usiamo la funzione linear_regression del modulo pingouin.\n\npg.linear_regression(df['x'], df['y'])\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n37.1\n2.110029\n17.582697\n8.790692e-13\n0.25465\n0.213242\n32.666994\n41.533006\n\n\n1\nx\n7.4\n2.984032\n2.479867\n2.326024e-02\n0.25465\n0.213242\n1.130782\n13.669218\n\n\n\n\n\n\n\n\nLa stima dei coefficienti √® altamente coerente con quella ottenuta utilizzando PyMC. L‚Äôintervallo di fiducia per il coefficiente b, che rappresenta la differenza tra le medie dei due gruppi, presenta una somiglianza notevole con l‚Äôintervallo di credibilit√† bayesiano.\nTuttavia, √® importante sottolineare che, anche se in questo caso specifico l‚Äôapproccio frequentista produce risultati simili all‚Äôapproccio bayesiano, non √® possibile generalizzare questa conclusione a tutti i casi. Le differenze tra i due approcci possono emergere in scenari diversi e richiedono un‚Äôanalisi caso per caso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#project-star",
    "href": "chapters/appendix/a60_ttest_exercises.html#project-star",
    "title": "Appendice T ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "T.3 Project Star",
    "text": "T.3 Project Star\nSvolgiamo ora un altro esercizio usando dei dati reali relativi al progetto Star. Il Project STAR (Student-Teacher Achievement Ratio) √® stato un grande esperimento educativo condotto negli Stati Uniti tra il 1985 e il 1990. L‚Äôobiettivo era quello di esaminare l‚Äôeffetto della dimensione delle classi sulla performance degli studenti. In particolare, gli studenti venivano assegnati in modo casuale a classi di piccole dimensioni (13-17 studenti) o grandi dimensioni (22-25 studenti).\nIl progetto coinvolse pi√π di 6.000 studenti e 1.000 insegnanti in 79 scuole elementari in Tennessee. I risultati dello studio indicarono che gli studenti assegnati a classi pi√π piccole hanno ottenuto risultati migliori in termini di performance accademica, partecipazione in classe, comportamento e assenze rispetto agli studenti assegnati a classi pi√π grandi.\nIn questo capitolo, analizziamo una parte dei dati del Project STAR. Come variabili abbiamo i punteggi ottenuti dagli studenti ai test standardizzati di lettura e matematica alla fine del terzo anno, insieme alla percentuale di studenti che hanno completato gli studi superiori.\nL‚Äôobiettivo dell‚Äôesercizio √® calcolare la media dell‚Äôeffetto causale della frequenza delle classi piccole rispetto alle classi di dimensioni standard sui punteggi dei test di lettura di terza elementare per tutta la popolazione target di studenti.\nLeggiamo i dati dal file STAR.csv.\n\ndf_star = pd.read_csv(\"../data/STAR.csv\")\ndf_star.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nLe medie dei due gruppi sono le seguenti.\n\ngroup_means = df_star.groupby('classtype')[\"reading\"].mean()\nprint(group_means)\n\nclasstype\nregular    625.492017\nsmall      632.702564\nName: reading, dtype: float64\n\n\nGeneriamo un violin plot per i punteggi nel test di lettura di terza elementare per i due gruppi.\n\nsns.violinplot(x=\"classtype\", y=\"reading\", data=df_star)\n\n\n\n\n\n\n\n\nL‚Äôipotesi nulla √® che i dati provengono da due popolazioni aventi la stessa media: \\(H_0: \\mu_1 - \\mu_2 = 0\\). Useremo un test bilaterale, ovvero rifiuteremo \\(H_0\\) sia quando il valore \\(T\\) cade nella regione di rifiuto perch√© \\(\\mu_1 &gt; \\mu_2 = 0\\), sia quando cade nella regione di rifiuto perch√© \\(\\mu_1 &lt; \\mu_2 = 0\\).\nPer semplicit√†, credo due DataFrame, uno per ciascun gruppo.\n\ndf_small = df_star[df_star['classtype'] == 'small']\ndf_regular = df_star[df_star['classtype'] == 'regular']\n\nSvolgo il test \\(t\\) di Student per due gruppi indipendenti con la funzione ttest.\n\nres = pg.ttest(df_small[\"reading\"], df_regular[\"reading\"], paired=False)\nprint(res)\n\n               T          dof alternative    p-val          CI95%   cohen-d  \\\nT-test  3.495654  1220.993525   two-sided  0.00049  [3.16, 11.26]  0.197183   \n\n          BF10     power  \nT-test  25.771  0.938789  \n\n\nInterpretazione. Avendo ottenuto un valore-p minore di \\(\\alpha\\), si conclude rifiutando l‚Äôipotesi nulla di uguaglianza delle due medie. Si presti per√≤ attenzione al \\(d\\) di Cohen: \\(d\\) = 0.20. Ci√≤ significa che la dimensione dell‚Äôeffetto √® piccola.\nSvolgiamo ora i calcoli passo-passo. Calcoliamo la differenza tra le medie dei due gruppi.\n\nmean_diff = np.mean(df_small[\"reading\"]) - np.mean(df_regular[\"reading\"])\nmean_diff\n\n7.210546686018347\n\n\nTroviamo i gradi di libert√† per la differenza tra due medie indipendenti.\n\nnum_rows = df_star.shape[0]\nnum_rows\n\n1274\n\n\n\ndof = 2 * num_rows - 2\ndof\n\n2546\n\n\nTroviamo il valore critico per un test bilaterale.\n\nt_c = st.t.ppf(0.975, dof)\nt_c\n\n1.9608961841574426\n\n\nSe non assumiamo che le due varianze siano uguali, allora l‚Äôerrore standard per la differenza tra le medie di due gruppi indipendenti √®\n\\[\n\\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\nse_diff = np.sqrt(\n    np.var(df_small[\"reading\"], ddof=1) / len(df_small[\"reading\"]) +\n    np.var(df_regular[\"reading\"], ddof=1) / len(df_regular[\"reading\"])\n    )\nse_diff\n\n2.0627173626882493\n\n\nTroviamo il valore della statistica \\(T\\).\n\nT = mean_diff / se_diff\nprint(T)\n\n3.4956542357413216\n\n\nTroviamo il valore-p.\n\n(1 - st.t.cdf(T, df=dof)) * 2\n\n0.0004809856733483109\n\n\nCalcoliamo ora l‚Äôintervallo di fiducia al 95% per la differenza tra le medie dei due gruppi:\n\\[\n(\\bar{X}_1 - \\bar{X}_2) \\pm t_{n_1 + n_2 - 2} \\cdot \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\npm = np.array([-1, +1])\nci = mean_diff + pm * (t_c * se_diff)\nprint(ci)\n\n[ 3.16577208 11.25532129]\n\n\nInterpretazione. Dai risultati ottenuti, si pu√≤ concludere che l‚Äôeffetto causale medio di frequentare una classe piccola sui punteggi dei test di lettura di terza elementare, per tutti gli studenti della popolazione target, √® probabilmente un aumento compreso tra 3.17 e 11.25 punti.\n\nT.3.1 Margine d‚Äôerrore\nEsiste un modo alternativo di esprimere gli intervalli di confidenza, che √® popolare nel mondo dei sondaggi. Coinvolge l‚Äôuso di ci√≤ che √® noto come ‚Äúmargine di errore‚Äù, definito come la met√† della larghezza dell‚Äôintervallo di confidenza. Utilizzando questo termine, possiamo esprimere l‚Äôintervallo di confidenza come:\n\\[\n\\text{stimatore} \\pm \\text{margine di errore.}\n\\]\nPer i dati presenti, possiamo dire che frequentare una classe piccola produce un incremento atteso di 7.21 ¬± 4.04 punti sui punteggi dei test di lettura di terza elementare. L‚Äôampiezza dell‚Äôintervallo di confidenza √® qui di 8.08 punti, quindi il margine di errore √® di 4.04 punti.\nSi deve notare la differenza concettuale tra il risultato espresso in termini di intervallo di confidenza o margine d‚Äôerrore, che rappresenta una differenza assoluta tra le medie dei due gruppi, e l‚Äôindice \\(d\\) di Cohen, il quale rappresenta una differenza relativa tra le medie dei due gruppi, ponderata in base all‚Äôincertezza della stima. In altre parole, mentre il margine d‚Äôerrore esprime la precisione della stima assoluta della differenza tra le medie, l‚Äôindice \\(d\\) di Cohen esprime la dimensione dell‚Äôeffetto relativo tra i due gruppi, tenendo conto della variazione naturale dei dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "href": "chapters/appendix/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "title": "Appendice T ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "T.4 Inferenza su una proporzione",
    "text": "T.4 Inferenza su una proporzione\nOccupiamoci ora dell‚Äôinferenza sulla proporzione di una popolazione. La teoria delle probabilit√† ci dice che il valore atteso della proporzione campionaria \\(\\hat{p}\\) √® la proporzione \\(p\\) della popolazione e che la deviazione standard della proporzione campionaria √® la deviazione standard della variabile casuale binomiale \\(Y\\) divisa per \\(n\\):\n\\[\\begin{align}\n\\mu_{\\hat p}&=\\frac{\\mu_Y}{n} = p \\\\\n\\sigma_{\\hat p} &=\\frac{\\sigma_Y}{n} = \\frac{\\sqrt{n \\cdot p \\cdot (1-p)}}{n} = \\sqrt{\\frac{p \\cdot (1-p)}{n}}\n\\end{align}\\]\nQuesto punto pu√≤ essere chiarito da una simulazione. Supponiamo di esaminare 10000 campioni casuali di ampiezza 10 estratti da una popolazione nella quale la probabilit√† di ‚Äúsuccesso‚Äù √® 0.6.\n\np = 0.6\nn = 10\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\nI primi 5 campioni sono i seguenti.\n\nY[0:5]\n\n[array([0, 0, 1, 1, 0, 1, 0, 1, 0, 1]),\n array([0, 0, 0, 1, 1, 1, 1, 0, 0, 1]),\n array([0, 1, 1, 1, 0, 1, 1, 0, 0, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0])]\n\n\n\n_ = plt.hist(np.sum(Y, axis=1), density=True)\n\n\n\n\n\n\n\n\nL‚Äôistogramma precedente √® un‚Äôapprossimazione empirica della distribuzione delle proporzioni campionarie di ampiezza 10 estratte da una popolazione con probabilit√† di successo uguale a 0.6.\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.5986799999999999\nValore teorico atteso: 0.6\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.154939528849161\nDeviazione standard teorica: 0.15491933384829668\n\n\nMan mano che aumenta il numero di campioni estratti dalla popolazione, i due valori diventano sempre pi√π simili.\nPer quel che riguarda la forma della distribuzione, come conseguenza del TLC possiamo dire che la distribuzione delle proporzioni campionarie tende sempre pi√π ad assumere una forma normale all‚Äôaumentare della dimensione dei campioni.\nPer mettere alla prova il TLC, consideriamo un caso estremo, ovvero una popolazione nella quale la probabilit√† di successo √® 0.03. Supponiamo che la numerosit√† campionaria sia uguale a 400.\n\np = 0.03\nn = 400\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.029917250000000003\nValore teorico atteso: 0.03\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.008587201373992577\nDeviazione standard teorica: 0.00852936105461599\n\n\n\nnp.mean(Y, axis=1)\n\narray([0.03  , 0.04  , 0.0275, ..., 0.045 , 0.0325, 0.035 ])\n\n\n\ny = np.mean(Y, axis=1)\nsns.distplot(y, bins=10, hist=True, kde=False, norm_hist=True, hist_kws={'edgecolor':'black'})\nx = np.linspace(0, 0.1, 1000)\ny = st.norm.pdf(x, np.mean(y), np.std(y))  # Normal density values\nplt.plot(x, y, 'r-', label='Normal Density')\n\n\n\n\n\n\n\n\n\nT.4.1 Brexit\nPrendiamo in considerazione un ulteriore relativo all‚Äôindagine BES condotta prima del referendum sulla Brexit del 2016 al fine di valutare l‚Äôopinione pubblica dell‚Äôintera popolazione del Regno Unito. Importiamo i dati.\n\nbes = pd.read_csv(\"../data/BES.csv\")\nbes.head()\n\n\n\n\n\n\n\n\n\nvote\nleave\neducation\nage\n\n\n\n\n0\nleave\n1.0\n3.0\n60\n\n\n1\nleave\n1.0\nNaN\n56\n\n\n2\nstay\n0.0\n5.0\n73\n\n\n3\nleave\n1.0\n4.0\n64\n\n\n4\ndon't know\nNaN\n2.0\n68\n\n\n\n\n\n\n\n\n\nbes.shape\n\n(30895, 4)\n\n\nEliminiamo le righe del DataFrame che contengono dati mancanti.\n\nbes_cleaned = bes.dropna()\nbes_cleaned.shape\n\n(25097, 4)\n\n\nCalcoliamo la proporzione di risposte ‚Äúleave‚Äù.\n\nbes_cleaned[\"leave\"].mean()\n\n0.47188907040682154\n\n\nL‚Äôoutput del sondaggio BES indica che il 47.19% dei partecipanti era a favore della Brexit. Tuttavia, non possiamo inferire da questo risultato che circa il 47% di tutti gli elettori del Regno Unito era a favore della Brexit, poich√© si tratta di un risultato a livello di campione. Per generalizzare a livello di popolazione, dobbiamo considerare la variabilit√† campionaria che introduce rumore nei nostri risultati.\nAbbiamo visto sopra che la distribuzione campionaria di una proporzione presenta le seguenti caratteristiche:\n\nLa media della distribuzione campionaria di una proporzione √® uguale alla proporzione della popolazione. Ci√≤ significa che in media, la proporzione dei valori del campione √® uguale alla proporzione della popolazione.\nLa deviazione standard della distribuzione campionaria di una proporzione √® calcolata come \\(\\sqrt{\\pi (1-\\pi) / n}\\), dove \\(\\pi\\) rappresenta la proporzione della popolazione e \\(n\\) √® la dimensione del campione. La deviazione standard rappresenta la dispersione dei valori del campione intorno alla proporzione della popolazione. Possiamo stimare l‚Äôerrore standard sostituendo \\(\\pi\\) con \\(p\\), la proporzione campionaria.\nLa distribuzione campionaria di una proporzione tende alla normale se la dimensione del campione √® grande.\n\nPer fare inferenze sul parametro \\(\\pi\\) della popolazione (la proporzione di elettori del Regno Unito a favore della Brexit nel 2016), possiamo costruire un intervallo di confidenza al 95% per la proporzione nella popolazione.\nPer iniziare il calcolo dell‚Äôintervallo di confidenza, dobbiamo prima determinare la dimensione del campione.\n\nn = bes_cleaned.shape[0]\nn\n\n25097\n\n\nPossiamo stimare l‚Äôerrore standard di una proporzione con la formula $ SE = . $\n\np = bes_cleaned[\"leave\"].mean()\nse = np.sqrt(p * (1 - p) / n)\nprint(se)\n\n0.0031511685382488307\n\n\nTroviamo il limite inferiore e il limite superiore dell‚Äôintervallo di fiducia al 95%.\n\npm = np.array([-1, +1])\nci = np.mean(bes_cleaned[\"leave\"]) + pm * st.norm.ppf(0.975) * se\nprint(f\"L'intervallo di fiducia al 95% √® [{ci[0]:.4f}, {ci[1]:.4f}].\")\n\nL'intervallo di fiducia al 95% √® [0.4657, 0.4781].\n\n\nSecondo l‚Äôapproccio frequentista, √® possibile affermare che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era compresa con una probabilit√† del 95% tra il 46.57% e il 47.81%. Questo intervallo di confidenza √® stato ottenuto mediante una procedura di stima con un livello di confidenza del 95%, il quale indica la probabilit√† che l‚Äôintervallo contenga il vero valore del parametro.\nInoltre, il margine di errore, che rappresenta la met√† della larghezza dell‚Äôintervallo di confidenza, √® di 0.62 punti percentuali. Ci√≤ significa che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era probabilmente del 47.19%, con un margine di errore di 0.62 punti percentuali.\nSi noti che il margine di errore dipende dalla dimensione del campione. Nel caso del sondaggio BES, che ha una grande dimensione del campione di 25097 osservazioni, il margine di errore √® relativamente piccolo. Tuttavia, per la maggior parte dei sondaggi che hanno una dimensione del campione molto pi√π piccola, di circa 1000 osservazioni, il margine di errore sar√† molto pi√π grande. In generale, all‚Äôaumentare della dimensione del campione, la larghezza dell‚Äôintervallo di confidenza diminuisce, e viceversa.\n\n\nT.4.2 Supporto per la Brexit ed et√†\nCon i dati del sondaggio BES facciamo un altro esempio relativo al confronto tra due medie indipendenti. Nello specifico, esamineremo la differenza d‚Äôet√† tra gli elettori che hanno espresso supporto per la Brexit e quelli che invece hanno sostenuto la posizione ‚Äústay‚Äù.\n\nsns.violinplot(x=\"leave\", y=\"age\", data=bes)\n\n\n\n\n\n\n\n\nIl violin plot rivela che l‚Äôet√† media dei sostenitory della posizione ‚Äúleave‚Äù √® pi√π alta dell‚Äôet√† media del gruppo ‚Äústay‚Äù. Si noti per√≤ che le due distribuzioni non sembrano gaussiane.\nPer verificare l‚Äôipotesi di gaussianit√† dei dati, usiamo un QQ-plot (Quantile-Quantile plot). Un QQ-plot √® uno strumento grafico utilizzato per verificare se una distribuzione di dati segue o meno una distribuzione teorica, come ad esempio una distribuzione normale. In pratica, un QQ-plot confronta i quantili di una distribuzione di dati con quelli di una distribuzione teorica, disegnando un grafico dei quantili teorici lungo l‚Äôasse x e dei quantili dei dati lungo l‚Äôasse y. Se i dati seguono la distribuzione teorica, allora i punti nel QQ-plot si distribuiranno lungo una linea retta. Se invece ci sono deviazioni dalla distribuzione teorica, i punti nel QQ-plot si discosteranno dalla retta e si potr√† individuare in che punto si verificano le maggiori deviazioni.\n\nax = pg.qqplot(bes[\"age\"], dist=\"norm\")\n\n\n\n\n\n\n\n\nSi pu√≤ osservare dal QQ-plot che i valori di et√† estremi della distribuzione differiscono marcatamente dalle corrispondenti aspettative teoriche. Solo per fare un esecizio, proseguiamo comunque con l‚Äôanalisi dei dati e applichiamo il test t di Student ai due gruppi d‚Äôet√†. Si noti per√≤ che, per dati non normali, una tale procedura di analisi statistica √® inappropriata.\nPossiamo anche visualizzare i dati dei due gruppi tramite un KDE plot (da notare che questa rappresentazione √® gi√† inclusa nel violin plot precedente).\n\nsns.kdeplot(data=bes, x=\"age\", hue=\"leave\")\n\n\n\n\n\n\n\n\nPer agevolare il test t di Student, dividiamo il DataFrame originale in due DataFrame distinti.\n\nleave_df = bes[bes[\"leave\"] == 1]\nstay_df = bes[bes[\"leave\"] == 0]\n\nL‚Äôipotesi nulla che viene sottoposta a verifica con il test t di Student √® l‚Äôuguaglianza delle medie dei valori dell‚Äôet√† nelle due popolazioni da cui i campioni sono stati estratti: \\(H_0: \\mu_{\\text{leave}} = \\mu_{\\text{stay}}\\). Il test t di Student pu√≤ essere facilmente eseguito utilizzando la funzione ttest del pacchetto pingouin.\n\nres = pg.ttest(leave_df[\"age\"], stay_df[\"age\"], paired=False)\nprint(res)\n\n                T           dof alternative  p-val         CI95%   cohen-d  \\\nT-test  41.588603  27738.840259   two-sided    0.0  [7.63, 8.38]  0.495062   \n\n       BF10  power  \nT-test  inf    1.0  \n\n\nSvolgiamo ora i calcoli applicando la formula del test t di Student. La statistica \\(t\\) di Student per la differenza tra le medie di due campioni indipendenti √®\n\\[T = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}},\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}2\\) sono le medie dei due campioni, \\(s^2_1\\) e \\(s^2_2\\) sono le varianze dei due campioni e \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\n\nn_l = leave_df.shape[0]\nn_l\n\n13692\n\n\n\nn_s = stay_df.shape[0]\nn_s\n\n14352\n\n\n\nn_l + n_s - 2\n\n28042\n\n\nCalcoliamo l‚Äôerrore standard della differenza delle medie di due campioni indipendenti.\n\nse = np.sqrt(\n    (np.var(leave_df[\"age\"], ddof=1) / n_l) + \n    (np.var(stay_df[\"age\"], ddof=1) / n_s)\n) \nse\n\n0.19250126816432642\n\n\nTroviamo la statistica t di Student.\n\nT = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) / se\n\nTroviamo il valore-p con la funzione t.sf che calcola l‚Äôarea sottesa alla funzione \\(t\\) nella coda di destra. √à importante notare che le funzioni Python che abbiamo utilizzato in precedenza calcolano i gradi di libert√† in modo diverso rispetto alla formula \\(n_1+n_2-2\\). Infatti, il numero di gradi di libert√† calcolato come \\(n_1+n_2-2\\) √® appropriato solo quando le varianze delle due popolazioni sono uguali. Se le varianze sono diverse, √® necessario introdurre un fattore di correzione, che viene calcolato mediante software. Tuttavia, per questo esercizio, procederemo con \\(n_1+n_2-2\\), poich√© per un valore \\(t\\) cos√¨ estremo non fa alcuna differenza.\n\n2 * st.t.sf(T, df = n_l + n_s - 2)\n\n0.0\n\n\nPoniamoci ora l‚Äôobiettivo di trovare l‚Äôintervallo di fiducia per la differenza tra le due medie. Iniziamo a trovare il valore critico della distribuzione \\(t\\) corrispondente al livello di significativit√† scelto.\n\nt_c = st.t.ppf(0.975, df=n_l + n_s - 2)\nt_c\n\n1.9600485852064147\n\n\nPossiamo ora trovare l‚Äôintervallo di fiducia.\n\npm = np.array([-1, +1])\nci = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) + pm * t_c * se\nprint(f\"L'intervallo di fiducia al 95% √® [{ci[0]:.2f}, {ci[1]:.2f}].\")\n\nL'intervallo di fiducia al 95% √® [7.63, 8.38].\n\n\nIn conclusione, l‚Äôintervallo di confidenza al 95% per la differenza di et√† media tra i sostenitori della Brexit e coloro che sostenevano la posizione ‚Äòstay‚Äô √® [7.63, 8.38]. Ci√≤ significa che, utilizzando una procedura di stima corretta nel 95% dei casi, ci si aspetta che l‚Äôet√† media dei sostenitori della Brexit sia 8 anni superiore a quella dei sostenitori della posizione ‚Äòstay‚Äô, con un‚Äôincertezza di +/- 0.375 anni.\n\nnp.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])\n\n8.00585876624487\n\n\n\n(8.38 - 7.63) / 2\n\n0.37500000000000044",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html",
    "href": "chapters/appendix/a70_predict_counts.html",
    "title": "Appendice U ‚Äî La predizione delle frequenze",
    "section": "",
    "text": "U.1 La ricerca sul trauma\nPer fare un esempio di questo approccio, in questo capitolo faremo riferimento alla ricerca sul trauma. In questo campo di ricerca, come in altri, il risultato di interesse pu√≤ essere rappresentato dalla frequenza del numero di episodi che si verificano in un dato periodo di tempo. Nel caso della ricerca sulla violenza domestica, ad esempio, potremmo esaminare il tasso di atti aggressivi durante l‚Äôintervallo tra un momento temporale di baseline e un‚Äôintervista di follow-up. Altri esempi di risultati esprimibili in termini di frequenze nalla ricerca post-traumatica includono la frequenza dell‚Äôabuso di sostanze durante un periodo di osservazione o il numero di interventi della polizia durante un dato periodo.\nNell‚Äôesempio seguente esamineremo l‚Äôuso della predizione bayesiana per predire il numero di aggressioni nei confronti del partner nelle relazioni di coppia. I dati presentati sono tratti da uno studio che esamina la frequenza di episodi di aggressione messi in atto da pazienti di sesso maschile che avevano recentemente iniziato un programma di trattamento dell‚Äôalcol nei confronti del loro partner di sesso femminile.\nLa frequenza degli episodi di violenza, cos√¨ come altri fenomeni quantificabili in termini di frequenze assolute, pu√≤ essere modellata da un processo di Poisson, che si basa sul presupposto che gli eventi siano casuali e abbiano la stessa probabilit√† di verificarsi in qualsiasi momento. Naturalmente, questa ipotesi non √® sempre valida, ma spesso √® sufficiente per la modellazione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-priori",
    "href": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-priori",
    "title": "Appendice U ‚Äî La predizione delle frequenze",
    "section": "U.2 La distribuzione a priori",
    "text": "U.2 La distribuzione a priori\nIn una ricerca sui pazienti che avevano recentemente iniziato un programma di trattamento per l‚Äôabuso o la dipendenza da alcol, {cite:t}gagnon2008poisson hanno trovato che, in un periodo di 6 mesi, il numero di assalti fisici da parte dei pazienti di genere maschile nei confronti del loro partner femminile √® uguale, in media, a 11.46 (\\(SD\\) = 25.79; \\(n\\) = 114).\nPer questi dati, √® dunque sensato pensare che la distribuzione del numero di episodi di aggressione fisica pu√≤ essere rappresentata dalla distribuzione esponenziale.\nDal punto di vista statistico, ricordiamo che la distribuzione esponenziale modella il numero di eventi che si verificano in un intervallo di tempo quando questi eventi si verificano raramente e indipendentemente l‚Äôuno dall‚Äôaltro.\nLa funzione di densit√† di probabilit√† della distribuzione esponenziale √® data da:\n\\[\nf(x) = Œªe^{(-Œªx)}\n\\]\ndove Œª √® il parametro della distribuzione e rappresenta il tasso medio di occorrenza degli eventi. La media e la varianza della distribuzione esponenziale sono entrambe uguali a 1/Œª.\nPoniamoci dunque il problema di rappresentare le nostre credenze a priori relative al numero di episodi di aggressione fisica mediante una distribuzione esponenziale.\nDalla ricerca di {cite:t}gagnon2008poisson sappiamo che, in un periodo di 6 mesi, il numero di assalti fisici nei confronti del partner femminile, in questa popolazione, √® uguale a 11.46.\nConsidereremo una distribuzione esponenziale per rappresentare le nostre credenze a priori circa la frequenza media \\(\\mu\\) degli episodi di aggressione nei confronti del partner per questa popolazione, in un periodo di 6 mesi. In Python, scipy.stats.expon √® un modulo che fornisce funzioni per lavorare con la distribuzione esponenziale. In particolare, la funzione pdf (probability density function) calcola la funzione di densit√† di probabilit√† della distribuzione esponenziale per un dato valore di x.\nLa sintassi per utilizzare questa funzione √® la seguente:\nscipy.stats.expon.pdf(x, loc=0, scale=1)\ndove x √® il valore per il quale si vuole calcolare la funzione di densit√† di probabilit√†. Il parametro loc(opzionale) e scale specificano rispettivamente la posizione e la scala della distribuzione. La posizione (loc) di solito √® impostata a 0, mentre la scala (scale) √® l‚Äôinverso del parametro Œª della distribuzione esponenziale. In altre parole, la scala √® uguale alla media della distribuzione esponenziale.\nPer il caso presente, dunque, se vogliamo che la distribuzione esponenziale abbia una media di 11.46, procediamo come indicato sotto\n\nx = np.linspace (0, 50, 100) \ny = st.expon.pdf(x, 0, 11.46)\nplt.plot(x, y);\n\n\n\n\n\n\n\n\nPer verificare che abbiamo implementato correttamente la funzione esponenziale con il parametro voluto, estraiamo un grande numero di realizzazioni della v.c. e calcoliamo la media.\n\nr = st.expon.rvs(0, 11.46, size=100000)\nr.mean()\n\n11.438957034038369",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#inferenza-bayesiana",
    "href": "chapters/appendix/a70_predict_counts.html#inferenza-bayesiana",
    "title": "Appendice U ‚Äî La predizione delle frequenze",
    "section": "U.3 Inferenza bayesiana",
    "text": "U.3 Inferenza bayesiana\nUna volta capito come descrivere le nostre credenze a priori, poniamoci il problema di usare PyMC per l‚Äôinferenza Bayesiana.\nConsideriamo un singlo individuo di genere maschile appartenente a questa popolazione. Se, in media, in 6 mesi ci aspettiamo un numero di episodi di violenza pari a 11.46, possiamo descrivere il numero di episodi di violenza per un singolo individuo con la seguente distribuzione esponenziale. Si noti che, in questo caso, la funzione pm.Exponential √® parametrizzata usando il parametro l che √® uguale a \\(\\lambda = 1/ \\mu\\).\n\nl = 1/11.46\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    idata = pm.sample_prior_predictive(samples=10000, random_seed=rng)\n\nSampling: [mu]\n\n\nEsaminiamo 10000 campioni casuali estratti dalla distribuzione a priori. Il risultato √® simile alla distribuzione di densit√† teorica rappresentata nel grafico precedente.\n\n_ = az.plot_posterior(idata.prior.mu);\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, stiamo usando una distribuzione a priori informativa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-verosimiglianza",
    "href": "chapters/appendix/a70_predict_counts.html#la-verosimiglianza",
    "title": "Appendice U ‚Äî La predizione delle frequenze",
    "section": "U.4 La verosimiglianza",
    "text": "U.4 La verosimiglianza\nAdesso inseriamo nel modello PyMC la verosimiglianza.\nIn questo caso, usiamo quale modello generativo dei dati una distribuzione di Poisson.\nLe distribuzioni di Poisson sono usate per modellare il numero di eventi rari che si verificano in un intervallo di tempo fisso. Ad esempio, il numero di episodi di comportamento inappropriato per settimana in individui con disturbi alimentari, nascite in un giorno o incidenti in una settimana.\nLa verosimiglianza di Poisson √® simile a quella binomiale, ma non ha un limite superiore al numero di successi.\nPer esempio, consideriamo un paziente chiamato Mario. Usando gli item della sottoscala relativa agli episodi di violenza fisica della Conflict Tactics Scales-2, troviamo che Mario ha avuto 8 episodi violenti nei confronti del partner negli ultimi 6 mesi.\nInseriamo questa informazione nel modello bayesiano usando 8 come dato che specifica una verosimiglianza di Poisson con parametro sconosciuto mu, a cui abbiamo attribuito una distribuzione a priori esponenziale ed eseguiamo il campionamento.\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    episodes = pm.Poisson(\"episodes\", mu, observed=8)\n    idata2 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 11 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "href": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "title": "Appendice U ‚Äî La predizione delle frequenze",
    "section": "U.5 La distribuzione a posteriori",
    "text": "U.5 La distribuzione a posteriori\nEstraiamo dall‚Äôoggetto idata2 i campioni della distribuzione a posteriori del parametro mu (media del numero di episodi di violenza negli ultimi 6 mesi).\n\nsample_posterior = idata2.posterior['mu']\n\nGeneriamo un grafico della distribuzione a posteriori del parametro mu.\n\naz.plot_posterior(sample_posterior)\n\n\n\n\n\n\n\n\nPossiamo dunque concludere, con un livello di certezza soggettiva del 94%, che per Mario, il numero di episodi di violenza nei confronti del partner varier√† da un minimo di 3.5 ad un massimo di 13, in un periodo di 6 mesi, con una media di 8.2.\nSupponiamo ora di volere confrontare due individui, Mario e Paolo. Di Mario abbiamo osservato 8 episodi di violenza in 6 mesi; di Paolo abbiamo osservato 12 episodi di violenza negli ultimi 6 mesi. Possiamo dire che Paolo √® pi√π violento di Mario? Oppure dobbiamo pensare che la differenza tra i due sia solo una fluttuazione casuale?\nScriviamo il modello bayesiano nel modo seguente, usando sempre la distribuzione a priori che abbiamo definito in precedenza.\n\nwith pm.Model() as model3:\n    mu_A = pm.Exponential(\"mu_A\", l)\n    mu_B = pm.Exponential(\"mu_B\", l)\n    episodes_A = pm.Poisson(\"episodes_A\", mu_A, observed=[8])\n    episodes_B = pm.Poisson(\"episodes_B\", mu_B, observed=[12])\n    idata3 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu_A, mu_B]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 36 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nEsaminiamo le distribuzioni a posteriori dei parametri mu_A e mu_B che rappresentano la media del numero di episodi di violenza per i due individui.\n\nwith model3:\n    az.plot_trace(idata3, kind=\"rank_bars\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nEstraiamo le distribuzioni a posteriori dei due parametri da idata3.\n\nmu_A = idata3.posterior['mu_A']\nmu_B = idata3.posterior['mu_B']\nmu_B.mean(), mu_A.mean()\n\n(&lt;xarray.DataArray 'mu_B' ()&gt;\n array(11.98949309),\n &lt;xarray.DataArray 'mu_A' ()&gt;\n array(8.26997179))\n\n\nRappresentiamo graficamente le due distribuzioni a posteriori.\n\naz.plot_posterior(mu_A)\naz.plot_posterior(mu_B);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVogliamo eseguire un test di ipotesi bayesiano per determinare la probabilit√† che la media del numero di episodi di violenza di Mario sia maggiore di quella di Paolo. Per fare ci√≤, calcoliamo quante volte mu_B √® maggiore di mu_A nelle due distribuzioni a posteriori.\n\n(mu_B &gt; mu_A).mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0.808)xarray.DataArray0.808array(0.808)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nPossiamo dunque dire che, se confrontiamo i valori dei parametri delle due distribuzioni a posteriori, nell‚Äô81% di casi risulta che Paolo √® pi√π violento di Mario.\nIl grafico seguente mostra le stime degli intervalli di credibilit√† del 94% per ciascuna delle 4 catene, pe i due parametri.\n\n_ = az.plot_forest(idata3, var_names=[\"mu_A\", \"mu_B\"])\n\n\n\n\n\n\n\n\nDato che gli intervalli di credibilit√† sono sovrapposti, concludiamo che non ci sono evidenze credibili di una differenza. Ovvero, sulla base delle nostre credenze a priori e sulla base dei dati osservati, ad un livello di certezza soggettiva del 94%, non possiamo concludere che Paolo sia pi√π violento di Mario.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "href": "chapters/appendix/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "title": "Appendice U ‚Äî La predizione delle frequenze",
    "section": "U.6 La predizione di episodi di violenza futuri",
    "text": "U.6 La predizione di episodi di violenza futuri\nConsideriamo ora il problema della predizione di dati futuri. Utilizziamo nuovamente il modello che abbiamo gi√† usato in precedenza, ovvero model3.\nCreiamo la distribuzione predittiva a posteriori per il parametro mu_A, ovvero la media del numero di eventi di violenza attesi in futuro per Mario.\n\nwith model3:\n    post_pred = pm.sample_posterior_predictive(idata3)\n\nSampling: [episodes_A, episodes_B]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n\npost_pred\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (chain: 4, draw: 2000, episodes_A_dim_2: 1,\n                       episodes_B_dim_2: 1)\nCoordinates:\n  * chain             (chain) int64 0 1 2 3\n  * draw              (draw) int64 0 1 2 3 4 5 ... 1994 1995 1996 1997 1998 1999\n  * episodes_A_dim_2  (episodes_A_dim_2) int64 0\n  * episodes_B_dim_2  (episodes_B_dim_2) int64 0\nData variables:\n    episodes_A        (chain, draw, episodes_A_dim_2) int64 1 4 12 ... 6 10 11\n    episodes_B        (chain, draw, episodes_B_dim_2) int64 18 13 4 ... 14 14 17\nAttributes:\n    created_at:                 2023-10-27T04:56:02.607337\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:chain: 4draw: 2000episodes_A_dim_2: 1episodes_B_dim_2: 1Coordinates: (4)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([   0,    1,    2, ..., 1997, 1998, 1999])episodes_A_dim_2(episodes_A_dim_2)int640array([0])episodes_B_dim_2(episodes_B_dim_2)int640array([0])Data variables: (2)episodes_A(chain, draw, episodes_A_dim_2)int641 4 12 14 7 4 1 ... 9 13 11 6 10 11array([[[ 1],\n        [ 4],\n        [12],\n        ...,\n        [ 6],\n        [13],\n        [ 7]],\n\n       [[12],\n        [12],\n        [ 4],\n        ...,\n        [ 4],\n        [ 6],\n        [15]],\n\n       [[ 9],\n        [ 4],\n        [ 8],\n        ...,\n        [ 9],\n        [ 5],\n        [12]],\n\n       [[22],\n        [ 3],\n        [ 7],\n        ...,\n        [ 6],\n        [10],\n        [11]]])episodes_B(chain, draw, episodes_B_dim_2)int6418 13 4 6 10 8 ... 9 22 7 14 14 17array([[[18],\n        [13],\n        [ 4],\n        ...,\n        [13],\n        [10],\n        [18]],\n\n       [[ 7],\n        [11],\n        [ 6],\n        ...,\n        [ 5],\n        [13],\n        [ 4]],\n\n       [[ 8],\n        [ 5],\n        [22],\n        ...,\n        [16],\n        [11],\n        [14]],\n\n       [[20],\n        [10],\n        [12],\n        ...,\n        [14],\n        [14],\n        [17]]])Indexes: (4)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='draw', length=2000))episodes_A_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_2'))episodes_B_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_2'))Attributes: (4)created_at :2023-10-27T04:56:02.607337arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (episodes_A_dim_0: 1, episodes_B_dim_0: 1)\nCoordinates:\n  * episodes_A_dim_0  (episodes_A_dim_0) int64 0\n  * episodes_B_dim_0  (episodes_B_dim_0) int64 0\nData variables:\n    episodes_A        (episodes_A_dim_0) int64 8\n    episodes_B        (episodes_B_dim_0) int64 12\nAttributes:\n    created_at:                 2023-10-27T04:56:02.610237\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:episodes_A_dim_0: 1episodes_B_dim_0: 1Coordinates: (2)episodes_A_dim_0(episodes_A_dim_0)int640array([0])episodes_B_dim_0(episodes_B_dim_0)int640array([0])Data variables: (2)episodes_A(episodes_A_dim_0)int648array([8])episodes_B(episodes_B_dim_0)int6412array([12])Indexes: (2)episodes_A_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_0'))episodes_B_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_0'))Attributes: (4)created_at :2023-10-27T04:56:02.610237arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n              \n            \n            \n\n\nRappresentiamo la distribuzione predittiva a posteriori di mu_A con un istogramma.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_A, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per Paolo.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_B, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nIn base alle nostre credenze precedenti e ai dati osservati negli ultimi 6 mesi, possiamo aspettarci con una certezza soggettiva del 94% che nei prossimi 6 mesi Mario avr√† tra 1 e 15 episodi di violenza, mentre Paolo ne avr√† tra 3 e 20.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a100_solutions.html",
    "href": "chapters/appendix/a100_solutions.html",
    "title": "Appendice V ‚Äî Soluzioni degli Esercizi",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 72\nEsercizio¬†72.1\n\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\n\n\n# Calcoliamo l'entropia di $p$.\nh_p = -np.sum(p * np.log(p))\nprint(\"Entropia di p: \", h_p)\n\nEntropia di p:  1.0296530140645737\n\n\n\n# Calcoliamo l'entropia incrociata tra $p$ e $q$.\nh_pq = -np.sum(p * np.log(q))\nprint(\"Entropia incrociata tra p e q: \", h_pq)\n\nEntropia incrociata tra p e q:  1.372238457997479\n\n\n\n# Calcoliamo la divergenza di Kullback-Leibler da $p$ a $q$.\nkl_pq = h_pq - h_p\nprint(\"Divergenza KL da p a q: \", kl_pq)\n\nDivergenza KL da p a q:  0.34258544393290524\n\n\n\n# Lo stesso risultato si ottiene applicando la formula della Divergenza $\\mathbb{KL}$.\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.3425854439329054\n\n\n\n# Se invece $q$ √® molto simile a $p$, la differenza $\\mathbb{KL}$ √® molto minore.\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.2, 0.55, 0.25])\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.007041377136023895\n\n\nEsercizio¬†72.2\n\n# Define the parameters\nn = 4\np = 0.2\n\n# Compute the probability mass function\ntrue_py = stats.binom.pmf(range(n + 1), n, p)\nprint(true_py)\n\n[0.4096 0.4096 0.1536 0.0256 0.0016]\n\n\n\nq1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01])\nprint(q1)\n\n[0.46 0.42 0.1  0.01 0.01]\n\n\n\nq2 = [0.2] * 5\nprint(q2)\n\n[0.2, 0.2, 0.2, 0.2, 0.2]\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_1$ da $p$ √®\nkl_pq1 = np.sum(true_py * (np.log(true_py) - np.log(q1)))\nprint(\"Divergenza KL di q1 da p: \", kl_pq1)\n\nDivergenza KL di q1 da p:  0.02925199033345882\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_2$ da $p$ √®:\nkl_pq2 = np.sum(true_py * (np.log(true_py) - np.log(q2)))\nprint(\"Divergenza KL di q2 da p: \", kl_pq2)\n\nDivergenza KL di q2 da p:  0.48635777871415425\n\n\n√à chiaro che perdiamo una quantit√† maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anzich√© \\(q_1\\).\nEsercizio¬†72.3\n\n# Definire le distribuzioni p e q\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\n\n# Calcolo dell'entropia di p\nh_p = -np.sum(p * np.log(p))\n\n# Calcolo dell'entropia incrociata da p a q\nh_pq = -np.sum(p * np.log(q))\n\n# Calcolo della divergenza KL da p a q\nkl_pq = h_pq - h_p\n\n# Calcolo dell'entropia di q\nh_q = -np.sum(q * np.log(q))\n\n# Calcolo dell'entropia incrociata da q a p\nh_qp = -np.sum(q * np.log(p))\n\n# Calcolo della divergenza KL da q a p\nkl_qp = h_qp - h_q\n\nprint(f\"Entropia di p: {h_p}\")\nprint(f\"Entropia incrociata da p a q: {h_pq}\")\nprint(f\"Divergenza KL da p a q: {kl_pq}\")\n\nprint(f\"\\nEntropia di q: {h_q}\")\nprint(f\"Entropia incrociata da q a p: {h_qp}\")\nprint(f\"Divergenza KL da q a p: {kl_qp}\")\n\nEntropia di p: 0.056001534354847345\nEntropia incrociata da p a q: 1.1954998257220641\nDivergenza KL da p a q: 1.1394982913672167\n\nEntropia di q: 0.6108643020548935\nEntropia incrociata da q a p: 3.226634230947714\nDivergenza KL da q a p: 2.6157699288928207",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>Soluzioni degli Esercizi</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/05_bayes_theorem.html#commenti-e-considerazioni-finali",
    "title": "26¬† Il teorema di Bayes",
    "section": "27.5 Commenti e Considerazioni Finali",
    "text": "27.5 Commenti e Considerazioni Finali\nIn questo capitolo abbiamo analizzato vari esempi nel campo medico e forense, dimostrando come il teorema di Bayes consenta di combinare le informazioni provenienti dalle osservazioni con le nostre conoscenze precedenti (priori) per aggiornare il nostro grado di convinzione rispetto a un‚Äôipotesi. Il teorema di Bayes offre un meccanismo razionale, noto come ‚Äúaggiornamento bayesiano‚Äù, per ricalibrare le nostre convinzioni iniziali in risposta a nuove evidenze.\nIl teorema di Bayes ci insegna che, nella ricerca scientifica come nella vita quotidiana, non siamo tanto interessati a conoscere la probabilit√† che qualcosa accada assumendo vera un‚Äôipotesi. Siamo invece interessati alla domanda opposta: qual √® la probabilit√† che un‚Äôipotesi sia vera, dato che abbiamo osservato una certa evidenza?\nIn questo capitolo, ci siamo concentrati sull‚Äôanalisi del teorema di Bayes utilizzando probabilit√† puntuali. Tuttavia, vedremo in seguito che il teorema di Bayes esprime pienamente il suo potenziale esplicativo quando l‚Äôevidenza e i gradi di certezza a priori delle ipotesi sono rappresentati in termini di distribuzioni di probabilit√† continue. Questo sar√† l‚Äôargomento del Capitolo 37.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#revisione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#revisione",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.1 Revisione",
    "text": "37.1 Revisione\nPrima di esplorare il flusso di lavoro bayesiano, √® utile rivisitare il teorema di Bayes nelle sue diverse forme.\nPer eventi discreti osservabili, il teorema di Bayes si esprime come:\n\\[ P(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)} \\]\nDove \\(P(A|B)\\) √® la probabilit√† dell‚Äôevento A dato che si √® verificato l‚Äôevento B.\nTuttavia, in molte applicazioni statistiche, siamo interessati a stimare parametri continui basandoci su dati osservati. In questo contesto, passiamo dalla notazione per probabilit√† discrete a quella per distribuzioni di probabilit√†. Consideriamo un vettore di dati osservati \\(y\\) e un vettore di parametri \\(\\theta\\). Il teorema di Bayes pu√≤ essere riformulato come:\n\\[ p(\\theta | y) = \\frac{p(y | \\theta) \\cdot p(\\theta)}{p(y)} \\]\nDove: - \\(p(\\cdot)\\) rappresenta una funzione di densit√† di probabilit√† (per variabili continue) o una funzione di massa di probabilit√† (per variabili discrete). - \\(p(\\theta | y)\\) √® la distribuzione posteriore dei parametri dato i dati. - \\(p(y | \\theta)\\) √® la funzione di verosimiglianza. - \\(p(\\theta)\\) √® la distribuzione a priori dei parametri. - \\(p(y)\\) √® la verosimiglianza marginale.\nQuesta formulazione pu√≤ essere interpretata verbalmente come:\n\\[\n\\text{Posteriore} = \\frac{\\text{Verosimiglianza} \\times \\text{A Priori}}{\\text{Verosimiglianza Marginale}}\n\\]\nApprofondiamo il significato di ciascun termine:\n\nPosteriore \\(p(\\theta | y)\\): √à la distribuzione di probabilit√† dei parametri condizionata ai dati osservati. Rappresenta la nostra conoscenza aggiornata sui parametri dopo aver considerato i dati.\nVerosimiglianza \\(p(y | \\theta)\\): Come discusso nel capitolo sulla verosimiglianza, questa √® la probabilit√† (o densit√†) dei dati osservati, espressa come funzione dei parametri \\(\\theta\\).\nA Priori \\(p(\\theta)\\): √à la distribuzione di probabilit√† iniziale dei parametri, prima di osservare i dati. Pu√≤ basarsi su conoscenze pregresse o assumere forme non informative per minimizzare l‚Äôinfluenza sulle inferenze.\nVerosimiglianza Marginale \\(p(y)\\): Questo termine normalizza la distribuzione posteriore, assicurando che integri a 1 e sia quindi una distribuzione di probabilit√† valida. Si calcola come:\n\\[ p(y) = \\int p(y | \\theta) p(\\theta) d\\theta \\]\n\nNell‚Äôinferenza bayesiana, utilizziamo le distribuzioni posteriori dei parametri per varie forme di inferenza, come il calcolo di intervalli di credibilit√†.\nLe distribuzioni a priori \\(p(\\theta)\\) giocano un ruolo cruciale, specialmente con campioni di dati piccoli, dove possono stabilizzare le stime riducendo l‚Äôimpatto delle fluttuazioni campionarie.\nNel processo di modellazione, consideriamo una variabile casuale \\(Y\\), di cui osserviamo una realizzazione \\(y\\). Ad esempio, \\(Y\\) potrebbe rappresentare il punteggio di uno studente in un test, con \\(y\\) il punteggio effettivamente osservato. Il modello probabilistico che specifica come \\(y\\) viene generato √® noto come processo generatore di dati (DGP).\nIl parametro \\(\\theta\\) caratterizza questo modello probabilistico e pu√≤ essere uno scalare (es. media) o un vettore (es. coefficienti di regressione). L‚Äôobiettivo dell‚Äôinferenza statistica √® stimare questi parametri dai dati. A differenza dell‚Äôapproccio frequentista, che considera \\(\\theta\\) fisso ma sconosciuto, l‚Äôapproccio bayesiano tratta \\(\\theta\\) come una variabile casuale con una propria distribuzione di probabilit√†.\nIn questo framework, la probabilit√† congiunta di parametri e dati si calcola combinando la distribuzione condizionale dei dati dati i parametri con la distribuzione a priori dei parametri. La distribuzione posteriore si ottiene quindi applicando il teorema di Bayes come mostrato sopra.\nPer modelli complessi con molti parametri, il calcolo della distribuzione posteriore pu√≤ richiedere tecniche computazionali avanzate, come i metodi Monte Carlo basati su catene di Markov (MCMC).",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#applicazioni-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#applicazioni-dellaggiornamento-bayesiano",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.2 Applicazioni dell‚ÄôAggiornamento Bayesiano",
    "text": "37.2 Applicazioni dell‚ÄôAggiornamento Bayesiano\nPer spiegare il concetto di aggiornamento bayesiano in maniera intuitiva, McElreath propone il seguente esempio. Supponiamo di avere un globo terrestre e di volere stimare qual √® la proporzione della superficie terrestre coperta d‚Äôacqua. Per stimare questa proporzione eseguiamo il seguente esperimento casuale: lanciamo in aria il globo e poi lo afferriamo quando cade. Registriamo se la superficie sotto il nostro indice destro √® terra o acqua. Ripetiamo questa procedura un certo numero di volte e calcoliamo la proporzione di volte in cui abbiamo osservato ‚Äúacqua‚Äù. In ogni lancio, ogni valore della proporzione sconosciuta \\(p\\) pu√≤ essere pi√π o meno probabile, date le evidenze fornite dai lanci precedenti.\nUn modello bayesiano inizia assegnando un insieme di probabilit√† iniziali a ciascuno dei possibili valori \\(p\\), dette probabilit√† a priori. Poi, queste probabilit√† vengono aggiornate alla luce dei dati raccolti, producendo le probabilit√† a posteriori. Questo processo di aggiornamento √® una forma di apprendimento, conosciuto come aggiornamento bayesiano.\nNell‚Äôesempio di McElreath, supponiamo che il nostro modello bayesiano assegni inizialmente la stessa probabilit√† a ogni possibile valore di \\(p\\) (proporzione di acqua). Ora, consideriamo il primo grafico in alto a sinistra nella figura.\nLa linea tratteggiata orizzontale rappresenta la distribuzione di probabilit√† a priori per ciascun possibile valore di \\(p\\). Dopo aver osservato il primo lancio, che risulta in ‚ÄúW‚Äù (acqua), il modello aggiorna le probabilit√† di \\(p\\) alla linea continua. La probabilit√† che \\(p\\) = 0 scende a zero, indicando che √® impossibile non avere acqua, dato che abbiamo osservato almeno una traccia di acqua sul globo. Allo stesso modo, la probabilit√† che \\(p\\) &gt; 0.5 aumenta, poich√© non c‚Äô√® ancora evidenza di terra sul globo, quindi le probabilit√† a priori vengono modificate per essere coerenti con questa osservazione. Tuttavia, le differenze nelle probabilit√† non sono ancora molto grandi, poich√© le evidenze raccolte finora sono limitate. In questo modo, la quantit√† di evidenza vista finora si riflette nelle probabilit√† di ciascun valore di \\(p\\): la probabilit√† che \\(p\\) sia 0 √® zero e la probabilit√† che \\(p\\) sia 1 √® massima. Quindi, la distribuzione a posteriori di \\(p\\) √® rappresentata dalla linea continua che collega questi due estremi.\n\ndef beta(W, L, p):\n    return factorial(W + L + 1) / (factorial(W) * factorial(L)) * p ** W * (1-p) ** L\n\n\ndef plot_beta_from_observations(observations: str, resolution: int = 50, **plot_kwargs):\n    \"\"\"Calcualte the posterior for a string of observations\"\"\"\n    n_W = len(observations.replace(\"L\", \"\"))\n    n_L = len(observations) - n_W\n    proportions = np.linspace(0, 1, resolution)\n        \n    probs = beta(n_W, n_L, proportions)\n    plt.plot(proportions, probs, **plot_kwargs)\n    plt.yticks([])\n    plt.title(observations)\n    \n\n# Tossing the globe\nobservations = \"WLWWWLWLW\"\nfig, axs = plt.subplots(3, 3, figsize=(8, 8))\nfor ii in range(9):\n    ax = axs[ii // 3][ii % 3]\n    plt.sca(ax)\n    # Plot previous\n    if ii &gt; 0:\n        plot_beta_from_observations(observations[:ii], color='k', linestyle='--')\n    else:\n        # First observation, no previous data\n        plot_beta_from_observations('', color='k', linestyle='--')\n        \n    color = 'C1' if observations[ii] == 'W' else 'C0'\n    plot_beta_from_observations(observations[:ii+1], color=color, linewidth=4, alpha=.5)\n    \n    if not ii % 3:\n        plt.ylabel(\"posterior probability\")\n\n\n\n\n\n\n\n\nCorrezione e miglioramento del testo\nNei grafici successivi, vengono introdotti ulteriori campioni dal globo, uno alla volta. Ogni curva tratteggiata rappresenta la curva continua dal grafico precedente, spostandosi da sinistra a destra e dall‚Äôalto in basso.\nLa seconda osservazione √® ‚Äúterra‚Äù (L). La distribuzione a priori √® la linea tratteggiata del secondo pannello, mentre la distribuzione a posteriori √® la linea curva. Otteniamo questa curva poich√© assegniamo una probabilit√† pari a 0 agli eventi \\(p\\) = 0 (abbiamo osservato ‚Äúacqua‚Äù) e \\(p\\) = 1 (abbiamo osservato ‚Äúterra‚Äù). In due lanci, abbiamo osservato una volta ‚Äúterra‚Äù e una volta ‚Äúacqua‚Äù. Pertanto, la probabilit√† che \\(p\\) = 0.5 √® massima, da cui deriva la curva che abbiamo disegnato.\nIl terzo lancio del globo produce nuovamente ‚Äúacqua‚Äù. A questo punto, il valore pi√π probabile di \\(p\\) √® 0.75. Modifichiamo dunque la distribuzione a priori (linea tratteggiata nel terzo pannello) in modo da rappresentare le nostre nuove conoscenze, come indicato dalla linea continua.\nOgni volta che viene osservata ‚Äúacqua‚Äù (W), il picco della curva di probabilit√† si sposta a destra, verso valori maggiori di \\(p\\). Ogni volta che viene osservata ‚Äúterra‚Äù (L), si sposta nella direzione opposta. L‚Äôaltezza massima della curva aumenta con ogni campione, indicando che la probabilit√† complessiva (1) viene ridistribuita su un numero minore di valori di \\(p\\), i quali accumulano una maggiore probabilit√† man mano che cresce la quantit√† di evidenze. Con l‚Äôaggiunta di ogni nuova osservazione, la curva viene aggiornata in modo coerente con tutte le osservazioni precedenti.\n√à importante notare che ogni insieme aggiornato di probabilit√† diventa la probabilit√† iniziale per l‚Äôosservazione successiva. Ogni conclusione √® il punto di partenza per l‚Äôinferenza futura. Questo processo di aggiornamento funziona anche al contrario: conoscendo l‚Äôultimo set di probabilit√† e l‚Äôultima osservazione, √® possibile matematicamente dedurre la curva di probabilit√† precedente. I dati possono essere presentati al modello in qualsiasi ordine, o anche tutti insieme. Di solito, i dati vengono considerati tutti insieme per comodit√†, ma √® importante capire che ci√≤ rappresenta solo una semplificazione di un processo di apprendimento iterativo.\nQuesto esempio illustra come la funzione di probabilit√† a posteriori si modifichi progressivamente con l‚Äôacquisizione di nuove evidenze. Tale processo avviene automaticamente, riflettendo il meccanismo di aggiornamento delle credenze che caratterizza l‚Äôinferenza bayesiana. In ogni pannello, la transizione dalla linea tratteggiata alla linea piena simboleggia questo aggiornamento: la linea tratteggiata rappresenta la distribuzione di probabilit√† a priori, ovvero le nostre credenze iniziali prima dell‚Äôosservazione dei nuovi dati; la linea piena, invece, rappresenta la distribuzione di probabilit√† a posteriori, che integra le nuove evidenze ai preconcetti iniziali. Quest‚Äôultima rispecchia dunque una sintesi ottimizzata delle informazioni pregresse e attuali, offrendo una rappresentazione aggiornata e pi√π accurata della realt√† in esame.\nIn questo specifico esempio, la distribuzione a priori del parametro \\(p\\) √® la distribuzione uniforme indicata dalla linea tratteggiata del primo pannello. I dati sono costituiti dall‚Äôosservazione di 6 successi in 9 prove. La distribuzione a posteriori \\(p(\\theta \\mid y)\\) √® rappresentata dalla funzione continua presente nell‚Äôultimo pannello. L‚Äôaggiornamento bayesiano √® il passaggio dalla funzione a priori uniforme \\(p(\\theta)\\) alla funzione a posteriori \\(p(\\theta \\mid y)\\). La moda della funzione \\(p(\\theta \\mid y)\\) ci indica il valore pi√π verosimile di \\(\\theta\\) (proporzione di acqua sul globo terrestre) dopo aver osservato 6 successi in 9 prove del nostro esperimento casuale (lancio del mappamondo).",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "37¬† Modellazione bayesiana",
    "section": "37.3 Il Processo Generatore dei Dati",
    "text": "37.3 Il Processo Generatore dei Dati\nNel processo di aggiornamento bayesiano, il ricercatore deve fare un‚Äôassunzione sul modello statistico che governa la produzione dei dati osservati. Questo modello statistico si chiama ‚Äúprocesso generatore dei dati‚Äù. Nel caso presente, √® facile capire qual √® il modello generatore dei dati. I nostri dati corrispondono a una sequenza di prove bernoulliane indipendenti, generate da un processo in cui possiamo assumere che la probabilit√† di successo, ovvero la probabilit√† di osservare ‚Äúacqua‚Äù, resta costante nella sequenza di prove. Questo √® giustificato dal fatto che le caratteristiche del mappamondo (ovvero la distribuzione spaziale di acqua e terra) restano costanti. In tali circostanze, il modello statistico all‚Äôorigine dei dati osservati √® il modello binomiale. Tenuto costante il numero di prove, il modello binomiale dipende da un solo parametro: la probabilit√† di successo \\(\\theta\\) (nel caso presente, la proporzione di acqua sul globo terrestre).\nL‚Äôaggiornamento bayesiano riguarda dunque le nostre credenze rispetto a \\(\\theta\\). In questo esempio, siamo passati da una situazione in cui non avevamo informazioni su \\(\\theta\\), rappresentata da una distribuzione uniforme in cui tutti i valori di \\(\\theta\\) nell‚Äôintervallo unitario [0, 1] erano ugualmente possibili, a una situazione in cui, avendo osservato 6 successi in 9 prove e applicato il teorema di Bayes, le nostre credenze su \\(\\theta\\) sono rappresentate dalla curva continua nell‚Äôultimo pannello. La moda (o la media, o la mediana) di tale funzione rappresenta il valore pi√π verosimile di \\(\\theta\\), avendo osservato i dati e integrato tali informazioni con le nostre credenze a priori. L‚Äôincertezza della nostra credenza a posteriori √® rappresentata dall‚Äôampiezza della distribuzione di \\(p(\\theta \\mid y)\\). Se la massa di \\(p(\\theta \\mid y)\\) si distribuisce su un intervallo ampio del supporto di \\(\\theta\\), significa che la nostra incertezza a posteriori √® grande; al contrario, se la massa di \\(p(\\theta \\mid y)\\) si distribuisce su un intervallo molto piccolo del supporto di \\(\\theta\\), possiamo concludere che abbiamo poca incertezza su quale sia il vero valore di \\(\\theta\\).\nIn questo esempio abbiamo visto come integrare una distribuzione uniforme con i dati costituiti da \\(y\\) successi in \\(N\\) prove bernoulliane. Nel capitolo Capitolo 38 vedremo in maniera pi√π dettagliata come si produce l‚Äôaggiornamento bayesiano nel caso di distribuzioni a priori discrete o continue, uniformi o non uniformi.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "37¬† Modellazione bayesiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Aug 05 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nBaribault, Beth, e Anne GE Collins. 2023. ¬´Troubleshooting Bayesian cognitive models.¬ª Psychological Methods.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza bayesiana",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_inductive_inference.html",
    "href": "chapters/entropy/04_inductive_inference.html",
    "title": "77¬† Limiti dell‚Äôinferenza induttiva",
    "section": "",
    "text": "Introduzione\n√à fondamentale comprendere che la selezione di ipotesi attraverso il teorema di Bayes, e i suoi sviluppi come il confronto tra modelli tramite il calcolo dell‚ÄôExpected Log Predictive Density (ELPD), non risolve completamente il problema dell‚Äôinferenza statistica. Secondo McElreath (2020), queste procedure affrontano problemi in un ‚Äúpiccolo mondo‚Äù, ma non √® chiaro come queste soluzioni si estendano al ‚Äúgrande mondo‚Äù che ci interessa realmente. L‚Äôobiettivo di questo capitolo √® approfondire questi temi, illustrando la disconnessione tra la teoria dei fenomeni empirici e i modelli statistici semplificati che possiamo testare in pratica.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_inductive_inference.html#inferenza-statistica",
    "href": "chapters/entropy/04_inductive_inference.html#inferenza-statistica",
    "title": "77¬† Limiti dell‚Äôinferenza induttiva",
    "section": "77.1 Inferenza Statistica",
    "text": "77.1 Inferenza Statistica\nL‚Äôinferenza statistica √® un processo di inferenza induttiva in cui i dati osservati non forniscono informazioni sufficienti per essere certi del processo che li ha generati, e la regola di Bayes offre una soluzione ottimale. McElreath (2020) introduce il concetto di ‚ÄúGrande Mondo‚Äù, che rappresenta l‚Äôinfinit√† di processi possibili che potrebbero spiegare le nostre osservazioni. Poich√© effettuare inferenze dirette su tutte le possibili propriet√† del Grande Mondo √® impraticabile, ci orientiamo verso il ‚ÄúPiccolo Mondo‚Äù, una rappresentazione semplificata che considera un insieme finito di modelli e parametri rilevanti per il nostro studio.\nAd esempio, nell‚Äôanalisi dell‚Äôaltezza, potremmo proporre un modello probabilistico in cui l‚Äôaltezza segue una distribuzione normale, caratterizzata da una media (¬µ) e una deviazione standard (œÉ), con l‚Äôintento di stimare questi parametri ignoti. La collezione di distribuzioni di probabilit√† derivante dalla variazione dei parametri del modello nel Piccolo Mondo costituisce la funzione di verosimiglianza. Tuttavia, questo insieme √® spesso troppo ampio per essere gestito con facilit√†. La nostra conoscenza pregressa o le nostre convinzioni riguardo al fenomeno in esame ci assistono nel restringere le possibilit√†.\nNell‚Äôinferenza bayesiana, queste convinzioni iniziali vengono espresse tramite una densit√† di probabilit√† a priori, che attribuisce un peso ai possibili parametri del modello in base alle nostre convinzioni iniziali. La regola di Bayes, cuore dell‚Äôinferenza bayesiana, permette di aggiornare queste convinzioni alla luce dei nuovi dati osservati. Attraverso questo processo, otteniamo la probabilit√† a posteriori dei parametri, che fornisce una stima pi√π accurata del processo generativo dei dati, T.\nIn sintesi, l‚Äôinferenza statistica ci avvicina alla comprensione di fenomeni complessi attraverso la modellazione delle osservazioni via processi semplificati nel ‚ÄúPiccolo Mondo‚Äù. Grazie all‚Äôinferenza bayesiana, che integra le conoscenze pregresse ai nuovi dati, perfezioniamo le nostre stime per una comprensione pi√π profonda del vero processo sottostante. Non miriamo a un ‚Äúmodello perfetto‚Äù che rifletta ogni dettaglio del ‚ÄúGrande Mondo‚Äù, bens√¨ a individuare modelli del ‚ÄúPiccolo Mondo‚Äù che siano efficaci nel fare previsioni sul fenomeno studiato. Attraverso la statistica, disponiamo degli strumenti per costruire, valutare e selezionare modelli basati sull‚Äôinferenza bayesiana, che ci consentono di aggiornare e rifinire i nostri modelli in risposta a nuove informazioni. Questo processo ci guida verso modelli ‚Äúutili‚Äù, che, seppur non perfetti, ci permettono di fare previsioni accurate e di approfondire la nostra comprensione del fenomeno di interesse.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_inductive_inference.html#sec-poetic-validity",
    "href": "chapters/entropy/04_inductive_inference.html#sec-poetic-validity",
    "title": "77¬† Limiti dell‚Äôinferenza induttiva",
    "section": "77.2 Validit√† Poetica",
    "text": "77.2 Validit√† Poetica\nIn precedenza, abbiamo focalizzato la nostra attenzione sul teorema di Bayes come metodo per verificare la plausibilit√† di un‚Äôipotesi, uno dei motivi chiave della sua importanza. Tuttavia, √® essenziale comprendere che la quantificazione della plausibilit√† di un‚Äôipotesi non risolve il problema scientifico dell‚Äôinferenza. Questo problema √® stato ben caratterizzato da Navarro (2019), utilizzando una metafora di Box (1976):\n\nSince all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.\n\nIn questa metafora, i topi rappresentano i dettagli del nostro modello statistico, mentre la tigre √® la disconnessione tra i dati osservati, modellizzati dal teorema di Bayes, e la teoria del fenomeno, che rappresenta il centro del nostro interesse.\nPaul Meehl ha articolato questo problema distinguendo tre piani: la teoria sostanziale (A), l‚Äôipotesi statistica testabile (T) e le osservazioni (O). L‚Äôarticolazione tra questi tre piani della riflessione scientifica solleva importanti difficolt√†:\n\nThe map from substantive theory (A) to testable statistical hypothesis (T) goes through a derivation chain involving auxiliary theories, instruments, ceteris paribus assertions, and experimental conditions. The map from hypothesis to observation is through the statistical model manufactured by the derivation chain.\n\nLa teoria statistica offre vari mezzi per inferire la veridicit√† di T da O, di solito attraverso la regola di Bayes. Tuttavia, anche se inferiamo che T ha un‚Äôalta probabilit√† date tutte le nostre evidenze, ci√≤ non risolve il problema di calcolare la probabilit√† di A da T. Meehl sosteneva l‚Äôassenza di una procedura formale capace di tradurre rigorosamente tra le osservazioni empiriche (O) e la teoria scientifica (A).\nIl modello statistico, costruito attraverso una catena di derivazione, mappa l‚Äôipotesi (T) sulle osservazioni (O). L‚Äôinferenza statistica, tipicamente basata sul teorema di Bayes, permette di valutare la probabilit√† di T dato O. Tuttavia, il passaggio cruciale da T a A rimane problematico. Questo coinvolge una catena di derivazione che include teorie ausiliarie, strumenti, assunzioni ceteris paribus e condizioni sperimentali (Hardt e Recht 2022). Il passaggio inverso da O a A rimane dunque problematico e non caratterizzato da propriet√† formali rigide.\nQuesta disconnessione tra T e A √® stata descritta come una forma di ‚Äúvalidit√† poetica‚Äù. Questo concetto si riferisce alla capacit√† di un‚Äôidea di risuonare con l‚Äôintelletto e l‚Äôesperienza umana attraverso il linguaggio, anche quando non pu√≤ essere rigorosamente validata in termini scientifici o statistici. La validit√† poetica sottolinea l‚Äôimportanza dell‚Äôintuizione e della comprensione qualitativa nel processo di teorizzazione scientifica, complementando l‚Äôapproccio puramente quantitativo e formale (Hardt e Recht 2022).\nLa dicotomia tra concetti teorici e concetti empirici, manifestata nel processo di operazionalizzazione, chiarisce ulteriormente questa problematica (Hempel 1970). L‚Äôoperazionalizzazione dei concetti teorici in concetti empirici √® un processo arbitrario e uno-a-molti, che comporta diverse implicazioni:\n\nSottodeterminazione delle teorie: Nessun test di ipotesi pu√≤ essere considerato un test diretto di una teoria, dato che l‚Äôoperazionalizzazione introduce un elemento di arbitrariet√†.\nFlessibilit√† teorica: La relazione uno-a-molti tra concetti teorici ed empirici permette un raffinamento progressivo delle teorie.\nAmbiguit√† empirica: Operazionalizzazioni diverse possono portare a risultati contraddittori rispetto alla stessa teoria.\nNecessit√† di formalizzazione: Le teorie psicologiche devono essere espresse in termini formali per consentire predizioni quantitative.\n\nIn conclusione, il problema della demarcazione tra teoria e osservazione in psicologia rimane un tema aperto e fondamentale. La consapevolezza di queste limitazioni epistemologiche dovrebbe informare sia la pratica della ricerca empirica che l‚Äôinterpretazione dei suoi risultati, promuovendo un approccio pi√π critico alla costruzione, validazione e interpretazione delle teorie psicologiche.\n\n77.2.1 Between the Devil and the Deep Blue Sea\nPoich√© esistono diverse teorie concorrenti sul mondo, ciascuna rappresentata come modelli computazionali parametrizzati che forniscono interpretazioni diverse di un set di dati, come decidere quale modello sia meglio supportato dai dati? Questo pu√≤ essere formulato come un problema di inferenza statistica, con la cross-validation come uno dei metodi per trovare una risposta.\nNavarro (2019) osserva che, sebbene l‚Äôapproccio della selezione di modelli sia encomiabile, una procedura di selezione applicata a problemi semplificati √® un cattivo sostituto per i problemi inferenziali affrontati dagli scienziati. Gli scienziati sono consapevoli che tutti i modelli sono errati. Non comprendiamo pienamente i fenomeni che studiamo, e ogni descrizione formale basata su modelli del fenomeno √® errata in modo sconosciuto e sistematico. Spesso ci troviamo di fronte al dilemma tra il diavolo della decisione statistica e il mare aperto delle questioni scientifiche. La letteratura sulla selezione di modelli tende a porre troppa enfasi sui problemi statistici di scelta del modello e troppo poca sulle questioni scientifiche a cui si riferiscono.\nCapire come i pattern qualitativi nei dati empirici emergano naturalmente da un modello computazionale di un processo psicologico √® spesso pi√π utile scientificamente rispetto alla presentazione di una misura quantificata delle sue performance. Dato quanto poco comprendiamo delle diverse modalit√† in cui funziona la cognizione umana e l‚Äôartificialit√† della maggior parte degli studi sperimentali, √® lecito chiedersi quale sia lo scopo di quantificare la capacit√† di un modello di fare previsioni precise su ogni dettaglio nei dati. In pratica, molte esercitazioni in cui la scelta del modello si basa troppo su misure quantitative delle performance selezionano modelli basati su assunzioni ancillari, il che difficilmente risolve un problema scientifico di interesse.\nNavarro (2019), la caratteristica pi√π utile di un modello non √® la sua capacit√† di predire in maniera perfetta un determinato campione di dati, ma la sua capacit√† di generalizzazione. Per illustrare questo concetto, Navarro (2019) descrive il motivo per cui riteniamo il modello di Rescorla-Wagner sul condizionamento pavloviano (Rescorla & Wagner, 1972) un punto di svolta fondamentale nello sviluppo delle teorie dell‚Äôapprendimento. Sebbene il modello fornisse una buona spiegazione di una serie di fenomeni di condizionamento gi√† noti, come il blocco (Kamin, 1969), la sovrapposizione (Pavlov, 1927), l‚Äôinibizione condizionata (Rescorla, 1969) e gli effetti di contingenza (Rescorla, 1968), il contributo davvero impressionante non risiedeva nella capacit√† di predire nuovi dati da repliche di questi esperimenti, ma piuttosto nella capacit√† di anticipare nuovi fenomeni, come la sovraaspettativa (Lattal & Nakajima, 1998) e il super condizionamento (Rescorla, 1971). In altre parole, una delle funzioni pi√π importanti di una teoria scientifica non √® semplicemente quella di predire nuovi dati da esperimenti vecchi, ma di incoraggiare l‚Äôesplorazione diretta di nuovi territori, come illustrato dal ruolo significativo che il modello di Rescorla-Wagner ha avuto nell‚Äôaiutare i neuroscienziati a investigare i segnali di errore di previsione della ricompensa (ad esempio, Schultz, Dayan & Montague, 1997).\nGronau e Wagenmakers (2019) inquadrano la questione della selezione dei modelli come un dilemma pericoloso in cui si √® intrappolati tra due mostri della mitologia classica: la Scilla dell‚Äôoverfitting e la Cariddi dell‚Äôunderfitting. Secondo Navarro (2019), √® invece pi√π comune per un ricercatore trovarsi a fronteggiare un dilemma di natura diversa, ovvero la tensione tra il diavolo della decisione statistica e il profondo mare blu delle questioni scientifiche. Gran parte della letteratura sulla selezione dei modelli pone troppa enfasi sugli aspetti statistici della scelta del modello e troppo poca sulle domande scientifiche a cui questi modelli si rivolgono. Nella vita reale molti esercizi in cui la scelta del modello si basa eccessivamente su misure quantitative di performance selezionano essenzialmente modelli in base alle loro assunzioni accessorie. Ma non √® chiaro se e come questo risolva un problema scientifico di interesse.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_inductive_inference.html#riflessioni-conclusive",
    "href": "chapters/entropy/04_inductive_inference.html#riflessioni-conclusive",
    "title": "77¬† Limiti dell‚Äôinferenza induttiva",
    "section": "77.3 Riflessioni Conclusive",
    "text": "77.3 Riflessioni Conclusive\nIn questo capitolo, abbiamo esaminato le complessit√† e le sfide dell‚Äôinferenza statistica e della selezione dei modelli attraverso una lente bayesiana. Sebbene il teorema di Bayes e i suoi strumenti derivati, come l‚ÄôExpected Log Predictive Density (ELPD), siano potenti per aggiornare e confrontare modelli, essi operano principalmente in un ‚ÄúPiccolo Mondo‚Äù semplificato. Questo limita la nostra capacit√† di trarre conclusioni definitive sul ‚ÄúGrande Mondo‚Äù reale che ci interessa.\nLa ‚Äúvalidit√† poetica‚Äù sottolinea l‚Äôimportanza di riconoscere le limitazioni intrinseche delle nostre rappresentazioni statistiche e di valorizzare l‚Äôintuizione e la comprensione qualitativa nel contesto scientifico. La distinzione tra concetti teorici e osservazioni empiriche ci ricorda che, nonostante i progressi metodologici, rimane una disconnessione fondamentale tra la teoria e le osservazioni empiriche.\nInfine, la capacit√† di un modello di generalizzare, piuttosto che di prevedere perfettamente i dati osservati, emerge come un criterio cruciale per la sua utilit√† scientifica. L‚Äôesempio del modello di Rescorla-Wagner illustra come un buon modello possa stimolare nuove esplorazioni e approfondimenti, dimostrando che il vero valore di una teoria scientifica risiede nella sua capacit√† di guidare l‚Äôindagine futura piuttosto che semplicemente adattarsi ai dati esistenti.\nIn sintesi, questo capitolo ci invita a mantenere un equilibrio tra rigore quantitativo e intuizione qualitativa, riconoscendo i limiti delle nostre tecniche e cercando continuamente di migliorare le nostre rappresentazioni del complesso mondo reale.\n\n\n\n\nBox, George EP. 1976. ¬´Science and statistics¬ª. Journal of the American Statistical Association 71 (356): 791‚Äì99.\n\n\nGronau, Quentin F, e Eric-Jan Wagenmakers. 2019. ¬´Limitations of Bayesian leave-one-out cross-validation for model selection¬ª. Computational brain & behavior 2 (1): 1‚Äì11.\n\n\nHardt, Moritz, e Benjamin Recht. 2022. Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton, NJ: Princeton University Press.\n\n\nHempel, Carl Gustav. 1970. La formazione dei concetti e delle teorie nella scienza empirica. Feltrinelli.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nNavarro, Danielle J. 2019. ¬´Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection¬ª. Computational Brain & Behavior 2 (1): 28‚Äì34.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_inductive_inference.html#section",
    "href": "chapters/entropy/04_inductive_inference.html#section",
    "title": "77¬† Inferenza induttiva",
    "section": "77.3 ",
    "text": "77.3 \nIn questa sezione della dispensa abbiamo affrontato il tema della selezioni di modelli. Given two or more competing theories about the world, each instantiated as parameterised computational models that provide different accounts of a data set, how should we decide which model is better supported by the data? Abbiamo visto come questo pu√≤ essere formulato come un statistical inference problem, with cross-validation (tra gli altri metodi) come possibile metodo per trovare una risposta.\nTo highlight the behaviour of different model selec- tion methods, we often consider ‚Äútoy problems‚Äù, simplified versions of serious inferential scenarios designed to elicit different intuitions about whether the model selection proce- dure behaves sensibly. In altre parole, sostituiamo un problema che riguarda il ‚Äúgrande mondo‚Äù (un problema impossibile da risolvere) con un problema che riguarda il ‚Äúpiccolo mondo‚Äù, laddove una soluzione pu√≤ essere trovata.\nNavarro (2019) fa notare che, bench√© l‚Äôapproccio della selezione di modelli sia encomiabile, a selection procedure applied to toy problems is a poor proxy for the inferential problems 40 facing scientists. E cita George Box‚Äôs (1976, p 792)\n\nSince all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_inductive_inference.html#between-the-devil-and-the-deep-blue-sea",
    "href": "chapters/entropy/04_inductive_inference.html#between-the-devil-and-the-deep-blue-sea",
    "title": "77¬† Inferenza induttiva",
    "section": "77.3 Between the devil and the deep blue sea",
    "text": "77.3 Between the devil and the deep blue sea\nDato che esistono diverse teorie concorrenti sul mondo, ciascuna rappresentata come modelli computazionali parametrizzati che forniscono interpretazioni diverse di un set di dati, come decidere quale modello sia meglio supportato dai dati? Questo pu√≤ essere formulato come un problema di inferenza statistica, con la cross-validation come uno dei metodi per trovare una risposta.\nNavarro (2019) nota che, sebbene l‚Äôapproccio della selezione di modelli sia encomiabile, una procedura di selezione applicata a problemi semplificati √® un cattivo sostituto per i problemi inferenziali affrontati dagli scienziati.\nGli scienziati sono consapevoli che tutti i modelli sono errati. Non comprendiamo pienamente i fenomeni che studiamo, e ogni descrizione formale basata su modelli del fenomeno √® errata in modo sconosciuto e sistematico. Spesso ci troviamo di fronte al dilemma tra il diavolo della decisione statistica e il mare aperto delle questioni scientifiche. La letteratura sulla selezione di modelli tende a porre troppa enfasi sui problemi statistici di scelta del modello e troppo poca sulle questioni scientifiche a cui si riferiscono.\nCapire come i pattern qualitativi nei dati empirici emergano naturalmente da un modello computazionale di un processo psicologico √® spesso pi√π utile scientificamente rispetto alla presentazione di una misura quantificata delle sue performance. Dato quanto poco comprendiamo delle diverse modalit√† in cui funziona la cognizione umana e l‚Äôartificialit√† della maggior parte degli studi sperimentali, √® lecito chiedersi quale sia lo scopo di quantificare la capacit√† di un modello di fare previsioni precise su ogni dettaglio nei dati. In pratica, molte esercitazioni in cui la scelta del modello si basa troppo su misure quantitative delle performance selezionano modelli basati su assunzioni ancillari, il che difficilmente risolve un problema scientifico di interesse.\nSecondo Navarro (2019), la caratteristica pi√π utile di un modello non √® la sua capacit√† di predire in maniera perfetta un determinato campione di dati, ma la sua capacit√† di generalizzazione.\nPer illustrare questo concetto, Navarro (2019) descrive il motivo per cui riteniamo il modello di Rescorla-Wagner sul condizionamento pavloviano (Rescorla & Wagner, 1972) un punto di svolta fondamentale nello sviluppo delle teorie dell‚Äôapprendimento. Sebbene il modello fornisse una buona spiegazione di una serie di fenomeni di condizionamento gi√† noti, come il blocco (Kamin, 1969), la sovrapposizione (Pavlov, 1927), l‚Äôinibizione condizionata (Rescorla, 1969) e gli effetti di contingenza (Rescorla, 1968), il contributo davvero impressionante non risiedeva nella capacit√† di predire nuovi dati da repliche di questi esperimenti, ma piuttosto nella capacit√† di anticipare nuovi fenomeni, come la sovraaspettativa (Lattal & Nakajima, 1998) e il super condizionamento (Rescorla, 1971). In altre parole, una delle funzioni pi√π importanti di una teoria scientifica non √® semplicemente quella di predire nuovi dati da esperimenti vecchi, ma di incoraggiare l‚Äôesplorazione diretta di nuovi territori, come illustrato dal ruolo significativo che il modello di Rescorla-Wagner ha avuto nell‚Äôaiutare i neuroscienziati a investigare i segnali di errore di previsione della ricompensa (ad esempio, Schultz, Dayan & Montague, 1997).\nGronau e Wagenmakers (2019) inquadrano la questione della selezione dei modelli come un dilemma pericoloso in cui si √® intrappolati tra due mostri della mitologia classica: la Scilla dell‚Äôoverfitting e la Cariddi dell‚Äôunderfitting. Secondo Navarro (2019), √® invece pi√π comune per un ricercatore trovarsi a fronteggiare un dilemma di natura diversa, ovvero la tensione tra il diavolo della decisione statistica e il profondo mare blu delle questioni scientifiche. Secondo Navarro (2019), gran parte della letteratura sulla selezione dei modelli pone troppa enfasi sugli aspetti statistici della scelta del modello e troppo poca sulle domande scientifiche a cui questi modelli si rivolgono. Nella vita reale molti esercizi in cui la scelta del modello si basa eccessivamente su misure quantitative di performance selezionano essenzialmente modelli in base alle loro assunzioni accessorie. Ma non √® chiaro se e come questo risolva un problema scientifico di interesse.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Inferenza induttiva</span>"
    ]
  }
]